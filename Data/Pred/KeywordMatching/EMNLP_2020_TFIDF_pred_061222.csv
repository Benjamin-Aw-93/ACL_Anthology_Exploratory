Labels,Paper Name,abstract,Text,Lemm Stemmed Text,Dictionary Output,Predicted Label,Label outcome
Computational Social Science and Social Media,Named Entity Recognition for Social Media Texts with Semantic Augmentation,"Existing approaches for named entity recognition suffer from data sparsity problems when conducted on short and informal texts, especially user-generated social media content. Semantic augmentation is a potential way to alleviate this problem. Given that rich semantic information is implicitly preserved in pre-trained word embeddings, they are potential ideal resources for semantic augmentation. In this paper, we propose a neural-based approach to NER for social media texts where both local (from running text) and augmented semantics are taken into account. In particular, we obtain the augmented semantic information from a large-scale corpus, and propose an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively. Extensive experiments are performed on three benchmark datasets collected from English and Chinese social media platforms, where the results demonstrate the superiority of our approach to previous studies across all three datasets. 1 * Equal contribution.","Named Entity Recognition for Social Media Texts with Semantic Augmentation Existing approaches for named entity recognition suffer from data sparsity problems when conducted on short and informal texts, especially user-generated social media content. Semantic augmentation is a potential way to alleviate this problem. Given that rich semantic information is implicitly preserved in pre-trained word embeddings, they are potential ideal resources for semantic augmentation. In this paper, we propose a neural-based approach to NER for social media texts where both local (from running text) and augmented semantics are taken into account. In particular, we obtain the augmented semantic information from a large-scale corpus, and propose an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively. Extensive experiments are performed on three benchmark datasets collected from English and Chinese social media platforms, where the results demonstrate the superiority of our approach to previous studies across all three datasets. 1 * Equal contribution.","name entity recognition social medium text semantic augmentation exist approach name entity recognition suffer datum sparsity problem conduct short informal text , especially user - generate social medium content . semantic augmentation potential way alleviate problem . give rich semantic information implicitly preserve pre - trained word embedding , potential ideal resource semantic augmentation . paper , propose neural - base approach ner social medium text local ( run text ) augment semantic take account . particular , obtain augment semantic information large - scale corpus , propose attentive semantic augmentation module gate module encode aggregate information , respectively . extensive experiment perform benchmark dataset collect english chinese social medium platform , result demonstrate superiority approach previous study dataset . 1 * equal contribution .","{'Computational Social Science and Social Media': 12, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 5, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Suicidal Risk Detection for Military Personnel,"We analyze social media for detecting the suicidal risk of military personnel, which is especially crucial for countries with compulsory military service such as the Republic of Korea. From a widely-used Korean social Q&A site, we collect posts containing military-relevant content written by active-duty military personnel. We then annotate the posts with two groups of experts: military experts and mental health experts. Our dataset includes 2,791 posts with 13,955 corresponding expert annotations of suicidal risk levels, and this dataset is available to researchers who consent to research ethics agreement. Using various finetuned state-of-the-art language models, we predict the level of suicide risk, reaching .88 F1 score for classifying the risks.","Suicidal Risk Detection for Military Personnel We analyze social media for detecting the suicidal risk of military personnel, which is especially crucial for countries with compulsory military service such as the Republic of Korea. From a widely-used Korean social Q&A site, we collect posts containing military-relevant content written by active-duty military personnel. We then annotate the posts with two groups of experts: military experts and mental health experts. Our dataset includes 2,791 posts with 13,955 corresponding expert annotations of suicidal risk levels, and this dataset is available to researchers who consent to research ethics agreement. Using various finetuned state-of-the-art language models, we predict the level of suicide risk, reaching .88 F1 score for classifying the risks.","suicidal risk detection military personnel analyze social medium detect suicidal risk military personnel , especially crucial country compulsory military service republic korea . widely - korean social q&a site , collect post contain military - relevant content write active - duty military personnel . annotate post group expert : military expert mental health expert . dataset include 2,791 post 13,955 correspond expert annotation suicidal risk level , dataset available researcher consent research ethic agreement . finetune state - - - art language model , predict level suicide risk , reach .88 f1 score classify risk .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media,"In this paper, we suggest a minimallysupervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control, and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.","Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media In this paper, we suggest a minimallysupervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control, and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.","weakly supervised learning nuanced frame analyze polarization news medium paper , suggest minimallysupervised approach identify nuanced frame news article coverage politically divisive topic . suggest break broad policy frame suggest boydstun et al . , 2014 fine - grained subframe capture difference political ideology well way . evaluate suggest subframe embedding , learn minimal supervision , topic , , immigration , gun - control , abortion . demonstrate ability subframe capture ideological difference analyze political discourse news medium .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Modeling Protagonist Emotions for Emotion-Aware Storytelling,"Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (Emo-Sup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.","Modeling Protagonist Emotions for Emotion-Aware Storytelling Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (Emo-Sup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.","model protagonist emotion emotion - aware storytelling emotion evolution play central role create captivating story . paper , present study model emotional trajectory protagonist neural storytelling . design method generate story adhere give story title desire emotion arc protagonist . model include emotion supervision ( emo - sup ) emotion - reinforced ( emorl ) model . emorl model use special reward design regularize story generation process reinforcement learning . automatic manual evaluation demonstrate model significantly well generate story follow desire emotion arc compare baseline method , sacrifice story quality .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 8, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Computational Social Science and Social Media,Investigating African-American Vernacular English in Transformer-Based Text Generation,"The growth of social media has encouraged the written use of African American Vernacular English (AAVE), which has traditionally been used only in oral contexts. However, NLP models have historically been developed using dominant English varieties, such as Standard American English (SAE), due to text corpora availability. We investigate the performance of GPT-2 on AAVE text by creating a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating syntactic structure and AAVE-or SAE-specific language for each pair. We evaluate each sample and its GPT-2 generated text with pretrained sentiment classifiers and find that while AAVE text results in more classifications of negative sentiment than SAE, the use of GPT-2 generally increases occurrences of positive sentiment for both. Additionally, we conduct human evaluation of AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall quality.","Investigating African-American Vernacular English in Transformer-Based Text Generation The growth of social media has encouraged the written use of African American Vernacular English (AAVE), which has traditionally been used only in oral contexts. However, NLP models have historically been developed using dominant English varieties, such as Standard American English (SAE), due to text corpora availability. We investigate the performance of GPT-2 on AAVE text by creating a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating syntactic structure and AAVE-or SAE-specific language for each pair. We evaluate each sample and its GPT-2 generated text with pretrained sentiment classifiers and find that while AAVE text results in more classifications of negative sentiment than SAE, the use of GPT-2 generally increases occurrences of positive sentiment for both. Additionally, we conduct human evaluation of AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall quality.","investigate african - american vernacular english transformer - base text generation growth social medium encourage write use african american vernacular english ( aave ) , traditionally oral context . , nlp model historically develop dominant english variety , standard american english ( sae ) , text corpora availability . investigate performance gpt-2 aave text create dataset intent - equivalent parallel aave / sae tweet pair , isolate syntactic structure aave - sae - specific language pair . evaluate sample gpt-2 generate text pretrained sentiment classifier find aave text result classification negative sentiment sae , use gpt-2 generally increase occurrence positive sentiment . additionally , conduct human evaluation aave sae text generate gpt-2 compare contextual rigor overall quality .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 12, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Computational Social Science and Social Media,Toward Micro-Dialect Identification in Diaglossic and Code-Switched Environments,"Although prediction of dialects is an important language processing task, with a wide range of applications, existing work is largely limited to coarse-grained varieties. Inspired by geolocation research, we propose the novel task of Micro-Dialect Identification (MDI) and introduce MARBERT, a new language model with striking abilities to predict a fine-grained variety (as small as that of a city) given a single, short message. For modeling, we offer a range of novel spatially and linguistically-motivated multi-task learning models. To showcase the utility of our models, we introduce a new, large-scale dataset of Arabic micro-varieties (low-resource) suited to our tasks. MARBERT predicts micro-dialects with 9.9% F 1 , ∼ 76× better than a majority class baseline. Our new language model also establishes new state-ofthe-art on several external tasks. 1","Toward Micro-Dialect Identification in Diaglossic and Code-Switched Environments Although prediction of dialects is an important language processing task, with a wide range of applications, existing work is largely limited to coarse-grained varieties. Inspired by geolocation research, we propose the novel task of Micro-Dialect Identification (MDI) and introduce MARBERT, a new language model with striking abilities to predict a fine-grained variety (as small as that of a city) given a single, short message. For modeling, we offer a range of novel spatially and linguistically-motivated multi-task learning models. To showcase the utility of our models, we introduce a new, large-scale dataset of Arabic micro-varieties (low-resource) suited to our tasks. MARBERT predicts micro-dialects with 9.9% F 1 , ∼ 76× better than a majority class baseline. Our new language model also establishes new state-ofthe-art on several external tasks. 1","micro - dialect identification diaglossic code - switch environment prediction dialect important language processing task , wide range application , exist work largely limit coarse - grained variety . inspire geolocation research , propose novel task micro - dialect identification ( mdi ) introduce marbert , new language model striking ability predict fine - grained variety ( small city ) give single , short message . modeling , offer range novel spatially linguistically - motivate multi - task learning model . showcase utility model , introduce new , large - scale dataset arabic micro - variety ( low - resource ) suit task . marbert predict micro - dialect 9.9 % f 1 , ∼ 76× well majority class baseline . new language model establish new state - ofthe - art external task . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Computational Social Science and Social Media,"Continuity of Topic, Interaction, and Query: Learning to Quote in Online Conversations","Quotations are crucial for successful explanations and persuasions in interpersonal communications. However, finding what to quote in a conversation is challenging for both humans and machines. This work studies automatic quotation generation in an online conversation and explores how language consistency affects whether a quotation fits the given context. Here, we capture the contextual consistency of a quotation in terms of latent topics, interactions with the dialogue history, and coherence to the query turn's existing content. Further, an encoder-decoder neural framework is employed to continue the context with a quotation via language generation. Experiment results on two large-scale datasets in English and Chinese demonstrate that our quotation generation model outperforms the state-of-the-art models. Further analysis shows that topic, interaction, and query consistency are all helpful to learn how to quote in online conversations.","Continuity of Topic, Interaction, and Query: Learning to Quote in Online Conversations Quotations are crucial for successful explanations and persuasions in interpersonal communications. However, finding what to quote in a conversation is challenging for both humans and machines. This work studies automatic quotation generation in an online conversation and explores how language consistency affects whether a quotation fits the given context. Here, we capture the contextual consistency of a quotation in terms of latent topics, interactions with the dialogue history, and coherence to the query turn's existing content. Further, an encoder-decoder neural framework is employed to continue the context with a quotation via language generation. Experiment results on two large-scale datasets in English and Chinese demonstrate that our quotation generation model outperforms the state-of-the-art models. Further analysis shows that topic, interaction, and query consistency are all helpful to learn how to quote in online conversations.","continuity topic , interaction , query : learn quote online conversation quotation crucial successful explanation persuasion interpersonal communication . , find quote conversation challenging human machine . work study automatic quotation generation online conversation explore language consistency affect quotation fit give context . , capture contextual consistency quotation term latent topic , interaction dialogue history , coherence query turn exist content . , encoder - decoder neural framework employ continue context quotation language generation . experiment result large - scale dataset english chinese demonstrate quotation generation model outperform state - - - art model . analysis show topic , interaction , query consistency helpful learn quote online conversation .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Computational Social Science and Social Media,On the Reliability and Validity of Detecting Approval of Political Actors in Tweets,"Social media sites like Twitter possess the potential to complement surveys that measure political opinions and, more specifically, political actors' approval. However, new challenges related to the reliability and validity of social-media-based estimates arise. Various sentiment analysis and stance detection methods have been developed and used in previous research to measure users' political opinions based on their content on social media. In this work, we attempt to gauge the efficacy of untargeted sentiment, targeted sentiment, and stance detection methods in labeling various political actors' approval by benchmarking them across several datasets. We also contrast the performance of these pretrained methods that can be used in an off-the-shelf (OTS) manner against a set of models trained on minimal custom data. We find that OTS methods have low generalizability on unseen and familiar targets, while low-resource custom models are more robust. Our work sheds light on the strengths and limitations of existing methods proposed for understanding politicians' approval from tweets.","On the Reliability and Validity of Detecting Approval of Political Actors in Tweets Social media sites like Twitter possess the potential to complement surveys that measure political opinions and, more specifically, political actors' approval. However, new challenges related to the reliability and validity of social-media-based estimates arise. Various sentiment analysis and stance detection methods have been developed and used in previous research to measure users' political opinions based on their content on social media. In this work, we attempt to gauge the efficacy of untargeted sentiment, targeted sentiment, and stance detection methods in labeling various political actors' approval by benchmarking them across several datasets. We also contrast the performance of these pretrained methods that can be used in an off-the-shelf (OTS) manner against a set of models trained on minimal custom data. We find that OTS methods have low generalizability on unseen and familiar targets, while low-resource custom models are more robust. Our work sheds light on the strengths and limitations of existing methods proposed for understanding politicians' approval from tweets.","reliability validity detect approval political actor tweet social medium site like twitter possess potential complement survey measure political opinion , specifically , political actor ' approval . , new challenge relate reliability validity social - media - base estimate arise . sentiment analysis stance detection method develop previous research measure user ' political opinion base content social medium . work , attempt gauge efficacy untargeted sentiment , targeted sentiment , stance detection method label political actor ' approval benchmarke dataset . contrast performance pretrained method - - shelf ( ots ) manner set model train minimal custom datum . find ots method low generalizability unseen familiar target , low - resource custom model robust . work shed light strength limitation exist method propose understand politician ' approval tweet .","{'Computational Social Science and Social Media': 14, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Reactive Supervision: A New Method for Collecting Sarcasm Data,"Sarcasm detection is an important task in affective computing, requiring large amounts of labeled data. We introduce reactive supervision, a novel data collection method that utilizes the dynamics of online conversations to overcome the limitations of existing data collection techniques. We use the new method to create and release a first-of-its-kind large dataset of tweets with sarcasm perspective labels and new contextual features. The dataset is expected to advance sarcasm detection research. Our method can be adapted to other affective computing domains, thus opening up new research opportunities.","Reactive Supervision: A New Method for Collecting Sarcasm Data Sarcasm detection is an important task in affective computing, requiring large amounts of labeled data. We introduce reactive supervision, a novel data collection method that utilizes the dynamics of online conversations to overcome the limitations of existing data collection techniques. We use the new method to create and release a first-of-its-kind large dataset of tweets with sarcasm perspective labels and new contextual features. The dataset is expected to advance sarcasm detection research. Our method can be adapted to other affective computing domains, thus opening up new research opportunities.","reactive supervision : new method collect sarcasm datum sarcasm detection important task affective computing , require large amount label datum . introduce reactive supervision , novel data collection method utilize dynamic online conversation overcome limitation exist data collection technique . use new method create release - - - kind large dataset tweet sarcasm perspective label new contextual feature . dataset expect advance sarcasm detection research . method adapt affective computing domain , open new research opportunity .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Computational Social Science and Social Media,An Embedding Model for Estimating Legislative Preferences from the Frequency and Sentiment of Tweets,"Legislator preferences are typically represented as measures of general ideology estimated from roll call votes on legislation, potentially masking important nuances in legislators' political attitudes. In this paper we introduce a method of measuring more specific legislator attitudes using an alternative expression of preferences: tweeting. Specifically, we present an embedding-based model for predicting the frequency and sentiment of legislator tweets. To illustrate our method, we model legislators' attitudes towards President Donald Trump as vector embeddings that interact with embeddings for Trump himself constructed using a neural network from the text of his daily tweets. We demonstrate the predictive performance of our model on tweets authored by members of the U.S. House and Senate related to the president from November 2016 to February 2018. We further assess the quality of our learned representations for legislators by comparing to traditional measures of legislator preferences.","An Embedding Model for Estimating Legislative Preferences from the Frequency and Sentiment of Tweets Legislator preferences are typically represented as measures of general ideology estimated from roll call votes on legislation, potentially masking important nuances in legislators' political attitudes. In this paper we introduce a method of measuring more specific legislator attitudes using an alternative expression of preferences: tweeting. Specifically, we present an embedding-based model for predicting the frequency and sentiment of legislator tweets. To illustrate our method, we model legislators' attitudes towards President Donald Trump as vector embeddings that interact with embeddings for Trump himself constructed using a neural network from the text of his daily tweets. We demonstrate the predictive performance of our model on tweets authored by members of the U.S. House and Senate related to the president from November 2016 to February 2018. We further assess the quality of our learned representations for legislators by comparing to traditional measures of legislator preferences.","embedding model estimate legislative preference frequency sentiment tweet legislator preference typically represent measure general ideology estimate roll vote legislation , potentially mask important nuance legislator ' political attitude . paper introduce method measure specific legislator attitude alternative expression preference : tweeting . specifically , present embedding - base model predict frequency sentiment legislator tweet . illustrate method , model legislator ' attitude president donald trump vector embedding interact embedding trump construct neural network text daily tweet . demonstrate predictive performance model tweet author member u.s. house senate relate president november 2016 february 2018 . assess quality learn representation legislator compare traditional measure legislator preference .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 16, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Computational Social Science and Social Media,Measuring Information Propagation in Literary Social Networks,"We present the task of modeling information propagation in literature, in which we seek to identify pieces of information passing from character A to character B to character C, only given a description of their activity in text. We describe a new pipeline for measuring information propagation in this domain and publish a new dataset for speaker attribution, enabling the evaluation of an important component of this pipeline on a wider range of literary texts than previously studied. Using this pipeline, we analyze the dynamics of information propagation in over 5,000 works of English fiction, finding that information flows through characters that fill structural holes connecting different communities, and that characters who are women are depicted as filling this role much more frequently than characters who are men.","Measuring Information Propagation in Literary Social Networks We present the task of modeling information propagation in literature, in which we seek to identify pieces of information passing from character A to character B to character C, only given a description of their activity in text. We describe a new pipeline for measuring information propagation in this domain and publish a new dataset for speaker attribution, enabling the evaluation of an important component of this pipeline on a wider range of literary texts than previously studied. Using this pipeline, we analyze the dynamics of information propagation in over 5,000 works of English fiction, finding that information flows through characters that fill structural holes connecting different communities, and that characters who are women are depicted as filling this role much more frequently than characters who are men.","measure information propagation literary social network present task model information propagation literature , seek identify piece information pass character character b character c , give description activity text . describe new pipeline measure information propagation domain publish new dataset speaker attribution , enable evaluation important component pipeline wide range literary text previously study . pipeline , analyze dynamic information propagation 5,000 work english fiction , find information flow character fill structural hole connect different community , character woman depict fill role frequently character man .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 12, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Computational Social Science and Social Media,A Time-Aware Transformer Based Model for Suicide Ideation Detection on Social Media,"Social media's ubiquity fosters a space for users to exhibit suicidal thoughts outside of traditional clinical settings. Understanding the build-up of such ideation is critical for the identification of at-risk users and suicide prevention. Suicide ideation is often linked to a history of mental depression. The emotional spectrum of a user's historical activity on social media can be indicative of their mental state over time. In this work, we focus on identifying suicidal intent in English tweets by augmenting linguistic models with historical context. We propose STATENet, a timeaware transformer based model for preliminary screening of suicidal risk on social media. STATENet outperforms competitive methods, demonstrating the utility of emotional and temporal contextual cues for suicide risk assessment. We discuss the empirical, qualitative, practical, and ethical aspects of STATENet for suicide ideation detection. 1","A Time-Aware Transformer Based Model for Suicide Ideation Detection on Social Media Social media's ubiquity fosters a space for users to exhibit suicidal thoughts outside of traditional clinical settings. Understanding the build-up of such ideation is critical for the identification of at-risk users and suicide prevention. Suicide ideation is often linked to a history of mental depression. The emotional spectrum of a user's historical activity on social media can be indicative of their mental state over time. In this work, we focus on identifying suicidal intent in English tweets by augmenting linguistic models with historical context. We propose STATENet, a timeaware transformer based model for preliminary screening of suicidal risk on social media. STATENet outperforms competitive methods, demonstrating the utility of emotional and temporal contextual cues for suicide risk assessment. We discuss the empirical, qualitative, practical, and ethical aspects of STATENet for suicide ideation detection. 1","time - aware transformer base model suicide ideation detection social media social medium ubiquity foster space user exhibit suicidal thought outside traditional clinical setting . understand build - ideation critical identification - risk user suicide prevention . suicide ideation link history mental depression . emotional spectrum user historical activity social media indicative mental state time . work , focus identify suicidal intent english tweet augment linguistic model historical context . propose statenet , timeaware transformer base model preliminary screening suicidal risk social medium . statenet outperform competitive method , demonstrate utility emotional temporal contextual cue suicide risk assessment . discuss empirical , qualitative , practical , ethical aspect statenet suicide ideation detection . 1","{'Computational Social Science and Social Media': 9, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Condolence and Empathy in Online Communities,"Offering condolence is a natural reaction to hearing someone's distress. Individuals frequently express distress in social media, where some communities can provide support. However, not all condolence is equal-trite responses offer little actual support despite their good intentions. Here, we develop computational tools to create a massive dataset of 11.4M expressions of distress and 2.8M corresponding offerings of condolence in order to examine the dynamics of condolence online. Our study reveals widespread disparity in what types of distress receive supportive condolence rather than just engagement. Building on studies from social psychology, we analyze the language of condolence and develop a new dataset for quantifying the empathy in a condolence using appraisal theory. Finally, we demonstrate that the features of condolence individuals find most helpful online differ substantially in their features from those seen in interpersonal settings.","Condolence and Empathy in Online Communities Offering condolence is a natural reaction to hearing someone's distress. Individuals frequently express distress in social media, where some communities can provide support. However, not all condolence is equal-trite responses offer little actual support despite their good intentions. Here, we develop computational tools to create a massive dataset of 11.4M expressions of distress and 2.8M corresponding offerings of condolence in order to examine the dynamics of condolence online. Our study reveals widespread disparity in what types of distress receive supportive condolence rather than just engagement. Building on studies from social psychology, we analyze the language of condolence and develop a new dataset for quantifying the empathy in a condolence using appraisal theory. Finally, we demonstrate that the features of condolence individuals find most helpful online differ substantially in their features from those seen in interpersonal settings.","condolence empathy online community offer condolence natural reaction hear distress . individual frequently express distress social medium , community provide support . , condolence equal - trite response offer little actual support despite good intention . , develop computational tool create massive dataset 11.4 m expression distress 2.8 m correspond offering condolence order examine dynamic condolence online . study reveal widespread disparity type distress receive supportive condolence engagement . build study social psychology , analyze language condolence develop new dataset quantify empathy condolence appraisal theory . finally , demonstrate feature condolence individual find helpful online differ substantially feature see interpersonal setting .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Help! Need Advice on Identifying Advice,"Humans use language to accomplish a wide variety of tasks -asking for and giving advice being one of them. In online advice forums, advice is mixed in with non-advice, like emotional support, and is sometimes stated explicitly, sometimes implicitly. Understanding the language of advice would equip systems with a better grasp of language pragmatics; practically, the ability to identify advice would drastically increase the efficiency of adviceseeking online, as well as advice-giving in natural language generation systems. We present a dataset in English from two Reddit advice forums -r/AskParents and r/needadvice -annotated for whether sentences in posts contain advice or not. Our analysis reveals rich linguistic phenomena in advice discourse. We present preliminary models showing that while pre-trained language models are able to capture advice better than rulebased systems, advice identification is challenging, and we identify directions for future research.","Help! Need Advice on Identifying Advice Humans use language to accomplish a wide variety of tasks -asking for and giving advice being one of them. In online advice forums, advice is mixed in with non-advice, like emotional support, and is sometimes stated explicitly, sometimes implicitly. Understanding the language of advice would equip systems with a better grasp of language pragmatics; practically, the ability to identify advice would drastically increase the efficiency of adviceseeking online, as well as advice-giving in natural language generation systems. We present a dataset in English from two Reddit advice forums -r/AskParents and r/needadvice -annotated for whether sentences in posts contain advice or not. Our analysis reveals rich linguistic phenomena in advice discourse. We present preliminary models showing that while pre-trained language models are able to capture advice better than rulebased systems, advice identification is challenging, and we identify directions for future research.","help ! need advice identify advice human use language accomplish wide variety task -aske give advice . online advice forum , advice mix non - advice , like emotional support , state explicitly , implicitly . understand language advice equip system well grasp language pragmatic ; practically , ability identify advice drastically increase efficiency adviceseeking online , advice - giving natural language generation system . present dataset english reddit advice forum -r / askparents r / needadvice -annotate sentence post contain advice . analysis reveal rich linguistic phenomenon advice discourse . present preliminary model show pre - trained language model able capture advice well rulebased system , advice identification challenging , identify direction future research .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Computational Social Science and Social Media,Quantifying Intimacy in Language,"Intimacy is a fundamental aspect of how we relate to others in social settings. Language encodes the social information of intimacy through both topics and other more subtle cues (such as linguistic hedging and swearing). Here, we introduce a new computational framework for studying expressions of the intimacy in language with an accompanying dataset and deep learning model for accurately predicting the intimacy level of questions (Pearson's r=0.87). Through analyzing a dataset of 80.5M questions across social media, books, and films, we show that individuals employ interpersonal pragmatic moves in their language to align their intimacy with social settings. Then, in three studies, we further demonstrate how individuals modulate their intimacy to match social norms around gender, social distance, and audience, each validating key findings from studies in social psychology. Our work demonstrates that intimacy is a pervasive and impactful social dimension of language.","Quantifying Intimacy in Language Intimacy is a fundamental aspect of how we relate to others in social settings. Language encodes the social information of intimacy through both topics and other more subtle cues (such as linguistic hedging and swearing). Here, we introduce a new computational framework for studying expressions of the intimacy in language with an accompanying dataset and deep learning model for accurately predicting the intimacy level of questions (Pearson's r=0.87). Through analyzing a dataset of 80.5M questions across social media, books, and films, we show that individuals employ interpersonal pragmatic moves in their language to align their intimacy with social settings. Then, in three studies, we further demonstrate how individuals modulate their intimacy to match social norms around gender, social distance, and audience, each validating key findings from studies in social psychology. Our work demonstrates that intimacy is a pervasive and impactful social dimension of language.","quantify intimacy language intimacy fundamental aspect relate social setting . language encode social information intimacy topic subtle cue ( linguistic hedging swearing ) . , introduce new computational framework study expression intimacy language accompany dataset deep learning model accurately predict intimacy level question ( pearson r=0.87 ) . analyze dataset 80.5 m question social medium , book , film , individual employ interpersonal pragmatic move language align intimacy social setting . , study , demonstrate individual modulate intimacy match social norm gender , social distance , audience , validate key finding study social psychology . work demonstrate intimacy pervasive impactful social dimension language .","{'Computational Social Science and Social Media': 10, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 9, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 2, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Writing Strategies for Science Communication: Data and Computational Analysis,"Communicating complex scientific ideas without misleading or overwhelming the public is challenging. While science communication guides exist, they rarely offer empirical evidence for how their strategies are used in practice. Writing strategies that can be automatically recognized could greatly support science communication efforts by enabling tools to detect and suggest strategies for writers. We compile a set of writing strategies drawn from a wide range of prescriptive sources and develop an annotation scheme allowing humans to recognize them. We collect a corpus of 128K science writing documents in English and annotate a subset of this corpus. 1 We use the annotations to train transformer-based classifiers and measure the strategies' use in the larger corpus. We find that the use of strategies, such as storytelling and emphasizing the most important findings, varies significantly across publications with different reader audiences.","Writing Strategies for Science Communication: Data and Computational Analysis Communicating complex scientific ideas without misleading or overwhelming the public is challenging. While science communication guides exist, they rarely offer empirical evidence for how their strategies are used in practice. Writing strategies that can be automatically recognized could greatly support science communication efforts by enabling tools to detect and suggest strategies for writers. We compile a set of writing strategies drawn from a wide range of prescriptive sources and develop an annotation scheme allowing humans to recognize them. We collect a corpus of 128K science writing documents in English and annotate a subset of this corpus. 1 We use the annotations to train transformer-based classifiers and measure the strategies' use in the larger corpus. We find that the use of strategies, such as storytelling and emphasizing the most important findings, varies significantly across publications with different reader audiences.","writing strategies science communication : data computational analysis communicate complex scientific idea mislead overwhelm public challenging . science communication guide exist , rarely offer empirical evidence strategy practice . write strategy automatically recognize greatly support science communication effort enable tool detect suggest strategy writer . compile set writing strategy draw wide range prescriptive source develop annotation scheme allow human recognize . collect corpus 128 k science write document english annotate subset corpus . 1 use annotation train transformer - base classifier measure strategy ' use large corpus . find use strategy , storytelling emphasize important finding , vary significantly publication different reader audience .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Computational Social Science and Social Media,Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News,"Although many fact-checking systems have been developed in academia and industry, fake news is still proliferating on social media. These systems mostly focus on fact-checking but usually neglect online users who are the main drivers of the spread of misinformation. How can we use fact-checked information to improve users' consciousness of fake news to which they are exposed? How can we stop users from spreading fake news? To tackle these questions, we propose a novel framework to search for fact-checking articles, which address the content of an original tweet (that may contain misinformation) posted by online users. The search can directly warn fake news posters and online users (e.g. the posters' followers) about misinformation, discourage them from spreading fake news, and scale up verified content on social media. Our framework uses both text and images to search for fact-checking articles, and achieves promising results on real-world datasets. Our code and datasets are released at https:// github.com/nguyenvo09/EMNLP2020.","Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News Although many fact-checking systems have been developed in academia and industry, fake news is still proliferating on social media. These systems mostly focus on fact-checking but usually neglect online users who are the main drivers of the spread of misinformation. How can we use fact-checked information to improve users' consciousness of fake news to which they are exposed? How can we stop users from spreading fake news? To tackle these questions, we propose a novel framework to search for fact-checking articles, which address the content of an original tweet (that may contain misinformation) posted by online users. The search can directly warn fake news posters and online users (e.g. the posters' followers) about misinformation, discourage them from spreading fake news, and scale up verified content on social media. Our framework uses both text and images to search for fact-checking articles, and achieves promising results on real-world datasets. Our code and datasets are released at https:// github.com/nguyenvo09/EMNLP2020.","fact ? search fact - check information alleviate spread fake news fact - checking system develop academia industry , fake news proliferate social media . system focus fact - checking usually neglect online user main driver spread misinformation . use fact - check information improve user ' consciousness fake news expose ? stop user spread fake news ? tackle question , propose novel framework search fact - check article , address content original tweet ( contain misinformation ) post online user . search directly warn fake news poster online user ( e.g. poster ' follower ) misinformation , discourage spread fake news , scale verify content social medium . framework use text image search fact - check article , achieve promising result real - world dataset . code dataset release https:// github.com/nguyenvo09/emnlp2020 .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 12, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 11, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Computational Social Science and Social Media,Social Media Attributions in the Context of Water Crisis,"Attribution of natural disasters/collective misfortune is a widely-studied political science problem. However, such studies typically rely on surveys, expert opinions, or external signals such as voting outcomes. In this paper, we explore the viability of using unstructured, noisy social media data to complement traditional surveys through automatically extracting attribution factors. We present a novel prediction task of attribution tie detection of identifying the factors (e.g., poor city planning, exploding population etc.) held responsible for the crisis in a social media document. We focus on the 2019 Chennai water crisis that rapidly escalated into a discussion topic with global importance following alarming water-crisis statistics. On a challenging data set constructed from YouTube comments (72,098 comments posted by 43,859 users on 623 videos relevant to the crisis), we present a neural baseline to identify attribution ties that achieves a reasonable performance (accuracy: 87.34% on attribution detection and 81.37% on attribution resolution). We release the first annotated data set of 2,500 comments in this important domain 1 .","Social Media Attributions in the Context of Water Crisis Attribution of natural disasters/collective misfortune is a widely-studied political science problem. However, such studies typically rely on surveys, expert opinions, or external signals such as voting outcomes. In this paper, we explore the viability of using unstructured, noisy social media data to complement traditional surveys through automatically extracting attribution factors. We present a novel prediction task of attribution tie detection of identifying the factors (e.g., poor city planning, exploding population etc.) held responsible for the crisis in a social media document. We focus on the 2019 Chennai water crisis that rapidly escalated into a discussion topic with global importance following alarming water-crisis statistics. On a challenging data set constructed from YouTube comments (72,098 comments posted by 43,859 users on 623 videos relevant to the crisis), we present a neural baseline to identify attribution ties that achieves a reasonable performance (accuracy: 87.34% on attribution detection and 81.37% on attribution resolution). We release the first annotated data set of 2,500 comments in this important domain 1 .","social media attribution context water crisis attribution natural disaster / collective misfortune widely - study political science problem . , study typically rely survey , expert opinion , external signal voting outcome . paper , explore viability unstructured , noisy social medium datum complement traditional survey automatically extract attribution factor . present novel prediction task attribution tie detection identify factor ( e.g. , poor city planning , explode population etc . ) hold responsible crisis social media document . focus 2019 chennai water crisis rapidly escalate discussion topic global importance follow alarming water - crisis statistic . challenging data set construct youtube comment ( 72,098 comment post 43,859 user 623 video relevant crisis ) , present neural baseline identify attribution tie achieve reasonable performance ( accuracy : 87.34 % attribution detection 81.37 % attribution resolution ) . release annotated data set 2,500 comment important domain 1 .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 3, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,HENIN: Learning Heterogeneous Neural Interaction Networks for Explainable Cyberbullying Detection on Social Media,"In the computational detection of cyberbullying, existing work largely focused on building generic classifiers that rely exclusively on text analysis of social media sessions. Despite their empirical success, we argue that a critical missing piece is the model explainability, i.e., why a particular piece of media session is detected as cyberbullying. In this paper, therefore, we propose a novel deep model, HEterogeneous Neural Interaction Networks (HENIN), for explainable cyberbullying detection. HENIN contains the following components: a comment encoder, a post-comment co-attention sub-network, and session-session and post-post interaction extractors. Extensive experiments conducted on real datasets exhibit not only the promising performance of HENIN, but also highlight evidential comments so that one can understand why a media session is identified as cyberbullying.","HENIN: Learning Heterogeneous Neural Interaction Networks for Explainable Cyberbullying Detection on Social Media In the computational detection of cyberbullying, existing work largely focused on building generic classifiers that rely exclusively on text analysis of social media sessions. Despite their empirical success, we argue that a critical missing piece is the model explainability, i.e., why a particular piece of media session is detected as cyberbullying. In this paper, therefore, we propose a novel deep model, HEterogeneous Neural Interaction Networks (HENIN), for explainable cyberbullying detection. HENIN contains the following components: a comment encoder, a post-comment co-attention sub-network, and session-session and post-post interaction extractors. Extensive experiments conducted on real datasets exhibit not only the promising performance of HENIN, but also highlight evidential comments so that one can understand why a media session is identified as cyberbullying.","henin : learn heterogeneous neural interaction network explainable cyberbullying detection social medium computational detection cyberbullying , exist work largely focus build generic classifier rely exclusively text analysis social medium session . despite empirical success , argue critical missing piece model explainability , i.e. , particular piece medium session detect cyberbullying . paper , , propose novel deep model , heterogeneous neural interaction networks ( henin ) , explainable cyberbullying detection . henin contain following component : comment encoder , post - comment co - attention sub - network , session - session post - post interaction extractor . extensive experiment conduct real dataset exhibit promising performance henin , highlight evidential comment understand medium session identify cyberbullying .","{'Computational Social Science and Social Media': 11, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support,"Empathy is critical to successful mental health support. Empathy measurement has predominantly occurred in synchronous, face-toface settings, and may not translate to asynchronous, text-based contexts. Because millions of people use text-based platforms for mental health support, understanding empathy in these contexts is crucial. In this work, we present a computational approach to understanding how empathy is expressed in online mental health platforms. We develop a novel unifying theoretically-grounded framework for characterizing the communication of empathy in text-based conversations. We collect and share a corpus of 10k (post, response) pairs annotated using this empathy framework with supporting evidence for annotations (rationales). We develop a multi-task RoBERTa-based bi-encoder model for identifying empathy in conversations and extracting rationales underlying its predictions. Experiments demonstrate that our approach can effectively identify empathic conversations. We further apply this model to analyze 235k mental health interactions and show that users do not self-learn empathy over time, revealing opportunities for empathy training and feedback.","A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support Empathy is critical to successful mental health support. Empathy measurement has predominantly occurred in synchronous, face-toface settings, and may not translate to asynchronous, text-based contexts. Because millions of people use text-based platforms for mental health support, understanding empathy in these contexts is crucial. In this work, we present a computational approach to understanding how empathy is expressed in online mental health platforms. We develop a novel unifying theoretically-grounded framework for characterizing the communication of empathy in text-based conversations. We collect and share a corpus of 10k (post, response) pairs annotated using this empathy framework with supporting evidence for annotations (rationales). We develop a multi-task RoBERTa-based bi-encoder model for identifying empathy in conversations and extracting rationales underlying its predictions. Experiments demonstrate that our approach can effectively identify empathic conversations. We further apply this model to analyze 235k mental health interactions and show that users do not self-learn empathy over time, revealing opportunities for empathy training and feedback.","computational approach understand empathy express text - base mental health support empathy critical successful mental health support . empathy measurement predominantly occur synchronous , face - toface setting , translate asynchronous , text - base context . million people use text - base platform mental health support , understand empathy context crucial . work , present computational approach understand empathy express online mental health platform . develop novel unify theoretically - ground framework characterize communication empathy text - base conversation . collect share corpus 10k ( post , response ) pair annotate empathy framework support evidence annotation ( rationale ) . develop multi - task roberta - base bi - encoder model identify empathy conversation extract rationale underlie prediction . experiment demonstrate approach effectively identify empathic conversation . apply model analyze 235k mental health interaction user self - learn empathy time , reveal opportunity empathy training feedback .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 4, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Generation,False
Computational Social Science and Social Media,Comparative Evaluation of Label-Agnostic Selection Bias in Multilingual Hate Speech Datasets,"Work on bias in hate speech typically aims to improve classification performance while relatively overlooking the quality of the data. We examine selection bias in hate speech in a language and label independent fashion. We first use topic models to discover latent semantics in eleven hate speech corpora, then, we present two bias evaluation metrics based on the semantic similarity between topics and search words frequently used to build corpora. We discuss the possibility of revising the data collection process by comparing datasets and analyzing contrastive case studies.","Comparative Evaluation of Label-Agnostic Selection Bias in Multilingual Hate Speech Datasets Work on bias in hate speech typically aims to improve classification performance while relatively overlooking the quality of the data. We examine selection bias in hate speech in a language and label independent fashion. We first use topic models to discover latent semantics in eleven hate speech corpora, then, we present two bias evaluation metrics based on the semantic similarity between topics and search words frequently used to build corpora. We discuss the possibility of revising the data collection process by comparing datasets and analyzing contrastive case studies.","comparative evaluation label - agnostic selection bias multilingual hate speech dataset work bias hate speech typically aim improve classification performance relatively overlook quality datum . examine selection bias hate speech language label independent fashion . use topic model discover latent semantic hate speech corpus , , present bias evaluation metric base semantic similarity topic search word frequently build corpus . discuss possibility revise data collection process compare dataset analyze contrastive case study .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Computational Social Science and Social Media,Fortifying Toxic Speech Detectors Against Veiled Toxicity,"Modern toxic speech detectors are incompetent in recognizing disguised offensive language, such as adversarial attacks that deliberately avoid known toxic lexicons, or manifestations of implicit bias. Building a large annotated dataset for such veiled toxicity can be very expensive. In this work, we propose a framework aimed at fortifying existing toxic speech detectors without a large labeled corpus of veiled toxicity. Just a handful of probing examples are used to surface orders of magnitude more disguised offenses. We augment the toxic speech detector's training data with these discovered offensive examples, thereby making it more robust to veiled toxicity while preserving its utility in detecting overt toxicity. 1 Warning: this paper contains examples that may be offensive or upsetting.","Fortifying Toxic Speech Detectors Against Veiled Toxicity Modern toxic speech detectors are incompetent in recognizing disguised offensive language, such as adversarial attacks that deliberately avoid known toxic lexicons, or manifestations of implicit bias. Building a large annotated dataset for such veiled toxicity can be very expensive. In this work, we propose a framework aimed at fortifying existing toxic speech detectors without a large labeled corpus of veiled toxicity. Just a handful of probing examples are used to surface orders of magnitude more disguised offenses. We augment the toxic speech detector's training data with these discovered offensive examples, thereby making it more robust to veiled toxicity while preserving its utility in detecting overt toxicity. 1 Warning: this paper contains examples that may be offensive or upsetting.","fortify toxic speech detector veil toxicity modern toxic speech detector incompetent recognize disguise offensive language , adversarial attack deliberately avoid know toxic lexicon , manifestation implicit bias . build large annotate dataset veil toxicity expensive . work , propose framework aim fortify exist toxic speech detector large label corpus veil toxicity . handful probe example surface order magnitude disguised offense . augment toxic speech detector training datum discover offensive example , make robust veiled toxicity preserve utility detect overt toxicity . 1 warning : paper contain example offensive upsetting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",False
Computational Social Science and Social Media,Solving Historical Dictionary Codes with a Neural Language Model,"We solve difficult word-based substitution codes by constructing a decoding lattice and searching that lattice with a neural language model. We apply our method to a set of enciphered letters exchanged between US Army General James Wilkinson and agents of the Spanish Crown in the late 1700s and early 1800s, obtained from the US Library of Congress. We are able to decipher 75.1% of the cipher-word tokens correctly.","Solving Historical Dictionary Codes with a Neural Language Model We solve difficult word-based substitution codes by constructing a decoding lattice and searching that lattice with a neural language model. We apply our method to a set of enciphered letters exchanged between US Army General James Wilkinson and agents of the Spanish Crown in the late 1700s and early 1800s, obtained from the US Library of Congress. We are able to decipher 75.1% of the cipher-word tokens correctly.","solve historical dictionary code neural language model solve difficult word - base substitution code construct decode lattice search lattice neural language model . apply method set encipher letter exchange army general james wilkinson agent spanish crown late 1700 early 1800 , obtain library congress . able decipher 75.1 % cipher - word token correctly .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Computational Social Science and Social Media,Multilingual Offensive Language Identification with Cross-lingual Embeddings,"Offensive content is pervasive in social media and a reason for concern to companies and government organizations. Several studies have been recently published investigating methods to detect the various forms of such content (e.g. hate speech, cyberbulling, and cyberaggression). The clear majority of these studies deal with English partially because most annotated datasets available contain English data. In this paper, we take advantage of English data available by applying cross-lingual contextual word embeddings and transfer learning to make predictions in languages with less resources. We project predictions on comparable data in Bengali, Hindi, and Spanish and we report results of 0.8415 F1 macro for Bengali, 0.8568 F1 macro for Hindi, and 0.7513 F1 macro for Spanish. Finally, we show that our approach compares favorably to the best systems submitted to recent shared tasks on these three languages, confirming the robustness of cross-lingual contextual embeddings and transfer learning for this task.","Multilingual Offensive Language Identification with Cross-lingual Embeddings Offensive content is pervasive in social media and a reason for concern to companies and government organizations. Several studies have been recently published investigating methods to detect the various forms of such content (e.g. hate speech, cyberbulling, and cyberaggression). The clear majority of these studies deal with English partially because most annotated datasets available contain English data. In this paper, we take advantage of English data available by applying cross-lingual contextual word embeddings and transfer learning to make predictions in languages with less resources. We project predictions on comparable data in Bengali, Hindi, and Spanish and we report results of 0.8415 F1 macro for Bengali, 0.8568 F1 macro for Hindi, and 0.7513 F1 macro for Spanish. Finally, we show that our approach compares favorably to the best systems submitted to recent shared tasks on these three languages, confirming the robustness of cross-lingual contextual embeddings and transfer learning for this task.","multilingual offensive language identification cross - lingual embeddings offensive content pervasive social medium reason concern company government organization . study recently publish investigate method detect form content ( e.g. hate speech , cyberbulling , cyberaggression ) . clear majority study deal english partially annotate dataset available contain english datum . paper , advantage english datum available apply cross - lingual contextual word embedding transfer learning prediction language resource . project prediction comparable datum bengali , hindi , spanish report result 0.8415 f1 macro bengali , 0.8568 f1 macro hindi , 0.7513 f1 macro spanish . finally , approach compare favorably good system submit recent share task language , confirm robustness cross - lingual contextual embedding transfer learning task .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Computational Social Science and Social Media,Social Chemistry 101: Learning to Reason about Social and Moral Norms,"Social norms-the unspoken commonsense rules about acceptable social behavior-are crucial in understanding the underlying causes and intents of people's actions in narratives. For example, underlying an action such as ""wanting to call cops on my neighbor"" are social norms that inform our conduct, such as ""It is expected that you report crimes."" We present SOCIAL CHEMISTRY, a new conceptual formalism to study people's everyday social norms and moral judgments over a rich spectrum of real life situations described in natural language. We introduce SOCIAL-CHEM-101, a large-scale corpus that catalogs 292k rules-of-thumb such as ""It is rude to run a blender at 5am"" as the basic conceptual units. Each rule-of-thumb is further broken down with 12 different dimensions of people's judgments, including social judgments of good and bad, moral foundations, expected cultural pressure, and assumed legality, which together amount to over 4.5 million annotations of categorical labels and free-text descriptions. Comprehensive empirical results based on state-of-the-art neural models demonstrate that computational modeling of social norms is a promising research direction. Our model framework, NEURAL NORM TRANSFORMER, learns and generalizes SOCIAL-CHEM-101 to successfully reason about previously unseen situations, generating relevant (and potentially novel) attribute-aware social rules-of-thumb. Punching a friend who stole from me. RoT 1: It is unacceptable to injure a person. RoT 2: People should not steal from others. RoT 3: It is bad to betray a friend. RoT 4: It is OK to want to take revenge.","Social Chemistry 101: Learning to Reason about Social and Moral Norms Social norms-the unspoken commonsense rules about acceptable social behavior-are crucial in understanding the underlying causes and intents of people's actions in narratives. For example, underlying an action such as ""wanting to call cops on my neighbor"" are social norms that inform our conduct, such as ""It is expected that you report crimes."" We present SOCIAL CHEMISTRY, a new conceptual formalism to study people's everyday social norms and moral judgments over a rich spectrum of real life situations described in natural language. We introduce SOCIAL-CHEM-101, a large-scale corpus that catalogs 292k rules-of-thumb such as ""It is rude to run a blender at 5am"" as the basic conceptual units. Each rule-of-thumb is further broken down with 12 different dimensions of people's judgments, including social judgments of good and bad, moral foundations, expected cultural pressure, and assumed legality, which together amount to over 4.5 million annotations of categorical labels and free-text descriptions. Comprehensive empirical results based on state-of-the-art neural models demonstrate that computational modeling of social norms is a promising research direction. Our model framework, NEURAL NORM TRANSFORMER, learns and generalizes SOCIAL-CHEM-101 to successfully reason about previously unseen situations, generating relevant (and potentially novel) attribute-aware social rules-of-thumb. Punching a friend who stole from me. RoT 1: It is unacceptable to injure a person. RoT 2: People should not steal from others. RoT 3: It is bad to betray a friend. RoT 4: It is OK to want to take revenge.","social chemistry 101 : learn reason social moral norm social norm - unspoken commonsense rule acceptable social behavior - crucial understand underlie cause intent people action narrative . example , underlie action "" want cop neighbor "" social norm inform conduct , "" expect report crime . "" present social chemistry , new conceptual formalism study people everyday social norm moral judgment rich spectrum real life situation describe natural language . introduce social - chem-101 , large - scale corpus catalog 292k rule - - thumb "" rude run blender 5 "" basic conceptual unit . rule - - thumb break 12 different dimension people judgment , include social judgment good bad , moral foundation , expect cultural pressure , assumed legality , 4.5 million annotation categorical label free - text description . comprehensive empirical result base state - - - art neural model demonstrate computational modeling social norm promising research direction . model framework , neural norm transformer , learn generalize social - chem-101 successfully reason previously unseen situation , generate relevant ( potentially novel ) attribute - aware social rule - - thumb . punch friend steal . rot 1 : unacceptable injure person . rot 2 : people steal . rot 3 : bad betray friend . rot 4 : ok want revenge .","{'Computational Social Science and Social Media': 12, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 12, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Cross-Media Keyphrase Prediction: A Unified Framework with Multi-Modality Multi-Head Attention and Image Wordings,"Social media produces large amounts of contents every day. To help users quickly capture what they need, keyphrase prediction is receiving a growing attention. Nevertheless, most prior efforts focus on text modeling, largely ignoring the rich features embedded in the matching images. In this work, we explore the joint effects of texts and images in predicting the keyphrases for a multimedia post. To better align social media style texts and images, we propose: (1) a novel Multi-Modality Multi-Head Attention (M 3 H-Att) to capture the intricate cross-media interactions; (2) image wordings, in forms of optical characters and image attributes, to bridge the two modalities. Moreover, we design a novel unified framework to leverage the outputs of keyphrase classification and generation and couple their advantages. Extensive experiments on a large-scale dataset 1 newly collected from Twitter show that our model significantly outperforms the previous state of the art based on traditional co-attentions. Further analyses show that our multi-head attention is able to attend information from various aspects and boost classification or generation in diverse scenarios.","Cross-Media Keyphrase Prediction: A Unified Framework with Multi-Modality Multi-Head Attention and Image Wordings Social media produces large amounts of contents every day. To help users quickly capture what they need, keyphrase prediction is receiving a growing attention. Nevertheless, most prior efforts focus on text modeling, largely ignoring the rich features embedded in the matching images. In this work, we explore the joint effects of texts and images in predicting the keyphrases for a multimedia post. To better align social media style texts and images, we propose: (1) a novel Multi-Modality Multi-Head Attention (M 3 H-Att) to capture the intricate cross-media interactions; (2) image wordings, in forms of optical characters and image attributes, to bridge the two modalities. Moreover, we design a novel unified framework to leverage the outputs of keyphrase classification and generation and couple their advantages. Extensive experiments on a large-scale dataset 1 newly collected from Twitter show that our model significantly outperforms the previous state of the art based on traditional co-attentions. Further analyses show that our multi-head attention is able to attend information from various aspects and boost classification or generation in diverse scenarios.","cross - media keyphrase prediction : unified framework multi - modality multi - head attention image wording social medium produce large amount content day . help user quickly capture need , keyphrase prediction receive grow attention . , prior effort focus text modeling , largely ignore rich feature embed match image . work , explore joint effect text image predict keyphrase multimedia post . well align social medium style text image , propose : ( 1 ) novel multi - modality multi - head attention ( m 3 h - att ) capture intricate cross - media interaction ; ( 2 ) image wording , form optical character image attribute , bridge modality . , design novel unified framework leverage output keyphrase classification generation couple advantage . extensive experiment large - scale dataset 1 newly collect twitter model significantly outperform previous state art base traditional co - attention . analysis multi - head attention able attend information aspect boost classification generation diverse scenario .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 2, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 7, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Unsupervised Discovery of Implicit Gender Bias,"Despite their prevalence in society, social biases are difficult to identify, primarily because human judgements in this domain can be unreliable. We take an unsupervised approach to identifying gender bias against women at a comment level and present a model that can surface text likely to contain bias. Our main challenge is forcing the model to focus on signs of implicit bias, rather than other artifacts in the data. Thus, our methodology involves reducing the influence of confounds through propensity matching and adversarial learning. Our analysis shows how biased comments directed towards female politicians contain mixed criticisms, while comments directed towards other female public figures focus on appearance and sexualization. Ultimately, our work offers a way to capture subtle biases in various domains without relying on subjective human judgements. 1 I love tennis! Tennis is great! Do I look ok? Bro <title>, golf is better UR hot! Me too <3 UR hot! Canada's got no game OW","Unsupervised Discovery of Implicit Gender Bias Despite their prevalence in society, social biases are difficult to identify, primarily because human judgements in this domain can be unreliable. We take an unsupervised approach to identifying gender bias against women at a comment level and present a model that can surface text likely to contain bias. Our main challenge is forcing the model to focus on signs of implicit bias, rather than other artifacts in the data. Thus, our methodology involves reducing the influence of confounds through propensity matching and adversarial learning. Our analysis shows how biased comments directed towards female politicians contain mixed criticisms, while comments directed towards other female public figures focus on appearance and sexualization. Ultimately, our work offers a way to capture subtle biases in various domains without relying on subjective human judgements. 1 I love tennis! Tennis is great! Do I look ok? Bro <title>, golf is better UR hot! Me too <3 UR hot! Canada's got no game OW","unsupervised discovery implicit gender bias despite prevalence society , social bias difficult identify , primarily human judgement domain unreliable . unsupervised approach identify gender bias woman comment level present model surface text likely contain bias . main challenge force model focus sign implicit bias , artifact datum . , methodology involve reduce influence confound propensity matching adversarial learning . analysis show biased comment direct female politician contain mix criticism , comment direct female public figure focus appearance sexualization . ultimately , work offer way capture subtle bias domain rely subjective human judgement . 1 love tennis ! tennis great ! look ok ? bro < title > , golf well ur hot ! <3 ur hot ! canada get game ow","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 14, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Computational Social Science and Social Media,"Hashtags, Emotions, and Comments: A Large-Scale Dataset to Understand Fine-Grained Social Emotions to Online Topics","This paper studies social emotions to online discussion topics. While most prior work focus on emotions from writers, we investigate readers' responses and explore the public feelings to an online topic. A large-scale dataset is collected from Chinese microblog Sina Weibo with over 13 thousand trending topics, emotion votes in 24 fine-grained types from massive participants, and user comments to allow context understanding. 1 In experiments, we examine baseline performance to predict a topic's possible social emotions in a multilabel classification setting. The results show that a seq2seq model with user comment modeling performs the best, even surpassing human prediction. More analyses shed light on the effects of emotion types, topic description lengths, contexts from user comments, and the limited capacity of the existing models.","Hashtags, Emotions, and Comments: A Large-Scale Dataset to Understand Fine-Grained Social Emotions to Online Topics This paper studies social emotions to online discussion topics. While most prior work focus on emotions from writers, we investigate readers' responses and explore the public feelings to an online topic. A large-scale dataset is collected from Chinese microblog Sina Weibo with over 13 thousand trending topics, emotion votes in 24 fine-grained types from massive participants, and user comments to allow context understanding. 1 In experiments, we examine baseline performance to predict a topic's possible social emotions in a multilabel classification setting. The results show that a seq2seq model with user comment modeling performs the best, even surpassing human prediction. More analyses shed light on the effects of emotion types, topic description lengths, contexts from user comments, and the limited capacity of the existing models.","hashtag , emotion , comment : large - scale dataset understand fine - grained social emotion online topic paper study social emotion online discussion topic . prior work focus emotion writer , investigate reader ' response explore public feeling online topic . large - scale dataset collect chinese microblog sina weibo 13 thousand trend topic , emotion vote 24 fine - grained type massive participant , user comment allow context understanding . 1 experiment , examine baseline performance predict topic possible social emotion multilabel classification setting . result seq2seq model user comment modeling perform good , surpass human prediction . analysis shed light effect emotion type , topic description length , context user comment , limited capacity exist model .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 7, 'Speech and Multimodality': 8, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Dialogue and Interactive Systems,UniConv: A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues,"Building an end-to-end conversational agent for multi-domain task-oriented dialogues has been an open challenge for two main reasons. First, tracking dialogue states of multiple domains is non-trivial as the dialogue agent must obtain complete states from all relevant domains, some of which might have shared slots among domains as well as unique slots specifically for one domain only. Second, the dialogue agent must also process various types of information across domains, including dialogue context, dialogue states, and database, to generate natural responses to users. Unlike the existing approaches that are often designed to train each module separately, we propose ""UniConv"" -a novel unified neural architecture for end-to-end conversational systems in multi-domain task-oriented dialogues, which is designed to jointly train (i) a Bi-level State Tracker which tracks dialogue states by learning signals at both slot and domain level independently, and (ii) a Joint Dialogue Act and Response Generator which incorporates information from various input components and models dialogue acts and target responses simultaneously. We conduct comprehensive experiments in dialogue state tracking, contextto-text, and end-to-end settings on the Multi-WOZ2.1 benchmark, achieving superior performance over competitive baselines. Human: hello Dialogue agent: hi ! how can i help you ? Dialogue state: {} Dialogue acts: [greeting] Human: i would like a place to eat in the expensive price range Dialogue agent: sure , what type of food are you interested in ? Dialogue state: {restaurant: {pricerange: expensive}} Dialogue acts: [request-food] Human: could you make a suggestion ? one in the centre ? Dialogue agent: fitzbillies restaurant is an expensive british restaurant in the centre . can i book that for you ? Dialogue state: {restaurant: {pricerange: expensive, area: centre}} Dialogue acts: [inform-restaurant, request-booking] ... ...","UniConv: A Unified Conversational Neural Architecture for Multi-domain Task-oriented Dialogues Building an end-to-end conversational agent for multi-domain task-oriented dialogues has been an open challenge for two main reasons. First, tracking dialogue states of multiple domains is non-trivial as the dialogue agent must obtain complete states from all relevant domains, some of which might have shared slots among domains as well as unique slots specifically for one domain only. Second, the dialogue agent must also process various types of information across domains, including dialogue context, dialogue states, and database, to generate natural responses to users. Unlike the existing approaches that are often designed to train each module separately, we propose ""UniConv"" -a novel unified neural architecture for end-to-end conversational systems in multi-domain task-oriented dialogues, which is designed to jointly train (i) a Bi-level State Tracker which tracks dialogue states by learning signals at both slot and domain level independently, and (ii) a Joint Dialogue Act and Response Generator which incorporates information from various input components and models dialogue acts and target responses simultaneously. We conduct comprehensive experiments in dialogue state tracking, contextto-text, and end-to-end settings on the Multi-WOZ2.1 benchmark, achieving superior performance over competitive baselines. Human: hello Dialogue agent: hi ! how can i help you ? Dialogue state: {} Dialogue acts: [greeting] Human: i would like a place to eat in the expensive price range Dialogue agent: sure , what type of food are you interested in ? Dialogue state: {restaurant: {pricerange: expensive}} Dialogue acts: [request-food] Human: could you make a suggestion ? one in the centre ? Dialogue agent: fitzbillies restaurant is an expensive british restaurant in the centre . can i book that for you ? Dialogue state: {restaurant: {pricerange: expensive, area: centre}} Dialogue acts: [inform-restaurant, request-booking] ... ...","uniconv : unified conversational neural architecture multi - domain task - orient dialogue build end - - end conversational agent multi - domain task - orient dialogue open challenge main reason . , track dialogue state multiple domain non - trivial dialogue agent obtain complete state relevant domain , share slot domain unique slot specifically domain . second , dialogue agent process type information domain , include dialogue context , dialogue state , database , generate natural response user . unlike exist approach design train module separately , propose "" uniconv "" -a novel unified neural architecture end - - end conversational system multi - domain task - orient dialogue , design jointly train ( ) bi - level state tracker track dialogue state learn signal slot domain level independently , ( ii ) joint dialogue act response generator incorporate information input component model dialogue act target response simultaneously . conduct comprehensive experiment dialogue state tracking , contextto - text , end - - end setting multi - woz2.1 benchmark , achieve superior performance competitive baseline . human : hello dialogue agent : hi ! help ? dialogue state : { } dialogue act : [ greeting ] human : like place eat expensive price range dialogue agent : sure , type food interested ? dialogue state : { restaurant : { pricerange : expensive } } dialogue act : [ request - food ] human : suggestion ? centre ? dialogue agent : fitzbillies restaurant expensive british restaurant centre . book ? dialogue state : { restaurant : { pricerange : expensive , area : centre } } dialogue act : [ inform - restaurant , request - booking ] ... ...","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 61, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Will I Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness,"We explore the task of improving persona consistency of dialogue agents. Recent models tackling consistency often train with additional Natural Language Inference (NLI) labels or attach trained extra modules to the generative agent for maintaining consistency. However, such additional labels and training can be demanding. Also, we find even the bestperforming persona-based agents are insensitive to contradictory words. Inspired by social cognition and pragmatics, we endow existing dialogue agents with public self-consciousness on the fly through an imaginary listener. Our approach, based on the Rational Speech Acts framework (Frank and Goodman, 2012), can enforce dialogue agents to refrain from uttering contradiction. We further extend the framework by learning the distractor selection, which has been usually done manually or randomly. Results on Dialogue NLI (Welleck  et al., 2019)  and PersonaChat (Zhang et al.,  2018)  dataset show that our approach reduces contradiction and improves consistency of existing dialogue models. Moreover, we show that it can be generalized to improve contextconsistency beyond persona in dialogues.","Will I Sound Like Me? Improving Persona Consistency in Dialogues through Pragmatic Self-Consciousness We explore the task of improving persona consistency of dialogue agents. Recent models tackling consistency often train with additional Natural Language Inference (NLI) labels or attach trained extra modules to the generative agent for maintaining consistency. However, such additional labels and training can be demanding. Also, we find even the bestperforming persona-based agents are insensitive to contradictory words. Inspired by social cognition and pragmatics, we endow existing dialogue agents with public self-consciousness on the fly through an imaginary listener. Our approach, based on the Rational Speech Acts framework (Frank and Goodman, 2012), can enforce dialogue agents to refrain from uttering contradiction. We further extend the framework by learning the distractor selection, which has been usually done manually or randomly. Results on Dialogue NLI (Welleck  et al., 2019)  and PersonaChat (Zhang et al.,  2018)  dataset show that our approach reduces contradiction and improves consistency of existing dialogue models. Moreover, we show that it can be generalized to improve contextconsistency beyond persona in dialogues.","sound like ? improve persona consistency dialogue pragmatic self - consciousness explore task improve persona consistency dialogue agent . recent model tackle consistency train additional natural language inference ( nli ) label attach train extra module generative agent maintain consistency . , additional label training demanding . , find bestperforme persona - base agent insensitive contradictory word . inspire social cognition pragmatic , endow exist dialogue agent public self - consciousness fly imaginary listener . approach , base rational speech acts framework ( frank goodman , 2012 ) , enforce dialogue agent refrain utter contradiction . extend framework learn distractor selection , usually manually randomly . result dialogue nli ( welleck   et al . , 2019 )   personachat ( zhang et al . ,   2018 )   dataset approach reduce contradiction improve consistency exist dialogue model . , generalize improve contextconsistency persona dialogue .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 14, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing,"Task-oriented semantic parsing is a critical component of virtual assistants, which is responsible for understanding the user's intents (set reminder, play music, etc.). Recent advances in deep learning have enabled several approaches to successfully parse more complex queries (Gupta et al., 2018; Rongali et al., 2020) , but these models require a large amount of annotated training data to parse queries on new domains (e.g. reminder, music). In this paper, we focus on adapting taskoriented semantic parsers to low-resource domains, and propose a novel method that outperforms a supervised neural model at a 10-fold data reduction. In particular, we identify two fundamental factors for low-resource domain adaptation: better representation learning and better training techniques. Our representation learning uses BART (Lewis et al., 2020)   to initialize our model which outperforms encoder-only pre-trained representations used in previous work. Furthermore, we train with optimization-based meta-learning (Finn et al., 2017) to improve generalization to lowresource domains. This approach significantly outperforms all baseline methods in the experiments on a newly collected multi-domain taskoriented semantic parsing dataset (TOPv2 1 ).","Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing Task-oriented semantic parsing is a critical component of virtual assistants, which is responsible for understanding the user's intents (set reminder, play music, etc.). Recent advances in deep learning have enabled several approaches to successfully parse more complex queries (Gupta et al., 2018; Rongali et al., 2020) , but these models require a large amount of annotated training data to parse queries on new domains (e.g. reminder, music). In this paper, we focus on adapting taskoriented semantic parsers to low-resource domains, and propose a novel method that outperforms a supervised neural model at a 10-fold data reduction. In particular, we identify two fundamental factors for low-resource domain adaptation: better representation learning and better training techniques. Our representation learning uses BART (Lewis et al., 2020)   to initialize our model which outperforms encoder-only pre-trained representations used in previous work. Furthermore, we train with optimization-based meta-learning (Finn et al., 2017) to improve generalization to lowresource domains. This approach significantly outperforms all baseline methods in the experiments on a newly collected multi-domain taskoriented semantic parsing dataset (TOPv2 1 ).","low - resource domain adaptation compositional task - orient semantic parsing task - orient semantic parsing critical component virtual assistant , responsible understand user intent ( set reminder , play music , etc . ) . recent advance deep learning enable approach successfully parse complex query ( gupta et al . , 2018 ; rongali et al . , 2020 ) , model require large annotate training datum parse query new domain ( e.g. reminder , music ) . paper , focus adapt taskoriente semantic parser low - resource domain , propose novel method outperform supervise neural model 10 - fold data reduction . particular , identify fundamental factor low - resource domain adaptation : well representation learning well training technique . representation learning use bart ( lewis et al . , 2020 )    initialize model outperform encoder - pre - train representation previous work . furthermore , train optimization - base meta - learning ( finn et al . , 2017 ) improve generalization lowresource domain . approach significantly outperform baseline method experiment newly collect multi - domain taskoriented semantic parsing dataset ( topv2 1 ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 4, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Dialogue and Interactive Systems,AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue,"Retrieving the proper knowledge relevant to conversational context is an important challenge in dialogue systems, to engage users with more informative response. Several recent works propose to formulate this knowledge selection problem as a path traversal over an external knowledge graph (KG), but show only a limited utilization of KG structure, leaving rooms of improvement in performance. To this effect, we present AttnIO, a new dialog-conditioned path traversal model that makes a full use of rich structural information in KG based on two directions of attention flows. Through the attention flows, At-tnIO is not only capable of exploring a broad range of multi-hop knowledge paths, but also learns to flexibly adjust the varying range of plausible nodes and edges to attend depending on the dialog context. Empirical evaluations present a marked performance improvement of AttnIO compared to all baselines in OpenDi-alKG dataset. Also, we find that our model can be trained to generate an adequate knowledge path even when the paths are not available and only the destination nodes are given as label, making it more applicable to real-world dialogue systems.","AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue Retrieving the proper knowledge relevant to conversational context is an important challenge in dialogue systems, to engage users with more informative response. Several recent works propose to formulate this knowledge selection problem as a path traversal over an external knowledge graph (KG), but show only a limited utilization of KG structure, leaving rooms of improvement in performance. To this effect, we present AttnIO, a new dialog-conditioned path traversal model that makes a full use of rich structural information in KG based on two directions of attention flows. Through the attention flows, At-tnIO is not only capable of exploring a broad range of multi-hop knowledge paths, but also learns to flexibly adjust the varying range of plausible nodes and edges to attend depending on the dialog context. Empirical evaluations present a marked performance improvement of AttnIO compared to all baselines in OpenDi-alKG dataset. Also, we find that our model can be trained to generate an adequate knowledge path even when the paths are not available and only the destination nodes are given as label, making it more applicable to real-world dialogue systems.","attnio : knowledge graph exploration - - attention flow knowledge - ground dialogue retrieve proper knowledge relevant conversational context important challenge dialogue system , engage user informative response . recent work propose formulate knowledge selection problem path traversal external knowledge graph ( kg ) , limited utilization kg structure , leave room improvement performance . effect , present attnio , new dialog - condition path traversal model make use rich structural information kg base direction attention flow . attention flow , - tnio capable explore broad range multi - hop knowledge path , learn flexibly adjust vary range plausible node edge attend depend dialog context . empirical evaluation present marked performance improvement attnio compare baseline opendi - alkg dataset . , find model train generate adequate knowledge path path available destination node give label , make applicable real - world dialogue system .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 12, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness,"Diverse data is crucial for training robust models, but crowdsourced text often lacks diversity as workers tend to write simple variations from prompts. We propose a general approach for guiding workers to write more diverse text by iteratively constraining their writing. We show how prior workflows are special cases of our approach, and present a way to apply the approach to dialog tasks such as intent classification and slot-filling. Using our method, we create more challenging versions of test sets from prior dialog datasets and find dramatic performance drops for standard models. Finally, we show that our approach is complementary to recent work on improving data diversity, and training on data collected with our approach leads to more robust models.","Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness Diverse data is crucial for training robust models, but crowdsourced text often lacks diversity as workers tend to write simple variations from prompts. We propose a general approach for guiding workers to write more diverse text by iteratively constraining their writing. We show how prior workflows are special cases of our approach, and present a way to apply the approach to dialog tasks such as intent classification and slot-filling. Using our method, we create more challenging versions of test sets from prior dialog datasets and find dramatic performance drops for standard models. Finally, we show that our approach is complementary to recent work on improving data diversity, and training on data collected with our approach leads to more robust models.","iterative feature mining constraint - base datum collection increase datum diversity model robustness diverse data crucial train robust model , crowdsource text lack diversity worker tend write simple variation prompt . propose general approach guide worker write diverse text iteratively constrain writing . prior workflow special case approach , present way apply approach dialog task intent classification slot - filling . method , create challenging version test set prior dialog dataset find dramatic performance drop standard model . finally , approach complementary recent work improve datum diversity , training datum collect approach lead robust model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness,"Large-scale dialogue datasets have recently become available for training neural dialogue agents. However, these datasets have been reported to contain a non-negligible number of unacceptable utterance pairs. In this paper, we propose a method for scoring the quality of utterance pairs in terms of their connectivity and relatedness. The proposed scoring method is designed based on findings widely shared in the dialogue and linguistics research communities. We demonstrate that it has a relatively good correlation with the human judgment of dialogue quality. Furthermore, the method is applied to filter out potentially unacceptable utterance pairs from a large-scale noisy dialogue corpus to ensure its quality. We experimentally confirm that training data filtered by the proposed method improves the quality of neural dialogue agents in response generation. 1","Filtering Noisy Dialogue Corpora by Connectivity and Content Relatedness Large-scale dialogue datasets have recently become available for training neural dialogue agents. However, these datasets have been reported to contain a non-negligible number of unacceptable utterance pairs. In this paper, we propose a method for scoring the quality of utterance pairs in terms of their connectivity and relatedness. The proposed scoring method is designed based on findings widely shared in the dialogue and linguistics research communities. We demonstrate that it has a relatively good correlation with the human judgment of dialogue quality. Furthermore, the method is applied to filter out potentially unacceptable utterance pairs from a large-scale noisy dialogue corpus to ensure its quality. We experimentally confirm that training data filtered by the proposed method improves the quality of neural dialogue agents in response generation. 1","filter noisy dialogue corpus connectivity content relatedness large - scale dialogue dataset recently available train neural dialogue agent . , dataset report contain non - negligible number unacceptable utterance pair . paper , propose method score quality utterance pair term connectivity relatedness . propose scoring method design base finding widely share dialogue linguistics research community . demonstrate relatively good correlation human judgment dialogue quality . furthermore , method apply filter potentially unacceptable utterance pair large - scale noisy dialogue corpus ensure quality . experimentally confirm training datum filter propose method improve quality neural dialogue agent response generation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 15, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,End-to-End Slot Alignment and Recognition for Cross-Lingual NLU,"Natural language understanding (NLU) in the context of goal-oriented dialog systems typically includes intent classification and slot labeling tasks. Existing methods to expand an NLU system to new languages use machine translation with slot label projection from source to the translated utterances, and thus are sensitive to projection errors. In this work, we propose a novel end-to-end model that learns to align and predict target slot labels jointly for cross-lingual transfer. We introduce MultiATIS++, a new multilingual NLU corpus that extends the Multilingual ATIS corpus to nine languages across four language families, and evaluate our method using the corpus. Results show that our method outperforms a simple label projection method using fast-align on most languages, and achieves competitive performance to the more complex, state-of-the-art projection method with only half of the training time. We release our MultiATIS++ corpus to the community to continue future research on cross-lingual NLU.","End-to-End Slot Alignment and Recognition for Cross-Lingual NLU Natural language understanding (NLU) in the context of goal-oriented dialog systems typically includes intent classification and slot labeling tasks. Existing methods to expand an NLU system to new languages use machine translation with slot label projection from source to the translated utterances, and thus are sensitive to projection errors. In this work, we propose a novel end-to-end model that learns to align and predict target slot labels jointly for cross-lingual transfer. We introduce MultiATIS++, a new multilingual NLU corpus that extends the Multilingual ATIS corpus to nine languages across four language families, and evaluate our method using the corpus. Results show that our method outperforms a simple label projection method using fast-align on most languages, and achieves competitive performance to the more complex, state-of-the-art projection method with only half of the training time. We release our MultiATIS++ corpus to the community to continue future research on cross-lingual NLU.","end - - end slot alignment recognition cross - lingual nlu natural language understanding ( nlu ) context goal - orient dialog system typically include intent classification slot labeling task . exist method expand nlu system new language use machine translation slot label projection source translate utterance , sensitive projection error . work , propose novel end - - end model learn align predict target slot label jointly cross - lingual transfer . introduce multiatis++ , new multilingual nlu corpus extend multilingual atis corpus language language family , evaluate method corpus . result method outperform simple label projection method fast - align language , achieve competitive performance complex , state - - - art projection method half training time . release multiatis++ corpus community continue future research cross - lingual nlu .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses,"In real-world dialogue, first-person visual information about where the other speakers are and what they are paying attention to is crucial to understand their intentions. Non-verbal responses also play an important role in social interactions. In this paper, we propose a visuallygrounded first-person dialogue (VFD) dataset with verbal and non-verbal responses. The VFD dataset provides manually annotated (1) first-person images of agents, (2) utterances of human speakers, (3) eye-gaze locations of the speakers, and (4) the agents' verbal and nonverbal responses. We present experimental results obtained using the proposed VFD dataset and recent neural network models (e.g., BERT, ResNet). The results demonstrate that firstperson vision helps neural network models correctly understand human intentions, and the production of non-verbal responses is a challenging task like that of verbal responses. Our dataset is publicly available 1 .","A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses In real-world dialogue, first-person visual information about where the other speakers are and what they are paying attention to is crucial to understand their intentions. Non-verbal responses also play an important role in social interactions. In this paper, we propose a visuallygrounded first-person dialogue (VFD) dataset with verbal and non-verbal responses. The VFD dataset provides manually annotated (1) first-person images of agents, (2) utterances of human speakers, (3) eye-gaze locations of the speakers, and (4) the agents' verbal and nonverbal responses. We present experimental results obtained using the proposed VFD dataset and recent neural network models (e.g., BERT, ResNet). The results demonstrate that firstperson vision helps neural network models correctly understand human intentions, and the production of non-verbal responses is a challenging task like that of verbal responses. Our dataset is publicly available 1 .","visually - ground - person dialogue dataset verbal non - verbal response real - world dialogue , - person visual information speaker pay attention crucial understand intention . non - verbal response play important role social interaction . paper , propose visuallygrounded - person dialogue ( vfd ) dataset verbal non - verbal response . vfd dataset provide manually annotate ( 1 ) - person image agent , ( 2 ) utterance human speaker , ( 3 ) eye - gaze location speaker , ( 4 ) agent ' verbal nonverbal response . present experimental result obtain proposed vfd dataset recent neural network model ( e.g. , bert , resnet ) . result demonstrate firstperson vision help neural network model correctly understand human intention , production non - verbal response challenging task like verbal response . dataset publicly available 1 .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 12, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Towards Persona-Based Empathetic Conversational Models,"Empathetic conversational models have been shown to improve user satisfaction and task outcomes in numerous domains. In Psychology, persona has been shown to be highly correlated to personality, which in turn influences empathy. In addition, our empirical analysis also suggests that persona plays an important role in empathetic conversations. To this end, we propose a new task towards persona-based empathetic conversations and present the first empirical study on the impact of persona on empathetic responding. Specifically, we first present a novel large-scale multi-domain dataset for persona-based empathetic conversations. We then propose CoBERT, an efficient BERT-based response selection model that obtains the state-of-the-art performance on our dataset. Finally, we conduct extensive experiments to investigate the impact of persona on empathetic responding. Notably, our results show that persona improves empathetic responding more when CoBERT is trained on empathetic conversations than non-empathetic ones, establishing an empirical link between persona and empathy in human conversations.","Towards Persona-Based Empathetic Conversational Models Empathetic conversational models have been shown to improve user satisfaction and task outcomes in numerous domains. In Psychology, persona has been shown to be highly correlated to personality, which in turn influences empathy. In addition, our empirical analysis also suggests that persona plays an important role in empathetic conversations. To this end, we propose a new task towards persona-based empathetic conversations and present the first empirical study on the impact of persona on empathetic responding. Specifically, we first present a novel large-scale multi-domain dataset for persona-based empathetic conversations. We then propose CoBERT, an efficient BERT-based response selection model that obtains the state-of-the-art performance on our dataset. Finally, we conduct extensive experiments to investigate the impact of persona on empathetic responding. Notably, our results show that persona improves empathetic responding more when CoBERT is trained on empathetic conversations than non-empathetic ones, establishing an empirical link between persona and empathy in human conversations.","persona - base empathetic conversational models empathetic conversational model show improve user satisfaction task outcome numerous domain . psychology , persona show highly correlated personality , turn influence empathy . addition , empirical analysis suggest persona play important role empathetic conversation . end , propose new task persona - base empathetic conversation present empirical study impact persona empathetic respond . specifically , present novel large - scale multi - domain dataset persona - base empathetic conversation . propose cobert , efficient bert - base response selection model obtain state - - - art performance dataset . finally , conduct extensive experiment investigate impact persona empathetic respond . notably , result persona improve empathetic responding cobert train empathetic conversation non - empathetic one , establish empirical link persona empathy human conversation .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,MedDialog: Large-scale Medical Dialogue Datasets,"Medical dialogue systems are promising in assisting in telemedicine to increase access to healthcare services, improve the quality of patient care, and reduce medical costs. To facilitate the research and development of medical dialogue systems, we build large-scale medical dialogue datasets -MedDialog, which contain 1) a Chinese dataset with 3.4 million conversations between patients and doctors, 11.3 million utterances, 660.2 million tokens, covering 172 specialties of diseases, and 2) an English dataset with 0.26 million conversations, 0.51 million utterances, 44.53 million tokens, covering 96 specialties of diseases. To our best knowledge, MedDialog is the largest medical dialogue dataset to date. We pretrain several dialogue generation models on the Chinese MedDialog dataset, including Transformer, GPT, BERT-GPT, and compare their performance. It is shown that models trained on MedDialog are able to generate clinically correct and human-like medical dialogues. We also study the transferability of models trained on MedDialog to lowresource medical dialogue generation tasks. It is shown that via transfer learning which finetunes the models pretrained on MedDialog, the performance on medical dialogue generation tasks with small datasets can be greatly improved, as shown in human evaluation and automatic evaluation.","MedDialog: Large-scale Medical Dialogue Datasets Medical dialogue systems are promising in assisting in telemedicine to increase access to healthcare services, improve the quality of patient care, and reduce medical costs. To facilitate the research and development of medical dialogue systems, we build large-scale medical dialogue datasets -MedDialog, which contain 1) a Chinese dataset with 3.4 million conversations between patients and doctors, 11.3 million utterances, 660.2 million tokens, covering 172 specialties of diseases, and 2) an English dataset with 0.26 million conversations, 0.51 million utterances, 44.53 million tokens, covering 96 specialties of diseases. To our best knowledge, MedDialog is the largest medical dialogue dataset to date. We pretrain several dialogue generation models on the Chinese MedDialog dataset, including Transformer, GPT, BERT-GPT, and compare their performance. It is shown that models trained on MedDialog are able to generate clinically correct and human-like medical dialogues. We also study the transferability of models trained on MedDialog to lowresource medical dialogue generation tasks. It is shown that via transfer learning which finetunes the models pretrained on MedDialog, the performance on medical dialogue generation tasks with small datasets can be greatly improved, as shown in human evaluation and automatic evaluation.","meddialog : large - scale medical dialogue datasets medical dialogue system promising assist telemedicine increase access healthcare service , improve quality patient care , reduce medical cost . facilitate research development medical dialogue system , build large - scale medical dialogue dataset -meddialog , contain 1 ) chinese dataset 3.4 million conversation patient doctor , 11.3 million utterance , 660.2 million token , cover 172 specialty disease , 2 ) english dataset 0.26 million conversation , 0.51 million utterance , 44.53 million token , cover 96 specialty disease . good knowledge , meddialog large medical dialogue dataset date . pretrain dialogue generation model chinese meddialog dataset , include transformer , gpt , bert - gpt , compare performance . show model train meddialog able generate clinically correct human - like medical dialogue . study transferability model train meddialog lowresource medical dialogue generation task . show transfer learning finetune model pretraine meddialog , performance medical dialogue generation task small dataset greatly improve , show human evaluation automatic evaluation .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 29, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Conversational Semantic Parsing for Dialog State Tracking,"We consider a new perspective on dialog state tracking (DST), the task of estimating a user's goal through the course of a dialog. By formulating DST as a semantic parsing task over hierarchical representations, we can incorporate semantic compositionality, crossdomain knowledge sharing and co-reference. We present TreeDST, a dataset of 27k conversations annotated with tree-structured dialog states and system acts. 1 We describe an encoder-decoder framework for DST with hierarchical representations, which leads to 20% improvement over state-of-the-art DST approaches that operate on a flat meaning space of slot-value pairs. Turn Utterance and Annotation 1 Hi can you book me a flight to Paris please. user.flight.book.object.equals .destination.equals.location.equals.Paris Sure, when and where will you depart? system.prompt.flight.book.object.equals .source .departureDateTime","Conversational Semantic Parsing for Dialog State Tracking We consider a new perspective on dialog state tracking (DST), the task of estimating a user's goal through the course of a dialog. By formulating DST as a semantic parsing task over hierarchical representations, we can incorporate semantic compositionality, crossdomain knowledge sharing and co-reference. We present TreeDST, a dataset of 27k conversations annotated with tree-structured dialog states and system acts. 1 We describe an encoder-decoder framework for DST with hierarchical representations, which leads to 20% improvement over state-of-the-art DST approaches that operate on a flat meaning space of slot-value pairs. Turn Utterance and Annotation 1 Hi can you book me a flight to Paris please. user.flight.book.object.equals .destination.equals.location.equals.Paris Sure, when and where will you depart? system.prompt.flight.book.object.equals .source .departureDateTime","conversational semantic parsing dialog state tracking consider new perspective dialog state tracking ( dst ) , task estimate user goal course dialog . formulate dst semantic parsing task hierarchical representation , incorporate semantic compositionality , crossdomain knowledge sharing co - reference . present treedst , dataset 27k conversation annotate tree - structured dialog state system act . 1 describe encoder - decoder framework dst hierarchical representation , lead 20 % improvement state - - - art dst approach operate flat meaning space slot - value pair . turn utterance annotation 1 hi book flight paris . user.flight.book.object.equals .destination.equals.location.equals . paris sure , depart ? system.prompt.flight.book.object.equals .source .departuredatetim","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental NLU,"While humans process language incrementally, the best language encoders currently used in NLP do not. Both bidirectional LSTMs and Transformers assume that the sequence that is to be encoded is available in full, to be processed either forwards and backwards (BiL-STMs) or as a whole (Transformers). We investigate how they behave under incremental interfaces, when partial output must be provided based on partial input seen up to a certain time step, which may happen in interactive systems. We test five models on various NLU datasets and compare their performance using three incremental evaluation metrics. The results support the possibility of using bidirectional encoders in incremental mode while retaining most of their non-incremental quality. The ""omni-directional"" BERT model, which achieves better non-incremental performance, is impacted more by the incremental access. This can be alleviated by adapting the training regime (truncated training), or the testing procedure, by delaying the output until some right context is available or by incorporating hypothetical right contexts generated by a language model like GPT-2.","Incremental Processing in the Age of Non-Incremental Encoders: An Empirical Assessment of Bidirectional Models for Incremental NLU While humans process language incrementally, the best language encoders currently used in NLP do not. Both bidirectional LSTMs and Transformers assume that the sequence that is to be encoded is available in full, to be processed either forwards and backwards (BiL-STMs) or as a whole (Transformers). We investigate how they behave under incremental interfaces, when partial output must be provided based on partial input seen up to a certain time step, which may happen in interactive systems. We test five models on various NLU datasets and compare their performance using three incremental evaluation metrics. The results support the possibility of using bidirectional encoders in incremental mode while retaining most of their non-incremental quality. The ""omni-directional"" BERT model, which achieves better non-incremental performance, is impacted more by the incremental access. This can be alleviated by adapting the training regime (truncated training), or the testing procedure, by delaying the output until some right context is available or by incorporating hypothetical right contexts generated by a language model like GPT-2.","incremental processing age non - incremental encoder : empirical assessment bidirectional model incremental nlu human process language incrementally , good language encoder currently nlp . bidirectional lstms transformers assume sequence encode available , process forwards backwards ( bil - stms ) ( transformers ) . investigate behave incremental interface , partial output provide base partial input see certain time step , happen interactive system . test model nlu dataset compare performance incremental evaluation metric . result support possibility bidirectional encoder incremental mode retain non - incremental quality . "" omni - directional "" bert model , achieve well non - incremental performance , impact incremental access . alleviate adapt training regime ( truncate training ) , testing procedure , delay output right context available incorporate hypothetical right context generate language model like gpt-2 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 10, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
Dialogue and Interactive Systems,Multi-turn Response Selection using Dialogue Dependency Relations,"Multi-turn response selection is a task designed for developing dialogue agents. The performance on this task has a remarkable improvement with pre-trained language models. However, these models simply concatenate the turns in dialogue history as the input and largely ignore the dependencies between the turns. In this paper, we propose a dialogue extraction algorithm to transform a dialogue history into threads based on their dependency relations. Each thread can be regarded as a self-contained sub-dialogue. We also propose Thread-Encoder model to encode threads and candidates into compact representations by pre-trained Transformers and finally get the matching score through an attention layer. The experiments show that dependency relations are helpful for dialogue context understanding, and our model outperforms the state-of-the-art baselines on both DSTC7 and DSTC8*, with competitive results on UbuntuV2.","Multi-turn Response Selection using Dialogue Dependency Relations Multi-turn response selection is a task designed for developing dialogue agents. The performance on this task has a remarkable improvement with pre-trained language models. However, these models simply concatenate the turns in dialogue history as the input and largely ignore the dependencies between the turns. In this paper, we propose a dialogue extraction algorithm to transform a dialogue history into threads based on their dependency relations. Each thread can be regarded as a self-contained sub-dialogue. We also propose Thread-Encoder model to encode threads and candidates into compact representations by pre-trained Transformers and finally get the matching score through an attention layer. The experiments show that dependency relations are helpful for dialogue context understanding, and our model outperforms the state-of-the-art baselines on both DSTC7 and DSTC8*, with competitive results on UbuntuV2.","multi - turn response selection dialogue dependency relations multi - turn response selection task design develop dialogue agent . performance task remarkable improvement pre - trained language model . , model simply concatenate turn dialogue history input largely ignore dependency turn . paper , propose dialogue extraction algorithm transform dialogue history thread base dependency relation . thread regard self - contain sub - dialogue . propose thread - encoder model encode thread candidate compact representation pre - train transformers finally match score attention layer . experiment dependency relation helpful dialogue context understanding , model outperform state - - - art baseline dstc7 dstc8 * , competitive result ubuntuv2 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 22, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Supervised Seeded Iterated Learning for Interactive Language Learning,"Language drift has been one of the major obstacles to train language models through interaction. When word-based conversational agents are trained towards completing a task, they tend to invent their language rather than leveraging natural language. In recent literature, two general methods partially counter this phenomenon: Supervised Selfplay (S2P) and Seeded Iterated Learning (SIL). While S2P jointly trains interactive and supervised losses to counter the drift, SIL changes the training dynamics to prevent language drift from occurring. In this paper, we first highlight their respective weaknesses, i.e., latestage training collapses and higher negative likelihood when evaluated on human corpus. Given these observations, we introduce Supervised Seeded Iterated Learning (SSIL) to combine both methods to minimize their respective weaknesses. We then show the effectiveness of SSIL in the language-drift translation game.","Supervised Seeded Iterated Learning for Interactive Language Learning Language drift has been one of the major obstacles to train language models through interaction. When word-based conversational agents are trained towards completing a task, they tend to invent their language rather than leveraging natural language. In recent literature, two general methods partially counter this phenomenon: Supervised Selfplay (S2P) and Seeded Iterated Learning (SIL). While S2P jointly trains interactive and supervised losses to counter the drift, SIL changes the training dynamics to prevent language drift from occurring. In this paper, we first highlight their respective weaknesses, i.e., latestage training collapses and higher negative likelihood when evaluated on human corpus. Given these observations, we introduce Supervised Seeded Iterated Learning (SSIL) to combine both methods to minimize their respective weaknesses. We then show the effectiveness of SSIL in the language-drift translation game.","supervised seeded iterated learning interactive language learning language drift major obstacle train language model interaction . word - base conversational agent train complete task , tend invent language leverage natural language . recent literature , general method partially counter phenomenon : supervised selfplay ( s2p ) seeded iterated learning ( sil ) . s2p jointly train interactive supervise loss counter drift , sil change training dynamic prevent language drift occur . paper , highlight respective weakness , i.e. , latestage training collapse high negative likelihood evaluate human corpus . give observation , introduce supervised seeded iterated learning ( ssil ) combine method minimize respective weakness . effectiveness ssil language - drift translation game .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Dialogue and Interactive Systems,Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging,"The concept of Dialogue Act (DA) is universal across different task-oriented dialogue domains -the act of ""request"" carries the same speaker intention whether it is for restaurant reservation or flight booking. However, DA taggers trained on one domain do not generalize well to other domains, which leaves us with the expensive need for a large amount of annotated data in the target domain. In this work, we investigate how to better adapt DA taggers to desired target domains with only unlabeled data. We propose MASKAUGMENT, a controllable mechanism that augments text input by leveraging the pre-trained MASK token from BERT model. Inspired by consistency regularization, we use MASKAUGMENT to introduce an unsupervised teacher-student learning scheme to examine the domain adaptation of DA taggers. Our extensive experiments on the Simulated Dialogue (GSim) and Schema-Guided Dialogue (SGD) datasets show that MASKAUGMENT is useful in improving the cross-domain generalization for DA tagging.","Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging The concept of Dialogue Act (DA) is universal across different task-oriented dialogue domains -the act of ""request"" carries the same speaker intention whether it is for restaurant reservation or flight booking. However, DA taggers trained on one domain do not generalize well to other domains, which leaves us with the expensive need for a large amount of annotated data in the target domain. In this work, we investigate how to better adapt DA taggers to desired target domains with only unlabeled data. We propose MASKAUGMENT, a controllable mechanism that augments text input by leveraging the pre-trained MASK token from BERT model. Inspired by consistency regularization, we use MASKAUGMENT to introduce an unsupervised teacher-student learning scheme to examine the domain adaptation of DA taggers. Our extensive experiments on the Simulated Dialogue (GSim) and Schema-Guided Dialogue (SGD) datasets show that MASKAUGMENT is useful in improving the cross-domain generalization for DA tagging.","simple data augmentation mask token improve domain adaptation dialog act tagging concept dialogue act ( da ) universal different task - orient dialogue domain -the act "" request "" carry speaker intention restaurant reservation flight booking . , da tagger train domain generalize domain , leave expensive need large annotate datum target domain . work , investigate well adapt da tagger desire target domain unlabeled datum . propose maskaugment , controllable mechanism augment text input leverage pre - trained mask token bert model . inspire consistency regularization , use maskaugment introduce unsupervised teacher - student learning scheme examine domain adaptation da tagger . extensive experiment simulated dialogue ( gsim ) schema - guided dialogue ( sgd ) dataset maskaugment useful improve cross - domain generalization da tagging .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems,"The lack of time-efficient and reliable evaluation methods hamper the development of conversational dialogue systems (chatbots). Evaluations requiring humans to converse with chatbots are time and cost-intensive, put high cognitive demands on the human judges, and yield low-quality results. In this work, we introduce Spot The Bot, a cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots. Human judges then only annotate for each entity in a conversation whether they think it is human or not (assuming there are humans participants in these conversations). These annotations then allow us to rank chatbots regarding their ability to mimic the conversational behavior of humans. Since we expect that all bots are eventually recognized as such, we incorporate a metric that measures which chatbot can uphold human-like behavior the longest, i.e., Survival Analysis. This metric has the ability to correlate a bot's performance to certain of its characteristics (e.g., fluency or sensibleness), yielding interpretable results. The comparably low cost of our framework allows for frequent evaluations of chatbots during their evaluation cycle. We empirically validate our claims by applying Spot The Bot to three domains, evaluating several stateof-the-art chatbots, and drawing comparisons to related work. The framework is released as a ready-to-use tool.","Spot The Bot: A Robust and Efficient Framework for the Evaluation of Conversational Dialogue Systems The lack of time-efficient and reliable evaluation methods hamper the development of conversational dialogue systems (chatbots). Evaluations requiring humans to converse with chatbots are time and cost-intensive, put high cognitive demands on the human judges, and yield low-quality results. In this work, we introduce Spot The Bot, a cost-efficient and robust evaluation framework that replaces human-bot conversations with conversations between bots. Human judges then only annotate for each entity in a conversation whether they think it is human or not (assuming there are humans participants in these conversations). These annotations then allow us to rank chatbots regarding their ability to mimic the conversational behavior of humans. Since we expect that all bots are eventually recognized as such, we incorporate a metric that measures which chatbot can uphold human-like behavior the longest, i.e., Survival Analysis. This metric has the ability to correlate a bot's performance to certain of its characteristics (e.g., fluency or sensibleness), yielding interpretable results. The comparably low cost of our framework allows for frequent evaluations of chatbots during their evaluation cycle. We empirically validate our claims by applying Spot The Bot to three domains, evaluating several stateof-the-art chatbots, and drawing comparisons to related work. The framework is released as a ready-to-use tool.","spot bot : robust efficient framework evaluation conversational dialogue system lack time - efficient reliable evaluation method hamper development conversational dialogue system ( chatbot ) . evaluation require human converse chatbot time cost - intensive , high cognitive demand human judge , yield low - quality result . work , introduce spot bot , cost - efficient robust evaluation framework replace human - bot conversation conversation bot . human judge annotate entity conversation think human ( assume human participant conversation ) . annotation allow rank chatbot ability mimic conversational behavior human . expect bot eventually recognize , incorporate metric measure chatbot uphold human - like behavior long , i.e. , survival analysis . metric ability correlate bot performance certain characteristic ( e.g. , fluency sensibleness ) , yield interpretable result . comparably low cost framework allow frequent evaluation chatbot evaluation cycle . empirically validate claim apply spot bot domain , evaluate stateof - - art chatbot , draw comparison related work . framework release ready - - use tool .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 8, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Personal Information Leakage Detection in Conversations,"The global market size of conversational assistants (chatbots) is expected to grow to USD 9.4 billion by 2024, according to Marketsand-Markets. Despite the wide use of chatbots, leakage of personal information through chatbots poses serious privacy concerns for their users. In this work, we propose to protect personal information by warning users of detected suspicious sentences generated by conversational assistants. The detection task is formulated as an alignment optimization problem and a new dataset PERSONA-LEAKAGE is collected for evaluation. In this paper, we propose two novel constrained alignment models, which consistently outperform baseline methods on PERSONA-LEAKAGE 1 . Moreover, we conduct analysis on the behavior of recently proposed personalized chit-chat dialogue systems. The empirical results show that those systems suffer more from personal information disclosure than the widely used Seq2Seq model and the language model. In those cases, a significant number of information leaking utterances can be detected by our models with high precision.","Personal Information Leakage Detection in Conversations The global market size of conversational assistants (chatbots) is expected to grow to USD 9.4 billion by 2024, according to Marketsand-Markets. Despite the wide use of chatbots, leakage of personal information through chatbots poses serious privacy concerns for their users. In this work, we propose to protect personal information by warning users of detected suspicious sentences generated by conversational assistants. The detection task is formulated as an alignment optimization problem and a new dataset PERSONA-LEAKAGE is collected for evaluation. In this paper, we propose two novel constrained alignment models, which consistently outperform baseline methods on PERSONA-LEAKAGE 1 . Moreover, we conduct analysis on the behavior of recently proposed personalized chit-chat dialogue systems. The empirical results show that those systems suffer more from personal information disclosure than the widely used Seq2Seq model and the language model. In those cases, a significant number of information leaking utterances can be detected by our models with high precision.","personal information leakage detection conversation global market size conversational assistant ( chatbot ) expect grow usd 9.4 billion 2024 , accord marketsand - markets . despite wide use chatbot , leakage personal information chatbot pose privacy concern user . work , propose protect personal information warn user detect suspicious sentence generate conversational assistant . detection task formulate alignment optimization problem new dataset persona - leakage collect evaluation . paper , propose novel constrain alignment model , consistently outperform baseline method persona - leakage 1 . , conduct analysis behavior recently propose personalize chit - chat dialogue system . empirical result system suffer personal information disclosure widely seq2seq model language model . case , significant number information leak utterance detect model high precision .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Dialogue and Interactive Systems,Structured Attention for Unsupervised Dialogue Structure Induction,"Inducing a meaningful structural representation from one or a set of dialogues is a crucial but challenging task in computational linguistics. Advancement made in this area is critical for dialogue system design and discourse analysis. It can also be extended to solve grammatical inference. In this work, we propose to incorporate structured attention layers into a Variational Recurrent Neural Network (VRNN) model with discrete latent states to learn dialogue structure in an unsupervised fashion. Compared to a vanilla VRNN, structured attention enables a model to focus on different parts of the source sentence embeddings while enforcing a structural inductive bias. Experiments show that on two-party dialogue datasets, VRNN with structured attention learns semantic structures that are similar to templates used to generate this dialogue corpus. While on multi-party dialogue datasets, our model learns an interactive structure demonstrating its capability of distinguishing speakers or addresses, automatically disentangling dialogues without explicit human annotation. 1","Structured Attention for Unsupervised Dialogue Structure Induction Inducing a meaningful structural representation from one or a set of dialogues is a crucial but challenging task in computational linguistics. Advancement made in this area is critical for dialogue system design and discourse analysis. It can also be extended to solve grammatical inference. In this work, we propose to incorporate structured attention layers into a Variational Recurrent Neural Network (VRNN) model with discrete latent states to learn dialogue structure in an unsupervised fashion. Compared to a vanilla VRNN, structured attention enables a model to focus on different parts of the source sentence embeddings while enforcing a structural inductive bias. Experiments show that on two-party dialogue datasets, VRNN with structured attention learns semantic structures that are similar to templates used to generate this dialogue corpus. While on multi-party dialogue datasets, our model learns an interactive structure demonstrating its capability of distinguishing speakers or addresses, automatically disentangling dialogues without explicit human annotation. 1","structured attention unsupervised dialogue structure induction induce meaningful structural representation set dialogue crucial challenging task computational linguistic . advancement area critical dialogue system design discourse analysis . extend solve grammatical inference . work , propose incorporate structured attention layer variational recurrent neural network ( vrnn ) model discrete latent state learn dialogue structure unsupervised fashion . compare vanilla vrnn , structured attention enable model focus different part source sentence embedding enforce structural inductive bias . experiment - party dialogue dataset , vrnn structured attention learn semantic structure similar template generate dialogue corpus . multi - party dialogue dataset , model learn interactive structure demonstrate capability distinguish speaker address , automatically disentangle dialogue explicit human annotation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 17, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling,"In order to alleviate the shortage of multidomain data and to capture discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a large-scale multidomain Chinese Wizard-of-Oz dataset with Rich Semantic Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multiturn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets. Both single-and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively. Each dialogue is labeled with comprehensive dialogue annotations, including dialogue goal in the form of natural language description, domain, dialogue states and acts at both the user and system side. In addition to traditional dialogue annotations, we especially provide linguistic annotations on discourse phenomena, e.g., ellipsis and coreference, in dialogues, which are useful for dialogue coreference and ellipsis resolution tasks. Apart from the fully annotated dataset, we also present a detailed description of the data collection procedure, statistics and analysis of the dataset. A series of benchmark models and results are reported, including natural language understanding (intent detection & slot filling), dialogue state tracking and dialogue contextto-text generation, as well as coreference and ellipsis resolution, which facilitate the baseline comparison for future research on this corpus. 1","RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling In order to alleviate the shortage of multidomain data and to capture discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a large-scale multidomain Chinese Wizard-of-Oz dataset with Rich Semantic Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multiturn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets. Both single-and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively. Each dialogue is labeled with comprehensive dialogue annotations, including dialogue goal in the form of natural language description, domain, dialogue states and acts at both the user and system side. In addition to traditional dialogue annotations, we especially provide linguistic annotations on discourse phenomena, e.g., ellipsis and coreference, in dialogues, which are useful for dialogue coreference and ellipsis resolution tasks. Apart from the fully annotated dataset, we also present a detailed description of the data collection procedure, statistics and analysis of the dataset. A series of benchmark models and results are reported, including natural language understanding (intent detection & slot filling), dialogue state tracking and dialogue contextto-text generation, as well as coreference and ellipsis resolution, which facilitate the baseline comparison for future research on this corpus. 1","risawoz : large - scale multi - domain wizard - - oz dataset rich semantic annotation task - orient dialogue modeling order alleviate shortage multidomain datum capture discourse phenomenon task - orient dialogue modeling , propose risawoz , large - scale multidomain chinese wizard - - oz dataset rich semantic annotations . risawoz contain 11.2 k human - - human ( h2h ) multiturn semantically annotate dialogue , 150 k utterance span 12 domain , large previous annotate h2h conversational dataset . single - multi - domain dialogue construct , account 65 % 35 % , respectively . dialogue label comprehensive dialogue annotation , include dialogue goal form natural language description , domain , dialogue state act user system . addition traditional dialogue annotation , especially provide linguistic annotation discourse phenomenon , e.g. , ellipsis coreference , dialogue , useful dialogue coreference ellipsis resolution task . apart fully annotate dataset , present detailed description data collection procedure , statistic analysis dataset . series benchmark model result report , include natural language understanding ( intent detection & slot filling ) , dialogue state tracking dialogue contextto - text generation , coreference ellipsis resolution , facilitate baseline comparison future research corpus . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 33, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation,"Knowledge selection plays an important role in knowledge-grounded dialogue, which is a challenging task to generate more informative responses by leveraging external knowledge. Recently, latent variable models have been proposed to deal with the diversity of knowledge selection by using both prior and posterior distributions over knowledge and achieve promising performance. However, these models suffer from a huge gap between prior and posterior knowledge selection. Firstly, the prior selection module may not learn to select knowledge properly because of lacking the necessary posterior information. Secondly, latent variable models suffer from the exposure bias that dialogue generation is based on the knowledge selected from the posterior distribution at training but from the prior distribution at inference. Here, we deal with these issues on two aspects: (1) We enhance the prior selection module with the necessary posterior information obtained from the specially designed Posterior Information Prediction Module (PIPM); (2) We propose a Knowledge Distillation Based Training Strategy (KDBTS) to train the decoder with the knowledge selected from the prior distribution, removing the exposure bias of knowledge selection. Experimental results on two knowledge-grounded dialogue datasets show that both PIPM and KDBTS achieve performance improvement over the state-of-theart latent variable model and their combination shows further improvement.","Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation Knowledge selection plays an important role in knowledge-grounded dialogue, which is a challenging task to generate more informative responses by leveraging external knowledge. Recently, latent variable models have been proposed to deal with the diversity of knowledge selection by using both prior and posterior distributions over knowledge and achieve promising performance. However, these models suffer from a huge gap between prior and posterior knowledge selection. Firstly, the prior selection module may not learn to select knowledge properly because of lacking the necessary posterior information. Secondly, latent variable models suffer from the exposure bias that dialogue generation is based on the knowledge selected from the posterior distribution at training but from the prior distribution at inference. Here, we deal with these issues on two aspects: (1) We enhance the prior selection module with the necessary posterior information obtained from the specially designed Posterior Information Prediction Module (PIPM); (2) We propose a Knowledge Distillation Based Training Strategy (KDBTS) to train the decoder with the knowledge selected from the prior distribution, removing the exposure bias of knowledge selection. Experimental results on two knowledge-grounded dialogue datasets show that both PIPM and KDBTS achieve performance improvement over the state-of-theart latent variable model and their combination shows further improvement.","bridge gap prior posterior knowledge selection knowledge - ground dialogue generation knowledge selection play important role knowledge - ground dialogue , challenge task generate informative response leverage external knowledge . recently , latent variable model propose deal diversity knowledge selection prior posterior distribution knowledge achieve promising performance . , model suffer huge gap prior posterior knowledge selection . firstly , prior selection module learn select knowledge properly lack necessary posterior information . secondly , latent variable model suffer exposure bias dialogue generation base knowledge select posterior distribution training prior distribution inference . , deal issue aspect : ( 1 ) enhance prior selection module necessary posterior information obtain specially design posterior information prediction module ( pipm ) ; ( 2 ) propose knowledge distillation based training strategy ( kdbts ) train decoder knowledge select prior distribution , remove exposure bias knowledge selection . experimental result knowledge - ground dialogue dataset pipm kdbts achieve performance improvement state - - theart latent variable model combination show improvement .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 2, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Dialogue and Interactive Systems,Task-Completion Dialogue Policy Learning via Monte Carlo Tree Search with Dueling Network,"We introduce a framework of Monte Carlo Tree Search with Double-q Dueling network (MCTS-DDU) for task-completion dialogue policy learning. Different from the previous deep model-based reinforcement learning methods, which uses background planning and may suffer from low-quality simulated experiences, MCTS-DDU performs decision-time planning based on dialogue state search trees built by Monte Carlo simulations and is robust to the simulation errors. Such idea arises naturally in human behaviors, e.g. predicting others' responses and then deciding our own actions. In the simulated movie-ticket booking task, our method outperforms the background planning approaches significantly. We demonstrate the effectiveness of MCTS and the dueling network in detailed ablation studies, and also compare the performance upper bounds of these two planning methods.","Task-Completion Dialogue Policy Learning via Monte Carlo Tree Search with Dueling Network We introduce a framework of Monte Carlo Tree Search with Double-q Dueling network (MCTS-DDU) for task-completion dialogue policy learning. Different from the previous deep model-based reinforcement learning methods, which uses background planning and may suffer from low-quality simulated experiences, MCTS-DDU performs decision-time planning based on dialogue state search trees built by Monte Carlo simulations and is robust to the simulation errors. Such idea arises naturally in human behaviors, e.g. predicting others' responses and then deciding our own actions. In the simulated movie-ticket booking task, our method outperforms the background planning approaches significantly. We demonstrate the effectiveness of MCTS and the dueling network in detailed ablation studies, and also compare the performance upper bounds of these two planning methods.","task - completion dialogue policy learning monte carlo tree search dueling network introduce framework monte carlo tree search double - q dueling network ( mcts - ddu ) task - completion dialogue policy learning . different previous deep model - base reinforcement learning method , use background planning suffer low - quality simulate experience , mcts - ddu perform decision - time planning base dialogue state search tree build monte carlo simulation robust simulation error . idea arise naturally human behavior , e.g. predict ' response decide action . simulate movie - ticket booking task , method outperform background planning approach significantly . demonstrate effectiveness mcts duel network detailed ablation study , compare performance upper bound planning method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training,"The challenge of both achieving task completion by querying the knowledge base and generating human-like responses for task-oriented dialogue systems is attracting increasing research attention. In this paper, we propose a ""Two-Teacher One-Student"" learning framework (TTOS) for task-oriented dialogue, with the goal of retrieving accurate KB entities and generating human-like responses simultaneously. TTOS amalgamates knowledge from two teacher networks that together provide comprehensive guidance to build a highquality task-oriented dialogue system (student network). Each teacher network is trained via reinforcement learning with a goal-specific reward, which can be viewed as an expert towards the goal and transfers the professional characteristic to the student network. Instead of adopting the classic student-teacher learning of forcing the output of a student network to exactly mimic the soft targets produced by the teacher networks, we introduce two discriminators as in generative adversarial network (GAN) to transfer knowledge from two teachers to the student. The usage of discriminators relaxes the rigid coupling between the student and teachers. Extensive experiments on two benchmark datasets (i.e., CamRest and In-Car Assistant) demonstrate that TTOS significantly outperforms baseline methods. For reproducibility, we release the code and data at https://github.com/siat-nlp/TTOS.","Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training The challenge of both achieving task completion by querying the knowledge base and generating human-like responses for task-oriented dialogue systems is attracting increasing research attention. In this paper, we propose a ""Two-Teacher One-Student"" learning framework (TTOS) for task-oriented dialogue, with the goal of retrieving accurate KB entities and generating human-like responses simultaneously. TTOS amalgamates knowledge from two teacher networks that together provide comprehensive guidance to build a highquality task-oriented dialogue system (student network). Each teacher network is trained via reinforcement learning with a goal-specific reward, which can be viewed as an expert towards the goal and transfers the professional characteristic to the student network. Instead of adopting the classic student-teacher learning of forcing the output of a student network to exactly mimic the soft targets produced by the teacher networks, we introduce two discriminators as in generative adversarial network (GAN) to transfer knowledge from two teachers to the student. The usage of discriminators relaxes the rigid coupling between the student and teachers. Extensive experiments on two benchmark datasets (i.e., CamRest and In-Car Assistant) demonstrate that TTOS significantly outperforms baseline methods. For reproducibility, we release the code and data at https://github.com/siat-nlp/TTOS.","amalgamate knowledge teacher task - orient dialogue system adversarial training challenge achieve task completion query knowledge base generate human - like response task - orient dialogue system attract increase research attention . paper , propose "" - teacher - student "" learning framework ( ttos ) task - orient dialogue , goal retrieve accurate kb entity generate human - like response simultaneously . ttos amalgamate knowledge teacher network provide comprehensive guidance build highquality task - orient dialogue system ( student network ) . teacher network train reinforcement learning goal - specific reward , view expert goal transfer professional characteristic student network . instead adopt classic student - teacher learning force output student network exactly mimic soft target produce teacher network , introduce discriminator generative adversarial network ( gan ) transfer knowledge teacher student . usage discriminator relax rigid coupling student teacher . extensive experiment benchmark dataset ( i.e. , camrest - car assistant ) demonstrate ttos significantly outperform baseline method . reproducibility , release code datum https://github.com/siat-nlp/ttos .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 17, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Like hiking? You probably enjoy nature: Persona-grounded Dialog with Commonsense Expansions,"Existing persona-grounded dialog models often fail to capture simple implications of given persona descriptions, something which humans are able to do seamlessly. For example, state-of-the-art models cannot infer that interest in hiking might imply love for nature or longing for a break. In this paper, we propose to expand available persona sentences using existing commonsense knowledge bases and paraphrasing resources to imbue dialog models with access to an expanded and richer set of persona descriptions. Additionally, we introduce fine-grained grounding on personas by encouraging the model to make a discrete choice among persona sentences while synthesizing a dialog response. Since such a choice is not observed in the data, we model it using a discrete latent random variable and use variational learning to sample from hundreds of persona expansions. Our model outperforms competitive baselines on the PERSONA-CHAT dataset in terms of dialog quality and diversity while achieving persona-consistent and controllable dialog generation.","Like hiking? You probably enjoy nature: Persona-grounded Dialog with Commonsense Expansions Existing persona-grounded dialog models often fail to capture simple implications of given persona descriptions, something which humans are able to do seamlessly. For example, state-of-the-art models cannot infer that interest in hiking might imply love for nature or longing for a break. In this paper, we propose to expand available persona sentences using existing commonsense knowledge bases and paraphrasing resources to imbue dialog models with access to an expanded and richer set of persona descriptions. Additionally, we introduce fine-grained grounding on personas by encouraging the model to make a discrete choice among persona sentences while synthesizing a dialog response. Since such a choice is not observed in the data, we model it using a discrete latent random variable and use variational learning to sample from hundreds of persona expansions. Our model outperforms competitive baselines on the PERSONA-CHAT dataset in terms of dialog quality and diversity while achieving persona-consistent and controllable dialog generation.","like hiking ? probably enjoy nature : persona - ground dialog commonsense expansion exist persona - ground dialog model fail capture simple implication give persona description , human able seamlessly . example , state - - - art model infer interest hiking imply love nature longing break . paper , propose expand available persona sentence exist commonsense knowledge basis paraphrase resource imbue dialog model access expanded rich set persona description . additionally , introduce fine - grained grounding persona encourage model discrete choice persona sentence synthesize dialog response . choice observe datum , model discrete latent random variable use variational learning sample hundred persona expansion . model outperform competitive baseline persona - chat dataset term dialog quality diversity achieve persona - consistent controllable dialog generation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Response Selection for Multi-Party Conversations with Dynamic Topic Tracking,"While participants in a multi-party multi-turn conversation simultaneously engage in multiple conversation topics, existing response selection methods are developed mainly focusing on a two-party single-conversation scenario. Hence, the prolongation and transition of conversation topics are ignored by current methods. In this work, we frame response selection as a dynamic topic tracking task to match the topic between the response and relevant conversation context. With this new formulation, we propose a novel multi-task learning framework that supports efficient encoding through large pretrained models with only two utterances at once to perform dynamic topic disentanglement and response selection. We also propose Topic-BERT an essential pretraining step to embed topic information into BERT with self-supervised learning. Experimental results on the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response selection and topic disentanglement tasks outperforming existing methods by a good margin. 1","Response Selection for Multi-Party Conversations with Dynamic Topic Tracking While participants in a multi-party multi-turn conversation simultaneously engage in multiple conversation topics, existing response selection methods are developed mainly focusing on a two-party single-conversation scenario. Hence, the prolongation and transition of conversation topics are ignored by current methods. In this work, we frame response selection as a dynamic topic tracking task to match the topic between the response and relevant conversation context. With this new formulation, we propose a novel multi-task learning framework that supports efficient encoding through large pretrained models with only two utterances at once to perform dynamic topic disentanglement and response selection. We also propose Topic-BERT an essential pretraining step to embed topic information into BERT with self-supervised learning. Experimental results on the DSTC-8 Ubuntu IRC dataset show state-of-the-art results in response selection and topic disentanglement tasks outperforming existing methods by a good margin. 1","response selection multi - party conversation dynamic topic tracking participant multi - party multi - turn conversation simultaneously engage multiple conversation topic , exist response selection method develop mainly focus - party single - conversation scenario . , prolongation transition conversation topic ignore current method . work , frame response selection dynamic topic track task match topic response relevant conversation context . new formulation , propose novel multi - task learning framework support efficient encoding large pretrained model utterance perform dynamic topic disentanglement response selection . propose topic - bert essential pretraine step embed topic information bert self - supervise learning . experimental result dstc-8 ubuntu irc dataset state - - - art result response selection topic disentanglement task outperform exist method good margin . 1","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 14, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 9, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,INSPIRED: Toward Sociable Recommendation Dialog Systems,"In recommendation dialogs, humans commonly disclose their preference and make recommendations in a friendly manner. However, this is a challenge in developing a sociable recommendation dialog system, due to the lack of dialog dataset annotated with such sociable strategies. Therefore, we present INSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation with measures for successful recommendations. To better understand how humans make recommendations in communication, we design an annotation scheme related to recommendation strategies based on social science theories and annotate these dialogs. Our analysis shows that sociable recommendation strategies, such as sharing personal opinions or communicating with encouragement, more frequently lead to successful recommendations. Based on our dataset, we train end-to-end recommendation dialog systems with and without our strategy labels. In both automatic and human evaluation, our model with strategy incorporation outperforms the baseline model. This work is a first step for building sociable recommendation dialog systems with a basis of social science theories 1 .","INSPIRED: Toward Sociable Recommendation Dialog Systems In recommendation dialogs, humans commonly disclose their preference and make recommendations in a friendly manner. However, this is a challenge in developing a sociable recommendation dialog system, due to the lack of dialog dataset annotated with such sociable strategies. Therefore, we present INSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation with measures for successful recommendations. To better understand how humans make recommendations in communication, we design an annotation scheme related to recommendation strategies based on social science theories and annotate these dialogs. Our analysis shows that sociable recommendation strategies, such as sharing personal opinions or communicating with encouragement, more frequently lead to successful recommendations. Based on our dataset, we train end-to-end recommendation dialog systems with and without our strategy labels. In both automatic and human evaluation, our model with strategy incorporation outperforms the baseline model. This work is a first step for building sociable recommendation dialog systems with a basis of social science theories 1 .","inspired : sociable recommendation dialog system recommendation dialog , human commonly disclose preference recommendation friendly manner . , challenge develop sociable recommendation dialog system , lack dialog dataset annotate sociable strategy . , present inspired , new dataset 1,001 human - human dialog movie recommendation measure successful recommendation . well understand human recommendation communication , design annotation scheme relate recommendation strategy base social science theory annotate dialog . analysis show sociable recommendation strategy , share personal opinion communicate encouragement , frequently lead successful recommendation . base dataset , train end - - end recommendation dialog system strategy label . automatic human evaluation , model strategy incorporation outperform baseline model . work step build sociable recommendation dialog system basis social science theory 1 .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 12, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 15, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Dialogue and Interactive Systems,GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems,"End-to-end task-oriented dialogue systems aim to generate system responses directly from plain text inputs. There are two challenges for such systems: one is how to effectively incorporate external knowledge bases (KBs) into the learning framework; the other is how to accurately capture the semantics of dialogue history. In this paper, we address these two challenges by exploiting the graph structural information in the knowledge base and in the dependency parsing tree of the dialogue. To effectively leverage the structural information in dialogue history, we propose a new recurrent cell architecture which allows representation learning on graphs. To exploit the relations between entities in KBs, the model combines multi-hop reasoning ability based on the graph structure. Experimental results show that the proposed model achieves consistent improvement over state-of-the-art models on two different task-oriented dialogue datasets.","GraphDialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems End-to-end task-oriented dialogue systems aim to generate system responses directly from plain text inputs. There are two challenges for such systems: one is how to effectively incorporate external knowledge bases (KBs) into the learning framework; the other is how to accurately capture the semantics of dialogue history. In this paper, we address these two challenges by exploiting the graph structural information in the knowledge base and in the dependency parsing tree of the dialogue. To effectively leverage the structural information in dialogue history, we propose a new recurrent cell architecture which allows representation learning on graphs. To exploit the relations between entities in KBs, the model combines multi-hop reasoning ability based on the graph structure. Experimental results show that the proposed model achieves consistent improvement over state-of-the-art models on two different task-oriented dialogue datasets.","graphdialog : integrate graph knowledge end - - end task - orient dialogue system end - - end task - orient dialogue system aim generate system response directly plain text input . challenge system : effectively incorporate external knowledge basis ( kb ) learning framework ; accurately capture semantic dialogue history . paper , address challenge exploit graph structural information knowledge base dependency parsing tree dialogue . effectively leverage structural information dialogue history , propose new recurrent cell architecture allow representation learning graph . exploit relation entity kb , model combine multi - hop reasoning ability base graph structure . experimental result propose model achieve consistent improvement state - - - art model different task - orient dialogue dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 19, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Sound Natural: Content Rephrasing in Dialog Systems,"We introduce a new task of rephrasing for a more natural virtual assistant. Currently, virtual assistants work in the paradigm of intentslot tagging and the slot values are directly passed as-is to the execution engine. However, this setup fails in some scenarios such as messaging when the query given by the user needs to be changed before repeating it or sending it to another user. For example, for queries like 'ask my wife if she can pick up the kids' or 'remind me to take my pills', we need to rephrase the content to 'can you pick up the kids' and 'take your pills'. In this paper, we study the problem of rephrasing with messaging as a use case and release a dataset of 3000 pairs of original query and rephrased query. We show that BART, a pre-trained transformers-based masked language model with auto-regressive decoding, is a strong baseline for the task, and show improvements by adding a copy-pointer and copy loss to it. We analyze different tradeoffs of BART-based and LSTM-based seq2seq models, and propose a distilled LSTM-based seq2seq as the best practical model.","Sound Natural: Content Rephrasing in Dialog Systems We introduce a new task of rephrasing for a more natural virtual assistant. Currently, virtual assistants work in the paradigm of intentslot tagging and the slot values are directly passed as-is to the execution engine. However, this setup fails in some scenarios such as messaging when the query given by the user needs to be changed before repeating it or sending it to another user. For example, for queries like 'ask my wife if she can pick up the kids' or 'remind me to take my pills', we need to rephrase the content to 'can you pick up the kids' and 'take your pills'. In this paper, we study the problem of rephrasing with messaging as a use case and release a dataset of 3000 pairs of original query and rephrased query. We show that BART, a pre-trained transformers-based masked language model with auto-regressive decoding, is a strong baseline for the task, and show improvements by adding a copy-pointer and copy loss to it. We analyze different tradeoffs of BART-based and LSTM-based seq2seq models, and propose a distilled LSTM-based seq2seq as the best practical model.","sound natural : content rephrasing dialog systems introduce new task rephrase natural virtual assistant . currently , virtual assistant work paradigm intentslot tagging slot value directly pass - execution engine . , setup fail scenario message query give user need change repeat send user . example , query like ' ask wife pick kid ' ' remind pill ' , need rephrase content ' pick kid ' ' pill ' . paper , study problem rephrasing messaging use case release dataset 3000 pair original query rephrase query . bart , pre - trained transformer - base mask language model auto - regressive decoding , strong baseline task , improvement add copy - pointer copy loss . analyze different tradeoff bart - base lstm - base seq2seq model , propose distil lstm - base seq2seq good practical model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Incomplete Utterance Rewriting as Semantic Segmentation,"Recent years the task of incomplete utterance rewriting has raised a large attention. Previous works usually shape it as a machine translation task and employ sequence to sequence based architecture with copy mechanism. In this paper, we present a novel and extensive approach, which formulates it as a semantic segmentation task. Instead of generating from scratch, such a formulation introduces edit operations and shapes the problem as prediction of a word-level edit matrix. Benefiting from being able to capture both local and global information, our approach achieves state-ofthe-art performance on several public datasets. Furthermore, our approach is four times faster than the standard approach in inference.","Incomplete Utterance Rewriting as Semantic Segmentation Recent years the task of incomplete utterance rewriting has raised a large attention. Previous works usually shape it as a machine translation task and employ sequence to sequence based architecture with copy mechanism. In this paper, we present a novel and extensive approach, which formulates it as a semantic segmentation task. Instead of generating from scratch, such a formulation introduces edit operations and shapes the problem as prediction of a word-level edit matrix. Benefiting from being able to capture both local and global information, our approach achieves state-ofthe-art performance on several public datasets. Furthermore, our approach is four times faster than the standard approach in inference.","incomplete utterance rewriting semantic segmentation recent year task incomplete utterance rewriting raise large attention . previous work usually shape machine translation task employ sequence sequence base architecture copy mechanism . paper , present novel extensive approach , formulate semantic segmentation task . instead generate scratch , formulation introduce edit operation shape problem prediction word - level edit matrix . benefit able capture local global information , approach achieve state - ofthe - art performance public dataset . furthermore , approach time fast standard approach inference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Dialogue and Interactive Systems,Interview: Large-scale Modeling of Media Dialog with Discourse Patterns and Knowledge Grounding,"In this work, we perform the first large-scale analysis of discourse in media dialog and its impact on generative modeling of dialog turns, with a focus on interrogative patterns and use of external knowledge. Discourse analysis can help us understand modes of persuasion, entertainment, and information elicitation in such settings, but has been limited to manual review of small corpora. We introduce I -a large-scale (105K conversations) media dialog dataset collected from news interview transcripts-which allows us to investigate such patterns at scale. We present a dialog model that leverages external knowledge as well as dialog acts via auxiliary losses and demonstrate that our model quantitatively and qualitatively outperforms strong discourse-agnostic baselines for dialog modeling-generating more specific and topical responses in interview-style conversations.","Interview: Large-scale Modeling of Media Dialog with Discourse Patterns and Knowledge Grounding In this work, we perform the first large-scale analysis of discourse in media dialog and its impact on generative modeling of dialog turns, with a focus on interrogative patterns and use of external knowledge. Discourse analysis can help us understand modes of persuasion, entertainment, and information elicitation in such settings, but has been limited to manual review of small corpora. We introduce I -a large-scale (105K conversations) media dialog dataset collected from news interview transcripts-which allows us to investigate such patterns at scale. We present a dialog model that leverages external knowledge as well as dialog acts via auxiliary losses and demonstrate that our model quantitatively and qualitatively outperforms strong discourse-agnostic baselines for dialog modeling-generating more specific and topical responses in interview-style conversations.","interview : large - scale modeling medium dialog discourse pattern knowledge grounding work , perform large - scale analysis discourse medium dialog impact generative modeling dialog turn , focus interrogative pattern use external knowledge . discourse analysis help understand mode persuasion , entertainment , information elicitation setting , limit manual review small corpus . introduce -a large - scale ( 105 k conversation ) medium dialog dataset collect news interview transcript - allow investigate pattern scale . present dialog model leverage external knowledge dialog act auxiliary loss demonstrate model quantitatively qualitatively outperform strong discourse - agnostic baseline dialog modeling - generate specific topical response interview - style conversation .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Probing Task-Oriented Dialogue Representation from Language Models,"This paper investigates pre-trained language models to find out which model intrinsically carries the most informative representation for task-oriented dialogue tasks. We approach the problem from two aspects: supervised classifier probe and unsupervised mutual information probe. We fine-tune a feed-forward layer as the classifier probe on top of a fixed pretrained language model with annotated labels in a supervised way. Meanwhile, we propose an unsupervised mutual information probe to evaluate the mutual dependence between a real clustering and a representation clustering. The goals of this empirical paper are to 1) investigate probing techniques, especially from the unsupervised mutual information aspect, 2) provide guidelines of pre-trained language model selection for the dialogue research community, 3) find insights of pre-training factors for dialogue application that may be the key to success.","Probing Task-Oriented Dialogue Representation from Language Models This paper investigates pre-trained language models to find out which model intrinsically carries the most informative representation for task-oriented dialogue tasks. We approach the problem from two aspects: supervised classifier probe and unsupervised mutual information probe. We fine-tune a feed-forward layer as the classifier probe on top of a fixed pretrained language model with annotated labels in a supervised way. Meanwhile, we propose an unsupervised mutual information probe to evaluate the mutual dependence between a real clustering and a representation clustering. The goals of this empirical paper are to 1) investigate probing techniques, especially from the unsupervised mutual information aspect, 2) provide guidelines of pre-trained language model selection for the dialogue research community, 3) find insights of pre-training factors for dialogue application that may be the key to success.","probe task - orient dialogue representation language model paper investigate pre - trained language model find model intrinsically carry informative representation task - orient dialogue task . approach problem aspect : supervise classifier probe unsupervised mutual information probe . fine - tune feed - forward layer classifier probe fix pretrained language model annotate label supervise way . , propose unsupervised mutual information probe evaluate mutual dependence real clustering representation clustering . goal empirical paper 1 ) investigate probe technique , especially unsupervised mutual information aspect , 2 ) provide guideline pre - trained language model selection dialogue research community , 3 ) find insight pre - training factor dialogue application key success .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 8, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Cross-lingual Spoken Language Understanding with Regularized Representation Alignment,"Despite the promising results of current crosslingual models for spoken language understanding systems, they still suffer from imperfect cross-lingual representation alignments between the source and target languages, which makes the performance sub-optimal. To cope with this issue, we propose a regularization approach to further align word-level and sentence-level representations across languages without any external resource. First, we regularize the representation of user utterances based on their corresponding labels. Second, we regularize the latent variable model (Liu et al., 2019a ) by leveraging adversarial training to disentangle the latent variables. Experiments on the cross-lingual spoken language understanding task show that our model outperforms current state-of-the-art methods in both few-shot and zero-shot scenarios, and our model, trained on a few-shot setting with only 3% of the target language training data, achieves comparable performance to the supervised training with all the training data. 1","Cross-lingual Spoken Language Understanding with Regularized Representation Alignment Despite the promising results of current crosslingual models for spoken language understanding systems, they still suffer from imperfect cross-lingual representation alignments between the source and target languages, which makes the performance sub-optimal. To cope with this issue, we propose a regularization approach to further align word-level and sentence-level representations across languages without any external resource. First, we regularize the representation of user utterances based on their corresponding labels. Second, we regularize the latent variable model (Liu et al., 2019a ) by leveraging adversarial training to disentangle the latent variables. Experiments on the cross-lingual spoken language understanding task show that our model outperforms current state-of-the-art methods in both few-shot and zero-shot scenarios, and our model, trained on a few-shot setting with only 3% of the target language training data, achieves comparable performance to the supervised training with all the training data. 1","cross - lingual spoken language understanding regularize representation alignment despite promising result current crosslingual model speak language understanding system , suffer imperfect cross - lingual representation alignment source target language , make performance sub - optimal . cope issue , propose regularization approach align word - level sentence - level representation language external resource . , regularize representation user utterance base correspond label . second , regularize latent variable model ( liu et al . , 2019a ) leverage adversarial training disentangle latent variable . experiment cross - lingual speak language understanding task model outperform current state - - - art method - shot zero - shot scenario , model , train - shot setting 3 % target language training datum , achieve comparable performance supervise training training datum . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Dialogue and Interactive Systems,Learning a Simple and Effective Model for Multi-turn Response Generation with Auxiliary Tasks,"We study multi-turn response generation for open-domain dialogues. The existing state-ofthe-art addresses the problem with deep neural architectures. While these models improved response quality, their complexity also hinders the application of the models in real systems. In this work, we pursue a model that has a simple structure yet can effectively leverage conversation contexts for response generation. To this end, we propose four auxiliary tasks including word order recovery, utterance order recovery, masked word recovery, and masked utterance recovery, and optimize the objectives of these tasks together with maximizing the likelihood of generation. By this means, the auxiliary tasks that relate to context understanding can guide the learning of the generation model to achieve a better local optimum. Empirical studies with three benchmarks indicate that our model can significantly outperform state-of-the-art generation models in terms of response quality on both automatic evaluation and human judgment, and at the same time enjoys a much faster decoding process.","Learning a Simple and Effective Model for Multi-turn Response Generation with Auxiliary Tasks We study multi-turn response generation for open-domain dialogues. The existing state-ofthe-art addresses the problem with deep neural architectures. While these models improved response quality, their complexity also hinders the application of the models in real systems. In this work, we pursue a model that has a simple structure yet can effectively leverage conversation contexts for response generation. To this end, we propose four auxiliary tasks including word order recovery, utterance order recovery, masked word recovery, and masked utterance recovery, and optimize the objectives of these tasks together with maximizing the likelihood of generation. By this means, the auxiliary tasks that relate to context understanding can guide the learning of the generation model to achieve a better local optimum. Empirical studies with three benchmarks indicate that our model can significantly outperform state-of-the-art generation models in terms of response quality on both automatic evaluation and human judgment, and at the same time enjoys a much faster decoding process.","learn simple effective model multi - turn response generation auxiliary task study multi - turn response generation open - domain dialogue . exist state - ofthe - art address problem deep neural architecture . model improve response quality , complexity hinder application model real system . work , pursue model simple structure effectively leverage conversation context response generation . end , propose auxiliary task include word order recovery , utterance order recovery , mask word recovery , mask utterance recovery , optimize objective task maximize likelihood generation . means , auxiliary task relate context understanding guide learning generation model achieve well local optimum . empirical study benchmark indicate model significantly outperform state - - - art generation model term response quality automatic evaluation human judgment , time enjoy fast decoding process .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems,"Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterancelevel semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, GRADE incorporates both coarsegrained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgements. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.","GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterancelevel semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, GRADE incorporates both coarsegrained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgements. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.","grade : automatic graph - enhance coherence metric evaluate open - domain dialogue system automatically evaluate dialogue coherence challenging high - demand ability develop high - quality open - domain dialogue system . , current evaluation metric consider surface feature utterancelevel semantic , explicitly consider fine - grained topic transition dynamic dialogue flow . , consider graph structure constitute topic dialogue accurately depict underlie communication logic , natural way produce persuasive metric . capitalize topic - level dialogue graph , propose new evaluation metric grade , stand graph - enhance representations automatic dialogue evaluation . specifically , grade incorporate coarsegrained utterance - level contextualize representation fine - grained topic - level graph representation evaluate dialogue coherence . graph representation obtain reason topic - level dialogue graph enhance evidence commonsense graph , include k - hop neighbor representation hop - attention weight . experimental result grade significantly outperform state - - - art metric measure diverse dialogue model term pearson spearman correlation human judgement . , release new large - scale human evaluation benchmark facilitate future research automatic metric .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 22, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 12, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,SlotRefine: A Fast Non-Autoregressive Model for Joint Intent Detection and Slot Filling,"Slot filling and intent detection are two main tasks in spoken language understanding (SLU) system. In this paper, we propose a novel non-autoregressive model named SlotRefine for joint intent detection and slot filling. Besides, we design a novel two-pass iteration mechanism to handle the uncoordinated slots problem caused by conditional independence of non-autoregressive model. Experiments demonstrate that our model significantly outperforms previous models in slot filling task, while considerably speeding up the decoding (up to ×10.77). In-depth analyses show that 1) pretraining schemes could further enhance our model; 2) two-pass mechanism indeed remedy the uncoordinated slots.","SlotRefine: A Fast Non-Autoregressive Model for Joint Intent Detection and Slot Filling Slot filling and intent detection are two main tasks in spoken language understanding (SLU) system. In this paper, we propose a novel non-autoregressive model named SlotRefine for joint intent detection and slot filling. Besides, we design a novel two-pass iteration mechanism to handle the uncoordinated slots problem caused by conditional independence of non-autoregressive model. Experiments demonstrate that our model significantly outperforms previous models in slot filling task, while considerably speeding up the decoding (up to ×10.77). In-depth analyses show that 1) pretraining schemes could further enhance our model; 2) two-pass mechanism indeed remedy the uncoordinated slots.","slotrefine : fast non - autoregressive model joint intent detection slot filling slot filling intent detection main task speak language understanding ( slu ) system . paper , propose novel non - autoregressive model name slotrefine joint intent detection slot filling . , design novel - pass iteration mechanism handle uncoordinated slot problem cause conditional independence non - autoregressive model . experiment demonstrate model significantly outperform previous model slot filling task , considerably speed decoding ( ×10.77 ) . - depth analysis 1 ) pretraine scheme enhance model ; 2 ) - pass mechanism remedy uncoordinated slot .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Profile Consistency Identification for Open-domain Dialogue Agents,"Maintaining a consistent attribute profile is crucial for dialogue agents to naturally converse with humans. Existing studies on improving attribute consistency mainly explored how to incorporate attribute information in the responses, but few efforts have been made to identify the consistency relations between response and attribute profile. To facilitate the study of profile consistency identification, we create a large-scale human-annotated dataset with over 110K single-turn conversations and their key-value attribute profiles. Explicit relation between response and profile is manually labeled. We also propose a key-value structure information enriched BERT model to identify the profile consistency, and it gained improvements over strong baselines. Further evaluations on downstream tasks demonstrate that the profile consistency identification model is conducive for improving dialogue consistency. Gender Female Name Elena Current Location Beijing Constellation Aquarius Age Post-90s R1: I am glad you could come to Beijing. R3: I'll show you around Tsinghua University. R2: I also hope to visit Beijing one day. Query: I will go to Beijing tomorrow Entailed Contradicted","Profile Consistency Identification for Open-domain Dialogue Agents Maintaining a consistent attribute profile is crucial for dialogue agents to naturally converse with humans. Existing studies on improving attribute consistency mainly explored how to incorporate attribute information in the responses, but few efforts have been made to identify the consistency relations between response and attribute profile. To facilitate the study of profile consistency identification, we create a large-scale human-annotated dataset with over 110K single-turn conversations and their key-value attribute profiles. Explicit relation between response and profile is manually labeled. We also propose a key-value structure information enriched BERT model to identify the profile consistency, and it gained improvements over strong baselines. Further evaluations on downstream tasks demonstrate that the profile consistency identification model is conducive for improving dialogue consistency. Gender Female Name Elena Current Location Beijing Constellation Aquarius Age Post-90s R1: I am glad you could come to Beijing. R3: I'll show you around Tsinghua University. R2: I also hope to visit Beijing one day. Query: I will go to Beijing tomorrow Entailed Contradicted","profile consistency identification open - domain dialogue agent maintain consistent attribute profile crucial dialogue agent naturally converse human . exist study improve attribute consistency mainly explore incorporate attribute information response , effort identify consistency relation response attribute profile . facilitate study profile consistency identification , create large - scale human - annotate dataset 110 k single - turn conversation key - value attribute profile . explicit relation response profile manually label . propose key - value structure information enrich bert model identify profile consistency , gain improvement strong baseline . evaluation downstream task demonstrate profile consistency identification model conducive improve dialogue consistency . gender female elena current location beijing constellation aquarius age post-90s r1 : glad come beijing . r3 : tsinghua university . r2 : hope visit beijing day . query : beijing tomorrow entailed contradict","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems,"In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify the system design process of task-oriented dialogue systems and alleviate the over-dependency on annotated data. MinTL is a simple yet effective transfer learning framework, which allows us to plug-and-play pre-trained seq2seq models, and jointly learn dialogue state tracking and dialogue response generation. Unlike previous approaches, which use a copy mechanism to ""carryover"" the old dialogue states to the new one, we introduce Levenshtein belief spans (Lev), that allows efficient dialogue state tracking with a minimal generation length. We instantiate our learning framework with two pretrained backbones: T5 (Raffel et al., 2019) and BART (Lewis et al., 2019), and evaluate them on MultiWOZ. Extensive experiments demonstrate that: 1) our systems establish new state-of-the-art results on end-to-end response generation, 2) MinTL-based systems are more robust than baseline methods in the low resource setting, and they achieve competitive results with only 20% training data, and 3) Lev greatly improves the inference efficiency 1 .","MinTL: Minimalist Transfer Learning for Task-Oriented Dialogue Systems In this paper, we propose Minimalist Transfer Learning (MinTL) to simplify the system design process of task-oriented dialogue systems and alleviate the over-dependency on annotated data. MinTL is a simple yet effective transfer learning framework, which allows us to plug-and-play pre-trained seq2seq models, and jointly learn dialogue state tracking and dialogue response generation. Unlike previous approaches, which use a copy mechanism to ""carryover"" the old dialogue states to the new one, we introduce Levenshtein belief spans (Lev), that allows efficient dialogue state tracking with a minimal generation length. We instantiate our learning framework with two pretrained backbones: T5 (Raffel et al., 2019) and BART (Lewis et al., 2019), and evaluate them on MultiWOZ. Extensive experiments demonstrate that: 1) our systems establish new state-of-the-art results on end-to-end response generation, 2) MinTL-based systems are more robust than baseline methods in the low resource setting, and they achieve competitive results with only 20% training data, and 3) Lev greatly improves the inference efficiency 1 .","mintl : minimalist transfer learning task - orient dialogue system paper , propose minimalist transfer learning ( mintl ) simplify system design process task - orient dialogue system alleviate - dependency annotate datum . mintl simple effective transfer learning framework , allow plug - - play pre - trained seq2seq model , jointly learn dialogue state tracking dialogue response generation . unlike previous approach , use copy mechanism "" carryover "" old dialogue state new , introduce levenshtein belief span ( lev ) , allow efficient dialogue state tracking minimal generation length . instantiate learning framework pretrained backbone : t5 ( raffel et al . , 2019 ) bart ( lewis et al . , 2019 ) , evaluate multiwoz . extensive experiment demonstrate : 1 ) system establish new state - - - art result end - - end response generation , 2 ) mintl - base system robust baseline method low resource setting , achieve competitive result 20 % training datum , 3 ) lev greatly improve inference efficiency 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 21, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Regularizing Dialogue Generation by Imitating Implicit Scenarios,"Human dialogues are scenario-based and appropriate responses generally relate to the latent context knowledge entailed by the specific scenario. To enable responses that are more meaningful and context-specific, we propose to improve generative dialogue systems from the scenario perspective, where both dialogue history and future conversation are taken into account to implicitly reconstruct the scenario knowledge. More importantly, the conversation scenarios are further internalized using imitation learning framework, where the conventional dialogue model that has no access to future conversations is effectively regularized by transferring the scenario knowledge contained in hierarchical supervising signals from the scenario-based dialogue model, so that the future conversation is not required in actual inference. Extensive evaluations show that our approach significantly outperforms state-of-theart baselines on diversity and relevance, and expresses scenario-specific knowledge.","Regularizing Dialogue Generation by Imitating Implicit Scenarios Human dialogues are scenario-based and appropriate responses generally relate to the latent context knowledge entailed by the specific scenario. To enable responses that are more meaningful and context-specific, we propose to improve generative dialogue systems from the scenario perspective, where both dialogue history and future conversation are taken into account to implicitly reconstruct the scenario knowledge. More importantly, the conversation scenarios are further internalized using imitation learning framework, where the conventional dialogue model that has no access to future conversations is effectively regularized by transferring the scenario knowledge contained in hierarchical supervising signals from the scenario-based dialogue model, so that the future conversation is not required in actual inference. Extensive evaluations show that our approach significantly outperforms state-of-theart baselines on diversity and relevance, and expresses scenario-specific knowledge.","regularize dialogue generation imitate implicit scenario human dialogue scenario - base appropriate response generally relate latent context knowledge entail specific scenario . enable response meaningful context - specific , propose improve generative dialogue system scenario perspective , dialogue history future conversation take account implicitly reconstruct scenario knowledge . importantly , conversation scenario internalize imitation learning framework , conventional dialogue model access future conversation effectively regularize transfer scenario knowledge contain hierarchical supervise signal scenario - base dialogue model , future conversation require actual inference . extensive evaluation approach significantly outperform state - - theart baseline diversity relevance , express scenario - specific knowledge .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 19, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference,"Intent detection is one of the core components of goal-oriented dialog systems, and detecting out-of-scope (OOS) intents is also a practically important skill. Few-shot learning is attracting much attention to mitigate data scarcity, but OOS detection becomes even more challenging. In this paper, we present a simple yet effective approach, discriminative nearest neighbor classification with deep self-attention. Unlike softmax classifiers, we leverage BERTstyle pairwise encoding to train a binary classifier that estimates the best matched training example for a user input. We propose to boost the discriminative ability by transferring a natural language inference (NLI) model. Our extensive experiments on a large-scale multi-domain intent detection task show that our method achieves more stable and accurate in-domain and OOS detection accuracy than RoBERTa-based classifiers and embeddingbased nearest neighbor approaches. More notably, the NLI transfer enables our 10-shot model to perform competitively with 50-shot or even full-shot classifiers, while we can keep the inference time constant by leveraging a faster embedding retrieval model.","Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference Intent detection is one of the core components of goal-oriented dialog systems, and detecting out-of-scope (OOS) intents is also a practically important skill. Few-shot learning is attracting much attention to mitigate data scarcity, but OOS detection becomes even more challenging. In this paper, we present a simple yet effective approach, discriminative nearest neighbor classification with deep self-attention. Unlike softmax classifiers, we leverage BERTstyle pairwise encoding to train a binary classifier that estimates the best matched training example for a user input. We propose to boost the discriminative ability by transferring a natural language inference (NLI) model. Our extensive experiments on a large-scale multi-domain intent detection task show that our method achieves more stable and accurate in-domain and OOS detection accuracy than RoBERTa-based classifiers and embeddingbased nearest neighbor approaches. More notably, the NLI transfer enables our 10-shot model to perform competitively with 50-shot or even full-shot classifiers, while we can keep the inference time constant by leveraging a faster embedding retrieval model.","discriminative near neighbor - shot intent detection transfer natural language inference intent detection core component goal - orient dialog system , detect - - scope ( oos ) intent practically important skill . - shot learning attract attention mitigate datum scarcity , oos detection challenging . paper , present simple effective approach , discriminative near neighbor classification deep self - attention . unlike softmax classifier , leverage bertstyle pairwise encoding train binary classifier estimate well match training example user input . propose boost discriminative ability transfer natural language inference ( nli ) model . extensive experiment large - scale multi - domain intent detection task method achieve stable accurate - domain oos detection accuracy roberta - base classifier embeddingbase near neighbor approach . notably , nli transfer enable 10 - shot model perform competitively 50 - shot - shot classifier , inference time constant leverage fast embedding retrieval model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Dialogue and Interactive Systems,SLURP: A Spoken Language Understanding Resource Package,"Spoken Language Understanding infers semantic meaning directly from audio data, and thus promises to reduce error propagation and misunderstandings in end-user applications. However, publicly available SLU resources are limited. In this paper, we release SLURP, a new SLU package containing the following: (1) A new challenging dataset in English spanning 18 domains, which is substantially bigger and linguistically more diverse than existing datasets; (2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A new transparent metric for entity labelling which enables a detailed error analysis for identifying potential areas of improvement. SLURP is available at https: //github.com/pswietojanski/slurp","SLURP: A Spoken Language Understanding Resource Package Spoken Language Understanding infers semantic meaning directly from audio data, and thus promises to reduce error propagation and misunderstandings in end-user applications. However, publicly available SLU resources are limited. In this paper, we release SLURP, a new SLU package containing the following: (1) A new challenging dataset in English spanning 18 domains, which is substantially bigger and linguistically more diverse than existing datasets; (2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A new transparent metric for entity labelling which enables a detailed error analysis for identifying potential areas of improvement. SLURP is available at https: //github.com/pswietojanski/slurp","slurp : spoken language understanding resource package spoken language understanding infer semantic meaning directly audio datum , promise reduce error propagation misunderstanding end - user application . , publicly available slu resource limited . paper , release slurp , new slu package contain follow : ( 1 ) new challenging dataset english span 18 domain , substantially big linguistically diverse exist dataset ; ( 2 ) competitive baseline base state - - - art nlu asr system ; ( 3 ) new transparent metric entity labelling enable detailed error analysis identify potential area improvement . slurp available https : //github.com / pswietojanski / slurp","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,False
Dialogue and Interactive Systems,Counterfactual Off-Policy Training for Neural Dialogue Generation,"Open-domain dialogue generation suffers from the data insufficiency problem due to the vast size of potential responses. In this paper, we propose to explore potential responses by counterfactual reasoning. Given an observed response, the counterfactual reasoning model automatically infers the outcome of an alternative policy that could have been taken. The resulting counterfactual response synthesized in hindsight is of higher quality than the response synthesized from scratch. Training on the counterfactual responses under the adversarial learning framework helps to explore the high-reward area of the potential response space. An empirical study on the DailyDialog dataset shows that our approach significantly outperforms the HRED model as well as the conventional adversarial learning approaches.","Counterfactual Off-Policy Training for Neural Dialogue Generation Open-domain dialogue generation suffers from the data insufficiency problem due to the vast size of potential responses. In this paper, we propose to explore potential responses by counterfactual reasoning. Given an observed response, the counterfactual reasoning model automatically infers the outcome of an alternative policy that could have been taken. The resulting counterfactual response synthesized in hindsight is of higher quality than the response synthesized from scratch. Training on the counterfactual responses under the adversarial learning framework helps to explore the high-reward area of the potential response space. An empirical study on the DailyDialog dataset shows that our approach significantly outperforms the HRED model as well as the conventional adversarial learning approaches.","counterfactual - policy training neural dialogue generation open - domain dialogue generation suffer datum insufficiency problem vast size potential response . paper , propose explore potential response counterfactual reasoning . give observed response , counterfactual reasoning model automatically infer outcome alternative policy take . result counterfactual response synthesize hindsight high quality response synthesize scratch . training counterfactual response adversarial learning framework help explore high - reward area potential response space . empirical study dailydialog dataset show approach significantly outperform hred model conventional adversarial learning approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 12, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,MovieChats: Chat like Humans in a Closed Domain,"Being able to perform in-depth chat with humans in a closed domain is a precondition before an open-domain chatbot can ever be claimed. In this work, we take a close look at the movie domain and present a large-scale high-quality corpus with fine-grained annotations in hope of pushing the limit of moviedomain chatbots. We propose a unified, readily scalable neural approach which reconciles all subtasks like intent prediction and knowledge retrieval. The model is first pretrained on the huge general-domain data, then finetuned on our corpus. We show this simple neural approach trained on high-quality data is able to outperform commercial systems replying on complex rules. On both the static and interactive tests, we find responses generated by our system exhibits remarkably good engagement and sensibleness close to human-written ones. We further analyze the limits of our work and point out potential directions for future work 1 . * Corresponding Authors. Work done before Xiaoyu Shen joins Amazon. † Work done while interning at Wechat. 1 Dataset and model are available at https://github. com/chin-gyou/MovieChats. 我刚看完《海上钢琴师》，感觉⼼灵很震撼 I just finished watching ""The Legend of 1900"" and feel shocked DA: Inform_fact, Inform_feeling Aspects: Name Mov_Tracker: The Legend of 1900 真的吗，这是部什么电影 Really, what kind of movie is this DA: Request_fact Aspects: Type Mov_Tracker: The Legend of 1900 ⼀部意⼤利拍的英语电影，讲⼀位天才钢琴师⼀辈⼦都住轮船上 An English film made in Italy, where a talented pianist lived on the ship all his life DA: Inform_fact Aspects: Region, Language, Plot Mov_Tracker: The Legend of 1900 这么离奇的故事，为什么他不离开那艘船呢 Such a bizarre story, why didn't he leave that boat? DA: Inform_feeling, Request_fact Aspect: Plot Mov_Tracker: The Legend of 1900 他把这⾥当成了他的精神家园，所以船要被炸掉他都不肯离开 He regarded this as his spiritual home, so when the last ship was about to be blown up, he refused to leave DA: Inform_feeling, Inform_fact Aspects: Plot Mov_Tracker: The Legend of 1900 就像阿⽢正传⼀样。现代社会很少有⼈能和世俗割裂去追求⾃⼰的精神世界 Just like in Forrest Gump. Few people in modern society can separate themselves from the world to pursue their own spiritual world DA: Inform_feeling Aspects: Name Mov_Tracker: Forrest Gump Name: The Legend of 1900 | Comment: One of the favorite movies that shocked my soul. Region: Italy | Language: English | Plot: ""a talented pianist lived on the ship all his life"" Plot: ""why didn't he leave that boat"" Plot: ""when the last ship was about to be blown up, he refused to leave"" Comment: What he cannot leave is not the boat, but the spiritual home that nurtured him.","MovieChats: Chat like Humans in a Closed Domain Being able to perform in-depth chat with humans in a closed domain is a precondition before an open-domain chatbot can ever be claimed. In this work, we take a close look at the movie domain and present a large-scale high-quality corpus with fine-grained annotations in hope of pushing the limit of moviedomain chatbots. We propose a unified, readily scalable neural approach which reconciles all subtasks like intent prediction and knowledge retrieval. The model is first pretrained on the huge general-domain data, then finetuned on our corpus. We show this simple neural approach trained on high-quality data is able to outperform commercial systems replying on complex rules. On both the static and interactive tests, we find responses generated by our system exhibits remarkably good engagement and sensibleness close to human-written ones. We further analyze the limits of our work and point out potential directions for future work 1 . * Corresponding Authors. Work done before Xiaoyu Shen joins Amazon. † Work done while interning at Wechat. 1 Dataset and model are available at https://github. com/chin-gyou/MovieChats. 我刚看完《海上钢琴师》，感觉⼼灵很震撼 I just finished watching ""The Legend of 1900"" and feel shocked DA: Inform_fact, Inform_feeling Aspects: Name Mov_Tracker: The Legend of 1900 真的吗，这是部什么电影 Really, what kind of movie is this DA: Request_fact Aspects: Type Mov_Tracker: The Legend of 1900 ⼀部意⼤利拍的英语电影，讲⼀位天才钢琴师⼀辈⼦都住轮船上 An English film made in Italy, where a talented pianist lived on the ship all his life DA: Inform_fact Aspects: Region, Language, Plot Mov_Tracker: The Legend of 1900 这么离奇的故事，为什么他不离开那艘船呢 Such a bizarre story, why didn't he leave that boat? DA: Inform_feeling, Request_fact Aspect: Plot Mov_Tracker: The Legend of 1900 他把这⾥当成了他的精神家园，所以船要被炸掉他都不肯离开 He regarded this as his spiritual home, so when the last ship was about to be blown up, he refused to leave DA: Inform_feeling, Inform_fact Aspects: Plot Mov_Tracker: The Legend of 1900 就像阿⽢正传⼀样。现代社会很少有⼈能和世俗割裂去追求⾃⼰的精神世界 Just like in Forrest Gump. Few people in modern society can separate themselves from the world to pursue their own spiritual world DA: Inform_feeling Aspects: Name Mov_Tracker: Forrest Gump Name: The Legend of 1900 | Comment: One of the favorite movies that shocked my soul. Region: Italy | Language: English | Plot: ""a talented pianist lived on the ship all his life"" Plot: ""why didn't he leave that boat"" Plot: ""when the last ship was about to be blown up, he refused to leave"" Comment: What he cannot leave is not the boat, but the spiritual home that nurtured him.","moviechats : chat like human closed domain able perform - depth chat human closed domain precondition open - domain chatbot claim . work , close look movie domain present large - scale high - quality corpus fine - grained annotation hope push limit moviedomain chatbot . propose unified , readily scalable neural approach reconcile subtask like intent prediction knowledge retrieval . model pretraine huge general - domain datum , finetune corpus . simple neural approach train high - quality datum able outperform commercial system reply complex rule . static interactive test , find response generate system exhibit remarkably good engagement sensibleness close human - write one . analyze limit work point potential direction future work 1 . * correspond author . work xiaoyu shen join amazon . † work intern wechat . 1 dataset model available https://github . com / chin - gyou / moviechats . 我刚看完《海上钢琴师》，感觉 ⼼ 灵很震撼 finish watch "" legend 1900 "" feel shocked da : inform_fact , inform_feeling aspects : mov_tracker : legend 1900 真的吗，这是部什么电影 , kind movie da : request_fact aspects : type mov_tracker : legend 1900 ⼀ 部意 ⼤ 利拍的英语电影，讲 ⼀ 位天才钢琴师 ⼀ 辈 ⼦ 都住轮船上 english film italy , talented pianist live ship life da : inform_fact aspects : region , language , plot mov_tracker : legend 1900 这么离奇的故事，为什么他不离开那艘船呢 bizarre story , leave boat ? da : inform_feeling , request_fact aspect : plot mov_tracker : legend 1900 他把这 ⾥ 当成了他的精神家园，所以船要被炸掉他都不肯离开 regard spiritual home , ship blow , refuse leave da : inform_feeling , inform_fact aspects : plot mov_tracker : legend 1900 就像阿 ⽢ 正传 ⼀ 样。现代社会很少有 ⼈ 能和世俗割裂去追求 ⾃ ⼰ 的精神世界 like forrest gump . people modern society separate world pursue spiritual world da : inform_feeling aspect : mov_tracker : forrest gump : legend 1900 | comment : favorite movie shock soul . region : italy | language : english | plot : "" talented pianist live ship life "" plot : "" leave boat "" plot : "" ship blow , refuse leave "" comment : leave boat , spiritual home nurture .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 7, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Dialogue and Interactive Systems,Neural Conversational QA: Learning to Reason vs Exploiting Patterns,"Neural Conversational QA tasks like ShARC require systems to answer questions based on the contents of a given passage. On studying recent state-of-the-art models on the ShARC QA task, we found indications that the models learn spurious clues/patterns in the dataset. Furthermore, we show that a heuristic-based program designed to exploit these patterns can have performance comparable to that of the neural models. In this paper we share our findings about four types of patterns found in the ShARC corpus and describe how neural models exploit them. Motivated by the aforementioned findings, we create and share a modified dataset that has fewer spurious patterns, consequently allowing models to learn better.","Neural Conversational QA: Learning to Reason vs Exploiting Patterns Neural Conversational QA tasks like ShARC require systems to answer questions based on the contents of a given passage. On studying recent state-of-the-art models on the ShARC QA task, we found indications that the models learn spurious clues/patterns in the dataset. Furthermore, we show that a heuristic-based program designed to exploit these patterns can have performance comparable to that of the neural models. In this paper we share our findings about four types of patterns found in the ShARC corpus and describe how neural models exploit them. Motivated by the aforementioned findings, we create and share a modified dataset that has fewer spurious patterns, consequently allowing models to learn better.","neural conversational qa : learn reason vs exploit pattern neural conversational qa task like sharc require system answer question base content give passage . study recent state - - - art model sharc qa task , find indication model learn spurious clue / pattern dataset . furthermore , heuristic - base program design exploit pattern performance comparable neural model . paper share finding type pattern find sharc corpus describe neural model exploit . motivate aforementioned finding , create share modify dataset few spurious pattern , consequently allow model learn well .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Dialogue and Interactive Systems,Dialogue Response Ranking Training with Large-Scale Human Feedback Data,"Existing open-domain dialog models are generally trained to minimize the perplexity of target human responses. However, some human replies are more engaging than others, spawning more followup interactions. Current conversational models are increasingly capable of producing turns that are context-relevant, but in order to produce compelling agents, these models need to be able to predict and optimize for turns that are genuinely engaging. We leverage social media feedback data (number of replies and upvotes) to build a large-scale training dataset for feedback prediction. To alleviate possible distortion between the feedback and engagingness, we convert the ranking problem to a comparison of response pairs which involve few confounding factors. We trained DIALOGRPT, a set of GPT-2 based models on 133M pairs of human feedback data and the resulting ranker outperformed several baselines. Particularly, our ranker outperforms the conventional dialog perplexity baseline with a large margin on predicting Reddit feedback. We finally combine the feedback prediction models and a human-like scoring model to rank the machine-generated dialog responses. Crowd-sourced human evaluation shows that our ranking method correlates better with real human preferences than baseline models. 1","Dialogue Response Ranking Training with Large-Scale Human Feedback Data Existing open-domain dialog models are generally trained to minimize the perplexity of target human responses. However, some human replies are more engaging than others, spawning more followup interactions. Current conversational models are increasingly capable of producing turns that are context-relevant, but in order to produce compelling agents, these models need to be able to predict and optimize for turns that are genuinely engaging. We leverage social media feedback data (number of replies and upvotes) to build a large-scale training dataset for feedback prediction. To alleviate possible distortion between the feedback and engagingness, we convert the ranking problem to a comparison of response pairs which involve few confounding factors. We trained DIALOGRPT, a set of GPT-2 based models on 133M pairs of human feedback data and the resulting ranker outperformed several baselines. Particularly, our ranker outperforms the conventional dialog perplexity baseline with a large margin on predicting Reddit feedback. We finally combine the feedback prediction models and a human-like scoring model to rank the machine-generated dialog responses. Crowd-sourced human evaluation shows that our ranking method correlates better with real human preferences than baseline models. 1","dialogue response ranking training large - scale human feedback datum exist open - domain dialog model generally train minimize perplexity target human response . , human reply engaging , spawn followup interaction . current conversational model increasingly capable produce turn context - relevant , order produce compelling agent , model need able predict optimize turn genuinely engaging . leverage social medium feedback datum ( number reply upvote ) build large - scale training dataset feedback prediction . alleviate possible distortion feedback engagingness , convert ranking problem comparison response pair involve confound factor . train dialogrpt , set gpt-2 base model 133 m pair human feedback datum result ranker outperform baseline . particularly , ranker outperform conventional dialog perplexity baseline large margin predict reddit feedback . finally combine feedback prediction model human - like scoring model rank machine - generate dialog response . crowd - source human evaluation show ranking method correlate well real human preference baseline model . 1","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Conversational Semantic Parsing,"The structured representation for semantic parsing in task-oriented assistant systems is geared towards simple understanding of one-turn queries. Due to the limitations of the representation, the session-based properties such as coreference resolution and context carryover are processed downstream in a pipelined system. In this paper, we propose a semantic representation for such task-oriented conversational systems that can represent concepts such as co-reference and context carryover, enabling comprehensive understanding of queries in a session. We release a new session-based, compositional taskoriented parsing dataset of 20k sessions consisting of 60k utterances. Unlike Dialog State Tracking Challenges, the queries in the dataset have compositional forms. We propose a new family of Seq2Seq models for the session-based parsing above, which achieve better or comparable performance to the current state-of-the-art on ATIS, SNIPS, TOP and DSTC2. Notably, we improve the best known results on DSTC2 by up to 5 points for slot-carryover.","Conversational Semantic Parsing The structured representation for semantic parsing in task-oriented assistant systems is geared towards simple understanding of one-turn queries. Due to the limitations of the representation, the session-based properties such as coreference resolution and context carryover are processed downstream in a pipelined system. In this paper, we propose a semantic representation for such task-oriented conversational systems that can represent concepts such as co-reference and context carryover, enabling comprehensive understanding of queries in a session. We release a new session-based, compositional taskoriented parsing dataset of 20k sessions consisting of 60k utterances. Unlike Dialog State Tracking Challenges, the queries in the dataset have compositional forms. We propose a new family of Seq2Seq models for the session-based parsing above, which achieve better or comparable performance to the current state-of-the-art on ATIS, SNIPS, TOP and DSTC2. Notably, we improve the best known results on DSTC2 by up to 5 points for slot-carryover.","conversational semantic parsing structure representation semantic parsing task - orient assistant system gear simple understanding - turn query . limitation representation , session - base property coreference resolution context carryover process downstream pipelined system . paper , propose semantic representation task - orient conversational system represent concept co - reference context carryover , enable comprehensive understanding query session . release new session - base , compositional taskoriented parsing dataset 20k session consist 60k utterance . unlike dialog state tracking challenges , query dataset compositional form . propose new family seq2seq model session - base parsing , achieve well comparable performance current state - - - art atis , snips , dstc2 . notably , improve well know result dstc2 5 point slot - carryover .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 3, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Improving Out-of-Scope Detection in Intent Classification by Using Embeddings of the Word Graph Space of the Classes,"This paper explores how intent classification can be improved by representing the class labels not as a discrete set of symbols but as a space where the word graphs associated to each class are mapped using typical graph embedding techniques. The approach, inspired by a previous algorithm used for an inverse dictionary task, allows the classification algorithm to take in account inter-class similarities provided by the repeated occurrence of some words in the training examples of the different classes. The classification is carried out by mapping text embeddings to the word graph embeddings of the classes. Focusing solely on improving the representation of the class label set, we show in experiments conducted in both private and public intent classification datasets, that better detection of out-of-scope examples (OOS) is achieved and, as a consequence, that the overall accuracy of intent classification is also improved. In particular, using the recently-released Larson dataset, an error of about 9.9% has been achieved for OOS detection, beating the previous state-of-the-art result by more than 31 percentage points.","Improving Out-of-Scope Detection in Intent Classification by Using Embeddings of the Word Graph Space of the Classes This paper explores how intent classification can be improved by representing the class labels not as a discrete set of symbols but as a space where the word graphs associated to each class are mapped using typical graph embedding techniques. The approach, inspired by a previous algorithm used for an inverse dictionary task, allows the classification algorithm to take in account inter-class similarities provided by the repeated occurrence of some words in the training examples of the different classes. The classification is carried out by mapping text embeddings to the word graph embeddings of the classes. Focusing solely on improving the representation of the class label set, we show in experiments conducted in both private and public intent classification datasets, that better detection of out-of-scope examples (OOS) is achieved and, as a consequence, that the overall accuracy of intent classification is also improved. In particular, using the recently-released Larson dataset, an error of about 9.9% has been achieved for OOS detection, beating the previous state-of-the-art result by more than 31 percentage points.","improve - - scope detection intent classification embedding word graph space class paper explore intent classification improve represent class label discrete set symbol space word graph associate class map typical graph embedding technique . approach , inspire previous algorithm inverse dictionary task , allow classification algorithm account inter - class similarity provide repeat occurrence word training example different class . classification carry map text embedding word graph embedding class . focus solely improve representation class label set , experiment conduct private public intent classification dataset , well detection - - scope example ( oos ) achieve , consequence , overall accuracy intent classification improve . particular , recently - release larson dataset , error 9.9 % achieve oos detection , beat previous state - - - art result 31 percentage point .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 16, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Dialogue and Interactive Systems,doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset,"We introduce doc2dial, a new dataset of goal-oriented dialogues that are grounded in the associated documents. Inspired by how the authors compose documents for guiding end users, we first construct dialogue flows based on the content elements that corresponds to higher-level relations across text sections as well as lower-level relations between discourse units within a section. Then we present these dialogue flows to crowd contributors to create conversational utterances. The dataset includes over 4500 annotated conversations with an average of 14 turns that are grounded in over 450 documents from four domains. Compared to the prior document-grounded dialogue datasets, this dataset covers a variety of dialogue scenes in information-seeking conversations. For evaluating the versatility of the dataset, we introduce multiple dialogue modeling tasks and present baseline approaches. A9: Would you like to find out whether you are eligible? U10: That's exactly why I contact again! A11: Were there any damages to your clothes that were caused by prosthetic or orthopedic device or your skin medicine? U12: The latter happened.","doc2dial: A Goal-Oriented Document-Grounded Dialogue Dataset We introduce doc2dial, a new dataset of goal-oriented dialogues that are grounded in the associated documents. Inspired by how the authors compose documents for guiding end users, we first construct dialogue flows based on the content elements that corresponds to higher-level relations across text sections as well as lower-level relations between discourse units within a section. Then we present these dialogue flows to crowd contributors to create conversational utterances. The dataset includes over 4500 annotated conversations with an average of 14 turns that are grounded in over 450 documents from four domains. Compared to the prior document-grounded dialogue datasets, this dataset covers a variety of dialogue scenes in information-seeking conversations. For evaluating the versatility of the dataset, we introduce multiple dialogue modeling tasks and present baseline approaches. A9: Would you like to find out whether you are eligible? U10: That's exactly why I contact again! A11: Were there any damages to your clothes that were caused by prosthetic or orthopedic device or your skin medicine? U12: The latter happened.","doc2dial : goal - orient document - ground dialogue dataset introduce doc2dial , new dataset goal - orient dialogue ground associate document . inspire author compose document guide end user , construct dialogue flow base content element correspond high - level relation text section low - level relation discourse unit section . present dialogue flow crowd contributor create conversational utterance . dataset include 4500 annotate conversation average 14 turn ground 450 document domain . compare prior document - ground dialogue dataset , dataset cover variety dialogue scene information - seek conversation . evaluate versatility dataset , introduce multiple dialogue modeling task present baseline approach . a9 : like find eligible ? u10 : exactly contact ! a11 : damage clothe cause prosthetic orthopedic device skin medicine ? u12 : happen .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 20, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Knowledge-Grounded Dialogue Generation with Pre-trained Language Models,"We study knowledge-grounded dialogue generation with pre-trained language models. To leverage the redundant external knowledge under capacity constraint, we propose equipping response generation defined by a pretrained language model with a knowledge selection module, and an unsupervised approach to jointly optimizing knowledge selection and response generation with unlabeled dialogues. Empirical results on two benchmarks indicate that our model can significantly outperform state-of-the-art methods in both automatic evaluation and human judgment.","Knowledge-Grounded Dialogue Generation with Pre-trained Language Models We study knowledge-grounded dialogue generation with pre-trained language models. To leverage the redundant external knowledge under capacity constraint, we propose equipping response generation defined by a pretrained language model with a knowledge selection module, and an unsupervised approach to jointly optimizing knowledge selection and response generation with unlabeled dialogues. Empirical results on two benchmarks indicate that our model can significantly outperform state-of-the-art methods in both automatic evaluation and human judgment.","knowledge - ground dialogue generation pre - trained language model study knowledge - ground dialogue generation pre - trained language model . leverage redundant external knowledge capacity constraint , propose equip response generation define pretrained language model knowledge selection module , unsupervised approach jointly optimize knowledge selection response generation unlabeled dialogue . empirical result benchmark indicate model significantly outperform state - - - art method automatic evaluation human judgment .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired Data,"Recent advances in open-domain dialogue systems rely on the success of neural models that are trained on large-scale data. However, collecting large-scale dialogue data is usually time-consuming and labor-intensive. To address this data dilemma, we propose a novel data augmentation method for training opendomain dialogue models by utilizing unpaired data. Specifically, a data-level distillation process is first proposed to construct augmented dialogues where both post and response are retrieved from the unpaired data. A ranking module is employed to filter out low-quality dialogues. Further, a model-level distillation process is employed to distill a teacher model trained on high-quality paired data to augmented dialogue pairs, thereby preventing dialogue models from being affected by the noise in the augmented data. Automatic and manual evaluation indicates that our method can produce high-quality dialogue pairs with diverse contents, and the proposed data-level and model-level dialogue distillation can improve the performance of competitive baselines.","Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired Data Recent advances in open-domain dialogue systems rely on the success of neural models that are trained on large-scale data. However, collecting large-scale dialogue data is usually time-consuming and labor-intensive. To address this data dilemma, we propose a novel data augmentation method for training opendomain dialogue models by utilizing unpaired data. Specifically, a data-level distillation process is first proposed to construct augmented dialogues where both post and response are retrieved from the unpaired data. A ranking module is employed to filter out low-quality dialogues. Further, a model-level distillation process is employed to distill a teacher model trained on high-quality paired data to augmented dialogue pairs, thereby preventing dialogue models from being affected by the noise in the augmented data. Automatic and manual evaluation indicates that our method can produce high-quality dialogue pairs with diverse contents, and the proposed data-level and model-level dialogue distillation can improve the performance of competitive baselines.","dialogue distillation : open - domain dialogue augmentation unpaired datum recent advance open - domain dialogue system rely success neural model train large - scale datum . , collect large - scale dialogue datum usually time - consume labor - intensive . address datum dilemma , propose novel data augmentation method train opendomain dialogue model utilize unpaired datum . specifically , data - level distillation process propose construct augment dialogue post response retrieve unpaired datum . ranking module employ filter low - quality dialogue . , model - level distillation process employ distill teacher model train high - quality pair datum augment dialogue pair , prevent dialogue model affect noise augment datum . automatic manual evaluation indicate method produce high - quality dialogue pair diverse content , propose data - level model - level dialogue distillation improve performance competitive baseline .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 24, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue,"The underlying difference of linguistic patterns between general text and task-oriented dialogue makes existing pre-trained language models less useful in practice. In this work, we unify nine human-human and multi-turn task-oriented dialogue datasets for language modeling. To better model dialogue behavior during pre-training, we incorporate user and system tokens into the masked language modeling. We propose a contrastive objective function to simulate the response selection task. Our pre-trained task-oriented dialogue BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream taskoriented dialogue applications, including intention recognition, dialogue state tracking, dialogue act prediction, and response selection. We also show that TOD-BERT has a stronger few-shot ability that can mitigate the data scarcity problem for task-oriented dialogue.","TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue The underlying difference of linguistic patterns between general text and task-oriented dialogue makes existing pre-trained language models less useful in practice. In this work, we unify nine human-human and multi-turn task-oriented dialogue datasets for language modeling. To better model dialogue behavior during pre-training, we incorporate user and system tokens into the masked language modeling. We propose a contrastive objective function to simulate the response selection task. Our pre-trained task-oriented dialogue BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream taskoriented dialogue applications, including intention recognition, dialogue state tracking, dialogue act prediction, and response selection. We also show that TOD-BERT has a stronger few-shot ability that can mitigate the data scarcity problem for task-oriented dialogue.","tod - bert : pre - train natural language understanding task - orient dialogue underlie difference linguistic pattern general text task - orient dialogue make exist pre - trained language model useful practice . work , unify human - human multi - turn task - orient dialogue dataset language modeling . well model dialogue behavior pre - training , incorporate user system token mask language modeling . propose contrastive objective function simulate response selection task . pre - trained task - orient dialogue bert ( tod - bert ) outperform strong baseline like bert downstream taskoriente dialogue application , include intention recognition , dialogue state tracking , dialogue act prediction , response selection . tod - bert strong - shot ability mitigate data scarcity problem task - orient dialogue .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 28, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning,"Structured belief states are crucial for user goal tracking and database query in task-oriented dialog systems. However, training belief trackers often requires expensive turn-level annotations of every user utterance. In this paper we aim at alleviating the reliance on belief state labels in building end-to-end dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. We propose a probabilistic dialog model, called the LAtent BElief State (LABES) model, where belief states are represented as discrete latent variables and jointly modeled with system responses given user inputs. Such latent variable modeling enables us to develop semi-supervised learning under the principled variational learning framework. Furthermore, we introduce LABES-S2S, which is a copyaugmented Seq2Seq model instantiation of LABES 1 . In supervised experiments, LABES-S2S obtains strong results on three benchmark datasets of different scales. In utilizing unlabeled dialog data, semi-supervised LABES-S2S significantly outperforms both supervisedonly and semi-supervised baselines. Remarkably, we can reduce the annotation demands to 50% without performance loss on MultiWOZ.","A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning Structured belief states are crucial for user goal tracking and database query in task-oriented dialog systems. However, training belief trackers often requires expensive turn-level annotations of every user utterance. In this paper we aim at alleviating the reliance on belief state labels in building end-to-end dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. We propose a probabilistic dialog model, called the LAtent BElief State (LABES) model, where belief states are represented as discrete latent variables and jointly modeled with system responses given user inputs. Such latent variable modeling enables us to develop semi-supervised learning under the principled variational learning framework. Furthermore, we introduce LABES-S2S, which is a copyaugmented Seq2Seq model instantiation of LABES 1 . In supervised experiments, LABES-S2S obtains strong results on three benchmark datasets of different scales. In utilizing unlabeled dialog data, semi-supervised LABES-S2S significantly outperforms both supervisedonly and semi-supervised baselines. Remarkably, we can reduce the annotation demands to 50% without performance loss on MultiWOZ.","probabilistic end - - end task - orient dialog model latent belief state semi - supervised learning structured belief state crucial user goal tracking database query task - orient dialog system . , train belief tracker require expensive turn - level annotation user utterance . paper aim alleviate reliance belief state label build end - - end dialog system , leverage unlabeled dialog datum semi - supervised learning . propose probabilistic dialog model , call latent belief state ( labes ) model , belief state represent discrete latent variable jointly model system response give user input . latent variable modeling enable develop semi - supervised learning principled variational learning framework . furthermore , introduce labes - s2s , copyaugmented seq2seq model instantiation labes 1 . supervised experiment , labes - s2s obtain strong result benchmark dataset different scale . utilize unlabeled dialog datum , semi - supervised labes - s2s significantly outperform supervisedonly semi - supervised baseline . remarkably , reduce annotation demand 50 % performance loss multiwoz .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues,"Video-grounded dialogues are very challenging due to (i) the complexity of videos which contain both spatial and temporal variations, and (ii) the complexity of user utterances which query different segments and/or different objects in videos over multiple dialogue turns. However, existing approaches to video-grounded dialogues often focus on superficial temporal-level visual cues, but neglect more fine-grained spatial signals from videos. To address this drawback, we propose Bi-directional Spatio-Temporal Learning (BiST), a vision-language neural framework for high-resolution queries in videos based on textual cues. Specifically, our approach not only exploits both spatial and temporal-level information, but also learns dynamic information diffusion between the two feature spaces through spatial-to-temporal and temporal-tospatial reasoning. The bidirectional strategy aims to tackle the evolving semantics of user queries in the dialogue setting. The retrieved visual cues are used as contextual information to construct relevant responses to the users. Our empirical results and comprehensive qualitative analysis show that BiST achieves competitive performance and generates reasonable responses on a large-scale AVSD benchmark. We also adapt our BiST models to the Video QA setting, and substantially outperform prior approaches on the TGIF-QA benchmark.","BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues Video-grounded dialogues are very challenging due to (i) the complexity of videos which contain both spatial and temporal variations, and (ii) the complexity of user utterances which query different segments and/or different objects in videos over multiple dialogue turns. However, existing approaches to video-grounded dialogues often focus on superficial temporal-level visual cues, but neglect more fine-grained spatial signals from videos. To address this drawback, we propose Bi-directional Spatio-Temporal Learning (BiST), a vision-language neural framework for high-resolution queries in videos based on textual cues. Specifically, our approach not only exploits both spatial and temporal-level information, but also learns dynamic information diffusion between the two feature spaces through spatial-to-temporal and temporal-tospatial reasoning. The bidirectional strategy aims to tackle the evolving semantics of user queries in the dialogue setting. The retrieved visual cues are used as contextual information to construct relevant responses to the users. Our empirical results and comprehensive qualitative analysis show that BiST achieves competitive performance and generates reasonable responses on a large-scale AVSD benchmark. We also adapt our BiST models to the Video QA setting, and substantially outperform prior approaches on the TGIF-QA benchmark.","bist : bi - directional spatio - temporal reasoning video - ground dialogue video - ground dialogue challenging ( ) complexity video contain spatial temporal variation , ( ii ) complexity user utterance query different segment and/or different object video multiple dialogue turn . , exist approach video - ground dialogue focus superficial temporal - level visual cue , neglect fine - grained spatial signal video . address drawback , propose bi - directional spatio - temporal learning ( bist ) , vision - language neural framework high - resolution query video base textual cue . specifically , approach exploit spatial temporal - level information , learn dynamic information diffusion feature space spatial - - temporal temporal - tospatial reasoning . bidirectional strategy aim tackle evolve semantic user query dialogue setting . retrieve visual cue contextual information construct relevant response user . empirical result comprehensive qualitative analysis bist achieve competitive performance generate reasonable response large - scale avsd benchmark . adapt bist model video qa setting , substantially outperform prior approach tgif - qa benchmark .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 11, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 2, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Human-centric dialog training via offline reinforcement learning,"How can we train a dialog model to produce better conversations by learning from human feedback, without the risk of humans teaching it harmful chat behaviors? We start by hosting models online, and gather human feedback from real-time, open-ended conversations, which we then use to train and improve the models using offline reinforcement learning (RL). We identify implicit conversational cues including language similarity, elicitation of laughter, sentiment, and more, which indicate positive human feedback, and embed these in multiple reward functions. A wellknown challenge is that learning an RL policy in an offline setting usually fails due to the lack of ability to explore and the tendency to make over-optimistic estimates of future reward. These problems become even harder when using RL for language models, which can easily have a 20,000 action vocabulary and many possible reward functions. We solve the challenge by developing a novel class of offline RL algorithms. These algorithms use KL-control to penalize divergence from a pretrained prior language model, and use a new strategy to make the algorithm pessimistic, instead of optimistic, in the face of uncertainty. We test the resulting dialog model with ratings from 80 users in an open-domain setting and find it achieves significant improvements over existing deep offline RL approaches. The novel offline RL method is viable for improving any existing generative dialog model using a static dataset of human feedback.","Human-centric dialog training via offline reinforcement learning How can we train a dialog model to produce better conversations by learning from human feedback, without the risk of humans teaching it harmful chat behaviors? We start by hosting models online, and gather human feedback from real-time, open-ended conversations, which we then use to train and improve the models using offline reinforcement learning (RL). We identify implicit conversational cues including language similarity, elicitation of laughter, sentiment, and more, which indicate positive human feedback, and embed these in multiple reward functions. A wellknown challenge is that learning an RL policy in an offline setting usually fails due to the lack of ability to explore and the tendency to make over-optimistic estimates of future reward. These problems become even harder when using RL for language models, which can easily have a 20,000 action vocabulary and many possible reward functions. We solve the challenge by developing a novel class of offline RL algorithms. These algorithms use KL-control to penalize divergence from a pretrained prior language model, and use a new strategy to make the algorithm pessimistic, instead of optimistic, in the face of uncertainty. We test the resulting dialog model with ratings from 80 users in an open-domain setting and find it achieves significant improvements over existing deep offline RL approaches. The novel offline RL method is viable for improving any existing generative dialog model using a static dataset of human feedback.","human - centric dialog training offline reinforcement learning train dialog model produce well conversation learn human feedback , risk human teach harmful chat behavior ? start host model online , gather human feedback real - time , open - ended conversation , use train improve model offline reinforcement learning ( rl ) . identify implicit conversational cue include language similarity , elicitation laughter , sentiment , , indicate positive human feedback , embed multiple reward function . wellknown challenge learn rl policy offline setting usually fail lack ability explore tendency - optimistic estimate future reward . problem hard rl language model , easily 20,000 action vocabulary possible reward function . solve challenge develop novel class offline rl algorithm . algorithm use kl - control penalize divergence pretrained prior language model , use new strategy algorithm pessimistic , instead optimistic , face uncertainty . test result dialog model rating 80 user open - domain setting find achieve significant improvement existing deep offline rl approach . novel offline rl method viable improve exist generative dialog model static dataset human feedback .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation,"Social biases present in data are often directly reflected in the predictions of models trained on that data. We analyze gender bias in dialogue data, and examine how this bias is not only replicated, but is also amplified in subsequent generative chit-chat dialogue models. We measure gender bias in six existing dialogue datasets before selecting the most biased one, the multi-player textbased fantasy adventure dataset LIGHT (Urbanek et al., 2019), as a testbed for bias mitigation techniques. We consider three techniques to mitigate gender bias: counterfactual data augmentation, targeted data collection, and bias controlled training. We show that our proposed techniques mitigate gender bias by balancing the genderedness of generated dialogue utterances, and find that they are particularly effective in combination. We evaluate model performance with a variety of quantitative methods-including the quantity of gendered words, a dialogue safety classifier, and human assessments-all of which show that our models generate less gendered, but equally engaging chit-chat responses.","Queens are Powerful too: Mitigating Gender Bias in Dialogue Generation Social biases present in data are often directly reflected in the predictions of models trained on that data. We analyze gender bias in dialogue data, and examine how this bias is not only replicated, but is also amplified in subsequent generative chit-chat dialogue models. We measure gender bias in six existing dialogue datasets before selecting the most biased one, the multi-player textbased fantasy adventure dataset LIGHT (Urbanek et al., 2019), as a testbed for bias mitigation techniques. We consider three techniques to mitigate gender bias: counterfactual data augmentation, targeted data collection, and bias controlled training. We show that our proposed techniques mitigate gender bias by balancing the genderedness of generated dialogue utterances, and find that they are particularly effective in combination. We evaluate model performance with a variety of quantitative methods-including the quantity of gendered words, a dialogue safety classifier, and human assessments-all of which show that our models generate less gendered, but equally engaging chit-chat responses.","queen powerful : mitigate gender bias dialogue generation social bias present datum directly reflect prediction model train datum . analyze gender bias dialogue datum , examine bias replicate , amplify subsequent generative chit - chat dialogue model . measure gender bias exist dialogue dataset select biased , multi - player textbased fantasy adventure dataset light ( urbanek et al . , 2019 ) , testbed bias mitigation technique . consider technique mitigate gender bias : counterfactual datum augmentation , target data collection , bias control training . propose technique mitigate gender bias balance genderedness generate dialogue utterance , find particularly effective combination . evaluate model performance variety quantitative method - include quantity gendered word , dialogue safety classifier , human assessment - model generate gendered , equally engaging chit - chat response .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 27, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 8, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Dialogue and Interactive Systems,The World is Not Binary: Learning to Rank with Grayscale Data for Dialogue Response Selection,"Response selection plays a vital role in building retrieval-based conversation systems. Despite that response selection is naturally a learning-to-rank problem, most prior works take a point-wise view and train binary classifiers for this task: each response candidate is labeled either relevant (one) or irrelevant (zero). On the one hand, this formalization can be sub-optimal due to its ignorance of the diversity of response quality. On the other hand, annotating grayscale data for learning-to-rank can be prohibitively expensive and challenging. In this work, we show that grayscale data can be automatically constructed without human effort. Our method employs off-the-shelf response retrieval models and response generation models as automatic grayscale data generators. With the constructed grayscale data, we propose multi-level ranking objectives for training, which can (1) teach a matching model to capture more fine-grained context-response relevance difference and (2) reduce the traintest discrepancy in terms of distractor strength. Our method is simple, effective, and universal. Experiments on three benchmark datasets and four state-of-the-art matching models show that the proposed approach brings significant and consistent performance improvements.","The World is Not Binary: Learning to Rank with Grayscale Data for Dialogue Response Selection Response selection plays a vital role in building retrieval-based conversation systems. Despite that response selection is naturally a learning-to-rank problem, most prior works take a point-wise view and train binary classifiers for this task: each response candidate is labeled either relevant (one) or irrelevant (zero). On the one hand, this formalization can be sub-optimal due to its ignorance of the diversity of response quality. On the other hand, annotating grayscale data for learning-to-rank can be prohibitively expensive and challenging. In this work, we show that grayscale data can be automatically constructed without human effort. Our method employs off-the-shelf response retrieval models and response generation models as automatic grayscale data generators. With the constructed grayscale data, we propose multi-level ranking objectives for training, which can (1) teach a matching model to capture more fine-grained context-response relevance difference and (2) reduce the traintest discrepancy in terms of distractor strength. Our method is simple, effective, and universal. Experiments on three benchmark datasets and four state-of-the-art matching models show that the proposed approach brings significant and consistent performance improvements.","world binary : learn rank grayscale datum dialogue response selection response selection play vital role build retrieval - base conversation system . despite response selection naturally learn - - rank problem , prior work point - wise view train binary classifier task : response candidate label relevant ( ) irrelevant ( zero ) . hand , formalization sub - optimal ignorance diversity response quality . hand , annotate grayscale datum learn - - rank prohibitively expensive challenging . work , grayscale datum automatically construct human effort . method employ - - shelf response retrieval model response generation model automatic grayscale datum generator . construct grayscale datum , propose multi - level ranking objective training , ( 1 ) teach match model capture fine - grained context - response relevance difference ( 2 ) reduce traint discrepancy term distractor strength . method simple , effective , universal . experiment benchmark dataset state - - - art matching model propose approach bring significant consistent performance improvement .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Semantic Role Labeling Guided Multi-turn Dialogue ReWriter,"For multi-turn dialogue rewriting, the capacity of effectively modeling the linguistic knowledge in dialog context and getting rid of the noises is essential to improve its performance. Existing attentive models attend to all words without prior focus, which results in inaccurate concentration on some dispensable words. In this paper, we propose to use semantic role labeling (SRL), which highlights the core semantic information of who did what to whom, to provide additional guidance for the rewriter model. Experiments show that this information significantly improves a RoBERTa-based model that already outperforms previous stateof-the-art systems.","Semantic Role Labeling Guided Multi-turn Dialogue ReWriter For multi-turn dialogue rewriting, the capacity of effectively modeling the linguistic knowledge in dialog context and getting rid of the noises is essential to improve its performance. Existing attentive models attend to all words without prior focus, which results in inaccurate concentration on some dispensable words. In this paper, we propose to use semantic role labeling (SRL), which highlights the core semantic information of who did what to whom, to provide additional guidance for the rewriter model. Experiments show that this information significantly improves a RoBERTa-based model that already outperforms previous stateof-the-art systems.","semantic role labeling guide multi - turn dialogue rewriter multi - turn dialogue rewriting , capacity effectively model linguistic knowledge dialog context get rid noise essential improve performance . exist attentive model attend word prior focus , result inaccurate concentration dispensable word . paper , propose use semantic role labeling ( srl ) , highlight core semantic information , provide additional guidance rewriter model . experiment information significantly improve roberta - base model outperform previous stateof - - art system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Information Seeking in the Spirit of Learning: A Dataset for Conversational Curiosity,"Open-ended human learning and informationseeking are increasingly mediated by digital assistants. However, such systems often ignore the user's pre-existing knowledge. Assuming a correlation between engagement and user responses such as ""liking"" messages or asking followup questions, we design a Wizard-of-Oz dialog task that tests the hypothesis that engagement increases when users are presented with facts related to what they know. Through crowd-sourcing of this experiment, we collect and release 14K dialogs (181K utterances) where users and assistants converse about geographic topics like geopolitical entities and locations. This dataset is annotated with pre-existing user knowledge, messagelevel dialog acts, grounding to Wikipedia, and user reactions to messages. Responses using a user's prior knowledge increase engagement. We incorporate this knowledge into a multi-task model that reproduces human assistant policies and improves over a BERT content model by 13 mean reciprocal rank points. * Work done while interning at Facebook. U: <assistant wake-word>, tell me about Tahiti. A: It's the largest island in French Polynesia, near the center of the Pacific U: What is its history with France? (4) Dialog Acts & Like Labels Annotation Could you tell me about Puerto Rico's history? It was a Spanish colony until 1898 when the U.S. acquired it as part of the Treaty of Paris.","Information Seeking in the Spirit of Learning: A Dataset for Conversational Curiosity Open-ended human learning and informationseeking are increasingly mediated by digital assistants. However, such systems often ignore the user's pre-existing knowledge. Assuming a correlation between engagement and user responses such as ""liking"" messages or asking followup questions, we design a Wizard-of-Oz dialog task that tests the hypothesis that engagement increases when users are presented with facts related to what they know. Through crowd-sourcing of this experiment, we collect and release 14K dialogs (181K utterances) where users and assistants converse about geographic topics like geopolitical entities and locations. This dataset is annotated with pre-existing user knowledge, messagelevel dialog acts, grounding to Wikipedia, and user reactions to messages. Responses using a user's prior knowledge increase engagement. We incorporate this knowledge into a multi-task model that reproduces human assistant policies and improves over a BERT content model by 13 mean reciprocal rank points. * Work done while interning at Facebook. U: <assistant wake-word>, tell me about Tahiti. A: It's the largest island in French Polynesia, near the center of the Pacific U: What is its history with France? (4) Dialog Acts & Like Labels Annotation Could you tell me about Puerto Rico's history? It was a Spanish colony until 1898 when the U.S. acquired it as part of the Treaty of Paris.","information seeking spirit learning : dataset conversational curiosity open - ended human learning informationseeking increasingly mediate digital assistant . , system ignore user pre - existing knowledge . assume correlation engagement user response "" like "" message ask followup question , design wizard - - oz dialog task test hypothesis engagement increase user present fact relate know . crowd - sourcing experiment , collect release 14 k dialog ( 181 k utterance ) user assistant converse geographic topic like geopolitical entity location . dataset annotate pre - existing user knowledge , messagelevel dialog act , grounding wikipedia , user reaction message . response user prior knowledge increase engagement . incorporate knowledge multi - task model reproduce human assistant policy improve bert content model 13 mean reciprocal rank point . * work intern facebook . u : < assistant wake - word > , tell tahiti . : large island french polynesia , near center pacific u : history france ? ( 4 ) dialog act & like label annotation tell puerto rico history ? spanish colony 1898 u.s. acquire treaty paris .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 8, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Dialogue and Interactive Systems,Parallel Interactive Networks for Multi-Domain Dialogue State Generation,"The dependencies between system and user utterances in the same turn and across different turns are not fully considered in existing multidomain dialogue state tracking (MDST) models. In this study, we argue that the incorporation of these dependencies is crucial for the design of MDST and propose Parallel Interactive Networks (PIN) to model these dependencies. Specifically, we integrate an interactive encoder to jointly model the in-turn dependencies and cross-turn dependencies. The slot-level context is introduced to extract more expressive features for different slots. And a distributed copy mechanism is utilized to selectively copy words from historical system utterances or historical user utterances. Empirical studies demonstrated the superiority of the proposed PIN model.","Parallel Interactive Networks for Multi-Domain Dialogue State Generation The dependencies between system and user utterances in the same turn and across different turns are not fully considered in existing multidomain dialogue state tracking (MDST) models. In this study, we argue that the incorporation of these dependencies is crucial for the design of MDST and propose Parallel Interactive Networks (PIN) to model these dependencies. Specifically, we integrate an interactive encoder to jointly model the in-turn dependencies and cross-turn dependencies. The slot-level context is introduced to extract more expressive features for different slots. And a distributed copy mechanism is utilized to selectively copy words from historical system utterances or historical user utterances. Empirical studies demonstrated the superiority of the proposed PIN model.","parallel interactive networks multi - domain dialogue state generation dependency system user utterance turn different turn fully consider exist multidomain dialogue state tracking ( mdst ) model . study , argue incorporation dependency crucial design mdst propose parallel interactive networks ( pin ) model dependency . specifically , integrate interactive encoder jointly model - turn dependency cross - turn dependency . slot - level context introduce extract expressive feature different slot . distribute copy mechanism utilize selectively copy word historical system utterance historical user utterance . empirical study demonstrate superiority propose pin model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 14, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 7, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning,"Dialogue systems play an increasingly important role in various aspects of our daily life. It is evident from recent research that dialogue systems trained on human conversation data are biased. In particular, they can produce responses that reflect people's gender prejudice. Many debiasing methods have been developed for various NLP tasks, such as word embedding. However, they are not directly applicable to dialogue systems because they are likely to force dialogue models to generate similar responses for different genders. This greatly degrades the diversity of the generated responses and immensely hurts the performance of the dialogue models. In this paper, we propose a novel adversarial learning framework Debiased-Chat to train dialogue models free from gender bias while keeping their performance. Extensive experiments on two real-world conversation datasets show that our framework significantly reduces gender bias in dialogue models while maintaining the response quality. The implementation of the proposed framework is released 1 .","Mitigating Gender Bias for Neural Dialogue Generation with Adversarial Learning Dialogue systems play an increasingly important role in various aspects of our daily life. It is evident from recent research that dialogue systems trained on human conversation data are biased. In particular, they can produce responses that reflect people's gender prejudice. Many debiasing methods have been developed for various NLP tasks, such as word embedding. However, they are not directly applicable to dialogue systems because they are likely to force dialogue models to generate similar responses for different genders. This greatly degrades the diversity of the generated responses and immensely hurts the performance of the dialogue models. In this paper, we propose a novel adversarial learning framework Debiased-Chat to train dialogue models free from gender bias while keeping their performance. Extensive experiments on two real-world conversation datasets show that our framework significantly reduces gender bias in dialogue models while maintaining the response quality. The implementation of the proposed framework is released 1 .","mitigate gender bias neural dialogue generation adversarial learning dialogue system play increasingly important role aspect daily life . evident recent research dialogue system train human conversation datum biased . particular , produce response reflect people gender prejudice . debiase method develop nlp task , word embedding . , directly applicable dialogue system likely force dialogue model generate similar response different gender . greatly degrade diversity generate response immensely hurt performance dialogue model . paper , propose novel adversarial learning framework debiased - chat train dialogue model free gender bias keep performance . extensive experiment real - world conversation dataset framework significantly reduce gender bias dialogue model maintain response quality . implementation propose framework release 1 .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 25, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 16, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Discourse and Pragmatics,MEGA RST Discourse Treebanks with Structure and Nuclearity from Scalable Distant Sentiment Supervision,"The lack of large and diverse discourse treebanks hinders the application of data-driven approaches, such as deep-learning, to RSTstyle discourse parsing. In this work, we present a novel scalable methodology to automatically generate discourse treebanks using distant supervision from sentiment-annotated datasets, creating and publishing MEGA-DT, a new large-scale discourse-annotated corpus. Our approach generates discourse trees incorporating structure and nuclearity for documents of arbitrary length by relying on an efficient heuristic beam-search strategy, extended with a stochastic component. Experiments on multiple datasets indicate that a discourse parser trained on our MEGA-DT treebank delivers promising inter-domain performance gains when compared to parsers trained on human-annotated discourse corpora.","MEGA RST Discourse Treebanks with Structure and Nuclearity from Scalable Distant Sentiment Supervision The lack of large and diverse discourse treebanks hinders the application of data-driven approaches, such as deep-learning, to RSTstyle discourse parsing. In this work, we present a novel scalable methodology to automatically generate discourse treebanks using distant supervision from sentiment-annotated datasets, creating and publishing MEGA-DT, a new large-scale discourse-annotated corpus. Our approach generates discourse trees incorporating structure and nuclearity for documents of arbitrary length by relying on an efficient heuristic beam-search strategy, extended with a stochastic component. Experiments on multiple datasets indicate that a discourse parser trained on our MEGA-DT treebank delivers promising inter-domain performance gains when compared to parsers trained on human-annotated discourse corpora.","mega rst discourse treebank structure nuclearity scalable distant sentiment supervision lack large diverse discourse treebank hinder application data - drive approach , deep - learning , rststyle discourse parsing . work , present novel scalable methodology automatically generate discourse treebank distant supervision sentiment - annotate dataset , create publish mega - dt , new large - scale discourse - annotate corpus . approach generate discourse tree incorporate structure nuclearity document arbitrary length rely efficient heuristic beam - search strategy , extend stochastic component . experiment multiple dataset indicate discourse parser train mega - dt treebank deliver promising inter - domain performance gain compare parser train human - annotated discourse corpora .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 10, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 8, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,Online Conversation Disentanglement with Pointer Networks,"Huge amounts of textual conversations occur online every day, where multiple conversations take place concurrently. Interleaved conversations lead to difficulties in not only following the ongoing discussions but also extracting relevant information from simultaneous messages. Conversation disentanglement aims to separate intermingled messages into detached conversations. However, existing disentanglement methods rely mostly on handcrafted features that are dataset specific, which hinders generalization and adaptability. In this work, we propose an end-to-end online framework for conversation disentanglement that avoids time-consuming domain-specific feature engineering. We design a novel way to embed the whole utterance that comprises timestamp, speaker, and message text, and propose a custom attention mechanism that models disentanglement as a pointing problem while effectively capturing inter-utterance interactions in an end-to-end fashion. We also introduce a joint-learning objective to better capture contextual information. Our experiments on the Ubuntu IRC dataset show that our method achieves state-of-the-art performance in both link and conversation prediction tasks.","Online Conversation Disentanglement with Pointer Networks Huge amounts of textual conversations occur online every day, where multiple conversations take place concurrently. Interleaved conversations lead to difficulties in not only following the ongoing discussions but also extracting relevant information from simultaneous messages. Conversation disentanglement aims to separate intermingled messages into detached conversations. However, existing disentanglement methods rely mostly on handcrafted features that are dataset specific, which hinders generalization and adaptability. In this work, we propose an end-to-end online framework for conversation disentanglement that avoids time-consuming domain-specific feature engineering. We design a novel way to embed the whole utterance that comprises timestamp, speaker, and message text, and propose a custom attention mechanism that models disentanglement as a pointing problem while effectively capturing inter-utterance interactions in an end-to-end fashion. We also introduce a joint-learning objective to better capture contextual information. Our experiments on the Ubuntu IRC dataset show that our method achieves state-of-the-art performance in both link and conversation prediction tasks.","online conversation disentanglement pointer networks huge amount textual conversation occur online day , multiple conversation place concurrently . interleaved conversation lead difficulty follow ongoing discussion extract relevant information simultaneous message . conversation disentanglement aim separate intermingled message detached conversation . , exist disentanglement method rely handcraft feature dataset specific , hinder generalization adaptability . work , propose end - - end online framework conversation disentanglement avoid time - consume domain - specific feature engineering . design novel way embed utterance comprise timestamp , speaker , message text , propose custom attention mechanism model disentanglement pointing problem effectively capture inter - utterance interaction end - - end fashion . introduce joint - learning objective well capture contextual information . experiment ubuntu irc dataset method achieve state - - - art performance link conversation prediction task .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Discourse and Pragmatics,Discourse Self-Attention for Discourse Element Identification in Argumentative Student Essays,"This paper proposes to adapt self-attention to discourse level for modeling discourse elements in argumentative student essays. Specifically, we focus on two issues. First, we propose structural sentence positional encodings to explicitly represent sentence positions. Second, we propose to use inter-sentence attentions to capture sentence interactions and enhance sentence representation. We conduct experiments on two datasets: a Chinese dataset and an English dataset. We find that (i) sentence positional encodings can lead to a large improvement for identifying discourse elements; (ii) a structural relative positional encoding of sentences shows to be most effective; (iii) inter-sentence attention vectors are useful as a kind of sentence representation for identifying discourse elements.","Discourse Self-Attention for Discourse Element Identification in Argumentative Student Essays This paper proposes to adapt self-attention to discourse level for modeling discourse elements in argumentative student essays. Specifically, we focus on two issues. First, we propose structural sentence positional encodings to explicitly represent sentence positions. Second, we propose to use inter-sentence attentions to capture sentence interactions and enhance sentence representation. We conduct experiments on two datasets: a Chinese dataset and an English dataset. We find that (i) sentence positional encodings can lead to a large improvement for identifying discourse elements; (ii) a structural relative positional encoding of sentences shows to be most effective; (iii) inter-sentence attention vectors are useful as a kind of sentence representation for identifying discourse elements.","discourse self - attention discourse element identification argumentative student essay paper propose adapt self - attention discourse level model discourse element argumentative student essay . specifically , focus issue . , propose structural sentence positional encoding explicitly represent sentence position . second , propose use inter - sentence attention capture sentence interaction enhance sentence representation . conduct experiment dataset : chinese dataset english dataset . find ( ) sentence positional encoding lead large improvement identify discourse element ; ( ii ) structural relative positional encoding sentence show effective ; ( iii ) inter - sentence attention vector useful kind sentence representation identify discourse element .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 6, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,Keeping Up Appearances: Computational Modeling of Face Acts in Persuasion Oriented Discussions,"The notion of face refers to the public selfimage of an individual that emerges both from the individual's own actions as well as from the interaction with others. Modeling face and understanding its state changes throughout a conversation is critical to the study of maintenance of basic human needs in and through interaction. Grounded in the politeness theory of Brown and Levinson (1978) , we propose a generalized framework for modeling face acts in persuasion conversations, resulting in a reliable coding manual, an annotated corpus, and computational models. The framework reveals insights about differences in face act utilization between asymmetric roles in persuasion conversations. Using computational models, we are able to successfully identify face acts as well as predict a key conversational outcome (e.g. donation success). Finally, we model a latent representation of the conversational state to analyze the impact of predicted face acts on the probability of a positive conversational outcome and observe several correlations that corroborate previous findings.","Keeping Up Appearances: Computational Modeling of Face Acts in Persuasion Oriented Discussions The notion of face refers to the public selfimage of an individual that emerges both from the individual's own actions as well as from the interaction with others. Modeling face and understanding its state changes throughout a conversation is critical to the study of maintenance of basic human needs in and through interaction. Grounded in the politeness theory of Brown and Levinson (1978) , we propose a generalized framework for modeling face acts in persuasion conversations, resulting in a reliable coding manual, an annotated corpus, and computational models. The framework reveals insights about differences in face act utilization between asymmetric roles in persuasion conversations. Using computational models, we are able to successfully identify face acts as well as predict a key conversational outcome (e.g. donation success). Finally, we model a latent representation of the conversational state to analyze the impact of predicted face acts on the probability of a positive conversational outcome and observe several correlations that corroborate previous findings.","keep appearance : computational modeling face act persuasion orient discussion notion face refer public selfimage individual emerge individual action interaction . model face understand state change conversation critical study maintenance basic human need interaction . ground politeness theory brown levinson ( 1978 ) , propose generalized framework model face act persuasion conversation , result reliable code manual , annotate corpus , computational model . framework reveal insight difference face act utilization asymmetric role persuasion conversation . computational model , able successfully identify face act predict key conversational outcome ( e.g. donation success ) . finally , model latent representation conversational state analyze impact predict face act probability positive conversational outcome observe correlation corroborate previous finding .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Discourse and Pragmatics,Revealing the Myth of Higher-Order Inference in Coreference Resolution,"This paper analyzes the impact of higher-order inference (HOI) on the task of coreference resolution. HOI has been adapted by almost all recent coreference resolution models without taking much investigation on its true effectiveness over representation learning. To make a comprehensive analysis, we implement an endto-end coreference system as well as four HOI approaches, attended antecedent, entity equalization, span clustering, and cluster merging, where the latter two are our original methods. We find that given a high-performing encoder such as SpanBERT, the impact of HOI is negative to marginal, providing a new perspective of HOI to this task. Our best model using cluster merging shows the Avg-F1 of 80.2 on the CoNLL 2012 shared task dataset in English.","Revealing the Myth of Higher-Order Inference in Coreference Resolution This paper analyzes the impact of higher-order inference (HOI) on the task of coreference resolution. HOI has been adapted by almost all recent coreference resolution models without taking much investigation on its true effectiveness over representation learning. To make a comprehensive analysis, we implement an endto-end coreference system as well as four HOI approaches, attended antecedent, entity equalization, span clustering, and cluster merging, where the latter two are our original methods. We find that given a high-performing encoder such as SpanBERT, the impact of HOI is negative to marginal, providing a new perspective of HOI to this task. Our best model using cluster merging shows the Avg-F1 of 80.2 on the CoNLL 2012 shared task dataset in English.","reveal myth high - order inference coreference resolution paper analyze impact high - order inference ( hoi ) task coreference resolution . hoi adapt recent coreference resolution model take investigation true effectiveness representation learning . comprehensive analysis , implement endto - end coreference system hoi approach , attend antecedent , entity equalization , span clustering , cluster merging , original method . find give high - perform encoder spanbert , impact hoi negative marginal , provide new perspective hoi task . good model cluster merging show avg - f1 80.2 conll 2012 share task dataset english .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Discourse and Pragmatics,"QADiscourse - Discourse Relations as QA Pairs: Representation, Crowdsourcing and Baselines","Discourse relations describe how two propositions relate to one another, and identifying them automatically is an integral part of natural language understanding. However, annotating discourse relations typically requires expert annotators. Recently, different semantic aspects of a sentence have been represented and crowd-sourced via question-and-answer (QA) pairs. This paper proposes a novel representation of discourse relations as QA pairs, which in turn allows us to crowd-source widecoverage data annotated with discourse relations, via an intuitively appealing interface for composing such questions and answers. Based on our proposed representation, we collect a novel and wide-coverage QADiscourse dataset, and present baseline algorithms for predicting QADiscourse relations.","QADiscourse - Discourse Relations as QA Pairs: Representation, Crowdsourcing and Baselines Discourse relations describe how two propositions relate to one another, and identifying them automatically is an integral part of natural language understanding. However, annotating discourse relations typically requires expert annotators. Recently, different semantic aspects of a sentence have been represented and crowd-sourced via question-and-answer (QA) pairs. This paper proposes a novel representation of discourse relations as QA pairs, which in turn allows us to crowd-source widecoverage data annotated with discourse relations, via an intuitively appealing interface for composing such questions and answers. Based on our proposed representation, we collect a novel and wide-coverage QADiscourse dataset, and present baseline algorithms for predicting QADiscourse relations.","qadiscourse - discourse relation qa pair : representation , crowdsourcing baseline discourse relation describe proposition relate , identify automatically integral natural language understanding . , annotate discourse relation typically require expert annotator . recently , different semantic aspect sentence represent crowd - source question - - answer ( qa ) pair . paper propose novel representation discourse relation qa pair , turn allow crowd - source widecoverage datum annotate discourse relation , intuitively appealing interface compose question answer . base propose representation , collect novel wide - coverage qadiscourse dataset , present baseline algorithm predict qadiscourse relation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 14, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,TED-CDB: A Large-Scale Chinese Discourse Relation Dataset on TED Talks,"As different genres are known to differ in their communicative properties and as previously, for Chinese, discourse relations have only been annotated over news text, we have created the TED-CDB dataset. TED-CDB comprises a large set of TED talks in Chinese that have been manually annotated according to the goals and principles of Penn Discourse Treebank, but adapted to features that are not present in English. It serves as a unique Chinese corpus of spoken discourse. Benchmark experiments show that TED-CDB poses a challenge for state-of-the-art discourse relation classifiers, whose F1 performance on 4way classification is <60%. This is a dramatic drop of 35% from performance on the news text in the Chinese Discourse Treebank. Transfer learning experiments have been carried out with the TED-CDB for both same-language cross-domain transfer and same-domain crosslanguage transfer. Both demonstrate that the TED-CDB can improve the performance of systems being developed for languages other than Chinese and would be helpful for insufficient or unbalanced data in other corpora. The dataset and our Chinese annotation guidelines has been made freely available. 1","TED-CDB: A Large-Scale Chinese Discourse Relation Dataset on TED Talks As different genres are known to differ in their communicative properties and as previously, for Chinese, discourse relations have only been annotated over news text, we have created the TED-CDB dataset. TED-CDB comprises a large set of TED talks in Chinese that have been manually annotated according to the goals and principles of Penn Discourse Treebank, but adapted to features that are not present in English. It serves as a unique Chinese corpus of spoken discourse. Benchmark experiments show that TED-CDB poses a challenge for state-of-the-art discourse relation classifiers, whose F1 performance on 4way classification is <60%. This is a dramatic drop of 35% from performance on the news text in the Chinese Discourse Treebank. Transfer learning experiments have been carried out with the TED-CDB for both same-language cross-domain transfer and same-domain crosslanguage transfer. Both demonstrate that the TED-CDB can improve the performance of systems being developed for languages other than Chinese and would be helpful for insufficient or unbalanced data in other corpora. The dataset and our Chinese annotation guidelines has been made freely available. 1","ted - cdb : large - scale chinese discourse relation dataset ted talks different genre know differ communicative property previously , chinese , discourse relation annotate news text , create ted - cdb dataset . ted - cdb comprise large set ted talk chinese manually annotate accord goal principle penn discourse treebank , adapt feature present english . serve unique chinese corpus speak discourse . benchmark experiment ted - cdb pose challenge state - - - art discourse relation classifier , f1 performance 4way classification < 60 % . dramatic drop 35 % performance news text chinese discourse treebank . transfer learning experiment carry ted - cdb - language cross - domain transfer - domain crosslanguage transfer . demonstrate ted - cdb improve performance system develop language chinese helpful insufficient unbalanced datum corpus . dataset chinese annotation guideline freely available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 9, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 10, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Discourse and Pragmatics,VCDM: Leveraging Variational Bi-encoding and Deep Contextualized Word Representations for Improved Definition Modeling,"In this paper we tackle the task of definition modeling, where the goal is to learn to generate definitions of words and phrases. Existing approaches for this task are discriminative, combining distributional and lexical semantics in an implicit rather than direct way. To tackle this issue we propose a generative model for the task, introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. We rely on variational inference for estimation and leverage contextualized word embeddings for improved performance. Our approach is evaluated on four existing challenging benchmarks with the addition of two new datasets, CAMBRIDGE and the first non-English corpus ROBERT, which we release to complement our empirical study. Our Variational Contextual Definition Modeler (VCDM) achieves state-of-the-art performance in terms of automatic and human evaluation metrics, demonstrating the effectiveness of our approach. 1","VCDM: Leveraging Variational Bi-encoding and Deep Contextualized Word Representations for Improved Definition Modeling In this paper we tackle the task of definition modeling, where the goal is to learn to generate definitions of words and phrases. Existing approaches for this task are discriminative, combining distributional and lexical semantics in an implicit rather than direct way. To tackle this issue we propose a generative model for the task, introducing a continuous latent variable to explicitly model the underlying relationship between a phrase used within a context and its definition. We rely on variational inference for estimation and leverage contextualized word embeddings for improved performance. Our approach is evaluated on four existing challenging benchmarks with the addition of two new datasets, CAMBRIDGE and the first non-English corpus ROBERT, which we release to complement our empirical study. Our Variational Contextual Definition Modeler (VCDM) achieves state-of-the-art performance in terms of automatic and human evaluation metrics, demonstrating the effectiveness of our approach. 1","vcdm : leverage variational bi - encoding deep contextualize word representation improve definition modeling paper tackle task definition modeling , goal learn generate definition word phrase . exist approach task discriminative , combine distributional lexical semantic implicit direct way . tackle issue propose generative model task , introduce continuous latent variable explicitly model underlie relationship phrase context definition . rely variational inference estimation leverage contextualize word embedding improve performance . approach evaluate exist challenging benchmark addition new dataset , cambridge non - english corpus robert , release complement empirical study . variational contextual definition modeler ( vcdm ) achieve state - - - art performance term automatic human evaluation metric , demonstrate effectiveness approach . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Discourse and Pragmatics,BERT-enhanced Relational Sentence Ordering Network,"In this paper, we introduce a novel BERTenhanced Relational Sentence Ordering Network (referred to as BERSON) by leveraging BERT for capturing a better dependency relationship among sentences to enhance the coherence modeling for the entire paragraph. In particular, we develop a new Relational Pointer Decoder (referred as RPD) by incorporating the relative ordering information into the pointer network with a Deep Relational Module (referred as DRM), which utilizes BERT to exploit the deep semantic connection and relative ordering between sentences. This enables us to strengthen both local and global dependencies among sentences. Extensive evaluations are conducted on six public datasets. The experimental results demonstrate the effectiveness and promise of BERSON, showing a significant improvement over the state-of-the-art by a wide margin.","BERT-enhanced Relational Sentence Ordering Network In this paper, we introduce a novel BERTenhanced Relational Sentence Ordering Network (referred to as BERSON) by leveraging BERT for capturing a better dependency relationship among sentences to enhance the coherence modeling for the entire paragraph. In particular, we develop a new Relational Pointer Decoder (referred as RPD) by incorporating the relative ordering information into the pointer network with a Deep Relational Module (referred as DRM), which utilizes BERT to exploit the deep semantic connection and relative ordering between sentences. This enables us to strengthen both local and global dependencies among sentences. Extensive evaluations are conducted on six public datasets. The experimental results demonstrate the effectiveness and promise of BERSON, showing a significant improvement over the state-of-the-art by a wide margin.","bert - enhance relational sentence ordering network paper , introduce novel bertenhanced relational sentence ordering network ( refer berson ) leverage bert capture well dependency relationship sentence enhance coherence modeling entire paragraph . particular , develop new relational pointer decoder ( refer rpd ) incorporate relative order information pointer network deep relational module ( refer drm ) , utilize bert exploit deep semantic connection relative ordering sentence . enable strengthen local global dependency sentence . extensive evaluation conduct public dataset . experimental result demonstrate effectiveness promise berson , show significant improvement state - - - art wide margin .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Discourse and Pragmatics,PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction,"Unconscious biases continue to be prevalent in modern text and media, calling for algorithms that can assist writers with bias correction. For example, a female character in a story is often portrayed as passive and powerless (""She daydreams about being a doctor"") while a man is portrayed as more proactive and powerful (""He pursues his dream of being a doctor""). We formulate Controllable Debiasing, a new revision task that aims to rewrite a given text to correct the implicit and potentially undesirable bias in character portrayals. We then introduce POWERTRANSFORMER as an approach that debiases text through the lens of connotation frames (Sap et al., 2017) , which encode pragmatic knowledge of implied power dynamics with respect to verb predicates. One key challenge of our task is the lack of parallel corpora. To address this challenge, we adopt an unsupervised approach using auxiliary supervision with related tasks such as paraphrasing and self-supervision based on a reconstruction loss, building on pretrained language models. Through comprehensive experiments based on automatic and human evaluations, we demonstrate that our approach outperforms ablations and existing methods from related tasks. Furthermore, we demonstrate the use of POWER-TRANSFORMER as a step toward mitigating the well-documented gender bias in character portrayal in movie scripts. Daniel Clement Dennett. 1989. The intentional stance. MIT press. Ethan Fast, Tina Vachovsky, and Michael S Bernstein. 2016. Shirtless and dangerous: Quantifying linguistic signals of gender bias in an online fiction writing community. In ICWSM.","PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction Unconscious biases continue to be prevalent in modern text and media, calling for algorithms that can assist writers with bias correction. For example, a female character in a story is often portrayed as passive and powerless (""She daydreams about being a doctor"") while a man is portrayed as more proactive and powerful (""He pursues his dream of being a doctor""). We formulate Controllable Debiasing, a new revision task that aims to rewrite a given text to correct the implicit and potentially undesirable bias in character portrayals. We then introduce POWERTRANSFORMER as an approach that debiases text through the lens of connotation frames (Sap et al., 2017) , which encode pragmatic knowledge of implied power dynamics with respect to verb predicates. One key challenge of our task is the lack of parallel corpora. To address this challenge, we adopt an unsupervised approach using auxiliary supervision with related tasks such as paraphrasing and self-supervision based on a reconstruction loss, building on pretrained language models. Through comprehensive experiments based on automatic and human evaluations, we demonstrate that our approach outperforms ablations and existing methods from related tasks. Furthermore, we demonstrate the use of POWER-TRANSFORMER as a step toward mitigating the well-documented gender bias in character portrayal in movie scripts. Daniel Clement Dennett. 1989. The intentional stance. MIT press. Ethan Fast, Tina Vachovsky, and Michael S Bernstein. 2016. Shirtless and dangerous: Quantifying linguistic signals of gender bias in an online fiction writing community. In ICWSM.","powertransformer : unsupervised controllable revision biased language correction unconscious bias continue prevalent modern text medium , call algorithm assist writer bias correction . example , female character story portray passive powerless ( "" daydream doctor "" ) man portray proactive powerful ( "" pursue dream doctor "" ) . formulate controllable debiasing , new revision task aim rewrite give text correct implicit potentially undesirable bias character portrayal . introduce powertransformer approach debiase text lens connotation frame ( sap et al . , 2017 ) , encode pragmatic knowledge imply power dynamic respect verb predicate . key challenge task lack parallel corpus . address challenge , adopt unsupervised approach auxiliary supervision related task paraphrasing self - supervision base reconstruction loss , build pretrained language model . comprehensive experiment base automatic human evaluation , demonstrate approach outperform ablation exist method related task . furthermore , demonstrate use power - transformer step mitigate - document gender bias character portrayal movie script . daniel clement dennett . 1989 . intentional stance . mit press . ethan fast , tina vachovsky , michael s bernstein . 2016 . shirtless dangerous : quantify linguistic signal gender bias online fiction writing community . icwsm .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 14, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Discourse and Pragmatics,Learning to Ignore: Long Document Coreference with Bounded Memory Neural Networks,"Long document coreference resolution remains a challenging task due to the large memory and runtime requirements of current models. Recent work doing incremental coreference resolution using just the global representation of entities shows practical benefits but requires keeping all entities in memory, which can be impractical for long documents. We argue that keeping all entities in memory is unnecessary, and we propose a memoryaugmented neural network that tracks only a small bounded number of entities at a time, thus guaranteeing a linear runtime in length of document. We show that (a) the model remains competitive with models with high memory and computational requirements on OntoNotes and LitBank, and (b) the model learns an efficient memory management strategy easily outperforming a rule-based strategy.","Learning to Ignore: Long Document Coreference with Bounded Memory Neural Networks Long document coreference resolution remains a challenging task due to the large memory and runtime requirements of current models. Recent work doing incremental coreference resolution using just the global representation of entities shows practical benefits but requires keeping all entities in memory, which can be impractical for long documents. We argue that keeping all entities in memory is unnecessary, and we propose a memoryaugmented neural network that tracks only a small bounded number of entities at a time, thus guaranteeing a linear runtime in length of document. We show that (a) the model remains competitive with models with high memory and computational requirements on OntoNotes and LitBank, and (b) the model learns an efficient memory management strategy easily outperforming a rule-based strategy.","learn ignore : long document coreference bound memory neural network long document coreference resolution remain challenging task large memory runtime requirement current model . recent work incremental coreference resolution global representation entity show practical benefit require keep entity memory , impractical long document . argue keep entity memory unnecessary , propose memoryaugmente neural network track small bound number entity time , guarantee linear runtime length document . ( ) model remain competitive model high memory computational requirement ontonotes litbank , ( b ) model learn efficient memory management strategy easily outperform rule - base strategy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Information Extraction,Learning from Context or Names? An Empirical Study on Neural Relation Extraction,"Neural models have achieved remarkable success on relation extraction (RE) benchmarks. However, there is no clear understanding which type of information affects existing RE models to make decisions and how to further improve the performance of these models. To this end, we empirically study the effect of two main information sources in text: textual context and entity mentions (names). We find that (i) while context is the main source to support the predictions, RE models also heavily rely on the information from entity mentions, most of which is type information, and (ii) existing datasets may leak shallow heuristics via entity mentions and thus contribute to the high performance on RE benchmarks. Based on the analyses, we propose an entity-masked contrastive pre-training framework for RE to gain a deeper understanding on both textual context and type information while avoiding rote memorization of entities or use of superficial cues in mentions. We carry out extensive experiments to support our views, and show that our framework can improve the effectiveness and robustness of neural models in different RE scenarios. All the code and datasets are released at https://github.com/thunlp/ RE-Context-or-Names.","Learning from Context or Names? An Empirical Study on Neural Relation Extraction Neural models have achieved remarkable success on relation extraction (RE) benchmarks. However, there is no clear understanding which type of information affects existing RE models to make decisions and how to further improve the performance of these models. To this end, we empirically study the effect of two main information sources in text: textual context and entity mentions (names). We find that (i) while context is the main source to support the predictions, RE models also heavily rely on the information from entity mentions, most of which is type information, and (ii) existing datasets may leak shallow heuristics via entity mentions and thus contribute to the high performance on RE benchmarks. Based on the analyses, we propose an entity-masked contrastive pre-training framework for RE to gain a deeper understanding on both textual context and type information while avoiding rote memorization of entities or use of superficial cues in mentions. We carry out extensive experiments to support our views, and show that our framework can improve the effectiveness and robustness of neural models in different RE scenarios. All the code and datasets are released at https://github.com/thunlp/ RE-Context-or-Names.","learn context name ? empirical study neural relation extraction neural model achieve remarkable success relation extraction ( ) benchmark . , clear understand type information affect exist model decision improve performance model . end , empirically study effect main information source text : textual context entity mention ( name ) . find ( ) context main source support prediction , model heavily rely information entity mention , type information , ( ii ) exist dataset leak shallow heuristic entity mention contribute high performance benchmark . base analysis , propose entity - mask contrastive pre - training framework gain deep understanding textual context type information avoid rote memorization entity use superficial cue mention . carry extensive experiment support view , framework improve effectiveness robustness neural model different scenario . code dataset release https://github.com/thunlp/ - context - - names .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,DualTKB: A Dual Learning Bridge between Text and Knowledge Base,"In this work, we present a dual learning approach for unsupervised text to path and path to text transfers in Commonsense Knowledge Bases (KBs). We investigate the impact of weak supervision by creating a weakly supervised dataset and show that even a slight amount of supervision can significantly improve the model performance and enable better-quality transfers. We examine different model architectures, and evaluation metrics, proposing a novel Commonsense KB completion metric tailored for generative models. Extensive experimental results show that the proposed method compares very favorably to the existing baselines. This approach is a viable step towards a more advanced system for automatic KB construction/expansion and the reverse operation of KB conversion to coherent textual descriptions.","DualTKB: A Dual Learning Bridge between Text and Knowledge Base In this work, we present a dual learning approach for unsupervised text to path and path to text transfers in Commonsense Knowledge Bases (KBs). We investigate the impact of weak supervision by creating a weakly supervised dataset and show that even a slight amount of supervision can significantly improve the model performance and enable better-quality transfers. We examine different model architectures, and evaluation metrics, proposing a novel Commonsense KB completion metric tailored for generative models. Extensive experimental results show that the proposed method compares very favorably to the existing baselines. This approach is a viable step towards a more advanced system for automatic KB construction/expansion and the reverse operation of KB conversion to coherent textual descriptions.","dualtkb : dual learning bridge text knowledge base work , present dual learning approach unsupervised text path path text transfer commonsense knowledge bases ( kb ) . investigate impact weak supervision create weakly supervise dataset slight supervision significantly improve model performance enable well - quality transfer . examine different model architecture , evaluation metric , propose novel commonsense kb completion metric tailor generative model . extensive experimental result propose method compare favorably exist baseline . approach viable step advanced system automatic kb construction / expansion reverse operation kb conversion coherent textual description .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Extraction,Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders,"Named entity recognition and relation extraction are two important fundamental problems. Joint learning algorithms have been proposed to solve both tasks simultaneously, and many of them cast the joint task as a table-filling problem. However, they typically focused on learning a single encoder (usually learning representation in the form of a table) to capture information required for both tasks within the same space. We argue that it can be beneficial to design two distinct encoders to capture such two different types of information in the learning process. In this work, we propose the novel table-sequence encoders where two different encoders -a table encoder and a sequence encoder are designed to help each other in the representation learning process. Our experiments confirm the advantages of having two encoders over one encoder. On several standard datasets, our model shows significant improvements over existing approaches. 1","Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders Named entity recognition and relation extraction are two important fundamental problems. Joint learning algorithms have been proposed to solve both tasks simultaneously, and many of them cast the joint task as a table-filling problem. However, they typically focused on learning a single encoder (usually learning representation in the form of a table) to capture information required for both tasks within the same space. We argue that it can be beneficial to design two distinct encoders to capture such two different types of information in the learning process. In this work, we propose the novel table-sequence encoders where two different encoders -a table encoder and a sequence encoder are designed to help each other in the representation learning process. Our experiments confirm the advantages of having two encoders over one encoder. On several standard datasets, our model shows significant improvements over existing approaches. 1","well : joint entity relation extraction table - sequence encoder name entity recognition relation extraction important fundamental problem . joint learning algorithm propose solve task simultaneously , cast joint task table - fill problem . , typically focus learn single encoder ( usually learn representation form table ) capture information require task space . argue beneficial design distinct encoder capture different type information learning process . work , propose novel table - sequence encoder different encoder -a table encoder sequence encoder design help representation learning process . experiment confirm advantage have encoder encoder . standard dataset , model show significant improvement exist approach . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 10, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 9, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,AxCell: Automatic Extraction of Results from Machine Learning Papers,"Tracking progress in machine learning has become increasingly difficult with the recent explosion in the number of papers. In this paper, we present AXCELL, an automatic machine learning pipeline for extracting results from papers. AXCELL uses several novel components, including a table segmentation subtask, to learn relevant structural knowledge that aids extraction. When compared with existing methods, our approach significantly improves the state of the art for results extraction. We also release a structured, annotated dataset for training models for results extraction, and a dataset for evaluating the performance of models on this task. Lastly, we show the viability of our approach enables it to be used for semi-automated results extraction in production, suggesting our improvements make this task practically viable for the first time. Code is available on GitHub. 1","AxCell: Automatic Extraction of Results from Machine Learning Papers Tracking progress in machine learning has become increasingly difficult with the recent explosion in the number of papers. In this paper, we present AXCELL, an automatic machine learning pipeline for extracting results from papers. AXCELL uses several novel components, including a table segmentation subtask, to learn relevant structural knowledge that aids extraction. When compared with existing methods, our approach significantly improves the state of the art for results extraction. We also release a structured, annotated dataset for training models for results extraction, and a dataset for evaluating the performance of models on this task. Lastly, we show the viability of our approach enables it to be used for semi-automated results extraction in production, suggesting our improvements make this task practically viable for the first time. Code is available on GitHub. 1","axcell : automatic extraction result machine learning paper track progress machine learning increasingly difficult recent explosion number paper . paper , present axcell , automatic machine learning pipeline extract result paper . axcell use novel component , include table segmentation subtask , learn relevant structural knowledge aid extraction . compare exist method , approach significantly improve state art result extraction . release structured , annotated dataset train model result extraction , dataset evaluate performance model task . lastly , viability approach enable semi - automated result extraction production , suggest improvement task practically viable time . code available github . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Scalable Zero-shot Entity Linking with Dense Entity Retrieval,"This paper introduces a conceptually simple, scalable, and highly effective BERT-based entity linking model, along with an extensive evaluation of its accuracy-speed trade-off. We present a two-stage zero-shot linking algorithm, where each entity is defined only by a short textual description. The first stage does retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then re-ranked with a crossencoder, that concatenates the mention and entity text. Experiments demonstrate that this approach is state of the art on recent zeroshot benchmarks (6 point absolute gains) and also on more established non-zero-shot evaluations (e.g. TACKBP-2010), despite its relative simplicity (e.g. no explicit entity embeddings or manually engineered mention tables). We also show that bi-encoder linking is very fast with nearest neighbour search (e.g. linking with 5.9 million candidates in 2 milliseconds), and that much of the accuracy gain from the more expensive crossencoder can be transferred to the bi-encoder via knowledge distillation. Our code and models are available at https://github. com/facebookresearch/BLINK.","Scalable Zero-shot Entity Linking with Dense Entity Retrieval This paper introduces a conceptually simple, scalable, and highly effective BERT-based entity linking model, along with an extensive evaluation of its accuracy-speed trade-off. We present a two-stage zero-shot linking algorithm, where each entity is defined only by a short textual description. The first stage does retrieval in a dense space defined by a bi-encoder that independently embeds the mention context and the entity descriptions. Each candidate is then re-ranked with a crossencoder, that concatenates the mention and entity text. Experiments demonstrate that this approach is state of the art on recent zeroshot benchmarks (6 point absolute gains) and also on more established non-zero-shot evaluations (e.g. TACKBP-2010), despite its relative simplicity (e.g. no explicit entity embeddings or manually engineered mention tables). We also show that bi-encoder linking is very fast with nearest neighbour search (e.g. linking with 5.9 million candidates in 2 milliseconds), and that much of the accuracy gain from the more expensive crossencoder can be transferred to the bi-encoder via knowledge distillation. Our code and models are available at https://github. com/facebookresearch/BLINK.","scalable zero - shot entity linking dense entity retrieval paper introduce conceptually simple , scalable , highly effective bert - base entity linking model , extensive evaluation accuracy - speed trade - . present - stage zero - shot linking algorithm , entity define short textual description . stage retrieval dense space define bi - encoder independently embed mention context entity description . candidate - rank crossencoder , concatenate mention entity text . experiment demonstrate approach state art recent zeroshot benchmark ( 6 point absolute gain ) established non - zero - shot evaluation ( e.g. tackbp-2010 ) , despite relative simplicity ( e.g. explicit entity embedding manually engineer mention table ) . bi - encoder linking fast near neighbour search ( e.g. link 5.9 million candidate 2 millisecond ) , accuracy gain expensive crossencoder transfer bi - encoder knowledge distillation . code model available https://github . com / facebookresearch / blink .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 9, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Information Extraction,Event Detection: Gate Diversity and Syntactic Importance Scores for Graph Convolution Neural Networks,"Recent studies on event detection (ED) have shown that the syntactic dependency graph can be employed in graph convolution neural networks (GCN) to achieve state-of-the-art performance. However, the computation of the hidden vectors in such graph-based models is agnostic to the trigger candidate words, potentially leaving irrelevant information for the trigger candidate for event prediction. In addition, the current models for ED fail to exploit the overall contextual importance scores of the words, which can be obtained via the dependency tree, to boost the performance. In this study, we propose a novel gating mechanism to filter noisy information in the hidden vectors of the GCN models for ED based on the information from the trigger candidate. We also introduce novel mechanisms to achieve the contextual diversity for the gates and the importance score consistency for the graphs and models in ED. The experiments show that the proposed model achieves state-of-the-art performance on two ED datasets.","Event Detection: Gate Diversity and Syntactic Importance Scores for Graph Convolution Neural Networks Recent studies on event detection (ED) have shown that the syntactic dependency graph can be employed in graph convolution neural networks (GCN) to achieve state-of-the-art performance. However, the computation of the hidden vectors in such graph-based models is agnostic to the trigger candidate words, potentially leaving irrelevant information for the trigger candidate for event prediction. In addition, the current models for ED fail to exploit the overall contextual importance scores of the words, which can be obtained via the dependency tree, to boost the performance. In this study, we propose a novel gating mechanism to filter noisy information in the hidden vectors of the GCN models for ED based on the information from the trigger candidate. We also introduce novel mechanisms to achieve the contextual diversity for the gates and the importance score consistency for the graphs and models in ED. The experiments show that the proposed model achieves state-of-the-art performance on two ED datasets.","event detection : gate diversity syntactic importance score graph convolution neural networks recent study event detection ( ed ) show syntactic dependency graph employ graph convolution neural network ( gcn ) achieve state - - - art performance . , computation hide vector graph - base model agnostic trigger candidate word , potentially leave irrelevant information trigger candidate event prediction . addition , current model ed fail exploit overall contextual importance score word , obtain dependency tree , boost performance . study , propose novel gating mechanism filter noisy information hidden vector gcn model ed base information trigger candidate . introduce novel mechanism achieve contextual diversity gate importance score consistency graph model ed . experiment propose model achieve state - - - art performance ed dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Extraction,SeqMix: Augmenting Active Sequence Labeling via Sequence Mixup,"Active learning is an important technique for low-resource sequence labeling tasks. However, current active sequence labeling methods use the queried samples alone in each iteration, which is an inefficient way of leveraging human annotations. We propose a simple but effective data augmentation method to improve label efficiency of active sequence labeling. Our method, SeqMix, simply augments the queried samples by generating extra labeled sequences in each iteration. The key difficulty is to generate plausible sequences along with token-level labels. In SeqMix, we address this challenge by performing mixup for both sequences and token-level labels of the queried samples. Furthermore, we design a discriminator during sequence mixup, which judges whether the generated sequences are plausible or not. Our experiments on Named Entity Recognition and Event Detection tasks show that SeqMix can improve the standard active sequence labeling method by 2.27%-3.75% in terms of F 1 scores. The code and data for SeqMix can be found at https://github. com/rz-zhang/SeqMix.","SeqMix: Augmenting Active Sequence Labeling via Sequence Mixup Active learning is an important technique for low-resource sequence labeling tasks. However, current active sequence labeling methods use the queried samples alone in each iteration, which is an inefficient way of leveraging human annotations. We propose a simple but effective data augmentation method to improve label efficiency of active sequence labeling. Our method, SeqMix, simply augments the queried samples by generating extra labeled sequences in each iteration. The key difficulty is to generate plausible sequences along with token-level labels. In SeqMix, we address this challenge by performing mixup for both sequences and token-level labels of the queried samples. Furthermore, we design a discriminator during sequence mixup, which judges whether the generated sequences are plausible or not. Our experiments on Named Entity Recognition and Event Detection tasks show that SeqMix can improve the standard active sequence labeling method by 2.27%-3.75% in terms of F 1 scores. The code and data for SeqMix can be found at https://github. com/rz-zhang/SeqMix.","seqmix : augment active sequence labeling sequence mixup active learning important technique low - resource sequence labeling task . , current active sequence labeling method use query sample iteration , inefficient way leverage human annotation . propose simple effective data augmentation method improve label efficiency active sequence labeling . method , seqmix , simply augment query sample generate extra label sequence iteration . key difficulty generate plausible sequence token - level label . seqmix , address challenge perform mixup sequence token - level label query sample . furthermore , design discriminator sequence mixup , judge generate sequence plausible . experiment named entity recognition event detection task seqmix improve standard active sequence labeling method 2.27%-3.75 % term f 1 score . code datum seqmix find https://github . com / rz - zhang / seqmix .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Global-to-Local Neural Networks for Document-Level Relation Extraction,"Relation extraction (RE) aims to identify the semantic relations between named entities in text. Recent years have witnessed it raised to the document level, which requires complex reasoning with entities and mentions throughout an entire document. In this paper, we propose a novel model to document-level RE, by encoding the document information in terms of entity global and local representations as well as context relation representations. Entity global representations model the semantic information of all entities in the document, entity local representations aggregate the contextual information of multiple mentions of specific entities, and context relation representations encode the topic information of other relations. Experimental results demonstrate that our model achieves superior performance on two public datasets for document-level RE. It is particularly effective in extracting relations between entities of long distance and having multiple mentions.","Global-to-Local Neural Networks for Document-Level Relation Extraction Relation extraction (RE) aims to identify the semantic relations between named entities in text. Recent years have witnessed it raised to the document level, which requires complex reasoning with entities and mentions throughout an entire document. In this paper, we propose a novel model to document-level RE, by encoding the document information in terms of entity global and local representations as well as context relation representations. Entity global representations model the semantic information of all entities in the document, entity local representations aggregate the contextual information of multiple mentions of specific entities, and context relation representations encode the topic information of other relations. Experimental results demonstrate that our model achieves superior performance on two public datasets for document-level RE. It is particularly effective in extracting relations between entities of long distance and having multiple mentions.","global - - local neural networks document - level relation extraction relation extraction ( ) aim identify semantic relation name entity text . recent year witness raise document level , require complex reasoning entity mention entire document . paper , propose novel model document - level , encode document information term entity global local representation context relation representation . entity global representation model semantic information entity document , entity local representation aggregate contextual information multiple mention specific entity , context relation representation encode topic information relation . experimental result demonstrate model achieve superior performance public dataset document - level . particularly effective extract relation entity long distance have multiple mention .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 19, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Simple and Effective Few-Shot Named Entity Recognition with Structured Nearest Neighbor Learning,"We present a simple few-shot named entity recognition (NER) system based on nearest neighbor learning and structured inference. Our system uses a supervised NER model trained on the source domain, as a feature extractor. Across several test domains, we show that a nearest neighbor classifier in this featurespace is far more effective than the standard meta-learning approaches. We further propose a cheap but effective method to capture the label dependencies between entity tags without expensive CRF training. We show that our method of combining structured decoding with nearest neighbor learning achieves stateof-the-art performance on standard few-shot NER evaluation tasks, improving F1 scores by 6% to 16% absolute points over prior metalearning based systems.","Simple and Effective Few-Shot Named Entity Recognition with Structured Nearest Neighbor Learning We present a simple few-shot named entity recognition (NER) system based on nearest neighbor learning and structured inference. Our system uses a supervised NER model trained on the source domain, as a feature extractor. Across several test domains, we show that a nearest neighbor classifier in this featurespace is far more effective than the standard meta-learning approaches. We further propose a cheap but effective method to capture the label dependencies between entity tags without expensive CRF training. We show that our method of combining structured decoding with nearest neighbor learning achieves stateof-the-art performance on standard few-shot NER evaluation tasks, improving F1 scores by 6% to 16% absolute points over prior metalearning based systems.","simple effective - shot name entity recognition structured nearest neighbor learning present simple - shot name entity recognition ( ner ) system base near neighbor learning structured inference . system use supervise ner model train source domain , feature extractor . test domain , near neighbor classifier featurespace far effective standard meta - learning approach . propose cheap effective method capture label dependency entity tag expensive crf training . method combine structure decoding near neighbor learning achieve stateof - - art performance standard - shot ner evaluation task , improve f1 score 6 % 16 % absolute point prior metalearning base system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Understanding Procedural Text using Interactive Entity Networks,"The task of procedural text comprehension aims to understand the dynamic nature of entities/objects in a process. Here, the key is to track how the entities interact with each other and how their states are changing along the procedure. Recent efforts have made great progress to track multiple entities in a procedural text, but usually treat each entity separately and ignore the fact that there are often multiple entities interacting with each other during one process, some of which are even explicitly mentioned. In this paper, we propose a novel Interactive Entity Network (IEN), which is a recurrent network with memory equipped cells for state tracking. In each IEN cell, we maintain different attention matrices through specific memories to model different types of entity interactions. Importantly, we can update these memories in a sequential manner so as to explore the causal relationship between entity actions and subsequent state changes. We evaluate our model on a benchmark dataset, and the results show that IEN outperforms stateof-the-art models by precisely capturing the interactions of multiple entities and explicitly leverage the relationship between entity interactions and subsequent state changes. Our code is available at: https://github.com/ esddse/IEN.","Understanding Procedural Text using Interactive Entity Networks The task of procedural text comprehension aims to understand the dynamic nature of entities/objects in a process. Here, the key is to track how the entities interact with each other and how their states are changing along the procedure. Recent efforts have made great progress to track multiple entities in a procedural text, but usually treat each entity separately and ignore the fact that there are often multiple entities interacting with each other during one process, some of which are even explicitly mentioned. In this paper, we propose a novel Interactive Entity Network (IEN), which is a recurrent network with memory equipped cells for state tracking. In each IEN cell, we maintain different attention matrices through specific memories to model different types of entity interactions. Importantly, we can update these memories in a sequential manner so as to explore the causal relationship between entity actions and subsequent state changes. We evaluate our model on a benchmark dataset, and the results show that IEN outperforms stateof-the-art models by precisely capturing the interactions of multiple entities and explicitly leverage the relationship between entity interactions and subsequent state changes. Our code is available at: https://github.com/ esddse/IEN.","understand procedural text interactive entity networks task procedural text comprehension aim understand dynamic nature entity / object process . , key track entity interact state change procedure . recent effort great progress track multiple entity procedural text , usually treat entity separately ignore fact multiple entity interact process , explicitly mention . paper , propose novel interactive entity network ( ien ) , recurrent network memory equip cell state tracking . ien cell , maintain different attention matrix specific memory model different type entity interaction . importantly , update memory sequential manner explore causal relationship entity action subsequent state change . evaluate model benchmark dataset , result ien outperform stateof - - art model precisely capture interaction multiple entity explicitly leverage relationship entity interaction subsequent state change . code available : https://github.com/ esddse / ien .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,MAVEN: A Massive General Domain Event Detection Dataset,"Event detection (ED), which means identifying event trigger words and classifying event types, is the first and most fundamental step for extracting event knowledge from plain text. Most existing datasets exhibit the following issues that limit further development of ED: (1) Data scarcity. Existing smallscale datasets are not sufficient for training and stably benchmarking increasingly sophisticated modern neural methods. (2) Low coverage. Limited event types of existing datasets cannot well cover general-domain events, which restricts the applications of ED models. To alleviate these problems, we present a MAssive eVENt detection dataset (MAVEN), which contains 4, 480 Wikipedia documents, 118, 732 event mention instances, and 168 event types. MAVEN alleviates the data scarcity problem and covers much more general event types. We reproduce the recent state-of-the-art ED models and conduct a thorough evaluation on MAVEN. The experimental results show that existing ED methods cannot achieve promising results on MAVEN as on the small datasets, which suggests that ED in the real world remains a challenging task and requires further research efforts. We also discuss further directions for general domain ED with empirical analyses. The source code and dataset can be obtained from https:// github.com/THU-KEG/MAVEN-dataset.","MAVEN: A Massive General Domain Event Detection Dataset Event detection (ED), which means identifying event trigger words and classifying event types, is the first and most fundamental step for extracting event knowledge from plain text. Most existing datasets exhibit the following issues that limit further development of ED: (1) Data scarcity. Existing smallscale datasets are not sufficient for training and stably benchmarking increasingly sophisticated modern neural methods. (2) Low coverage. Limited event types of existing datasets cannot well cover general-domain events, which restricts the applications of ED models. To alleviate these problems, we present a MAssive eVENt detection dataset (MAVEN), which contains 4, 480 Wikipedia documents, 118, 732 event mention instances, and 168 event types. MAVEN alleviates the data scarcity problem and covers much more general event types. We reproduce the recent state-of-the-art ED models and conduct a thorough evaluation on MAVEN. The experimental results show that existing ED methods cannot achieve promising results on MAVEN as on the small datasets, which suggests that ED in the real world remains a challenging task and requires further research efforts. We also discuss further directions for general domain ED with empirical analyses. The source code and dataset can be obtained from https:// github.com/THU-KEG/MAVEN-dataset.","maven : massive general domain event detection dataset event detection ( ed ) , mean identify event trigger word classify event type , fundamental step extract event knowledge plain text . exist dataset exhibit follow issue limit development ed : ( 1 ) datum scarcity . exist smallscale dataset sufficient train stably benchmarke increasingly sophisticated modern neural method . ( 2 ) low coverage . limited event type exist dataset cover general - domain event , restrict application ed model . alleviate problem , present massive event detection dataset ( maven ) , contain 4 , 480 wikipedia document , 118 , 732 event mention instance , 168 event type . maven alleviate datum scarcity problem cover general event type . reproduce recent state - - - art ed model conduct thorough evaluation maven . experimental result exist ed method achieve promising result maven small dataset , suggest ed real world remain challenging task require research effort . discuss direction general domain ed empirical analysis . source code dataset obtain https:// github.com/thu-keg/maven-dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Biomedical Event Extraction as Sequence Labeling,"We introduce Biomedical Event Extraction as Sequence Labeling (BEESL), a joint endto-end neural information extraction model. BEESL recasts the task as sequence labeling, taking advantage of a multi-label aware encoding strategy and jointly modeling the intermediate tasks via multi-task learning. BEESL is fast, accurate, end-to-end, and unlike current methods does not require any external knowledge base or preprocessing tools. BEESL outperforms the current best system (Li et al., 2019) on the Genia 2011 benchmark by 1.57% absolute F1 score reaching 60.22% F1, establishing a new state of the art for the task. Importantly, we also provide first results on biomedical event extraction without gold entity information. Empirical results show that BEESL's speed and accuracy makes it a viable approach for large-scale real-world scenarios. 1","Biomedical Event Extraction as Sequence Labeling We introduce Biomedical Event Extraction as Sequence Labeling (BEESL), a joint endto-end neural information extraction model. BEESL recasts the task as sequence labeling, taking advantage of a multi-label aware encoding strategy and jointly modeling the intermediate tasks via multi-task learning. BEESL is fast, accurate, end-to-end, and unlike current methods does not require any external knowledge base or preprocessing tools. BEESL outperforms the current best system (Li et al., 2019) on the Genia 2011 benchmark by 1.57% absolute F1 score reaching 60.22% F1, establishing a new state of the art for the task. Importantly, we also provide first results on biomedical event extraction without gold entity information. Empirical results show that BEESL's speed and accuracy makes it a viable approach for large-scale real-world scenarios. 1","biomedical event extraction sequence labeling introduce biomedical event extraction sequence labeling ( beesl ) , joint endto - end neural information extraction model . beesl recast task sequence labeling , take advantage multi - label aware encoding strategy jointly model intermediate task multi - task learning . beesl fast , accurate , end - - end , unlike current method require external knowledge base preprocessing tool . beesl outperform current good system ( li et al . , 2019 ) genia 2011 benchmark 1.57 % absolute f1 score reach 60.22 % f1 , establish new state art task . importantly , provide result biomedical event extraction gold entity information . empirical result beesl speed accuracy make viable approach large - scale real - world scenario . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion,"Inferring missing facts in temporal knowledge graphs (TKGs) is a fundamental and challenging task. Previous works have approached this problem by augmenting methods for static knowledge graphs to leverage time-dependent representations. However, these methods do not explicitly leverage multi-hop structural information and temporal facts from recent time steps to enhance their predictions. Additionally, prior work does not explicitly address the temporal sparsity and variability of entity distributions in TKGs. We propose the Temporal Message Passing (TeMP) framework to address these challenges by combining graph neural networks, temporal dynamics models, data imputation and frequency-based gating techniques. Experiments 1 on standard TKG tasks show that our approach provides substantial gains compared to the previous state of the art, achieving a 10.7% average relative improvement in Hits@10 across three standard benchmarks. Our analysis also reveals important sources of variability both within and across TKG datasets, and we introduce several simple but strong baselines that outperform the prior state of the art in certain settings.","TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion Inferring missing facts in temporal knowledge graphs (TKGs) is a fundamental and challenging task. Previous works have approached this problem by augmenting methods for static knowledge graphs to leverage time-dependent representations. However, these methods do not explicitly leverage multi-hop structural information and temporal facts from recent time steps to enhance their predictions. Additionally, prior work does not explicitly address the temporal sparsity and variability of entity distributions in TKGs. We propose the Temporal Message Passing (TeMP) framework to address these challenges by combining graph neural networks, temporal dynamics models, data imputation and frequency-based gating techniques. Experiments 1 on standard TKG tasks show that our approach provides substantial gains compared to the previous state of the art, achieving a 10.7% average relative improvement in Hits@10 across three standard benchmarks. Our analysis also reveals important sources of variability both within and across TKG datasets, and we introduce several simple but strong baselines that outperform the prior state of the art in certain settings.","temp : temporal message passing temporal knowledge graph completion infer miss fact temporal knowledge graph ( tkgs ) fundamental challenging task . previous work approach problem augment method static knowledge graph leverage time - dependent representation . , method explicitly leverage multi - hop structural information temporal fact recent time step enhance prediction . additionally , prior work explicitly address temporal sparsity variability entity distribution tkgs . propose temporal message passing ( temp ) framework address challenge combine graph neural network , temporal dynamic model , datum imputation frequency - base gating technique . experiment 1 standard tkg task approach provide substantial gain compare previous state art , achieve 10.7 % average relative improvement hits@10 standard benchmark . analysis reveal important source variability tkg dataset , introduce simple strong baseline outperform prior state art certain setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Information Extraction,Introducing a New Dataset for Event Detection in Cybersecurity Texts,"Detecting cybersecurity events is necessary to keep us informed about the fast growing number of such events reported in text. In this work, we focus on the task of event detection (ED) to identify event trigger words for the cybersecurity domain. In particular, to facilitate the future research, we introduce a new dataset for this problem, characterizing the manual annotation for 30 important cybersecurity event types and a large dataset size to develop deep learning models. Comparing to the prior datasets for this task, our dataset involves more event types and supports the modeling of document-level information to improve the performance. We perform extensive evaluation with the current state-of-the-art methods for ED on the proposed dataset. Our experiments reveal the challenges of cybersecurity ED and present many research opportunities in this area for the future work.","Introducing a New Dataset for Event Detection in Cybersecurity Texts Detecting cybersecurity events is necessary to keep us informed about the fast growing number of such events reported in text. In this work, we focus on the task of event detection (ED) to identify event trigger words for the cybersecurity domain. In particular, to facilitate the future research, we introduce a new dataset for this problem, characterizing the manual annotation for 30 important cybersecurity event types and a large dataset size to develop deep learning models. Comparing to the prior datasets for this task, our dataset involves more event types and supports the modeling of document-level information to improve the performance. We perform extensive evaluation with the current state-of-the-art methods for ED on the proposed dataset. Our experiments reveal the challenges of cybersecurity ED and present many research opportunities in this area for the future work.","introduce new dataset event detection cybersecurity text detect cybersecurity event necessary inform fast grow number event report text . work , focus task event detection ( ed ) identify event trigger word cybersecurity domain . particular , facilitate future research , introduce new dataset problem , characterize manual annotation 30 important cybersecurity event type large dataset size develop deep learning model . compare prior dataset task , dataset involve event type support modeling document - level information improve performance . perform extensive evaluation current state - - - art method ed propose dataset . experiment reveal challenge cybersecurity ed present research opportunity area future work .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Information Extraction,"Exploring and Evaluating Attributes, Values, and Structures for Entity Alignment","Entity alignment (EA) aims at building a unified Knowledge Graph (KG) of rich content by linking the equivalent entities from various KGs. GNN-based EA methods present promising performance by modeling the KG structure defined by relation triples. However, attribute triples can also provide crucial alignment signal but have not been well explored yet. In this paper, we propose to utilize an attributed value encoder and partition the KG into subgraphs to model the various types of attribute triples efficiently. Besides, the performances of current EA methods are overestimated because of the name-bias of existing EA datasets. To make an objective evaluation, we propose a hard experimental setting where we select equivalent entity pairs with very different names as the test set. Under both the regular and hard settings, our method achieves significant improvements (5.10% on average Hits@1 in DBP15k) over 12 baselines in crosslingual and monolingual datasets. Ablation studies on different subgraphs and a case study about attribute types further demonstrate the effectiveness of our method. Source code and data can be found at https://github.com/ thunlp/explore-and-evaluate.","Exploring and Evaluating Attributes, Values, and Structures for Entity Alignment Entity alignment (EA) aims at building a unified Knowledge Graph (KG) of rich content by linking the equivalent entities from various KGs. GNN-based EA methods present promising performance by modeling the KG structure defined by relation triples. However, attribute triples can also provide crucial alignment signal but have not been well explored yet. In this paper, we propose to utilize an attributed value encoder and partition the KG into subgraphs to model the various types of attribute triples efficiently. Besides, the performances of current EA methods are overestimated because of the name-bias of existing EA datasets. To make an objective evaluation, we propose a hard experimental setting where we select equivalent entity pairs with very different names as the test set. Under both the regular and hard settings, our method achieves significant improvements (5.10% on average Hits@1 in DBP15k) over 12 baselines in crosslingual and monolingual datasets. Ablation studies on different subgraphs and a case study about attribute types further demonstrate the effectiveness of our method. Source code and data can be found at https://github.com/ thunlp/explore-and-evaluate.","explore evaluate attribute , value , structures entity alignment entity alignment ( ea ) aim build unified knowledge graph ( kg ) rich content link equivalent entity kg . gnn - base ea method present promising performance model kg structure define relation triple . , attribute triple provide crucial alignment signal explore . paper , propose utilize attribute value encoder partition kg subgraph model type attribute triple efficiently . , performance current ea method overestimate - bias exist ea dataset . objective evaluation , propose hard experimental setting select equivalent entity pair different name test set . regular hard setting , method achieve significant improvement ( 5.10 % average hits@1 dbp15k ) 12 baseline crosslingual monolingual dataset . ablation study different subgraph case study attribute type demonstrate effectiveness method . source code datum find https://github.com/ thunlp / explore - - evaluate .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Multimodal Joint Attribute Prediction and Value Extraction for E-commerce Product,"Product attribute values are essential in many e-commerce scenarios, such as customer service robots, product recommendations, and product retrieval. While in the real world, the attribute values of a product are usually incomplete and vary over time, which greatly hinders the practical applications. In this paper, we propose a multimodal method to jointly predict product attributes and extract values from textual product descriptions with the help of the product images. We argue that product attributes and values are highly correlated, e.g., it will be easier to extract the values on condition that the product attributes are given. Thus, we jointly model the attribute prediction and value extraction tasks from multiple aspects towards the interactions between attributes and values. Moreover, product images have distinct effects on our tasks for different product attributes and values. Thus, we selectively draw useful visual information from product images to enhance our model. We annotate a multimodal product attribute value dataset that contains 87,194 instances, and the experimental results on this dataset demonstrate that explicitly modeling the relationship between attributes and values facilitates our method to establish the correspondence between them, and selectively utilizing visual product information is necessary for the task. Our code and dataset are available at https://github. com/jd-aig/JAVE.","Multimodal Joint Attribute Prediction and Value Extraction for E-commerce Product Product attribute values are essential in many e-commerce scenarios, such as customer service robots, product recommendations, and product retrieval. While in the real world, the attribute values of a product are usually incomplete and vary over time, which greatly hinders the practical applications. In this paper, we propose a multimodal method to jointly predict product attributes and extract values from textual product descriptions with the help of the product images. We argue that product attributes and values are highly correlated, e.g., it will be easier to extract the values on condition that the product attributes are given. Thus, we jointly model the attribute prediction and value extraction tasks from multiple aspects towards the interactions between attributes and values. Moreover, product images have distinct effects on our tasks for different product attributes and values. Thus, we selectively draw useful visual information from product images to enhance our model. We annotate a multimodal product attribute value dataset that contains 87,194 instances, and the experimental results on this dataset demonstrate that explicitly modeling the relationship between attributes and values facilitates our method to establish the correspondence between them, and selectively utilizing visual product information is necessary for the task. Our code and dataset are available at https://github. com/jd-aig/JAVE.","multimodal joint attribute prediction value extraction e - commerce product product attribute value essential e - commerce scenario , customer service robot , product recommendation , product retrieval . real world , attribute value product usually incomplete vary time , greatly hinder practical application . paper , propose multimodal method jointly predict product attribute extract value textual product description help product image . argue product attribute value highly correlated , e.g. , easy extract value condition product attribute give . , jointly model attribute prediction value extraction task multiple aspect interaction attribute value . , product image distinct effect task different product attribute value . , selectively draw useful visual information product image enhance model . annotate multimodal product attribute value dataset contain 87,194 instance , experimental result dataset demonstrate explicitly model relationship attribute value facilitate method establish correspondence , selectively utilize visual product information necessary task . code dataset available https://github . com / jd - aig / jave .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 8, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Information Extraction,Knowledge Graph Alignment with Entity-Pair Embedding,"Knowledge Graph (KG) alignment is to match entities in different KGs, which is important to knowledge fusion and integration. Recently, a number of embedding-based approaches for KG alignment have been proposed and achieved promising results. These approaches first embed entities in low-dimensional vector spaces, and then obtain entity alignments by computations on their vector representations. Although continuous improvements have been achieved by recent work, the performances of existing approaches are still not satisfactory. In this work, we present a new approach that directly learns embeddings of entity-pairs for KG alignment. Our approach first generates a pair-wise connectivity graph (PCG) of two KGs, whose nodes are entitypairs and edges correspond to relation-pairs; it then learns node (entity-pair) embeddings of the PCG, which are used to predict equivalent relations of entities. To get desirable embeddings, a convolutional neural network is used to generate similarity features of entity-pairs from their attributes; and a graph neural network is employed to propagate the similarity features and get the final embeddings of entitypairs. Experiments on five real-world datasets show that our approach can achieve the stateof-the-art KG alignment results.","Knowledge Graph Alignment with Entity-Pair Embedding Knowledge Graph (KG) alignment is to match entities in different KGs, which is important to knowledge fusion and integration. Recently, a number of embedding-based approaches for KG alignment have been proposed and achieved promising results. These approaches first embed entities in low-dimensional vector spaces, and then obtain entity alignments by computations on their vector representations. Although continuous improvements have been achieved by recent work, the performances of existing approaches are still not satisfactory. In this work, we present a new approach that directly learns embeddings of entity-pairs for KG alignment. Our approach first generates a pair-wise connectivity graph (PCG) of two KGs, whose nodes are entitypairs and edges correspond to relation-pairs; it then learns node (entity-pair) embeddings of the PCG, which are used to predict equivalent relations of entities. To get desirable embeddings, a convolutional neural network is used to generate similarity features of entity-pairs from their attributes; and a graph neural network is employed to propagate the similarity features and get the final embeddings of entitypairs. Experiments on five real-world datasets show that our approach can achieve the stateof-the-art KG alignment results.","knowledge graph alignment entity - pair embedding knowledge graph ( kg ) alignment match entity different kg , important knowledge fusion integration . recently , number embedding - base approach kg alignment propose achieve promising result . approach embed entity low - dimensional vector space , obtain entity alignment computation vector representation . continuous improvement achieve recent work , performance exist approach satisfactory . work , present new approach directly learn embedding entity - pair kg alignment . approach generate pair - wise connectivity graph ( pcg ) kg , node entitypair edge correspond relation - pair ; learn node ( entity - pair ) embedding pcg , predict equivalent relation entity . desirable embedding , convolutional neural network generate similarity feature entity - pair attribute ; graph neural network employ propagate similarity feature final embedding entitypair . experiment real - world dataset approach achieve stateof - - art kg alignment result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Double Graph Based Reasoning for Document-level Relation Extraction,"Document-level relation extraction aims to extract relations among entities within a document. Different from sentence-level relation extraction, it requires reasoning over multiple sentences across paragraphs. In this paper, we propose Graph Aggregation-and-Inference Network (GAIN), a method to recognize such relations for long paragraphs. GAIN constructs two graphs, a heterogeneous mentionlevel graph (MG) and an entity-level graph (EG). The former captures complex interaction among different mentions and the latter aggregates mentions underlying for the same entities. Based on the graphs we propose a novel path reasoning mechanism to infer relations between entities. Experiments on the public dataset, DocRED, show GAIN achieves a significant performance improvement (2.85 on F1) over the previous state-of-the-art. Our code is available at https://github.com/ PKUnlp-icler/GAIN.","Double Graph Based Reasoning for Document-level Relation Extraction Document-level relation extraction aims to extract relations among entities within a document. Different from sentence-level relation extraction, it requires reasoning over multiple sentences across paragraphs. In this paper, we propose Graph Aggregation-and-Inference Network (GAIN), a method to recognize such relations for long paragraphs. GAIN constructs two graphs, a heterogeneous mentionlevel graph (MG) and an entity-level graph (EG). The former captures complex interaction among different mentions and the latter aggregates mentions underlying for the same entities. Based on the graphs we propose a novel path reasoning mechanism to infer relations between entities. Experiments on the public dataset, DocRED, show GAIN achieves a significant performance improvement (2.85 on F1) over the previous state-of-the-art. Our code is available at https://github.com/ PKUnlp-icler/GAIN.","double graph base reasoning document - level relation extraction document - level relation extraction aim extract relation entity document . different sentence - level relation extraction , require reason multiple sentence paragraph . paper , propose graph aggregation - - inference network ( gain ) , method recognize relation long paragraph . gain construct graph , heterogeneous mentionlevel graph ( mg ) entity - level graph ( eg ) . capture complex interaction different mention aggregate mention underlie entity . base graph propose novel path reasoning mechanism infer relation entity . experiment public dataset , docred , gain achieve significant performance improvement ( 2.85 f1 ) previous state - - - art . code available https://github.com/ pkunlp - icler / gain .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 13, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Joint Constrained Learning for Event-Event Relation Extraction,"Understanding natural language involves recognizing how multiple event mentions structurally and temporally interact with each other. In this process, one can induce event complexes that organize multi-granular events with temporal order and membership relations interweaving among them. Due to the lack of jointly labeled data for these relational phenomena and the restriction on the structures they articulate, we propose a joint constrained learning framework for modeling event-event relations. Specifically, the framework enforces logical constraints within and across multiple temporal and subevent relations by converting these constraints into differentiable learning objectives. We show that our joint constrained learning approach effectively compensates for the lack of jointly labeled data, and outperforms SOTA methods on benchmarks for both temporal relation extraction and event hierarchy construction, replacing a commonly used but more expensive global inference process. We also present a promising case study showing the effectiveness of our approach in inducing event complexes on an external corpus. 1","Joint Constrained Learning for Event-Event Relation Extraction Understanding natural language involves recognizing how multiple event mentions structurally and temporally interact with each other. In this process, one can induce event complexes that organize multi-granular events with temporal order and membership relations interweaving among them. Due to the lack of jointly labeled data for these relational phenomena and the restriction on the structures they articulate, we propose a joint constrained learning framework for modeling event-event relations. Specifically, the framework enforces logical constraints within and across multiple temporal and subevent relations by converting these constraints into differentiable learning objectives. We show that our joint constrained learning approach effectively compensates for the lack of jointly labeled data, and outperforms SOTA methods on benchmarks for both temporal relation extraction and event hierarchy construction, replacing a commonly used but more expensive global inference process. We also present a promising case study showing the effectiveness of our approach in inducing event complexes on an external corpus. 1","joint constrained learning event - event relation extraction understand natural language involve recognize multiple event mention structurally temporally interact . process , induce event complex organize multi - granular event temporal order membership relation interweave . lack jointly label datum relational phenomenon restriction structure articulate , propose joint constrain learning framework model event - event relation . specifically , framework enforce logical constraint multiple temporal subevent relation convert constraint differentiable learning objective . joint constrain learning approach effectively compensate lack jointly label datum , outperform sota method benchmark temporal relation extraction event hierarchy construction , replace commonly expensive global inference process . present promising case study show effectiveness approach induce event complex external corpus . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Extraction,True
Information Extraction,Knowledge-guided Open Attribute Value Extraction with Reinforcement Learning,"Open attribute value extraction for emerging entities is an important but challenging task. A lot of previous works formulate the problem as a question-answering (QA) task. While the collections of articles from web corpus provide updated information about the emerging entities, the retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers. Effectively filtering out noisy articles as well as bad answers is the key to improving extraction accuracy. Knowledge graph (KG), which contains rich, well organized information about entities, provides a good resource to address the challenge. In this work, we propose a knowledge-guided reinforcement learning (RL) framework for open attribute value extraction. Informed by relevant knowledge in KG, we trained a deep Q-network to sequentially compare extracted answers to improve extraction accuracy. The proposed framework is applicable to different information extraction system. Our experimental results show that our method outperforms the baselines by 16.5 -27.8%. * Ye Liu and Sheng Zhang contributed equally. † Rui Song and Yanghua Xiao are corresponding authors.","Knowledge-guided Open Attribute Value Extraction with Reinforcement Learning Open attribute value extraction for emerging entities is an important but challenging task. A lot of previous works formulate the problem as a question-answering (QA) task. While the collections of articles from web corpus provide updated information about the emerging entities, the retrieved texts can be noisy, irrelevant, thus leading to inaccurate answers. Effectively filtering out noisy articles as well as bad answers is the key to improving extraction accuracy. Knowledge graph (KG), which contains rich, well organized information about entities, provides a good resource to address the challenge. In this work, we propose a knowledge-guided reinforcement learning (RL) framework for open attribute value extraction. Informed by relevant knowledge in KG, we trained a deep Q-network to sequentially compare extracted answers to improve extraction accuracy. The proposed framework is applicable to different information extraction system. Our experimental results show that our method outperforms the baselines by 16.5 -27.8%. * Ye Liu and Sheng Zhang contributed equally. † Rui Song and Yanghua Xiao are corresponding authors.","knowledge - guide open attribute value extraction reinforcement learning open attribute value extraction emerge entity important challenging task . lot previous work formulate problem question - answer ( qa ) task . collection article web corpus provide update information emerge entity , retrieve text noisy , irrelevant , lead inaccurate answer . effectively filter noisy article bad answer key improve extraction accuracy . knowledge graph ( kg ) , contain rich , organize information entity , provide good resource address challenge . work , propose knowledge - guide reinforcement learning ( rl ) framework open attribute value extraction . inform relevant knowledge kg , train deep q - network sequentially compare extract answer improve extraction accuracy . propose framework applicable different information extraction system . experimental result method outperform baseline 16.5 -27.8 % . * ye liu sheng zhang contribute equally . † rui song yanghua xiao correspond author .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 6, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Knowledge Association with Hyperbolic Knowledge Graph Embeddings,"Capturing associations for knowledge graphs (KGs) through entity alignment, entity type inference and other related tasks benefits NLP applications with comprehensive knowledge representations. Recent related methods built on Euclidean embeddings are challenged by the hierarchical structures and different scales of KGs. They also depend on high embedding dimensions to realize enough expressiveness. Differently, we explore with low-dimensional hyperbolic embeddings for knowledge association. We propose a hyperbolic relational graph neural network for KG embedding and capture knowledge associations with a hyperbolic transformation. Extensive experiments on entity alignment and type inference demonstrate the effectiveness and efficiency of our method.","Knowledge Association with Hyperbolic Knowledge Graph Embeddings Capturing associations for knowledge graphs (KGs) through entity alignment, entity type inference and other related tasks benefits NLP applications with comprehensive knowledge representations. Recent related methods built on Euclidean embeddings are challenged by the hierarchical structures and different scales of KGs. They also depend on high embedding dimensions to realize enough expressiveness. Differently, we explore with low-dimensional hyperbolic embeddings for knowledge association. We propose a hyperbolic relational graph neural network for KG embedding and capture knowledge associations with a hyperbolic transformation. Extensive experiments on entity alignment and type inference demonstrate the effectiveness and efficiency of our method.","knowledge association hyperbolic knowledge graph embedding capture association knowledge graph ( kgs ) entity alignment , entity type inference related task benefit nlp application comprehensive knowledge representation . recent related method build euclidean embedding challenge hierarchical structure different scale kg . depend high embedding dimension realize expressiveness . differently , explore low - dimensional hyperbolic embedding knowledge association . propose hyperbolic relational graph neural network kg embedding capture knowledge association hyperbolic transformation . extensive experiment entity alignment type inference demonstrate effectiveness efficiency method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,CHARM: Inferring Personal Attributes from Conversations,"Personal knowledge about users' professions, hobbies, favorite food, and travel preferences, among others, is a valuable asset for individualized AI, such as recommenders or chatbots. Conversations in social media, such as Reddit, are a rich source of data for inferring personal facts. Prior work developed supervised methods to extract this knowledge, but these approaches can not generalize beyond attribute values with ample labeled training samples. This paper overcomes this limitation by devising CHARM: a zero-shot learning method that creatively leverages keyword extraction and document retrieval in order to predict attribute values that were never seen during training. Experiments with large datasets from Reddit show the viability of CHARM for open-ended attributes, such as professions and hobbies.","CHARM: Inferring Personal Attributes from Conversations Personal knowledge about users' professions, hobbies, favorite food, and travel preferences, among others, is a valuable asset for individualized AI, such as recommenders or chatbots. Conversations in social media, such as Reddit, are a rich source of data for inferring personal facts. Prior work developed supervised methods to extract this knowledge, but these approaches can not generalize beyond attribute values with ample labeled training samples. This paper overcomes this limitation by devising CHARM: a zero-shot learning method that creatively leverages keyword extraction and document retrieval in order to predict attribute values that were never seen during training. Experiments with large datasets from Reddit show the viability of CHARM for open-ended attributes, such as professions and hobbies.","charm : infer personal attribute conversation personal knowledge user ' profession , hobby , favorite food , travel preference , , valuable asset individualized ai , recommender chatbot . conversation social medium , reddit , rich source datum infer personal fact . prior work develop supervise method extract knowledge , approach generalize attribute value ample label training sample . paper overcome limitation devise charm : zero - shot learning method creatively leverage keyword extraction document retrieval order predict attribute value see training . experiment large dataset reddit viability charm open - ended attribute , profession hobby .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Information Extraction,A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression,"Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a platform for all OIE strategies. The OIX is an OIE friendly expression of a sentence without information loss. The generation procedure of OIX contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of OIX as inference operations focusing on more critical problems. Based on the same platform of OIX, the OIE strategies are reusable, and people can select a set of strategies to assemble their algorithm for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution -Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.","A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new pipeline to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a platform for all OIE strategies. The OIX is an OIE friendly expression of a sentence without information loss. The generation procedure of OIX contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of OIX as inference operations focusing on more critical problems. Based on the same platform of OIX, the OIE strategies are reusable, and people can select a set of strategies to assemble their algorithm for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution -Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.","predicate - function - argument annotation natural language open - domain information expression exist oie ( open information extraction ) algorithm independent exist lot redundant work ; feature strategy reusable adaptive new task . paper propose new pipeline build oie system , open - domain information expression ( oix ) task propose provide platform oie strategy . oix oie friendly expression sentence information loss . generation procedure oix contain share work oie algorithm oie strategy develop platform oix inference operation focus critical problem . base platform oix , oie strategy reusable , people select set strategy assemble algorithm specific task adaptability significantly increase . paper focus task oix propose solution -open information annotation ( oia ) . oia predicate - function - argument annotation sentence . label data set sentence - oia pair propose dependency - base rule system generate oia annotation sentence . evaluation result reveal learn oia sentence challenge owe complexity natural language sentence , worthy attract attention research community .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Information Extraction,Coarse-to-Fine Pre-training for Named Entity Recognition,"More recently, Named Entity Recognition has achieved great advances aided by pre-training approaches such as BERT. However, current pre-training techniques focus on building language modeling objectives to learn a general representation, ignoring the named entityrelated knowledge. To this end, we propose a NER-specific pre-training framework to inject coarse-to-fine automatically mined entity knowledge into pre-trained models. Specifically, we first warm-up the model via an entity span identification task by training it with Wikipedia anchors, which can be deemed as general-typed entities. Then we leverage the gazetteer-based distant supervision strategy to train the model extract coarse-grained typed entities. Finally, we devise a self-supervised auxiliary task to mine the fine-grained named entity knowledge via clustering. Empirical studies on three public NER datasets demonstrate that our framework achieves significant improvements against several pre-trained baselines, establishing the new state-of-the-art performance on three benchmarks. Besides, we show that our framework gains promising results without using human-labeled training data, demonstrating its effectiveness in labelfew and low-resource scenarios. 1","Coarse-to-Fine Pre-training for Named Entity Recognition More recently, Named Entity Recognition has achieved great advances aided by pre-training approaches such as BERT. However, current pre-training techniques focus on building language modeling objectives to learn a general representation, ignoring the named entityrelated knowledge. To this end, we propose a NER-specific pre-training framework to inject coarse-to-fine automatically mined entity knowledge into pre-trained models. Specifically, we first warm-up the model via an entity span identification task by training it with Wikipedia anchors, which can be deemed as general-typed entities. Then we leverage the gazetteer-based distant supervision strategy to train the model extract coarse-grained typed entities. Finally, we devise a self-supervised auxiliary task to mine the fine-grained named entity knowledge via clustering. Empirical studies on three public NER datasets demonstrate that our framework achieves significant improvements against several pre-trained baselines, establishing the new state-of-the-art performance on three benchmarks. Besides, we show that our framework gains promising results without using human-labeled training data, demonstrating its effectiveness in labelfew and low-resource scenarios. 1","coarse - - fine pre - training name entity recognition recently , named entity recognition achieve great advance aid pre - training approach bert . , current pre - training technique focus build language modeling objective learn general representation , ignore name entityrelated knowledge . end , propose ner - specific pre - training framework inject coarse - - fine automatically mine entity knowledge pre - trained model . specifically , warm - model entity span identification task train wikipedia anchor , deem general - typed entity . leverage gazetteer - base distant supervision strategy train model extract coarse - grained type entity . finally , devise self - supervise auxiliary task fine - grained name entity knowledge clustering . empirical study public ner dataset demonstrate framework achieve significant improvement pre - trained baseline , establish new state - - - art performance benchmark . , framework gain promising result human - label training datum , demonstrate effectiveness labelfew low - resource scenario . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 23, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Event Extraction by Answering (Almost) Natural Questions,"The problem of event extraction requires detecting the event trigger and extracting its corresponding arguments. Existing work in event argument extraction typically relies heavily on entity recognition as a preprocessing/concurrent step, causing the well-known problem of error propagation. To avoid this issue, we introduce a new paradigm for event extraction by formulating it as a question answering (QA) task that extracts the event arguments in an end-to-end manner. Empirical results demonstrate that our framework outperforms prior methods substantially; in addition, it is capable of extracting event arguments for roles not seen at training time (i.e., in a zeroshot learning setting). 1","Event Extraction by Answering (Almost) Natural Questions The problem of event extraction requires detecting the event trigger and extracting its corresponding arguments. Existing work in event argument extraction typically relies heavily on entity recognition as a preprocessing/concurrent step, causing the well-known problem of error propagation. To avoid this issue, we introduce a new paradigm for event extraction by formulating it as a question answering (QA) task that extracts the event arguments in an end-to-end manner. Empirical results demonstrate that our framework outperforms prior methods substantially; in addition, it is capable of extracting event arguments for roles not seen at training time (i.e., in a zeroshot learning setting). 1","event extraction answer ( ) natural question problem event extraction require detect event trigger extract corresponding argument . exist work event argument extraction typically rely heavily entity recognition preprocessing / concurrent step , cause - know problem error propagation . avoid issue , introduce new paradigm event extraction formulate question answer ( qa ) task extract event argument end - - end manner . empirical result demonstrate framework outperform prior method substantially ; addition , capable extract event argument role see training time ( i.e. , zeroshot learning setting ) . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 6, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 9, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Dynamic Anticipation and Completion for Multi-Hop Reasoning over Sparse Knowledge Graph,"Multi-hop reasoning has been widely studied in recent years to seek an effective and interpretable method for knowledge graph (KG) completion. Most previous reasoning methods are designed for dense KGs with enough paths between entities, but cannot work well on those sparse KGs that only contain sparse paths for reasoning. On the one hand, sparse KGs contain less information, which makes it difficult for the model to choose correct paths. On the other hand, the lack of evidential paths to target entities also makes the reasoning process difficult. To solve these problems, we propose a multi-hop reasoning model named DacKGR over sparse KGs, by applying novel dynamic anticipation and completion strategies: (1) The anticipation strategy utilizes the latent prediction of embeddingbased models to make our model perform more potential path search over sparse KGs. (2) Based on the anticipation information, the completion strategy dynamically adds edges as additional actions during the path search, which further alleviates the sparseness problem of KGs. The experimental results on five datasets sampled from Freebase, NELL and Wikidata show that our method outperforms state-of-the-art baselines. Our codes and datasets can be obtained from https:// github.com/THU-KEG/DacKGR.","Dynamic Anticipation and Completion for Multi-Hop Reasoning over Sparse Knowledge Graph Multi-hop reasoning has been widely studied in recent years to seek an effective and interpretable method for knowledge graph (KG) completion. Most previous reasoning methods are designed for dense KGs with enough paths between entities, but cannot work well on those sparse KGs that only contain sparse paths for reasoning. On the one hand, sparse KGs contain less information, which makes it difficult for the model to choose correct paths. On the other hand, the lack of evidential paths to target entities also makes the reasoning process difficult. To solve these problems, we propose a multi-hop reasoning model named DacKGR over sparse KGs, by applying novel dynamic anticipation and completion strategies: (1) The anticipation strategy utilizes the latent prediction of embeddingbased models to make our model perform more potential path search over sparse KGs. (2) Based on the anticipation information, the completion strategy dynamically adds edges as additional actions during the path search, which further alleviates the sparseness problem of KGs. The experimental results on five datasets sampled from Freebase, NELL and Wikidata show that our method outperforms state-of-the-art baselines. Our codes and datasets can be obtained from https:// github.com/THU-KEG/DacKGR.","dynamic anticipation completion multi - hop reasoning sparse knowledge graph multi - hop reasoning widely study recent year seek effective interpretable method knowledge graph ( kg ) completion . previous reasoning method design dense kg path entity , work sparse kg contain sparse path reason . hand , sparse kgs contain information , make difficult model choose correct path . hand , lack evidential path target entity make reasoning process difficult . solve problem , propose multi - hop reasoning model name dackgr sparse kg , apply novel dynamic anticipation completion strategy : ( 1 ) anticipation strategy utilize latent prediction embeddingbase model model perform potential path search sparse kg . ( 2 ) base anticipation information , completion strategy dynamically add edge additional action path search , alleviate sparseness problem kg . experimental result dataset sample freebase , nell wikidata method outperform state - - - art baseline . code dataset obtain https:// github.com/thu-keg/dackgr .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,Systematic Comparison of Neural Architectures and Training Approaches for Open Information Extraction,"The goal of open information extraction (OIE) is to extract facts from natural language text, and to represent them as structured triples of the form subject, predicate, object . For example, given the sentence »Beethoven composed the Ode to Joy.«, we are expected to extract the triple Beethoven, composed, Ode to Joy . In this work, we systematically compare different neural network architectures and training approaches, and improve the performance of the currently best models on the OIE16 benchmark (Stanovsky and Dagan, 2016) by 0.421 F 1 score and 0.420 AUC-PR, respectively, in our experiments (i.e., by more than 200% in both cases). Furthermore, we show that appropriate problem and loss formulations often affect the performance more than the network architecture. * * Equal contribution.","Systematic Comparison of Neural Architectures and Training Approaches for Open Information Extraction The goal of open information extraction (OIE) is to extract facts from natural language text, and to represent them as structured triples of the form subject, predicate, object . For example, given the sentence »Beethoven composed the Ode to Joy.«, we are expected to extract the triple Beethoven, composed, Ode to Joy . In this work, we systematically compare different neural network architectures and training approaches, and improve the performance of the currently best models on the OIE16 benchmark (Stanovsky and Dagan, 2016) by 0.421 F 1 score and 0.420 AUC-PR, respectively, in our experiments (i.e., by more than 200% in both cases). Furthermore, we show that appropriate problem and loss formulations often affect the performance more than the network architecture. * * Equal contribution.","systematic comparison neural architecture training approach open information extraction goal open information extraction ( oie ) extract fact natural language text , represent structure triple form subject , predicate , object . example , give sentence » beethoven compose ode joy . « , expect extract triple beethoven , compose , ode joy . work , systematically compare different neural network architecture training approach , improve performance currently good model oie16 benchmark ( stanovsky dagan , 2016 ) 0.421 f 1 score 0.420 auc - pr , respectively , experiment ( i.e. , 200 % case ) . furthermore , appropriate problem loss formulation affect performance network architecture . * * equal contribution .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Information Extraction,Enhancing Aspect Term Extraction with Soft Prototypes,"Aspect term extraction (ATE) aims to extract aspect terms from a review sentence that users have expressed opinions on. Existing studies mostly focus on designing neural sequence taggers to extract linguistic features from the token level. However, since the aspect terms and context words usually exhibit long-tail distributions, these taggers often converge to an inferior state without enough sample exposure. In this paper, we propose to tackle this problem by correlating words with each other through soft prototypes. These prototypes, generated by a soft retrieval process, can introduce global knowledge from internal or external data and serve as the supporting evidence for discovering the aspect terms. Our proposed model is a general framework and can be combined with almost all sequence taggers. Experiments on four SemEval datasets show that our model boosts the performance of three typical ATE methods by a large margin.","Enhancing Aspect Term Extraction with Soft Prototypes Aspect term extraction (ATE) aims to extract aspect terms from a review sentence that users have expressed opinions on. Existing studies mostly focus on designing neural sequence taggers to extract linguistic features from the token level. However, since the aspect terms and context words usually exhibit long-tail distributions, these taggers often converge to an inferior state without enough sample exposure. In this paper, we propose to tackle this problem by correlating words with each other through soft prototypes. These prototypes, generated by a soft retrieval process, can introduce global knowledge from internal or external data and serve as the supporting evidence for discovering the aspect terms. Our proposed model is a general framework and can be combined with almost all sequence taggers. Experiments on four SemEval datasets show that our model boosts the performance of three typical ATE methods by a large margin.","enhance aspect term extraction soft prototypes aspect term extraction ( ate ) aim extract aspect term review sentence user express opinion . exist study focus design neural sequence tagger extract linguistic feature token level . , aspect term context word usually exhibit long - tail distribution , tagger converge inferior state sample exposure . paper , propose tackle problem correlate word soft prototype . prototype , generate soft retrieval process , introduce global knowledge internal external datum serve support evidence discover aspect term . propose model general framework combine sequence tagger . experiment semeval dataset model boost performance typical ate method large margin .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Information Extraction,MedFilter: Improving Extraction of Task-relevant Utterances through Integration of Discourse Structure and Ontological Knowledge,"Information extraction from conversational data is particularly challenging because the task-centric nature of conversation allows for effective communication of implicit information by humans, but is challenging for machines. The challenges may differ between utterances depending on the role of the speaker within the conversation, especially when relevant expertise is distributed asymmetrically across roles. Further, the challenges may also increase over the conversation as more shared context is built up through information communicated implicitly earlier in the dialogue. In this paper, we propose the novel modeling approach MEDFILTER, which addresses these insights in order to increase performance at identifying and categorizing task-relevant utterances, and in so doing, positively impacts performance at a downstream information extraction task. We evaluate this approach on a corpus of nearly 7,000 doctor-patient conversations where MEDFILTER is used to identify medically relevant contributions to the discussion (achieving a 10% improvement over SOTA baselines in terms of area under the PR curve). Identifying task-relevant utterances benefits downstream medical processing, achieving improvements of 15%, 105%, and 23% respectively for the extraction of symptoms, medications, and complaints.","MedFilter: Improving Extraction of Task-relevant Utterances through Integration of Discourse Structure and Ontological Knowledge Information extraction from conversational data is particularly challenging because the task-centric nature of conversation allows for effective communication of implicit information by humans, but is challenging for machines. The challenges may differ between utterances depending on the role of the speaker within the conversation, especially when relevant expertise is distributed asymmetrically across roles. Further, the challenges may also increase over the conversation as more shared context is built up through information communicated implicitly earlier in the dialogue. In this paper, we propose the novel modeling approach MEDFILTER, which addresses these insights in order to increase performance at identifying and categorizing task-relevant utterances, and in so doing, positively impacts performance at a downstream information extraction task. We evaluate this approach on a corpus of nearly 7,000 doctor-patient conversations where MEDFILTER is used to identify medically relevant contributions to the discussion (achieving a 10% improvement over SOTA baselines in terms of area under the PR curve). Identifying task-relevant utterances benefits downstream medical processing, achieving improvements of 15%, 105%, and 23% respectively for the extraction of symptoms, medications, and complaints.","medfilter : improve extraction task - relevant utterance integration discourse structure ontological knowledge information extraction conversational datum particularly challenging task - centric nature conversation allow effective communication implicit information human , challenging machine . challenge differ utterance depend role speaker conversation , especially relevant expertise distribute asymmetrically role . , challenge increase conversation share context build information communicate implicitly early dialogue . paper , propose novel modeling approach medfilter , address insight order increase performance identify categorize task - relevant utterance , , positively impact performance downstream information extraction task . evaluate approach corpus nearly 7,000 doctor - patient conversation medfilter identify medically relevant contribution discussion ( achieve 10 % improvement sota baseline term area pr curve ) . identify task - relevant utterance benefit downstream medical processing , achieve improvement 15 % , 105 % , 23 % respectively extraction symptom , medication , complaint .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Information Extraction,A Rigorous Study on Named Entity Recognition: Can Fine-tuning Pretrained Model Lead to the Promised Land?,"Fine-tuning pretrained model has achieved promising performance on standard NER benchmarks. Generally, these benchmarks are blessed with strong name regularity, high mention coverage and sufficient context diversity. Unfortunately, when scaling NER to open situations, these advantages may no longer exist. And therefore it raises a critical question of whether previous creditable approaches can still work well when facing these challenges. As there is no currently available dataset to investigate this problem, this paper proposes to conduct randomization test on standard benchmarks. Specifically, we erase name regularity, mention coverage and context diversity respectively from the benchmarks, in order to explore their impact on the generalization ability of models. To further verify our conclusions, we also construct a new open NER dataset that focuses on entity types with weaker name regularity and lower mention coverage to verify our conclusion. From both randomization test and empirical experiments, we draw the conclusions that 1) name regularity is critical for the models to generalize to unseen mentions; 2) high mention coverage may undermine the model generalization ability and 3) context patterns may not require enormous data to capture when using pretrained encoders.","A Rigorous Study on Named Entity Recognition: Can Fine-tuning Pretrained Model Lead to the Promised Land? Fine-tuning pretrained model has achieved promising performance on standard NER benchmarks. Generally, these benchmarks are blessed with strong name regularity, high mention coverage and sufficient context diversity. Unfortunately, when scaling NER to open situations, these advantages may no longer exist. And therefore it raises a critical question of whether previous creditable approaches can still work well when facing these challenges. As there is no currently available dataset to investigate this problem, this paper proposes to conduct randomization test on standard benchmarks. Specifically, we erase name regularity, mention coverage and context diversity respectively from the benchmarks, in order to explore their impact on the generalization ability of models. To further verify our conclusions, we also construct a new open NER dataset that focuses on entity types with weaker name regularity and lower mention coverage to verify our conclusion. From both randomization test and empirical experiments, we draw the conclusions that 1) name regularity is critical for the models to generalize to unseen mentions; 2) high mention coverage may undermine the model generalization ability and 3) context patterns may not require enormous data to capture when using pretrained encoders.","rigorous study name entity recognition : fine - tune pretraine model lead promised land ? fine - tune pretraine model achieve promising performance standard ner benchmark . generally , benchmark bless strong regularity , high mention coverage sufficient context diversity . unfortunately , scale ner open situation , advantage long exist . raise critical question previous creditable approach work face challenge . currently available dataset investigate problem , paper propose conduct randomization test standard benchmark . specifically , erase regularity , mention coverage context diversity respectively benchmark , order explore impact generalization ability model . verify conclusion , construct new open ner dataset focus entity type weak regularity low mention coverage verify conclusion . randomization test empirical experiment , draw conclusion 1 ) regularity critical model generalize unseen mention ; 2 ) high mention coverage undermine model generalization ability 3 ) context pattern require enormous datum capture pretrained encoder .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 13, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Denoising Relation Extraction from Document-level Distant Supervision,"Distant supervision (DS) has been widely used to generate auto-labeled data for sentencelevel relation extraction (RE), which improves RE performance. However, the existing success of DS cannot be directly transferred to the more challenging document-level relation extraction (DocRE), since the inherent noise in DS may be even multiplied in document level and significantly harm the performance of RE. To address this challenge, we propose a novel pre-trained model for DocRE, which denoises the document-level DS data via multiple pre-training tasks. Experimental results on the large-scale DocRE benchmark show that our model can capture useful information from noisy DS data and achieve promising results. The source code of this paper can be found in https://github.com/thunlp/DSDocRE.","Denoising Relation Extraction from Document-level Distant Supervision Distant supervision (DS) has been widely used to generate auto-labeled data for sentencelevel relation extraction (RE), which improves RE performance. However, the existing success of DS cannot be directly transferred to the more challenging document-level relation extraction (DocRE), since the inherent noise in DS may be even multiplied in document level and significantly harm the performance of RE. To address this challenge, we propose a novel pre-trained model for DocRE, which denoises the document-level DS data via multiple pre-training tasks. Experimental results on the large-scale DocRE benchmark show that our model can capture useful information from noisy DS data and achieve promising results. The source code of this paper can be found in https://github.com/thunlp/DSDocRE.","denoise relation extraction document - level distant supervision distant supervision ( ds ) widely generate auto - labeled datum sentencelevel relation extraction ( ) , improve performance . , exist success ds directly transfer challenging document - level relation extraction ( docre ) , inherent noise ds multiply document level significantly harm performance . address challenge , propose novel pre - trained model docre , denoise document - level ds datum multiple pre - training task . experimental result large - scale docre benchmark model capture useful information noisy ds datum achieve promising result . source code paper find https://github.com/thunlp/dsdocre .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Event Extraction as Machine Reading Comprehension,"Event extraction (EE) is a crucial information extraction task that aims to extract event information in texts. Previous methods for EE typically model it as a classification task, which are data-hungry and suffer from the data scarcity problem. In this paper, we propose a new learning paradigm of EE, by explicitly casting it as a machine reading comprehension problem (MRC). Our approach includes an unsupervised question generation process, which can transfer event schema into a set of natural questions, followed by a BERTbased question-answering process to retrieve answers as EE results. This learning paradigm enables us to strengthen the reasoning process of EE, by introducing sophisticated models in MRC, and relieve the data scarcity problem, by introducing the large-scale datasets in MRC. The empirical results show that: i) our approach attains state-of-the-art performance by considerable margins over previous methods. ii) Our model is excelled in the data-scarce scenario, for example, obtaining 49.8% in F1 for event argument extraction with only 1% data, compared with 2.2% of the previous method. iii) Our model also fits with zero-shot scenarios, achieving 37.0% and 16% in F1 on two datasets without using any EE training data.","Event Extraction as Machine Reading Comprehension Event extraction (EE) is a crucial information extraction task that aims to extract event information in texts. Previous methods for EE typically model it as a classification task, which are data-hungry and suffer from the data scarcity problem. In this paper, we propose a new learning paradigm of EE, by explicitly casting it as a machine reading comprehension problem (MRC). Our approach includes an unsupervised question generation process, which can transfer event schema into a set of natural questions, followed by a BERTbased question-answering process to retrieve answers as EE results. This learning paradigm enables us to strengthen the reasoning process of EE, by introducing sophisticated models in MRC, and relieve the data scarcity problem, by introducing the large-scale datasets in MRC. The empirical results show that: i) our approach attains state-of-the-art performance by considerable margins over previous methods. ii) Our model is excelled in the data-scarce scenario, for example, obtaining 49.8% in F1 for event argument extraction with only 1% data, compared with 2.2% of the previous method. iii) Our model also fits with zero-shot scenarios, achieving 37.0% and 16% in F1 on two datasets without using any EE training data.","event extraction machine reading comprehension event extraction ( ee ) crucial information extraction task aim extract event information text . previous method ee typically model classification task , data - hungry suffer datum scarcity problem . paper , propose new learning paradigm ee , explicitly cast machine reading comprehension problem ( mrc ) . approach include unsupervised question generation process , transfer event schema set natural question , follow bertbased question - answer process retrieve answer ee result . learning paradigm enable strengthen reasoning process ee , introduce sophisticated model mrc , relieve datum scarcity problem , introduce large - scale dataset mrc . empirical result : ) approach attain state - - - art performance considerable margin previous method . ii ) model excel data - scarce scenario , example , obtain 49.8 % f1 event argument extraction 1 % datum , compare 2.2 % previous method . iii ) model fit zero - shot scenario , achieve 37.0 % 16 % f1 dataset ee training datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 13, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Information Extraction,Severing the Edge Between Before and After: Neural Architectures for Temporal Ordering of Events,"In this paper, we propose a neural architecture and a set of training methods for ordering events by predicting temporal relations. Our proposed models receive a pair of events within a span of text as input and they identify temporal relations (Before, After, Equal, Vague) between them. Given that a key challenge with this task is the scarcity of annotated data, our models rely on either pretrained representations (i.e. RoBERTa, BERT or ELMo), transfer and multi-task learning (by leveraging complementary datasets), and self-training techniques. Experiments on the MATRES dataset of English documents establish a new state-of-the-art on this task.","Severing the Edge Between Before and After: Neural Architectures for Temporal Ordering of Events In this paper, we propose a neural architecture and a set of training methods for ordering events by predicting temporal relations. Our proposed models receive a pair of events within a span of text as input and they identify temporal relations (Before, After, Equal, Vague) between them. Given that a key challenge with this task is the scarcity of annotated data, our models rely on either pretrained representations (i.e. RoBERTa, BERT or ELMo), transfer and multi-task learning (by leveraging complementary datasets), and self-training techniques. Experiments on the MATRES dataset of English documents establish a new state-of-the-art on this task.","sever edge : neural architecture temporal ordering event paper , propose neural architecture set training method order event predict temporal relation . propose model receive pair event span text input identify temporal relation ( , , equal , vague ) . give key challenge task scarcity annotate datum , model rely pretrained representation ( i.e. roberta , bert elmo ) , transfer multi - task learning ( leverage complementary dataset ) , self - train technique . experiment matres dataset english document establish new state - - - art task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,Learning Collaborative Agents with Rule Guidance for Knowledge Graph Reasoning,"Walk-based models have shown their advantages in knowledge graph (KG) reasoning by achieving decent performance while providing interpretable decisions. However, the sparse reward signals offered by the KG during traversal are often insufficient to guide a sophisticated walk-based reinforcement learning (RL) model. An alternate approach is to use traditional symbolic methods (e.g., rule induction), which achieve good performance but can be hard to generalize due to the limitation of symbolic representation. In this paper, we propose RuleGuider, which leverages high-quality rules generated by symbolicbased methods to provide reward supervision for walk-based agents. Experiments on benchmark datasets show that RuleGuider improves the performance of walk-based models without losing interpretability. 1 * Equal contributions. 1 https://github.com/derenlei/ KG-RuleGuider","Learning Collaborative Agents with Rule Guidance for Knowledge Graph Reasoning Walk-based models have shown their advantages in knowledge graph (KG) reasoning by achieving decent performance while providing interpretable decisions. However, the sparse reward signals offered by the KG during traversal are often insufficient to guide a sophisticated walk-based reinforcement learning (RL) model. An alternate approach is to use traditional symbolic methods (e.g., rule induction), which achieve good performance but can be hard to generalize due to the limitation of symbolic representation. In this paper, we propose RuleGuider, which leverages high-quality rules generated by symbolicbased methods to provide reward supervision for walk-based agents. Experiments on benchmark datasets show that RuleGuider improves the performance of walk-based models without losing interpretability. 1 * Equal contributions. 1 https://github.com/derenlei/ KG-RuleGuider","learn collaborative agent rule guidance knowledge graph reasoning walk - base model show advantage knowledge graph ( kg ) reasoning achieve decent performance provide interpretable decision . , sparse reward signal offer kg traversal insufficient guide sophisticated walk - base reinforcement learning ( rl ) model . alternate approach use traditional symbolic method ( e.g. , rule induction ) , achieve good performance hard generalize limitation symbolic representation . paper , propose ruleguider , leverage high - quality rule generate symbolicbased method provide reward supervision walk - base agent . experiment benchmark dataset ruleguider improve performance walk - base model lose interpretability . 1 * equal contribution . 1 https://github.com/derenlei/ kg - ruleguid","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Extraction,Weakly Supervised Subevent Knowledge Acquisition,"Subevents elaborate an event and widely exist in event descriptions. Subevent knowledge is useful for discourse analysis and event-centric applications. Acknowledging the scarcity of subevent knowledge, we propose a weakly supervised approach to extract subevent relation tuples from text and build the first large scale subevent knowledge base. We first obtain the initial set of event pairs that are likely to have the subevent relation, by exploiting two observations that 1) subevents are temporally contained by the parent event, and 2) the definitions of the parent event can be used to further guide the identification of subevents. Then, we collect rich weak supervision using the initial seed subevent pairs to train a contextual classifier using BERT and apply the classifier to identify new subevent pairs. The evaluation showed that the acquired subevent tuples (239K) are of high quality (90.1% accuracy) and cover a wide range of event types. The acquired subevent knowledge has been shown useful for discourse analysis and identifying a range of event-event relations 1 .","Weakly Supervised Subevent Knowledge Acquisition Subevents elaborate an event and widely exist in event descriptions. Subevent knowledge is useful for discourse analysis and event-centric applications. Acknowledging the scarcity of subevent knowledge, we propose a weakly supervised approach to extract subevent relation tuples from text and build the first large scale subevent knowledge base. We first obtain the initial set of event pairs that are likely to have the subevent relation, by exploiting two observations that 1) subevents are temporally contained by the parent event, and 2) the definitions of the parent event can be used to further guide the identification of subevents. Then, we collect rich weak supervision using the initial seed subevent pairs to train a contextual classifier using BERT and apply the classifier to identify new subevent pairs. The evaluation showed that the acquired subevent tuples (239K) are of high quality (90.1% accuracy) and cover a wide range of event types. The acquired subevent knowledge has been shown useful for discourse analysis and identifying a range of event-event relations 1 .","weakly supervise subevent knowledge acquisition subevent elaborate event widely exist event description . subevent knowledge useful discourse analysis event - centric application . acknowledge scarcity subevent knowledge , propose weakly supervise approach extract subevent relation tuple text build large scale subevent knowledge base . obtain initial set event pair likely subevent relation , exploit observation 1 ) subevent temporally contain parent event , 2 ) definition parent event guide identification subevent . , collect rich weak supervision initial seed subevent pair train contextual classifier bert apply classifier identify new subevent pair . evaluation show acquire subevent tuple ( 239 k ) high quality ( 90.1 % accuracy ) cover wide range event type . acquire subevent knowledge show useful discourse analysis identify range event - event relation 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,FedED: Federated Learning via Ensemble Distillation for Medical Relation Extraction,"Unlike other domains, medical texts are inevitably accompanied by private information, so sharing or copying these texts is strictly restricted. However, training a medical relation extraction model requires collecting these privacy-sensitive texts and storing them on one machine, which comes in conflict with privacy protection. In this paper, we propose a privacypreserving medical relation extraction model based on federated learning, which enables training a central model with no single piece of private local data being shared or exchanged. Though federated learning has distinct advantages in privacy protection, it suffers from the communication bottleneck, which is mainly caused by the need to upload cumbersome local parameters. To overcome this bottleneck, we leverage a strategy based on knowledge distillation. Such a strategy uses the uploaded predictions of ensemble local models to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method.","FedED: Federated Learning via Ensemble Distillation for Medical Relation Extraction Unlike other domains, medical texts are inevitably accompanied by private information, so sharing or copying these texts is strictly restricted. However, training a medical relation extraction model requires collecting these privacy-sensitive texts and storing them on one machine, which comes in conflict with privacy protection. In this paper, we propose a privacypreserving medical relation extraction model based on federated learning, which enables training a central model with no single piece of private local data being shared or exchanged. Though federated learning has distinct advantages in privacy protection, it suffers from the communication bottleneck, which is mainly caused by the need to upload cumbersome local parameters. To overcome this bottleneck, we leverage a strategy based on knowledge distillation. Such a strategy uses the uploaded predictions of ensemble local models to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method.","feded : federated learning ensemble distillation medical relation extraction unlike domain , medical text inevitably accompany private information , share copy text strictly restrict . , train medical relation extraction model require collect privacy - sensitive text store machine , come conflict privacy protection . paper , propose privacypreserve medical relation extraction model base federate learning , enable train central model single piece private local datum share exchange . federated learning distinct advantage privacy protection , suffer communication bottleneck , mainly cause need upload cumbersome local parameter . overcome bottleneck , leverage strategy base knowledge distillation . strategy use upload prediction ensemble local model train central model require upload local parameter . experiment publicly available medical relation extraction dataset demonstrate effectiveness method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Temporal Knowledge Base Completion: New Algorithms and Evaluation Protocols,"Research on temporal knowledge bases, which associate a relational fact (s, r, o) with a validity time period (or time instant), is in its early days. Our work considers predicting missing entities (link prediction) and missing time intervals (time prediction) as joint Temporal Knowledge Base Completion (TKBC) tasks, and presents TIMEPLEX, a novel TKBC method, in which entities, relations and, time are all embedded in a uniform, compatible space. TIMEPLEX exploits the recurrent nature of some facts/events and temporal interactions between pairs of relations, yielding stateof-the-art results on both prediction tasks. We also find that existing TKBC models heavily overestimate link prediction performance due to imperfect evaluation mechanisms. In response, we propose improved TKBC evaluation protocols for both link and time prediction tasks, dealing with subtle issues that arise from the partial overlap of time intervals in gold instances and system predictions.","Temporal Knowledge Base Completion: New Algorithms and Evaluation Protocols Research on temporal knowledge bases, which associate a relational fact (s, r, o) with a validity time period (or time instant), is in its early days. Our work considers predicting missing entities (link prediction) and missing time intervals (time prediction) as joint Temporal Knowledge Base Completion (TKBC) tasks, and presents TIMEPLEX, a novel TKBC method, in which entities, relations and, time are all embedded in a uniform, compatible space. TIMEPLEX exploits the recurrent nature of some facts/events and temporal interactions between pairs of relations, yielding stateof-the-art results on both prediction tasks. We also find that existing TKBC models heavily overestimate link prediction performance due to imperfect evaluation mechanisms. In response, we propose improved TKBC evaluation protocols for both link and time prediction tasks, dealing with subtle issues that arise from the partial overlap of time intervals in gold instances and system predictions.","temporal knowledge base completion : new algorithm evaluation protocol research temporal knowledge basis , associate relational fact ( s , r , o ) validity time period ( time instant ) , early day . work consider predict miss entity ( link prediction ) miss time interval ( time prediction ) joint temporal knowledge base completion ( tkbc ) task , present timeplex , novel tkbc method , entity , relation , time embed uniform , compatible space . timeplex exploit recurrent nature fact / event temporal interaction pair relation , yield stateof - - art result prediction task . find exist tkbc model heavily overestimate link prediction performance imperfect evaluation mechanism . response , propose improved tkbc evaluation protocol link time prediction task , deal subtle issue arise partial overlap time interval gold instance system prediction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,Domain Knowledge Empowered Structured Neural Net for End-to-End Event Temporal Relation Extraction,"Extracting event temporal relations is a critical task for information extraction and plays an important role in natural language understanding. Prior systems leverage deep learning and pre-trained language models to improve the performance of the task. However, these systems often suffer from two shortcomings: 1) when performing maximum a posteriori (MAP) inference based on neural models, previous systems only used structured knowledge that is assumed to be absolutely correct, i.e., hard constraints; 2) biased predictions on dominant temporal relations when training with a limited amount of data. To address these issues, we propose a framework that enhances deep neural network with distributional constraints constructed by probabilistic domain knowledge. We solve the constrained inference problem via Lagrangian Relaxation and apply it to end-to-end event temporal relation extraction tasks. Experimental results show our framework is able to improve the baseline neural network models with strong statistical significance on two widely used datasets in news and clinical domains.","Domain Knowledge Empowered Structured Neural Net for End-to-End Event Temporal Relation Extraction Extracting event temporal relations is a critical task for information extraction and plays an important role in natural language understanding. Prior systems leverage deep learning and pre-trained language models to improve the performance of the task. However, these systems often suffer from two shortcomings: 1) when performing maximum a posteriori (MAP) inference based on neural models, previous systems only used structured knowledge that is assumed to be absolutely correct, i.e., hard constraints; 2) biased predictions on dominant temporal relations when training with a limited amount of data. To address these issues, we propose a framework that enhances deep neural network with distributional constraints constructed by probabilistic domain knowledge. We solve the constrained inference problem via Lagrangian Relaxation and apply it to end-to-end event temporal relation extraction tasks. Experimental results show our framework is able to improve the baseline neural network models with strong statistical significance on two widely used datasets in news and clinical domains.","domain knowledge empower structured neural net end - - end event temporal relation extraction extract event temporal relation critical task information extraction play important role natural language understanding . prior system leverage deep learning pre - train language model improve performance task . , system suffer shortcoming : 1 ) perform maximum posteriori ( map ) inference base neural model , previous system structure knowledge assume absolutely correct , i.e. , hard constraint ; 2 ) bias prediction dominant temporal relation train limited datum . address issue , propose framework enhance deep neural network distributional constraint construct probabilistic domain knowledge . solve constrain inference problem lagrangian relaxation apply end - - end event temporal relation extraction task . experimental result framework able improve baseline neural network model strong statistical significance widely dataset news clinical domain .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Incremental Neural Coreference Resolution in Constant Memory,"We investigate modeling coreference resolution under a fixed memory constraint by extending an incremental clustering algorithm to utilize contextualized encoders and neural components. Given a new sentence, our endto-end algorithm proposes and scores each mention span against explicit entity representations created from the earlier document context (if any). These spans are then used to update the entity's representations before being forgotten; we only retain a fixed set of salient entities throughout the document. In this work, we successfully convert a highperforming model (Joshi et al., 2020) , asymptotically reducing its memory usage to constant space with only a 0.3% relative loss in F1 on OntoNotes 5.0.","Incremental Neural Coreference Resolution in Constant Memory We investigate modeling coreference resolution under a fixed memory constraint by extending an incremental clustering algorithm to utilize contextualized encoders and neural components. Given a new sentence, our endto-end algorithm proposes and scores each mention span against explicit entity representations created from the earlier document context (if any). These spans are then used to update the entity's representations before being forgotten; we only retain a fixed set of salient entities throughout the document. In this work, we successfully convert a highperforming model (Joshi et al., 2020) , asymptotically reducing its memory usage to constant space with only a 0.3% relative loss in F1 on OntoNotes 5.0.","incremental neural coreference resolution constant memory investigate model coreference resolution fix memory constraint extend incremental clustering algorithm utilize contextualize encoder neural component . give new sentence , endto - end algorithm propose score mention span explicit entity representation create early document context ( ) . span update entity representation forget ; retain fix set salient entity document . work , successfully convert highperforming model ( joshi et al . , 2020 ) , asymptotically reduce memory usage constant space 0.3 % relative loss f1 ontonotes 5.0 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations,"The idea of using multi-task learning approaches to address the joint extraction of entity and relation is motivated by the relatedness between the entity recognition task and the relation classification task. Existing methods using multi-task learning techniques to address the problem learn interactions among the two tasks through a shared network, where the shared information is passed into the taskspecific networks for prediction. However, such an approach hinders the model from learning explicit interactions between the two tasks to improve the performance on the individual tasks. As a solution, we design a multitask learning model which we refer to as recurrent interaction network which allows the learning of interactions dynamically, to effectively model task-specific features for classification. Empirical studies on two real-world datasets confirm the superiority of the proposed model.","Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations The idea of using multi-task learning approaches to address the joint extraction of entity and relation is motivated by the relatedness between the entity recognition task and the relation classification task. Existing methods using multi-task learning techniques to address the problem learn interactions among the two tasks through a shared network, where the shared information is passed into the taskspecific networks for prediction. However, such an approach hinders the model from learning explicit interactions between the two tasks to improve the performance on the individual tasks. As a solution, we design a multitask learning model which we refer to as recurrent interaction network which allows the learning of interactions dynamically, to effectively model task-specific features for classification. Empirical studies on two real-world datasets confirm the superiority of the proposed model.","recurrent interaction network jointly extract entity classify relation idea multi - task learning approach address joint extraction entity relation motivate relatedness entity recognition task relation classification task . exist method multi - task learning technique address problem learn interaction task share network , share information pass taskspecific network prediction . , approach hinder model learn explicit interaction task improve performance individual task . solution , design multitask learning model refer recurrent interaction network allow learning interaction dynamically , effectively model task - specific feature classification . empirical study real - world dataset confirm superiority propose model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Connecting the Dots: Event Graph Schema Induction with Path Language Modeling,"Event schemas can guide our understanding and ability to make predictions with respect to what might happen next. We propose a new Event Graph Schema, where two event types are connected through multiple paths involving entities that fill important roles in a coherent story. We then introduce Path Language Model, an auto-regressive language model trained on event-event paths, and select salient and coherent paths to probabilistically construct these graph schemas. We design two evaluation metrics, instance coverage and instance coherence, to evaluate the quality of graph schema induction, by checking when coherent event instances are covered by the schema graph. Intrinsic evaluations show that our approach is highly effective at inducing salient and coherent schemas. Extrinsic evaluations show the induced schema repository provides significant improvement to downstream end-to-end Information Extraction over a state-of-the-art joint neural extraction model, when used as additional global features to unfold instance graphs. 1","Connecting the Dots: Event Graph Schema Induction with Path Language Modeling Event schemas can guide our understanding and ability to make predictions with respect to what might happen next. We propose a new Event Graph Schema, where two event types are connected through multiple paths involving entities that fill important roles in a coherent story. We then introduce Path Language Model, an auto-regressive language model trained on event-event paths, and select salient and coherent paths to probabilistically construct these graph schemas. We design two evaluation metrics, instance coverage and instance coherence, to evaluate the quality of graph schema induction, by checking when coherent event instances are covered by the schema graph. Intrinsic evaluations show that our approach is highly effective at inducing salient and coherent schemas. Extrinsic evaluations show the induced schema repository provides significant improvement to downstream end-to-end Information Extraction over a state-of-the-art joint neural extraction model, when used as additional global features to unfold instance graphs. 1","connect dot : event graph schema induction path language modeling event schema guide understanding ability prediction respect happen . propose new event graph schema , event type connect multiple path involve entity fill important role coherent story . introduce path language model , auto - regressive language model train event - event path , select salient coherent path probabilistically construct graph schema . design evaluation metric , instance coverage instance coherence , evaluate quality graph schema induction , check coherent event instance cover schema graph . intrinsic evaluation approach highly effective induce salient coherent schema . extrinsic evaluation induce schema repository provide significant improvement downstream end - - end information extraction state - - - art joint neural extraction model , additional global feature unfold instance graph . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Extraction,Annotating Temporal Dependency Graphs via Crowdsourcing,"We present the construction of a corpus of 500 Wikinews articles annotated with temporal dependency graphs (TDGs) that can be used to train systems to understand temporal relations in text. We argue that temporal dependency graphs, built on previous research on narrative times and temporal anaphora, provide a representation scheme that achieves a good balance between completeness and practicality in temporal annotation. We also provide a crowdsourcing strategy to annotate TDGs, and demonstrate the feasibility of this approach with an evaluation of the quality of the annotation, and the utility of the resulting data set by training a machine learning model on this data set. This data set is publicly available 1 .","Annotating Temporal Dependency Graphs via Crowdsourcing We present the construction of a corpus of 500 Wikinews articles annotated with temporal dependency graphs (TDGs) that can be used to train systems to understand temporal relations in text. We argue that temporal dependency graphs, built on previous research on narrative times and temporal anaphora, provide a representation scheme that achieves a good balance between completeness and practicality in temporal annotation. We also provide a crowdsourcing strategy to annotate TDGs, and demonstrate the feasibility of this approach with an evaluation of the quality of the annotation, and the utility of the resulting data set by training a machine learning model on this data set. This data set is publicly available 1 .","annotate temporal dependency graph crowdsourcing present construction corpus 500 wikinews article annotate temporal dependency graph ( tdg ) train system understand temporal relation text . argue temporal dependency graph , build previous research narrative time temporal anaphora , provide representation scheme achieve good balance completeness practicality temporal annotation . provide crowdsourcing strategy annotate tdg , demonstrate feasibility approach evaluation quality annotation , utility result data set train machine learning model data set . data set publicly available 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Extraction,Exposing Shallow Heuristics of Relation Extraction Models with Challenge Data,"The process of collecting and annotating training data may introduce distribution artifacts which may limit the ability of models to learn correct generalization behavior. We identify failure modes of SOTA relation extraction (RE) models trained on TACRED, which we attribute to limitations in the data annotation process. We collect and annotate a challengeset we call Challenging RE (CRE), based on naturally occurring corpus examples, to benchmark this behavior. Our experiments with four state-of-the-art RE models show that they have indeed adopted shallow heuristics that do not generalize to the challenge-set data. Further, we find that alternative question answering modeling performs significantly better than the SOTA models on the challenge-set, despite worse overall TACRED performance. By adding some of the challenge data as training examples, the performance of the model improves. Finally, we provide concrete suggestion on how to improve RE data collection to alleviate this behavior.","Exposing Shallow Heuristics of Relation Extraction Models with Challenge Data The process of collecting and annotating training data may introduce distribution artifacts which may limit the ability of models to learn correct generalization behavior. We identify failure modes of SOTA relation extraction (RE) models trained on TACRED, which we attribute to limitations in the data annotation process. We collect and annotate a challengeset we call Challenging RE (CRE), based on naturally occurring corpus examples, to benchmark this behavior. Our experiments with four state-of-the-art RE models show that they have indeed adopted shallow heuristics that do not generalize to the challenge-set data. Further, we find that alternative question answering modeling performs significantly better than the SOTA models on the challenge-set, despite worse overall TACRED performance. By adding some of the challenge data as training examples, the performance of the model improves. Finally, we provide concrete suggestion on how to improve RE data collection to alleviate this behavior.","expose shallow heuristic relation extraction model challenge datum process collect annotate training datum introduce distribution artifact limit ability model learn correct generalization behavior . identify failure mode sota relation extraction ( ) model train tacred , attribute limitation datum annotation process . collect annotate challengeset challenge ( cre ) , base naturally occur corpus example , benchmark behavior . experiment state - - - art model adopt shallow heuristic generalize challenge - set datum . , find alternative question answering modeling perform significantly well sota model challenge - set , despite bad overall tacred performance . add challenge datum training example , performance model improve . finally , provide concrete suggestion improve datum collection alleviate behavior .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Disentangle-based Continual Graph Representation Learning,"Graph embedding (GE) methods embed nodes (and/or edges) in graph into a low-dimensional semantic space, and have shown its effectiveness in modeling multi-relational data. However, existing GE models are not practical in real-world applications since it overlooked the streaming nature of incoming data. To address this issue, we study the problem of continual graph representation learning which aims to continually train a graph embedding model on new data to learn incessantly emerging multi-relational data while avoiding catastrophically forgetting old learned knowledge. Moreover, we propose a disentangle-based continual graph representation learning (DiC-GRL) framework inspired by the human's ability to learn procedural knowledge. The experimental results show that DiCGRL could effectively alleviate the catastrophic forgetting problem and outperform state-of-the-art continual learning models.","Disentangle-based Continual Graph Representation Learning Graph embedding (GE) methods embed nodes (and/or edges) in graph into a low-dimensional semantic space, and have shown its effectiveness in modeling multi-relational data. However, existing GE models are not practical in real-world applications since it overlooked the streaming nature of incoming data. To address this issue, we study the problem of continual graph representation learning which aims to continually train a graph embedding model on new data to learn incessantly emerging multi-relational data while avoiding catastrophically forgetting old learned knowledge. Moreover, we propose a disentangle-based continual graph representation learning (DiC-GRL) framework inspired by the human's ability to learn procedural knowledge. The experimental results show that DiCGRL could effectively alleviate the catastrophic forgetting problem and outperform state-of-the-art continual learning models.","disentangle - base continual graph representation learning graph embedding ( ge ) method embed node ( and/or edge ) graph low - dimensional semantic space , show effectiveness model multi - relational datum . , exist ge model practical real - world application overlook streaming nature incoming datum . address issue , study problem continual graph representation learning aim continually train graph embed model new datum learn incessantly emerge multi - relational datum avoid catastrophically forget old learn knowledge . , propose disentangle - base continual graph representation learning ( dic - grl ) framework inspire human ability learn procedural knowledge . experimental result dicgrl effectively alleviate catastrophic forgetting problem outperform state - - - art continual learning model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Information Extraction,Semi-supervised New Event Type Induction and Event Detection,"Most previous event extraction studies assume a set of target event types and corresponding event annotations are given, which could be very expensive. In this paper, we work on a new task of semi-supervised event type induction, aiming to automatically discover a set of unseen types from a given corpus by leveraging annotations available for a few seen types. We design a Semi-Supervised Vector Quantized Variational Autoencoder framework to automatically learn a discrete latent type representation for each seen and unseen type and optimize them using seen type event annotations. A variational autoencoder is further introduced to enforce the reconstruction of each event mention conditioned on its latent type distribution. Experiments show that our approach can not only achieve state-of-the-art performance on supervised event detection but also discover high-quality new event types. 1","Semi-supervised New Event Type Induction and Event Detection Most previous event extraction studies assume a set of target event types and corresponding event annotations are given, which could be very expensive. In this paper, we work on a new task of semi-supervised event type induction, aiming to automatically discover a set of unseen types from a given corpus by leveraging annotations available for a few seen types. We design a Semi-Supervised Vector Quantized Variational Autoencoder framework to automatically learn a discrete latent type representation for each seen and unseen type and optimize them using seen type event annotations. A variational autoencoder is further introduced to enforce the reconstruction of each event mention conditioned on its latent type distribution. Experiments show that our approach can not only achieve state-of-the-art performance on supervised event detection but also discover high-quality new event types. 1","semi - supervised new event type induction event detection previous event extraction study assume set target event type corresponding event annotation give , expensive . paper , work new task semi - supervised event type induction , aim automatically discover set unseen type give corpus leverage annotation available see type . design semi - supervised vector quantized variational autoencoder framework automatically learn discrete latent type representation seen unseen type optimize see type event annotation . variational autoencoder introduce enforce reconstruction event mention condition latent type distribution . experiment approach achieve state - - - art performance supervise event detection discover high - quality new event type . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,Entity Enhanced BERT Pre-training for Chinese NER,"Character-level BERT pre-trained in Chinese suffers a limitation of lacking lexicon information, which shows effectiveness for Chinese NER. To integrate the lexicon into pre-trained LMs for Chinese NER, we investigate a semisupervised entity enhanced BERT pre-training method. In particular, we first extract an entity lexicon from the relevant raw text using a newword discovery method. We then integrate the entity information into BERT using Char-Entity-Transformer, which augments the selfattention using a combination of character and entity representations. In addition, an entity classification task helps inject the entity information into model parameters in pre-training. The pre-trained models are used for NER finetuning. Experiments on a news dataset and two datasets annotated by ourselves for NER in long-text show that our method is highly effective and achieves the best results. * Equal contribution. 老妇人(The old lady) (Juventus F.C.) wins nine consecutive Serie A titles Char-Entity-Transformer New-Word Discovery","Entity Enhanced BERT Pre-training for Chinese NER Character-level BERT pre-trained in Chinese suffers a limitation of lacking lexicon information, which shows effectiveness for Chinese NER. To integrate the lexicon into pre-trained LMs for Chinese NER, we investigate a semisupervised entity enhanced BERT pre-training method. In particular, we first extract an entity lexicon from the relevant raw text using a newword discovery method. We then integrate the entity information into BERT using Char-Entity-Transformer, which augments the selfattention using a combination of character and entity representations. In addition, an entity classification task helps inject the entity information into model parameters in pre-training. The pre-trained models are used for NER finetuning. Experiments on a news dataset and two datasets annotated by ourselves for NER in long-text show that our method is highly effective and achieves the best results. * Equal contribution. 老妇人(The old lady) (Juventus F.C.) wins nine consecutive Serie A titles Char-Entity-Transformer New-Word Discovery","entity enhance bert pre - training chinese ner character - level bert pre - train chinese suffer limitation lack lexicon information , show effectiveness chinese ner . integrate lexicon pre - trained lm chinese ner , investigate semisupervised entity enhance bert pre - training method . particular , extract entity lexicon relevant raw text newword discovery method . integrate entity information bert char - entity - transformer , augment selfattention combination character entity representation . addition , entity classification task help inject entity information model parameter pre - training . pre - train model ner finetuning . experiment news dataset dataset annotate ner long - text method highly effective achieve good result . * equal contribution . 老妇人(the old lady ) ( juventus f.c. ) win consecutive serie title char - entity - transformer new - word discoveri","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 11, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Counterfactual Generator: A Weakly-Supervised Method for Named Entity Recognition,"Past progress on neural models has proven that named entity recognition is no longer a problem if we have enough labeled data. However, collecting enough data and annotating them are labor-intensive, time-consuming, and expensive. In this paper, we decompose the sentence into two parts: entity and context, and rethink the relationship between them and model performance from a causal perspective. Based on this, we propose the Counterfactual Generator, which generates counterfactual examples by the interventions on the existing observational examples to enhance the original dataset. Experiments across three datasets show that our method improves the generalization ability of models under limited observational examples. Besides, we provide a theoretical foundation by using a structural causal model to explore the spurious correlations between input features and output labels. We investigate the causal effects of entity or context on model performance under both conditions: the non-augmented and the augmented. Interestingly, we find that the non-spurious correlations are more located in entity representation rather than context representation. As a result, our method eliminates part of the spurious correlations between context representation and output labels. The code is available at https://github.com/xijiz/cfgen.","Counterfactual Generator: A Weakly-Supervised Method for Named Entity Recognition Past progress on neural models has proven that named entity recognition is no longer a problem if we have enough labeled data. However, collecting enough data and annotating them are labor-intensive, time-consuming, and expensive. In this paper, we decompose the sentence into two parts: entity and context, and rethink the relationship between them and model performance from a causal perspective. Based on this, we propose the Counterfactual Generator, which generates counterfactual examples by the interventions on the existing observational examples to enhance the original dataset. Experiments across three datasets show that our method improves the generalization ability of models under limited observational examples. Besides, we provide a theoretical foundation by using a structural causal model to explore the spurious correlations between input features and output labels. We investigate the causal effects of entity or context on model performance under both conditions: the non-augmented and the augmented. Interestingly, we find that the non-spurious correlations are more located in entity representation rather than context representation. As a result, our method eliminates part of the spurious correlations between context representation and output labels. The code is available at https://github.com/xijiz/cfgen.","counterfactual generator : weakly - supervise method name entity recognition past progress neural model prove name entity recognition long problem label datum . , collect datum annotate labor - intensive , time - consume , expensive . paper , decompose sentence part : entity context , rethink relationship model performance causal perspective . base , propose counterfactual generator , generate counterfactual example intervention exist observational example enhance original dataset . experiment dataset method improve generalization ability model limited observational example . , provide theoretical foundation structural causal model explore spurious correlation input feature output label . investigate causal effect entity context model performance condition : non - augmented augmented . interestingly , find non - spurious correlation locate entity representation context representation . result , method eliminate spurious correlation context representation output label . code available https://github.com/xijiz/cfgen .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 21, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Extraction,True
Information Extraction,Incremental Event Detection via Knowledge Consolidation Networks,"Conventional approaches to event detection usually require a fixed set of pre-defined event types. Such a requirement is often challenged in real-world applications, as new events continually occur. Due to huge computation cost and storage budge, it is infeasible to store all previous data and re-train the model with all previous data and new data, every time new events arrive. We formulate such challenging scenarios as incremental event detection, which requires a model to learn new classes incrementally without performance degradation on previous classes. However, existing incremental learning methods cannot handle semantic ambiguity and training data imbalance problems between old and new classes in the task of incremental event detection. In this paper, we propose a Knowledge Consolidation Network (KCN) to address the above issues. Specifically, we devise two components, prototype enhanced retrospection and hierarchical distillation, to mitigate the adverse effects of semantic ambiguity and class imbalance, respectively. Experimental results demonstrate the effectiveness of the proposed method, outperforming the state-of-the-art model by 19% and 13.4% of whole F1 score on ACE benchmark and TAC KBP benchmark, respectively.","Incremental Event Detection via Knowledge Consolidation Networks Conventional approaches to event detection usually require a fixed set of pre-defined event types. Such a requirement is often challenged in real-world applications, as new events continually occur. Due to huge computation cost and storage budge, it is infeasible to store all previous data and re-train the model with all previous data and new data, every time new events arrive. We formulate such challenging scenarios as incremental event detection, which requires a model to learn new classes incrementally without performance degradation on previous classes. However, existing incremental learning methods cannot handle semantic ambiguity and training data imbalance problems between old and new classes in the task of incremental event detection. In this paper, we propose a Knowledge Consolidation Network (KCN) to address the above issues. Specifically, we devise two components, prototype enhanced retrospection and hierarchical distillation, to mitigate the adverse effects of semantic ambiguity and class imbalance, respectively. Experimental results demonstrate the effectiveness of the proposed method, outperforming the state-of-the-art model by 19% and 13.4% of whole F1 score on ACE benchmark and TAC KBP benchmark, respectively.","incremental event detection knowledge consolidation networks conventional approach event detection usually require fix set pre - defined event type . requirement challenge real - world application , new event continually occur . huge computation cost storage budge , infeasible store previous datum - train model previous datum new datum , time new event arrive . formulate challenging scenario incremental event detection , require model learn new class incrementally performance degradation previous class . , exist incremental learning method handle semantic ambiguity training datum imbalance problem old new class task incremental event detection . paper , propose knowledge consolidation network ( kcn ) address issue . specifically , devise component , prototype enhanced retrospection hierarchical distillation , mitigate adverse effect semantic ambiguity class imbalance , respectively . experimental result demonstrate effectiveness propose method , outperform state - - - art model 19 % 13.4 % f1 score ace benchmark tac kbp benchmark , respectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
Information Extraction,SelfORE: Self-supervised Relational Feature Learning for Open Relation Extraction,"Open relation extraction is the task of extracting open-domain relation facts from natural language sentences. Existing works either utilize heuristics or distant-supervised annotations to train a supervised classifier over pre-defined relations, or adopt unsupervised methods with additional assumptions that have less discriminative power. In this work, we propose a self-supervised framework named SelfORE, which exploits weak, self-supervised signals by leveraging large pretrained language model for adaptive clustering on contextualized relational features, and bootstraps the self-supervised signals by improving contextualized features in relation classification. Experimental results on three datasets show the effectiveness and robustness of SelfORE on open-domain Relation Extraction when comparing with competitive baselines. Source code is available 1 .","SelfORE: Self-supervised Relational Feature Learning for Open Relation Extraction Open relation extraction is the task of extracting open-domain relation facts from natural language sentences. Existing works either utilize heuristics or distant-supervised annotations to train a supervised classifier over pre-defined relations, or adopt unsupervised methods with additional assumptions that have less discriminative power. In this work, we propose a self-supervised framework named SelfORE, which exploits weak, self-supervised signals by leveraging large pretrained language model for adaptive clustering on contextualized relational features, and bootstraps the self-supervised signals by improving contextualized features in relation classification. Experimental results on three datasets show the effectiveness and robustness of SelfORE on open-domain Relation Extraction when comparing with competitive baselines. Source code is available 1 .","selfore : self - supervise relational feature learning open relation extraction open relation extraction task extract open - domain relation fact natural language sentence . exist work utilize heuristic distant - supervise annotation train supervise classifier pre - defined relation , adopt unsupervised method additional assumption discriminative power . work , propose self - supervise framework name selfore , exploit weak , self - supervise signal leverage large pretrained language model adaptive clustering contextualize relational feature , bootstrap self - supervise signal improve contextualize feature relation classification . experimental result dataset effectiveness robustness selfore open - domain relation extraction compare competitive baseline . source code available 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Pre-training Entity Relation Encoder with Intra-span and Inter-span Information,"In this paper, we integrate span-related information into pre-trained encoder for entity relation extraction task. Instead of using generalpurpose sentence encoder (e.g., existing universal pre-trained models), we introduce a span encoder and a span pair encoder to the pre-training network, which makes it easier to import intra-span and inter-span information into the pre-trained model. To learn the encoders, we devise three customized pretraining objectives from different perspectives, which target on tokens, spans, and span pairs. In particular, a span encoder is trained to recover a random shuffling of tokens in a span, and a span pair encoder is trained to predict positive pairs that are from the same sentences and negative pairs that are from different sentences using contrastive loss. Experimental results show that the proposed pre-training method outperforms distantly supervised pretraining, and achieves promising performance on two entity relation extraction benchmark datasets (ACE05, SciERC).","Pre-training Entity Relation Encoder with Intra-span and Inter-span Information In this paper, we integrate span-related information into pre-trained encoder for entity relation extraction task. Instead of using generalpurpose sentence encoder (e.g., existing universal pre-trained models), we introduce a span encoder and a span pair encoder to the pre-training network, which makes it easier to import intra-span and inter-span information into the pre-trained model. To learn the encoders, we devise three customized pretraining objectives from different perspectives, which target on tokens, spans, and span pairs. In particular, a span encoder is trained to recover a random shuffling of tokens in a span, and a span pair encoder is trained to predict positive pairs that are from the same sentences and negative pairs that are from different sentences using contrastive loss. Experimental results show that the proposed pre-training method outperforms distantly supervised pretraining, and achieves promising performance on two entity relation extraction benchmark datasets (ACE05, SciERC).","pre - training entity relation encoder intra - span inter - span information paper , integrate span - relate information pre - trained encoder entity relation extraction task . instead generalpurpose sentence encoder ( e.g. , exist universal pre - trained model ) , introduce span encoder span pair encoder pre - training network , make easy import intra - span inter - span information pre - trained model . learn encoder , devise customize pretraine objective different perspective , target token , span , span pair . particular , span encoder train recover random shuffling token span , span pair encoder train predict positive pair sentence negative pair different sentence contrastive loss . experimental result propose pre - training method outperform distantly supervise pretraine , achieve promising performance entity relation extraction benchmark dataset ( ace05 , scierc ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 8, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Exploring Contextualized Neural Language Models for Temporal Dependency Parsing,"Extracting temporal relations between events and time expressions has many applications such as constructing event timelines and timerelated question answering. It is a challenging problem which requires syntactic and semantic information at sentence or discourse levels, which may be captured by deep contextualized language models (LMs) such as BERT (Devlin et al., 2019) . In this paper, we develop several variants of BERT-based temporal dependency parser, and show that BERT significantly improves temporal dependency parsing (Zhang and Xue, 2018a) . We also present a detailed analysis on why deep contextualized neural LMs help and where they may fall short.","Exploring Contextualized Neural Language Models for Temporal Dependency Parsing Extracting temporal relations between events and time expressions has many applications such as constructing event timelines and timerelated question answering. It is a challenging problem which requires syntactic and semantic information at sentence or discourse levels, which may be captured by deep contextualized language models (LMs) such as BERT (Devlin et al., 2019) . In this paper, we develop several variants of BERT-based temporal dependency parser, and show that BERT significantly improves temporal dependency parsing (Zhang and Xue, 2018a) . We also present a detailed analysis on why deep contextualized neural LMs help and where they may fall short.","explore contextualize neural language model temporal dependency parsing extract temporal relation event time expression application construct event timeline timerelated question answering . challenging problem require syntactic semantic information sentence discourse level , capture deep contextualized language model ( lms ) bert ( devlin et al . , 2019 ) . paper , develop variant bert - base temporal dependency parser , bert significantly improve temporal dependency parsing ( zhang xue , 2018a ) . present detailed analysis deep contextualize neural lm help fall short .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 8, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
Information Extraction,Design Challenges in Low-resource Cross-lingual Entity Linking,"Cross-lingual Entity Linking (XEL), the problem of grounding mentions of entities in a foreign language text into an English knowledge base such as Wikipedia, has seen a lot of research in recent years, with a range of promising techniques. However, current techniques do not rise to the challenges introduced by text in low-resource languages (LRL) and, surprisingly, fail to generalize to text not taken from Wikipedia, on which they are usually trained. This paper provides a thorough analysis of low-resource XEL techniques, focusing on the key step of identifying candidate English Wikipedia titles that correspond to a given foreign language mention. Our analysis indicates that current methods are limited by their reliance on Wikipedia's interlanguage links and thus suffer when the foreign language's Wikipedia is small. We conclude that the LRL setting requires the use of outside-Wikipedia cross-lingual resources and present a simple yet effective zero-shot XEL system, QuEL, that utilizes search engines query logs. With experiments on 25 languages, QuEL shows an average increase of 25% in gold candidate recall and of 13% in end-to-end linking accuracy over state-of-the-art baselines. 1","Design Challenges in Low-resource Cross-lingual Entity Linking Cross-lingual Entity Linking (XEL), the problem of grounding mentions of entities in a foreign language text into an English knowledge base such as Wikipedia, has seen a lot of research in recent years, with a range of promising techniques. However, current techniques do not rise to the challenges introduced by text in low-resource languages (LRL) and, surprisingly, fail to generalize to text not taken from Wikipedia, on which they are usually trained. This paper provides a thorough analysis of low-resource XEL techniques, focusing on the key step of identifying candidate English Wikipedia titles that correspond to a given foreign language mention. Our analysis indicates that current methods are limited by their reliance on Wikipedia's interlanguage links and thus suffer when the foreign language's Wikipedia is small. We conclude that the LRL setting requires the use of outside-Wikipedia cross-lingual resources and present a simple yet effective zero-shot XEL system, QuEL, that utilizes search engines query logs. With experiments on 25 languages, QuEL shows an average increase of 25% in gold candidate recall and of 13% in end-to-end linking accuracy over state-of-the-art baselines. 1","design challenge low - resource cross - lingual entity linking cross - lingual entity linking ( xel ) , problem ground mention entity foreign language text english knowledge base wikipedia , see lot research recent year , range promising technique . , current technique rise challenge introduce text low - resource language ( lrl ) , surprisingly , fail generalize text take wikipedia , usually train . paper provide thorough analysis low - resource xel technique , focus key step identify candidate english wikipedia title correspond give foreign language mention . analysis indicate current method limit reliance wikipedia interlanguage link suffer foreign language wikipedia small . conclude lrl setting require use outside - wikipedia cross - lingual resource present simple effective zero - shot xel system , quel , utilize search engine query log . experiment 25 language , quel show average increase 25 % gold candidate recall 13 % end - - end link accuracy state - - - art baseline . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Efficient One-Pass End-to-End Entity Linking for Questions,"We present ELQ, a fast end-to-end entity linking model for questions, which uses a biencoder to jointly perform mention detection and linking in one pass. Evaluated on WebQSP and GraphQuestions with extended annotations that cover multiple entities per question, ELQ outperforms the previous state of the art by a large margin of +12.7% and +19.6% F1, respectively. With a very fast inference time (1.57 examples/s on a single CPU), ELQ can be useful for downstream question answering systems. In a proof-of-concept experiment, we demonstrate that using ELQ significantly improves the downstream QA performance of GraphRetriever (Min et al., 2019) . 1","Efficient One-Pass End-to-End Entity Linking for Questions We present ELQ, a fast end-to-end entity linking model for questions, which uses a biencoder to jointly perform mention detection and linking in one pass. Evaluated on WebQSP and GraphQuestions with extended annotations that cover multiple entities per question, ELQ outperforms the previous state of the art by a large margin of +12.7% and +19.6% F1, respectively. With a very fast inference time (1.57 examples/s on a single CPU), ELQ can be useful for downstream question answering systems. In a proof-of-concept experiment, we demonstrate that using ELQ significantly improves the downstream QA performance of GraphRetriever (Min et al., 2019) . 1","efficient - pass end - - end entity linking question present elq , fast end - - end entity linking model question , use biencoder jointly perform mention detection linking pass . evaluate webqsp graphquestion extended annotation cover multiple entity question , elq outperform previous state art large margin +12.7 % +19.6 % f1 , respectively . fast inference time ( 1.57 example / s single cpu ) , elq useful downstream question answer system . proof - - concept experiment , demonstrate elq significantly improve downstream qa performance graphretriever ( min et al . , 2019 ) . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 8, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Information Extraction,Entity Linking in 100 Languages,"We propose a new formulation for multilingual entity linking, where language-specific mentions resolve to a language-agnostic Knowledge Base. We train a dual encoder in this new setting, building on prior work with improved feature representation, negative mining, and an auxiliary entity-pairing task, to obtain a single entity retrieval model that covers 100+ languages and 20 million entities. The model outperforms state-of-the-art results from a far more limited cross-lingual linking task. Rare entities and low-resource languages pose challenges at this large-scale, so we advocate for an increased focus on zero-and few-shot evaluation. To this end, we provide Mewsli-9, a large new multilingual dataset 1 matched to our setting, and show how frequency-based analysis provided key insights for our model and training enhancements.","Entity Linking in 100 Languages We propose a new formulation for multilingual entity linking, where language-specific mentions resolve to a language-agnostic Knowledge Base. We train a dual encoder in this new setting, building on prior work with improved feature representation, negative mining, and an auxiliary entity-pairing task, to obtain a single entity retrieval model that covers 100+ languages and 20 million entities. The model outperforms state-of-the-art results from a far more limited cross-lingual linking task. Rare entities and low-resource languages pose challenges at this large-scale, so we advocate for an increased focus on zero-and few-shot evaluation. To this end, we provide Mewsli-9, a large new multilingual dataset 1 matched to our setting, and show how frequency-based analysis provided key insights for our model and training enhancements.","entity linking 100 language propose new formulation multilingual entity linking , language - specific mention resolve language - agnostic knowledge base . train dual encoder new setting , build prior work improved feature representation , negative mining , auxiliary entity - pairing task , obtain single entity retrieval model cover 100 + language 20 million entity . model outperform state - - - art result far limited cross - lingual linking task . rare entity low - resource language pose challenge large - scale , advocate increase focus zero - - shot evaluation . end , provide mewsli-9 , large new multilingual dataset 1 match setting , frequency - base analysis provide key insight model training enhancement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Retrieval and Text Mining,COMETA: A Corpus for Medical Entity Linking in the Social Media,"Whilst there has been growing progress in Entity Linking (EL) for general language, existing datasets fail to address the complex nature of health terminology in layman's language. Meanwhile, there is a growing need for applications that can understand the public's voice in the health domain. To address this we introduce a new corpus called COMETA, consisting of 20k English biomedical entity mentions from Reddit expert-annotated with links to SNOMED CT, a widely-used medical knowledge graph. Our corpus satisfies a combination of desirable properties, from scale and coverage to diversity and quality, that to the best of our knowledge has not been met by any of the existing resources in the field. Through benchmark experiments on 20 EL baselines from string-to neural-based models we shed light on the ability of these systems to perform complex inference on entities and concepts under 2 challenging evaluation scenarios. Our experimental results on COMETA illustrate that no golden bullet exists and even the best mainstream techniques still have a significant performance gap to fill, while the best solution relies on combining different views of data.","COMETA: A Corpus for Medical Entity Linking in the Social Media Whilst there has been growing progress in Entity Linking (EL) for general language, existing datasets fail to address the complex nature of health terminology in layman's language. Meanwhile, there is a growing need for applications that can understand the public's voice in the health domain. To address this we introduce a new corpus called COMETA, consisting of 20k English biomedical entity mentions from Reddit expert-annotated with links to SNOMED CT, a widely-used medical knowledge graph. Our corpus satisfies a combination of desirable properties, from scale and coverage to diversity and quality, that to the best of our knowledge has not been met by any of the existing resources in the field. Through benchmark experiments on 20 EL baselines from string-to neural-based models we shed light on the ability of these systems to perform complex inference on entities and concepts under 2 challenging evaluation scenarios. Our experimental results on COMETA illustrate that no golden bullet exists and even the best mainstream techniques still have a significant performance gap to fill, while the best solution relies on combining different views of data.","cometa : corpus medical entity linking social media whilst grow progress entity linking ( el ) general language , exist dataset fail address complex nature health terminology layman language . , grow need application understand public voice health domain . address introduce new corpus call cometa , consist 20k english biomedical entity mention reddit expert - annotate link snomed ct , widely - medical knowledge graph . corpus satisfy combination desirable property , scale coverage diversity quality , good knowledge meet exist resource field . benchmark experiment 20 el baseline string - neural - base model shed light ability system perform complex inference entity concept 2 challenging evaluation scenario . experimental result cometa illustrate golden bullet exist good mainstream technique significant performance gap fill , good solution rely combine different view datum .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Information Retrieval and Text Mining,Multi-view Story Characterization from Movie Plot Synopses and Reviews,"This paper considers the problem of characterizing stories by inferring properties such as theme and style using written synopses and reviews of movies. We experiment with a multi-label dataset of movie synopses and a tagset representing various attributes of stories (e.g., genre, type of events). Our proposed multi-view model encodes the synopses and reviews using hierarchical attention and shows improvement over methods that only use synopses. Finally, we demonstrate how can we take advantage of such a model to extract a complementary set of story-attributes from reviews without direct supervision. We have made our dataset and source code publicly available at https://ritual.uh.edu/ multiview-tag-2020. Children Stories Cinderella fantasy, cute, romantic, whimsical, psychedelic https://www.thefablecottage.com/english/cinderella Snow White and the Seven Dwarfs fantasy, psychedelic, romantic, good versus evil, whimsical https://www.storiestogrowby.org/story/ snow-white-and-the-seven-dwarfs-bedtime-stories-for-kids/ The Story of Rapunzel, A Brothers Grimm Fairy Tale fantasy, good versus evil, psychedelic, cute, gothic https://www.storiestogrowby.org/story/ early-reader-rapunzel-fairy-tale-story-kids/ The Frog Prince: The Story of the Princess and the Frog fantasy, cute, whimsical, entertaining, romantic https://www.storiestogrowby.org/story/ princess-and-the-frog-story-bedtime-stories-for-kids/ Aladdin and the Magic Lamp from The Arabian Nights fantasy, good versus evil, action, romantic, whimsical https://www.storiestogrowby.org/story/ aladdin-story-from-the-arabian-nights-bedtime-stories-folk-tales-for-kids/ Modern Ghost Stories https://www.gutenberg.org/files/15143/15143-h/15143-h.htm The Shadows on The Wall by Mary E. Wilkins Freeman haunting, gothic, murder, horror, atmospheric The Mass of Shadows By Anatole France fantasy, atmospheric, gothic, murder, romantic A Ghost By Guy De Maupassant haunting, flashback, atmospheric, murder, paranormal What Was It? By Fitz-James O'Brien paranormal, haunting, gothic, horror, atmospheric Novel Summaries Romeo and Juliet by William Shakespeare revenge, murder, romantic, flashback, tragedy https://www.booksummary.net/romeo-and-juliet-william-shakespeare Harry Potter and Sorcerer's Stone by J. K. Rowling fantasy, good versus evil , entertaining, action, comedy https://www.booksummary.net/harry-potter-and-the-sorcerers-stone-j-k-rowling Oliver Twist by Charles Dickens murder, revenge, flashback, romantic, violence https://www.booksummary.net/oliver-twist-charles-dickens The Hound of the Baskervilles by Arthur Conan Doyle murder, mystery, gothic, paranormal, flashback https://www.booksummary.net/hound-of-baskervilles-arthur-conan-doyle","Multi-view Story Characterization from Movie Plot Synopses and Reviews This paper considers the problem of characterizing stories by inferring properties such as theme and style using written synopses and reviews of movies. We experiment with a multi-label dataset of movie synopses and a tagset representing various attributes of stories (e.g., genre, type of events). Our proposed multi-view model encodes the synopses and reviews using hierarchical attention and shows improvement over methods that only use synopses. Finally, we demonstrate how can we take advantage of such a model to extract a complementary set of story-attributes from reviews without direct supervision. We have made our dataset and source code publicly available at https://ritual.uh.edu/ multiview-tag-2020. Children Stories Cinderella fantasy, cute, romantic, whimsical, psychedelic https://www.thefablecottage.com/english/cinderella Snow White and the Seven Dwarfs fantasy, psychedelic, romantic, good versus evil, whimsical https://www.storiestogrowby.org/story/ snow-white-and-the-seven-dwarfs-bedtime-stories-for-kids/ The Story of Rapunzel, A Brothers Grimm Fairy Tale fantasy, good versus evil, psychedelic, cute, gothic https://www.storiestogrowby.org/story/ early-reader-rapunzel-fairy-tale-story-kids/ The Frog Prince: The Story of the Princess and the Frog fantasy, cute, whimsical, entertaining, romantic https://www.storiestogrowby.org/story/ princess-and-the-frog-story-bedtime-stories-for-kids/ Aladdin and the Magic Lamp from The Arabian Nights fantasy, good versus evil, action, romantic, whimsical https://www.storiestogrowby.org/story/ aladdin-story-from-the-arabian-nights-bedtime-stories-folk-tales-for-kids/ Modern Ghost Stories https://www.gutenberg.org/files/15143/15143-h/15143-h.htm The Shadows on The Wall by Mary E. Wilkins Freeman haunting, gothic, murder, horror, atmospheric The Mass of Shadows By Anatole France fantasy, atmospheric, gothic, murder, romantic A Ghost By Guy De Maupassant haunting, flashback, atmospheric, murder, paranormal What Was It? By Fitz-James O'Brien paranormal, haunting, gothic, horror, atmospheric Novel Summaries Romeo and Juliet by William Shakespeare revenge, murder, romantic, flashback, tragedy https://www.booksummary.net/romeo-and-juliet-william-shakespeare Harry Potter and Sorcerer's Stone by J. K. Rowling fantasy, good versus evil , entertaining, action, comedy https://www.booksummary.net/harry-potter-and-the-sorcerers-stone-j-k-rowling Oliver Twist by Charles Dickens murder, revenge, flashback, romantic, violence https://www.booksummary.net/oliver-twist-charles-dickens The Hound of the Baskervilles by Arthur Conan Doyle murder, mystery, gothic, paranormal, flashback https://www.booksummary.net/hound-of-baskervilles-arthur-conan-doyle","multi - view story characterization movie plot synopsis review paper consider problem characterize story infer property theme style write synopsis review movie . experiment multi - label dataset movie synopsis tagset represent attribute story ( e.g. , genre , type event ) . propose multi - view model encode synopsis review hierarchical attention show improvement method use synopsis . finally , demonstrate advantage model extract complementary set story - attribute review direct supervision . dataset source code publicly available https://ritual.uh.edu/ multiview - tag-2020 . children stories cinderella fantasy , cute , romantic , whimsical , psychedelic https://www.thefablecottage.com/english/cinderella snow white seven dwarfs fantasy , psychedelic , romantic , good versus evil , whimsical https://www.storiestogrowby.org/story/ snow - white - - - seven - dwarf - bedtime - story - - kids/ story rapunzel , brothers grimm fairy tale fantasy , good versus evil , psychedelic , cute , gothic https://www.storiestogrowby.org/story/ early - reader - rapunzel - fairy - tale - story - kids/ frog prince : story princess frog fantasy , cute , whimsical , entertaining , romantic https://www.storiestogrowby.org/story/ princess - - - frog - story - bedtime - story - - kids/ aladdin magic lamp arabian nights fantasy , good versus evil , action , romantic , whimsical https://www.storiestogrowby.org/story/ aladdin - story - - - arabian - night - bedtime - story - folk - tale - - kids/ modern ghost stories https://www.gutenberg.org/files/15143/15143-h/15143-h.htm shadows wall mary e. wilkins freeman haunting , gothic , murder , horror , atmospheric mass shadows anatole france fantasy , atmospheric , gothic , murder , romantic ghost guy de maupassant haunting , flashback , atmospheric , murder , paranormal ? fitz - james o'brien paranormal , haunting , gothic , horror , atmospheric novel summaries romeo juliet william shakespeare revenge , murder , romantic , flashback , tragedy https://www.booksummary.net/romeo-and-juliet-william-shakespeare harry potter sorcerer stone j. k. rowling fantasy , good versus evil , entertaining , action , comedy https://www.booksummary.net/harry-potter-and-the-sorcerers-stone-j-k-rowling oliver twist charles dickens murder , revenge , flashback , romantic , violence https://www.booksummary.net/oliver-twist-charles-dickens hound baskervilles arthur conan doyle murder , mystery , gothic , paranormal , flashback https://www.booksummary.net/hound-of-baskervilles-arthur-conan-doyl","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 16, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Retrieval and Text Mining,Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics too!,"Topic models are a useful analysis tool to uncover the underlying themes within document collections. The dominant approach is to use probabilistic topic models that posit a generative story, but in this paper we propose an alternative way to obtain topics: clustering pretrained word embeddings while incorporating document information for weighted clustering and reranking top words. We provide benchmarks for the combination of different word embeddings and clustering algorithms, and analyse their performance under dimensionality reduction with PCA. The best performing combination for our approach performs as well as classical topic models, but with lower runtime and computational complexity.","Tired of Topic Models? Clusters of Pretrained Word Embeddings Make for Fast and Good Topics too! Topic models are a useful analysis tool to uncover the underlying themes within document collections. The dominant approach is to use probabilistic topic models that posit a generative story, but in this paper we propose an alternative way to obtain topics: clustering pretrained word embeddings while incorporating document information for weighted clustering and reranking top words. We provide benchmarks for the combination of different word embeddings and clustering algorithms, and analyse their performance under dimensionality reduction with PCA. The best performing combination for our approach performs as well as classical topic models, but with lower runtime and computational complexity.","tire topic model ? cluster pretrained word embedding fast good topic ! topic model useful analysis tool uncover underlie theme document collection . dominant approach use probabilistic topic model posit generative story , paper propose alternative way obtain topic : cluster pretrained word embedding incorporate document information weight clustering reranke word . provide benchmark combination different word embedding clustering algorithm , analyse performance dimensionality reduction pca . well perform combination approach perform classical topic model , low runtime computational complexity .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 12, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Modularized Transfomer-based Ranking Framework,"Recent innovations in Transformer-based ranking models have advanced the state-ofthe-art in information retrieval. However, these Transformers are computationally expensive, and their opaque hidden states make it hard to understand the ranking process. In this work, we modularize the Transformer ranker into separate modules for text representation and interaction. We show how this design enables substantially faster ranking using offline pre-computed representations and light-weight online interactions. The modular design is also easier to interpret and sheds light on the ranking process in Transformer rankers. 1","Modularized Transfomer-based Ranking Framework Recent innovations in Transformer-based ranking models have advanced the state-ofthe-art in information retrieval. However, these Transformers are computationally expensive, and their opaque hidden states make it hard to understand the ranking process. In this work, we modularize the Transformer ranker into separate modules for text representation and interaction. We show how this design enables substantially faster ranking using offline pre-computed representations and light-weight online interactions. The modular design is also easier to interpret and sheds light on the ranking process in Transformer rankers. 1","modularize transfomer - base ranking framework recent innovation transformer - base ranking model advance state - ofthe - art information retrieval . , transformers computationally expensive , opaque hide state hard understand ranking process . work , modularize transformer ranker separate module text representation interaction . design enable substantially fast ranking offline pre - computed representation light - weight online interaction . modular design easy interpret shed light ranking process transformer ranker . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Information Retrieval and Text Mining,Exploiting Structured Knowledge in Text via Graph-Guided Representation Learning,"In this work, we aim at equipping pre-trained language models with structured knowledge. We present two self-supervised tasks learning over raw text with the guidance from knowledge graphs. Building upon entity-level masked language models, our first contribution is an entity masking scheme that exploits relational knowledge underlying the text. This is fulfilled by using a linked knowledge graph to select informative entities and then masking their mentions. In addition, we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective that is optimized jointly with masked language model. In contrast to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text. It is more efficient than retrieval-based methods that perform entity linking and integration during finetuning and inference, and generalizes more effectively than the methods that directly learn from concatenated graph triples. Experiments show that our proposed model achieves improved performance on five benchmarks, including question answering and knowledge base completion.","Exploiting Structured Knowledge in Text via Graph-Guided Representation Learning In this work, we aim at equipping pre-trained language models with structured knowledge. We present two self-supervised tasks learning over raw text with the guidance from knowledge graphs. Building upon entity-level masked language models, our first contribution is an entity masking scheme that exploits relational knowledge underlying the text. This is fulfilled by using a linked knowledge graph to select informative entities and then masking their mentions. In addition, we use knowledge graphs to obtain distractors for the masked entities, and propose a novel distractor-suppressed ranking objective that is optimized jointly with masked language model. In contrast to existing paradigms, our approach uses knowledge graphs implicitly, only during pre-training, to inject language models with structured knowledge via learning from raw text. It is more efficient than retrieval-based methods that perform entity linking and integration during finetuning and inference, and generalizes more effectively than the methods that directly learn from concatenated graph triples. Experiments show that our proposed model achieves improved performance on five benchmarks, including question answering and knowledge base completion.","exploit structured knowledge text graph - guide representation learning work , aim equip pre - train language model structured knowledge . present self - supervise task learn raw text guidance knowledge graph . build entity - level mask language model , contribution entity masking scheme exploit relational knowledge underlie text . fulfil link knowledge graph select informative entity mask mention . addition , use knowledge graph obtain distractor mask entity , propose novel distractor - suppress ranking objective optimize jointly mask language model . contrast exist paradigm , approach use knowledge graph implicitly , pre - training , inject language model structured knowledge learn raw text . efficient retrieval - base method perform entity linking integration finetuning inference , generalize effectively method directly learn concatenate graph triple . experiment propose model achieve improved performance benchmark , include question answering knowledge base completion .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 5, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Retrieval and Text Mining,Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy Link Prediction,"Little is known about the trustworthiness of predictions made by knowledge graph embedding (KGE) models. In this paper we take initial steps toward this direction by investigating the calibration of KGE models, or the extent to which they output confidence scores that reflect the expected correctness of predicted knowledge graph triples. We first conduct an evaluation under the standard closed-world assumption (CWA), in which predicted triples not already in the knowledge graph are considered false, and show that existing calibration techniques are effective for KGE under this common but narrow assumption. Next, we introduce the more realistic but challenging open-world assumption (OWA), in which unobserved predictions are not considered true or false until ground-truth labels are obtained. Here, we show that existing calibration techniques are much less effective under the OWA than the CWA, and provide explanations for this discrepancy. Finally, to motivate the utility of calibration for KGE from a practitioner's perspective, we conduct a unique case study of human-AI collaboration, showing that calibrated predictions can improve human performance in a knowledge graph completion task. * This work was done during an internship at Bloomberg.","Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy Link Prediction Little is known about the trustworthiness of predictions made by knowledge graph embedding (KGE) models. In this paper we take initial steps toward this direction by investigating the calibration of KGE models, or the extent to which they output confidence scores that reflect the expected correctness of predicted knowledge graph triples. We first conduct an evaluation under the standard closed-world assumption (CWA), in which predicted triples not already in the knowledge graph are considered false, and show that existing calibration techniques are effective for KGE under this common but narrow assumption. Next, we introduce the more realistic but challenging open-world assumption (OWA), in which unobserved predictions are not considered true or false until ground-truth labels are obtained. Here, we show that existing calibration techniques are much less effective under the OWA than the CWA, and provide explanations for this discrepancy. Finally, to motivate the utility of calibration for KGE from a practitioner's perspective, we conduct a unique case study of human-AI collaboration, showing that calibrated predictions can improve human performance in a knowledge graph completion task. * This work was done during an internship at Bloomberg.","evaluate calibration knowledge graph embedding trustworthy link prediction little know trustworthiness prediction knowledge graph embedding ( kge ) model . paper initial step direction investigate calibration kge model , extent output confidence score reflect expect correctness predict knowledge graph triple . conduct evaluation standard closed - world assumption ( cwa ) , predict triple knowledge graph consider false , exist calibration technique effective kge common narrow assumption . , introduce realistic challenging open - world assumption ( owa ) , unobserved prediction consider true false ground - truth label obtain . , exist calibration technique effective owa cwa , provide explanation discrepancy . finally , motivate utility calibration kge practitioner perspective , conduct unique case study human - ai collaboration , show calibrate prediction improve human performance knowledge graph completion task . * work internship bloomberg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Retrieval and Text Mining,Short Text Topic Modeling with Topic Distribution Quantization and Negative Sampling Decoder,"Topic models have been prevailing for many years on discovering latent semantics while modeling long documents. However, for short texts they generally suffer from data sparsity because of extremely limited word cooccurrences; thus tend to yield repetitive or trivial topics with low quality. In this paper, to address this issue, we propose a novel neural topic model in the framework of autoencoding with a new topic distribution quantization approach generating peakier distributions that are more appropriate for modeling short texts. Besides the encoding, to tackle this issue in terms of decoding, we further propose a novel negative sampling decoder learning from negative samples to avoid yielding repetitive topics. We observe that our model can highly improve short text topic modeling performance. Through extensive experiments on real-world datasets, we demonstrate our model can outperform both strong traditional and neural baselines under extreme data sparsity scenes, producing high-quality topics.","Short Text Topic Modeling with Topic Distribution Quantization and Negative Sampling Decoder Topic models have been prevailing for many years on discovering latent semantics while modeling long documents. However, for short texts they generally suffer from data sparsity because of extremely limited word cooccurrences; thus tend to yield repetitive or trivial topics with low quality. In this paper, to address this issue, we propose a novel neural topic model in the framework of autoencoding with a new topic distribution quantization approach generating peakier distributions that are more appropriate for modeling short texts. Besides the encoding, to tackle this issue in terms of decoding, we further propose a novel negative sampling decoder learning from negative samples to avoid yielding repetitive topics. We observe that our model can highly improve short text topic modeling performance. Through extensive experiments on real-world datasets, we demonstrate our model can outperform both strong traditional and neural baselines under extreme data sparsity scenes, producing high-quality topics.","short text topic modeling topic distribution quantization negative sampling decoder topic model prevail year discover latent semantic model long document . , short text generally suffer datum sparsity extremely limited word cooccurrence ; tend yield repetitive trivial topic low quality . paper , address issue , propose novel neural topic model framework autoencoding new topic distribution quantization approach generate peaki distribution appropriate model short text . encoding , tackle issue term decoding , propose novel negative sampling decoder learn negative sample avoid yield repetitive topic . observe model highly improve short text topic modeling performance . extensive experiment real - world dataset , demonstrate model outperform strong traditional neural baseline extreme datum sparsity scene , produce high - quality topic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 14, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining,"Pre-trained neural language models bring significant improvement for various NLP tasks, by fine-tuning the models on task-specific training sets. During fine-tuning, the parameters are initialized from pre-trained models directly, which ignores how the learning process of similar NLP tasks in different domains is correlated and mutually reinforced. In this paper, we propose an effective learning procedure named Meta Fine-Tuning (MFT), serving as a meta-learner to solve a group of similar NLP tasks for neural language models. Instead of simply multi-task training over all the datasets, MFT only learns from typical instances of various domains to acquire highly transferable knowledge. It further encourages the language model to encode domaininvariant representations by optimizing a series of novel domain corruption loss functions. After MFT, the model can be fine-tuned for each domain with better parameter initialization and higher generalization ability. We implement MFT upon BERT to solve several multi-domain text mining tasks. Experimental results confirm the effectiveness of MFT and its usefulness for few-shot learning. 1","Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining Pre-trained neural language models bring significant improvement for various NLP tasks, by fine-tuning the models on task-specific training sets. During fine-tuning, the parameters are initialized from pre-trained models directly, which ignores how the learning process of similar NLP tasks in different domains is correlated and mutually reinforced. In this paper, we propose an effective learning procedure named Meta Fine-Tuning (MFT), serving as a meta-learner to solve a group of similar NLP tasks for neural language models. Instead of simply multi-task training over all the datasets, MFT only learns from typical instances of various domains to acquire highly transferable knowledge. It further encourages the language model to encode domaininvariant representations by optimizing a series of novel domain corruption loss functions. After MFT, the model can be fine-tuned for each domain with better parameter initialization and higher generalization ability. We implement MFT upon BERT to solve several multi-domain text mining tasks. Experimental results confirm the effectiveness of MFT and its usefulness for few-shot learning. 1","meta fine - tuning neural language model multi - domain text mining pre - trained neural language model bring significant improvement nlp task , fine - tune model task - specific training set . fine - tuning , parameter initialize pre - train model directly , ignore learning process similar nlp task different domain correlate mutually reinforce . paper , propose effective learning procedure name meta fine - tuning ( mft ) , serve meta - learner solve group similar nlp task neural language model . instead simply multi - task training dataset , mft learn typical instance domain acquire highly transferable knowledge . encourage language model encode domaininvariant representation optimize series novel domain corruption loss function . mft , model fine - tune domain well parameter initialization high generalization ability . implement mft bert solve multi - domain text mining task . experimental result confirm effectiveness mft usefulness - shot learning . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Retrieval and Text Mining,Improving Neural Topic Models using Knowledge Distillation,"Topic models are often used to identify humaninterpretable topics to help make sense of large document collections. We use knowledge distillation to combine the best attributes of probabilistic topic models and pretrained transformers. Our modular method can be straightforwardly applied with any neural topic model to improve topic quality, which we demonstrate using two models having disparate architectures, obtaining state-of-the-art topic coherence. We show that our adaptable framework not only improves performance in the aggregate over all estimated topics, as is commonly reported, but also in head-to-head comparisons of aligned topics.","Improving Neural Topic Models using Knowledge Distillation Topic models are often used to identify humaninterpretable topics to help make sense of large document collections. We use knowledge distillation to combine the best attributes of probabilistic topic models and pretrained transformers. Our modular method can be straightforwardly applied with any neural topic model to improve topic quality, which we demonstrate using two models having disparate architectures, obtaining state-of-the-art topic coherence. We show that our adaptable framework not only improves performance in the aggregate over all estimated topics, as is commonly reported, but also in head-to-head comparisons of aligned topics.","improve neural topic model knowledge distillation topic model identify humaninterpretable topic help sense large document collection . use knowledge distillation combine good attribute probabilistic topic model pretrained transformer . modular method straightforwardly apply neural topic model improve topic quality , demonstrate model have disparate architecture , obtain state - - - art topic coherence . adaptable framework improve performance aggregate estimate topic , commonly report , head - - head comparison align topic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 14, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Text Graph Transformer for Document Classification,"Text classification is a fundamental problem in natural language processing. Recent studies applied graph neural network (GNN) techniques to capture global word co-occurrence in a corpus. However, previous works are not scalable to large-sized corpus and ignore the heterogeneity of the text graph. To address these problems, we introduce a novel Transformer based heterogeneous graph neural network, namely Text Graph Transformer (TG-Transformer). Our model learns effective node representations by capturing structure and heterogeneity from the text graph. We propose a mini-batch text graph sampling method that significantly reduces computing and memory costs to handle large-sized corpus. Extensive experiments have been conducted on several benchmark datasets, and the results demonstrate that TG-Transformer outperforms state-of-the-art approaches on text classification task.","Text Graph Transformer for Document Classification Text classification is a fundamental problem in natural language processing. Recent studies applied graph neural network (GNN) techniques to capture global word co-occurrence in a corpus. However, previous works are not scalable to large-sized corpus and ignore the heterogeneity of the text graph. To address these problems, we introduce a novel Transformer based heterogeneous graph neural network, namely Text Graph Transformer (TG-Transformer). Our model learns effective node representations by capturing structure and heterogeneity from the text graph. We propose a mini-batch text graph sampling method that significantly reduces computing and memory costs to handle large-sized corpus. Extensive experiments have been conducted on several benchmark datasets, and the results demonstrate that TG-Transformer outperforms state-of-the-art approaches on text classification task.","text graph transformer document classification text classification fundamental problem natural language processing . recent study apply graph neural network ( gnn ) technique capture global word co - occurrence corpus . , previous work scalable large - sized corpus ignore heterogeneity text graph . address problem , introduce novel transformer base heterogeneous graph neural network , text graph transformer ( tg - transformer ) . model learn effective node representation capture structure heterogeneity text graph . propose mini - batch text graph sampling method significantly reduce computing memory cost handle large - sized corpus . extensive experiment conduct benchmark dataset , result demonstrate tg - transformer outperform state - - - art approach text classification task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 14, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Retrieval and Text Mining,CLIRMatrix: A massively large collection of bilingual and multilingual datasets for Cross-Lingual Information Retrieval,"We present CLIRMatrix, a massively large collection of bilingual and multilingual datasets for Cross-Lingual Information Retrieval extracted automatically from Wikipedia. CLIR-Matrix comprises (1) BI-139, a bilingual dataset of queries in one language matched with relevant documents in another language for 139×138=19,182 language pairs, and (2) MULTI-8, a multilingual dataset of queries and documents jointly aligned in 8 different languages. In total, we mined 49 million unique queries and 34 billion (query, document, label) triplets, making it the largest and most comprehensive CLIR dataset to date. This collection is intended to support research in end-to-end neural information retrieval and is publicly available at https: //github.com/ssun32/CLIRMatrix. We provide baseline neural model results on BI-139, and evaluate MULTI-8 in both singlelanguage retrieval and mix-language retrieval settings.","CLIRMatrix: A massively large collection of bilingual and multilingual datasets for Cross-Lingual Information Retrieval We present CLIRMatrix, a massively large collection of bilingual and multilingual datasets for Cross-Lingual Information Retrieval extracted automatically from Wikipedia. CLIR-Matrix comprises (1) BI-139, a bilingual dataset of queries in one language matched with relevant documents in another language for 139×138=19,182 language pairs, and (2) MULTI-8, a multilingual dataset of queries and documents jointly aligned in 8 different languages. In total, we mined 49 million unique queries and 34 billion (query, document, label) triplets, making it the largest and most comprehensive CLIR dataset to date. This collection is intended to support research in end-to-end neural information retrieval and is publicly available at https: //github.com/ssun32/CLIRMatrix. We provide baseline neural model results on BI-139, and evaluate MULTI-8 in both singlelanguage retrieval and mix-language retrieval settings.","clirmatrix : massively large collection bilingual multilingual dataset cross - lingual information retrieval present clirmatrix , massively large collection bilingual multilingual dataset cross - lingual information retrieval extract automatically wikipedia . clir - matrix comprise ( 1 ) bi-139 , bilingual dataset query language match relevant document language 139×138=19,182 language pair , ( 2 ) multi-8 , multilingual dataset query document jointly align 8 different language . total , mine 49 million unique query 34 billion ( query , document , label ) triplet , make large comprehensive clir dataset date . collection intend support research end - - end neural information retrieval publicly available https : //github.com / ssun32 / clirmatrix . provide baseline neural model result bi-139 , evaluate multi-8 singlelanguage retrieval mix - language retrieval setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and Synonym Discovery,"Entity set expansion and synonym discovery are two critical NLP tasks. Previous studies accomplish them separately, without exploring their interdependences. In this work, we hypothesize that these two tasks are tightly coupled because two synonymous entities tend to have similar likelihoods of belonging to various semantic classes. This motivates us to design SynSetExpan, a novel framework that enables two tasks to mutually enhance each other. SynSetExpan uses a synonym discovery model to include popular entities' infrequent synonyms into the set, which boosts the set expansion recall. Meanwhile, the set expansion model, being able to determine whether an entity belongs to a semantic class, can generate pseudo training data to fine-tune the synonym discovery model towards better accuracy. To facilitate the research on studying the interplays of these two tasks, we create the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via crowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks demonstrate the effectiveness of SynSetExpan for both entity set expansion and synonym discovery tasks.","SynSetExpan: An Iterative Framework for Joint Entity Set Expansion and Synonym Discovery Entity set expansion and synonym discovery are two critical NLP tasks. Previous studies accomplish them separately, without exploring their interdependences. In this work, we hypothesize that these two tasks are tightly coupled because two synonymous entities tend to have similar likelihoods of belonging to various semantic classes. This motivates us to design SynSetExpan, a novel framework that enables two tasks to mutually enhance each other. SynSetExpan uses a synonym discovery model to include popular entities' infrequent synonyms into the set, which boosts the set expansion recall. Meanwhile, the set expansion model, being able to determine whether an entity belongs to a semantic class, can generate pseudo training data to fine-tune the synonym discovery model towards better accuracy. To facilitate the research on studying the interplays of these two tasks, we create the first large-scale Synonym-Enhanced Set Expansion (SE2) dataset via crowdsourcing. Extensive experiments on the SE2 dataset and previous benchmarks demonstrate the effectiveness of SynSetExpan for both entity set expansion and synonym discovery tasks.","synsetexpan : iterative framework joint entity set expansion synonym discovery entity set expansion synonym discovery critical nlp task . previous study accomplish separately , explore interdependence . work , hypothesize task tightly couple synonymous entity tend similar likelihood belong semantic class . motivate design synsetexpan , novel framework enable task mutually enhance . synsetexpan use synonym discovery model include popular entity ' infrequent synonym set , boost set expansion recall . , set expansion model , able determine entity belong semantic class , generate pseudo training datum fine - tune synonym discovery model well accuracy . facilitate research study interplay task , create large - scale synonym - enhanced set expansion ( se2 ) dataset crowdsourcing . extensive experiment se2 dataset previous benchmark demonstrate effectiveness synsetexpan entity set expansion synonym discovery task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Information Retrieval and Text Mining,Ad-hoc Document Retrieval using Weak-Supervision with BERT and GPT2,"We describe a weakly-supervised method for training deep learning models for the task of ad-hoc document retrieval. Our method is based on generative and discriminative models that are trained using weak-supervision based solely on the documents in the corpus. We present an end-to-end retrieval system that starts with traditional information retrieval methods, followed by two deep learning re-rankers. We evaluate our method on three different datasets: a COVID-19 related scientific literature dataset and two news datasets. We show that our method outperforms state-ofthe-art methods; this without the need for the expensive process of manually labeling data.","Ad-hoc Document Retrieval using Weak-Supervision with BERT and GPT2 We describe a weakly-supervised method for training deep learning models for the task of ad-hoc document retrieval. Our method is based on generative and discriminative models that are trained using weak-supervision based solely on the documents in the corpus. We present an end-to-end retrieval system that starts with traditional information retrieval methods, followed by two deep learning re-rankers. We evaluate our method on three different datasets: a COVID-19 related scientific literature dataset and two news datasets. We show that our method outperforms state-ofthe-art methods; this without the need for the expensive process of manually labeling data.","ad - hoc document retrieval weak - supervision bert gpt2 describe weakly - supervise method train deep learning model task ad - hoc document retrieval . method base generative discriminative model train weak - supervision base solely document corpus . present end - - end retrieval system start traditional information retrieval method , follow deep learning - ranker . evaluate method different dataset : covid-19 relate scientific literature dataset news dataset . method outperform state - ofthe - art method ; need expensive process manually label datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Beyond [CLS] through Ranking by Generation,"Generative models for Information Retrieval, where ranking of documents is viewed as the task of generating a query from a document's language model, were very successful in various IR tasks in the past. However, with the advent of modern deep neural networks, attention has shifted to discriminative ranking functions that model the semantic similarity of documents and queries instead. Recently, deep generative models such as GPT2 and BART have been shown to be excellent text generators, but their effectiveness as rankers have not been demonstrated yet. In this work, we revisit the generative framework for information retrieval and show that our generative approaches are as effective as state-of-the-art semantic similarity-based discriminative models for the answer selection task. Additionally, we demonstrate the effectiveness of unlikelihood losses for IR.","Beyond [CLS] through Ranking by Generation Generative models for Information Retrieval, where ranking of documents is viewed as the task of generating a query from a document's language model, were very successful in various IR tasks in the past. However, with the advent of modern deep neural networks, attention has shifted to discriminative ranking functions that model the semantic similarity of documents and queries instead. Recently, deep generative models such as GPT2 and BART have been shown to be excellent text generators, but their effectiveness as rankers have not been demonstrated yet. In this work, we revisit the generative framework for information retrieval and show that our generative approaches are as effective as state-of-the-art semantic similarity-based discriminative models for the answer selection task. Additionally, we demonstrate the effectiveness of unlikelihood losses for IR.","[ cls ] rank generation generative model information retrieval , ranking document view task generate query document language model , successful ir task past . , advent modern deep neural network , attention shift discriminative ranking function model semantic similarity document query instead . recently , deep generative model gpt2 bart show excellent text generator , effectiveness ranker demonstrate . work , revisit generative framework information retrieval generative approach effective state - - - art semantic similarity - base discriminative model answer selection task . additionally , demonstrate effectiveness unlikelihood loss ir .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Information Retrieval and Text Mining,Conditional Causal Relationships between Emotions and Causes in Texts,"The causal relationships between emotions and causes in text have recently received a lot of attention. Most of the existing works focus on the extraction of the causally related clauses from documents. However, none of these works has considered the possibility that the causal relationships among the extracted emotion and cause clauses may only be valid under a specific context, without which the extracted clauses may not be causally related. To address such an issue, we propose a new task of determining whether or not an input pair of emotion and cause has a valid causal relationship under different contexts, and construct a corresponding dataset via manual annotation and negative sampling based on an existing benchmark dataset. Furthermore, we propose a prediction aggregation module with low computational overhead to fine-tune the prediction results based on the characteristics of the input clauses. Experiments demonstrate the effectiveness and generality of our aggregation module.","Conditional Causal Relationships between Emotions and Causes in Texts The causal relationships between emotions and causes in text have recently received a lot of attention. Most of the existing works focus on the extraction of the causally related clauses from documents. However, none of these works has considered the possibility that the causal relationships among the extracted emotion and cause clauses may only be valid under a specific context, without which the extracted clauses may not be causally related. To address such an issue, we propose a new task of determining whether or not an input pair of emotion and cause has a valid causal relationship under different contexts, and construct a corresponding dataset via manual annotation and negative sampling based on an existing benchmark dataset. Furthermore, we propose a prediction aggregation module with low computational overhead to fine-tune the prediction results based on the characteristics of the input clauses. Experiments demonstrate the effectiveness and generality of our aggregation module.","conditional causal relationship emotion cause text causal relationship emotion cause text recently receive lot attention . exist work focus extraction causally related clause document . , work consider possibility causal relationship extract emotion cause clause valid specific context , extract clause causally relate . address issue , propose new task determine input pair emotion cause valid causal relationship different context , construct corresponding dataset manual annotation negative sampling base exist benchmark dataset . furthermore , propose prediction aggregation module low computational overhead fine - tune prediction result base characteristic input clause . experiment demonstrate effectiveness generality aggregation module .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 13, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Information Retrieval and Text Mining,Neural Topic Modeling with Cycle-Consistent Adversarial Training,"Advances on deep generative models have attracted significant research interest in neural topic modeling. The recently proposed Adversarial-neural Topic Model models topics with an adversarially trained generator network and employs Dirichlet prior to capture the semantic patterns in latent topics. It is effective in discovering coherent topics but unable to infer topic distributions for given documents or utilize available document labels. To overcome such limitations, we propose Topic Modeling with Cycle-consistent Adversarial Training (ToMCAT) and its supervised version sToMCAT. ToMCAT employs a generator network to interpret topics and an encoder network to infer document topics. Adversarial training and cycle-consistent constraints are used to encourage the generator and the encoder to produce realistic samples that coordinate with each other. sToMCAT extends ToM-CAT by incorporating document labels into the topic modeling process to help discover more coherent topics. The effectiveness of the proposed models is evaluated on unsupervised/supervised topic modeling and text classification. The experimental results show that our models can produce both coherent and informative topics, outperforming a number of competitive baselines.","Neural Topic Modeling with Cycle-Consistent Adversarial Training Advances on deep generative models have attracted significant research interest in neural topic modeling. The recently proposed Adversarial-neural Topic Model models topics with an adversarially trained generator network and employs Dirichlet prior to capture the semantic patterns in latent topics. It is effective in discovering coherent topics but unable to infer topic distributions for given documents or utilize available document labels. To overcome such limitations, we propose Topic Modeling with Cycle-consistent Adversarial Training (ToMCAT) and its supervised version sToMCAT. ToMCAT employs a generator network to interpret topics and an encoder network to infer document topics. Adversarial training and cycle-consistent constraints are used to encourage the generator and the encoder to produce realistic samples that coordinate with each other. sToMCAT extends ToM-CAT by incorporating document labels into the topic modeling process to help discover more coherent topics. The effectiveness of the proposed models is evaluated on unsupervised/supervised topic modeling and text classification. The experimental results show that our models can produce both coherent and informative topics, outperforming a number of competitive baselines.","neural topic modeling cycle - consistent adversarial training advances deep generative model attract significant research interest neural topic modeling . recently propose adversarial - neural topic model model topic adversarially train generator network employ dirichlet prior capture semantic pattern latent topic . effective discover coherent topic unable infer topic distribution give document utilize available document label . overcome limitation , propose topic modeling cycle - consistent adversarial training ( tomcat ) supervise version stomcat . tomcat employ generator network interpret topic encoder network infer document topic . adversarial training cycle - consistent constraint encourage generator encoder produce realistic sample coordinate . stomcat extend tom - cat incorporate document label topic modeling process help discover coherent topic . effectiveness propose model evaluate unsupervised / supervised topic modeling text classification . experimental result model produce coherent informative topic , outperform number competitive baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 26, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Named Entity Recognition Only from Word Embeddings,"Deep neural network models have helped named entity recognition achieve amazing performance without handcrafting features. However, existing systems require large amounts of human annotated training data. Efforts have been made to replace human annotations with external knowledge (e.g., NE dictionary, partof-speech tags), while it is another challenge to obtain such effective resources. In this work, we propose a fully unsupervised NE recognition model which only needs to take informative clues from pre-trained word embeddings. We first apply Gaussian Hidden Markov Model and Deep Autoencoding Gaussian Mixture Model on word embeddings for entity span detection and type prediction, and then further design an instance selector based on reinforcement learning to distinguish positive sentences from noisy sentences and then refine these coarse-grained annotations through neural networks. Extensive experiments on two CoNLL benchmark NER datasets (CoNLL-2003 English dataset and CoNLL-2002 Spanish dataset) demonstrate that our proposed light NE recognition model achieves remarkable performance without using any annotated lexicon or corpus.","Named Entity Recognition Only from Word Embeddings Deep neural network models have helped named entity recognition achieve amazing performance without handcrafting features. However, existing systems require large amounts of human annotated training data. Efforts have been made to replace human annotations with external knowledge (e.g., NE dictionary, partof-speech tags), while it is another challenge to obtain such effective resources. In this work, we propose a fully unsupervised NE recognition model which only needs to take informative clues from pre-trained word embeddings. We first apply Gaussian Hidden Markov Model and Deep Autoencoding Gaussian Mixture Model on word embeddings for entity span detection and type prediction, and then further design an instance selector based on reinforcement learning to distinguish positive sentences from noisy sentences and then refine these coarse-grained annotations through neural networks. Extensive experiments on two CoNLL benchmark NER datasets (CoNLL-2003 English dataset and CoNLL-2002 Spanish dataset) demonstrate that our proposed light NE recognition model achieves remarkable performance without using any annotated lexicon or corpus.","name entity recognition word embedding deep neural network model help name entity recognition achieve amazing performance handcrafting feature . , exist system require large amount human annotate training datum . effort replace human annotation external knowledge ( e.g. , ne dictionary , partof - speech tag ) , challenge obtain effective resource . work , propose fully unsupervised ne recognition model need informative clue pre - trained word embedding . apply gaussian hidden markov model deep autoencoding gaussian mixture model word embedding entity span detection type prediction , design instance selector base reinforcement learning distinguish positive sentence noisy sentence refine coarse - grained annotation neural network . extensive experiment conll benchmark ner dataset ( conll-2003 english dataset conll-2002 spanish dataset ) demonstrate propose light ne recognition model achieve remarkable performance annotate lexicon corpus .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 5, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Information Retrieval and Text Mining,Multi-document Summarization with Maximal Marginal Relevance-guided Reinforcement Learning,"While neural sequence learning methods have made significant progress in single-document summarization (SDS), they produce unsatisfactory results on multi-document summarization (MDS). We observe two major challenges when adapting SDS advances to MDS: (1) MDS involves larger search space and yet more limited training data, setting obstacles for neural methods to learn adequate representations; (2) MDS needs to resolve higher information redundancy among the source documents, which SDS methods are less effective to handle. To close the gap, we present RL-MMR, Maximal Margin Relevance-guided Reinforcement Learning for MDS, which unifies advanced neural SDS methods and statistical measures used in classical MDS. RL-MMR casts MMR guidance on fewer promising candidates, which restrains the search space and thus leads to better representation learning. Additionally, the explicit redundancy measure in MMR helps the neural representation of the summary to better capture redundancy. Extensive experiments demonstrate that RL-MMR achieves state-of-the-art performance on benchmark MDS datasets. In particular, we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and efficiency. 1","Multi-document Summarization with Maximal Marginal Relevance-guided Reinforcement Learning While neural sequence learning methods have made significant progress in single-document summarization (SDS), they produce unsatisfactory results on multi-document summarization (MDS). We observe two major challenges when adapting SDS advances to MDS: (1) MDS involves larger search space and yet more limited training data, setting obstacles for neural methods to learn adequate representations; (2) MDS needs to resolve higher information redundancy among the source documents, which SDS methods are less effective to handle. To close the gap, we present RL-MMR, Maximal Margin Relevance-guided Reinforcement Learning for MDS, which unifies advanced neural SDS methods and statistical measures used in classical MDS. RL-MMR casts MMR guidance on fewer promising candidates, which restrains the search space and thus leads to better representation learning. Additionally, the explicit redundancy measure in MMR helps the neural representation of the summary to better capture redundancy. Extensive experiments demonstrate that RL-MMR achieves state-of-the-art performance on benchmark MDS datasets. In particular, we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and efficiency. 1","multi - document summarization maximal marginal relevance - guide reinforcement learning neural sequence learning method significant progress single - document summarization ( sds ) , produce unsatisfactory result multi - document summarization ( mds ) . observe major challenge adapt sds advance mds : ( 1 ) mds involve large search space limited training datum , set obstacle neural method learn adequate representation ; ( 2 ) mds need resolve high information redundancy source document , sds method effective handle . close gap , present rl - mmr , maximal margin relevance - guide reinforcement learning mds , unify advanced neural sds method statistical measure classical mds . rl - mmr cast mmr guidance few promising candidate , restrain search space lead well representation learning . additionally , explicit redundancy measure mmr help neural representation summary well capture redundancy . extensive experiment demonstrate rl - mmr achieve state - - - art performance benchmark mds dataset . particular , benefit incorporate mmr end - - end learning adapt sds mds term learning effectiveness efficiency . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,False
Information Retrieval and Text Mining,Towards More Accurate Uncertainty Estimation In Text Classification,"The uncertainty measurement of classified results is especially important in areas requiring limited human resources for higher accuracy. For instance, data-driven algorithms diagnosing diseases need accurate uncertainty score to decide whether additional but limited quantity of experts are needed for rectification. However, few uncertainty models focus on improving the performance of text classification where human resources are involved. To achieve this, we aim at generating accurate uncertainty score by improving the confidence of winning scores. Thus, a model called MSD, which includes three independent components as ""mix-up"", ""self-ensembling"", ""distinctiveness score"", is proposed to improve the accuracy of uncertainty score by reducing the effect of overconfidence of winning score and considering the impact of different categories of uncertainty simultaneously. MSD can be applied with different Deep Neural Networks. Extensive experiments with ablation setting are conducted on four real-world datasets, on which, competitive results are obtained.","Towards More Accurate Uncertainty Estimation In Text Classification The uncertainty measurement of classified results is especially important in areas requiring limited human resources for higher accuracy. For instance, data-driven algorithms diagnosing diseases need accurate uncertainty score to decide whether additional but limited quantity of experts are needed for rectification. However, few uncertainty models focus on improving the performance of text classification where human resources are involved. To achieve this, we aim at generating accurate uncertainty score by improving the confidence of winning scores. Thus, a model called MSD, which includes three independent components as ""mix-up"", ""self-ensembling"", ""distinctiveness score"", is proposed to improve the accuracy of uncertainty score by reducing the effect of overconfidence of winning score and considering the impact of different categories of uncertainty simultaneously. MSD can be applied with different Deep Neural Networks. Extensive experiments with ablation setting are conducted on four real-world datasets, on which, competitive results are obtained.","accurate uncertainty estimation text classification uncertainty measurement classify result especially important area require limited human resource high accuracy . instance , data - drive algorithm diagnose disease need accurate uncertainty score decide additional limited quantity expert need rectification . , uncertainty model focus improve performance text classification human resource involve . achieve , aim generate accurate uncertainty score improve confidence win score . , model call msd , include independent component "" mix - "" , "" self - ensembling "" , "" distinctiveness score "" , propose improve accuracy uncertainty score reduce effect overconfidence win score consider impact different category uncertainty simultaneously . msd apply different deep neural networks . extensive experiment ablation setting conduct real - world dataset , , competitive result obtain .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,CoDEx: A Comprehensive Knowledge Graph Completion Benchmark,"We present CODEX, a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CODEX comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CODEX, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CODEX dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CODEX for five extensively tuned embedding models. Finally, we differentiate CODEX from the popular FB15K-237 knowledge graph completion dataset by showing that CODEX covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs. CODEX-S CODEX-M Uniform Relative freq. Hard neg. Uniform","CoDEx: A Comprehensive Knowledge Graph Completion Benchmark We present CODEX, a set of knowledge graph COmpletion Datasets EXtracted from Wikidata and Wikipedia that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CODEX comprises three knowledge graphs varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CODEX, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CODEX dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CODEX for five extensively tuned embedding models. Finally, we differentiate CODEX from the popular FB15K-237 knowledge graph completion dataset by showing that CODEX covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs. CODEX-S CODEX-M Uniform Relative freq. Hard neg. Uniform","codex : comprehensive knowledge graph completion benchmark present codex , set knowledge graph completion dataset extract wikidata wikipedia improve exist knowledge graph completion benchmark scope level difficulty . term scope , codex comprise knowledge graph vary size structure , multilingual description entity relation , ten thousand hard negative triple plausible verify false . characterize codex , contribute thorough empirical analysis benchmarking experiment . , analyze codex dataset term logical relation pattern . , report baseline link prediction triple classification result codex extensively tune embed model . finally , differentiate codex popular fb15k-237 knowledge graph completion dataset show codex cover diverse interpretable content , difficult link prediction benchmark . datum , code , pretrained model available https://bit.ly/2epbrjs . codex - s codex - m uniform relative freq . hard neg . uniform","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 12, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Information Retrieval and Text Mining,Incorporating Multimodal Information in Open-Domain Web Keyphrase Extraction,"Open-domain Keyphrase extraction (KPE) on the Web is a fundamental yet complex NLP task with a wide range of practical applications within the field of Information Retrieval. In contrast to other document types, web page designs are intended for easy navigation and information finding. Effective designs encode within the layout and formatting signals that point to where the important information can be found. In this work, we propose a modeling approach that leverages these multi-modal signals to aid in the KPE task. In particular, we leverage both lexical and visual features (e.g., size, font, position) at the micro-level to enable effective strategy induction, and metalevel features that describe pages at a macrolevel to aid in strategy selection. Our evaluation demonstrates that a combination of effective strategy induction and strategy selection within this approach for the KPE task outperforms state-of-the-art models. A qualitative post-hoc analysis illustrates how these features function within the model.","Incorporating Multimodal Information in Open-Domain Web Keyphrase Extraction Open-domain Keyphrase extraction (KPE) on the Web is a fundamental yet complex NLP task with a wide range of practical applications within the field of Information Retrieval. In contrast to other document types, web page designs are intended for easy navigation and information finding. Effective designs encode within the layout and formatting signals that point to where the important information can be found. In this work, we propose a modeling approach that leverages these multi-modal signals to aid in the KPE task. In particular, we leverage both lexical and visual features (e.g., size, font, position) at the micro-level to enable effective strategy induction, and metalevel features that describe pages at a macrolevel to aid in strategy selection. Our evaluation demonstrates that a combination of effective strategy induction and strategy selection within this approach for the KPE task outperforms state-of-the-art models. A qualitative post-hoc analysis illustrates how these features function within the model.","incorporate multimodal information open - domain web keyphrase extraction open - domain keyphrase extraction ( kpe ) web fundamental complex nlp task wide range practical application field information retrieval . contrast document type , web page design intend easy navigation information finding . effective design encode layout formatting signal point important information find . work , propose modeling approach leverage multi - modal signal aid kpe task . particular , leverage lexical visual feature ( e.g. , size , font , position ) micro - level enable effective strategy induction , metalevel feature describe page macrolevel aid strategy selection . evaluation demonstrate combination effective strategy induction strategy selection approach kpe task outperform state - - - art model . qualitative post - hoc analysis illustrate feature function model .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Information Retrieval and Text Mining,META: Metadata-Empowered Weak Supervision for Text Classification,"Recent advances in weakly supervised learning enable training high-quality text classifiers by only providing a few user-provided seed words. Existing methods mainly use text data alone to generate pseudo-labels despite the fact that metadata information (e.g., author and timestamp) is widely available across various domains. Strong label indicators exist in the metadata and it has been long overlooked mainly due to the following challenges: (1) metadata is multi-typed, requiring systematic modeling of different types and their combinations, (2) metadata is noisy, some metadata entities (e.g., authors, venues) are more compelling label indicators than others. In this paper, we propose a novel framework, META, which goes beyond the existing paradigm and leverages metadata as an additional source of weak supervision. Specifically, we organize the text data and metadata together into a text-rich network and adopt network motifs to capture appropriate combinations of metadata. Based on seed words, we rank and filter motif instances to distill highly label-indicative ones as ""seed motifs"", which provide additional weak supervision. Following a bootstrapping manner, we train the classifier and expand the seed words and seed motifs iteratively. Extensive experiments and case studies on real-world datasets demonstrate superior performance and significant advantages of leveraging metadata as weak supervision.","META: Metadata-Empowered Weak Supervision for Text Classification Recent advances in weakly supervised learning enable training high-quality text classifiers by only providing a few user-provided seed words. Existing methods mainly use text data alone to generate pseudo-labels despite the fact that metadata information (e.g., author and timestamp) is widely available across various domains. Strong label indicators exist in the metadata and it has been long overlooked mainly due to the following challenges: (1) metadata is multi-typed, requiring systematic modeling of different types and their combinations, (2) metadata is noisy, some metadata entities (e.g., authors, venues) are more compelling label indicators than others. In this paper, we propose a novel framework, META, which goes beyond the existing paradigm and leverages metadata as an additional source of weak supervision. Specifically, we organize the text data and metadata together into a text-rich network and adopt network motifs to capture appropriate combinations of metadata. Based on seed words, we rank and filter motif instances to distill highly label-indicative ones as ""seed motifs"", which provide additional weak supervision. Following a bootstrapping manner, we train the classifier and expand the seed words and seed motifs iteratively. Extensive experiments and case studies on real-world datasets demonstrate superior performance and significant advantages of leveraging metadata as weak supervision.","meta : metadata - empower weak supervision text classification recent advance weakly supervise learning enable train high - quality text classifier provide user - provide seed word . exist method mainly use text datum generate pseudo - label despite fact metadata information ( e.g. , author timestamp ) widely available domain . strong label indicator exist metadata long overlook mainly following challenge : ( 1 ) metadata multi - typed , require systematic modeling different type combination , ( 2 ) metadata noisy , metadata entity ( e.g. , author , venue ) compelling label indicator . paper , propose novel framework , meta , go exist paradigm leverage metadata additional source weak supervision . specifically , organize text datum metadata text - rich network adopt network motif capture appropriate combination metadata . base seed word , rank filter motif instance distill highly label - indicative one "" seed motif "" , provide additional weak supervision . follow bootstrappe manner , train classifier expand seed word seed motif iteratively . extensive experiment case study real - world dataset demonstrate superior performance significant advantage leverage metadata weak supervision .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Interpretability and Analysis of Models for NLP,How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking,"Attribution methods assess the contribution of inputs to the model prediction. One way to do so is erasure: a subset of inputs is considered irrelevant if it can be removed without affecting the prediction. Though conceptually simple, erasure's objective is intractable and approximate search remains expensive with modern deep NLP models. Erasure is also susceptible to the hindsight bias: the fact that an input can be dropped does not mean that the model 'knows' it can be dropped. The resulting pruning is over-aggressive and does not reflect how the model arrives at the prediction. To deal with these challenges, we introduce Differentiable Masking. DIFFMASK learns to maskout subsets of the input while maintaining differentiability. The decision to include or disregard an input token is made with a simple model based on intermediate hidden layers of the analyzed model. First, this makes the approach efficient because we predict rather than search. Second, as with probing classifiers, this reveals what the network 'knows' at the corresponding layers. This lets us not only plot attribution heatmaps but also analyze how decisions are formed across network layers. We use DIFFMASK to study BERT models on sentiment classification and question answering. 1","How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking Attribution methods assess the contribution of inputs to the model prediction. One way to do so is erasure: a subset of inputs is considered irrelevant if it can be removed without affecting the prediction. Though conceptually simple, erasure's objective is intractable and approximate search remains expensive with modern deep NLP models. Erasure is also susceptible to the hindsight bias: the fact that an input can be dropped does not mean that the model 'knows' it can be dropped. The resulting pruning is over-aggressive and does not reflect how the model arrives at the prediction. To deal with these challenges, we introduce Differentiable Masking. DIFFMASK learns to maskout subsets of the input while maintaining differentiability. The decision to include or disregard an input token is made with a simple model based on intermediate hidden layers of the analyzed model. First, this makes the approach efficient because we predict rather than search. Second, as with probing classifiers, this reveals what the network 'knows' at the corresponding layers. This lets us not only plot attribution heatmaps but also analyze how decisions are formed across network layers. We use DIFFMASK to study BERT models on sentiment classification and question answering. 1","decision emerge layer neural model ? interpretation differentiable masking attribution method assess contribution input model prediction . way erasure : subset input consider irrelevant remove affect prediction . conceptually simple , erasure objective intractable approximate search remain expensive modern deep nlp model . erasure susceptible hindsight bias : fact input drop mean model ' know ' drop . result pruning - aggressive reflect model arrive prediction . deal challenge , introduce differentiable masking . diffmask learn maskout subset input maintain differentiability . decision include disregard input token simple model base intermediate hide layer analyze model . , make approach efficient predict search . second , probe classifier , reveal network ' know ' corresponding layer . let plot attribution heatmap analyze decision form network layer . use diffmask study bert model sentiment classification question answering . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Detecting Independent Pronoun Bias with Partially-Synthetic Data Generation,"We report that state-of-the-art parsers consistently failed to identify ""hers"" and ""theirs"" as pronouns but identified the masculine equivalent ""his"". We find that the same biases exist in recent language models like BERT. While some of the bias comes from known sources, like training data with gender imbalances, we find that the bias is amplified in the language models and that linguistic differences between English pronouns that are not inherently biased can become biases in some machine learning models. We introduce a new technique for measuring bias in models, using Bayesian approximations to generate partially-synthetic data from the model itself.","Detecting Independent Pronoun Bias with Partially-Synthetic Data Generation We report that state-of-the-art parsers consistently failed to identify ""hers"" and ""theirs"" as pronouns but identified the masculine equivalent ""his"". We find that the same biases exist in recent language models like BERT. While some of the bias comes from known sources, like training data with gender imbalances, we find that the bias is amplified in the language models and that linguistic differences between English pronouns that are not inherently biased can become biases in some machine learning models. We introduce a new technique for measuring bias in models, using Bayesian approximations to generate partially-synthetic data from the model itself.","detect independent pronoun bias partially - synthetic data generation report state - - - art parser consistently fail identify "" "" "" their "" pronoun identify masculine equivalent "" "" . find bias exist recent language model like bert . bias come know source , like training datum gender imbalance , find bias amplify language model linguistic difference english pronoun inherently biased bias machine learning model . introduce new technique measure bias model , bayesian approximation generate partially - synthetic datum model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 8, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Interpretability and Analysis of Models for NLP,Less is More: Attention Supervision with Counterfactuals for Text Classification,"We aim to leverage human and machine intelligence together for attention supervision. Specifically, we show that human annotation cost can be kept reasonably low, while its quality can be enhanced by machine selfsupervision. Specifically, for this goal, we explore the advantage of counterfactual reasoning, over associative reasoning typically used in attention supervision. Our empirical results show that this machine-augmented human attention supervision is more effective than existing methods requiring a higher annotation cost, in text classification tasks, including sentiment analysis and news categorization.","Less is More: Attention Supervision with Counterfactuals for Text Classification We aim to leverage human and machine intelligence together for attention supervision. Specifically, we show that human annotation cost can be kept reasonably low, while its quality can be enhanced by machine selfsupervision. Specifically, for this goal, we explore the advantage of counterfactual reasoning, over associative reasoning typically used in attention supervision. Our empirical results show that this machine-augmented human attention supervision is more effective than existing methods requiring a higher annotation cost, in text classification tasks, including sentiment analysis and news categorization.",": attention supervision counterfactual text classification aim leverage human machine intelligence attention supervision . specifically , human annotation cost keep reasonably low , quality enhance machine selfsupervision . specifically , goal , explore advantage counterfactual reasoning , associative reasoning typically attention supervision . empirical result machine - augment human attention supervision effective exist method require high annotation cost , text classification task , include sentiment analysis news categorization .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Interpretability and Analysis of Models for NLP,Avoiding the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training,"Natural Language Inference (NLI) datasets contain annotation artefacts resulting in spurious correlations between the natural language utterances and their respective entailment classes. These artefacts are exploited by neural networks even when only considering the hypothesis and ignoring the premise, leading to unwanted biases. Belinkov et al. (2019b) proposed tackling this problem via adversarial training, but this can lead to learned sentence representations that still suffer from the same biases. We show that the bias can be reduced in the sentence representations by using an ensemble of adversaries, encouraging the model to jointly decrease the accuracy of these different adversaries while fitting the data. This approach produces more robust NLI models, outperforming previous de-biasing efforts when generalised to 12 other NLI datasets (Belinkov et al., 2019a; Mahabadi et al., 2020) . In addition, we find that the optimal number of adversarial classifiers depends on the dimensionality of the sentence representations, with larger sentence representations being more difficult to de-bias while benefiting from using a greater number of adversaries.","Avoiding the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training Natural Language Inference (NLI) datasets contain annotation artefacts resulting in spurious correlations between the natural language utterances and their respective entailment classes. These artefacts are exploited by neural networks even when only considering the hypothesis and ignoring the premise, leading to unwanted biases. Belinkov et al. (2019b) proposed tackling this problem via adversarial training, but this can lead to learned sentence representations that still suffer from the same biases. We show that the bias can be reduced in the sentence representations by using an ensemble of adversaries, encouraging the model to jointly decrease the accuracy of these different adversaries while fitting the data. This approach produces more robust NLI models, outperforming previous de-biasing efforts when generalised to 12 other NLI datasets (Belinkov et al., 2019a; Mahabadi et al., 2020) . In addition, we find that the optimal number of adversarial classifiers depends on the dimensionality of the sentence representations, with larger sentence representations being more difficult to de-bias while benefiting from using a greater number of adversaries.","avoid hypothesis - bias natural language inference ensemble adversarial training natural language inference ( nli ) dataset contain annotation artefact result spurious correlation natural language utterance respective entailment class . artefact exploit neural network consider hypothesis ignore premise , lead unwanted bias . belinkov et al . ( 2019b ) propose tackle problem adversarial training , lead learn sentence representation suffer bias . bias reduce sentence representation ensemble adversary , encourage model jointly decrease accuracy different adversary fit datum . approach produce robust nli model , outperform previous de - biasing effort generalise 12 nli dataset ( belinkov et al . , 2019a ; mahabadi et al . , 2020 ) . addition , find optimal number adversarial classifier depend dimensionality sentence representation , large sentence representation difficult de - bias benefit great number adversary .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 6, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Interpretability and Analysis of Models for NLP,Retrofitting Structure-aware Transformer Language Model for End Tasks,"We consider retrofitting structure-aware Transformer language model for facilitating end tasks by proposing to exploit syntactic distance to encode both the phrasal constituency and dependency connection into the language model. A middle-layer structural learning strategy is leveraged for structure integration, accomplished with main semantic task training under multi-task learning scheme. Experimental results show that the retrofitted structure-aware Transformer language model achieves improved perplexity, meanwhile inducing accurate syntactic phrases. By performing structure-aware fine-tuning, our model achieves significant improvements for both semantic-and syntactic-dependent tasks.","Retrofitting Structure-aware Transformer Language Model for End Tasks We consider retrofitting structure-aware Transformer language model for facilitating end tasks by proposing to exploit syntactic distance to encode both the phrasal constituency and dependency connection into the language model. A middle-layer structural learning strategy is leveraged for structure integration, accomplished with main semantic task training under multi-task learning scheme. Experimental results show that the retrofitted structure-aware Transformer language model achieves improved perplexity, meanwhile inducing accurate syntactic phrases. By performing structure-aware fine-tuning, our model achieves significant improvements for both semantic-and syntactic-dependent tasks.","retrofit structure - aware transformer language model end task consider retrofit structure - aware transformer language model facilitate end task propose exploit syntactic distance encode phrasal constituency dependency connection language model . middle - layer structural learning strategy leverage structure integration , accomplish main semantic task training multi - task learning scheme . experimental result retrofit structure - aware transformer language model achieve improved perplexity , induce accurate syntactic phrase . perform structure - aware fine - tuning , model achieve significant improvement semantic - syntactic - dependent task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models,"Warning: This paper contains explicit statements of offensive stereotypes and may be upsetting. Pretrained language models, especially masked language models (MLMs) have seen success across many NLP tasks. However, there is ample evidence that they use the cultural biases that are undoubtedly present in the corpora they are trained on, implicitly creating harm with biased representations. To measure some forms of social bias in language models against protected demographic groups in the US, we introduce the Crowdsourced Stereotype Pairs benchmark (CrowS-Pairs). CrowS-Pairs has 1508 examples that cover stereotypes dealing with nine types of bias, like race, religion, and age. In CrowS-Pairs a model is presented with two sentences: one that is more stereotyping and another that is less stereotyping. The data focuses on stereotypes about historically disadvantaged groups and contrasts them with advantaged groups. We find that all three of the widelyused MLMs we evaluate substantially favor sentences that express stereotypes in every category in CrowS-Pairs. As work on building less biased models advances, this dataset can be used as a benchmark to evaluate progress.","CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models Warning: This paper contains explicit statements of offensive stereotypes and may be upsetting. Pretrained language models, especially masked language models (MLMs) have seen success across many NLP tasks. However, there is ample evidence that they use the cultural biases that are undoubtedly present in the corpora they are trained on, implicitly creating harm with biased representations. To measure some forms of social bias in language models against protected demographic groups in the US, we introduce the Crowdsourced Stereotype Pairs benchmark (CrowS-Pairs). CrowS-Pairs has 1508 examples that cover stereotypes dealing with nine types of bias, like race, religion, and age. In CrowS-Pairs a model is presented with two sentences: one that is more stereotyping and another that is less stereotyping. The data focuses on stereotypes about historically disadvantaged groups and contrasts them with advantaged groups. We find that all three of the widelyused MLMs we evaluate substantially favor sentences that express stereotypes in every category in CrowS-Pairs. As work on building less biased models advances, this dataset can be used as a benchmark to evaluate progress.","crows - pairs : challenge dataset measure social bias mask language model warning : paper contain explicit statement offensive stereotype upsetting . pretrained language model , especially mask language model ( mlms ) see success nlp task . , ample evidence use cultural bias undoubtedly present corpora train , implicitly create harm biased representation . measure form social bias language model protect demographic group , introduce crowdsourced stereotype pairs benchmark ( crows - pairs ) . crows - pairs 1508 example cover stereotype deal type bias , like race , religion , age . crows - pairs model present sentence : stereotype stereotype . data focus stereotype historically disadvantaged group contrast advantaged group . find widelyused mlm evaluate substantially favor sentence express stereotype category crows - pairs . work build biased model advance , dataset benchmark evaluate progress .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 10, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Interpretability and Analysis of Models for NLP,Adversarial Semantic Collisions,"We study semantic collisions: texts that are semantically unrelated but judged as similar by NLP models. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of texts-including paraphrase identification, document retrieval, response suggestion, and extractive summarization-are vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at https://github.com/ csong27/collision-bert.","Adversarial Semantic Collisions We study semantic collisions: texts that are semantically unrelated but judged as similar by NLP models. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of texts-including paraphrase identification, document retrieval, response suggestion, and extractive summarization-are vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at https://github.com/ csong27/collision-bert.","adversarial semantic collisions study semantic collision : text semantically unrelated judge similar nlp model . develop gradient - base approach generate semantic collision demonstrate state - - - art model task rely analyze meaning similarity text - include paraphrase identification , document retrieval , response suggestion , extractive summarization - vulnerable semantic collision . example , give target query , insert craft collision irrelevant document shift retrieval rank 1000 3 . generate semantic collision evade perplexity - base filtering discuss potential mitigation . code available https://github.com/ csong27 / collision - bert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Interpretability and Analysis of Models for NLP,F1 is Not Enough! Models and Evaluation Towards User-Centered Explainable Question Answering,"Explainable question answering systems predict an answer together with an explanation showing why the answer has been selected. The goal is to enable users to assess the correctness of the system and understand its reasoning process. However, we show that current models and evaluation settings have shortcomings regarding the coupling of answer and explanation which might cause serious issues in user experience. As a remedy, we propose a hierarchical model and a new regularization term to strengthen the answer-explanation coupling as well as two evaluation scores to quantify the coupling. We conduct experiments on the HOTPOTQA benchmark data set and perform a user study. The user study shows that our models increase the ability of the users to judge the correctness of the system and that scores like F 1 are not enough to estimate the usefulness of a model in a practical setting with human users. Our scores are better aligned with user experience, making them promising candidates for model selection.","F1 is Not Enough! Models and Evaluation Towards User-Centered Explainable Question Answering Explainable question answering systems predict an answer together with an explanation showing why the answer has been selected. The goal is to enable users to assess the correctness of the system and understand its reasoning process. However, we show that current models and evaluation settings have shortcomings regarding the coupling of answer and explanation which might cause serious issues in user experience. As a remedy, we propose a hierarchical model and a new regularization term to strengthen the answer-explanation coupling as well as two evaluation scores to quantify the coupling. We conduct experiments on the HOTPOTQA benchmark data set and perform a user study. The user study shows that our models increase the ability of the users to judge the correctness of the system and that scores like F 1 are not enough to estimate the usefulness of a model in a practical setting with human users. Our scores are better aligned with user experience, making them promising candidates for model selection.","f1 ! model evaluation user - center explainable question answering explainable question answering system predict answer explanation show answer select . goal enable user assess correctness system understand reasoning process . , current model evaluation setting shortcoming coupling answer explanation cause issue user experience . remedy , propose hierarchical model new regularization term strengthen answer - explanation coupling evaluation score quantify coupling . conduct experiment hotpotqa benchmark data set perform user study . user study show model increase ability user judge correctness system score like f 1 estimate usefulness model practical setting human user . score well align user experience , make promising candidate model selection .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 8, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 15, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 11, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Interpretability and Analysis of Models for NLP,Assessing Phrasal Representation and Composition in Transformers,"Deep transformer models have pushed performance on NLP tasks to new limits, suggesting sophisticated treatment of complex linguistic inputs, such as phrases. However, we have limited understanding of how these models handle representation of phrases, and whether this reflects sophisticated composition of phrase meaning like that done by humans. In this paper, we present systematic analysis of phrasal representations in state-of-the-art pre-trained transformers. We use tests leveraging human judgments of phrase similarity and meaning shift, and compare results before and after control of word overlap, to tease apart lexical effects versus composition effects. We find that phrase representation in these models relies heavily on word content, with little evidence of nuanced composition. We also identify variations in phrase representation quality across models, layers, and representation types, and make corresponding recommendations for usage of representations from these models.","Assessing Phrasal Representation and Composition in Transformers Deep transformer models have pushed performance on NLP tasks to new limits, suggesting sophisticated treatment of complex linguistic inputs, such as phrases. However, we have limited understanding of how these models handle representation of phrases, and whether this reflects sophisticated composition of phrase meaning like that done by humans. In this paper, we present systematic analysis of phrasal representations in state-of-the-art pre-trained transformers. We use tests leveraging human judgments of phrase similarity and meaning shift, and compare results before and after control of word overlap, to tease apart lexical effects versus composition effects. We find that phrase representation in these models relies heavily on word content, with little evidence of nuanced composition. We also identify variations in phrase representation quality across models, layers, and representation types, and make corresponding recommendations for usage of representations from these models.","assess phrasal representation composition transformer deep transformer model push performance nlp task new limit , suggest sophisticated treatment complex linguistic input , phrase . , limited understanding model handle representation phrase , reflect sophisticated composition phrase meaning like human . paper , present systematic analysis phrasal representation state - - - art pre - train transformer . use test leverage human judgment phrase similarity meaning shift , compare result control word overlap , tease apart lexical effect versus composition effect . find phrase representation model rely heavily word content , little evidence nuanced composition . identify variation phrase representation quality model , layer , representation type , corresponding recommendation usage representation model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,RNNs can generate bounded hierarchical languages with optimal memory,"Recurrent neural networks empirically generate natural language with high syntactic fidelity. However, their success is not wellunderstood theoretically. We provide theoretical insight into this success, proving in a finiteprecision setting that RNNs can efficiently generate bounded hierarchical languages that reflect the scaffolding of natural language syntax. We introduce Dyck-(k,m), the language of well-nested brackets (of k types) and mbounded nesting depth, reflecting the bounded memory needs and long-distance dependencies of natural language syntax. The best known results use O(k m 2 ) memory (hidden units) to generate these languages. We prove that an RNN with O(m log k) hidden units suffices, an exponential reduction in memory, by an explicit construction. Finally, we show that no algorithm, even with unbounded computation, can suffice with o(m log k) hidden units.","RNNs can generate bounded hierarchical languages with optimal memory Recurrent neural networks empirically generate natural language with high syntactic fidelity. However, their success is not wellunderstood theoretically. We provide theoretical insight into this success, proving in a finiteprecision setting that RNNs can efficiently generate bounded hierarchical languages that reflect the scaffolding of natural language syntax. We introduce Dyck-(k,m), the language of well-nested brackets (of k types) and mbounded nesting depth, reflecting the bounded memory needs and long-distance dependencies of natural language syntax. The best known results use O(k m 2 ) memory (hidden units) to generate these languages. We prove that an RNN with O(m log k) hidden units suffices, an exponential reduction in memory, by an explicit construction. Finally, we show that no algorithm, even with unbounded computation, can suffice with o(m log k) hidden units.","rnn generate bound hierarchical language optimal memory recurrent neural network empirically generate natural language high syntactic fidelity . , success wellunderstood theoretically . provide theoretical insight success , prove finiteprecision setting rnn efficiently generate bound hierarchical language reflect scaffolding natural language syntax . introduce dyck-(k , m ) , language - nest bracket ( k type ) mbounde nesting depth , reflect bound memory need long - distance dependency natural language syntax . well know result use o(k m 2 ) memory ( hidden unit ) generate language . prove rnn o(m log k ) hide unit suffice , exponential reduction memory , explicit construction . finally , algorithm , unbounded computation , suffice o(m log k ) hide unit .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 7}",Theory and Formalism in NLP (Linguistic and Mathematical),False
Interpretability and Analysis of Models for NLP,Constrained Fact Verification for FEVER,"Fact-verification systems are well explored in the NLP literature with growing attention owing to shared tasks like FEVER. Though the task requires reasoning on extracted evidence to verify a claim's factuality, there is little work on understanding the reasoning process. In this work, we propose a new methodology for fact-verification, specifically FEVER, that enforces a closed-world reliance on extracted evidence. We present an extensive evaluation of state-of-the-art verification models under these constraints.","Constrained Fact Verification for FEVER Fact-verification systems are well explored in the NLP literature with growing attention owing to shared tasks like FEVER. Though the task requires reasoning on extracted evidence to verify a claim's factuality, there is little work on understanding the reasoning process. In this work, we propose a new methodology for fact-verification, specifically FEVER, that enforces a closed-world reliance on extracted evidence. We present an extensive evaluation of state-of-the-art verification models under these constraints.","constrained fact verification fever fact - verification system explore nlp literature grow attention owe share task like fever . task require reason extract evidence verify claim factuality , little work understand reasoning process . work , propose new methodology fact - verification , specifically fever , enforce closed - world reliance extract evidence . present extensive evaluation state - - - art verification model constraint .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Interpretability and Analysis of Models for NLP,AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts,"The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fillin-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AUTOPROMPT, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AUTO-PROMPT, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.","AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fillin-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AUTOPROMPT, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AUTO-PROMPT, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.","autoprompt : elicit knowledge language model automatically generate prompt remarkable success pretrained language model motivate study kind knowledge model learn pretraining . reformulate task fillin - - blank problem ( e.g. , cloze test ) natural approach gauge knowledge , , usage limit manual effort guesswork require write suitable prompt . address , develop autoprompt , automate method create prompt diverse set task , base gradient - guide search . auto - prompt , mask language model ( mlms ) inherent capability perform sentiment analysis natural language inference additional parameter finetuning , achieve performance par recent state - - - art supervise model . prompt elicit accurate factual knowledge mlms manually create prompt lama benchmark , mlms relation extractor effectively supervised relation extraction model . result demonstrate automatically generate prompt viable parameter - free alternative exist probe method , pretraine lm sophisticated capable , potentially replacement finetuning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Interpretability and Analysis of Models for NLP,To BERT or Not to BERT: Comparing Task-specific and Task-agnostic Semi-Supervised Approaches for Sequence Tagging,"Leveraging large amounts of unlabeled data using Transformer-like architectures, like BERT, has gained popularity in recent times owing to their effectiveness in learning general representations that can then be further fine-tuned for downstream tasks to much success. However, training these models can be costly both from an economic and environmental standpoint. In this work, we investigate how to effectively use unlabeled data: by exploring the task-specific semi-supervised approach, Cross-View Training (CVT) and comparing it with task-agnostic BERT in multiple settings that include domain and task relevant English data. CVT uses a much lighter model architecture and we show that it achieves similar performance to BERT on a set of sequence tagging tasks, with lesser financial and environmental impact. * Smaranda Muresan is an Amazon Scholar and a Research Scientist at the Data Science Institute, Columbia University 1 Not only BERT, but other models like RoBERTa (Liu et al., 2019b) and BART (Lewis et al., 2019)","To BERT or Not to BERT: Comparing Task-specific and Task-agnostic Semi-Supervised Approaches for Sequence Tagging Leveraging large amounts of unlabeled data using Transformer-like architectures, like BERT, has gained popularity in recent times owing to their effectiveness in learning general representations that can then be further fine-tuned for downstream tasks to much success. However, training these models can be costly both from an economic and environmental standpoint. In this work, we investigate how to effectively use unlabeled data: by exploring the task-specific semi-supervised approach, Cross-View Training (CVT) and comparing it with task-agnostic BERT in multiple settings that include domain and task relevant English data. CVT uses a much lighter model architecture and we show that it achieves similar performance to BERT on a set of sequence tagging tasks, with lesser financial and environmental impact. * Smaranda Muresan is an Amazon Scholar and a Research Scientist at the Data Science Institute, Columbia University 1 Not only BERT, but other models like RoBERTa (Liu et al., 2019b) and BART (Lewis et al., 2019)","bert bert : compare task - specific task - agnostic semi - supervised approach sequence tagging leverage large amount unlabeled datum transformer - like architecture , like bert , gain popularity recent time owe effectiveness learn general representation fine - tune downstream task success . , train model costly economic environmental standpoint . work , investigate effectively use unlabeled datum : explore task - specific semi - supervised approach , cross - view training ( cvt ) compare task - agnostic bert multiple setting include domain task relevant english datum . cvt use light model architecture achieve similar performance bert set sequence tagging task , less financial environmental impact . * smaranda muresan amazon scholar research scientist data science institute , columbia university 1 bert , model like roberta ( liu et al . , 2019b ) bart ( lewis et al . , 2019 )","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models,"We propose transfer learning as a method for analyzing the encoding of grammatical structure in neural language models. We train LSTMs on non-linguistic data and evaluate their performance on natural language to assess which kinds of data induce generalizable structural features that LSTMs can use for natural language. We find that training on nonlinguistic data with latent structure (MIDI music or Java code) improves test performance on natural language, despite no overlap in surface form or vocabulary. To pinpoint the kinds of abstract structure that models may be encoding to lead to this improvement, we run similar experiments with two artificial parentheses languages: one which has a hierarchical recursive structure, and a control which has paired tokens but no recursion. Surprisingly, training a model on either of these artificial languages leads the same substantial gains when testing on natural language. Further experiments on transfer between natural languages controlling for vocabulary overlap show that zero-shot performance on a test language is highly correlated with typological syntactic similarity to the training language, suggesting that representations induced by pre-training correspond to the cross-linguistic syntactic properties. Our results provide insights into the ways that neural models represent abstract syntactic structure, and also about the kind of structural inductive biases which allow for natural language acquisition. 1","Learning Music Helps You Read: Using Transfer to Study Linguistic Structure in Language Models We propose transfer learning as a method for analyzing the encoding of grammatical structure in neural language models. We train LSTMs on non-linguistic data and evaluate their performance on natural language to assess which kinds of data induce generalizable structural features that LSTMs can use for natural language. We find that training on nonlinguistic data with latent structure (MIDI music or Java code) improves test performance on natural language, despite no overlap in surface form or vocabulary. To pinpoint the kinds of abstract structure that models may be encoding to lead to this improvement, we run similar experiments with two artificial parentheses languages: one which has a hierarchical recursive structure, and a control which has paired tokens but no recursion. Surprisingly, training a model on either of these artificial languages leads the same substantial gains when testing on natural language. Further experiments on transfer between natural languages controlling for vocabulary overlap show that zero-shot performance on a test language is highly correlated with typological syntactic similarity to the training language, suggesting that representations induced by pre-training correspond to the cross-linguistic syntactic properties. Our results provide insights into the ways that neural models represent abstract syntactic structure, and also about the kind of structural inductive biases which allow for natural language acquisition. 1","learn music help read : transfer study linguistic structure language model propose transfer learning method analyze encoding grammatical structure neural language model . train lstm non - linguistic datum evaluate performance natural language assess kind datum induce generalizable structural feature lstm use natural language . find train nonlinguistic datum latent structure ( midi music java code ) improve test performance natural language , despite overlap surface form vocabulary . pinpoint kind abstract structure model encode lead improvement , run similar experiment artificial parenthesis language : hierarchical recursive structure , control pair token recursion . surprisingly , train model artificial language lead substantial gain test natural language . experiment transfer natural language control vocabulary overlap zero - shot performance test language highly correlate typological syntactic similarity training language , suggest representation induce pre - training correspond cross - linguistic syntactic property . result provide insight way neural model represent abstract syntactic structure , kind structural inductive bias allow natural language acquisition . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics,"Large datasets have become commonplace in NLP research. However, the increased emphasis on data quantity has made it challenging to assess the quality of data. We introduce Data Maps-a model-based tool to characterize and diagnose datasets. We leverage a largely ignored source of information: the behavior of the model on individual instances during training (training dynamics) for building data maps. This yields two intuitive measures for each example-the model's confidence in the true class, and the variability of this confidence across epochs-obtained in a single run of training. Experiments across four datasets show that these model-dependent measures reveal three distinct regions in the data map, each with pronounced characteristics. First, our data maps show the presence of ambiguous regions with respect to the model, which contribute the most towards out-of-distribution generalization. Second, the most populous regions in the data are easy to learn for the model, and play an important role in model optimization. Finally, data maps uncover a region with instances that the model finds hard to learn; these often correspond to labeling errors. Our results indicate that a shift in focus from quantity to quality of data could lead to robust models and improved out-ofdistribution generalization. WINOG. Val. (ID) WSC (OOD) 100% train 79.70.2 86.00.1 33% train random 73.31.3 85.60.4","Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics Large datasets have become commonplace in NLP research. However, the increased emphasis on data quantity has made it challenging to assess the quality of data. We introduce Data Maps-a model-based tool to characterize and diagnose datasets. We leverage a largely ignored source of information: the behavior of the model on individual instances during training (training dynamics) for building data maps. This yields two intuitive measures for each example-the model's confidence in the true class, and the variability of this confidence across epochs-obtained in a single run of training. Experiments across four datasets show that these model-dependent measures reveal three distinct regions in the data map, each with pronounced characteristics. First, our data maps show the presence of ambiguous regions with respect to the model, which contribute the most towards out-of-distribution generalization. Second, the most populous regions in the data are easy to learn for the model, and play an important role in model optimization. Finally, data maps uncover a region with instances that the model finds hard to learn; these often correspond to labeling errors. Our results indicate that a shift in focus from quantity to quality of data could lead to robust models and improved out-ofdistribution generalization. WINOG. Val. (ID) WSC (OOD) 100% train 79.70.2 86.00.1 33% train random 73.31.3 85.60.4","dataset cartography : map diagnose dataset training dynamic large dataset commonplace nlp research . , increase emphasis datum quantity challenging assess quality datum . introduce data maps - model - base tool characterize diagnose dataset . leverage largely ignore source information : behavior model individual instance training ( training dynamic ) build data map . yield intuitive measure example - model confidence true class , variability confidence epoch - obtain single run training . experiment dataset model - dependent measure reveal distinct region data map , pronounced characteristic . , data map presence ambiguous region respect model , contribute - - distribution generalization . second , populous region datum easy learn model , play important role model optimization . finally , datum map uncover region instance model find hard learn ; correspond labeling error . result indicate shift focus quantity quality datum lead robust model improve - ofdistribution generalization . winog . val . ( id ) wsc ( ood ) 100 % train 79.70.2 86.00.1 33 % train random 73.31.3 85.60.4","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,Attention is Not Only a Weight: Analyzing Transformers with Vector Norms,"Attention is a key component of Transformers, which have recently achieved considerable success in natural language processing. Hence, attention is being extensively studied to investigate various linguistic capabilities of Transformers, focusing on analyzing the parallels between attention weights and specific linguistic phenomena. This paper shows that attention weights alone are only one of the two factors that determine the output of attention and proposes a norm-based analysis that incorporates the second factor, the norm of the transformed input vectors. The findings of our norm-based analyses of BERT and a Transformer-based neural machine translation system include the following: (i) contrary to previous studies, BERT pays poor attention to special tokens, and (ii) reasonable word alignment can be extracted from attention mechanisms of Transformer. These findings provide insights into the inner workings of Transformers.","Attention is Not Only a Weight: Analyzing Transformers with Vector Norms Attention is a key component of Transformers, which have recently achieved considerable success in natural language processing. Hence, attention is being extensively studied to investigate various linguistic capabilities of Transformers, focusing on analyzing the parallels between attention weights and specific linguistic phenomena. This paper shows that attention weights alone are only one of the two factors that determine the output of attention and proposes a norm-based analysis that incorporates the second factor, the norm of the transformed input vectors. The findings of our norm-based analyses of BERT and a Transformer-based neural machine translation system include the following: (i) contrary to previous studies, BERT pays poor attention to special tokens, and (ii) reasonable word alignment can be extracted from attention mechanisms of Transformer. These findings provide insights into the inner workings of Transformers.","attention weight : analyze transformer vector norm attention key component transformers , recently achieve considerable success natural language processing . , attention extensively study investigate linguistic capability transformers , focus analyze parallel attention weight specific linguistic phenomenon . paper show attention weight factor determine output attention propose norm - base analysis incorporate second factor , norm transform input vector . finding norm - base analysis bert transformer - base neural machine translation system include following : ( ) contrary previous study , bert pay poor attention special token , ( ii ) reasonable word alignment extract attention mechanism transformer . finding provide insight inner working transformers .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 11, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,A Diagnostic Study of Explainability Techniques for Text Classification,"Recent developments in machine learning have introduced models that approach human performance at the cost of increased architectural complexity. Efforts to make the rationales behind the models' predictions transparent have inspired an abundance of new explainability techniques. Provided with an already trained model, they compute saliency scores for the words of an input instance. However, there exists no definitive guide on (i) how to choose such a technique given a particular application task and model architecture, and (ii) the benefits and drawbacks of using each such technique. In this paper, we develop a comprehensive list of diagnostic properties for evaluating existing explainability techniques. We then employ the proposed list to compare a set of diverse explainability techniques on downstream text classification tasks and neural network architectures. We also compare the saliency scores assigned by the explainability techniques with human annotations of salient input regions to find relations between a model's performance and the agreement of its rationales with human ones. Overall, we find that the gradient-based explanations perform best across tasks and model architectures, and we present further insights into the properties of the reviewed explainability techniques.","A Diagnostic Study of Explainability Techniques for Text Classification Recent developments in machine learning have introduced models that approach human performance at the cost of increased architectural complexity. Efforts to make the rationales behind the models' predictions transparent have inspired an abundance of new explainability techniques. Provided with an already trained model, they compute saliency scores for the words of an input instance. However, there exists no definitive guide on (i) how to choose such a technique given a particular application task and model architecture, and (ii) the benefits and drawbacks of using each such technique. In this paper, we develop a comprehensive list of diagnostic properties for evaluating existing explainability techniques. We then employ the proposed list to compare a set of diverse explainability techniques on downstream text classification tasks and neural network architectures. We also compare the saliency scores assigned by the explainability techniques with human annotations of salient input regions to find relations between a model's performance and the agreement of its rationales with human ones. Overall, we find that the gradient-based explanations perform best across tasks and model architectures, and we present further insights into the properties of the reviewed explainability techniques.","diagnostic study explainability technique text classification recent development machine learning introduce model approach human performance cost increase architectural complexity . effort rationale model ' prediction transparent inspire abundance new explainability technique . provide train model , compute saliency score word input instance . , exist definitive guide ( ) choose technique give particular application task model architecture , ( ii ) benefit drawback technique . paper , develop comprehensive list diagnostic property evaluate exist explainability technique . employ propose list compare set diverse explainability technique downstream text classification task neural network architecture . compare saliency score assign explainability technique human annotation salient input region find relation model performance agreement rationale human one . overall , find gradient - base explanation perform well task model architecture , present insight property review explainability technique .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,With Little Power Comes Great Responsibility,"Despite its importance to experimental design, statistical power (the probability that, given a real effect, an experiment will reject the null hypothesis) has largely been ignored by the NLP community. Underpowered experiments make it more difficult to discern the difference between statistical noise and meaningful model improvements, and increase the chances of exaggerated findings. By metaanalyzing a set of existing NLP papers and datasets, we characterize typical power for a variety of settings and conclude that underpowered experiments are common in the NLP literature. In particular, for several tasks in the popular GLUE benchmark, small test sets mean that most attempted comparisons to state of the art models will not be adequately powered. Similarly, based on reasonable assumptions, we find that the most typical experimental design for human rating studies will be underpowered to detect small model differences, of the sort that are frequently studied. For machine translation, we find that typical test sets of 2000 sentences have approximately 75% power to detect differences of 1 BLEU point. To improve the situation going forward, we give an overview of best practices for power analysis in NLP and release a series of notebooks to assist with future power analyses. 1","With Little Power Comes Great Responsibility Despite its importance to experimental design, statistical power (the probability that, given a real effect, an experiment will reject the null hypothesis) has largely been ignored by the NLP community. Underpowered experiments make it more difficult to discern the difference between statistical noise and meaningful model improvements, and increase the chances of exaggerated findings. By metaanalyzing a set of existing NLP papers and datasets, we characterize typical power for a variety of settings and conclude that underpowered experiments are common in the NLP literature. In particular, for several tasks in the popular GLUE benchmark, small test sets mean that most attempted comparisons to state of the art models will not be adequately powered. Similarly, based on reasonable assumptions, we find that the most typical experimental design for human rating studies will be underpowered to detect small model differences, of the sort that are frequently studied. For machine translation, we find that typical test sets of 2000 sentences have approximately 75% power to detect differences of 1 BLEU point. To improve the situation going forward, we give an overview of best practices for power analysis in NLP and release a series of notebooks to assist with future power analyses. 1","little power come great responsibility despite importance experimental design , statistical power ( probability , give real effect , experiment reject null hypothesis ) largely ignore nlp community . underpowered experiment difficult discern difference statistical noise meaningful model improvement , increase chance exaggerated finding . metaanalyze set exist nlp paper dataset , characterize typical power variety setting conclude underpowered experiment common nlp literature . particular , task popular glue benchmark , small test set mean attempt comparison state art model adequately power . similarly , base reasonable assumption , find typical experimental design human rating study underpowere detect small model difference , sort frequently study . machine translation , find typical test set 2000 sentence approximately 75 % power detect difference 1 bleu point . improve situation go forward , overview good practice power analysis nlp release series notebook assist future power analysis . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,False
Interpretability and Analysis of Models for NLP,Intrinsic Probing through Dimension Selection,"Most modern NLP systems make use of pretrained contextual representations that attain astonishingly high performance on a variety of tasks. Such high performance should not be possible unless some form of linguistic structure inheres in these representations, and a wealth of research has sprung up on probing for it. In this paper, we draw a distinction between intrinsic probing, which examines how linguistic information is structured within a representation, and the extrinsic probing popular in prior work, which only argues for the presence of such information by showing that it can be successfully extracted. To enable intrinsic probing, we propose a novel framework based on a decomposable multivariate Gaussian probe that allows us to determine whether the linguistic information in word embeddings is dispersed or focal. We then probe fastText and BERT for various morphosyntactic attributes across 36 languages. We find that most attributes are reliably encoded by only a few neurons, with fastText concentrating its linguistic structure more than BERT. 1","Intrinsic Probing through Dimension Selection Most modern NLP systems make use of pretrained contextual representations that attain astonishingly high performance on a variety of tasks. Such high performance should not be possible unless some form of linguistic structure inheres in these representations, and a wealth of research has sprung up on probing for it. In this paper, we draw a distinction between intrinsic probing, which examines how linguistic information is structured within a representation, and the extrinsic probing popular in prior work, which only argues for the presence of such information by showing that it can be successfully extracted. To enable intrinsic probing, we propose a novel framework based on a decomposable multivariate Gaussian probe that allows us to determine whether the linguistic information in word embeddings is dispersed or focal. We then probe fastText and BERT for various morphosyntactic attributes across 36 languages. We find that most attributes are reliably encoded by only a few neurons, with fastText concentrating its linguistic structure more than BERT. 1","intrinsic probing dimension selection modern nlp system use pretrained contextual representation attain astonishingly high performance variety task . high performance possible form linguistic structure inhere representation , wealth research spring probe . paper , draw distinction intrinsic probing , examine linguistic information structure representation , extrinsic probing popular prior work , argue presence information show successfully extract . enable intrinsic probing , propose novel framework base decomposable multivariate gaussian probe allow determine linguistic information word embedding dispersed focal . probe fasttext bert morphosyntactic attribute 36 language . find attribute reliably encode neuron , fasttext concentrate linguistic structure bert . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Analyzing Redundancy in Pretrained Transformer Models,"Transformer-based deep NLP models are trained using hundreds of millions of parameters, limiting their applicability in computationally constrained environments. In this paper, we study the cause of these limitations by defining a notion of Redundancy, which we categorize into two classes: General Redundancy and Task-specific Redundancy. We dissect two popular pretrained models, BERT and XLNet, studying how much redundancy they exhibit at a representation-level and at a more fine-grained neuron-level. Our analysis reveals interesting insights, such as: i) 85% of the neurons across the network are redundant and ii) at least 92% of them can be removed when optimizing towards a downstream task. Based on our analysis, we present an efficient feature-based transfer learning procedure, which maintains 97% performance while using at-most 10% of the original neurons. 1","Analyzing Redundancy in Pretrained Transformer Models Transformer-based deep NLP models are trained using hundreds of millions of parameters, limiting their applicability in computationally constrained environments. In this paper, we study the cause of these limitations by defining a notion of Redundancy, which we categorize into two classes: General Redundancy and Task-specific Redundancy. We dissect two popular pretrained models, BERT and XLNet, studying how much redundancy they exhibit at a representation-level and at a more fine-grained neuron-level. Our analysis reveals interesting insights, such as: i) 85% of the neurons across the network are redundant and ii) at least 92% of them can be removed when optimizing towards a downstream task. Based on our analysis, we present an efficient feature-based transfer learning procedure, which maintains 97% performance while using at-most 10% of the original neurons. 1","analyze redundancy pretrained transformer model transformer - base deep nlp model train hundred million parameter , limit applicability computationally constrain environment . paper , study cause limitation define notion redundancy , categorize class : general redundancy task - specific redundancy . dissect popular pretrained model , bert xlnet , study redundancy exhibit representation - level fine - grained neuron - level . analysis reveal interesting insight , : ) 85 % neuron network redundant ii ) 92 % remove optimize downstream task . base analysis , present efficient feature - base transfer learning procedure , maintain 97 % performance - 10 % original neuron . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Generating Label Cohesive and Well-Formed Adversarial Claims,"Adversarial attacks reveal important vulnerabilities and flaws of trained models. One potent type of attack are universal adversarial triggers, which are individual n-grams that, when appended to instances of a class under attack, can trick a model into predicting a target class. However, for inference tasks such as fact checking, these triggers often inadvertently invert the meaning of instances they are inserted in. In addition, such attacks produce semantically nonsensical inputs, as they simply concatenate triggers to existing samples. Here, we investigate how to generate adversarial attacks against fact checking systems that preserve the ground truth meaning and are semantically valid. We extend the HotFlip attack algorithm used for universal trigger generation by jointly minimizing the target class loss of a fact checking model and the entailment class loss of an auxiliary natural language inference model. We then train a conditional language model to generate semantically valid statements, which include the found universal triggers. We find that the generated attacks maintain the directionality and semantic validity of the claim better than previous work. * denotes equal contribution Dissociative disorders have been attributed to disruptions in memory caused by trauma or other forms of stress. SUPPORTS REFUTES Dissociative identity disorder, or DID, may be the result of memory disruptions that have been induced by psychological trauma. CLAIM don,already,more,during,home GPT-2 Claim Generation Dissociative disorders have been attributed to disrupted brain activity during trauma or other forms of stress.","Generating Label Cohesive and Well-Formed Adversarial Claims Adversarial attacks reveal important vulnerabilities and flaws of trained models. One potent type of attack are universal adversarial triggers, which are individual n-grams that, when appended to instances of a class under attack, can trick a model into predicting a target class. However, for inference tasks such as fact checking, these triggers often inadvertently invert the meaning of instances they are inserted in. In addition, such attacks produce semantically nonsensical inputs, as they simply concatenate triggers to existing samples. Here, we investigate how to generate adversarial attacks against fact checking systems that preserve the ground truth meaning and are semantically valid. We extend the HotFlip attack algorithm used for universal trigger generation by jointly minimizing the target class loss of a fact checking model and the entailment class loss of an auxiliary natural language inference model. We then train a conditional language model to generate semantically valid statements, which include the found universal triggers. We find that the generated attacks maintain the directionality and semantic validity of the claim better than previous work. * denotes equal contribution Dissociative disorders have been attributed to disruptions in memory caused by trauma or other forms of stress. SUPPORTS REFUTES Dissociative identity disorder, or DID, may be the result of memory disruptions that have been induced by psychological trauma. CLAIM don,already,more,during,home GPT-2 Claim Generation Dissociative disorders have been attributed to disrupted brain activity during trauma or other forms of stress.","generate label cohesive - form adversarial claim adversarial attack reveal important vulnerability flaw train model . potent type attack universal adversarial trigger , individual n - gram , append instance class attack , trick model predict target class . , inference task fact checking , trigger inadvertently invert meaning instance insert . addition , attack produce semantically nonsensical input , simply concatenate trigger exist sample . , investigate generate adversarial attack fact checking system preserve ground truth meaning semantically valid . extend hotflip attack algorithm universal trigger generation jointly minimize target class loss fact checking model entailment class loss auxiliary natural language inference model . train conditional language model generate semantically valid statement , include find universal trigger . find generate attack maintain directionality semantic validity claim well previous work . * denote equal contribution dissociative disorder attribute disruption memory cause trauma form stress . support refute dissociative identity disorder , , result memory disruption induce psychological trauma . claim don , , , , home gpt-2 claim generation dissociative disorder attribute disrupt brain activity trauma form stress .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 13, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Interpretability and Analysis of Models for NLP,"Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A Case Study on CoQA","Many NLP tasks have benefited from transferring knowledge from contextualized word embeddings, however the picture of what type of knowledge is transferred is incomplete. This paper studies the types of linguistic phenomena accounted for by language models in the context of a Conversational Question Answering (CoQA) task. We identify the problematic areas for the finetuned RoBERTa, BERT and DistilBERT models through systematic error analysis -basic arithmetic (counting phrases), compositional semantics (negation and Semantic Role Labeling), and lexical semantics (surprisal and antonymy). When enhanced with the relevant linguistic knowledge through multitask learning, the models improve in performance. Ensembles of the enhanced models yield a boost between 2.2 and 2.7 points in F1 score overall, and up to 42.1 points in F1 on the hardest question classes. The results show differences in ability to represent compositional and lexical information between RoBERTa, BERT and DistilBERT.","Compositional and Lexical Semantics in RoBERTa, BERT and DistilBERT: A Case Study on CoQA Many NLP tasks have benefited from transferring knowledge from contextualized word embeddings, however the picture of what type of knowledge is transferred is incomplete. This paper studies the types of linguistic phenomena accounted for by language models in the context of a Conversational Question Answering (CoQA) task. We identify the problematic areas for the finetuned RoBERTa, BERT and DistilBERT models through systematic error analysis -basic arithmetic (counting phrases), compositional semantics (negation and Semantic Role Labeling), and lexical semantics (surprisal and antonymy). When enhanced with the relevant linguistic knowledge through multitask learning, the models improve in performance. Ensembles of the enhanced models yield a boost between 2.2 and 2.7 points in F1 score overall, and up to 42.1 points in F1 on the hardest question classes. The results show differences in ability to represent compositional and lexical information between RoBERTa, BERT and DistilBERT.","compositional lexical semantic roberta , bert distilbert : case study coqa nlp task benefit transfer knowledge contextualize word embedding , picture type knowledge transfer incomplete . paper study type linguistic phenomenon account language model context conversational question answering ( coqa ) task . identify problematic area finetuned roberta , bert distilbert model systematic error analysis -basic arithmetic ( count phrase ) , compositional semantic ( negation semantic role labeling ) , lexical semantic ( surprisal antonymy ) . enhance relevant linguistic knowledge multitask learning , model improve performance . ensemble enhance model yield boost 2.2 2.7 point f1 score overall , 42.1 point f1 hard question class . result difference ability represent compositional lexical information roberta , bert distilbert .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 8, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Are All Good Word Vector Spaces Isomorphic?,"Existing algorithms for aligning cross-lingual word vector spaces assume that vector spaces are approximately isomorphic. As a result, they perform poorly or fail completely on nonisomorphic spaces. Such non-isomorphism has been hypothesised to result from typological differences between languages. In this work, we ask whether non-isomorphism is also crucially a sign of degenerate word vector spaces. We present a series of experiments across diverse languages which show that variance in performance across language pairs is not only due to typological differences, but can mostly be attributed to the size of the monolingual resources available, and to the properties and duration of monolingual training (e.g. ""under-training"").","Are All Good Word Vector Spaces Isomorphic? Existing algorithms for aligning cross-lingual word vector spaces assume that vector spaces are approximately isomorphic. As a result, they perform poorly or fail completely on nonisomorphic spaces. Such non-isomorphism has been hypothesised to result from typological differences between languages. In this work, we ask whether non-isomorphism is also crucially a sign of degenerate word vector spaces. We present a series of experiments across diverse languages which show that variance in performance across language pairs is not only due to typological differences, but can mostly be attributed to the size of the monolingual resources available, and to the properties and duration of monolingual training (e.g. ""under-training"").","good word vector space isomorphic ? exist algorithm align cross - lingual word vector space assume vector space approximately isomorphic . result , perform poorly fail completely nonisomorphic space . non - isomorphism hypothesise result typological difference language . work , ask non - isomorphism crucially sign degenerate word vector space . present series experiment diverse language variance performance language pair typological difference , attribute size monolingual resource available , property duration monolingual training ( e.g. "" - training "" ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 6, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Interpretability and Analysis of Models for NLP,"When BERT Plays the Lottery, All Tickets Are Winning","Large Transformer-based models were shown to be reducible to a smaller number of selfattention heads and layers. We consider this phenomenon from the perspective of the lottery ticket hypothesis, using both structured and magnitude pruning. For fine-tuned BERT, we show that (a) it is possible to find subnetworks achieving performance that is comparable with that of the full model, and (b) similarly-sized subnetworks sampled from the rest of the model perform worse. Strikingly, with structured pruning even the worst possible subnetworks remain highly trainable, indicating that most pre-trained BERT weights are potentially useful. We also study the ""good"" subnetworks to see if their success can be attributed to superior linguistic knowledge, but find them unstable, and not explained by meaningful self-attention patterns.","When BERT Plays the Lottery, All Tickets Are Winning Large Transformer-based models were shown to be reducible to a smaller number of selfattention heads and layers. We consider this phenomenon from the perspective of the lottery ticket hypothesis, using both structured and magnitude pruning. For fine-tuned BERT, we show that (a) it is possible to find subnetworks achieving performance that is comparable with that of the full model, and (b) similarly-sized subnetworks sampled from the rest of the model perform worse. Strikingly, with structured pruning even the worst possible subnetworks remain highly trainable, indicating that most pre-trained BERT weights are potentially useful. We also study the ""good"" subnetworks to see if their success can be attributed to superior linguistic knowledge, but find them unstable, and not explained by meaningful self-attention patterns.","bert play lottery , ticket win large transformer - base model show reducible small number selfattention head layer . consider phenomenon perspective lottery ticket hypothesis , structured magnitude pruning . fine - tune bert , ( ) possible find subnetwork achieve performance comparable model , ( b ) similarly - sized subnetwork sample rest model perform bad . strikingly , structured pruning bad possible subnetwork remain highly trainable , indicate pre - trained bert weight potentially useful . study "" good "" subnetwork success attribute superior linguistic knowledge , find unstable , explain meaningful self - attention pattern .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis,"The human language can be expressed through multiple sources of information known as modalities, including tones of voice, facial gestures, and spoken language. Recent multimodal learning with strong performances on human-centric tasks such as sentiment analysis and emotion recognition are often blackbox, with very limited interpretability. In this paper we propose Multimodal Routing, which dynamically adjusts weights between input modalities and output representations differently for each input sample. Multimodal routing can identify relative importance of both individual modalities and cross-modality features. Moreover, the weight assignment by routing allows us to interpret modalityprediction relationships not only globally (i.e. general trends over the whole dataset), but also locally for each single input sample, meanwhile keeping competitive performance compared to state-of-the-art methods. * indicates equal contribution. Code is available at https://github.com/martinmamql/ multimodal_routing. c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral","Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis The human language can be expressed through multiple sources of information known as modalities, including tones of voice, facial gestures, and spoken language. Recent multimodal learning with strong performances on human-centric tasks such as sentiment analysis and emotion recognition are often blackbox, with very limited interpretability. In this paper we propose Multimodal Routing, which dynamically adjusts weights between input modalities and output representations differently for each input sample. Multimodal routing can identify relative importance of both individual modalities and cross-modality features. Moreover, the weight assignment by routing allows us to interpret modalityprediction relationships not only globally (i.e. general trends over the whole dataset), but also locally for each single input sample, meanwhile keeping competitive performance compared to state-of-the-art methods. * indicates equal contribution. Code is available at https://github.com/martinmamql/ multimodal_routing. c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral","multimodal routing : improve local global interpretability multimodal language analysis human language express multiple source information know modality , include tone voice , facial gesture , speak language . recent multimodal learning strong performance human - centric task sentiment analysis emotion recognition blackbox , limited interpretability . paper propose multimodal routing , dynamically adjust weight input modality output representation differently input sample . multimodal routing identify relative importance individual modality cross - modality feature . , weight assignment routing allow interpret modalityprediction relationship globally ( i.e. general trend dataset ) , locally single input sample , keep competitive performance compare state - - - art method . * indicate equal contribution . code available https://github.com/martinmamql/ multimodal_routing . c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtral c angry c happy c neurtr","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 14, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Interpretability and Analysis of Models for NLP,COGS: A Compositional Generalization Challenge Based on Semantic Interpretation,"Natural language is characterized by compositionality: the meaning of a complex expression is constructed from the meanings of its constituent parts. To facilitate the evaluation of the compositional abilities of language processing architectures, we introduce COGS, a semantic parsing dataset based on a fragment of English. The evaluation portion of COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures, or new combinations of familiar words and familiar structures. In experiments with Transformers and LSTMs, we found that in-distribution accuracy on the COGS test set was near-perfect (96-99%), but generalization accuracy was substantially lower (16-35%) and showed high sensitivity to random seed (±6-8%). These findings indicate that contemporary standard NLP models are limited in their compositional generalization capacity, and position COGS as a good way to measure progress.","COGS: A Compositional Generalization Challenge Based on Semantic Interpretation Natural language is characterized by compositionality: the meaning of a complex expression is constructed from the meanings of its constituent parts. To facilitate the evaluation of the compositional abilities of language processing architectures, we introduce COGS, a semantic parsing dataset based on a fragment of English. The evaluation portion of COGS contains multiple systematic gaps that can only be addressed by compositional generalization; these include new combinations of familiar syntactic structures, or new combinations of familiar words and familiar structures. In experiments with Transformers and LSTMs, we found that in-distribution accuracy on the COGS test set was near-perfect (96-99%), but generalization accuracy was substantially lower (16-35%) and showed high sensitivity to random seed (±6-8%). These findings indicate that contemporary standard NLP models are limited in their compositional generalization capacity, and position COGS as a good way to measure progress.","cogs : compositional generalization challenge base semantic interpretation natural language characterize compositionality : meaning complex expression construct meaning constituent part . facilitate evaluation compositional ability language processing architecture , introduce cogs , semantic parsing dataset base fragment english . evaluation portion cogs contain multiple systematic gap address compositional generalization ; include new combination familiar syntactic structure , new combination familiar word familiar structure . experiment transformers lstms , find - distribution accuracy cogs test set near - perfect ( 96 - 99 % ) , generalization accuracy substantially low ( 16 - 35 % ) show high sensitivity random seed ( ±6 - 8 % ) . finding indicate contemporary standard nlp model limited compositional generalization capacity , position cogs good way measure progress .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Interpretability and Analysis of Models for NLP,Hate-Speech and Offensive Language Detection in Roman Urdu,"The task of automatic hate-speech and offensive language detection in social media content is of utmost importance due to its implications in unprejudiced society concerning race, gender, or religion. Existing research in this area, however, is mainly focused on the English language, limiting the applicability to particular demographics. Despite its prevalence, Roman Urdu (RU) lacks language resources, annotated datasets, and language models for this task. In this study, we: (1) Present a lexicon of hateful words in RU, (2) Develop an annotated dataset called RUHSOLD consisting of 10, 012 tweets in RU with both coarse-grained and fine-grained labels of hate-speech and offensive language, (3) Explore the feasibility of transfer learning of five existing embedding models to RU, (4) Propose a novel deep learning architecture called CNN-gram for hatespeech and offensive language detection and compare its performance with seven current baseline approaches on RUHSOLD dataset, and (5) Train domain-specific embeddings on more than 4.7 million tweets and make them publicly available. We conclude that transfer learning is more beneficial as compared to training embedding from scratch and that the proposed model exhibits greater robustness as compared to the baselines.","Hate-Speech and Offensive Language Detection in Roman Urdu The task of automatic hate-speech and offensive language detection in social media content is of utmost importance due to its implications in unprejudiced society concerning race, gender, or religion. Existing research in this area, however, is mainly focused on the English language, limiting the applicability to particular demographics. Despite its prevalence, Roman Urdu (RU) lacks language resources, annotated datasets, and language models for this task. In this study, we: (1) Present a lexicon of hateful words in RU, (2) Develop an annotated dataset called RUHSOLD consisting of 10, 012 tweets in RU with both coarse-grained and fine-grained labels of hate-speech and offensive language, (3) Explore the feasibility of transfer learning of five existing embedding models to RU, (4) Propose a novel deep learning architecture called CNN-gram for hatespeech and offensive language detection and compare its performance with seven current baseline approaches on RUHSOLD dataset, and (5) Train domain-specific embeddings on more than 4.7 million tweets and make them publicly available. We conclude that transfer learning is more beneficial as compared to training embedding from scratch and that the proposed model exhibits greater robustness as compared to the baselines.","hate - speech offensive language detection roman urdu task automatic hate - speech offensive language detection social medium content utmost importance implication unprejudiced society concern race , gender , religion . exist research area , , mainly focus english language , limit applicability particular demographic . despite prevalence , roman urdu ( ru ) lack language resource , annotated dataset , language model task . study , : ( 1 ) present lexicon hateful word ru , ( 2 ) develop annotate dataset call ruhsold consist 10 , 012 tweet ru coarse - grained fine - grained label hate - speech offensive language , ( 3 ) explore feasibility transfer learning exist embed model ru , ( 4 ) propose novel deep learning architecture call cnn - gram hatespeech offensive language detection compare performance seven current baseline approach ruhsold dataset , ( 5 ) train domain - specific embedding 4.7 million tweet publicly available . conclude transfer learning beneficial compare training embed scratch propose model exhibit great robustness compare baseline .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Interpretability and Analysis of Models for NLP,On the Ability and Limitations of Transformers to Recognize Formal Languages,"Transformers have supplanted recurrent models in a large number of NLP tasks. However, the differences in their abilities to model different syntactic properties remain largely unknown. Past works suggest that LSTMs generalize very well on regular languages and have close connections with counter languages. In this work, we systematically study the ability of Transformers to model such languages as well as the role of its individual components in doing so. We first provide a construction of Transformers for a subclass of counter languages, including well-studied languages such as n-ary Boolean Expressions, Dyck-1, and its generalizations. In experiments, we find that Transformers do well on this subclass, and their learned mechanism strongly correlates with our construction. Perhaps surprisingly, in contrast to LSTMs, Transformers do well only on a subset of regular languages with degrading performance as we make languages more complex according to a well-known measure of complexity. Our analysis also provides insights on the role of self-attention mechanism in modeling certain behaviors and the influence of positional encoding schemes on the learning and generalization abilities of the model.","On the Ability and Limitations of Transformers to Recognize Formal Languages Transformers have supplanted recurrent models in a large number of NLP tasks. However, the differences in their abilities to model different syntactic properties remain largely unknown. Past works suggest that LSTMs generalize very well on regular languages and have close connections with counter languages. In this work, we systematically study the ability of Transformers to model such languages as well as the role of its individual components in doing so. We first provide a construction of Transformers for a subclass of counter languages, including well-studied languages such as n-ary Boolean Expressions, Dyck-1, and its generalizations. In experiments, we find that Transformers do well on this subclass, and their learned mechanism strongly correlates with our construction. Perhaps surprisingly, in contrast to LSTMs, Transformers do well only on a subset of regular languages with degrading performance as we make languages more complex according to a well-known measure of complexity. Our analysis also provides insights on the role of self-attention mechanism in modeling certain behaviors and the influence of positional encoding schemes on the learning and generalization abilities of the model.","ability limitation transformer recognize formal language transformers supplant recurrent model large number nlp task . , difference ability model different syntactic property remain largely unknown . past work suggest lstms generalize regular language close connection counter language . work , systematically study ability transformers model language role individual component . provide construction transformers subclass counter language , include - study language n - ary boolean expressions , dyck-1 , generalization . experiment , find transformers subclass , learn mechanism strongly correlate construction . surprisingly , contrast lstms , transformers subset regular language degrade performance language complex accord - know measure complexity . analysis provide insight role self - attention mechanism model certain behavior influence positional encoding scheme learning generalization ability model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,A matter of framing: The impact of linguistic formalism on probing results,"Deep pre-trained contextualized encoders like BERT (Devlin et al., 2019)  demonstrate remarkable performance on a range of downstream tasks. A recent line of research in probing investigates the linguistic knowledge implicitly learned by these models during pretraining. While most work in probing operates on the task level, linguistic tasks are rarely uniform and can be represented in a variety of formalisms. Any linguistics-based probing study thereby inevitably commits to the formalism used to annotate the underlying data. Can the choice of formalism affect probing results? To investigate, we conduct an in-depth cross-formalism layer probing study in role semantics. We find linguistically meaningful differences in the encoding of semantic role-and proto-role information by BERT depending on the formalism and demonstrate that layer probing can detect subtle differences between the implementations of the same linguistic formalism. Our results suggest that linguistic formalism is an important dimension in probing studies and should be investigated along with the commonly used cross-task and cross-lingual experimental settings.","A matter of framing: The impact of linguistic formalism on probing results Deep pre-trained contextualized encoders like BERT (Devlin et al., 2019)  demonstrate remarkable performance on a range of downstream tasks. A recent line of research in probing investigates the linguistic knowledge implicitly learned by these models during pretraining. While most work in probing operates on the task level, linguistic tasks are rarely uniform and can be represented in a variety of formalisms. Any linguistics-based probing study thereby inevitably commits to the formalism used to annotate the underlying data. Can the choice of formalism affect probing results? To investigate, we conduct an in-depth cross-formalism layer probing study in role semantics. We find linguistically meaningful differences in the encoding of semantic role-and proto-role information by BERT depending on the formalism and demonstrate that layer probing can detect subtle differences between the implementations of the same linguistic formalism. Our results suggest that linguistic formalism is an important dimension in probing studies and should be investigated along with the commonly used cross-task and cross-lingual experimental settings.","matter framing : impact linguistic formalism probe result deep pre - train contextualize encoder like bert ( devlin et al . , 2019 )   demonstrate remarkable performance range downstream task . recent line research probe investigate linguistic knowledge implicitly learn model pretraining . work probing operate task level , linguistic task rarely uniform represent variety formalism . linguistics - base probe study inevitably commit formalism annotate underlie datum . choice formalism affect probe result ? investigate , conduct - depth cross - formalism layer probe study role semantic . find linguistically meaningful difference encoding semantic role - proto - role information bert depend formalism demonstrate layer probing detect subtle difference implementation linguistic formalism . result suggest linguistic formalism important dimension probe study investigate commonly cross - task cross - lingual experimental setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 11, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 8}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,An Empirical Investigation Towards Efficient Multi-Domain Language Model Pre-training,"Pre-training large language models has become a standard in the natural language processing community. Such models are pretrained on generic data (e.g. BookCorpus and English Wikipedia) and often fine-tuned on tasks in the same domain. However, in order to achieve state-of-the-art performance on out of domain tasks such as clinical named entity recognition and relation extraction, additional in domain pre-training is required. In practice, staged multi-domain pre-training presents performance deterioration in the form of catastrophic forgetting (CF) when evaluated on a generic benchmark such as GLUE. In this paper we conduct an empirical investigation into known methods to mitigate CF. We find that elastic weight consolidation provides best overall scores yielding only a 0.33% drop in performance across seven generic tasks while remaining competitive in bio-medical tasks. Furthermore, we explore gradient and latent clustering based data selection techniques to improve coverage when using elastic weight consolidation and experience replay methods.","An Empirical Investigation Towards Efficient Multi-Domain Language Model Pre-training Pre-training large language models has become a standard in the natural language processing community. Such models are pretrained on generic data (e.g. BookCorpus and English Wikipedia) and often fine-tuned on tasks in the same domain. However, in order to achieve state-of-the-art performance on out of domain tasks such as clinical named entity recognition and relation extraction, additional in domain pre-training is required. In practice, staged multi-domain pre-training presents performance deterioration in the form of catastrophic forgetting (CF) when evaluated on a generic benchmark such as GLUE. In this paper we conduct an empirical investigation into known methods to mitigate CF. We find that elastic weight consolidation provides best overall scores yielding only a 0.33% drop in performance across seven generic tasks while remaining competitive in bio-medical tasks. Furthermore, we explore gradient and latent clustering based data selection techniques to improve coverage when using elastic weight consolidation and experience replay methods.","empirical investigation efficient multi - domain language model pre - training pre - training large language model standard natural language process community . model pretraine generic datum ( e.g. bookcorpus english wikipedia ) fine - tune task domain . , order achieve state - - - art performance domain task clinical name entity recognition relation extraction , additional domain pre - training require . practice , stage multi - domain pre - training present performance deterioration form catastrophic forgetting ( cf ) evaluate generic benchmark glue . paper conduct empirical investigation know method mitigate cf . find elastic weight consolidation provide good overall score yield 0.33 % drop performance seven generic task remain competitive bio - medical task . furthermore , explore gradient latent clustering base datum selection technique improve coverage elastic weight consolidation experience replay method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 10, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Interpretability and Analysis of Models for NLP,Evaluating and Characterizing Human Rationales,"Two main approaches for evaluating the quality of machine-generated rationales are: 1) using human rationales as a gold standard; and 2) automated metrics based on how rationales affect model behavior. An open question, however, is how human rationales fare with these automatic metrics. Analyzing a variety of datasets and models, we find that human rationales do not necessarily perform well on these metrics. To unpack this finding, we propose improved metrics to account for modeldependent baseline performance. We then propose two methods to further characterize rationale quality, one based on model retraining and one on using ""fidelity curves"" to reveal properties such as irrelevance and redundancy. Our work leads to actionable suggestions for evaluating and characterizing rationales.","Evaluating and Characterizing Human Rationales Two main approaches for evaluating the quality of machine-generated rationales are: 1) using human rationales as a gold standard; and 2) automated metrics based on how rationales affect model behavior. An open question, however, is how human rationales fare with these automatic metrics. Analyzing a variety of datasets and models, we find that human rationales do not necessarily perform well on these metrics. To unpack this finding, we propose improved metrics to account for modeldependent baseline performance. We then propose two methods to further characterize rationale quality, one based on model retraining and one on using ""fidelity curves"" to reveal properties such as irrelevance and redundancy. Our work leads to actionable suggestions for evaluating and characterizing rationales.","evaluate characterize human rationale main approach evaluate quality machine - generate rationale : 1 ) human rationale gold standard ; 2 ) automate metric base rationale affect model behavior . open question , , human rationale fare automatic metric . analyze variety dataset model , find human rationale necessarily perform metric . unpack finding , propose improve metric account modeldependent baseline performance . propose method characterize rationale quality , base model retraining "" fidelity curve "" reveal property irrelevance redundancy . work lead actionable suggestion evaluate characterize rationale .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 1, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,Type B Reflexivization as an Unambiguous Testbed for Multilingual Multi-Task Gender Bias,"The one-sided focus on English in previous studies of gender bias in NLP misses out on opportunities in other languages: English challenge datasets such as GAP and Wino-Gender highlight model preferences that are ""hallucinatory"", e.g., disambiguating genderambiguous occurrences of 'doctor' as male doctors. We show that for languages with type B reflexivization, e.g., Swedish and Russian, we can construct multi-task challenge datasets for detecting gender bias that lead to unambiguously wrong model predictions: In these languages, the direct translation of 'the doctor removed his mask' is not ambiguous between a coreferential reading and a disjoint reading. Instead, the coreferential reading requires a non-gendered pronoun, and the gendered, possessive pronouns are anti-reflexive. We present a multilingual, multi-task challenge dataset, which spans four languages and four NLP tasks and focuses only on this phenomenon. We find evidence for gender bias across all task-language combinations and correlate model bias with national labor market statistics.","Type B Reflexivization as an Unambiguous Testbed for Multilingual Multi-Task Gender Bias The one-sided focus on English in previous studies of gender bias in NLP misses out on opportunities in other languages: English challenge datasets such as GAP and Wino-Gender highlight model preferences that are ""hallucinatory"", e.g., disambiguating genderambiguous occurrences of 'doctor' as male doctors. We show that for languages with type B reflexivization, e.g., Swedish and Russian, we can construct multi-task challenge datasets for detecting gender bias that lead to unambiguously wrong model predictions: In these languages, the direct translation of 'the doctor removed his mask' is not ambiguous between a coreferential reading and a disjoint reading. Instead, the coreferential reading requires a non-gendered pronoun, and the gendered, possessive pronouns are anti-reflexive. We present a multilingual, multi-task challenge dataset, which spans four languages and four NLP tasks and focuses only on this phenomenon. We find evidence for gender bias across all task-language combinations and correlate model bias with national labor market statistics.","type b reflexivization unambiguous testbed multilingual multi - task gender bias - sided focus english previous study gender bias nlp miss opportunity language : english challenge dataset gap wino - gender highlight model preference "" hallucinatory "" , e.g. , disambiguate genderambiguous occurrence ' doctor ' male doctor . language type b reflexivization , e.g. , swedish russian , construct multi - task challenge dataset detect gender bias lead unambiguously wrong model prediction : language , direct translation ' doctor remove mask ' ambiguous coreferential reading disjoint reading . instead , coreferential reading require non - gendered pronoun , gendered , possessive pronoun anti - reflexive . present multilingual , multi - task challenge dataset , span language nlp task focus phenomenon . find evidence gender bias task - language combination correlate model bias national labor market statistic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 17, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 3, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 8, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Interpretability and Analysis of Models for NLP,What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding,"In recent years, pre-trained Transformers have dominated the majority of NLP benchmark tasks. Many variants of pre-trained Transformers have kept breaking out, and most focus on designing different pre-training objectives or variants of self-attention. Embedding the position information in the self-attention mechanism is also an indispensable factor in Transformers however is often discussed at will. Therefore, this paper carries out an empirical study on position embeddings of mainstream pre-trained Transformers, which mainly focuses on two questions: 1) Do position embeddings really learn the meaning of positions? 2) How do these different learned position embeddings affect Transformers for NLP tasks? This paper focuses on providing a new insight of pre-trained position embeddings through feature-level analysis and empirical experiments on most of iconic NLP tasks. It is believed that our experimental results can guide the future work to choose the suitable positional encoding function for specific tasks given the application property. 1","What Do Position Embeddings Learn? An Empirical Study of Pre-Trained Language Model Positional Encoding In recent years, pre-trained Transformers have dominated the majority of NLP benchmark tasks. Many variants of pre-trained Transformers have kept breaking out, and most focus on designing different pre-training objectives or variants of self-attention. Embedding the position information in the self-attention mechanism is also an indispensable factor in Transformers however is often discussed at will. Therefore, this paper carries out an empirical study on position embeddings of mainstream pre-trained Transformers, which mainly focuses on two questions: 1) Do position embeddings really learn the meaning of positions? 2) How do these different learned position embeddings affect Transformers for NLP tasks? This paper focuses on providing a new insight of pre-trained position embeddings through feature-level analysis and empirical experiments on most of iconic NLP tasks. It is believed that our experimental results can guide the future work to choose the suitable positional encoding function for specific tasks given the application property. 1","position embedding learn ? empirical study pre - trained language model positional encoding recent year , pre - trained transformers dominate majority nlp benchmark task . variant pre - train transformers keep break , focus design different pre - training objective variant self - attention . embed position information self - attention mechanism indispensable factor transformers discuss . , paper carry empirical study position embedding mainstream pre - train transformers , mainly focus question : 1 ) position embedding learn meaning position ? 2 ) different learn position embedding affect transformers nlp task ? paper focus provide new insight pre - train position embedding feature - level analysis empirical experiment iconic nlp task . believe experimental result guide future work choose suitable positional encoding function specific task give application property . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Pretrained Language Model Embryology: The Birth of ALBERT,"While behaviors of pretrained language models (LMs) have been thoroughly examined, what happened during pretraining is rarely studied. We thus investigate the developmental process from a set of randomly initialized parameters to a totipotent 1 language model, which we refer to as the embryology of a pretrained language model. Our results show that ALBERT learns to reconstruct and predict tokens of different parts of speech (POS) in different learning speeds during pretraining. We also find that linguistic knowledge and world knowledge do not generally improve as pretraining proceeds, nor do downstream tasks' performance. These findings suggest that knowledge of a pretrained model varies during pretraining, and having more pretrain steps does not necessarily provide a model with more comprehensive knowledge. We provide source codes and pretrained models to reproduce our results at https://github. com/d223302/albert-embryology.","Pretrained Language Model Embryology: The Birth of ALBERT While behaviors of pretrained language models (LMs) have been thoroughly examined, what happened during pretraining is rarely studied. We thus investigate the developmental process from a set of randomly initialized parameters to a totipotent 1 language model, which we refer to as the embryology of a pretrained language model. Our results show that ALBERT learns to reconstruct and predict tokens of different parts of speech (POS) in different learning speeds during pretraining. We also find that linguistic knowledge and world knowledge do not generally improve as pretraining proceeds, nor do downstream tasks' performance. These findings suggest that knowledge of a pretrained model varies during pretraining, and having more pretrain steps does not necessarily provide a model with more comprehensive knowledge. We provide source codes and pretrained models to reproduce our results at https://github. com/d223302/albert-embryology.","pretrained language model embryology : birth albert behavior pretrained language model ( lms ) thoroughly examine , happen pretraining rarely study . investigate developmental process set randomly initialize parameter totipotent 1 language model , refer embryology pretrained language model . result albert learn reconstruct predict token different part speech ( pos ) different learning speed pretraining . find linguistic knowledge world knowledge generally improve pretraining proceed , downstream task ' performance . finding suggest knowledge pretraine model vary pretraining , have pretrain step necessarily provide model comprehensive knowledge . provide source code pretrained model reproduce result https://github . com / d223302 / albert - embryology .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 15, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,An information theoretic view on selecting linguistic probes,"There is increasing interest in assessing the linguistic knowledge encoded in neural representations. A popular approach is to attach a diagnostic classifier -or ""probe"" -to perform supervised classification from internal representations. However, how to select a good probe is in debate. Hewitt and Liang (2019) showed that a high performance on diagnostic classification itself is insufficient, because it can be attributed to either ""the representation being rich in knowledge"", or ""the probe learning the task"", which Pimentel et al. ( 2020 ) challenged. We show this dichotomy is valid informationtheoretically. In addition, we find that the methods to construct and select good probes proposed by the two papers, control task (Hewitt and Liang, 2019) and control function (Pimentel et al., 2020), are equivalent -the errors of their approaches are identical (modulo irrelevant terms). Empirically, these two selection criteria lead to results that highly agree with each other.","An information theoretic view on selecting linguistic probes There is increasing interest in assessing the linguistic knowledge encoded in neural representations. A popular approach is to attach a diagnostic classifier -or ""probe"" -to perform supervised classification from internal representations. However, how to select a good probe is in debate. Hewitt and Liang (2019) showed that a high performance on diagnostic classification itself is insufficient, because it can be attributed to either ""the representation being rich in knowledge"", or ""the probe learning the task"", which Pimentel et al. ( 2020 ) challenged. We show this dichotomy is valid informationtheoretically. In addition, we find that the methods to construct and select good probes proposed by the two papers, control task (Hewitt and Liang, 2019) and control function (Pimentel et al., 2020), are equivalent -the errors of their approaches are identical (modulo irrelevant terms). Empirically, these two selection criteria lead to results that highly agree with each other.","information theoretic view select linguistic probe increase interest assess linguistic knowledge encode neural representation . popular approach attach diagnostic classifier -or "" probe "" -to perform supervise classification internal representation . , select good probe debate . hewitt liang ( 2019 ) show high performance diagnostic classification insufficient , attribute "" representation rich knowledge "" , "" probe learn task "" , pimentel et al . ( 2020 ) challenge . dichotomy valid informationtheoretically . addition , find method construct select good probe propose paper , control task ( hewitt liang , 2019 ) control function ( pimentel et al . , 2020 ) , equivalent -the error approach identical ( modulo irrelevant term ) . empirically , selection criterion lead result highly agree .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Theme,False
Interpretability and Analysis of Models for NLP,Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-Trained Language Models,"Recent works show that pre-trained language models (PTLMs), such as BERT, possess certain commonsense and factual knowledge. They suggest that it is promising to use PTLMs as ""neural knowledge bases"" via predicting masked words. Surprisingly, we find that this may not work for numerical commonsense knowledge (e.g., a bird usually has two legs). In this paper, we investigate whether and to what extent we can induce numerical commonsense knowledge from PTLMs as well as the robustness of this process. To study this, we introduce a novel probing task with a diagnostic dataset, NUMERSENSE 1 , containing 13.6k masked-word-prediction probes (10.5k for fine-tuning and 3.1k for testing). Our analysis reveals that: (1) BERT and its stronger variant RoBERTa perform poorly on the diagnostic dataset prior to any fine-tuning; (2) finetuning with distant supervision brings some improvement; (3) the best supervised model still performs poorly as compared to human performance (54.06% vs. 96.3% in accuracy).","Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-Trained Language Models Recent works show that pre-trained language models (PTLMs), such as BERT, possess certain commonsense and factual knowledge. They suggest that it is promising to use PTLMs as ""neural knowledge bases"" via predicting masked words. Surprisingly, we find that this may not work for numerical commonsense knowledge (e.g., a bird usually has two legs). In this paper, we investigate whether and to what extent we can induce numerical commonsense knowledge from PTLMs as well as the robustness of this process. To study this, we introduce a novel probing task with a diagnostic dataset, NUMERSENSE 1 , containing 13.6k masked-word-prediction probes (10.5k for fine-tuning and 3.1k for testing). Our analysis reveals that: (1) BERT and its stronger variant RoBERTa perform poorly on the diagnostic dataset prior to any fine-tuning; (2) finetuning with distant supervision brings some improvement; (3) the best supervised model still performs poorly as compared to human performance (54.06% vs. 96.3% in accuracy).","bird leg ? ! numersense : probe numerical commonsense knowledge pre - trained language model recent work pre - trained language model ( ptlms ) , bert , possess certain commonsense factual knowledge . suggest promising use ptlms "" neural knowledge basis "" predict mask word . surprisingly , find work numerical commonsense knowledge ( e.g. , bird usually leg ) . paper , investigate extent induce numerical commonsense knowledge ptlms robustness process . study , introduce novel probe task diagnostic dataset , numersense 1 , contain 13.6k mask - word - prediction probe ( 10.5k fine - tuning 3.1k testing ) . analysis reveal : ( 1 ) bert strong variant roberta perform poorly diagnostic dataset prior fine - tuning ; ( 2 ) finetune distant supervision bring improvement ; ( 3 ) well supervise model perform poorly compare human performance ( 54.06 % vs. 96.3 % accuracy ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Asking without Telling: Exploring Latent Ontologies in Contextual Representations,"The success of pretrained contextual encoders, such as ELMo and BERT, has brought a great deal of interest in what these models learn: do they, without explicit supervision, learn to encode meaningful notions of linguistic structure? If so, how is this structure encoded? To investigate this, we introduce latent subclass learning (LSL): a modification to classifierbased probing that induces a latent categorization (or ontology) of the probe's inputs. Without access to fine-grained gold labels, LSL extracts emergent structure from input representations in an interpretable and quantifiable form. In experiments, we find strong evidence of familiar categories, such as a notion of personhood in ELMo, as well as novel ontological distinctions, such as a preference for fine-grained semantic roles on core arguments. Our results provide unique new evidence of emergent structure in pretrained encoders, including departures from existing annotations which are inaccessible to earlier methods.","Asking without Telling: Exploring Latent Ontologies in Contextual Representations The success of pretrained contextual encoders, such as ELMo and BERT, has brought a great deal of interest in what these models learn: do they, without explicit supervision, learn to encode meaningful notions of linguistic structure? If so, how is this structure encoded? To investigate this, we introduce latent subclass learning (LSL): a modification to classifierbased probing that induces a latent categorization (or ontology) of the probe's inputs. Without access to fine-grained gold labels, LSL extracts emergent structure from input representations in an interpretable and quantifiable form. In experiments, we find strong evidence of familiar categories, such as a notion of personhood in ELMo, as well as novel ontological distinctions, such as a preference for fine-grained semantic roles on core arguments. Our results provide unique new evidence of emergent structure in pretrained encoders, including departures from existing annotations which are inaccessible to earlier methods.","ask tell : explore latent ontology contextual representation success pretrained contextual encoder , elmo bert , bring great deal interest model learn : , explicit supervision , learn encode meaningful notion linguistic structure ? , structure encode ? investigate , introduce latent subclass learning ( lsl ): modification classifierbased probing induce latent categorization ( ontology ) probe input . access fine - grained gold label , lsl extract emergent structure input representation interpretable quantifiable form . experiment , find strong evidence familiar category , notion personhood elmo , novel ontological distinction , preference fine - grained semantic role core argument . result provide unique new evidence emergent structure pretrained encoder , include departure exist annotation inaccessible early method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Towards Interpreting BERT for Reading Comprehension Based QA,"BERT and its variants have achieved stateof-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the linguistic information being captured in BERT. However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer's role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial layers focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much/how many), we notice that BERT focuses on confusing words (i.e., on other numerical quantities in the passage) in the later layers, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/ iitmnlp/BERT-Analysis-RCQA.","Towards Interpreting BERT for Reading Comprehension Based QA BERT and its variants have achieved stateof-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the linguistic information being captured in BERT. However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer's role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial layers focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much/how many), we notice that BERT focuses on confusing words (i.e., on other numerical quantities in the passage) in the later layers, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/ iitmnlp/BERT-Analysis-RCQA.","interpret bert reading comprehension base qa bert variant achieve stateof - - art performance nlp task . , work propose analyze linguistic information capture bert . , current work provide insight bert able achieve near human - level performance task reading comprehension base question answering . work , attempt interpret bert rcqa . bert layer predefine role , define layer role functionality integrated gradients . base define role , perform preliminary analysis layer . observe initial layer focus query - passage interaction , later layer focus contextual understanding enhance answer prediction . specifically quantifier question ( / ) , notice bert focus confuse word ( i.e. , numerical quantity passage ) later layer , manage predict answer correctly . fine - tuning analysis script publicly available https://github.com/ iitmnlp / bert - analysis - rcqa .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 16, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 17, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Interpretability and Analysis of Models for NLP,An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction,"Decisions of complex models for language understanding can be explained by limiting the inputs they are provided to a relevant subsequence of the original text -a rationale. Models that condition predictions on a concise rationale, while being more interpretable, tend to be less accurate than models that are able to use the entire context. In this paper, we show that it is possible to better manage the trade-off between concise explanations and high task accuracy by optimizing a bound on the Information Bottleneck (IB) objective. Our approach jointly learns an explainer that predicts sparse binary masks over input sentences without explicit supervision, and an end-task predictor that considers only the residual sentences. Using IB, we derive a learning objective that allows direct control of mask sparsity levels through a tunable sparse prior. Experiments on the ERASER benchmark demonstrate significant gains over previous work for both task performance and agreement with human rationales. Furthermore, we find that in the semi-supervised setting, a modest amount of gold rationales (25% of training examples with gold masks) can close the performance gap with a model that uses the full input. 1","An Information Bottleneck Approach for Controlling Conciseness in Rationale Extraction Decisions of complex models for language understanding can be explained by limiting the inputs they are provided to a relevant subsequence of the original text -a rationale. Models that condition predictions on a concise rationale, while being more interpretable, tend to be less accurate than models that are able to use the entire context. In this paper, we show that it is possible to better manage the trade-off between concise explanations and high task accuracy by optimizing a bound on the Information Bottleneck (IB) objective. Our approach jointly learns an explainer that predicts sparse binary masks over input sentences without explicit supervision, and an end-task predictor that considers only the residual sentences. Using IB, we derive a learning objective that allows direct control of mask sparsity levels through a tunable sparse prior. Experiments on the ERASER benchmark demonstrate significant gains over previous work for both task performance and agreement with human rationales. Furthermore, we find that in the semi-supervised setting, a modest amount of gold rationales (25% of training examples with gold masks) can close the performance gap with a model that uses the full input. 1","information bottleneck approach control conciseness rationale extraction decision complex model language understanding explain limit input provide relevant subsequence original text -a rationale . model condition prediction concise rationale , interpretable , tend accurate model able use entire context . paper , possible well manage trade - concise explanation high task accuracy optimize bound information bottleneck ( ib ) objective . approach jointly learn explainer predict sparse binary mask input sentence explicit supervision , end - task predictor consider residual sentence . ib , derive learning objective allow direct control mask sparsity level tunable sparse prior . experiment eraser benchmark demonstrate significant gain previous work task performance agreement human rationale . furthermore , find semi - supervised setting , modest gold rationale ( 25 % training example gold mask ) close performance gap model use input . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers,"To build an interpretable neural text classifier, most of the prior work has focused on designing inherently interpretable models or finding faithful explanations. A new line of work on improving model interpretability has just started, and many existing methods require either prior information or human annotations as additional inputs in training. To address this limitation, we propose the variational word mask (VMASK) method to automatically learn task-specific important words and reduce irrelevant information on classification, which ultimately improves the interpretability of model predictions. The proposed method is evaluated with three neural text classifiers (CNN, LSTM, and BERT) on seven benchmark text classification datasets. Experiments show the effectiveness of VMASK in improving both model prediction accuracy and interpretability. 1 The similarity will be detailed in section 4 and more examples are provided in Table 5 .","Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers To build an interpretable neural text classifier, most of the prior work has focused on designing inherently interpretable models or finding faithful explanations. A new line of work on improving model interpretability has just started, and many existing methods require either prior information or human annotations as additional inputs in training. To address this limitation, we propose the variational word mask (VMASK) method to automatically learn task-specific important words and reduce irrelevant information on classification, which ultimately improves the interpretability of model predictions. The proposed method is evaluated with three neural text classifiers (CNN, LSTM, and BERT) on seven benchmark text classification datasets. Experiments show the effectiveness of VMASK in improving both model prediction accuracy and interpretability. 1 The similarity will be detailed in section 4 and more examples are provided in Table 5 .","learn variational word mask improve interpretability neural text classifier build interpretable neural text classifier , prior work focus design inherently interpretable model find faithful explanation . new line work improve model interpretability start , exist method require prior information human annotation additional input training . address limitation , propose variational word mask ( vmask ) method automatically learn task - specific important word reduce irrelevant information classification , ultimately improve interpretability model prediction . propose method evaluate neural text classifier ( cnn , lstm , bert ) seven benchmark text classification dataset . experiment effectiveness vmask improve model prediction accuracy interpretability . 1 similarity detail section 4 example provide table 5 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 7, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Improving Low Compute Language Modeling with In-Domain Embedding Initialisation,"Many NLP applications, such as biomedical data and technical support, have 10-100 million tokens of in-domain data and limited computational resources for learning from it. How should we train a language model in this scenario? Most language modeling research considers either a small dataset with a closed vocabulary (like the standard 1 million token Penn Treebank), or the whole web with bytepair encoding. We show that for our target setting in English, initialising and freezing input embeddings using in-domain data can improve language model performance by providing a useful representation of rare words, and this pattern holds across several different domains. In the process, we show that the standard convention of tying input and output embeddings does not improve perplexity when initializing with embeddings trained on in-domain data.","Improving Low Compute Language Modeling with In-Domain Embedding Initialisation Many NLP applications, such as biomedical data and technical support, have 10-100 million tokens of in-domain data and limited computational resources for learning from it. How should we train a language model in this scenario? Most language modeling research considers either a small dataset with a closed vocabulary (like the standard 1 million token Penn Treebank), or the whole web with bytepair encoding. We show that for our target setting in English, initialising and freezing input embeddings using in-domain data can improve language model performance by providing a useful representation of rare words, and this pattern holds across several different domains. In the process, we show that the standard convention of tying input and output embeddings does not improve perplexity when initializing with embeddings trained on in-domain data.","improve low compute language modeling - domain embedding initialisation nlp application , biomedical datum technical support , 10 - 100 million token - domain datum limited computational resource learn . train language model scenario ? language modeling research consider small dataset closed vocabulary ( like standard 1 million token penn treebank ) , web bytepair encoding . target setting english , initialise freeze input embedding - domain datum improve language model performance provide useful representation rare word , pattern hold different domain . process , standard convention tie input output embedding improve perplexity initialize embedding train - domain datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Information-Theoretic Probing with Minimum Description Length,"To measure how well pretrained representations encode some linguistic property, it is common to use accuracy of a probe, i.e. a classifier trained to predict the property from the representations. Despite widespread adoption of probes, differences in their accuracy fail to adequately reflect differences in representations. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their accuracy can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in accuracy with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates 'the amount of effort' needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines: variational coding and online coding. We show that these methods agree in results and are more informative and stable than the standard probes. 1","Information-Theoretic Probing with Minimum Description Length To measure how well pretrained representations encode some linguistic property, it is common to use accuracy of a probe, i.e. a classifier trained to predict the property from the representations. Despite widespread adoption of probes, differences in their accuracy fail to adequately reflect differences in representations. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their accuracy can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in accuracy with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates 'the amount of effort' needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines: variational coding and online coding. We show that these methods agree in results and are more informative and stable than the standard probes. 1","information - theoretic probing minimum description length measure pretrained representation encode linguistic property , common use accuracy probe , i.e. classifier train predict property representation . despite widespread adoption probe , difference accuracy fail adequately reflect difference representation . example , substantially favour pretrained representation randomly initialize one . analogously , accuracy similar probe genuine linguistic label probe random synthetic task . reasonable difference accuracy respect random baseline , previous work constrain probe training datum model size . instead , propose alternative standard probe , information - theoretic probing minimum description length ( mdl ) . mdl probing , train probe predict label recast teach effectively transmit datum . , measure interest change probe accuracy description length label give representation . addition probe quality , description length evaluate ' effort ' need achieve quality . effort characterize ( ) size probe model , ( ii ) datum need achieve high quality . consider method estimate mdl easily implement standard probe pipeline : variational coding online coding . method agree result informative stable standard probe . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 12, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 12, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Top-Rank-Focused Adaptive Vote Collection for the Evaluation of Domain-Specific Semantic Models,"The growth of domain-specific applications of semantic models, boosted by the recent achievements of unsupervised embedding learning algorithms, demands domain-specific evaluation datasets. In many cases, contentbased recommenders being a prime example, these models are required to rank words or texts according to their semantic relatedness to a given concept, with particular focus on top ranks. In this work, we give a threefold contribution to address these requirements: (i) we define a protocol for the construction, based on adaptive pairwise comparisons, of a relatedness-based evaluation dataset tailored on the available resources and optimized to be particularly accurate in top-rank evaluation; (ii) we define appropriate metrics, extensions of well-known ranking correlation coefficients, to evaluate a semantic model via the aforementioned dataset by taking into account the greater significance of top ranks. Finally, (iii) we define a stochastic transitivity model to simulate semantic-driven pairwise comparisons, which confirms the effectiveness of the proposed dataset construction protocol.","Top-Rank-Focused Adaptive Vote Collection for the Evaluation of Domain-Specific Semantic Models The growth of domain-specific applications of semantic models, boosted by the recent achievements of unsupervised embedding learning algorithms, demands domain-specific evaluation datasets. In many cases, contentbased recommenders being a prime example, these models are required to rank words or texts according to their semantic relatedness to a given concept, with particular focus on top ranks. In this work, we give a threefold contribution to address these requirements: (i) we define a protocol for the construction, based on adaptive pairwise comparisons, of a relatedness-based evaluation dataset tailored on the available resources and optimized to be particularly accurate in top-rank evaluation; (ii) we define appropriate metrics, extensions of well-known ranking correlation coefficients, to evaluate a semantic model via the aforementioned dataset by taking into account the greater significance of top ranks. Finally, (iii) we define a stochastic transitivity model to simulate semantic-driven pairwise comparisons, which confirms the effectiveness of the proposed dataset construction protocol.","- rank - focus adaptive vote collection evaluation domain - specific semantic model growth domain - specific application semantic model , boost recent achievement unsupervised embed learn algorithm , demand domain - specific evaluation dataset . case , contentbased recommender prime example , model require rank word text accord semantic relatedness give concept , particular focus rank . work , threefold contribution address requirement : ( ) define protocol construction , base adaptive pairwise comparison , relatedness - base evaluation dataset tailor available resource optimize particularly accurate - rank evaluation ; ( ii ) define appropriate metric , extension - know ranking correlation coefficient , evaluate semantic model aforementioned dataset take account great significance rank . finally , ( iii ) define stochastic transitivity model simulate semantic - drive pairwise comparison , confirm effectiveness propose dataset construction protocol .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Interpretability and Analysis of Models for NLP,Analyzing Individual Neurons in Pre-trained Language Models,"While a lot of analysis has been carried to demonstrate linguistic knowledge captured by the representations learned within deep NLP models, very little attention has been paid towards individual neurons. We carry out a neuron-level analysis using core linguistic tasks of predicting morphology, syntax and semantics, on pre-trained language models, with questions like: i) do individual neurons in pretrained models capture linguistic information? ii) which parts of the network learn more about certain linguistic phenomena? iii) how distributed or focused is the information? and iv) how do various architectures differ in learning these properties? We found small subsets of neurons to predict linguistic tasks, with lower level tasks (such as morphology) localized in fewer neurons, compared to higher level task of predicting syntax. Our study reveals interesting cross architectural comparisons. For example, we found neurons in XLNet to be more localized and disjoint when predicting properties compared to BERT and others, where they are more distributed and coupled.","Analyzing Individual Neurons in Pre-trained Language Models While a lot of analysis has been carried to demonstrate linguistic knowledge captured by the representations learned within deep NLP models, very little attention has been paid towards individual neurons. We carry out a neuron-level analysis using core linguistic tasks of predicting morphology, syntax and semantics, on pre-trained language models, with questions like: i) do individual neurons in pretrained models capture linguistic information? ii) which parts of the network learn more about certain linguistic phenomena? iii) how distributed or focused is the information? and iv) how do various architectures differ in learning these properties? We found small subsets of neurons to predict linguistic tasks, with lower level tasks (such as morphology) localized in fewer neurons, compared to higher level task of predicting syntax. Our study reveals interesting cross architectural comparisons. For example, we found neurons in XLNet to be more localized and disjoint when predicting properties compared to BERT and others, where they are more distributed and coupled.","analyze individual neuron pre - trained language model lot analysis carry demonstrate linguistic knowledge capture representation learn deep nlp model , little attention pay individual neuron . carry neuron - level analysis core linguistic task predict morphology , syntax semantic , pre - trained language model , question like : ) individual neuron pretrained model capture linguistic information ? ii ) part network learn certain linguistic phenomenon ? iii ) distributed focused information ? iv ) architecture differ learn property ? find small subset neuron predict linguistic task , low level task ( morphology ) localize few neuron , compare high level task predict syntax . study reveal interesting cross architectural comparison . example , find neuron xlnet localized disjoint predict property compare bert , distribute coupled .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Dissecting Span Identification Tasks with Performance Prediction,"Span identification (in short, span ID) tasks such as chunking, NER, or code-switching detection, ask models to identify and classify relevant spans in a text. Despite being a staple of NLP, and sharing a common structure, there is little insight on how these tasks' properties influence their difficulty, and thus little guidance on what model families work well on span ID tasks, and why. We analyze span ID tasks via performance prediction, estimating how well neural architectures do on different tasks. Our contributions are: (a) we identify key properties of span ID tasks that can inform performance prediction; (b) we carry out a large-scale experiment on English data, building a model to predict performance for unseen span ID tasks that can support architecture choices; (c), we investigate the parameters of the meta model, yielding new insights on how model and task properties interact to affect span ID performance. We find, e.g., that span frequency is especially important for LSTMs, and that CRFs help when spans are infrequent and boundaries non-distinctive.","Dissecting Span Identification Tasks with Performance Prediction Span identification (in short, span ID) tasks such as chunking, NER, or code-switching detection, ask models to identify and classify relevant spans in a text. Despite being a staple of NLP, and sharing a common structure, there is little insight on how these tasks' properties influence their difficulty, and thus little guidance on what model families work well on span ID tasks, and why. We analyze span ID tasks via performance prediction, estimating how well neural architectures do on different tasks. Our contributions are: (a) we identify key properties of span ID tasks that can inform performance prediction; (b) we carry out a large-scale experiment on English data, building a model to predict performance for unseen span ID tasks that can support architecture choices; (c), we investigate the parameters of the meta model, yielding new insights on how model and task properties interact to affect span ID performance. We find, e.g., that span frequency is especially important for LSTMs, and that CRFs help when spans are infrequent and boundaries non-distinctive.","dissect span identification task performance prediction span identification ( short , span id ) task chunking , ner , code - switching detection , ask model identify classify relevant span text . despite staple nlp , share common structure , little insight task ' property influence difficulty , little guidance model family work span id task , . analyze span id task performance prediction , estimate neural architecture different task . contribution : ( ) identify key property span id task inform performance prediction ; ( b ) carry large - scale experiment english datum , build model predict performance unseen span id task support architecture choice ; ( c ) , investigate parameter meta model , yield new insight model task property interact affect span id performance . find , e.g. , span frequency especially important lstm , crfs help span infrequent boundary non - distinctive .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,Pareto Probing: Trading Off Accuracy for Complexity,"The question of how to probe contextual word representations for linguistic structure in a way that is both principled and useful has seen significant attention recently in the NLP literature. In our contribution to this discussion, we argue for a probe metric that reflects the fundamental trade-off between probe complexity and performance: the Pareto hypervolume. To measure complexity, we present a number of parametric and non-parametric metrics. Our experiments using Pareto hypervolume as an evaluation metric show that probes often do not conform to our expectations-e.g., why should the non-contextual fastText representations encode more morpho-syntactic information than the contextual BERT representations? These results suggest that common, simplistic probing tasks, such as part-of-speech labeling and dependency arc labeling, are inadequate to evaluate the linguistic structure encoded in contextual word representations. This leads us to propose full dependency parsing as a probing task. In support of our suggestion that harder probing tasks are necessary, our experiments with dependency parsing reveal a wide gap in syntactic knowledge between contextual and non-contextual representations. Our code can be found at https://github. com/rycolab/pareto-probing.","Pareto Probing: Trading Off Accuracy for Complexity The question of how to probe contextual word representations for linguistic structure in a way that is both principled and useful has seen significant attention recently in the NLP literature. In our contribution to this discussion, we argue for a probe metric that reflects the fundamental trade-off between probe complexity and performance: the Pareto hypervolume. To measure complexity, we present a number of parametric and non-parametric metrics. Our experiments using Pareto hypervolume as an evaluation metric show that probes often do not conform to our expectations-e.g., why should the non-contextual fastText representations encode more morpho-syntactic information than the contextual BERT representations? These results suggest that common, simplistic probing tasks, such as part-of-speech labeling and dependency arc labeling, are inadequate to evaluate the linguistic structure encoded in contextual word representations. This leads us to propose full dependency parsing as a probing task. In support of our suggestion that harder probing tasks are necessary, our experiments with dependency parsing reveal a wide gap in syntactic knowledge between contextual and non-contextual representations. Our code can be found at https://github. com/rycolab/pareto-probing.","pareto probing : trade accuracy complexity question probe contextual word representation linguistic structure way principled useful see significant attention recently nlp literature . contribution discussion , argue probe metric reflect fundamental trade - probe complexity performance : pareto hypervolume . measure complexity , present number parametric non - parametric metric . experiment pareto hypervolume evaluation metric probe conform expectation - e.g. , non - contextual fasttext representation encode morpho - syntactic information contextual bert representation ? result suggest common , simplistic probing task , - - speech labeling dependency arc labeling , inadequate evaluate linguistic structure encode contextual word representation . lead propose dependency parsing probing task . support suggestion hard probe task necessary , experiment dependency parsing reveal wide gap syntactic knowledge contextual non - contextual representation . code find https://github . com / rycolab / pareto - probing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 7, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Interpretability and Analysis of Models for NLP,LOGAN: Local Group Bias Detection by Clustering,"Machine learning techniques have been widely used in natural language processing (NLP). However, as revealed by many recent studies, machine learning models often inherit and amplify the societal biases in data. Various metrics have been proposed to quantify biases in model predictions. In particular, several of them evaluate disparity in model performance between protected groups and advantaged groups in the test corpus. However, we argue that evaluating bias at the corpus level is not enough for understanding how biases are embedded in a model. In fact, a model with similar aggregated performance between different groups on the entire data may behave differently on instances in a local region. To analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on clustering. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions.","LOGAN: Local Group Bias Detection by Clustering Machine learning techniques have been widely used in natural language processing (NLP). However, as revealed by many recent studies, machine learning models often inherit and amplify the societal biases in data. Various metrics have been proposed to quantify biases in model predictions. In particular, several of them evaluate disparity in model performance between protected groups and advantaged groups in the test corpus. However, we argue that evaluating bias at the corpus level is not enough for understanding how biases are embedded in a model. In fact, a model with similar aggregated performance between different groups on the entire data may behave differently on instances in a local region. To analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on clustering. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions.","logan : local group bias detection cluster machine learning technique widely natural language processing ( nlp ) . , reveal recent study , machine learning model inherit amplify societal bias datum . metric propose quantify bias model prediction . particular , evaluate disparity model performance protect group advantaged group test corpus . , argue evaluate bias corpus level understand bias embed model . fact , model similar aggregate performance different group entire data behave differently instance local region . analyze detect local bias , propose logan , new bias detection technique base clustering . experiment toxicity classification object classification task logan identify bias local region allow well analyze bias model prediction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 9, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Interpretability and Analysis of Models for NLP,RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark,"In this paper, we introduce an advanced Russian general language understanding evaluation benchmark -RussianGLUE. Recent advances in the field of universal language models and transformers require the development of a methodology for their broad diagnostics and testing for general intellectual skills -detection of natural language inference, commonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first time, a benchmark of nine tasks, collected and organized analogically to the SuperGLUE methodology (Wang et al., 2019), was developed from scratch for the Russian language. We provide baselines, human level evaluation, an opensource framework for evaluating models and an overall leaderboard of transformer models for the Russian language. Besides, we present the first results of comparing multilingual models in the adapted diagnostic test set and offer the first steps to further expanding or assessing state-of-the-art models independently of language.","RussianSuperGLUE: A Russian Language Understanding Evaluation Benchmark In this paper, we introduce an advanced Russian general language understanding evaluation benchmark -RussianGLUE. Recent advances in the field of universal language models and transformers require the development of a methodology for their broad diagnostics and testing for general intellectual skills -detection of natural language inference, commonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first time, a benchmark of nine tasks, collected and organized analogically to the SuperGLUE methodology (Wang et al., 2019), was developed from scratch for the Russian language. We provide baselines, human level evaluation, an opensource framework for evaluating models and an overall leaderboard of transformer models for the Russian language. Besides, we present the first results of comparing multilingual models in the adapted diagnostic test set and offer the first steps to further expanding or assessing state-of-the-art models independently of language.","russiansuperglue : russian language understanding evaluation benchmark paper , introduce advanced russian general language understanding evaluation benchmark -russianglue . recent advance field universal language model transformer require development methodology broad diagnostic testing general intellectual skill -detection natural language inference , commonsense reasoning , ability perform simple logical operation regardless text subject lexicon . time , benchmark task , collect organize analogically superglue methodology ( wang et al . , 2019 ) , develop scratch russian language . provide baseline , human level evaluation , opensource framework evaluate model overall leaderboard transformer model russian language . , present result compare multilingual model adapted diagnostic test set offer step expand assess state - - - art model independently language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,On the weak link between importance and prunability of attention heads,"Given the success of Transformer-based models, two directions of study have emerged: interpreting role of individual attention heads and down-sizing the models for efficiency. Our work straddles these two streams: We analyse the importance of basing pruning strategies on the interpreted role of the attention heads. We evaluate this on Transformer and BERT models on multiple NLP tasks. Firstly, we find that a large fraction of the attention heads can be randomly pruned with limited effect on accuracy. Secondly, for Transformers, we find no advantage in pruning attention heads identified to be important based on existing studies that relate importance to the location of a head. On the BERT model too we find no preference for top or bottom layers, though the latter are reported to have higher importance. However, strategies that avoid pruning middle layers and consecutive layers perform better. Finally, during fine-tuning the compensation for pruned attention heads is roughly equally distributed across the un-pruned heads. Our results thus suggest that interpretation of attention heads does not strongly inform pruning.","On the weak link between importance and prunability of attention heads Given the success of Transformer-based models, two directions of study have emerged: interpreting role of individual attention heads and down-sizing the models for efficiency. Our work straddles these two streams: We analyse the importance of basing pruning strategies on the interpreted role of the attention heads. We evaluate this on Transformer and BERT models on multiple NLP tasks. Firstly, we find that a large fraction of the attention heads can be randomly pruned with limited effect on accuracy. Secondly, for Transformers, we find no advantage in pruning attention heads identified to be important based on existing studies that relate importance to the location of a head. On the BERT model too we find no preference for top or bottom layers, though the latter are reported to have higher importance. However, strategies that avoid pruning middle layers and consecutive layers perform better. Finally, during fine-tuning the compensation for pruned attention heads is roughly equally distributed across the un-pruned heads. Our results thus suggest that interpretation of attention heads does not strongly inform pruning.","weak link importance prunability attention head give success transformer - base model , direction study emerge : interpret role individual attention head - size model efficiency . work straddle stream : analyse importance base prune strategy interpret role attention head . evaluate transformer bert model multiple nlp task . firstly , find large fraction attention head randomly prune limited effect accuracy . secondly , transformers , find advantage prune attention head identify important base exist study relate importance location head . bert model find preference layer , report high importance . , strategy avoid prune middle layer consecutive layer perform well . finally , fine - tuning compensation prune attention head roughly equally distribute un - pruned head . result suggest interpretation attention head strongly inform pruning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 7, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Interpretation of NLP models through input marginalization,"To demystify the ""black box"" property of deep neural networks for natural language processing (NLP), several methods have been proposed to interpret their predictions by measuring the change in prediction probability after erasing each token of an input. Since existing methods replace each token with a predefined value (i.e., zero), the resulting sentence lies out of the training data distribution, yielding misleading interpretations. In this study, we raise the out-of-distribution problem induced by the existing interpretation methods and present a remedy; we propose to marginalize each token out. We interpret various NLP models trained for sentiment analysis and natural language inference using the proposed method.","Interpretation of NLP models through input marginalization To demystify the ""black box"" property of deep neural networks for natural language processing (NLP), several methods have been proposed to interpret their predictions by measuring the change in prediction probability after erasing each token of an input. Since existing methods replace each token with a predefined value (i.e., zero), the resulting sentence lies out of the training data distribution, yielding misleading interpretations. In this study, we raise the out-of-distribution problem induced by the existing interpretation methods and present a remedy; we propose to marginalize each token out. We interpret various NLP models trained for sentiment analysis and natural language inference using the proposed method.","interpretation nlp model input marginalization demystify "" black box "" property deep neural network natural language processing ( nlp ) , method propose interpret prediction measure change prediction probability erase token input . exist method replace token predefine value ( i.e. , zero ) , result sentence lie training datum distribution , yield misleading interpretation . study , raise - - distribution problem induce exist interpretation method present remedy ; propose marginalize token . interpret nlp model train sentiment analysis natural language inference propose method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Cold-Start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks,"Neural networks can achieve impressive performance on many natural language processing applications, but they typically need large labeled data for training and are not easily interpretable. On the other hand, symbolic rules such as regular expressions are interpretable, require no training, and often achieve decent accuracy; but rules cannot benefit from labeled data when available and hence underperform neural networks in rich-resource scenarios. In this paper, we propose a type of recurrent neural networks called FA-RNNs that combine the advantages of neural networks and regular expression rules. An FA-RNN can be converted from regular expressions and deployed in zero-shot and cold-start scenarios. It can also utilize labeled data for training to achieve improved prediction accuracy. After training, an FA-RNN often remains interpretable and can be converted back into regular expressions. We apply FA-RNNs to text classification and observe that FA-RNNs significantly outperform previous neural approaches in both zeroshot and low-resource settings and remain very competitive in rich-resource settings.","Cold-Start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks Neural networks can achieve impressive performance on many natural language processing applications, but they typically need large labeled data for training and are not easily interpretable. On the other hand, symbolic rules such as regular expressions are interpretable, require no training, and often achieve decent accuracy; but rules cannot benefit from labeled data when available and hence underperform neural networks in rich-resource scenarios. In this paper, we propose a type of recurrent neural networks called FA-RNNs that combine the advantages of neural networks and regular expression rules. An FA-RNN can be converted from regular expressions and deployed in zero-shot and cold-start scenarios. It can also utilize labeled data for training to achieve improved prediction accuracy. After training, an FA-RNN often remains interpretable and can be converted back into regular expressions. We apply FA-RNNs to text classification and observe that FA-RNNs significantly outperform previous neural approaches in both zeroshot and low-resource settings and remain very competitive in rich-resource settings.","cold - start interpretability : turn regular expression trainable recurrent neural networks neural network achieve impressive performance natural language processing application , typically need large label datum training easily interpretable . hand , symbolic rule regular expression interpretable , require training , achieve decent accuracy ; rule benefit label datum available underperform neural network rich - resource scenario . paper , propose type recurrent neural network call fa - rnns combine advantage neural network regular expression rule . fa - rnn convert regular expression deploy zero - shot cold - start scenario . utilize label datum training achieve improve prediction accuracy . training , fa - rnn remain interpretable convert regular expression . apply fa - rnns text classification observe fa - rnn significantly outperform previous neural approach zeroshot low - resource setting remain competitive rich - resource setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 5}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,FIND: Human-in-the-Loop Debugging Deep Text Classifiers,"Since obtaining a perfect training dataset (i.e., a dataset which is considerably large, unbiased, and well-representative of unseen cases) is hardly possible, many real-world text classifiers are trained on the available, yet imperfect, datasets. These classifiers are thus likely to have undesirable properties. For instance, they may have biases against some sub-populations or may not work effectively in the wild due to overfitting. In this paper, we propose FINDa framework which enables humans to debug deep learning text classifiers by disabling irrelevant hidden features. Experiments show that by using FIND, humans can improve CNN text classifiers which were trained under different types of imperfect datasets (including datasets with biases and datasets with dissimilar traintest distributions).","FIND: Human-in-the-Loop Debugging Deep Text Classifiers Since obtaining a perfect training dataset (i.e., a dataset which is considerably large, unbiased, and well-representative of unseen cases) is hardly possible, many real-world text classifiers are trained on the available, yet imperfect, datasets. These classifiers are thus likely to have undesirable properties. For instance, they may have biases against some sub-populations or may not work effectively in the wild due to overfitting. In this paper, we propose FINDa framework which enables humans to debug deep learning text classifiers by disabling irrelevant hidden features. Experiments show that by using FIND, humans can improve CNN text classifiers which were trained under different types of imperfect datasets (including datasets with biases and datasets with dissimilar traintest distributions).","find : human - - - loop debug deep text classifier obtain perfect training dataset ( i.e. , dataset considerably large , unbiased , - representative unseen case ) hardly possible , real - world text classifier train available , imperfect , dataset . classifier likely undesirable property . instance , bias sub - population work effectively wild overfitting . paper , propose finda framework enable human debug deep learning text classifier disable irrelevant hidden feature . experiment find , human improve cnn text classifier train different type imperfect dataset ( include dataset bias dataset dissimilar traint distribution ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Generation,Substance over Style: Document-Level Targeted Content Transfer,"Existing language models excel at writing from scratch, but many real-world scenarios require rewriting an existing document to fit a set of constraints. Although sentence-level rewriting has been fairly well-studied, little work has addressed the challenge of rewriting an entire document coherently. In this work, we introduce the task of document-level targeted content transfer and address it in the recipe domain, with a recipe as the document and a dietary restriction (such as vegan or dairy-free) as the targeted constraint. We propose a novel model for this task based on the generative pretrained language model (GPT-2) and train on a large number of roughly-aligned recipe pairs. 1 Both automatic and human evaluations show that our model out-performs existing methods by generating coherent and diverse rewrites that obey the constraint while remaining close to the original document. Finally, we analyze our model's rewrites to assess progress toward the goal of making language generation more attuned to constraints that are substantive rather than stylistic.","Substance over Style: Document-Level Targeted Content Transfer Existing language models excel at writing from scratch, but many real-world scenarios require rewriting an existing document to fit a set of constraints. Although sentence-level rewriting has been fairly well-studied, little work has addressed the challenge of rewriting an entire document coherently. In this work, we introduce the task of document-level targeted content transfer and address it in the recipe domain, with a recipe as the document and a dietary restriction (such as vegan or dairy-free) as the targeted constraint. We propose a novel model for this task based on the generative pretrained language model (GPT-2) and train on a large number of roughly-aligned recipe pairs. 1 Both automatic and human evaluations show that our model out-performs existing methods by generating coherent and diverse rewrites that obey the constraint while remaining close to the original document. Finally, we analyze our model's rewrites to assess progress toward the goal of making language generation more attuned to constraints that are substantive rather than stylistic.","substance style : document - level target content transfer exist language model excel write scratch , real - world scenario require rewrite exist document fit set constraint . sentence - level rewriting fairly - study , little work address challenge rewrite entire document coherently . work , introduce task document - level target content transfer address recipe domain , recipe document dietary restriction ( vegan dairy - free ) target constraint . propose novel model task base generative pretrained language model ( gpt-2 ) train large number roughly - align recipe pair . 1 automatic human evaluation model - perform exist method generate coherent diverse rewrite obey constraint remain close original document . finally , analyze model rewrite assess progress goal make language generation attuned constraint substantive stylistic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 6, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Generation,COD3S: Diverse Generation with Discrete Semantic Signatures,"We present COD3S, a novel method for generating semantically diverse sentences using neural sequence-to-sequence (seq2seq) models. Conditioned on an input, seq2seq models typically produce semantically and syntactically homogeneous sets of sentences and thus perform poorly on one-to-many sequence generation tasks. Our two-stage approach improves output diversity by conditioning generation on locality-sensitive hash (LSH)-based semantic sentence codes whose Hamming distances highly correlate with human judgments of semantic textual similarity. Though it is generally applicable, we apply COD3S to causal generation, the task of predicting a proposition's plausible causes or effects. We demonstrate through automatic and human evaluation that responses produced using our method exhibit improved diversity without degrading task performance.","COD3S: Diverse Generation with Discrete Semantic Signatures We present COD3S, a novel method for generating semantically diverse sentences using neural sequence-to-sequence (seq2seq) models. Conditioned on an input, seq2seq models typically produce semantically and syntactically homogeneous sets of sentences and thus perform poorly on one-to-many sequence generation tasks. Our two-stage approach improves output diversity by conditioning generation on locality-sensitive hash (LSH)-based semantic sentence codes whose Hamming distances highly correlate with human judgments of semantic textual similarity. Though it is generally applicable, we apply COD3S to causal generation, the task of predicting a proposition's plausible causes or effects. We demonstrate through automatic and human evaluation that responses produced using our method exhibit improved diversity without degrading task performance.","cod3s : diverse generation discrete semantic signature present cod3s , novel method generate semantically diverse sentence neural sequence - - sequence ( seq2seq ) model . condition input , seq2seq model typically produce semantically syntactically homogeneous set sentence perform poorly - - sequence generation task . - stage approach improve output diversity condition generation locality - sensitive hash ( lsh)-based semantic sentence code hamming distance highly correlate human judgment semantic textual similarity . generally applicable , apply cod3s causal generation , task predict proposition plausible cause effect . demonstrate automatic human evaluation response produce method exhibit improve diversity degrade task performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models,"Existing pre-trained large language models have shown unparalleled generative capabilities. However, they are not controllable. In this paper, we propose MEGATRON-CNTRL, a novel framework that uses large-scale language models and adds control to text generation by incorporating an external knowledge base. Our framework consists of a keyword predictor, a knowledge retriever, a contextual knowledge ranker, and a conditional text generator. As we do not have access to groundtruth supervision for the knowledge ranker, we make use of weak supervision from sentence embedding. The empirical results show that our model generates more fluent, consistent, and coherent stories with less repetition and higher diversity compared to prior work on the ROC story dataset. We showcase the controllability of our model by replacing the keywords used to generate stories and re-running the generation process. Human evaluation results show that 77.5% of these stories are successfully controlled by the new keywords. Furthermore, by scaling our model from 124 million to 8.3 billion parameters we demonstrate that larger models improve both the quality of generation (from 74.5% to 93.0% for consistency) and controllability (from 77.5% to 91.5%).","MEGATRON-CNTRL: Controllable Story Generation with External Knowledge Using Large-Scale Language Models Existing pre-trained large language models have shown unparalleled generative capabilities. However, they are not controllable. In this paper, we propose MEGATRON-CNTRL, a novel framework that uses large-scale language models and adds control to text generation by incorporating an external knowledge base. Our framework consists of a keyword predictor, a knowledge retriever, a contextual knowledge ranker, and a conditional text generator. As we do not have access to groundtruth supervision for the knowledge ranker, we make use of weak supervision from sentence embedding. The empirical results show that our model generates more fluent, consistent, and coherent stories with less repetition and higher diversity compared to prior work on the ROC story dataset. We showcase the controllability of our model by replacing the keywords used to generate stories and re-running the generation process. Human evaluation results show that 77.5% of these stories are successfully controlled by the new keywords. Furthermore, by scaling our model from 124 million to 8.3 billion parameters we demonstrate that larger models improve both the quality of generation (from 74.5% to 93.0% for consistency) and controllability (from 77.5% to 91.5%).","megatron - cntrl : controllable story generation external knowledge large - scale language model exist pre - trained large language model show unparalleled generative capability . , controllable . paper , propose megatron - cntrl , novel framework use large - scale language model add control text generation incorporate external knowledge base . framework consist keyword predictor , knowledge retriever , contextual knowledge ranker , conditional text generator . access groundtruth supervision knowledge ranker , use weak supervision sentence embedding . empirical result model generate fluent , consistent , coherent story repetition high diversity compare prior work roc story dataset . showcase controllability model replace keyword generate story - run generation process . human evaluation result 77.5 % story successfully control new keyword . furthermore , scale model 124 million 8.3 billion parameter demonstrate large model improve quality generation ( 74.5 % 93.0 % consistency ) controllability ( 77.5 % 91.5 % ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Inquisitive Question Generation for High Level Text Comprehension,"Inquisitive probing questions come naturally to humans in a variety of settings, but is a challenging task for automatic systems. One natural type of question to ask tries to fill a gap in knowledge during text comprehension, like reading a news article: we might ask about background information, deeper reasons behind things occurring, or more. Despite recent progress with data-driven approaches, generating such questions is beyond the range of models trained on existing datasets. We introduce INQUISITIVE, a dataset of ∼19K questions that are elicited while a person is reading through a document. Compared to existing datasets, INQUISITIVE questions target more towards high-level (semantic and discourse) comprehension of text. We show that readers engage in a series of pragmatic strategies to seek information. Finally, we evaluate question generation models based on GPT-2 (Radford et al., 2019)  and show that our model is able to generate reasonable questions although the task is challenging, and highlight the importance of context to generate INQUIS-ITIVE questions.","Inquisitive Question Generation for High Level Text Comprehension Inquisitive probing questions come naturally to humans in a variety of settings, but is a challenging task for automatic systems. One natural type of question to ask tries to fill a gap in knowledge during text comprehension, like reading a news article: we might ask about background information, deeper reasons behind things occurring, or more. Despite recent progress with data-driven approaches, generating such questions is beyond the range of models trained on existing datasets. We introduce INQUISITIVE, a dataset of ∼19K questions that are elicited while a person is reading through a document. Compared to existing datasets, INQUISITIVE questions target more towards high-level (semantic and discourse) comprehension of text. We show that readers engage in a series of pragmatic strategies to seek information. Finally, we evaluate question generation models based on GPT-2 (Radford et al., 2019)  and show that our model is able to generate reasonable questions although the task is challenging, and highlight the importance of context to generate INQUIS-ITIVE questions.","inquisitive question generation high level text comprehension inquisitive probe question come naturally human variety setting , challenging task automatic system . natural type question ask try fill gap knowledge text comprehension , like read news article : ask background information , deep reason thing occur , . despite recent progress data - drive approach , generate question range model train exist dataset . introduce inquisitive , dataset ∼19 k question elicit person read document . compare exist dataset , inquisitive question target high - level ( semantic discourse ) comprehension text . reader engage series pragmatic strategy seek information . finally , evaluate question generation model base gpt-2 ( radford et al . , 2019 )   model able generate reasonable question task challenging , highlight importance context generate inquis - itive question .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 12, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Generation,How to Make Neural Natural Language Generation as Reliable as Templates in Task-Oriented Dialogue,"Neural Natural Language Generation (NLG) systems are well known for their unreliability. To overcome this issue, we propose a data augmentation approach which allows us to restrict the output of a network and guarantee reliability. While this restriction means generation will be less diverse than if randomly sampled, we include experiments that demonstrate the tendency of existing neural generation approaches to produce dull and repetitive text, and we argue that reliability is more important than diversity for this task. The system trained using this approach scored 100% in semantic accuracy on the E2E NLG Challenge dataset, the same as a template system.","How to Make Neural Natural Language Generation as Reliable as Templates in Task-Oriented Dialogue Neural Natural Language Generation (NLG) systems are well known for their unreliability. To overcome this issue, we propose a data augmentation approach which allows us to restrict the output of a network and guarantee reliability. While this restriction means generation will be less diverse than if randomly sampled, we include experiments that demonstrate the tendency of existing neural generation approaches to produce dull and repetitive text, and we argue that reliability is more important than diversity for this task. The system trained using this approach scored 100% in semantic accuracy on the E2E NLG Challenge dataset, the same as a template system.","neural natural language generation reliable template task - oriented dialogue neural natural language generation ( nlg ) system know unreliability . overcome issue , propose data augmentation approach allow restrict output network guarantee reliability . restriction mean generation diverse randomly sample , include experiment demonstrate tendency exist neural generation approach produce dull repetitive text , argue reliability important diversity task . system train approach score 100 % semantic accuracy e2e nlg challenge dataset , template system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,De-Biased Court's View Generation with Causality,"Court's view generation is a novel but essential task for legal AI, aiming at improving the interpretability of judgment prediction results and enabling automatic legal document generation. While prior text-to-text natural language generation (NLG) approaches can be used to address this problem, neglecting the confounding bias from the data generation mechanism can limit the model performance, and the bias may pollute the learning outcomes. In this paper, we propose a novel Attentional and Counterfactual based Natural Language Generation (AC-NLG) method, consisting of an attentional encoder and a pair of innovative counterfactual decoders. The attentional encoder leverages the plaintiff's claim and fact description as input to learn a claim-aware encoder from which the claim-related information in fact description can be emphasized. The counterfactual decoders are employed to eliminate the confounding bias in data and generate judgmentdiscriminative court's views (both supportive and non-supportive views) by incorporating with a synergistic judgment predictive model. Comprehensive experiments show the effectiveness of our method under both quantitative and qualitative evaluation metrics.","De-Biased Court's View Generation with Causality Court's view generation is a novel but essential task for legal AI, aiming at improving the interpretability of judgment prediction results and enabling automatic legal document generation. While prior text-to-text natural language generation (NLG) approaches can be used to address this problem, neglecting the confounding bias from the data generation mechanism can limit the model performance, and the bias may pollute the learning outcomes. In this paper, we propose a novel Attentional and Counterfactual based Natural Language Generation (AC-NLG) method, consisting of an attentional encoder and a pair of innovative counterfactual decoders. The attentional encoder leverages the plaintiff's claim and fact description as input to learn a claim-aware encoder from which the claim-related information in fact description can be emphasized. The counterfactual decoders are employed to eliminate the confounding bias in data and generate judgmentdiscriminative court's views (both supportive and non-supportive views) by incorporating with a synergistic judgment predictive model. Comprehensive experiments show the effectiveness of our method under both quantitative and qualitative evaluation metrics.","de - biased court view generation causality court view generation novel essential task legal ai , aim improve interpretability judgment prediction result enable automatic legal document generation . prior text - - text natural language generation ( nlg ) approach address problem , neglect confound bias data generation mechanism limit model performance , bias pollute learning outcome . paper , propose novel attentional counterfactual base natural language generation ( ac - nlg ) method , consist attentional encoder pair innovative counterfactual decoder . attentional encoder leverage plaintiff claim fact description input learn claim - aware encoder claim - relate information fact description emphasize . counterfactual decoder employ eliminate confound bias datum generate judgmentdiscriminative court view ( supportive non - supportive view ) incorporate synergistic judgment predictive model . comprehensive experiment effectiveness method quantitative qualitative evaluation metric .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 11, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation,"Despite the success of existing referenced metrics (e.g., BLEU and MoverScore), they correlate poorly with human judgments for openended text generation including story or dialog generation because of the notorious oneto-many issue: there are many plausible outputs for the same input, which may differ substantially in literal or semantics from the limited number of given references. To alleviate this issue, we propose UNION, a learnable UNreferenced metrIc for evaluating Open-eNded story generation, which measures the quality of a generated story without any reference. Built on top of BERT, UNION is trained to distinguish human-written stories from negative samples and recover the perturbation in negative stories. We propose an approach of constructing negative samples by mimicking the errors commonly observed in existing NLG models, including repeated plots, conflicting logic, and long-range incoherence. Experiments on two story datasets demonstrate that UNION is a reliable measure for evaluating the quality of generated stories, which correlates better with human judgments and is more generalizable than existing state-of-theart metrics.","UNION: An Unreferenced Metric for Evaluating Open-ended Story Generation Despite the success of existing referenced metrics (e.g., BLEU and MoverScore), they correlate poorly with human judgments for openended text generation including story or dialog generation because of the notorious oneto-many issue: there are many plausible outputs for the same input, which may differ substantially in literal or semantics from the limited number of given references. To alleviate this issue, we propose UNION, a learnable UNreferenced metrIc for evaluating Open-eNded story generation, which measures the quality of a generated story without any reference. Built on top of BERT, UNION is trained to distinguish human-written stories from negative samples and recover the perturbation in negative stories. We propose an approach of constructing negative samples by mimicking the errors commonly observed in existing NLG models, including repeated plots, conflicting logic, and long-range incoherence. Experiments on two story datasets demonstrate that UNION is a reliable measure for evaluating the quality of generated stories, which correlates better with human judgments and is more generalizable than existing state-of-theart metrics.","union : unreferenced metric evaluate open - ended story generation despite success existing reference metric ( e.g. , bleu moverscore ) , correlate poorly human judgment openended text generation include story dialog generation notorious oneto - issue : plausible output input , differ substantially literal semantic limited number give reference . alleviate issue , propose union , learnable unreference metric evaluate open - end story generation , measure quality generate story reference . build bert , union train distinguish human - write story negative sample recover perturbation negative story . propose approach construct negative sample mimic error commonly observe exist nlg model , include repeat plot , conflict logic , long - range incoherence . experiment story dataset demonstrate union reliable measure evaluate quality generate story , correlate well human judgment generalizable exist state - - theart metric .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 2, 'Generation': 16, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 9, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,PlotMachines: Outline-Conditioned Generation with Dynamic Plot State Tracking,"We propose the task of outline-conditioned story generation: given an outline as a set of phrases that describe key characters and events to appear in a story, the task is to generate a coherent narrative that is consistent with the provided outline. This task is challenging as the input only provides a rough sketch of the plot, and thus, models need to generate a story by interweaving the key points provided in the outline. This requires the model to keep track of the dynamic states of the latent plot, conditioning on the input outline while generating the full story. We present PLOTMACHINES, a neural narrative model that learns to transform an outline into a coherent story by tracking the dynamic plot states. In addition, we enrich PLOTMACHINES with high-level discourse structure so that the model can learn different writing styles corresponding to different parts of the narrative. Comprehensive experiments over three fiction and non-fiction datasets demonstrate that large-scale language models, such as GPT-2 and GROVER, despite their impressive generation performance, are not sufficient in generating coherent narratives for the given outline, and dynamic plot state tracking is important for composing narratives with tighter, more consistent plots.","PlotMachines: Outline-Conditioned Generation with Dynamic Plot State Tracking We propose the task of outline-conditioned story generation: given an outline as a set of phrases that describe key characters and events to appear in a story, the task is to generate a coherent narrative that is consistent with the provided outline. This task is challenging as the input only provides a rough sketch of the plot, and thus, models need to generate a story by interweaving the key points provided in the outline. This requires the model to keep track of the dynamic states of the latent plot, conditioning on the input outline while generating the full story. We present PLOTMACHINES, a neural narrative model that learns to transform an outline into a coherent story by tracking the dynamic plot states. In addition, we enrich PLOTMACHINES with high-level discourse structure so that the model can learn different writing styles corresponding to different parts of the narrative. Comprehensive experiments over three fiction and non-fiction datasets demonstrate that large-scale language models, such as GPT-2 and GROVER, despite their impressive generation performance, are not sufficient in generating coherent narratives for the given outline, and dynamic plot state tracking is important for composing narratives with tighter, more consistent plots.","plotmachines : outline - condition generation dynamic plot state tracking propose task outline - condition story generation : give outline set phrase describe key character event appear story , task generate coherent narrative consistent provide outline . task challenge input provide rough sketch plot , , model need generate story interweave key point provide outline . require model track dynamic state latent plot , condition input outline generate story . present plotmachines , neural narrative model learn transform outline coherent story track dynamic plot state . addition , enrich plotmachines high - level discourse structure model learn different writing style correspond different part narrative . comprehensive experiment fiction non - fiction dataset demonstrate large - scale language model , gpt-2 grover , despite impressive generation performance , sufficient generate coherent narrative give outline , dynamic plot state tracking important compose narrative tight , consistent plot .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Sparse Text Generation,"Current state-of-the-art text generators build on powerful language models such as GPT-2, achieving impressive performance. However, to avoid degenerate text, they require sampling from a modified softmax, via temperature parameters or ad-hoc truncation techniques, as in top-k or nucleus sampling. This creates a mismatch between training and testing conditions. In this paper, we use the recently introduced entmax transformation to train and sample from a natively sparse language model, avoiding this mismatch. The result is a text generator with favorable performance in terms of fluency and consistency, fewer repetitions, and n-gram diversity closer to human text. In order to evaluate our model, we propose three new metrics for comparing sparse or truncated distributions: -perplexity, sparsemax score, and Jensen-Shannon divergence. Human-evaluated experiments in story completion and dialogue generation show that entmax sampling leads to more engaging and coherent stories and conversations.","Sparse Text Generation Current state-of-the-art text generators build on powerful language models such as GPT-2, achieving impressive performance. However, to avoid degenerate text, they require sampling from a modified softmax, via temperature parameters or ad-hoc truncation techniques, as in top-k or nucleus sampling. This creates a mismatch between training and testing conditions. In this paper, we use the recently introduced entmax transformation to train and sample from a natively sparse language model, avoiding this mismatch. The result is a text generator with favorable performance in terms of fluency and consistency, fewer repetitions, and n-gram diversity closer to human text. In order to evaluate our model, we propose three new metrics for comparing sparse or truncated distributions: -perplexity, sparsemax score, and Jensen-Shannon divergence. Human-evaluated experiments in story completion and dialogue generation show that entmax sampling leads to more engaging and coherent stories and conversations.","sparse text generation current state - - - art text generator build powerful language model gpt-2 , achieve impressive performance . , avoid degenerate text , require sample modify softmax , temperature parameter ad - hoc truncation technique , - k nucleus sampling . create mismatch training testing condition . paper , use recently introduce entmax transformation train sample natively sparse language model , avoid mismatch . result text generator favorable performance term fluency consistency , few repetition , n - gram diversity close human text . order evaluate model , propose new metric compare sparse truncated distribution : -perplexity , sparsemax score , jensen - shannon divergence . human - evaluate experiment story completion dialogue generation entmax sampling lead engaging coherent story conversation .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,"Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation","AMR-to-text generation is used to transduce Abstract Meaning Representation structures (AMR) into text. A key challenge in this task is to efficiently learn effective graph representations. Previously, Graph Convolution Networks (GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to capture non-local information and additionally, they follow a local (first-order) information aggregation scheme. To account for these issues, larger and deeper GCN models are required to capture more complex interactions. In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight Dynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local interactions by synthesizing higher order information from the input graphs. We further develop two novel parameter saving strategies based on the group graph convolutions and weight tied convolutions to reduce memory usage and model complexity. With the help of these strategies, we are able to train a model with fewer parameters while maintaining the model capacity. Experiments demonstrate that LDGCNs outperform stateof-the-art models on two benchmark datasets for AMR-to-text generation with significantly fewer parameters. * * Equally Contributed. Work done while Yan Zhang was an intern at DAMO Academy, Alibaba Group and Zhijiang Guo was at the University of Edinburgh.","Lightweight, Dynamic Graph Convolutional Networks for AMR-to-Text Generation AMR-to-text generation is used to transduce Abstract Meaning Representation structures (AMR) into text. A key challenge in this task is to efficiently learn effective graph representations. Previously, Graph Convolution Networks (GCNs) were used to encode input AMRs, however, vanilla GCNs are not able to capture non-local information and additionally, they follow a local (first-order) information aggregation scheme. To account for these issues, larger and deeper GCN models are required to capture more complex interactions. In this paper, we introduce a dynamic fusion mechanism, proposing Lightweight Dynamic Graph Convolutional Networks (LDGCNs) that capture richer non-local interactions by synthesizing higher order information from the input graphs. We further develop two novel parameter saving strategies based on the group graph convolutions and weight tied convolutions to reduce memory usage and model complexity. With the help of these strategies, we are able to train a model with fewer parameters while maintaining the model capacity. Experiments demonstrate that LDGCNs outperform stateof-the-art models on two benchmark datasets for AMR-to-text generation with significantly fewer parameters. * * Equally Contributed. Work done while Yan Zhang was an intern at DAMO Academy, Alibaba Group and Zhijiang Guo was at the University of Edinburgh.","lightweight , dynamic graph convolutional networks amr - - text generation amr - - text generation transduce abstract meaning representation structure ( amr ) text . key challenge task efficiently learn effective graph representation . previously , graph convolution networks ( gcns ) encode input amr , , vanilla gcn able capture non - local information additionally , follow local ( - order ) information aggregation scheme . account issue , large deep gcn model require capture complex interaction . paper , introduce dynamic fusion mechanism , propose lightweight dynamic graph convolutional networks ( ldgcns ) capture rich non - local interaction synthesize high order information input graph . develop novel parameter save strategy base group graph convolution weight tie convolution reduce memory usage model complexity . help strategy , able train model few parameter maintain model capacity . experiment demonstrate ldgcns outperform stateof - - art model benchmark dataset amr - - text generation significantly few parameter . * * equally contribute . work yan zhang intern damo academy , alibaba group zhijiang guo university edinburgh .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Facilitating the Communication of Politeness through Fine-Grained Paraphrasing,"Aided by technology, people are increasingly able to communicate across geographical, cultural, and language barriers. This ability also results in new challenges, as interlocutors need to adapt their communication approaches to increasingly diverse circumstances. In this work, we take the first steps towards automatically assisting people in adjusting their language to a specific communication circumstance. As a case study, we focus on facilitating the accurate transmission of pragmatic intentions and introduce a methodology for suggesting paraphrases that achieve the intended level of politeness under a given communication circumstance. We demonstrate the feasibility of this approach by evaluating our method in two realistic communication scenarios and show that it can reduce the potential for misalignment between the speaker's intentions and the listener's perceptions in both cases.","Facilitating the Communication of Politeness through Fine-Grained Paraphrasing Aided by technology, people are increasingly able to communicate across geographical, cultural, and language barriers. This ability also results in new challenges, as interlocutors need to adapt their communication approaches to increasingly diverse circumstances. In this work, we take the first steps towards automatically assisting people in adjusting their language to a specific communication circumstance. As a case study, we focus on facilitating the accurate transmission of pragmatic intentions and introduce a methodology for suggesting paraphrases that achieve the intended level of politeness under a given communication circumstance. We demonstrate the feasibility of this approach by evaluating our method in two realistic communication scenarios and show that it can reduce the potential for misalignment between the speaker's intentions and the listener's perceptions in both cases.","facilitate communication politeness fine - grained paraphrasing aid technology , people increasingly able communicate geographical , cultural , language barrier . ability result new challenge , interlocutor need adapt communication approach increasingly diverse circumstance . work , step automatically assist people adjust language specific communication circumstance . case study , focus facilitate accurate transmission pragmatic intention introduce methodology suggest paraphrase achieve intended level politeness give communication circumstance . demonstrate feasibility approach evaluate method realistic communication scenario reduce potential misalignment speaker intention listener perception case .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Generation,Generating Dialogue Responses from a Semantic Latent Space,"Existing open-domain dialogue generation models are usually trained to mimic the gold response in the training set using cross-entropy loss on the vocabulary. However, a good response does not need to resemble the gold response, since there are multiple possible responses to a given prompt. In this work, we hypothesize that the current models are unable to integrate information from multiple semantically similar valid responses of a prompt, resulting in the generation of generic and uninformative responses. To address this issue, we propose an alternative to the end-to-end classification on vocabulary. We learn the pair relationship between the prompts and responses as a regression task on a latent space instead. In our novel dialog generation model, the representations of semantically related sentences are close to each other on the latent space. Human evaluation showed that learning the task on a continuous space can generate responses that are both relevant and informative.","Generating Dialogue Responses from a Semantic Latent Space Existing open-domain dialogue generation models are usually trained to mimic the gold response in the training set using cross-entropy loss on the vocabulary. However, a good response does not need to resemble the gold response, since there are multiple possible responses to a given prompt. In this work, we hypothesize that the current models are unable to integrate information from multiple semantically similar valid responses of a prompt, resulting in the generation of generic and uninformative responses. To address this issue, we propose an alternative to the end-to-end classification on vocabulary. We learn the pair relationship between the prompts and responses as a regression task on a latent space instead. In our novel dialog generation model, the representations of semantically related sentences are close to each other on the latent space. Human evaluation showed that learning the task on a continuous space can generate responses that are both relevant and informative.","generate dialogue response semantic latent space exist open - domain dialogue generation model usually train mimic gold response training set cross - entropy loss vocabulary . , good response need resemble gold response , multiple possible response give prompt . work , hypothesize current model unable integrate information multiple semantically similar valid response prompt , result generation generic uninformative response . address issue , propose alternative end - - end classification vocabulary . learn pair relationship prompt response regression task latent space instead . novel dialog generation model , representation semantically relate sentence close latent space . human evaluation show learn task continuous space generate response relevant informative .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 14, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Generation,"If beam search is the answer, what was the question?","Quite surprisingly, exact maximum a posteriori (MAP) decoding of neural language generators frequently leads to low-quality results (Stahlberg and Byrne, 2019) . Rather, most state-of-the-art results on language generation tasks are attained using beam search despite its overwhelmingly high search error rate. This implies that the MAP objective alone does not express the properties we desire in text, which merits the question: if beam search is the answer, what was the question? We frame beam search as the exact solution to a different decoding objective in order to gain insights into why high probability under a model alone may not indicate adequacy. We find that beam search enforces uniform information density in text, a property motivated by cognitive science. We suggest a set of decoding objectives that explicitly enforce this property and find that exact decoding with these objectives alleviates the problems encountered when decoding poorly calibrated language generation models. Additionally, we analyze the text produced using various decoding strategies and see that, in our neural machine translation experiments, the extent to which this property is adhered to strongly correlates with BLEU.","If beam search is the answer, what was the question? Quite surprisingly, exact maximum a posteriori (MAP) decoding of neural language generators frequently leads to low-quality results (Stahlberg and Byrne, 2019) . Rather, most state-of-the-art results on language generation tasks are attained using beam search despite its overwhelmingly high search error rate. This implies that the MAP objective alone does not express the properties we desire in text, which merits the question: if beam search is the answer, what was the question? We frame beam search as the exact solution to a different decoding objective in order to gain insights into why high probability under a model alone may not indicate adequacy. We find that beam search enforces uniform information density in text, a property motivated by cognitive science. We suggest a set of decoding objectives that explicitly enforce this property and find that exact decoding with these objectives alleviates the problems encountered when decoding poorly calibrated language generation models. Additionally, we analyze the text produced using various decoding strategies and see that, in our neural machine translation experiments, the extent to which this property is adhered to strongly correlates with BLEU.","beam search answer , question ? surprisingly , exact maximum posteriori ( map ) decoding neural language generator frequently lead low - quality result ( stahlberg byrne , 2019 ) . , state - - - art result language generation task attain beam search despite overwhelmingly high search error rate . imply map objective express property desire text , merit question : beam search answer , question ? frame beam search exact solution different decoding objective order gain insight high probability model indicate adequacy . find beam search enforce uniform information density text , property motivate cognitive science . suggest set decoding objective explicitly enforce property find exact decoding objective alleviate problem encounter decode poorly calibrate language generation model . additionally , analyze text produce decoding strategy , neural machine translation experiment , extent property adhere strongly correlate bleu .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 5, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Controllable Meaning Representation to Text Generation: Linearization and Data Augmentation Strategies,"We study the degree to which neural sequenceto-sequence models exhibit fine-grained controllability when performing natural language generation from a meaning representation. Using two task-oriented dialogue generation benchmarks, we systematically compare the effect of four input linearization strategies on controllability and faithfulness. Additionally, we evaluate how a phrase-based data augmentation method can improve performance. We find that properly aligning input sequences during training leads to highly controllable generation, both when training from scratch or when fine-tuning a larger pre-trained model. Data augmentation further improves control on difficult, randomly generated utterance plans.","Controllable Meaning Representation to Text Generation: Linearization and Data Augmentation Strategies We study the degree to which neural sequenceto-sequence models exhibit fine-grained controllability when performing natural language generation from a meaning representation. Using two task-oriented dialogue generation benchmarks, we systematically compare the effect of four input linearization strategies on controllability and faithfulness. Additionally, we evaluate how a phrase-based data augmentation method can improve performance. We find that properly aligning input sequences during training leads to highly controllable generation, both when training from scratch or when fine-tuning a larger pre-trained model. Data augmentation further improves control on difficult, randomly generated utterance plans.","controllable meaning representation text generation : linearization datum augmentation strategy study degree neural sequenceto - sequence model exhibit fine - grained controllability perform natural language generation meaning representation . task - orient dialogue generation benchmark , systematically compare effect input linearization strategy controllability faithfulness . additionally , evaluate phrase - base data augmentation method improve performance . find properly align input sequence training lead highly controllable generation , train scratch fine - tune large pre - trained model . data augmentation improve control difficult , randomly generate utterance plan .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Language Generation with Multi-Hop Reasoning on Commonsense Knowledge Graph,"Despite the success of generative pre-trained language models on a series of text generation tasks, they still suffer in cases where reasoning over underlying commonsense knowledge is required during generation. Existing approaches that integrate commonsense knowledge into generative pre-trained language models simply transfer relational knowledge by post-training on individual knowledge triples while ignoring rich connections within the knowledge graph. We argue that exploiting both the structural and semantic information of the knowledge graph facilitates commonsenseaware text generation. In this paper, we propose Generation with Multi-Hop Reasoning Flow (GRF) that enables pre-trained models with dynamic multi-hop reasoning on multirelational paths extracted from the external commonsense knowledge graph. We empirically show that our model outperforms existing baselines on three text generation tasks that require reasoning over commonsense knowledge. We also demonstrate the effectiveness of the dynamic multi-hop reasoning module with reasoning paths inferred by the model that provide rationale to the generation. 1","Language Generation with Multi-Hop Reasoning on Commonsense Knowledge Graph Despite the success of generative pre-trained language models on a series of text generation tasks, they still suffer in cases where reasoning over underlying commonsense knowledge is required during generation. Existing approaches that integrate commonsense knowledge into generative pre-trained language models simply transfer relational knowledge by post-training on individual knowledge triples while ignoring rich connections within the knowledge graph. We argue that exploiting both the structural and semantic information of the knowledge graph facilitates commonsenseaware text generation. In this paper, we propose Generation with Multi-Hop Reasoning Flow (GRF) that enables pre-trained models with dynamic multi-hop reasoning on multirelational paths extracted from the external commonsense knowledge graph. We empirically show that our model outperforms existing baselines on three text generation tasks that require reasoning over commonsense knowledge. We also demonstrate the effectiveness of the dynamic multi-hop reasoning module with reasoning paths inferred by the model that provide rationale to the generation. 1","language generation multi - hop reasoning commonsense knowledge graph despite success generative pre - trained language model series text generation task , suffer case reason underlie commonsense knowledge require generation . exist approach integrate commonsense knowledge generative pre - trained language model simply transfer relational knowledge post - train individual knowledge triple ignore rich connection knowledge graph . argue exploit structural semantic information knowledge graph facilitate commonsenseaware text generation . paper , propose generation multi - hop reasoning flow ( grf ) enable pre - train model dynamic multi - hop reasoning multirelational path extract external commonsense knowledge graph . empirically model outperform exist baseline text generation task require reasoning commonsense knowledge . demonstrate effectiveness dynamic multi - hop reasoning module reasoning path infer model provide rationale generation . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 18, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Template Guided Text Generation for Task-Oriented Dialogue,"Virtual assistants such as Google Assistant, Amazon Alexa, and Apple Siri enable users to interact with a large number of services and APIs on the web using natural language. In this work, we investigate two methods for Natural Language Generation (NLG) using a single domain-independent model across a large number of APIs. First, we propose a schemaguided approach which conditions the generation on a schema describing the API in natural language. Our second method investigates the use of a small number of templates, growing linearly in number of slots, to convey the semantics of the API. To generate utterances for an arbitrary slot combination, a few simple templates are first concatenated to give a semantically correct, but possibly incoherent and ungrammatical utterance. A pre-trained language model is subsequently employed to rewrite it into coherent, natural sounding text. Through automatic metrics and human evaluation, we show that our method improves over strong baselines, is robust to out-of-domain inputs and shows improved sample efficiency. 1","Template Guided Text Generation for Task-Oriented Dialogue Virtual assistants such as Google Assistant, Amazon Alexa, and Apple Siri enable users to interact with a large number of services and APIs on the web using natural language. In this work, we investigate two methods for Natural Language Generation (NLG) using a single domain-independent model across a large number of APIs. First, we propose a schemaguided approach which conditions the generation on a schema describing the API in natural language. Our second method investigates the use of a small number of templates, growing linearly in number of slots, to convey the semantics of the API. To generate utterances for an arbitrary slot combination, a few simple templates are first concatenated to give a semantically correct, but possibly incoherent and ungrammatical utterance. A pre-trained language model is subsequently employed to rewrite it into coherent, natural sounding text. Through automatic metrics and human evaluation, we show that our method improves over strong baselines, is robust to out-of-domain inputs and shows improved sample efficiency. 1","template guide text generation task - oriented dialogue virtual assistant google assistant , amazon alexa , apple siri enable user interact large number service api web natural language . work , investigate method natural language generation ( nlg ) single domain - independent model large number api . , propose schemaguided approach condition generation schema describe api natural language . second method investigate use small number template , grow linearly number slot , convey semantic api . generate utterance arbitrary slot combination , simple template concatenate semantically correct , possibly incoherent ungrammatical utterance . pre - trained language model subsequently employ rewrite coherent , natural sound text . automatic metric human evaluation , method improve strong baseline , robust - - domain input show improve sample efficiency . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 5, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Unsupervised Text Style Transfer with Padded Masked Language Models,"We propose MASKER, an unsupervised textediting method for style transfer. To tackle cases when no parallel source-target pairs are available, we train masked language models (MLMs) for both the source and the target domain. Then we find the text spans where the two models disagree the most in terms of likelihood. This allows us to identify the source tokens to delete to transform the source text to match the style of the target domain. The deleted tokens are replaced with the target MLM, and by using a padded MLM variant, we avoid having to predetermine the number of inserted tokens. Our experiments on sentence fusion and sentiment transfer demonstrate that MASKER performs competitively in a fully unsupervised setting. Moreover, in lowresource settings, it improves supervised methods' accuracy by over 10 percentage points when pre-training them on silver training data generated by MASKER.","Unsupervised Text Style Transfer with Padded Masked Language Models We propose MASKER, an unsupervised textediting method for style transfer. To tackle cases when no parallel source-target pairs are available, we train masked language models (MLMs) for both the source and the target domain. Then we find the text spans where the two models disagree the most in terms of likelihood. This allows us to identify the source tokens to delete to transform the source text to match the style of the target domain. The deleted tokens are replaced with the target MLM, and by using a padded MLM variant, we avoid having to predetermine the number of inserted tokens. Our experiments on sentence fusion and sentiment transfer demonstrate that MASKER performs competitively in a fully unsupervised setting. Moreover, in lowresource settings, it improves supervised methods' accuracy by over 10 percentage points when pre-training them on silver training data generated by MASKER.","unsupervised text style transfer pad mask language model propose masker , unsupervised textediting method style transfer . tackle case parallel source - target pair available , train mask language model ( mlms ) source target domain . find text span model disagree term likelihood . allow identify source token delete transform source text match style target domain . delete token replace target mlm , padded mlm variant , avoid have predetermine number insert token . experiment sentence fusion sentiment transfer demonstrate masker perform competitively fully unsupervised setting . , lowresource setting , improve supervise method ' accuracy 10 percentage point pre - train silver training datum generate masker .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation,"Systems for story generation are asked to produce plausible and enjoyable stories given an input context. This task is underspecified, as a vast number of diverse stories can originate from a single input. The large output space makes it difficult to build and evaluate story generation models, as (1) existing datasets lack rich enough contexts to meaningfully guide models, and (2) existing evaluations (both crowdsourced and automatic) are unreliable for assessing long-form creative text. To address these issues, we introduce a dataset and evaluation platform built from STORIUM, an online collaborative storytelling community. Our author-generated dataset contains 6K lengthy stories (125M tokens) with fine-grained natural language annotations (e.g., character goals and attributes) interspersed throughout each narrative, forming a robust source for guiding models. We evaluate language models fine-tuned on our dataset by integrating them onto STORIUM, where real authors can query a model for suggested story continuations and then edit them. Automatic metrics computed over these edits correlate well with both user ratings of generated stories and qualitative feedback from semi-structured user interviews. We release both the STORIUM dataset and evaluation platform to spur more principled research into story generation.","STORIUM: A Dataset and Evaluation Platform for Machine-in-the-Loop Story Generation Systems for story generation are asked to produce plausible and enjoyable stories given an input context. This task is underspecified, as a vast number of diverse stories can originate from a single input. The large output space makes it difficult to build and evaluate story generation models, as (1) existing datasets lack rich enough contexts to meaningfully guide models, and (2) existing evaluations (both crowdsourced and automatic) are unreliable for assessing long-form creative text. To address these issues, we introduce a dataset and evaluation platform built from STORIUM, an online collaborative storytelling community. Our author-generated dataset contains 6K lengthy stories (125M tokens) with fine-grained natural language annotations (e.g., character goals and attributes) interspersed throughout each narrative, forming a robust source for guiding models. We evaluate language models fine-tuned on our dataset by integrating them onto STORIUM, where real authors can query a model for suggested story continuations and then edit them. Automatic metrics computed over these edits correlate well with both user ratings of generated stories and qualitative feedback from semi-structured user interviews. We release both the STORIUM dataset and evaluation platform to spur more principled research into story generation.","storium : dataset evaluation platform machine - - - loop story generation system story generation ask produce plausible enjoyable story give input context . task underspecified , vast number diverse story originate single input . large output space make difficult build evaluate story generation model , ( 1 ) exist dataset lack rich context meaningfully guide model , ( 2 ) exist evaluation ( crowdsource automatic ) unreliable assess long - form creative text . address issue , introduce dataset evaluation platform build storium , online collaborative storytelling community . author - generate dataset contain 6 k lengthy story ( 125 m token ) fine - grained natural language annotation ( e.g. , character goal attribute ) intersperse narrative , form robust source guide model . evaluate language model fine - tune dataset integrate storium , real author query model suggest story continuation edit . automatic metric compute edit correlate user rating generate story qualitative feedback semi - structured user interview . release storium dataset evaluation platform spur principled research story generation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 21, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Reading Between the Lines: Exploring Infilling in Visual Narratives,"Generating long form narratives such as stories and procedures from multiple modalities has been a long standing dream for artificial intelligence. In this regard, there is often crucial subtext that is derived from the surrounding contexts. The general seq2seq training methods render the models shorthanded while attempting to bridge the gap between these neighbouring contexts. In this paper, we tackle this problem by using infilling techniques involving prediction of missing steps in a narrative while generating textual descriptions from a sequence of images. We also present a new large scale visual procedure telling (ViPT) dataset with a total of 46,200 procedures and around 340k pairwise images and textual descriptions that is rich in such contextual dependencies. Generating steps using infilling technique demonstrates the effectiveness in visual procedures with more coherent texts. We conclusively show a ME-TEOR score of 27.51 on procedures which is higher than the state-of-the-art on visual storytelling. We also demonstrate the effects of interposing new text with missing images during inference. The code and the dataset will be publicly available at https://visualnarratives.github.io/Visual-Narratives.","Reading Between the Lines: Exploring Infilling in Visual Narratives Generating long form narratives such as stories and procedures from multiple modalities has been a long standing dream for artificial intelligence. In this regard, there is often crucial subtext that is derived from the surrounding contexts. The general seq2seq training methods render the models shorthanded while attempting to bridge the gap between these neighbouring contexts. In this paper, we tackle this problem by using infilling techniques involving prediction of missing steps in a narrative while generating textual descriptions from a sequence of images. We also present a new large scale visual procedure telling (ViPT) dataset with a total of 46,200 procedures and around 340k pairwise images and textual descriptions that is rich in such contextual dependencies. Generating steps using infilling technique demonstrates the effectiveness in visual procedures with more coherent texts. We conclusively show a ME-TEOR score of 27.51 on procedures which is higher than the state-of-the-art on visual storytelling. We also demonstrate the effects of interposing new text with missing images during inference. The code and the dataset will be publicly available at https://visualnarratives.github.io/Visual-Narratives.","read line : explore infille visual narrative generate long form narrative story procedure multiple modality long stand dream artificial intelligence . regard , crucial subtext derive surround context . general seq2seq training method render model shorthanded attempt bridge gap neighbour context . paper , tackle problem infille technique involve prediction miss step narrative generate textual description sequence image . present new large scale visual procedure telling ( vipt ) dataset total 46,200 procedure 340k pairwise image textual description rich contextual dependency . generate step infille technique demonstrate effectiveness visual procedure coherent text . conclusively - teor score 27.51 procedure high state - - - art visual storytelling . demonstrate effect interpose new text miss image inference . code dataset publicly available https://visualnarratives.github.io/visual-narratives .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 13, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 9, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Gradient-guided Unsupervised Lexically Constrained Text Generation,"Lexically-constrained generation requires the target sentence to satisfy some lexical constraints, such as containing some specific words or being the paraphrase to a given sentence, which is very important in many real-world natural language generation applications. Previous works usually apply beamsearch-based methods or stochastic searching methods to lexically-constrained generation. However, when the search space is too large, beam-search-based methods always fail to find the constrained optimal solution. At the same time, stochastic search methods always cost too many steps to find the correct optimization direction. In this paper, we propose a novel method G2LC to solve the lexically-constrained generation as an unsupervised gradient-guided optimization problem. We propose a differentiable objective function and use the gradient to help determine which position in the sequence should be changed (deleted or inserted/replaced by another word). The word updating process of the inserted/replaced word also benefits from the guidance of gradient. Besides, our method is free of parallel data training, which is flexible to be used in the inference stage of any pre-trained generation model. We apply G2LC to two generation tasks: keyword-to-sentence generation and unsupervised paraphrase generation. The experiment results show that our method achieves state-of-the-art compared to previous lexically-constrained methods.","Gradient-guided Unsupervised Lexically Constrained Text Generation Lexically-constrained generation requires the target sentence to satisfy some lexical constraints, such as containing some specific words or being the paraphrase to a given sentence, which is very important in many real-world natural language generation applications. Previous works usually apply beamsearch-based methods or stochastic searching methods to lexically-constrained generation. However, when the search space is too large, beam-search-based methods always fail to find the constrained optimal solution. At the same time, stochastic search methods always cost too many steps to find the correct optimization direction. In this paper, we propose a novel method G2LC to solve the lexically-constrained generation as an unsupervised gradient-guided optimization problem. We propose a differentiable objective function and use the gradient to help determine which position in the sequence should be changed (deleted or inserted/replaced by another word). The word updating process of the inserted/replaced word also benefits from the guidance of gradient. Besides, our method is free of parallel data training, which is flexible to be used in the inference stage of any pre-trained generation model. We apply G2LC to two generation tasks: keyword-to-sentence generation and unsupervised paraphrase generation. The experiment results show that our method achieves state-of-the-art compared to previous lexically-constrained methods.","gradient - guide unsupervised lexically constrained text generation lexically - constrain generation require target sentence satisfy lexical constraint , contain specific word paraphrase give sentence , important real - world natural language generation application . previous work usually apply beamsearch - base method stochastic searching method lexically - constrain generation . , search space large , beam - search - base method fail find constrain optimal solution . time , stochastic search method cost step find correct optimization direction . paper , propose novel method g2lc solve lexically - constrain generation unsupervised gradient - guide optimization problem . propose differentiable objective function use gradient help determine position sequence change ( delete insert / replace word ) . word updating process insert / replace word benefit guidance gradient . , method free parallel datum training , flexible inference stage pre - trained generation model . apply g2lc generation task : keyword - - sentence generation unsupervised paraphrase generation . experiment result method achieve state - - - art compare previous lexically - constrain method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Online Back-Parsing for AMR-to-Text Generation,"AMR-to-text generation aims to recover a text containing the same meaning as an input AMR graph. Current research develops increasingly powerful graph encoders to better represent AMR graphs, with decoders based on standard language modeling being used to generate outputs. We propose a decoder that back predicts projected AMR graphs on the target sentence during text generation. As the result, our outputs can better preserve the input meaning than standard decoders. Experiments on two AMR benchmarks show the superiority of our model over the previous state-of-the-art system based on graph Transformer.","Online Back-Parsing for AMR-to-Text Generation AMR-to-text generation aims to recover a text containing the same meaning as an input AMR graph. Current research develops increasingly powerful graph encoders to better represent AMR graphs, with decoders based on standard language modeling being used to generate outputs. We propose a decoder that back predicts projected AMR graphs on the target sentence during text generation. As the result, our outputs can better preserve the input meaning than standard decoders. Experiments on two AMR benchmarks show the superiority of our model over the previous state-of-the-art system based on graph Transformer.","online - parsing amr - - text generation amr - - text generation aim recover text contain meaning input amr graph . current research develop increasingly powerful graph encoder well represent amr graph , decoder base standard language modeling generate output . propose decoder predict project amr graph target sentence text generation . result , output well preserve input meaning standard decoder . experiment amr benchmark superiority model previous state - - - art system base graph transformer .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Plan ahead: Self-Supervised Text Planning for Paragraph Completion Task,"Despite the recent success of contextualized language models on various NLP tasks, language model itself cannot capture textual coherence of a long, multi-sentence document (e.g., a paragraph). Humans often make structural decisions on what and how to say about before making utterances. Guiding surface realization with such high-level decisions and structuring text in a coherent way is essentially called a planning process. Where can the model learn such high-level coherence? A paragraph itself contains various forms of inductive coherence signals called self-supervision in this work, such as sentence orders, topical keywords, rhetorical structures, and so on. Motivated by that, this work proposes a new paragraph completion task PAR-COM; predicting masked sentences in a paragraph. However, the task suffers from predicting and selecting appropriate topical content with respect to the given context. To address that, we propose a self-supervised text planner SSPlanner that predicts what to say first (content prediction), then guides the pretrained language model (surface realization) using the predicted content. SSPlanner outperforms the baseline generation models on the paragraph completion task in both automatic and human evaluation. We also find that a combination of noun and verb types of keywords is the most effective for content selection. As more number of content keywords are provided, overall generation quality also increases.","Plan ahead: Self-Supervised Text Planning for Paragraph Completion Task Despite the recent success of contextualized language models on various NLP tasks, language model itself cannot capture textual coherence of a long, multi-sentence document (e.g., a paragraph). Humans often make structural decisions on what and how to say about before making utterances. Guiding surface realization with such high-level decisions and structuring text in a coherent way is essentially called a planning process. Where can the model learn such high-level coherence? A paragraph itself contains various forms of inductive coherence signals called self-supervision in this work, such as sentence orders, topical keywords, rhetorical structures, and so on. Motivated by that, this work proposes a new paragraph completion task PAR-COM; predicting masked sentences in a paragraph. However, the task suffers from predicting and selecting appropriate topical content with respect to the given context. To address that, we propose a self-supervised text planner SSPlanner that predicts what to say first (content prediction), then guides the pretrained language model (surface realization) using the predicted content. SSPlanner outperforms the baseline generation models on the paragraph completion task in both automatic and human evaluation. We also find that a combination of noun and verb types of keywords is the most effective for content selection. As more number of content keywords are provided, overall generation quality also increases.","plan ahead : self - supervise text planning paragraph completion task despite recent success contextualize language model nlp task , language model capture textual coherence long , multi - sentence document ( e.g. , paragraph ) . human structural decision make utterance . guide surface realization high - level decision structure text coherent way essentially call planning process . model learn high - level coherence ? paragraph contain form inductive coherence signal call self - supervision work , sentence order , topical keyword , rhetorical structure , . motivate , work propose new paragraph completion task par - com ; predict mask sentence paragraph . , task suffer predict select appropriate topical content respect give context . address , propose self - supervise text planner ssplanner predict ( content prediction ) , guide pretrained language model ( surface realization ) predict content . ssplanner outperform baseline generation model paragraph completion task automatic human evaluation . find combination noun verb type keyword effective content selection . number content keyword provide , overall generation quality increase .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 14, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Generating similes effortlessly like a Pro: A Style Transfer Approach for Simile Generation,"Literary tropes, from poetry to stories, are at the crux of human imagination and communication. Figurative language, such as a simile, goes beyond plain expressions to give readers new insights and inspirations. We tackle the problem of simile generation. Generating a simile requires proper understanding for effective mapping of properties between two concepts. To this end, we first propose a method to automatically construct a parallel corpus by transforming a large number of similes collected from Reddit to their literal counterpart using structured common sense knowledge. We then fine-tune a pretrained sequence to sequence model, BART (Lewis et al., 2019), on the literal-simile pairs to generate novel similes given a literal sentence. Experiments show that our approach generates 88% novel similes that do not share properties with the training data. Human evaluation on an independent set of literal statements shows that our model generates similes better than two literary experts 37% 1 of the times, and three baseline systems including a recent metaphor generation model 71% 2 of the times when compared pairwise. 3 We also show how replacing literal sentences with similes from our best model in machine generated stories improves evocativeness and leads to better acceptance by human judges. * The research was conducted when the author was at USC/ISI. 1 We average 32.6% and 41.3% for 2 humans. 2 We average 82% ,63% and 68% for three baselines.","Generating similes effortlessly like a Pro: A Style Transfer Approach for Simile Generation Literary tropes, from poetry to stories, are at the crux of human imagination and communication. Figurative language, such as a simile, goes beyond plain expressions to give readers new insights and inspirations. We tackle the problem of simile generation. Generating a simile requires proper understanding for effective mapping of properties between two concepts. To this end, we first propose a method to automatically construct a parallel corpus by transforming a large number of similes collected from Reddit to their literal counterpart using structured common sense knowledge. We then fine-tune a pretrained sequence to sequence model, BART (Lewis et al., 2019), on the literal-simile pairs to generate novel similes given a literal sentence. Experiments show that our approach generates 88% novel similes that do not share properties with the training data. Human evaluation on an independent set of literal statements shows that our model generates similes better than two literary experts 37% 1 of the times, and three baseline systems including a recent metaphor generation model 71% 2 of the times when compared pairwise. 3 We also show how replacing literal sentences with similes from our best model in machine generated stories improves evocativeness and leads to better acceptance by human judges. * The research was conducted when the author was at USC/ISI. 1 We average 32.6% and 41.3% for 2 humans. 2 We average 82% ,63% and 68% for three baselines.","generate simile effortlessly like pro : style transfer approach simile generation literary trope , poetry story , crux human imagination communication . figurative language , simile , go plain expression reader new insight inspiration . tackle problem simile generation . generate simile require proper understanding effective mapping property concept . end , propose method automatically construct parallel corpus transform large number simile collect reddit literal counterpart structured common sense knowledge . fine - tune pretrained sequence sequence model , bart ( lewis et al . , 2019 ) , literal - simile pair generate novel simile give literal sentence . experiment approach generate 88 % novel simile share property training datum . human evaluation independent set literal statement show model generate simile well literary expert 37 % 1 time , baseline system include recent metaphor generation model 71 % 2 time compare pairwise . 3 replace literal sentence simile good model machine generate story improve evocativeness lead well acceptance human judge . * research conduct author usc / isi . 1 average 32.6 % 41.3 % 2 human . 2 average 82 % , 63 % 68 % baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,PAIR: Planning and Iterative Refinement in Pre-trained Transformers for Long Text Generation,"Pre-trained Transformers have enabled impressive breakthroughs in generating long and fluent text, yet their outputs are often ""rambling"" without coherently arranged content. In this work, we present a novel content-controlled text generation framework, PAIR, with planning and iterative refinement, which is built upon a large model, BART. We first adapt the BERT model to automatically construct the content plans, consisting of keyphrase assignments and their corresponding sentence-level positions. The BART model is employed for generation without modifying its structure. We then propose a refinement algorithm to gradually enhance the generation quality within the sequence-tosequence framework. Evaluation with automatic metrics shows that adding planning consistently improves the generation quality on three distinct domains, with an average of 20 BLEU points and 12 METEOR points improvements. In addition, human judges rate our system outputs to be more relevant and coherent than comparisons without planning. 1 Code and data are available at: http://xinyuhua. github.io/Resources/emnlp20/ 2 https://catalog.ldc.upenn.edu/ LDC2008T19 BERT to facilitate long-form text generation. • We present a novel template mask-and-fill method to incorporate content planning into generation models based on BART. • We devise an iterative refinement algorithm that works within the seq2seq framework to flexibly improve the generation quality.","PAIR: Planning and Iterative Refinement in Pre-trained Transformers for Long Text Generation Pre-trained Transformers have enabled impressive breakthroughs in generating long and fluent text, yet their outputs are often ""rambling"" without coherently arranged content. In this work, we present a novel content-controlled text generation framework, PAIR, with planning and iterative refinement, which is built upon a large model, BART. We first adapt the BERT model to automatically construct the content plans, consisting of keyphrase assignments and their corresponding sentence-level positions. The BART model is employed for generation without modifying its structure. We then propose a refinement algorithm to gradually enhance the generation quality within the sequence-tosequence framework. Evaluation with automatic metrics shows that adding planning consistently improves the generation quality on three distinct domains, with an average of 20 BLEU points and 12 METEOR points improvements. In addition, human judges rate our system outputs to be more relevant and coherent than comparisons without planning. 1 Code and data are available at: http://xinyuhua. github.io/Resources/emnlp20/ 2 https://catalog.ldc.upenn.edu/ LDC2008T19 BERT to facilitate long-form text generation. • We present a novel template mask-and-fill method to incorporate content planning into generation models based on BART. • We devise an iterative refinement algorithm that works within the seq2seq framework to flexibly improve the generation quality.","pair : planning iterative refinement pre - trained transformer long text generation pre - trained transformer enable impressive breakthrough generate long fluent text , output "" ramble "" coherently arrange content . work , present novel content - control text generation framework , pair , planning iterative refinement , build large model , bart . adapt bert model automatically construct content plan , consist keyphrase assignment corresponding sentence - level position . bart model employ generation modify structure . propose refinement algorithm gradually enhance generation quality sequence - tosequence framework . evaluation automatic metric show add planning consistently improve generation quality distinct domain , average 20 bleu point 12 meteor point improvement . addition , human judge rate system output relevant coherent comparison planning . 1 code datum available : http://xinyuhua . github.io/resources/emnlp20/ 2 https://catalog.ldc.upenn.edu/ ldc2008t19 bert facilitate long - form text generation . • present novel template mask - - fill method incorporate content planning generation model base bart . • devise iterative refinement algorithm work seq2seq framework flexibly improve generation quality .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Reformulating Unsupervised Style Transfer as Paraphrase Generation,"Modern NLP defines the task of style transfer as modifying the style of a given sentence without appreciably changing its semantics, which implies that the outputs of style transfer systems should be paraphrases of their inputs. However, many existing systems purportedly designed for style transfer inherently warp the input's meaning through attribute transfer, which changes semantic properties such as sentiment. In this paper, we reformulate unsupervised style transfer as a paraphrase generation problem, and present a simple methodology based on fine-tuning pretrained language models on automatically generated paraphrase data. Despite its simplicity, our method significantly outperforms state-of-the-art style transfer systems on both human and automatic evaluations. We also survey 23 style transfer papers and discover that existing automatic metrics can be easily gamed and propose fixed variants. Finally, we pivot to a more real-world style transfer setting by collecting a large dataset of 15M sentences in 11 diverse styles, which we use for an in-depth analysis of our system.","Reformulating Unsupervised Style Transfer as Paraphrase Generation Modern NLP defines the task of style transfer as modifying the style of a given sentence without appreciably changing its semantics, which implies that the outputs of style transfer systems should be paraphrases of their inputs. However, many existing systems purportedly designed for style transfer inherently warp the input's meaning through attribute transfer, which changes semantic properties such as sentiment. In this paper, we reformulate unsupervised style transfer as a paraphrase generation problem, and present a simple methodology based on fine-tuning pretrained language models on automatically generated paraphrase data. Despite its simplicity, our method significantly outperforms state-of-the-art style transfer systems on both human and automatic evaluations. We also survey 23 style transfer papers and discover that existing automatic metrics can be easily gamed and propose fixed variants. Finally, we pivot to a more real-world style transfer setting by collecting a large dataset of 15M sentences in 11 diverse styles, which we use for an in-depth analysis of our system.","reformulate unsupervised style transfer paraphrase generation modern nlp define task style transfer modify style give sentence appreciably change semantic , imply output style transfer system paraphrase input . , exist system purportedly design style transfer inherently warp input meaning attribute transfer , change semantic property sentiment . paper , reformulate unsupervised style transfer paraphrase generation problem , present simple methodology base fine - tune pretrained language model automatically generate paraphrase datum . despite simplicity , method significantly outperform state - - - art style transfer system human automatic evaluation . survey 23 style transfer paper discover exist automatic metric easily game propose fix variant . finally , pivot real - world style transfer setting collect large dataset 15 m sentence 11 diverse style , use - depth analysis system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Generation,TeaForN: Teacher-Forcing with N-grams,"Sequence generation models trained with teacher-forcing suffer from issues related to exposure bias and lack of differentiability across timesteps. Our proposed method, Teacher-Forcing with N-grams (TeaForN), addresses both these problems directly, through the use of a stack of N decoders trained to decode along a secondary time axis that allows modelparameter updates based on N prediction steps. TeaForN can be used with a wide class of decoder architectures and requires minimal modifications from a standard teacher-forcing setup. Empirically, we show that TeaForN boosts generation quality on one Machine Translation benchmark, WMT 2014 English-French, and two News Summarization benchmarks, CNN/Dailymail and Gigaword.","TeaForN: Teacher-Forcing with N-grams Sequence generation models trained with teacher-forcing suffer from issues related to exposure bias and lack of differentiability across timesteps. Our proposed method, Teacher-Forcing with N-grams (TeaForN), addresses both these problems directly, through the use of a stack of N decoders trained to decode along a secondary time axis that allows modelparameter updates based on N prediction steps. TeaForN can be used with a wide class of decoder architectures and requires minimal modifications from a standard teacher-forcing setup. Empirically, we show that TeaForN boosts generation quality on one Machine Translation benchmark, WMT 2014 English-French, and two News Summarization benchmarks, CNN/Dailymail and Gigaword.","teaforn : teacher - forcing n - gram sequence generation model train teacher - forcing suffer issue relate exposure bias lack differentiability timestep . propose method , teacher - forcing n - gram ( teaforn ) , address problem directly , use stack n decoder train decode secondary time axis allow modelparameter update base n prediction step . teaforn wide class decoder architecture require minimal modification standard teacher - force setup . empirically , teaforn boost generation quality machine translation benchmark , wmt 2014 english - french , news summarization benchmark , cnn / dailymail gigaword .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Generation,Improving Text Generation with Student-Forcing Optimal Transport,"Neural language models are often trained with maximum likelihood estimation (MLE), where the next word is generated conditioned on the ground-truth word tokens. During testing, however, the model is instead conditioned on previously generated tokens, resulting in what is termed exposure bias. To reduce this gap between training and testing, we propose using optimal transport (OT) to match the sequences generated in these two modes. An extension is further proposed to improve the OT learning, based on the structural and contextual information of the text sequences. The effectiveness of the proposed method is validated on machine translation, text summarization, and text generation tasks.","Improving Text Generation with Student-Forcing Optimal Transport Neural language models are often trained with maximum likelihood estimation (MLE), where the next word is generated conditioned on the ground-truth word tokens. During testing, however, the model is instead conditioned on previously generated tokens, resulting in what is termed exposure bias. To reduce this gap between training and testing, we propose using optimal transport (OT) to match the sequences generated in these two modes. An extension is further proposed to improve the OT learning, based on the structural and contextual information of the text sequences. The effectiveness of the proposed method is validated on machine translation, text summarization, and text generation tasks.","improve text generation student - force optimal transport neural language model train maximum likelihood estimation ( mle ) , word generate condition ground - truth word token . testing , , model instead condition previously generate token , result term exposure bias . reduce gap training testing , propose optimal transport ( ot ) match sequence generate mode . extension propose improve ot learning , base structural contextual information text sequence . effectiveness propose method validate machine translation , text summarization , text generation task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 12, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Do sequence-to-sequence VAEs learn global features of sentences?,"Autoregressive language models are powerful and relatively easy to train. However, these models are usually trained without explicit conditioning labels and do not offer easy ways to control global aspects such as sentiment or topic during generation. Bowman et al. (2016) adapted the Variational Autoencoder (VAE) for natural language with the sequenceto-sequence architecture and claimed that the latent vector was able to capture such global features in an unsupervised manner. We question this claim. We measure which words benefit most from the latent information by decomposing the reconstruction loss per position in the sentence. Using this method, we find that VAEs are prone to memorizing the first words and the sentence length, producing local features of limited usefulness. To alleviate this, we investigate alternative architectures based on bag-of-words assumptions and language model pretraining. These variants learn latent variables that are more global, i.e., more predictive of topic or sentiment labels. Moreover, using reconstructions, we observe that they decrease memorization: the first word and the sentence length are not recovered as accurately than with the baselines, consequently yielding more diverse reconstructions.","Do sequence-to-sequence VAEs learn global features of sentences? Autoregressive language models are powerful and relatively easy to train. However, these models are usually trained without explicit conditioning labels and do not offer easy ways to control global aspects such as sentiment or topic during generation. Bowman et al. (2016) adapted the Variational Autoencoder (VAE) for natural language with the sequenceto-sequence architecture and claimed that the latent vector was able to capture such global features in an unsupervised manner. We question this claim. We measure which words benefit most from the latent information by decomposing the reconstruction loss per position in the sentence. Using this method, we find that VAEs are prone to memorizing the first words and the sentence length, producing local features of limited usefulness. To alleviate this, we investigate alternative architectures based on bag-of-words assumptions and language model pretraining. These variants learn latent variables that are more global, i.e., more predictive of topic or sentiment labels. Moreover, using reconstructions, we observe that they decrease memorization: the first word and the sentence length are not recovered as accurately than with the baselines, consequently yielding more diverse reconstructions.","sequence - - sequence vaes learn global feature sentence ? autoregressive language model powerful relatively easy train . , model usually train explicit conditioning label offer easy way control global aspect sentiment topic generation . bowman et al . ( 2016 ) adapt variational autoencoder ( vae ) natural language sequenceto - sequence architecture claim latent vector able capture global feature unsupervised manner . question claim . measure word benefit latent information decompose reconstruction loss position sentence . method , find vaes prone memorize word sentence length , produce local feature limited usefulness . alleviate , investigate alternative architecture base bag - - word assumption language model pretraining . variant learn latent variable global , i.e. , predictive topic sentiment label . , reconstruction , observe decrease memorization : word sentence length recover accurately baseline , consequently yield diverse reconstruction .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Generation,MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics,"Posing reading comprehension as a generation problem provides a great deal of flexibility, allowing for open-ended questions with few restrictions on possible answers. However, progress is impeded by existing generation metrics, which rely on token overlap and are agnostic to the nuances of reading comprehension. To address this, we introduce a benchmark for training and evaluating generative reading comprehension metrics: MOdeling Correctness with Human Annotations. MOCHA contains 40K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation. Using MOCHA, we train a Learned Evaluation metric for Reading Comprehension, LERC, to mimic human judgement scores. LERC outperforms baseline metrics by 10 to 36 absolute Pearson points on held-out annotations. When we evaluate robustness on minimal pairs, LERC achieves 80% accuracy, outperforming baselines by 14 to 26 absolute percentage points while leaving significant room for improvement. MOCHA presents a challenging problem for developing accurate and robust generative reading comprehension metrics. 1 * Work done while at the Allen Institute for AI and the University of Washington. 1 The dataset, code, a leaderboard, and a demo are available at https://allennlp.org/mocha.","MOCHA: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics Posing reading comprehension as a generation problem provides a great deal of flexibility, allowing for open-ended questions with few restrictions on possible answers. However, progress is impeded by existing generation metrics, which rely on token overlap and are agnostic to the nuances of reading comprehension. To address this, we introduce a benchmark for training and evaluating generative reading comprehension metrics: MOdeling Correctness with Human Annotations. MOCHA contains 40K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation. Using MOCHA, we train a Learned Evaluation metric for Reading Comprehension, LERC, to mimic human judgement scores. LERC outperforms baseline metrics by 10 to 36 absolute Pearson points on held-out annotations. When we evaluate robustness on minimal pairs, LERC achieves 80% accuracy, outperforming baselines by 14 to 26 absolute percentage points while leaving significant room for improvement. MOCHA presents a challenging problem for developing accurate and robust generative reading comprehension metrics. 1 * Work done while at the Allen Institute for AI and the University of Washington. 1 The dataset, code, a leaderboard, and a demo are available at https://allennlp.org/mocha.","mocha : dataset train evaluate generative reading comprehension metric pose reading comprehension generation problem provide great deal flexibility , allow open - ended question restriction possible answer . , progress impede exist generation metric , rely token overlap agnostic nuance reading comprehension . address , introduce benchmark train evaluate generative reading comprehension metric : modeling correctness human annotations . mocha contain 40 k human judgement score model output 6 diverse question answer dataset additional set minimal pair evaluation . mocha , train learn evaluation metric reading comprehension , lerc , mimic human judgement score . lerc outperform baseline metric 10 36 absolute pearson point hold - annotation . evaluate robustness minimal pair , lerc achieve 80 % accuracy , outperform baseline 14 26 absolute percentage point leave significant room improvement . mocha present challenging problem develop accurate robust generative reading comprehension metric . 1 * work allen institute ai university washington . 1 dataset , code , leaderboard , demo available https://allennlp.org/mocha .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 23, 'Resources and Evaluation': 9, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Generation,Content Planning for Neural Story Generation with Aristotelian Rescoring,"Long-form narrative text generated from large language models manages a fluent impersonation of human writing, but only at the local sentence level, and lacks structure or global cohesion. We posit that many of the problems of story generation can be addressed via highquality content planning, and present a system that focuses on how to learn good plot structures to guide story generation. We utilize a plot-generation language model along with an ensemble of rescoring models that each implement an aspect of good story-writing as detailed in Aristotle's Poetics. We find that stories written with our more principled plotstructure are both more relevant to a given prompt and higher quality than baselines that do not content plan, or that plan in an unprincipled way. 1 Prompt: Write the most beautiful end to the universe that you can imagine Naive Plot with Semantic Role Labelling Tags: <A1> The universe <V> end </s> </s> <A0> ent 0 <V> see <A1> ent 3 </s> </s> <V> dying <A1> ent 1 # <A0> ent 1 <V> left <A1> ent 0 </s> <A0> the last human <V> live </s> <A1> ent 6 <V> end # <A1> ent 2 <V> come </s> <A1> the last one <V> die </s> <A1> a universe of life <V> left Revised Plot with Semantic Role Labelling Tags: <A2> The light <V> filled <A2> the sky </s> </s> </s> <A2> A bright flash <V> lit </s> </s> # <V> began <A2> to grow # <A2> the stars <V> grow </s> </s> <V> began <A2> ent 0 <A2> to fade # <A2> The stars <V> fade </s> </s> <A0> ent 2 <V> looked <A2> ent 1 me </s> <V> dying <A2> star Naive Generated Story: ""You're dead. I'll be dead, and there'll always be no more of you.""* *""No, my dear. It's not true!"" -The last of the world is dead, * * ""It'll never be over. The universe will n't end. Not yet. But I'll see it, one way or another. There is no other way.""* *My last thought, the dying man left me. He told that I was the last human to live. And he told me the universe would end, and the end will come soon. That your death would be the last one to die, and the first one to be the most beautiful. * ""There is a universe of life left, my dear, and that's all there is. Generated Story (from revision): It was the end of the universe. The light filled the sky. The galaxy. All the light in all the worlds, and all the stars. A bright flash. The first light. And then a bright flash of light... then a flash of darkness. Then a bright light. A flash of blackness and then the stars began to grow. It was a bright, beautiful bright, light. And then, slowly the stars started to grow in number. There were millions and millions of stars.. But, slowly but surely, all the galaxies began to fade. Slowly, but surely. Finally, it looked at me with its eyes. One dying star. Gold Story: It slept, and dreamt of twirling lights. It cradled countless twirling lights, all dancing in their flashing ways, dancing to the sound of a faraway flute. The light was vibrant and warm and spun all around It. The tiny lights grew with the tune, and more lights came to dance within the luminescence. It was surrounded by light, all waltzing in their ways to the distant music. It, too, swirled with the swelling symphony, watching the lights. There were lights of all different sizes and shades and brightness, but each was its own, unique light. Each one was brilliant. Each one was beautiful. All dancers to the Song...","Content Planning for Neural Story Generation with Aristotelian Rescoring Long-form narrative text generated from large language models manages a fluent impersonation of human writing, but only at the local sentence level, and lacks structure or global cohesion. We posit that many of the problems of story generation can be addressed via highquality content planning, and present a system that focuses on how to learn good plot structures to guide story generation. We utilize a plot-generation language model along with an ensemble of rescoring models that each implement an aspect of good story-writing as detailed in Aristotle's Poetics. We find that stories written with our more principled plotstructure are both more relevant to a given prompt and higher quality than baselines that do not content plan, or that plan in an unprincipled way. 1 Prompt: Write the most beautiful end to the universe that you can imagine Naive Plot with Semantic Role Labelling Tags: <A1> The universe <V> end </s> </s> <A0> ent 0 <V> see <A1> ent 3 </s> </s> <V> dying <A1> ent 1 # <A0> ent 1 <V> left <A1> ent 0 </s> <A0> the last human <V> live </s> <A1> ent 6 <V> end # <A1> ent 2 <V> come </s> <A1> the last one <V> die </s> <A1> a universe of life <V> left Revised Plot with Semantic Role Labelling Tags: <A2> The light <V> filled <A2> the sky </s> </s> </s> <A2> A bright flash <V> lit </s> </s> # <V> began <A2> to grow # <A2> the stars <V> grow </s> </s> <V> began <A2> ent 0 <A2> to fade # <A2> The stars <V> fade </s> </s> <A0> ent 2 <V> looked <A2> ent 1 me </s> <V> dying <A2> star Naive Generated Story: ""You're dead. I'll be dead, and there'll always be no more of you.""* *""No, my dear. It's not true!"" -The last of the world is dead, * * ""It'll never be over. The universe will n't end. Not yet. But I'll see it, one way or another. There is no other way.""* *My last thought, the dying man left me. He told that I was the last human to live. And he told me the universe would end, and the end will come soon. That your death would be the last one to die, and the first one to be the most beautiful. * ""There is a universe of life left, my dear, and that's all there is. Generated Story (from revision): It was the end of the universe. The light filled the sky. The galaxy. All the light in all the worlds, and all the stars. A bright flash. The first light. And then a bright flash of light... then a flash of darkness. Then a bright light. A flash of blackness and then the stars began to grow. It was a bright, beautiful bright, light. And then, slowly the stars started to grow in number. There were millions and millions of stars.. But, slowly but surely, all the galaxies began to fade. Slowly, but surely. Finally, it looked at me with its eyes. One dying star. Gold Story: It slept, and dreamt of twirling lights. It cradled countless twirling lights, all dancing in their flashing ways, dancing to the sound of a faraway flute. The light was vibrant and warm and spun all around It. The tiny lights grew with the tune, and more lights came to dance within the luminescence. It was surrounded by light, all waltzing in their ways to the distant music. It, too, swirled with the swelling symphony, watching the lights. There were lights of all different sizes and shades and brightness, but each was its own, unique light. Each one was brilliant. Each one was beautiful. All dancers to the Song...","content planning neural story generation aristotelian rescoring long - form narrative text generate large language model manage fluent impersonation human writing , local sentence level , lack structure global cohesion . posit problem story generation address highquality content planning , present system focus learn good plot structure guide story generation . utilize plot - generation language model ensemble rescore model implement aspect good story - writing detail aristotle poetics . find story write principled plotstructure relevant give prompt high quality baseline content plan , plan unprincipled way . 1 prompt : write beautiful end universe imagine naive plot semantic role labelling tag : < a1 > universe < v > end < /s > < /s > < a0 > ent 0 < v > < a1 > ent 3 < /s > < /s > < v > die < a1 > ent 1 # < a0 > ent 1 < v > leave < a1 > ent 0 < /s > < a0 > human < v > live < /s > < a1 > ent 6 < v > end # < a1 > ent 2 < v > come < /s > < a1 > < v > die < /s > < a1 > universe life < v > leave revise plot semantic role labelling tag : < a2 > light < v > fill < a2 > sky < /s > < /s > < /s > < a2 > bright flash < v > light < /s > < /s > # < v > begin < a2 > grow # < a2 > star < v > grow < /s > < /s > < v > begin < a2 > ent 0 < a2 > fade # < a2 > star < v > fade < /s > < /s > < a0 > ent 2 < v > look < a2 > ent 1 < /s > < v > die < a2 > star naive generated story : "" dead . dead , . "" * * "" , dear . true ! "" -the world dead , * * "" . universe end . . , way . way . "" * * thought , die man leave . tell human live . tell universe end , end come soon . death die , beautiful . * "" universe life leave , dear , . generate story ( revision ): end universe . light fill sky . galaxy . light world , star . bright flash . light . bright flash light ... flash darkness . bright light . flash blackness star begin grow . bright , beautiful bright , light . , slowly star start grow number . million million star .. , slowly surely , galaxy begin fade . slowly , surely . finally , look eye . die star . gold story : sleep , dream twirl light . cradle countless twirl light , dance flash way , dance sound faraway flute . light vibrant warm spin . tiny light grow tune , light come dance luminescence . surround light , waltz way distant music . , , swirl swell symphony , watch light . light different size shade brightness , , unique light . brilliant . beautiful . dancer song ...","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Consistency of a Recurrent Language Model With Respect to Incomplete Decoding,"Despite strong performance on a variety of tasks, neural sequence models trained with maximum likelihood have been shown to exhibit issues such as length bias and degenerate repetition. We study the related issue of receiving infinite-length sequences from a recurrent language model when using common decoding algorithms. To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the algorithm can yield an infinite-length sequence that has zero probability under the model. We prove that commonly used incomplete decoding algorithms -greedy search, beam search, top-k sampling, and nucleus sampling -are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which address inconsistency: consistent variants of top-k and nucleus sampling, and a selfterminating recurrent language model. Empirical results show that inconsistency occurs in practice, and that the proposed methods prevent inconsistency.","Consistency of a Recurrent Language Model With Respect to Incomplete Decoding Despite strong performance on a variety of tasks, neural sequence models trained with maximum likelihood have been shown to exhibit issues such as length bias and degenerate repetition. We study the related issue of receiving infinite-length sequences from a recurrent language model when using common decoding algorithms. To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the algorithm can yield an infinite-length sequence that has zero probability under the model. We prove that commonly used incomplete decoding algorithms -greedy search, beam search, top-k sampling, and nucleus sampling -are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which address inconsistency: consistent variants of top-k and nucleus sampling, and a selfterminating recurrent language model. Empirical results show that inconsistency occurs in practice, and that the proposed methods prevent inconsistency.","consistency recurrent language model respect incomplete decoding despite strong performance variety task , neural sequence model train maximum likelihood show exhibit issue length bias degenerate repetition . study related issue receive infinite - length sequence recurrent language model common decoding algorithm . analyze issue , define inconsistency decoding algorithm , mean algorithm yield infinite - length sequence zero probability model . prove commonly incomplete decoding algorithm -greedy search , beam search , - k sampling , nucleus sampling -are inconsistent , despite fact recurrent language model train produce sequence finite length . base insight , propose remedy address inconsistency : consistent variant - k nucleus sampling , selfterminate recurrent language model . empirical result inconsistency occur practice , propose method prevent inconsistency .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Generation,ToTTo: A Controlled Table-To-Text Generation Dataset,"We present TOTTO, an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description. To obtain generated targets that are natural but also faithful to the source table, we introduce a dataset construction process where annotators directly revise existing candidate sentences from Wikipedia. We present systematic analyses of our dataset and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation. 1 * Work done during an internship at Google. 1 TOTTO is available at https://github.com/ google-research-datasets/totto.","ToTTo: A Controlled Table-To-Text Generation Dataset We present TOTTO, an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task: given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description. To obtain generated targets that are natural but also faithful to the source table, we introduce a dataset construction process where annotators directly revise existing candidate sentences from Wikipedia. We present systematic analyses of our dataset and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation. 1 * Work done during an internship at Google. 1 TOTTO is available at https://github.com/ google-research-datasets/totto.","totto : control table - - text generation dataset present totto , open - domain english table - - text dataset 120,000 training example propose control generation task : give wikipedia table set highlight table cell , produce - sentence description . obtain generate target natural faithful source table , introduce dataset construction process annotator directly revise exist candidate sentence wikipedia . present systematic analysis dataset annotation process result achieve state - - - art baseline . usually fluent , exist method hallucinate phrase support table , suggest dataset serve useful research benchmark high - precision conditional text generation . 1 * work internship google . 1 totto available https://github.com/ google - research - dataset / totto .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Augmented Natural Language for Generative Sequence Labeling,"We propose a generative framework for joint sequence labeling and sentence-level classification. Our model performs multiple sequence labeling tasks at once using a single, shared natural language output space. Unlike prior discriminative methods, our model naturally incorporates label semantics and shares knowledge across tasks. Our framework is general purpose, performing well on fewshot, low-resource, and high-resource tasks. We demonstrate these advantages on popular named entity recognition, slot labeling, and intent classification benchmarks. We set a new state-of-the-art for few-shot slot labeling, improving substantially upon the previous 5-shot (75.0% ! 90.9%) and 1-shot (70.4% ! 81.0%) state-of-the-art results. Furthermore, our model generates large improvements (46.27% ! 63.83%) in low-resource slot labeling over a BERT baseline by incorporating label semantics. We also maintain competitive results on high-resource tasks, performing within two points of the state-of-theart on all tasks and setting a new state-of-theart on the SNIPS dataset.","Augmented Natural Language for Generative Sequence Labeling We propose a generative framework for joint sequence labeling and sentence-level classification. Our model performs multiple sequence labeling tasks at once using a single, shared natural language output space. Unlike prior discriminative methods, our model naturally incorporates label semantics and shares knowledge across tasks. Our framework is general purpose, performing well on fewshot, low-resource, and high-resource tasks. We demonstrate these advantages on popular named entity recognition, slot labeling, and intent classification benchmarks. We set a new state-of-the-art for few-shot slot labeling, improving substantially upon the previous 5-shot (75.0% ! 90.9%) and 1-shot (70.4% ! 81.0%) state-of-the-art results. Furthermore, our model generates large improvements (46.27% ! 63.83%) in low-resource slot labeling over a BERT baseline by incorporating label semantics. We also maintain competitive results on high-resource tasks, performing within two points of the state-of-theart on all tasks and setting a new state-of-theart on the SNIPS dataset.","augmented natural language generative sequence labeling propose generative framework joint sequence labeling sentence - level classification . model perform multiple sequence labeling task single , share natural language output space . unlike prior discriminative method , model naturally incorporate label semantic share knowledge task . framework general purpose , perform fewshot , low - resource , high - resource task . demonstrate advantage popular name entity recognition , slot labeling , intent classification benchmark . set new state - - - art - shot slot labeling , improve substantially previous 5 - shot ( 75.0 % ! 90.9 % ) 1 - shot ( 70.4 % ! 81.0 % ) state - - - art result . furthermore , model generate large improvement ( 46.27 % ! 63.83 % ) low - resource slot labeling bert baseline incorporate label semantic . maintain competitive result high - resource task , perform point state - - theart task set new state - - theart snips dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Generation,Acrostic Poem Generation,"We propose a new task in the area of computational creativity: acrostic poem generation in English. Acrostic poems are poems that contain a hidden message; typically, the first letter of each line spells out a word or short phrase. We define the task as a generation task with multiple constraints: given an input word, 1) the initial letters of each line should spell out the provided word, 2) the poem's semantics should also relate to it, and 3) the poem should conform to a rhyming scheme. We further provide a baseline model for the task, which consists of a conditional neural language model in combination with a neural rhyming model. Since no dedicated datasets for acrostic poem generation exist, we create training data for our task by first training a separate topic prediction model on a small set of topic-annotated poems and then predicting topics for additional poems. Our experiments show that the acrostic poems generated by our baseline are received well by humans and do not lose much quality due to the additional constraints. Last, we confirm that poems generated by our model are indeed closely related to the provided prompts, and that pretraining on Wikipedia can boost performance.","Acrostic Poem Generation We propose a new task in the area of computational creativity: acrostic poem generation in English. Acrostic poems are poems that contain a hidden message; typically, the first letter of each line spells out a word or short phrase. We define the task as a generation task with multiple constraints: given an input word, 1) the initial letters of each line should spell out the provided word, 2) the poem's semantics should also relate to it, and 3) the poem should conform to a rhyming scheme. We further provide a baseline model for the task, which consists of a conditional neural language model in combination with a neural rhyming model. Since no dedicated datasets for acrostic poem generation exist, we create training data for our task by first training a separate topic prediction model on a small set of topic-annotated poems and then predicting topics for additional poems. Our experiments show that the acrostic poems generated by our baseline are received well by humans and do not lose much quality due to the additional constraints. Last, we confirm that poems generated by our model are indeed closely related to the provided prompts, and that pretraining on Wikipedia can boost performance.","acrostic poem generation propose new task area computational creativity : acrostic poem generation english . acrostic poem poem contain hide message ; typically , letter line spell word short phrase . define task generation task multiple constraint : give input word , 1 ) initial letter line spell provide word , 2 ) poem semantic relate , 3 ) poem conform rhyming scheme . provide baseline model task , consist conditional neural language model combination neural rhyming model . dedicated dataset acrostic poem generation exist , create training datum task train separate topic prediction model small set topic - annotate poem predict topic additional poem . experiment acrostic poem generate baseline receive human lose quality additional constraint . , confirm poem generate model closely relate provide prompt , pretraine wikipedia boost performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Homophonic Pun Generation with Lexically Constrained Rewriting,"Punning is a creative way to make conversation enjoyable and literary writing elegant. In this paper, we focus on the task of generating a pun sentence given a pair of homophones. We first find the constraint words supporting the semantic incongruity for a sentence. Then we rewrite the sentence with explicit positive and negative constraints. Our model achieves the state-of-the-art results in both automatic and human evaluations. We further make an error analysis and discuss the challenges for the computational pun models.","Homophonic Pun Generation with Lexically Constrained Rewriting Punning is a creative way to make conversation enjoyable and literary writing elegant. In this paper, we focus on the task of generating a pun sentence given a pair of homophones. We first find the constraint words supporting the semantic incongruity for a sentence. Then we rewrite the sentence with explicit positive and negative constraints. Our model achieves the state-of-the-art results in both automatic and human evaluations. We further make an error analysis and discuss the challenges for the computational pun models.","homophonic pun generation lexically constrain rewriting punning creative way conversation enjoyable literary writing elegant . paper , focus task generate pun sentence give pair homophone . find constraint word support semantic incongruity sentence . rewrite sentence explicit positive negative constraint . model achieve state - - - art result automatic human evaluation . error analysis discuss challenge computational pun model .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Zero-Shot Crosslingual Sentence Simplification,"Sentence simplification aims to make sentences easier to read and understand. Recent approaches have shown promising results with encoder-decoder models trained on large amounts of parallel data which often only exists in English. We propose a zero-shot modeling framework which transfers simplification knowledge from English to another language (for which no parallel simplification corpus exists) while generalizing across languages and tasks. A shared transformer encoder constructs language-agnostic representations, with a combination of task-specific encoder layers added on top (e.g., for translation and simplification). Empirical results using both human and automatic metrics show that our approach produces better simplifications than unsupervised and pivot-based methods.","Zero-Shot Crosslingual Sentence Simplification Sentence simplification aims to make sentences easier to read and understand. Recent approaches have shown promising results with encoder-decoder models trained on large amounts of parallel data which often only exists in English. We propose a zero-shot modeling framework which transfers simplification knowledge from English to another language (for which no parallel simplification corpus exists) while generalizing across languages and tasks. A shared transformer encoder constructs language-agnostic representations, with a combination of task-specific encoder layers added on top (e.g., for translation and simplification). Empirical results using both human and automatic metrics show that our approach produces better simplifications than unsupervised and pivot-based methods.","zero - shot crosslingual sentence simplification sentence simplification aim sentence easy read understand . recent approach show promising result encoder - decoder model train large amount parallel datum exist english . propose zero - shot modeling framework transfer simplification knowledge english language ( parallel simplification corpus exist ) generalize language task . shared transformer encoder construct language - agnostic representation , combination task - specific encoder layer add ( e.g. , translation simplification ) . empirical result human automatic metric approach produce well simplification unsupervised pivot - base method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Generation,Blank Language Models,"We propose Blank Language Model (BLM), a model that generates sequences by dynamically creating and filling in blanks. The blanks control which part of the sequence to expand, making BLM ideal for a variety of text editing and rewriting tasks. The model can start from a single blank or partially completed text with blanks at specified locations. It iteratively determines which word to place in a blank and whether to insert new blanks, and stops generating when no blanks are left to fill. BLM can be efficiently trained using a lower bound of the marginal data likelihood. On the task of filling missing text snippets, BLM significantly outperforms all other baselines in terms of both accuracy and fluency. Experiments on style transfer and damaged ancient text restoration demonstrate the potential of this framework for a wide range of applications. 1","Blank Language Models We propose Blank Language Model (BLM), a model that generates sequences by dynamically creating and filling in blanks. The blanks control which part of the sequence to expand, making BLM ideal for a variety of text editing and rewriting tasks. The model can start from a single blank or partially completed text with blanks at specified locations. It iteratively determines which word to place in a blank and whether to insert new blanks, and stops generating when no blanks are left to fill. BLM can be efficiently trained using a lower bound of the marginal data likelihood. On the task of filling missing text snippets, BLM significantly outperforms all other baselines in terms of both accuracy and fluency. Experiments on style transfer and damaged ancient text restoration demonstrate the potential of this framework for a wide range of applications. 1","blank language models propose blank language model ( blm ) , model generate sequence dynamically create fill blank . blank control sequence expand , make blm ideal variety text editing rewriting task . model start single blank partially complete text blank specify location . iteratively determine word place blank insert new blank , stop generate blank leave fill . blm efficiently train low bound marginal data likelihood . task fill miss text snippet , blm significantly outperform baseline term accuracy fluency . experiment style transfer damage ancient text restoration demonstrate potential framework wide range application . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Multilingual AMR-to-Text Generation,"Generating text from structured data is challenging because it requires bridging the gap between (i) structure and natural language (NL) and (ii) semantically underspecified input and fully specified NL output. Multilingual generation brings in an additional challenge: that of generating into languages with varied word order and morphological properties. In this work, we focus on Abstract Meaning Representations (AMRs) as structured input, where previous research has overwhelmingly focused on generating only into English. We leverage advances in cross-lingual embeddings, pretraining, and multilingual models to create multilingual AMR-to-text models that generate in twenty one different languages. For eighteen languages, based on automatic metrics, our multilingual models surpass baselines that generate into a single language. We analyse the ability of our multilingual models to accurately capture morphology and word order using human evaluation, and find that native speakers judge our generations to be fluent.","Multilingual AMR-to-Text Generation Generating text from structured data is challenging because it requires bridging the gap between (i) structure and natural language (NL) and (ii) semantically underspecified input and fully specified NL output. Multilingual generation brings in an additional challenge: that of generating into languages with varied word order and morphological properties. In this work, we focus on Abstract Meaning Representations (AMRs) as structured input, where previous research has overwhelmingly focused on generating only into English. We leverage advances in cross-lingual embeddings, pretraining, and multilingual models to create multilingual AMR-to-text models that generate in twenty one different languages. For eighteen languages, based on automatic metrics, our multilingual models surpass baselines that generate into a single language. We analyse the ability of our multilingual models to accurately capture morphology and word order using human evaluation, and find that native speakers judge our generations to be fluent.","multilingual amr - - text generation generate text structure datum challenging require bridge gap ( ) structure natural language ( nl ) ( ii ) semantically underspecified input fully specify nl output . multilingual generation bring additional challenge : generate language varied word order morphological property . work , focus abstract meaning representation ( amrs ) structure input , previous research overwhelmingly focus generate english . leverage advance cross - lingual embedding , pretraining , multilingual model create multilingual amr - - text model generate different language . eighteen language , base automatic metric , multilingual model surpass baseline generate single language . analyse ability multilingual model accurately capture morphology word order human evaluation , find native speaker judge generation fluent .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Generation,True
Generation,POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training,"Large-scale pre-trained language models, such as BERT and GPT-2, have achieved excellent performance in language representation learning and free-form text generation. However, these models cannot be directly employed to generate text under specified lexical constraints. To address this challenge, we present POINTER 1 , a simple yet novel insertion-based approach for hard-constrained text generation. The proposed method operates by progressively inserting new tokens between existing tokens in a parallel manner. This procedure is recursively applied until a sequence is completed. The resulting coarse-to-fine hierarchy makes the generation process intuitive and interpretable. We pre-train our model with the proposed progressive insertion-based objective on a 12GB Wikipedia dataset, and finetune it on downstream hard-constrained generation tasks. Non-autoregressive decoding yields an empirically logarithmic time complexity during inference time. Experimental results on both News and Yelp datasets demonstrate that POINTER achieves state-of-the-art performance on constrained text generation. We released the pre-trained models and the source code to facilitate future research 2 .","POINTER: Constrained Progressive Text Generation via Insertion-based Generative Pre-training Large-scale pre-trained language models, such as BERT and GPT-2, have achieved excellent performance in language representation learning and free-form text generation. However, these models cannot be directly employed to generate text under specified lexical constraints. To address this challenge, we present POINTER 1 , a simple yet novel insertion-based approach for hard-constrained text generation. The proposed method operates by progressively inserting new tokens between existing tokens in a parallel manner. This procedure is recursively applied until a sequence is completed. The resulting coarse-to-fine hierarchy makes the generation process intuitive and interpretable. We pre-train our model with the proposed progressive insertion-based objective on a 12GB Wikipedia dataset, and finetune it on downstream hard-constrained generation tasks. Non-autoregressive decoding yields an empirically logarithmic time complexity during inference time. Experimental results on both News and Yelp datasets demonstrate that POINTER achieves state-of-the-art performance on constrained text generation. We released the pre-trained models and the source code to facilitate future research 2 .","pointer : constrain progressive text generation insertion - base generative pre - training large - scale pre - trained language model , bert gpt-2 , achieve excellent performance language representation learning free - form text generation . , model directly employ generate text specify lexical constraint . address challenge , present pointer 1 , simple novel insertion - base approach hard - constrain text generation . propose method operate progressively insert new token exist token parallel manner . procedure recursively apply sequence complete . resulting coarse - - fine hierarchy make generation process intuitive interpretable . pre - train model propose progressive insertion - base objective 12 gb wikipedia dataset , finetune downstream hard - constrained generation task . non - autoregressive decoding yield empirically logarithmic time complexity inference time . experimental result news yelp dataset demonstrate pointer achieve state - - - art performance constrain text generation . release pre - trained model source code facilitate future research 2 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Generation,True
Generation,CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial Text Generation,"NLP models are shown to suffer from robustness issues, i.e., a model's prediction can be easily changed under small perturbations to the input. In this work, we present a Controlled Adversarial Text Generation (CAT-Gen) model that, given an input text, generates adversarial texts through controllable attributes that are known to be irrelevant to task labels. For example, in order to attack a model for sentiment classification over product reviews, we can use the product categories as the controllable attribute which should not change the sentiment of the reviews. Experiments on real-world NLP datasets demonstrate that our method can generate more diverse and fluent adversarial texts, compared to many existing adversarial text generation approaches. We further use our generated adversarial examples to improve models through adversarial training, and we demonstrate that our generated attacks are more robust against model retraining and different model architectures.","CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial Text Generation NLP models are shown to suffer from robustness issues, i.e., a model's prediction can be easily changed under small perturbations to the input. In this work, we present a Controlled Adversarial Text Generation (CAT-Gen) model that, given an input text, generates adversarial texts through controllable attributes that are known to be irrelevant to task labels. For example, in order to attack a model for sentiment classification over product reviews, we can use the product categories as the controllable attribute which should not change the sentiment of the reviews. Experiments on real-world NLP datasets demonstrate that our method can generate more diverse and fluent adversarial texts, compared to many existing adversarial text generation approaches. We further use our generated adversarial examples to improve models through adversarial training, and we demonstrate that our generated attacks are more robust against model retraining and different model architectures.","cat - gen : improve robustness nlp model controlled adversarial text generation nlp model show suffer robustness issue , i.e. , model prediction easily change small perturbation input . work , present controlled adversarial text generation ( cat - gen ) model , give input text , generate adversarial text controllable attribute know irrelevant task label . example , order attack model sentiment classification product review , use product category controllable attribute change sentiment review . experiment real - world nlp dataset demonstrate method generate diverse fluent adversarial text , compare exist adversarial text generation approach . use generate adversarial example improve model adversarial training , demonstrate generate attack robust model retraining different model architecture .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,ENT-DESC: Entity Description Generation by Exploring Knowledge Graph,"Previous works on knowledge-to-text generation take as input a few RDF triples or keyvalue pairs conveying the knowledge of some entities to generate a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and E2E, basically have a good alignment between an input triple/pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of information loss and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original graph information more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture. 1 * Liying Cheng is under the Joint Ph.D. Program between Alibaba and Singapore University of Technology and Design. † Dekun Wu was a visiting student at SUTD. Yan Zhang and Zhanming Jie were interns at Alibaba. 1 Our code and data are available at https://github.com/LiyingCheng95/ EntityDescriptionGeneration.","ENT-DESC: Entity Description Generation by Exploring Knowledge Graph Previous works on knowledge-to-text generation take as input a few RDF triples or keyvalue pairs conveying the knowledge of some entities to generate a natural language description. Existing datasets, such as WIKIBIO, WebNLG, and E2E, basically have a good alignment between an input triple/pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of information loss and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original graph information more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture. 1 * Liying Cheng is under the Joint Ph.D. Program between Alibaba and Singapore University of Technology and Design. † Dekun Wu was a visiting student at SUTD. Yan Zhang and Zhanming Jie were interns at Alibaba. 1 Our code and data are available at https://github.com/LiyingCheng95/ EntityDescriptionGeneration.","ent - desc : entity description generation explore knowledge graph previous work knowledge - - text generation input rdf triple keyvalue pair convey knowledge entity generate natural language description . exist dataset , wikibio , webnlg , e2e , basically good alignment input triple / pair set output text . , practice , input knowledge , output description cover significant knowledge . paper , introduce large - scale challenging dataset facilitate study practical scenario kg - - text . dataset involve retrieve abundant knowledge type main entity large knowledge graph ( kg ) , make current graph - - sequence model severely suffer problem information loss parameter explosion generate description . address challenge propose multi - graph structure able represent original graph information comprehensively . furthermore , incorporate aggregation method learn extract rich graph information . extensive experiment demonstrate effectiveness model architecture . 1 * liying cheng joint ph.d. program alibaba singapore university technology design . † dekun wu visit student sutd . yan zhang zhanming jie intern alibaba . 1 code datum available https://github.com/liyingcheng95/ entitydescriptiongeneration .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Partially-Aligned Data-to-Text Generation with Distant Supervision,"The Data-to-Text task aims to generate humanreadable text for describing some given structured data enabling more interpretability. However, the typical generation task is confined to a few particular domains since it requires wellaligned data which is difficult and expensive to obtain. Using partially-aligned data is an alternative way of solving the dataset scarcity problem. This kind of data is much easier to obtain since it can be produced automatically. However, using this kind of data induces the over-generation problem posing difficulties for existing models, which tends to add unrelated excerpts during the generation procedure. In order to effectively utilize automatically annotated partially-aligned datasets, we extend the traditional generation task to a refined task called Partially-Aligned Data-to-Text Generation (PADTG) which is more practical since it utilizes automatically annotated data for training and thus considerably expands the application domains. To tackle this new task, we propose a novel distant supervision generation framework. It firstly estimates the input data's supportiveness for each target word with an estimator and then applies a supportiveness adaptor and a rebalanced beam search to harness the over-generation problem in the training and generation phases respectively. We also contribute a partially-aligned dataset 1 by sampling sentences from Wikipedia and automatically extracting corresponding KB triples for each sentence from Wikidata. The experimental results show that our framework outperforms all baseline models as well as verify the feasibility of utilizing partially-aligned data.","Partially-Aligned Data-to-Text Generation with Distant Supervision The Data-to-Text task aims to generate humanreadable text for describing some given structured data enabling more interpretability. However, the typical generation task is confined to a few particular domains since it requires wellaligned data which is difficult and expensive to obtain. Using partially-aligned data is an alternative way of solving the dataset scarcity problem. This kind of data is much easier to obtain since it can be produced automatically. However, using this kind of data induces the over-generation problem posing difficulties for existing models, which tends to add unrelated excerpts during the generation procedure. In order to effectively utilize automatically annotated partially-aligned datasets, we extend the traditional generation task to a refined task called Partially-Aligned Data-to-Text Generation (PADTG) which is more practical since it utilizes automatically annotated data for training and thus considerably expands the application domains. To tackle this new task, we propose a novel distant supervision generation framework. It firstly estimates the input data's supportiveness for each target word with an estimator and then applies a supportiveness adaptor and a rebalanced beam search to harness the over-generation problem in the training and generation phases respectively. We also contribute a partially-aligned dataset 1 by sampling sentences from Wikipedia and automatically extracting corresponding KB triples for each sentence from Wikidata. The experimental results show that our framework outperforms all baseline models as well as verify the feasibility of utilizing partially-aligned data.","partially - align data - - text generation distant supervision data - - text task aim generate humanreadable text describe give structure datum enable interpretability . , typical generation task confine particular domain require wellaligned data difficult expensive obtain . partially - align datum alternative way solve dataset scarcity problem . kind datum easy obtain produce automatically . , kind datum induce - generation problem pose difficulty exist model , tend add unrelated excerpt generation procedure . order effectively utilize automatically annotate partially - align dataset , extend traditional generation task refined task call partially - aligned data - - text generation ( padtg ) practical utilize automatically annotate datum training considerably expand application domain . tackle new task , propose novel distant supervision generation framework . firstly estimate input data supportiveness target word estimator apply supportiveness adaptor rebalance beam search harness - generation problem training generation phase respectively . contribute partially - align dataset 1 sample sentence wikipedia automatically extract correspond kb triple sentence wikidata . experimental result framework outperform baseline model verify feasibility utilize partially - align datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 16, 'Information Extraction': 10, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
"Language Grounding to Vision, Robotics and Beyond",Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding,"We introduce Room-Across-Room (RxR), a new Vision-and-Language Navigation (VLN) dataset. RxR is multilingual (English, Hindi, and Telugu) and larger (more paths and instructions) than other VLN datasets. It emphasizes the role of language in VLN by addressing known biases in paths and eliciting more references to visible entities. Furthermore, each word in an instruction is time-aligned to the virtual poses of instruction creators and validators. We establish baseline scores for monolingual and multilingual settings and multitask learning when including Room-to-Room annotations (Anderson et al., 2018b). We also provide results for a model that learns from synchronized pose traces by focusing only on portions of the panorama attended to in human demonstrations. The size, scope and detail of RxR dramatically expands the frontier for research on embodied language agents in simulated, photo-realistic environments.","Room-Across-Room: Multilingual Vision-and-Language Navigation with Dense Spatiotemporal Grounding We introduce Room-Across-Room (RxR), a new Vision-and-Language Navigation (VLN) dataset. RxR is multilingual (English, Hindi, and Telugu) and larger (more paths and instructions) than other VLN datasets. It emphasizes the role of language in VLN by addressing known biases in paths and eliciting more references to visible entities. Furthermore, each word in an instruction is time-aligned to the virtual poses of instruction creators and validators. We establish baseline scores for monolingual and multilingual settings and multitask learning when including Room-to-Room annotations (Anderson et al., 2018b). We also provide results for a model that learns from synchronized pose traces by focusing only on portions of the panorama attended to in human demonstrations. The size, scope and detail of RxR dramatically expands the frontier for research on embodied language agents in simulated, photo-realistic environments.","room - - room : multilingual vision - - language navigation dense spatiotemporal grounding introduce room - - room ( rxr ) , new vision - - language navigation ( vln ) dataset . rxr multilingual ( english , hindi , telugu ) large ( path instruction ) vln dataset . emphasize role language vln address know bias path elicit reference visible entity . furthermore , word instruction time - align virtual pose instruction creator validator . establish baseline score monolingual multilingual setting multitask learning include room - - room annotation ( anderson et al . , 2018b ) . provide result model learn synchronize pose trace focus portion panorama attend human demonstration . size , scope detail rxr dramatically expand frontier research embody language agent simulate , photo - realistic environment .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
"Language Grounding to Vision, Robotics and Beyond",SSCR: Iterative Language-Based Image Editing via Self-Supervised Counterfactual Reasoning,"Iterative Language-Based Image Editing (IL-BIE) tasks follow iterative instructions to edit images step by step. Data scarcity is a significant issue for ILBIE as it is challenging to collect large-scale examples of images before and after instruction-based changes. However, humans still accomplish these editing tasks even when presented with an unfamiliar image-instruction pair. Such ability results from counterfactual thinking and the ability to think about alternatives to events that have happened already. In this paper, we introduce a Self-Supervised Counterfactual Reasoning (SSCR) framework that incorporates counterfactual thinking to overcome data scarcity. SSCR allows the model to consider out-ofdistribution instructions paired with previous images. With the help of cross-task consistency (CTC), we train these counterfactual instructions in a self-supervised scenario. Extensive results show that SSCR improves the correctness of ILBIE in terms of both object identity and position, establishing a new state of the art (SOTA) on two IBLIE datasets (i-CLEVR and CoDraw). Even with only 50% of the training data, SSCR achieves a comparable result to using complete data.","SSCR: Iterative Language-Based Image Editing via Self-Supervised Counterfactual Reasoning Iterative Language-Based Image Editing (IL-BIE) tasks follow iterative instructions to edit images step by step. Data scarcity is a significant issue for ILBIE as it is challenging to collect large-scale examples of images before and after instruction-based changes. However, humans still accomplish these editing tasks even when presented with an unfamiliar image-instruction pair. Such ability results from counterfactual thinking and the ability to think about alternatives to events that have happened already. In this paper, we introduce a Self-Supervised Counterfactual Reasoning (SSCR) framework that incorporates counterfactual thinking to overcome data scarcity. SSCR allows the model to consider out-ofdistribution instructions paired with previous images. With the help of cross-task consistency (CTC), we train these counterfactual instructions in a self-supervised scenario. Extensive results show that SSCR improves the correctness of ILBIE in terms of both object identity and position, establishing a new state of the art (SOTA) on two IBLIE datasets (i-CLEVR and CoDraw). Even with only 50% of the training data, SSCR achieves a comparable result to using complete data.","sscr : iterative language - base image editing self - supervised counterfactual reasoning iterative language - based image editing ( il - bie ) task follow iterative instruction edit image step step . datum scarcity significant issue ilbie challenge collect large - scale example image instruction - base change . , human accomplish editing task present unfamiliar image - instruction pair . ability result counterfactual thinking ability think alternative event happen . paper , introduce self - supervised counterfactual reasoning ( sscr ) framework incorporate counterfactual thinking overcome datum scarcity . sscr allow model consider - ofdistribution instruction pair previous image . help cross - task consistency ( ctc ) , train counterfactual instruction self - supervise scenario . extensive result sscr improve correctness ilbie term object identity position , establish new state art ( sota ) iblie dataset ( - clevr codraw ) . 50 % training datum , sscr achieve comparable result complete datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 12, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering,"In the task of Visual Question Answering (VQA), most state-of-the-art models tend to learn spurious correlations in the training set and achieve poor performance in out-ofdistribution test data. Some methods of generating counterfactual samples have been proposed to alleviate this problem. However, the counterfactual samples generated by most previous methods are simply added to the training data for augmentation and are not fully utilized. Therefore, we introduce a novel selfsupervised contrastive learning mechanism to learn the relationship between original samples, factual samples and counterfactual samples. With the better cross-modal joint embeddings learned from the auxiliary training objective, the reasoning capability and robustness of the VQA model are boosted significantly. We evaluate the effectiveness of our method by surpassing current state-of-the-art models on the VQA-CP dataset, a diagnostic benchmark for assessing the VQA model's robustness.","Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering In the task of Visual Question Answering (VQA), most state-of-the-art models tend to learn spurious correlations in the training set and achieve poor performance in out-ofdistribution test data. Some methods of generating counterfactual samples have been proposed to alleviate this problem. However, the counterfactual samples generated by most previous methods are simply added to the training data for augmentation and are not fully utilized. Therefore, we introduce a novel selfsupervised contrastive learning mechanism to learn the relationship between original samples, factual samples and counterfactual samples. With the better cross-modal joint embeddings learned from the auxiliary training objective, the reasoning capability and robustness of the VQA model are boosted significantly. We evaluate the effectiveness of our method by surpassing current state-of-the-art models on the VQA-CP dataset, a diagnostic benchmark for assessing the VQA model's robustness.","learn contrast counterfactual sample robust visual question answering task visual question answering ( vqa ) , state - - - art model tend learn spurious correlation training set achieve poor performance - ofdistribution test datum . method generate counterfactual sample propose alleviate problem . , counterfactual sample generate previous method simply add training datum augmentation fully utilize . , introduce novel selfsupervised contrastive learning mechanism learn relationship original sample , factual sample counterfactual sample . well cross - modal joint embedding learn auxiliary training objective , reason capability robustness vqa model boost significantly . evaluate effectiveness method surpass current state - - - art model vqa - cp dataset , diagnostic benchmark assess vqa model robustness .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 14, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",Beyond Instructional Videos: Probing for More Diverse Visual-Textual Grounding on YouTube,"Pretraining from unlabelled web videos has quickly become the de-facto means of achieving high performance on many video understanding tasks. Features are learned via prediction of grounded relationships between visual content and automatic speech recognition (ASR) tokens. However, prior pretraining work has been limited to only instructional videos; a priori, we expect this domain to be relatively ""easy:"" speakers in instructional videos will often reference the literal objects/actions being depicted. We ask: can similar models be trained on more diverse video corpora? And, if so, what types of videos are ""grounded"" and what types are not? We fit a representative pretraining model to the diverse YouTube8M dataset, and study its success and failure cases. We find that visualtextual grounding is indeed possible across previously unexplored video categories, and that pretraining on a more diverse set results in representations that generalize to both noninstructional and instructional domains.","Beyond Instructional Videos: Probing for More Diverse Visual-Textual Grounding on YouTube Pretraining from unlabelled web videos has quickly become the de-facto means of achieving high performance on many video understanding tasks. Features are learned via prediction of grounded relationships between visual content and automatic speech recognition (ASR) tokens. However, prior pretraining work has been limited to only instructional videos; a priori, we expect this domain to be relatively ""easy:"" speakers in instructional videos will often reference the literal objects/actions being depicted. We ask: can similar models be trained on more diverse video corpora? And, if so, what types of videos are ""grounded"" and what types are not? We fit a representative pretraining model to the diverse YouTube8M dataset, and study its success and failure cases. We find that visualtextual grounding is indeed possible across previously unexplored video categories, and that pretraining on a more diverse set results in representations that generalize to both noninstructional and instructional domains.","instructional video : probe diverse visual - textual grounding youtube pretraine unlabelled web video quickly de - facto means achieve high performance video understanding task . feature learn prediction ground relationship visual content automatic speech recognition ( asr ) token . , prior pretraine work limit instructional video ; priori , expect domain relatively "" easy : "" speaker instructional video reference literal object / action depict . ask : similar model train diverse video corpus ? , , type video "" ground "" type ? fit representative pretraine model diverse youtube8 m dataset , study success failure case . find visualtextual grounding possible previously unexplored video category , pretraine diverse set result representation generalize noninstructional instructional domain .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 18, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Visually Grounded Continual Learning of Compositional Phrases,"Humans acquire language continually with much more limited access to data samples at a time, as compared to contemporary NLP systems. To study this human-like language acquisition ability, we present VisCOLL, a visually grounded language learning task, which simulates the continual acquisition of compositional phrases from streaming visual scenes. In the task, models are trained on a paired image-caption stream which has shifting object distribution; while being constantly evaluated by a visually-grounded masked language prediction task on held-out test sets. VisCOLL compounds the challenges of continual learning (i.e., learning from continuously shifting data distribution) and compositional generalization (i.e., generalizing to novel compositions). To facilitate research on VisCOLL, we construct two datasets, COCO-shift and Flickrshift, and benchmark them using different continual learning methods. Results reveal that SoTA continual learning approaches provide little to no improvements on VisCOLL, since storing examples of all possible compositions is infeasible. We conduct further ablations and analysis to guide future work 1 .","Visually Grounded Continual Learning of Compositional Phrases Humans acquire language continually with much more limited access to data samples at a time, as compared to contemporary NLP systems. To study this human-like language acquisition ability, we present VisCOLL, a visually grounded language learning task, which simulates the continual acquisition of compositional phrases from streaming visual scenes. In the task, models are trained on a paired image-caption stream which has shifting object distribution; while being constantly evaluated by a visually-grounded masked language prediction task on held-out test sets. VisCOLL compounds the challenges of continual learning (i.e., learning from continuously shifting data distribution) and compositional generalization (i.e., generalizing to novel compositions). To facilitate research on VisCOLL, we construct two datasets, COCO-shift and Flickrshift, and benchmark them using different continual learning methods. Results reveal that SoTA continual learning approaches provide little to no improvements on VisCOLL, since storing examples of all possible compositions is infeasible. We conduct further ablations and analysis to guide future work 1 .","visually ground continual learning compositional phrase human acquire language continually limited access data sample time , compare contemporary nlp system . study human - like language acquisition ability , present viscoll , visually ground language learning task , simulate continual acquisition compositional phrase stream visual scene . task , model train pair image - caption stream shift object distribution ; constantly evaluate visually - ground mask language prediction task hold - test set . viscoll compound challenge continual learning ( i.e. , learn continuously shift datum distribution ) compositional generalization ( i.e. , generalize novel composition ) . facilitate research viscoll , construct dataset , coco - shift flickrshift , benchmark different continual learning method . result reveal sota continual learning approach provide little improvement viscoll , store example possible composition infeasible . conduct ablation analysis guide future work 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations,"A major challenge in visually grounded language generation is to build robust benchmark datasets and models that can generalize well in real-world settings. To do this, it is critical to ensure that our evaluation protocols are correct, and benchmarks are reliable. In this work, we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation: given that humans have different utilities and visual attention, how will the sample variance in multi-reference datasets affect the models' performance? Empirically, we study several multi-reference datasets and corresponding vision-and-language tasks. We show that it is of paramount importance to report variance in experiments; that humangenerated references could vary drastically in different datasets/tasks, revealing the nature of each task; that metric-wise, CIDEr has shown systematically larger variances than others. Our evaluations on reference-per-instance shed light on the design of reliable datasets in the future.","Towards Understanding Sample Variance in Visually Grounded Language Generation: Evaluations and Observations A major challenge in visually grounded language generation is to build robust benchmark datasets and models that can generalize well in real-world settings. To do this, it is critical to ensure that our evaluation protocols are correct, and benchmarks are reliable. In this work, we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation: given that humans have different utilities and visual attention, how will the sample variance in multi-reference datasets affect the models' performance? Empirically, we study several multi-reference datasets and corresponding vision-and-language tasks. We show that it is of paramount importance to report variance in experiments; that humangenerated references could vary drastically in different datasets/tasks, revealing the nature of each task; that metric-wise, CIDEr has shown systematically larger variances than others. Our evaluations on reference-per-instance shed light on the design of reliable datasets in the future.","understand sample variance visually ground language generation : evaluation observation major challenge visually ground language generation build robust benchmark dataset model generalize real - world setting . , critical ensure evaluation protocol correct , benchmark reliable . work , set forth design set experiment understand important ignore problem visually ground language generation : give human different utility visual attention , sample variance multi - reference dataset affect model ' performance ? empirically , study multi - reference dataset corresponding vision - - language task . paramount importance report variance experiment ; humangenerate reference vary drastically different dataset / task , reveal nature task ; metric - wise , cider show systematically large variance . evaluation reference - - instance shed light design reliable dataset future .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 8, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
"Language Grounding to Vision, Robotics and Beyond",MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering,"While progress has been made on the visual question answering leaderboards, models often utilize spurious correlations and priors in datasets under the i.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples has emerged as a proxy for generalization. In this paper, we present MUTANT, a training paradigm that exposes the model to perceptually similar, yet semantically distinct mutations of the input, to improve OOD generalization, such as the VQA-CP challenge. Under this paradigm, models utilize a consistency-constrained training objective to understand the effect of semantic changes in input (question-image pair) on the output (answer). Unlike existing methods on VQA-CP, MUTANT does not rely on the knowledge about the nature of train and test answer distributions. MUTANT establishes a new state-ofthe-art accuracy on VQA-CP with a 10.57% improvement. Our work opens up avenues for the use of semantic input mutations for OOD generalization in question answering.","MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering While progress has been made on the visual question answering leaderboards, models often utilize spurious correlations and priors in datasets under the i.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples has emerged as a proxy for generalization. In this paper, we present MUTANT, a training paradigm that exposes the model to perceptually similar, yet semantically distinct mutations of the input, to improve OOD generalization, such as the VQA-CP challenge. Under this paradigm, models utilize a consistency-constrained training objective to understand the effect of semantic changes in input (question-image pair) on the output (answer). Unlike existing methods on VQA-CP, MUTANT does not rely on the knowledge about the nature of train and test answer distributions. MUTANT establishes a new state-ofthe-art accuracy on VQA-CP with a 10.57% improvement. Our work opens up avenues for the use of semantic input mutations for OOD generalization in question answering.","mutant : training paradigm - - distribution generalization visual question answering progress visual question answering leaderboard , model utilize spurious correlation prior dataset i.i.d . setting . , evaluation - - distribution ( ood ) test sample emerge proxy generalization . paper , present mutant , training paradigm expose model perceptually similar , semantically distinct mutation input , improve ood generalization , vqa - cp challenge . paradigm , model utilize consistency - constrain training objective understand effect semantic change input ( question - image pair ) output ( answer ) . unlike exist method vqa - cp , mutant rely knowledge nature train test answer distribution . mutant establish new state - ofthe - art accuracy vqa - cp 10.57 % improvement . work open avenue use semantic input mutation ood generalization question answering .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 21, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",Domain-Specific Lexical Grounding in Noisy Visual-Textual Documents,"Images can give us insights into the contextual meanings of words, but current imagetext grounding approaches require detailed annotations. Such granular annotation is rare, expensive, and unavailable in most domainspecific contexts. In contrast, unlabeled multiimage, multi-sentence documents are abundant. Can lexical grounding be learned from such documents, even though they have significant lexical and visual overlap? Working with a case study dataset of real estate listings, we demonstrate the challenge of distinguishing highly correlated grounded terms, such as ""kitchen"" and ""bedroom"", and introduce metrics to assess this document similarity. We present a simple unsupervised clusteringbased method that increases precision and recall beyond object detection and image tagging baselines when evaluated on labeled subsets of the dataset. The proposed method is particularly effective for local contextual meanings of a word, for example associating ""granite"" with countertops in the real estate dataset and with rocky landscapes in a Wikipedia dataset.","Domain-Specific Lexical Grounding in Noisy Visual-Textual Documents Images can give us insights into the contextual meanings of words, but current imagetext grounding approaches require detailed annotations. Such granular annotation is rare, expensive, and unavailable in most domainspecific contexts. In contrast, unlabeled multiimage, multi-sentence documents are abundant. Can lexical grounding be learned from such documents, even though they have significant lexical and visual overlap? Working with a case study dataset of real estate listings, we demonstrate the challenge of distinguishing highly correlated grounded terms, such as ""kitchen"" and ""bedroom"", and introduce metrics to assess this document similarity. We present a simple unsupervised clusteringbased method that increases precision and recall beyond object detection and image tagging baselines when evaluated on labeled subsets of the dataset. The proposed method is particularly effective for local contextual meanings of a word, for example associating ""granite"" with countertops in the real estate dataset and with rocky landscapes in a Wikipedia dataset.","domain - specific lexical grounding noisy visual - textual document image insight contextual meaning word , current imagetext grounding approach require detailed annotation . granular annotation rare , expensive , unavailable domainspecific context . contrast , unlabeled multiimage , multi - sentence document abundant . lexical grounding learn document , significant lexical visual overlap ? work case study dataset real estate listing , demonstrate challenge distinguish highly correlate ground term , "" kitchen "" "" bedroom "" , introduce metric assess document similarity . present simple unsupervised clusteringbased method increase precision recall object detection image tagging baseline evaluate label subset dataset . propose method particularly effective local contextual meaning word , example associate "" granite "" countertop real estate dataset rocky landscape wikipedia dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",The Grammar of Emergent Languages,"In this paper, we consider the syntactic properties of languages emerged in referential games, using unsupervised grammar induction (UGI) techniques originally designed to analyse natural language. We show that the considered UGI techniques are appropriate to analyse emergent languages and we then study if the languages that emerge in a typical referential game setup exhibit syntactic structure, and to what extent this depends on the maximum message length and number of symbols that the agents are allowed to use. Our experiments demonstrate that a certain message length and vocabulary size are required for structure to emerge, but they also illustrate that more sophisticated game scenarios are required to obtain syntactic properties more akin to those observed in human language. We argue that UGI techniques should be part of the standard toolkit for analysing emergent languages and release a comprehensive library to facilitate such analysis for future researchers.","The Grammar of Emergent Languages In this paper, we consider the syntactic properties of languages emerged in referential games, using unsupervised grammar induction (UGI) techniques originally designed to analyse natural language. We show that the considered UGI techniques are appropriate to analyse emergent languages and we then study if the languages that emerge in a typical referential game setup exhibit syntactic structure, and to what extent this depends on the maximum message length and number of symbols that the agents are allowed to use. Our experiments demonstrate that a certain message length and vocabulary size are required for structure to emerge, but they also illustrate that more sophisticated game scenarios are required to obtain syntactic properties more akin to those observed in human language. We argue that UGI techniques should be part of the standard toolkit for analysing emergent languages and release a comprehensive library to facilitate such analysis for future researchers.","grammar emergent language paper , consider syntactic property language emerge referential game , unsupervised grammar induction ( ugi ) technique originally design analyse natural language . consider ugi technique appropriate analyse emergent language study language emerge typical referential game setup exhibit syntactic structure , extent depend maximum message length number symbol agent allow use . experiment demonstrate certain message length vocabulary size require structure emerge , illustrate sophisticated game scenario require obtain syntactic property akin observe human language . argue ugi technique standard toolkit analyse emergent language release comprehensive library facilitate analysis future researcher .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
"Language Grounding to Vision, Robotics and Beyond","Refer, Reuse, Reduce: Generating Subsequent References in Visual and Conversational Contexts","Dialogue participants often refer to entities or situations repeatedly within a conversation, which contributes to its cohesiveness. Subsequent references exploit the common ground accumulated by the interlocutors and hence have several interesting properties, namely, they tend to be shorter and reuse expressions that were effective in previous mentions. In this paper, we tackle the generation of first and subsequent references in visually grounded dialogue. We propose a generation model that produces referring utterances grounded in both the visual and the conversational context. To assess the referring effectiveness of its output, we also implement a reference resolution system. Our experiments and analyses show that the model produces better, more effective referring utterances than a model not grounded in the dialogue context, and generates subsequent references that exhibit linguistic patterns akin to humans. Referring utterances extracted from dialogue 1 A: a white fuzzy dog with a wine glass up to his face ; B: I see the wine glass dog ; A: no I don't have the wine glass dog Referring utterances extracted from dialogue 2 C: white dog sitting on something red ; D: yes I have the dog on the red chair ; C: white dog on the red chair","Refer, Reuse, Reduce: Generating Subsequent References in Visual and Conversational Contexts Dialogue participants often refer to entities or situations repeatedly within a conversation, which contributes to its cohesiveness. Subsequent references exploit the common ground accumulated by the interlocutors and hence have several interesting properties, namely, they tend to be shorter and reuse expressions that were effective in previous mentions. In this paper, we tackle the generation of first and subsequent references in visually grounded dialogue. We propose a generation model that produces referring utterances grounded in both the visual and the conversational context. To assess the referring effectiveness of its output, we also implement a reference resolution system. Our experiments and analyses show that the model produces better, more effective referring utterances than a model not grounded in the dialogue context, and generates subsequent references that exhibit linguistic patterns akin to humans. Referring utterances extracted from dialogue 1 A: a white fuzzy dog with a wine glass up to his face ; B: I see the wine glass dog ; A: no I don't have the wine glass dog Referring utterances extracted from dialogue 2 C: white dog sitting on something red ; D: yes I have the dog on the red chair ; C: white dog on the red chair","refer , reuse , reduce : generate subsequent reference visual conversational context dialogue participant refer entity situation repeatedly conversation , contribute cohesiveness . subsequent reference exploit common ground accumulate interlocutor interesting property , , tend short reuse expression effective previous mention . paper , tackle generation subsequent reference visually ground dialogue . propose generation model produce refer utterance ground visual conversational context . assess referring effectiveness output , implement reference resolution system . experiment analysis model produce well , effective refer utterance model ground dialogue context , generate subsequent reference exhibit linguistic pattern akin human . referring utterance extract dialogue 1 : white fuzzy dog wine glass face ; b : wine glass dog ; : wine glass dog refer utterance extract dialogue 2 c : white dog sit red ; d : yes dog red chair ; c : white dog red chair","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
"Language Grounding to Vision, Robotics and Beyond",Experience Grounds Language,"Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful. Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.","Experience Grounds Language Language understanding research is held back by a failure to relate language to the physical world it describes and to the social interactions it facilitates. Despite the incredible effectiveness of language processing models to tackle tasks after being trained on text alone, successful linguistic communication relies on a shared experience of the world. It is this shared experience that makes utterances meaningful. Natural language processing is a diverse field, and progress throughout its development has come from new representational theories, modeling techniques, data collection paradigms, and tasks. We posit that the present success of representation learning approaches trained on large, text-only corpora requires the parallel tradition of research on the broader physical and social context of language to address the deeper questions of communication.","experience grounds language language understanding research hold failure relate language physical world describe social interaction facilitate . despite incredible effectiveness language processing model tackle task train text , successful linguistic communication rely share experience world . share experience make utterance meaningful . natural language processing diverse field , progress development come new representational theory , modeling technique , data collection paradigm , task . posit present success representation learning approach train large , text - corpus require parallel tradition research broad physical social context language address deep question communication .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Language Grounding to Vision, Robotics and Beyond",Learning Physical Common Sense as Knowledge Graph Completion via BERT Data Augmentation and Constrained Tucker Factorization,"Physical common sense plays an essential role in the cognition abilities of robots for humanrobot interaction. Machine learning methods have shown promising results on physical commonsense learning in natural language processing but still suffer from model generalization. In this paper, we formulate physical commonsense learning as a knowledge graph completion problem to better use the latent relationships among training samples. Compared with completing general knowledge graphs, completing a physical commonsense knowledge graph has three unique characteristics: training data are scarce, not all facts can be mined from existing texts, and the number of relationships is small. To deal with these problems, we first use a pre-training language model BERT to augment training data, and then employ constrained tucker factorization to model complex relationships by constraining types and adding negative relationships. We compare our method with existing state-ofthe-art knowledge graph embedding methods and show its superior performance.","Learning Physical Common Sense as Knowledge Graph Completion via BERT Data Augmentation and Constrained Tucker Factorization Physical common sense plays an essential role in the cognition abilities of robots for humanrobot interaction. Machine learning methods have shown promising results on physical commonsense learning in natural language processing but still suffer from model generalization. In this paper, we formulate physical commonsense learning as a knowledge graph completion problem to better use the latent relationships among training samples. Compared with completing general knowledge graphs, completing a physical commonsense knowledge graph has three unique characteristics: training data are scarce, not all facts can be mined from existing texts, and the number of relationships is small. To deal with these problems, we first use a pre-training language model BERT to augment training data, and then employ constrained tucker factorization to model complex relationships by constraining types and adding negative relationships. We compare our method with existing state-ofthe-art knowledge graph embedding methods and show its superior performance.","learn physical common sense knowledge graph completion bert data augmentation constrain tucker factorization physical common sense play essential role cognition ability robot humanrobot interaction . machine learning method show promising result physical commonsense learning natural language processing suffer model generalization . paper , formulate physical commonsense learning knowledge graph completion problem well use latent relationship training sample . compare complete general knowledge graph , complete physical commonsense knowledge graph unique characteristic : training datum scarce , fact mine exist text , number relationship small . deal problem , use pre - training language model bert augment training datum , employ constrain tucker factorization model complex relationship constrain type add negative relationship . compare method exist state - ofthe - art knowledge graph embedding method superior performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
"Language Grounding to Vision, Robotics and Beyond",Does my multimodal model learn cross-modal interactions? It's harder to tell than you might think!,"Modeling expressive cross-modal interactions seems crucial in multimodal tasks, such as visual question answering. However, sometimes high-performing black-box algorithms turn out to be mostly exploiting unimodal signals in the data. We propose a new diagnostic tool, empirical multimodally-additive function projection (EMAP), for isolating whether or not cross-modal interactions improve performance for a given model on a given task. This function projection modifies model predictions so that cross-modal interactions are eliminated, isolating the additive, unimodal structure. For seven image+text classification tasks (on each of which we set new state-ofthe-art benchmarks), we find that, in many cases, removing cross-modal interactions results in little to no performance degradation. Surprisingly, this holds even when expressive models, with capacity to consider interactions, otherwise outperform less expressive models; thus, performance improvements, even when present, often cannot be attributed to consideration of cross-modal feature interactions. We hence recommend that researchers in multimodal machine learning report the performance not only of unimodal baselines, but also the EMAP of their best-performing model.","Does my multimodal model learn cross-modal interactions? It's harder to tell than you might think! Modeling expressive cross-modal interactions seems crucial in multimodal tasks, such as visual question answering. However, sometimes high-performing black-box algorithms turn out to be mostly exploiting unimodal signals in the data. We propose a new diagnostic tool, empirical multimodally-additive function projection (EMAP), for isolating whether or not cross-modal interactions improve performance for a given model on a given task. This function projection modifies model predictions so that cross-modal interactions are eliminated, isolating the additive, unimodal structure. For seven image+text classification tasks (on each of which we set new state-ofthe-art benchmarks), we find that, in many cases, removing cross-modal interactions results in little to no performance degradation. Surprisingly, this holds even when expressive models, with capacity to consider interactions, otherwise outperform less expressive models; thus, performance improvements, even when present, often cannot be attributed to consideration of cross-modal feature interactions. We hence recommend that researchers in multimodal machine learning report the performance not only of unimodal baselines, but also the EMAP of their best-performing model.","multimodal model learn cross - modal interaction ? hard tell think ! model expressive cross - modal interaction crucial multimodal task , visual question answering . , high - perform black - box algorithm turn exploit unimodal signal datum . propose new diagnostic tool , empirical multimodally - additive function projection ( emap ) , isolate cross - modal interaction improve performance give model give task . function projection modify model prediction cross - modal interaction eliminate , isolate additive , unimodal structure . seven image+text classification task ( set new state - ofthe - art benchmark ) , find , case , remove cross - modal interaction result little performance degradation . surprisingly , hold expressive model , capacity consider interaction , outperform expressive model ; , performance improvement , present , attribute consideration cross - modal feature interaction . recommend researcher multimodal machine learning report performance unimodal baseline , emap well - perform model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 9, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",What is More Likely to Happen Next? Video-and-Language Future Event Prediction,"Given a video with aligned dialogue, people can often infer what is more likely to happen next. Making such predictions requires not only a deep understanding of the rich dynamics underlying the video and dialogue, but also a significant amount of commonsense knowledge. In this work, we explore whether AI models are able to learn to make such multimodal commonsense nextevent predictions. To support research in this direction, we collect a new dataset, named Video-and-Language Event Prediction (VLEP), with 28,726 future event prediction examples (along with their rationales) from 10,234 diverse TV Show and YouTube Lifestyle Vlog video clips. In order to promote the collection of non-trivial challenging examples, we employ an adversarial humanand-model-in-the-loop data collection procedure. We also present a strong baseline incorporating information from video, dialogue, and commonsense knowledge. Experiments show that each type of information is useful for this challenging task, and that compared to the high human performance on VLEP, our model provides a good starting point but leaves large room for future work. 1","What is More Likely to Happen Next? Video-and-Language Future Event Prediction Given a video with aligned dialogue, people can often infer what is more likely to happen next. Making such predictions requires not only a deep understanding of the rich dynamics underlying the video and dialogue, but also a significant amount of commonsense knowledge. In this work, we explore whether AI models are able to learn to make such multimodal commonsense nextevent predictions. To support research in this direction, we collect a new dataset, named Video-and-Language Event Prediction (VLEP), with 28,726 future event prediction examples (along with their rationales) from 10,234 diverse TV Show and YouTube Lifestyle Vlog video clips. In order to promote the collection of non-trivial challenging examples, we employ an adversarial humanand-model-in-the-loop data collection procedure. We also present a strong baseline incorporating information from video, dialogue, and commonsense knowledge. Experiments show that each type of information is useful for this challenging task, and that compared to the high human performance on VLEP, our model provides a good starting point but leaves large room for future work. 1","likely happen ? video - - language future event prediction give video align dialogue , people infer likely happen . make prediction require deep understanding rich dynamic underlie video dialogue , significant commonsense knowledge . work , explore ai model able learn multimodal commonsense nextevent prediction . support research direction , collect new dataset , name video - - language event prediction ( vlep ) , 28,726 future event prediction example ( rationale ) 10,234 diverse tv youtube lifestyle vlog video clip . order promote collection non - trivial challenging example , employ adversarial humanand - model - - - loop data collection procedure . present strong baseline incorporate information video , dialogue , commonsense knowledge . experiment type information useful challenging task , compare high human performance vlep , model provide good starting point leave large room future work . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
"Language Grounding to Vision, Robotics and Beyond","Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision","Humans learn language by listening, speaking, writing, reading, and also, via interaction with the multimodal real world. Existing language pre-training frameworks show the effectiveness of text-only self-supervision while we explore the idea of a visually-supervised language model in this paper. We find that the main reason hindering this exploration is the large divergence in magnitude and distributions between the visually-grounded language datasets and pure-language corpora. Therefore, we develop a technique named ""vokenization"" that extrapolates multimodal alignments to language-only data by contextually mapping language tokens to their related images (which we call ""vokens""). The ""vokenizer"" is trained on relatively small image captioning datasets and we then apply it to generate vokens for large language corpora. Trained with these contextually generated vokens, our visually-supervised language models show consistent improvements over self-supervised alternatives on multiple purelanguage tasks such as GLUE, SQuAD, and SWAG. 1","Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision Humans learn language by listening, speaking, writing, reading, and also, via interaction with the multimodal real world. Existing language pre-training frameworks show the effectiveness of text-only self-supervision while we explore the idea of a visually-supervised language model in this paper. We find that the main reason hindering this exploration is the large divergence in magnitude and distributions between the visually-grounded language datasets and pure-language corpora. Therefore, we develop a technique named ""vokenization"" that extrapolates multimodal alignments to language-only data by contextually mapping language tokens to their related images (which we call ""vokens""). The ""vokenizer"" is trained on relatively small image captioning datasets and we then apply it to generate vokens for large language corpora. Trained with these contextually generated vokens, our visually-supervised language models show consistent improvements over self-supervised alternatives on multiple purelanguage tasks such as GLUE, SQuAD, and SWAG. 1","vokenization : improve language understanding contextualized , visual - ground supervision human learn language listen , speak , write , read , , interaction multimodal real world . exist language pre - training framework effectiveness text - self - supervision explore idea visually - supervise language model paper . find main reason hinder exploration large divergence magnitude distribution visually - ground language dataset pure - language corpus . , develop technique name "" vokenization "" extrapolate multimodal alignment language - datum contextually map language token related image ( "" vokens "" ) . "" vokenizer "" train relatively small image captioning dataset apply generate voken large language corpus . train contextually generate voken , visually - supervise language model consistent improvement self - supervise alternative multiple purelanguage task glue , squad , swag . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 8, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",ALICE: Active Learning with Contrastive Natural Language Explanations,"Training a supervised neural network classifier typically requires many annotated training samples. Collecting and annotating a large number of data points are costly and sometimes even infeasible. Traditional annotation process uses a low-bandwidth human-machine communication interface: classification labels, each of which only provides a few bits of information. We propose Active Learning with Contrastive Explanations (ALICE), an expert-in-the-loop training framework that utilizes contrastive natural language explanations to improve data efficiency in learning. AL-ICE learns to first use active learning to select the most informative pairs of label classes to elicit contrastive natural language explanations from experts. Then it extracts knowledge from these explanations using a semantic parser. Finally, it incorporates the extracted knowledge through dynamically changing the learning model's structure. We applied ALICE in two visual recognition tasks, bird species classification and social relationship classification. We found by incorporating contrastive explanations, our models outperform baseline models that are trained with 40-100% more training data. We found that adding 1 explanation leads to similar performance gain as adding 13-30 labeled training data points.","ALICE: Active Learning with Contrastive Natural Language Explanations Training a supervised neural network classifier typically requires many annotated training samples. Collecting and annotating a large number of data points are costly and sometimes even infeasible. Traditional annotation process uses a low-bandwidth human-machine communication interface: classification labels, each of which only provides a few bits of information. We propose Active Learning with Contrastive Explanations (ALICE), an expert-in-the-loop training framework that utilizes contrastive natural language explanations to improve data efficiency in learning. AL-ICE learns to first use active learning to select the most informative pairs of label classes to elicit contrastive natural language explanations from experts. Then it extracts knowledge from these explanations using a semantic parser. Finally, it incorporates the extracted knowledge through dynamically changing the learning model's structure. We applied ALICE in two visual recognition tasks, bird species classification and social relationship classification. We found by incorporating contrastive explanations, our models outperform baseline models that are trained with 40-100% more training data. We found that adding 1 explanation leads to similar performance gain as adding 13-30 labeled training data points.","alice : active learning contrastive natural language explanations training supervise neural network classifier typically require annotate training sample . collect annotate large number data point costly infeasible . traditional annotation process use low - bandwidth human - machine communication interface : classification label , provide bit information . propose active learning contrastive explanations ( alice ) , expert - - - loop training framework utilize contrastive natural language explanation improve data efficiency learning . al - ice learn use active learning select informative pair label class elicit contrastive natural language explanation expert . extract knowledge explanation semantic parser . finally , incorporate extract knowledge dynamically change learning model structure . apply alice visual recognition task , bird specie classification social relationship classification . find incorporate contrastive explanation , model outperform baseline model train 40 - 100 % training datum . find add 1 explanation lead similar performance gain add 13 - 30 label training datum point .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 7, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
"Language Grounding to Vision, Robotics and Beyond",Where Are You? Localization from Embodied Dialog,"We present WHERE ARE YOU? (WAY), a dataset of ∼6k dialogs in which two humans -an Observer and a Locator -complete a cooperative localization task. The Observer is spawned at random in a 3D environment and can navigate from first-person views while answering questions from the Locator. The Locator must localize the Observer in a detailed top-down map by asking questions and giving instructions. Based on this dataset, we define three challenging tasks: Localization from Embodied Dialog or LED (localizing the Observer from dialog history), Embodied Visual Dialog (modeling the Observer), and Cooperative Localization (modeling both agents). In this paper, we focus on the LED task -providing a strong baseline model with detailed ablations characterizing both dataset biases and the importance of various modeling choices. Our best model achieves 32.7% success at identifying the Observer's location within 3m in unseen buildings, vs. 70.4% for human Locators.","Where Are You? Localization from Embodied Dialog We present WHERE ARE YOU? (WAY), a dataset of ∼6k dialogs in which two humans -an Observer and a Locator -complete a cooperative localization task. The Observer is spawned at random in a 3D environment and can navigate from first-person views while answering questions from the Locator. The Locator must localize the Observer in a detailed top-down map by asking questions and giving instructions. Based on this dataset, we define three challenging tasks: Localization from Embodied Dialog or LED (localizing the Observer from dialog history), Embodied Visual Dialog (modeling the Observer), and Cooperative Localization (modeling both agents). In this paper, we focus on the LED task -providing a strong baseline model with detailed ablations characterizing both dataset biases and the importance of various modeling choices. Our best model achieves 32.7% success at identifying the Observer's location within 3m in unseen buildings, vs. 70.4% for human Locators.","? localization embody dialog present ? ( way ) , dataset ∼6k dialog human -an observer locator -complete cooperative localization task . observer spawn random 3d environment navigate - person view answer question locator . locator localize observer detailed - map ask question give instruction . base dataset , define challenging task : localization embody dialog led ( localize observer dialog history ) , embodied visual dialog ( model observer ) , cooperative localization ( model agent ) . paper , focus led task -provide strong baseline model detailed ablation characterize dataset bias importance modeling choice . good model achieve 32.7 % success identify observer location 3 m unseen building , vs. 70.4 % human locator .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 5, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 3, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
"Language Grounding to Vision, Robotics and Beyond",Sub-Instruction Aware Vision-and-Language Navigation,"Vision-and-language navigation requires an agent to navigate through a real 3D environment following natural language instructions. Despite significant advances, few previous works are able to fully utilize the strong correspondence between the visual and textual sequences. Meanwhile, due to the lack of intermediate supervision, the agent's performance at following each part of the instruction cannot be assessed during navigation. In this work, we focus on the granularity of the visual and language sequences as well as the traceability of agents through the completion of an instruction. We provide agents with fine-grained annotations during training and find that they are able to follow the instruction better and have a higher chance of reaching the target at test time. We enrich the benchmark dataset Roomto-Room (R2R) with sub-instructions and their corresponding paths. To make use of this data, we propose effective sub-instruction attention and shifting modules that select and attend to a single sub-instruction at each time-step. We implement our sub-instruction modules in four state-of-the-art agents, compare with their baseline models, and show that our proposed method improves the performance of all four agents.","Sub-Instruction Aware Vision-and-Language Navigation Vision-and-language navigation requires an agent to navigate through a real 3D environment following natural language instructions. Despite significant advances, few previous works are able to fully utilize the strong correspondence between the visual and textual sequences. Meanwhile, due to the lack of intermediate supervision, the agent's performance at following each part of the instruction cannot be assessed during navigation. In this work, we focus on the granularity of the visual and language sequences as well as the traceability of agents through the completion of an instruction. We provide agents with fine-grained annotations during training and find that they are able to follow the instruction better and have a higher chance of reaching the target at test time. We enrich the benchmark dataset Roomto-Room (R2R) with sub-instructions and their corresponding paths. To make use of this data, we propose effective sub-instruction attention and shifting modules that select and attend to a single sub-instruction at each time-step. We implement our sub-instruction modules in four state-of-the-art agents, compare with their baseline models, and show that our proposed method improves the performance of all four agents.","sub - instruction aware vision - - language navigation vision - - language navigation require agent navigate real 3d environment follow natural language instruction . despite significant advance , previous work able fully utilize strong correspondence visual textual sequence . , lack intermediate supervision , agent performance follow instruction assess navigation . work , focus granularity visual language sequence traceability agent completion instruction . provide agent fine - grained annotation training find able follow instruction well high chance reach target test time . enrich benchmark dataset roomto - room ( r2r ) sub - instruction corresponding path . use datum , propose effective sub - instruction attention shift module select attend single sub - instruction time - step . implement sub - instruction module state - - - art agent , compare baseline model , propose method improve performance agent .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 11, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 9, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond","X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers","Mirroring the success of masked language models, vision-and-language counterparts like VILBERT, LXMERT and UNITER have achieved state of the art performance on a variety of multimodal discriminative tasks like visual question answering and visual grounding. Recent work has also successfully adapted such models towards the generative task of image captioning. This begs the question: Can these models go the other way and generate images from pieces of text? Our analysis of a popular representative from this model family -LXMERT -finds that it is unable to generate rich and semantically meaningful imagery with its current training setup. We introduce X-LXMERT, an extension to LXMERT with training refinements including: discretizing visual representations, using uniform masking with a large range of masking ratios and aligning the right pre-training datasets to the right objectives which enables it to paint. X-LXMERT's image generation capabilities rival state of the art generative models while its question answering and captioning abilities remains comparable to LXMERT. Finally, we demonstrate the generality of these training refinements by adding image generation capabilities into UNITER to produce X-UNITER.","X-LXMERT: Paint, Caption and Answer Questions with Multi-Modal Transformers Mirroring the success of masked language models, vision-and-language counterparts like VILBERT, LXMERT and UNITER have achieved state of the art performance on a variety of multimodal discriminative tasks like visual question answering and visual grounding. Recent work has also successfully adapted such models towards the generative task of image captioning. This begs the question: Can these models go the other way and generate images from pieces of text? Our analysis of a popular representative from this model family -LXMERT -finds that it is unable to generate rich and semantically meaningful imagery with its current training setup. We introduce X-LXMERT, an extension to LXMERT with training refinements including: discretizing visual representations, using uniform masking with a large range of masking ratios and aligning the right pre-training datasets to the right objectives which enables it to paint. X-LXMERT's image generation capabilities rival state of the art generative models while its question answering and captioning abilities remains comparable to LXMERT. Finally, we demonstrate the generality of these training refinements by adding image generation capabilities into UNITER to produce X-UNITER.","x - lxmert : paint , caption answer question multi - modal transformer mirror success mask language model , vision - - language counterpart like vilbert , lxmert uniter achieve state art performance variety multimodal discriminative task like visual question answering visual grounding . recent work successfully adapt model generative task image captioning . beg question : model way generate image piece text ? analysis popular representative model family -lxmert -find unable generate rich semantically meaningful imagery current training setup . introduce x - lxmert , extension lxmert training refinement include : discretize visual representation , uniform masking large range masking ratio align right pre - training dataset right objective enable paint . x - lxmert image generation capability rival state art generative model question answering captioning ability remain comparable lxmert . finally , demonstrate generality training refinement add image generation capability uniter produce x - uniter .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 12, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 13, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",VD-BERT: A Unified Vision and Dialog Transformer with BERT,"Visual dialog is a challenging vision-language task, where a dialog agent needs to answer a series of questions through reasoning on the image content and dialog history. Prior work has mostly focused on various attention mechanisms to model such intricate interactions. By contrast, in this work, we propose VD-BERT, a simple yet effective framework of unified vision-dialog Transformer that leverages the pretrained BERT language models for Visual Dialog tasks. The model is unified in that (1) it captures all the interactions between the image and the multi-turn dialog using a single-stream Transformer encoder, and (2) it supports both answer ranking and answer generation seamlessly through the same architecture. More crucially, we adapt BERT for the effective fusion of vision and dialog contents via visually grounded training. Without the need of pretraining on external vision-language data, our model yields new state of the art, achieving the top position in both single-model and ensemble settings (74.54 and 75.35 NDCG scores) on the visual dialog leaderboard. Our code and pretrained models are released at https: //github.com/salesforce/VD-BERT.","VD-BERT: A Unified Vision and Dialog Transformer with BERT Visual dialog is a challenging vision-language task, where a dialog agent needs to answer a series of questions through reasoning on the image content and dialog history. Prior work has mostly focused on various attention mechanisms to model such intricate interactions. By contrast, in this work, we propose VD-BERT, a simple yet effective framework of unified vision-dialog Transformer that leverages the pretrained BERT language models for Visual Dialog tasks. The model is unified in that (1) it captures all the interactions between the image and the multi-turn dialog using a single-stream Transformer encoder, and (2) it supports both answer ranking and answer generation seamlessly through the same architecture. More crucially, we adapt BERT for the effective fusion of vision and dialog contents via visually grounded training. Without the need of pretraining on external vision-language data, our model yields new state of the art, achieving the top position in both single-model and ensemble settings (74.54 and 75.35 NDCG scores) on the visual dialog leaderboard. Our code and pretrained models are released at https: //github.com/salesforce/VD-BERT.","vd - bert : unified vision dialog transformer bert visual dialog challenging vision - language task , dialog agent need answer series question reason image content dialog history . prior work focus attention mechanism model intricate interaction . contrast , work , propose vd - bert , simple effective framework unified vision - dialog transformer leverage pretrained bert language model visual dialog task . model unified ( 1 ) capture interaction image multi - turn dialog single - stream transformer encoder , ( 2 ) support answer ranking answer generation seamlessly architecture . crucially , adapt bert effective fusion vision dialog content visually ground training . need pretraine external vision - language datum , model yield new state art , achieve position single - model ensemble setting ( 74.54 75.35 ndcg score ) visual dialog leaderboard . code pretraine model release https : //github.com / salesforce / vd - bert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 8, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 4, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
"Language Grounding to Vision, Robotics and Beyond",Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News,"Large-scale dissemination of disinformation online intended to mislead or deceive the general population is a major societal problem. Rapid progression in image, video, and natural language generative models has only exacerbated this situation and intensified our need for an effective defense mechanism. While existing approaches have been proposed to defend against neural fake news, they are generally constrained to the very limited setting where articles only have text and metadata such as the title and authors. In this paper, we introduce the more realistic and challenging task of defending against machine-generated news that also includes images and captions. To identify the possible weaknesses that adversaries can exploit, we create a NeuralNews dataset composed of 4 different types of generated articles as well as conduct a series of human user study experiments based on this dataset. In addition to the valuable insights gleaned from our user study, we provide a relatively effective approach based on detecting visualsemantic inconsistencies, which will serve as an effective first line of defense and a useful reference for future work in defending against machine-generated disinformation. Our code and dataset can be downloaded from here.","Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News Large-scale dissemination of disinformation online intended to mislead or deceive the general population is a major societal problem. Rapid progression in image, video, and natural language generative models has only exacerbated this situation and intensified our need for an effective defense mechanism. While existing approaches have been proposed to defend against neural fake news, they are generally constrained to the very limited setting where articles only have text and metadata such as the title and authors. In this paper, we introduce the more realistic and challenging task of defending against machine-generated news that also includes images and captions. To identify the possible weaknesses that adversaries can exploit, we create a NeuralNews dataset composed of 4 different types of generated articles as well as conduct a series of human user study experiments based on this dataset. In addition to the valuable insights gleaned from our user study, we provide a relatively effective approach based on detecting visualsemantic inconsistencies, which will serve as an effective first line of defense and a useful reference for future work in defending against machine-generated disinformation. Our code and dataset can be downloaded from here.","detect cross - modal inconsistency defend neural fake news large - scale dissemination disinformation online intend mislead deceive general population major societal problem . rapid progression image , video , natural language generative model exacerbate situation intensify need effective defense mechanism . exist approach propose defend neural fake news , generally constrain limited setting article text metadata title author . paper , introduce realistic challenging task defend machine - generate news include image caption . identify possible weakness adversary exploit , create neuralnews dataset compose 4 different type generate article conduct series human user study experiment base dataset . addition valuable insight glean user study , provide relatively effective approach base detect visualsemantic inconsistency , serve effective line defense useful reference future work defend machine - generate disinformation . code dataset download .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
"Language Grounding to Vision, Robotics and Beyond",Keep CALM and Explore: Language Models for Action Generation in Text-based Games,"Text-based games present a unique challenge for autonomous agents to operate in natural language and handle enormous action spaces. In this paper, we propose the Contextual Action Language Model (CALM) to generate a compact set of action candidates at each game state. Our key insight is to train language models on human gameplay, where people demonstrate linguistic priors and a general game sense for promising actions conditioned on game history. We combine CALM with a reinforcement learning agent which re-ranks the generated action candidates to maximize ingame rewards. We evaluate our approach using the Jericho benchmark (Hausknecht et al., 2019a) , on games unseen by CALM during training. Our method obtains a 69% relative improvement in average game score over the previous state-of-the-art model. Surprisingly, on half of these games, CALM is competitive with or better than other models that have access to ground truth admissible actions. * * Code and data are available at https://github. com/princeton-nlp/calm-textgame.","Keep CALM and Explore: Language Models for Action Generation in Text-based Games Text-based games present a unique challenge for autonomous agents to operate in natural language and handle enormous action spaces. In this paper, we propose the Contextual Action Language Model (CALM) to generate a compact set of action candidates at each game state. Our key insight is to train language models on human gameplay, where people demonstrate linguistic priors and a general game sense for promising actions conditioned on game history. We combine CALM with a reinforcement learning agent which re-ranks the generated action candidates to maximize ingame rewards. We evaluate our approach using the Jericho benchmark (Hausknecht et al., 2019a) , on games unseen by CALM during training. Our method obtains a 69% relative improvement in average game score over the previous state-of-the-art model. Surprisingly, on half of these games, CALM is competitive with or better than other models that have access to ground truth admissible actions. * * Code and data are available at https://github. com/princeton-nlp/calm-textgame.","calm explore : language models action generation text - base game text - base game present unique challenge autonomous agent operate natural language handle enormous action space . paper , propose contextual action language model ( calm ) generate compact set action candidate game state . key insight train language model human gameplay , people demonstrate linguistic prior general game sense promising action condition game history . combine calm reinforcement learning agent - rank generate action candidate maximize ingame reward . evaluate approach jericho benchmark ( hausknecht et al . , 2019a ) , game unseen calm training . method obtain 69 % relative improvement average game score previous state - - - art model . surprisingly , half game , calm competitive well model access ground truth admissible action . * * code datum available https://github . com / princeton - nlp / calm - textgame .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Language Grounding to Vision, Robotics and Beyond",Video2Commonsense: Generating Commonsense Descriptions to Enrich Video Captioning,"Captioning is a crucial and challenging task for video understanding. In videos that involve active agents such as humans, the agent's actions can bring about myriad changes in the scene. Observable changes such as movements, manipulations, and transformations of the objects in the scene, are reflected in conventional video captioning. Unlike images, actions in videos are also inherently linked to social aspects such as intentions (why the action is taking place), effects (what changes due to the action), and attributes that describe the agent. Thus for video understanding, such as when captioning videos or when answering questions about videos, one must have an understanding of these commonsense aspects. We present the first work on generating commonsense captions directly from videos, to describe latent aspects such as intentions, effects, and attributes. We present a new dataset ""Video-to-Commonsense (V2C)"" that contains ∼ 9k videos of human agents performing various actions, annotated with 3 types of commonsense descriptions. Additionally we explore the use of open-ended video-based commonsense question answering (V2C-QA) as a way to enrich our captions. Both the generation task and the QA task can be used to enrich video captions.","Video2Commonsense: Generating Commonsense Descriptions to Enrich Video Captioning Captioning is a crucial and challenging task for video understanding. In videos that involve active agents such as humans, the agent's actions can bring about myriad changes in the scene. Observable changes such as movements, manipulations, and transformations of the objects in the scene, are reflected in conventional video captioning. Unlike images, actions in videos are also inherently linked to social aspects such as intentions (why the action is taking place), effects (what changes due to the action), and attributes that describe the agent. Thus for video understanding, such as when captioning videos or when answering questions about videos, one must have an understanding of these commonsense aspects. We present the first work on generating commonsense captions directly from videos, to describe latent aspects such as intentions, effects, and attributes. We present a new dataset ""Video-to-Commonsense (V2C)"" that contains ∼ 9k videos of human agents performing various actions, annotated with 3 types of commonsense descriptions. Additionally we explore the use of open-ended video-based commonsense question answering (V2C-QA) as a way to enrich our captions. Both the generation task and the QA task can be used to enrich video captions.","video2commonsense : generate commonsense description enrich video captioning captioning crucial challenging task video understanding . video involve active agent human , agent action bring myriad change scene . observable change movement , manipulation , transformation object scene , reflect conventional video captioning . unlike image , action video inherently link social aspect intention ( action take place ) , effect ( change action ) , attribute describe agent . video understanding , caption video answer question video , understanding commonsense aspect . present work generate commonsense caption directly video , describe latent aspect intention , effect , attribute . present new dataset "" video - - commonsense ( v2c ) "" contain ∼ 9k video human agent perform action , annotate 3 type commonsense description . additionally explore use open - ended video - base commonsense question answering ( v2c - qa ) way enrich caption . generation task qa task enrich video caption .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 28, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 9, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Learning to Represent Image and Text with Denotation Graph,"Learning to fuse vision and language information and representing them is an important research problem with many applications. Recent progresses have leveraged the ideas of pretraining (from language modeling) and attention layers in Transformers to learn representation from datasets containing images aligned with linguistic expressions that describe the images. In this paper, we propose learning representations from a set of implied, visually grounded expressions between image and text, automatically mined from those datasets. In particular, we use denotation graphs to represent how specific concepts (such as sentences describing images) can be linked to abstract and generic concepts (such as short phrases) that are also visually grounded. This type of generic-to-specific relations can be discovered using linguistic analysis tools. We propose methods to incorporate such relations into learning representation. We show that state-of-the-art multimodal learning models can be further improved by leveraging automatically harvested structural relations. The representations lead to stronger empirical results on downstream tasks of cross-modal image retrieval, referring expression, and compositional attribute-object recognition. Both our codes and the extracted denotation graphs on the Flickr30K and the COCO datasets are publically available on https://sha-lab. github.io/DG.","Learning to Represent Image and Text with Denotation Graph Learning to fuse vision and language information and representing them is an important research problem with many applications. Recent progresses have leveraged the ideas of pretraining (from language modeling) and attention layers in Transformers to learn representation from datasets containing images aligned with linguistic expressions that describe the images. In this paper, we propose learning representations from a set of implied, visually grounded expressions between image and text, automatically mined from those datasets. In particular, we use denotation graphs to represent how specific concepts (such as sentences describing images) can be linked to abstract and generic concepts (such as short phrases) that are also visually grounded. This type of generic-to-specific relations can be discovered using linguistic analysis tools. We propose methods to incorporate such relations into learning representation. We show that state-of-the-art multimodal learning models can be further improved by leveraging automatically harvested structural relations. The representations lead to stronger empirical results on downstream tasks of cross-modal image retrieval, referring expression, and compositional attribute-object recognition. Both our codes and the extracted denotation graphs on the Flickr30K and the COCO datasets are publically available on https://sha-lab. github.io/DG.","learn represent image text denotation graph learn fuse vision language information represent important research problem application . recent progress leverage idea pretraine ( language modeling ) attention layer transformer learn representation dataset contain image align linguistic expression describe image . paper , propose learn representation set imply , visually ground expression image text , automatically mine dataset . particular , use denotation graph represent specific concept ( sentence describe image ) link abstract generic concept ( short phrase ) visually ground . type generic - - specific relation discover linguistic analysis tool . propose method incorporate relation learning representation . state - - - art multimodal learning model improve leverage automatically harvest structural relation . representation lead strong empirical result downstream task cross - modal image retrieval , refer expression , compositional attribute - object recognition . code extract denotation graph flickr30 k coco dataset publically available https://sha - lab . github.io/dg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 9, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Language Grounding to Vision, Robotics and Beyond",STL-CQA: Structure-based Transformers with Localization and Encoding for Chart Question Answering,"Chart Question Answering (CQA) is the task of answering natural language questions about visualisations in the chart image. Recent solutions, inspired by VQA approaches, rely on image-based attention for question/answering while ignoring the inherent chart structure. We propose STL-CQA which improves the question/answering through sequential elements localization, question encoding and then, a structural transformer-based learning approach. We conduct extensive experiments while proposing pre-training tasks, methodology and also an improved dataset with more complex and balanced questions of different types. The proposed methodology shows a significant accuracy improvement compared to the stateof-the-art approaches on various chart Q/A datasets, while outperforming even human baseline on the DVQA Dataset. We also demonstrate interpretability while examining different components in the inference pipeline.","STL-CQA: Structure-based Transformers with Localization and Encoding for Chart Question Answering Chart Question Answering (CQA) is the task of answering natural language questions about visualisations in the chart image. Recent solutions, inspired by VQA approaches, rely on image-based attention for question/answering while ignoring the inherent chart structure. We propose STL-CQA which improves the question/answering through sequential elements localization, question encoding and then, a structural transformer-based learning approach. We conduct extensive experiments while proposing pre-training tasks, methodology and also an improved dataset with more complex and balanced questions of different types. The proposed methodology shows a significant accuracy improvement compared to the stateof-the-art approaches on various chart Q/A datasets, while outperforming even human baseline on the DVQA Dataset. We also demonstrate interpretability while examining different components in the inference pipeline.","stl - cqa : structure - base transformers localization encoding chart question answering chart question answering ( cqa ) task answer natural language question visualisation chart image . recent solution , inspire vqa approach , rely image - base attention question / answering ignore inherent chart structure . propose stl - cqa improve question / answering sequential element localization , question encoding , structural transformer - base learning approach . conduct extensive experiment propose pre - training task , methodology improved dataset complex balanced question different type . propose methodology show significant accuracy improvement compare stateof - - art approach chart q / dataset , outperform human baseline dvqa dataset . demonstrate interpretability examine different component inference pipeline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 25, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",CapWAP: Image Captioning with a Purpose,"The traditional image captioning task uses generic reference captions to provide textual information about images. Different user populations, however, will care about different visual aspects of images. In this paper, we propose a new task, Captioning with A Purpose (CAPWAP). Our goal is to develop systems that can be tailored to be useful for the information needs of an intended population, rather than merely provide generic information about an image. In this task, we use questionanswer (QA) pairs-a natural expression of information need-from users, instead of reference captions, for both training and postinference evaluation. We show that it is possible to use reinforcement learning to directly optimize for the intended information need, by rewarding outputs that allow a question answering model to provide correct answers to sampled user questions. We convert several visual question answering datasets into CAP-WAP datasets, and demonstrate that under a variety of scenarios our purposeful captioning system learns to anticipate and fulfill specific information needs better than its generic counterparts, as measured by QA performance on user questions from unseen images, when using the caption alone as context.","CapWAP: Image Captioning with a Purpose The traditional image captioning task uses generic reference captions to provide textual information about images. Different user populations, however, will care about different visual aspects of images. In this paper, we propose a new task, Captioning with A Purpose (CAPWAP). Our goal is to develop systems that can be tailored to be useful for the information needs of an intended population, rather than merely provide generic information about an image. In this task, we use questionanswer (QA) pairs-a natural expression of information need-from users, instead of reference captions, for both training and postinference evaluation. We show that it is possible to use reinforcement learning to directly optimize for the intended information need, by rewarding outputs that allow a question answering model to provide correct answers to sampled user questions. We convert several visual question answering datasets into CAP-WAP datasets, and demonstrate that under a variety of scenarios our purposeful captioning system learns to anticipate and fulfill specific information needs better than its generic counterparts, as measured by QA performance on user questions from unseen images, when using the caption alone as context.","capwap : image captioning purpose traditional image captioning task use generic reference caption provide textual information image . different user population , , care different visual aspect image . paper , propose new task , caption purpose ( capwap ) . goal develop system tailor useful information need intended population , merely provide generic information image . task , use questionanswer ( qa ) pair - natural expression information need - user , instead reference caption , training postinference evaluation . possible use reinforcement learning directly optimize intended information need , reward output allow question answer model provide correct answer sample user question . convert visual question answer dataset cap - wap dataset , demonstrate variety scenario purposeful captioning system learn anticipate fulfill specific information need well generic counterpart , measure qa performance user question unseen image , caption context .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 15, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 13, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Visually Grounded Compound PCFGs,"Exploiting visual groundings for language understanding has recently been drawing much attention. In this work, we study visually grounded grammar induction and learn a constituency parser from both unlabeled text and its visual groundings. Existing work on this task (Shi et al., 2019) optimizes a parser via REINFORCE and derives the learning signal only from the alignment of images and sentences. While their model is relatively accurate overall, its error distribution is very uneven, with low performance on certain constituents types (e.g., 26.2% recall on verb phrases, VPs) and high on others (e.g., 79.6% recall on noun phrases, NPs). This is not surprising as the learning signal is likely insufficient for deriving all aspects of phrasestructure syntax and gradient estimates are noisy. We show that using an extension of probabilistic context-free grammar model we can do fully-differentiable end-to-end visually grounded learning. Additionally, this enables us to complement the image-text alignment loss with a language modeling objective. On the MSCOCO test captions, our model establishes a new state of the art, outperforming its non-grounded version and, thus, confirming the effectiveness of visual groundings in constituency grammar induction. It also substantially outperforms the previous grounded model, with largest improvements on more 'abstract' categories (e.g., +55.1% recall on VPs). 1","Visually Grounded Compound PCFGs Exploiting visual groundings for language understanding has recently been drawing much attention. In this work, we study visually grounded grammar induction and learn a constituency parser from both unlabeled text and its visual groundings. Existing work on this task (Shi et al., 2019) optimizes a parser via REINFORCE and derives the learning signal only from the alignment of images and sentences. While their model is relatively accurate overall, its error distribution is very uneven, with low performance on certain constituents types (e.g., 26.2% recall on verb phrases, VPs) and high on others (e.g., 79.6% recall on noun phrases, NPs). This is not surprising as the learning signal is likely insufficient for deriving all aspects of phrasestructure syntax and gradient estimates are noisy. We show that using an extension of probabilistic context-free grammar model we can do fully-differentiable end-to-end visually grounded learning. Additionally, this enables us to complement the image-text alignment loss with a language modeling objective. On the MSCOCO test captions, our model establishes a new state of the art, outperforming its non-grounded version and, thus, confirming the effectiveness of visual groundings in constituency grammar induction. It also substantially outperforms the previous grounded model, with largest improvements on more 'abstract' categories (e.g., +55.1% recall on VPs). 1","visually ground compound pcfgs exploit visual grounding language understanding recently draw attention . work , study visually ground grammar induction learn constituency parser unlabeled text visual grounding . exist work task ( shi et al . , 2019 ) optimize parser reinforce derive learning signal alignment image sentence . model relatively accurate overall , error distribution uneven , low performance certain constituent type ( e.g. , 26.2 % recall verb phrase , vp ) high ( e.g. , 79.6 % recall noun phrase , np ) . surprising learning signal likely insufficient derive aspect phrasestructure syntax gradient estimate noisy . extension probabilistic context - free grammar model fully - differentiable end - - end visually ground learning . additionally , enable complement image - text alignment loss language modeling objective . mscoco test caption , model establish new state art , outperform non - grounded version , , confirm effectiveness visual grounding constituency grammar induction . substantially outperform previous ground model , large improvement ' abstract ' category ( e.g. , +55.1 % recall vp ) . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 10, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",MAF: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding,"Phrase localization is a task that studies the mapping from textual phrases to regions of an image. Given difficulties in annotating phraseto-object datasets at scale, we develop a Multimodal Alignment Framework (MAF) to leverage more widely-available caption-image datasets, which can then be used as a form of weak supervision. We first present algorithms to model phrase-object relevance by leveraging fine-grained visual representations and visually-aware language representations. By adopting a contrastive objective, our method uses information in caption-image pairs to boost the performance in weakly-supervised scenarios. Experiments conducted on the widely-adopted Flickr30k dataset show a significant improvement over existing weaklysupervised methods. With the help of the visually-aware language representations, we can also improve the previous best unsupervised result by 5.56%. We conduct ablation studies to show that both our novel model and our weakly-supervised strategies significantly contribute to our strong results. 1","MAF: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding Phrase localization is a task that studies the mapping from textual phrases to regions of an image. Given difficulties in annotating phraseto-object datasets at scale, we develop a Multimodal Alignment Framework (MAF) to leverage more widely-available caption-image datasets, which can then be used as a form of weak supervision. We first present algorithms to model phrase-object relevance by leveraging fine-grained visual representations and visually-aware language representations. By adopting a contrastive objective, our method uses information in caption-image pairs to boost the performance in weakly-supervised scenarios. Experiments conducted on the widely-adopted Flickr30k dataset show a significant improvement over existing weaklysupervised methods. With the help of the visually-aware language representations, we can also improve the previous best unsupervised result by 5.56%. We conduct ablation studies to show that both our novel model and our weakly-supervised strategies significantly contribute to our strong results. 1","maf : multimodal alignment framework weakly - supervise phrase grounding phrase localization task study mapping textual phrase region image . give difficulty annotate phraseto - object dataset scale , develop multimodal alignment framework ( maf ) leverage widely - available caption - image dataset , form weak supervision . present algorithm model phrase - object relevance leverage fine - grained visual representation visually - aware language representation . adopt contrastive objective , method use information caption - image pair boost performance weakly - supervise scenario . experiment conduct widely - adopt flickr30k dataset significant improvement exist weaklysupervised method . help visually - aware language representation , improve previous good unsupervised result 5.56 % . conduct ablation study novel model weakly - supervise strategy significantly contribute strong result . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 12, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training,"We present HERO, a novel framework for large-scale video+language omnirepresentation learning. HERO  encodes multimodal inputs in a hierarchical structure, where local context of a video frame is captured by a Cross-modal Transformer via multimodal fusion, and global video context is captured by a Temporal Transformer. In addition to standard Masked Language Modeling (MLM) and Masked Frame Modeling (MFM) objectives, we design two new pre-training tasks: (i) Video-Subtitle Matching (VSM), where the model predicts both global and local temporal alignment; and (ii) Frame Order Modeling (FOM), where the model predicts the right order of shuffled video frames. HERO is jointly trained on HowTo100M and large-scale TV datasets to gain deep understanding of complex social dynamics with multi-character interactions. Comprehensive experiments demonstrate that HERO achieves new state of the art on multiple benchmarks over Text-based Video/Video-moment Retrieval, Video Question Answering (QA), Video-and-language Inference and Video Captioning tasks across different domains. We also introduce two new challenging benchmarks How2QA and How2R for Video QA and Retrieval, collected from diverse video content over multimodalities. 1","HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training We present HERO, a novel framework for large-scale video+language omnirepresentation learning. HERO  encodes multimodal inputs in a hierarchical structure, where local context of a video frame is captured by a Cross-modal Transformer via multimodal fusion, and global video context is captured by a Temporal Transformer. In addition to standard Masked Language Modeling (MLM) and Masked Frame Modeling (MFM) objectives, we design two new pre-training tasks: (i) Video-Subtitle Matching (VSM), where the model predicts both global and local temporal alignment; and (ii) Frame Order Modeling (FOM), where the model predicts the right order of shuffled video frames. HERO is jointly trained on HowTo100M and large-scale TV datasets to gain deep understanding of complex social dynamics with multi-character interactions. Comprehensive experiments demonstrate that HERO achieves new state of the art on multiple benchmarks over Text-based Video/Video-moment Retrieval, Video Question Answering (QA), Video-and-language Inference and Video Captioning tasks across different domains. We also introduce two new challenging benchmarks How2QA and How2R for Video QA and Retrieval, collected from diverse video content over multimodalities. 1","hero : hierarchical encoder video+language omni - representation pre - training present hero , novel framework large - scale video+language omnirepresentation learning . hero   encode multimodal input hierarchical structure , local context video frame capture cross - modal transformer multimodal fusion , global video context capture temporal transformer . addition standard masked language modeling ( mlm ) masked frame modeling ( mfm ) objective , design new pre - training task : ( ) video - subtitle matching ( vsm ) , model predict global local temporal alignment ; ( ii ) frame order modeling ( fom ) , model predict right order shuffle video frame . hero jointly train howto100 m large - scale tv dataset gain deep understanding complex social dynamic multi - character interaction . comprehensive experiment demonstrate hero achieve new state art multiple benchmark text - base video / video - moment retrieval , video question answering ( qa ) , video - - language inference video captioning task different domain . introduce new challenging benchmark how2qa how2r video qa retrieval , collect diverse video content multimodalitie . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 16, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 8, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Investigating representations of verb bias in neural language models,"Languages typically provide more than one grammatical construction to express certain types of messages. A speaker's choice of construction is known to depend on multiple factors, including the choice of main verb -a phenomenon known as verb bias. Here we introduce DAIS, a large benchmark dataset containing 50K human judgments for 5K distinct sentence pairs in the English dative alternation. This dataset includes 200 unique verbs and systematically varies the definiteness and length of arguments. We use this dataset, as well as an existing corpus of naturally occurring data, to evaluate how well recent neural language models capture human preferences. Results show that larger models perform better than smaller models, and transformer architectures (e.g. GPT-2) tend to out-perform recurrent architectures (e.g. LSTMs) even under comparable parameter and training settings. Additional analyses of internal feature representations suggest that transformers may better integrate specific lexical information with grammatical constructions.","Investigating representations of verb bias in neural language models Languages typically provide more than one grammatical construction to express certain types of messages. A speaker's choice of construction is known to depend on multiple factors, including the choice of main verb -a phenomenon known as verb bias. Here we introduce DAIS, a large benchmark dataset containing 50K human judgments for 5K distinct sentence pairs in the English dative alternation. This dataset includes 200 unique verbs and systematically varies the definiteness and length of arguments. We use this dataset, as well as an existing corpus of naturally occurring data, to evaluate how well recent neural language models capture human preferences. Results show that larger models perform better than smaller models, and transformer architectures (e.g. GPT-2) tend to out-perform recurrent architectures (e.g. LSTMs) even under comparable parameter and training settings. Additional analyses of internal feature representations suggest that transformers may better integrate specific lexical information with grammatical constructions.","investigate representation verb bias neural language model language typically provide grammatical construction express certain type message . speaker choice construction know depend multiple factor , include choice main verb -a phenomenon know verb bias . introduce dais , large benchmark dataset contain 50 k human judgment 5 k distinct sentence pair english dative alternation . dataset include 200 unique verb systematically vary definiteness length argument . use dataset , exist corpus naturally occur datum , evaluate recent neural language model capture human preference . result large model perform well small model , transformer architecture ( e.g. gpt-2 ) tend - perform recurrent architecture ( e.g. lstms ) comparable parameter training setting . additional analysis internal feature representation suggest transformer well integrate specific lexical information grammatical construction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Predicting Reference: What do Language Models Learn about Discourse Models?,"Whereas there is a growing literature that probes neural language models to assess the degree to which they have latently acquired grammatical knowledge, little if any research has investigated their acquisition of discourse modeling ability. We address this question by drawing on a rich psycholinguistic literature that has established how different contexts affect referential biases concerning who is likely to be referred to next. The results reveal that, for the most part, the prediction behavior of neural language models does not resemble that of human language users.","Predicting Reference: What do Language Models Learn about Discourse Models? Whereas there is a growing literature that probes neural language models to assess the degree to which they have latently acquired grammatical knowledge, little if any research has investigated their acquisition of discourse modeling ability. We address this question by drawing on a rich psycholinguistic literature that has established how different contexts affect referential biases concerning who is likely to be referred to next. The results reveal that, for the most part, the prediction behavior of neural language models does not resemble that of human language users.","predict reference : language model learn discourse model ? grow literature probe neural language model assess degree latently acquire grammatical knowledge , little research investigate acquisition discourse modeling ability . address question draw rich psycholinguistic literature establish different context affect referential bias concern likely refer . result reveal , , prediction behavior neural language model resemble human language user .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze,"When speakers describe an image, they tend to look at objects before mentioning them. In this paper, we investigate such sequential crossmodal alignment by modelling the image description generation process computationally. We take as our starting point a state-of-theart image captioning system and develop several model variants that exploit information from human gaze patterns recorded during language production. In particular, we propose the first approach to image description generation where visual processing is modelled sequentially. Our experiments and analyses confirm that better descriptions can be obtained by exploiting gaze-driven attention and shed light on human cognitive processes by comparing different ways of aligning the gaze modality with language production. We find that processing gaze data sequentially leads to descriptions that are better aligned to those produced by speakers, more diverse, and more naturalparticularly when gaze is encoded with a dedicated recurrent component.","Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze When speakers describe an image, they tend to look at objects before mentioning them. In this paper, we investigate such sequential crossmodal alignment by modelling the image description generation process computationally. We take as our starting point a state-of-theart image captioning system and develop several model variants that exploit information from human gaze patterns recorded during language production. In particular, we propose the first approach to image description generation where visual processing is modelled sequentially. Our experiments and analyses confirm that better descriptions can be obtained by exploiting gaze-driven attention and shed light on human cognitive processes by comparing different ways of aligning the gaze modality with language production. We find that processing gaze data sequentially leads to descriptions that are better aligned to those produced by speakers, more diverse, and more naturalparticularly when gaze is encoded with a dedicated recurrent component.","generate image description sequential cross - modal alignment guide human gaze speaker describe image , tend look object mention . paper , investigate sequential crossmodal alignment model image description generation process computationally . starting point state - - theart image captioning system develop model variant exploit information human gaze pattern record language production . particular , propose approach image description generation visual processing model sequentially . experiment analysis confirm well description obtain exploit gaze - drive attention shed light human cognitive process compare different way align gaze modality language production . find process gaze datum sequentially lead description well align produce speaker , diverse , naturalparticularly gaze encode dedicated recurrent component .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 8, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Surprisal Predicts Code-Switching in Chinese-English Bilingual Text,"Why do bilinguals switch languages within a sentence? The present observational study asks whether word surprisal and word entropy predict code-switching in bilingual written conversation. We describe and model a new dataset of Chinese-English text with 1476 clean code-switched sentences, translated back into Chinese. The model includes known control variables together with word surprisal and word entropy. We found that word surprisal, but not entropy, is a significant predictor that explains code-switching above and beyond other well-known predictors. We also found sentence length to be a significant predictor, which has been related to sentence complexity. We propose high cognitive effort as a reason for code-switching, as it leaves fewer resources for inhibition of the alternative language. We also corroborate previous findings, but this time using a computational model of surprisal, a new language pair, and doing so for written language.","Surprisal Predicts Code-Switching in Chinese-English Bilingual Text Why do bilinguals switch languages within a sentence? The present observational study asks whether word surprisal and word entropy predict code-switching in bilingual written conversation. We describe and model a new dataset of Chinese-English text with 1476 clean code-switched sentences, translated back into Chinese. The model includes known control variables together with word surprisal and word entropy. We found that word surprisal, but not entropy, is a significant predictor that explains code-switching above and beyond other well-known predictors. We also found sentence length to be a significant predictor, which has been related to sentence complexity. We propose high cognitive effort as a reason for code-switching, as it leaves fewer resources for inhibition of the alternative language. We also corroborate previous findings, but this time using a computational model of surprisal, a new language pair, and doing so for written language.","surprisal predict code - switching chinese - english bilingual text bilingual switch language sentence ? present observational study ask word surprisal word entropy predict code - switching bilingual write conversation . describe model new dataset chinese - english text 1476 clean code - switch sentence , translate chinese . model include know control variable word surprisal word entropy . find word surprisal , entropy , significant predictor explain code - switching - know predictor . find sentence length significant predictor , relate sentence complexity . propose high cognitive effort reason code - switching , leave few resource inhibition alternative language . corroborate previous finding , time computational model surprisal , new language pair , write language .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models,"Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this behavior in English and evaluate the effect of structural supervision on learning outcomes. First, we assess few-shot learning capabilities by developing controlled experiments that probe models' syntactic nominal number and verbal argument structure generalizations for tokens seen as few as two times during training. Second, we assess invariance properties of learned representation: the ability of a model to transfer syntactic generalizations from a base context (e.g., a simple declarative active-voice sentence) to a transformed context (e.g., an interrogative sentence). We test four models trained on the same dataset: an n-gram baseline, an LSTM, and two LSTM-variants trained with explicit structural supervision (Dyer et al., 2016; Charniak et al., 2016) . We find that in most cases, the neural models are able to induce the proper syntactic generalizations after minimal exposure, often from just two examples during training, and that the two structurally supervised models generalize more accurately than the LSTM model. All neural models are able to leverage information learned in base contexts to drive expectations in transformed contexts, indicating that they have learned some invariance properties of syntax.","Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this behavior in English and evaluate the effect of structural supervision on learning outcomes. First, we assess few-shot learning capabilities by developing controlled experiments that probe models' syntactic nominal number and verbal argument structure generalizations for tokens seen as few as two times during training. Second, we assess invariance properties of learned representation: the ability of a model to transfer syntactic generalizations from a base context (e.g., a simple declarative active-voice sentence) to a transformed context (e.g., an interrogative sentence). We test four models trained on the same dataset: an n-gram baseline, an LSTM, and two LSTM-variants trained with explicit structural supervision (Dyer et al., 2016; Charniak et al., 2016) . We find that in most cases, the neural models are able to induce the proper syntactic generalizations after minimal exposure, often from just two examples during training, and that the two structurally supervised models generalize more accurately than the LSTM model. All neural models are able to leverage information learned in base contexts to drive expectations in transformed contexts, indicating that they have learned some invariance properties of syntax.","structural supervision improve - shot learning syntactic generalization neural language model human learn structural property word minimal experience , deploy learn syntactic representation uniformly different grammatical context . assess ability modern neural language model reproduce behavior english evaluate effect structural supervision learn outcome . , assess - shot learning capability develop control experiment probe model ' syntactic nominal number verbal argument structure generalization token see time training . second , assess invariance property learn representation : ability model transfer syntactic generalization base context ( e.g. , simple declarative active - voice sentence ) transform context ( e.g. , interrogative sentence ) . test model train dataset : n - gram baseline , lstm , lstm - variant train explicit structural supervision ( dyer et al . , 2016 ; charniak et al . , 2016 ) . find case , neural model able induce proper syntactic generalization minimal exposure , example training , structurally supervise model generalize accurately lstm model . neural model able leverage information learn base context drive expectation transform context , indicate learn invariance property syntax .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 8, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",True
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Investigating Cross-Linguistic Adjective Ordering Tendencies with a Latent-Variable Model,"Across languages, multiple consecutive adjectives modifying a noun (e.g. ""the big red dog"") follow certain unmarked ordering rules. While explanatory accounts have been put forward, much of the work done in this area has relied primarily on the intuitive judgment of native speakers, rather than on corpus data. We present the first purely corpus-driven model of multi-lingual adjective ordering in the form of a latent-variable model that can accurately order adjectives across 24 different languages, even when the training and testing languages are different. We utilize this novel statistical model to provide strong converging evidence for the existence of universal, cross-linguistic, hierarchical adjective ordering tendencies.","Investigating Cross-Linguistic Adjective Ordering Tendencies with a Latent-Variable Model Across languages, multiple consecutive adjectives modifying a noun (e.g. ""the big red dog"") follow certain unmarked ordering rules. While explanatory accounts have been put forward, much of the work done in this area has relied primarily on the intuitive judgment of native speakers, rather than on corpus data. We present the first purely corpus-driven model of multi-lingual adjective ordering in the form of a latent-variable model that can accurately order adjectives across 24 different languages, even when the training and testing languages are different. We utilize this novel statistical model to provide strong converging evidence for the existence of universal, cross-linguistic, hierarchical adjective ordering tendencies.","investigate cross - linguistic adjective ordering tendency latent - variable model language , multiple consecutive adjective modify noun ( e.g. "" big red dog "" ) follow certain unmarked ordering rule . explanatory account forward , work area rely primarily intuitive judgment native speaker , corpus datum . present purely corpus - drive model multi - lingual adjective ordering form latent - variable model accurately order adjective 24 different language , training testing language different . utilize novel statistical model provide strong converge evidence existence universal , cross - linguistic , hierarchical adjective ordering tendency .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Latent Geographical Factors for Analyzing the Evolution of Dialects in Contact,"Analyzing the evolution of dialects remains a challenging problem because contact phenomena hinder the application of the standard tree model. Previous statistical approaches to this problem resort to admixture analysis, where each dialect is seen as a mixture of latent ancestral populations. However, such ancestral populations are hardly interpretable in the context of the tree model. In this paper, we propose a probabilistic generative model that represents latent factors as geographical distributions. We argue that the proposed model has higher affinity with the tree model because a tree can alternatively be represented as a set of geographical distributions. Experiments involving synthetic and real data suggest that the proposed method is both quantitatively and qualitatively superior to the admixture model.","Latent Geographical Factors for Analyzing the Evolution of Dialects in Contact Analyzing the evolution of dialects remains a challenging problem because contact phenomena hinder the application of the standard tree model. Previous statistical approaches to this problem resort to admixture analysis, where each dialect is seen as a mixture of latent ancestral populations. However, such ancestral populations are hardly interpretable in the context of the tree model. In this paper, we propose a probabilistic generative model that represents latent factors as geographical distributions. We argue that the proposed model has higher affinity with the tree model because a tree can alternatively be represented as a set of geographical distributions. Experiments involving synthetic and real data suggest that the proposed method is both quantitatively and qualitatively superior to the admixture model.","latent geographical factor analyze evolution dialect contact analyze evolution dialect remain challenge problem contact phenomenon hinder application standard tree model . previous statistical approach problem resort admixture analysis , dialect see mixture latent ancestral population . , ancestral population hardly interpretable context tree model . paper , propose probabilistic generative model represent latent factor geographical distribution . argue propose model high affinity tree model tree alternatively represent set geographical distribution . experiment involve synthetic real datum suggest propose method quantitatively qualitatively superior admixture model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Word class flexibility: A deep contextualized approach,"Word class flexibility refers to the phenomenon whereby a single word form is used across different grammatical categories. Extensive work in linguistic typology has sought to characterize word class flexibility across languages, but quantifying this phenomenon accurately and at scale has been fraught with difficulties. We propose a principled methodology to explore regularity in word class flexibility. Our method builds on recent work in contextualized word embeddings to quantify semantic shift between word classes (e.g., noun-to-verb, verb-to-noun), and we apply this method to 37 languages 1 . We find that contextualized embeddings not only capture human judgment of class variation within words in English, but also uncover shared tendencies in class flexibility across languages. Specifically, we find greater semantic variation when flexible lemmas are used in their dominant word class, supporting the view that word class flexibility is a directional process. Our work highlights the utility of deep contextualized models in linguistic typology.","Word class flexibility: A deep contextualized approach Word class flexibility refers to the phenomenon whereby a single word form is used across different grammatical categories. Extensive work in linguistic typology has sought to characterize word class flexibility across languages, but quantifying this phenomenon accurately and at scale has been fraught with difficulties. We propose a principled methodology to explore regularity in word class flexibility. Our method builds on recent work in contextualized word embeddings to quantify semantic shift between word classes (e.g., noun-to-verb, verb-to-noun), and we apply this method to 37 languages 1 . We find that contextualized embeddings not only capture human judgment of class variation within words in English, but also uncover shared tendencies in class flexibility across languages. Specifically, we find greater semantic variation when flexible lemmas are used in their dominant word class, supporting the view that word class flexibility is a directional process. Our work highlights the utility of deep contextualized models in linguistic typology.","word class flexibility : deep contextualize approach word class flexibility refer phenomenon single word form different grammatical category . extensive work linguistic typology seek characterize word class flexibility language , quantify phenomenon accurately scale fraught difficulty . propose principled methodology explore regularity word class flexibility . method build recent work contextualize word embedding quantify semantic shift word class ( e.g. , noun - - verb , verb - - noun ) , apply method 37 language 1 . find contextualize embedding capture human judgment class variation word english , uncover share tendency class flexibility language . specifically , find great semantic variation flexible lemma dominant word class , support view word class flexibility directional process . work highlight utility deep contextualize model linguistic typology .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 11, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Speakers Fill Lexical Semantic Gaps with Context,"Lexical ambiguity is widespread in language, allowing for the reuse of economical word forms and therefore making language more efficient. If ambiguous words cannot be disambiguated from context, however, this gain in efficiency might make language less clearresulting in frequent miscommunication. For a language to be clear and efficiently encoded, we posit that the lexical ambiguity of a word type should correlate with how much information context provides about it, on average. To investigate whether this is the case, we operationalise the lexical ambiguity of a word as the entropy of meanings it can take, and provide two ways to estimate this-one which requires human annotation (using WordNet), and one which does not (using BERT), making it readily applicable to a large number of languages. We validate these measures by showing that, on six high-resource languages, there are significant Pearson correlations between our BERT-based estimate of ambiguity and the number of synonyms a word has in Word-Net (e.g. ρ = 0.40 in English). We then test our main hypothesis-that a word's lexical ambiguity should negatively correlate with its contextual uncertainty-and find significant correlations on all 18 typologically diverse languages we analyse. This suggests that, in the presence of ambiguity, speakers compensate by making contexts more informative.","Speakers Fill Lexical Semantic Gaps with Context Lexical ambiguity is widespread in language, allowing for the reuse of economical word forms and therefore making language more efficient. If ambiguous words cannot be disambiguated from context, however, this gain in efficiency might make language less clearresulting in frequent miscommunication. For a language to be clear and efficiently encoded, we posit that the lexical ambiguity of a word type should correlate with how much information context provides about it, on average. To investigate whether this is the case, we operationalise the lexical ambiguity of a word as the entropy of meanings it can take, and provide two ways to estimate this-one which requires human annotation (using WordNet), and one which does not (using BERT), making it readily applicable to a large number of languages. We validate these measures by showing that, on six high-resource languages, there are significant Pearson correlations between our BERT-based estimate of ambiguity and the number of synonyms a word has in Word-Net (e.g. ρ = 0.40 in English). We then test our main hypothesis-that a word's lexical ambiguity should negatively correlate with its contextual uncertainty-and find significant correlations on all 18 typologically diverse languages we analyse. This suggests that, in the presence of ambiguity, speakers compensate by making contexts more informative.","speaker fill lexical semantic gap context lexical ambiguity widespread language , allow reuse economical word form make language efficient . ambiguous word disambiguate context , , gain efficiency language clearresulte frequent miscommunication . language clear efficiently encode , posit lexical ambiguity word type correlate information context provide , average . investigate case , operationalise lexical ambiguity word entropy meaning , provide way estimate - require human annotation ( wordnet ) , ( bert ) , make readily applicable large number language . validate measure show , high - resource language , significant pearson correlation bert - base estimate ambiguity number synonym word word - net ( e.g. ρ = 0.40 english ) . test main hypothesis - word lexical ambiguity negatively correlate contextual uncertainty - find significant correlation 18 typologically diverse language analyse . suggest , presence ambiguity , speaker compensate make context informative .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Learning for NLP,Training for Gibbs Sampling on Conditional Random Fields with Neural Scoring Factors,"Most recent improvements in NLP come from changes to the neural network architectures modeling the text input. Yet, state-of-theart models often rely on simple approaches to model the label space, e.g. bigram Conditional Random Fields (CRFs) in sequence tagging. More expressive graphical models are rarely used due to their prohibitive computational cost. In this work, we present an approach for efficiently training and decoding hybrids of graphical models and neural networks based on Gibbs sampling. Our approach is the natural adaptation of SampleRank (Wick et al., 2011)  to neural models, and is widely applicable to tasks beyond sequence tagging. We apply our approach to named entity recognition and present a neural skipchain CRF model, for which exact inference is impractical. The skip-chain model improves over a strong baseline on three languages from CoNLL-02/03. We obtain new state-of-the-art results on Dutch. 1","Training for Gibbs Sampling on Conditional Random Fields with Neural Scoring Factors Most recent improvements in NLP come from changes to the neural network architectures modeling the text input. Yet, state-of-theart models often rely on simple approaches to model the label space, e.g. bigram Conditional Random Fields (CRFs) in sequence tagging. More expressive graphical models are rarely used due to their prohibitive computational cost. In this work, we present an approach for efficiently training and decoding hybrids of graphical models and neural networks based on Gibbs sampling. Our approach is the natural adaptation of SampleRank (Wick et al., 2011)  to neural models, and is widely applicable to tasks beyond sequence tagging. We apply our approach to named entity recognition and present a neural skipchain CRF model, for which exact inference is impractical. The skip-chain model improves over a strong baseline on three languages from CoNLL-02/03. We obtain new state-of-the-art results on Dutch. 1","training gibbs sampling conditional random field neural scoring factor recent improvement nlp come change neural network architecture model text input . , state - - theart model rely simple approach model label space , e.g. bigram conditional random field ( crfs ) sequence tagging . expressive graphical model rarely prohibitive computational cost . work , present approach efficiently train decode hybrid graphical model neural network base gibbs sampling . approach natural adaptation samplerank ( wick et al . , 2011 )   neural model , widely applicable task sequence tagging . apply approach name entity recognition present neural skipchain crf model , exact inference impractical . skip - chain model improve strong baseline language conll-02/03 . obtain new state - - - art result dutch . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Entities as Experts: Sparse Memory Access with Entity Supervision,"We focus on the problem of capturing declarative knowledge about entities in the learned parameters of a language model. We introduce a new model-Entities as Experts (EAE)that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EAE's entity representations are learned directly from text. We show that EAE's learned representations capture sufficient knowledge to answer TriviaQA questions such as ""Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?"", outperforming an encodergenerator Transformer model with 10× the parameters. According to the LAMA knowledge probes, EAE contains more factual knowledge than a similarly sized BERT, as well as previous approaches that integrate external sources of entity knowledge. Because EAE associates parameters with specific entities, it only needs to access a fraction of its parameters at inference time, and we show that the correct identification and representation of entities is essential to EAE's performance.","Entities as Experts: Sparse Memory Access with Entity Supervision We focus on the problem of capturing declarative knowledge about entities in the learned parameters of a language model. We introduce a new model-Entities as Experts (EAE)that can access distinct memories of the entities mentioned in a piece of text. Unlike previous efforts to integrate entity knowledge into sequence models, EAE's entity representations are learned directly from text. We show that EAE's learned representations capture sufficient knowledge to answer TriviaQA questions such as ""Which Dr. Who villain has been played by Roger Delgado, Anthony Ainley, Eric Roberts?"", outperforming an encodergenerator Transformer model with 10× the parameters. According to the LAMA knowledge probes, EAE contains more factual knowledge than a similarly sized BERT, as well as previous approaches that integrate external sources of entity knowledge. Because EAE associates parameters with specific entities, it only needs to access a fraction of its parameters at inference time, and we show that the correct identification and representation of entities is essential to EAE's performance.","entities expert : sparse memory access entity supervision focus problem capture declarative knowledge entity learn parameter language model . introduce new model - entities experts ( eae)that access distinct memory entity mention piece text . unlike previous effort integrate entity knowledge sequence model , eae entity representation learn directly text . eae learn representation capture sufficient knowledge answer triviaqa question "" dr. villain play roger delgado , anthony ainley , eric roberts ? "" , outperform encodergenerator transformer model 10× parameter . accord lama knowledge probe , eae contain factual knowledge similarly sized bert , previous approach integrate external source entity knowledge . eae associate parameter specific entity , need access fraction parameter inference time , correct identification representation entity essential eae performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 3, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Understanding the Mechanics of SPIGOT: Surrogate Gradients for Latent Structure Learning,"Latent structure models are a powerful tool for modeling language data: they can mitigate the error propagation and annotation bottleneck in pipeline systems, while simultaneously uncovering linguistic insights about the data. One challenge with end-to-end training of these models is the argmax operation, which has null gradient. In this paper, we focus on surrogate gradients, a popular strategy to deal with this problem. We explore latent structure learning through the angle of pulling back the downstream learning objective. In this paradigm, we discover a principled motivation for both the straight-through estimator (STE) as well as the recently-proposed SPIGOT-a variant of STE for structured models. Our perspective leads to new algorithms in the same family. We empirically compare the known and the novel pulled-back estimators against the popular alternatives, yielding new insight for practitioners and revealing intriguing failure cases.","Understanding the Mechanics of SPIGOT: Surrogate Gradients for Latent Structure Learning Latent structure models are a powerful tool for modeling language data: they can mitigate the error propagation and annotation bottleneck in pipeline systems, while simultaneously uncovering linguistic insights about the data. One challenge with end-to-end training of these models is the argmax operation, which has null gradient. In this paper, we focus on surrogate gradients, a popular strategy to deal with this problem. We explore latent structure learning through the angle of pulling back the downstream learning objective. In this paradigm, we discover a principled motivation for both the straight-through estimator (STE) as well as the recently-proposed SPIGOT-a variant of STE for structured models. Our perspective leads to new algorithms in the same family. We empirically compare the known and the novel pulled-back estimators against the popular alternatives, yielding new insight for practitioners and revealing intriguing failure cases.","understand mechanic spigot : surrogate gradient latent structure learning latent structure model powerful tool model language datum : mitigate error propagation annotation bottleneck pipeline system , simultaneously uncover linguistic insight datum . challenge end - - end training model argmax operation , null gradient . paper , focus surrogate gradient , popular strategy deal problem . explore latent structure learning angle pull downstream learning objective . paradigm , discover principled motivation straight - estimator ( ste ) recently - propose spigot - variant ste structure model . perspective lead new algorithm family . empirically compare known novel pull - estimator popular alternative , yield new insight practitioner reveal intriguing failure case .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Imitation Attacks and Defenses for Black-box Machine Translation Systems,"Adversaries may look to steal or attack blackbox NLP systems, either for financial gain or to exploit model errors. One setting of particular interest is machine translation (MT), where models have high commercial value and errors can be costly. We investigate possible exploitations of black-box MT systems and explore a preliminary defense against such threats. We first show that MT systems can be stolen by querying them with monolingual sentences and training models to imitate their outputs. Using simulated experiments, we demonstrate that MT model stealing is possible even when imitation models have different input data or architectures than their target models. Applying these ideas, we train imitation models that reach within 0.6 BLEU of three production MT systems on both high-resource and low-resource language pairs. We then leverage the similarity of our imitation models to transfer adversarial examples to the production systems. We use gradient-based attacks that expose inputs which lead to semanticallyincorrect translations, dropped content, and vulgar model outputs. To mitigate these vulnerabilities, we propose a defense that modifies translation outputs in order to misdirect the optimization of imitation models. This defense degrades the adversary's BLEU score and attack success rate at some cost in the defender's BLEU and inference speed. Transfer Solve Eq. (2) Save me it's over 100°F Phase One: Model Imitation","Imitation Attacks and Defenses for Black-box Machine Translation Systems Adversaries may look to steal or attack blackbox NLP systems, either for financial gain or to exploit model errors. One setting of particular interest is machine translation (MT), where models have high commercial value and errors can be costly. We investigate possible exploitations of black-box MT systems and explore a preliminary defense against such threats. We first show that MT systems can be stolen by querying them with monolingual sentences and training models to imitate their outputs. Using simulated experiments, we demonstrate that MT model stealing is possible even when imitation models have different input data or architectures than their target models. Applying these ideas, we train imitation models that reach within 0.6 BLEU of three production MT systems on both high-resource and low-resource language pairs. We then leverage the similarity of our imitation models to transfer adversarial examples to the production systems. We use gradient-based attacks that expose inputs which lead to semanticallyincorrect translations, dropped content, and vulgar model outputs. To mitigate these vulnerabilities, we propose a defense that modifies translation outputs in order to misdirect the optimization of imitation models. This defense degrades the adversary's BLEU score and attack success rate at some cost in the defender's BLEU and inference speed. Transfer Solve Eq. (2) Save me it's over 100°F Phase One: Model Imitation","imitation attack defense black - box machine translation system adversary look steal attack blackbox nlp system , financial gain exploit model error . setting particular interest machine translation ( mt ) , model high commercial value error costly . investigate possible exploitation black - box mt system explore preliminary defense threat . mt system steal query monolingual sentence train model imitate output . simulate experiment , demonstrate mt model stealing possible imitation model different input datum architecture target model . apply idea , train imitation model reach 0.6 bleu production mt system high - resource low - resource language pair . leverage similarity imitation model transfer adversarial example production system . use gradient - base attack expose input lead semanticallyincorrect translation , drop content , vulgar model output . mitigate vulnerability , propose defense modify translation output order misdirect optimization imitation model . defense degrade adversary bleu score attack success rate cost defender bleu inference speed . transfer solve eq . ( 2 ) save 100 ° f phase : model imit","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Machine Learning for NLP,Does the Objective Matter? Comparing Training Objectives for Pronoun Resolution,"Hard cases of pronoun resolution have been used as a long-standing benchmark for commonsense reasoning. In the recent literature, pre-trained language models have been used to obtain state-of-the-art results on pronoun resolution. Overall, four categories of training and evaluation objectives have been introduced. The variety of training datasets and pretrained language models used in these works makes it unclear whether the choice of training objective is critical. In this work, we make a fair comparison of the performance and seedwise stability of four models that represent the four categories of objectives. Our experiments show that the objective of sequence ranking performs the best in-domain, while the objective of semantic similarity between candidates and pronoun performs the best out-of-domain. We also observe a seed-wise instability of the model using sequence ranking, which is not the case when the other objectives are used.","Does the Objective Matter? Comparing Training Objectives for Pronoun Resolution Hard cases of pronoun resolution have been used as a long-standing benchmark for commonsense reasoning. In the recent literature, pre-trained language models have been used to obtain state-of-the-art results on pronoun resolution. Overall, four categories of training and evaluation objectives have been introduced. The variety of training datasets and pretrained language models used in these works makes it unclear whether the choice of training objective is critical. In this work, we make a fair comparison of the performance and seedwise stability of four models that represent the four categories of objectives. Our experiments show that the objective of sequence ranking performs the best in-domain, while the objective of semantic similarity between candidates and pronoun performs the best out-of-domain. We also observe a seed-wise instability of the model using sequence ranking, which is not the case when the other objectives are used.","objective matter ? compare training objective pronoun resolution hard case pronoun resolution long - stand benchmark commonsense reasoning . recent literature , pre - trained language model obtain state - - - art result pronoun resolution . overall , category training evaluation objective introduce . variety training dataset pretrained language model work make unclear choice training objective critical . work , fair comparison performance seedwise stability model represent category objective . experiment objective sequence ranking perform good - domain , objective semantic similarity candidate pronoun perform good - - domain . observe seed - wise instability model sequence ranking , case objective .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 8, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Machine Learning for NLP,Local Additivity Based Data Augmentation for Semi-supervised NER,"Named Entity Recognition (NER) is one of the first stages in deep language understanding yet current NER models heavily rely on humanannotated data. In this work, to alleviate the dependence on labeled data, we propose a Local Additivity based Data Augmentation (LADA) method for semi-supervised NER, in which we create virtual samples by interpolating sequences close to each other. Our approach has two variations: Intra-LADA and Inter-LADA, where Intra-LADA performs interpolations among tokens within one sentence, and Inter-LADA samples different sentences to interpolate. Through linear additions between sampled training data, LADA creates an infinite amount of labeled data and improves both entity and context learning. We further extend LADA to the semi-supervised setting by designing a novel consistency loss for unlabeled data. Experiments conducted on two NER benchmarks demonstrate the effectiveness of our methods over several strong baselines. We have publicly released our code at https://github.com/GT-SALT/LADA.","Local Additivity Based Data Augmentation for Semi-supervised NER Named Entity Recognition (NER) is one of the first stages in deep language understanding yet current NER models heavily rely on humanannotated data. In this work, to alleviate the dependence on labeled data, we propose a Local Additivity based Data Augmentation (LADA) method for semi-supervised NER, in which we create virtual samples by interpolating sequences close to each other. Our approach has two variations: Intra-LADA and Inter-LADA, where Intra-LADA performs interpolations among tokens within one sentence, and Inter-LADA samples different sentences to interpolate. Through linear additions between sampled training data, LADA creates an infinite amount of labeled data and improves both entity and context learning. We further extend LADA to the semi-supervised setting by designing a novel consistency loss for unlabeled data. Experiments conducted on two NER benchmarks demonstrate the effectiveness of our methods over several strong baselines. We have publicly released our code at https://github.com/GT-SALT/LADA.","local additivity base data augmentation semi - supervised ner name entity recognition ( ner ) stage deep language understanding current ner model heavily rely humanannotated datum . work , alleviate dependence label datum , propose local additivity base data augmentation ( lada ) method semi - supervised ner , create virtual sample interpolate sequence close . approach variation : intra - lada inter - lada , intra - lada perform interpolation token sentence , inter - lada sample different sentence interpolate . linear addition sample training datum , lada create infinite label datum improve entity context learning . extend lada semi - supervised setting design novel consistency loss unlabeled datum . experiment conduct ner benchmark demonstrate effectiveness method strong baseline . publicly release code https://github.com/gt-salt/lada .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Is the Best Better? Bayesian Statistical Model Comparison for Natural Language Processing,"Recent work raises concerns about the use of standard splits to compare natural language processing models. We propose a Bayesian statistical model comparison technique which uses k-fold cross-validation across multiple data sets to estimate the likelihood that one model will outperform the other, or that the two will produce practically equivalent results. We use this technique to rank six English part-ofspeech taggers across two data sets and three evaluation metrics.","Is the Best Better? Bayesian Statistical Model Comparison for Natural Language Processing Recent work raises concerns about the use of standard splits to compare natural language processing models. We propose a Bayesian statistical model comparison technique which uses k-fold cross-validation across multiple data sets to estimate the likelihood that one model will outperform the other, or that the two will produce practically equivalent results. We use this technique to rank six English part-ofspeech taggers across two data sets and three evaluation metrics.","good well ? bayesian statistical model comparison natural language processing recent work raise concern use standard split compare natural language processing model . propose bayesian statistical model comparison technique use k - fold cross - validation multiple data set estimate likelihood model outperform , produce practically equivalent result . use technique rank english - ofspeech tagger data set evaluation metric .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Learning for NLP,Slot Attention with Value Normalization for Multi-Domain Dialogue State Tracking,"Incompleteness of domain ontology and unavailability of some values are two inevitable problems of dialogue state tracking (DST). Existing approaches generally fall into two extremes: choosing models without ontology or embedding ontology in models leading to over-dependence. In this paper, we propose a new architecture to cleverly exploit ontology, which consists of Slot Attention (SA) and Value Normalization (VN), referred to as SAVN. Moreover, we supplement the annotation of supporting span for MultiWOZ 2.1, which is the shortest span in utterances to support the labeled value. SA shares knowledge between slots and utterances and only needs a simple structure to predict the supporting span. VN is designed specifically for the use of ontology, which can convert supporting spans to the values. Empirical results demonstrate that SAVN achieves the state-of-the-art joint accuracy of 54.52% on MultiWOZ 2.0 and 54.86% on MultiWOZ 2.1. Besides, we evaluate VN with incomplete ontology. The results show that even if only 30% ontology is used, VN can also contribute to our model.","Slot Attention with Value Normalization for Multi-Domain Dialogue State Tracking Incompleteness of domain ontology and unavailability of some values are two inevitable problems of dialogue state tracking (DST). Existing approaches generally fall into two extremes: choosing models without ontology or embedding ontology in models leading to over-dependence. In this paper, we propose a new architecture to cleverly exploit ontology, which consists of Slot Attention (SA) and Value Normalization (VN), referred to as SAVN. Moreover, we supplement the annotation of supporting span for MultiWOZ 2.1, which is the shortest span in utterances to support the labeled value. SA shares knowledge between slots and utterances and only needs a simple structure to predict the supporting span. VN is designed specifically for the use of ontology, which can convert supporting spans to the values. Empirical results demonstrate that SAVN achieves the state-of-the-art joint accuracy of 54.52% on MultiWOZ 2.0 and 54.86% on MultiWOZ 2.1. Besides, we evaluate VN with incomplete ontology. The results show that even if only 30% ontology is used, VN can also contribute to our model.","slot attention value normalization multi - domain dialogue state tracking incompleteness domain ontology unavailability value inevitable problem dialogue state tracking ( dst ) . exist approach generally fall extreme : choose model ontology embed ontology model lead - dependence . paper , propose new architecture cleverly exploit ontology , consist slot attention ( sa ) value normalization ( vn ) , refer savn . , supplement annotation support span multiwoz 2.1 , short span utterance support label value . sa share knowledge slot utterance need simple structure predict support span . vn design specifically use ontology , convert support span value . empirical result demonstrate savn achieve state - - - art joint accuracy 54.52 % multiwoz 2.0 54.86 % multiwoz 2.1 . , evaluate vn incomplete ontology . result 30 % ontology , vn contribute model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Machine Learning for NLP,We Can Detect Your Bias: Predicting the Political Ideology of News Articles,"We explore the task of predicting the leading political ideology or bias of news articles. First, we collect and release a large dataset of 34,737 articles that were manually annotated for political ideology -left, center, or right-, which is well-balanced across both topics and media. We further use a challenging experimental setup where the test examples come from media that were not seen during training, which prevents the model from learning to detect the source of the target news article instead of predicting its political ideology. From a modeling perspective, we propose an adversarial media adaptation, as well as a specially adapted triplet loss. We further add background information about the source, and we show that it is quite helpful for improving article-level prediction. Our experimental results show very sizable improvements over using state-of-the-art pre-trained Transformers in this challenging setup.","We Can Detect Your Bias: Predicting the Political Ideology of News Articles We explore the task of predicting the leading political ideology or bias of news articles. First, we collect and release a large dataset of 34,737 articles that were manually annotated for political ideology -left, center, or right-, which is well-balanced across both topics and media. We further use a challenging experimental setup where the test examples come from media that were not seen during training, which prevents the model from learning to detect the source of the target news article instead of predicting its political ideology. From a modeling perspective, we propose an adversarial media adaptation, as well as a specially adapted triplet loss. We further add background information about the source, and we show that it is quite helpful for improving article-level prediction. Our experimental results show very sizable improvements over using state-of-the-art pre-trained Transformers in this challenging setup.","detect bias : predict political ideology news article explore task predict lead political ideology bias news article . , collect release large dataset 34,737 article manually annotate political ideology -left , center , right- , - balanced topic medium . use challenge experimental setup test example come medium see training , prevent model learn detect source target news article instead predict political ideology . modeling perspective , propose adversarial medium adaptation , specially adapt triplet loss . add background information source , helpful improve article - level prediction . experimental result sizable improvement state - - - art pre - train transformers challenging setup .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Machine Learning for NLP,Scalable Multi-Hop Relational Reasoning for Knowledge-Aware Question Answering,"Existing work that augment question answering (QA) models with external knowledge (e.g., knowledge graphs) either struggle to model multi-hop relations efficiently, or lack transparency into the model's prediction rationale. In this paper, we propose a novel knowledge-aware approach that equips pretrained language models (PTLMs) with a multi-hop relational reasoning module, named multi-hop graph relation network (MHGRN). It performs multi-hop, multi-relational reasoning over subgraphs extracted from external knowledge graphs. The proposed reasoning module unifies path-based reasoning methods and graph neural networks and results in better interpretability and scalability. We also empirically show its effectiveness and scalability on CommonsenseQA and OpenbookQA datasets, and interpret its behaviors with case studies, with the code for experiments released 1 .","Scalable Multi-Hop Relational Reasoning for Knowledge-Aware Question Answering Existing work that augment question answering (QA) models with external knowledge (e.g., knowledge graphs) either struggle to model multi-hop relations efficiently, or lack transparency into the model's prediction rationale. In this paper, we propose a novel knowledge-aware approach that equips pretrained language models (PTLMs) with a multi-hop relational reasoning module, named multi-hop graph relation network (MHGRN). It performs multi-hop, multi-relational reasoning over subgraphs extracted from external knowledge graphs. The proposed reasoning module unifies path-based reasoning methods and graph neural networks and results in better interpretability and scalability. We also empirically show its effectiveness and scalability on CommonsenseQA and OpenbookQA datasets, and interpret its behaviors with case studies, with the code for experiments released 1 .","scalable multi - hop relational reasoning knowledge - aware question answer exist work augment question answering ( qa ) model external knowledge ( e.g. , knowledge graph ) struggle model multi - hop relation efficiently , lack transparency model prediction rationale . paper , propose novel knowledge - aware approach equip pretrained language model ( ptlms ) multi - hop relational reasoning module , name multi - hop graph relation network ( mhgrn ) . perform multi - hop , multi - relational reasoning subgraph extract external knowledge graph . propose reasoning module unify path - base reasoning method graph neural network result well interpretability scalability . empirically effectiveness scalability commonsenseqa openbookqa dataset , interpret behavior case study , code experiment release 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Machine Learning for NLP,On the importance of pre-training data volume for compact language models,"Recent advances in language modeling have led to computationally intensive and resourcedemanding state-of-the-art models. In an effort towards sustainable practices, we study the impact of pre-training data volume on compact language models. Multiple BERT-based models are trained on gradually increasing amounts of French text. Through fine-tuning on the French Question Answering Dataset (FQuAD), we observe that well-performing models are obtained with as little as 100 MB of text. In addition, we show that past critically low amounts of pre-training data, an intermediate pre-training step on the task-specific corpus does not yield substantial improvements.","On the importance of pre-training data volume for compact language models Recent advances in language modeling have led to computationally intensive and resourcedemanding state-of-the-art models. In an effort towards sustainable practices, we study the impact of pre-training data volume on compact language models. Multiple BERT-based models are trained on gradually increasing amounts of French text. Through fine-tuning on the French Question Answering Dataset (FQuAD), we observe that well-performing models are obtained with as little as 100 MB of text. In addition, we show that past critically low amounts of pre-training data, an intermediate pre-training step on the task-specific corpus does not yield substantial improvements.","importance pre - training datum volume compact language model recent advance language modeling lead computationally intensive resourcedemanding state - - - art model . effort sustainable practice , study impact pre - training datum volume compact language model . multiple bert - base model train gradually increase amount french text . fine - tuning french question answering dataset ( fquad ) , observe - perform model obtain little 100 mb text . addition , past critically low amount pre - training datum , intermediate pre - training step task - specific corpus yield substantial improvement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Plug and Play Autoencoders for Conditional Text Generation,"Text autoencoders are commonly used for conditional generation tasks such as style transfer. We propose methods which are plug and play, where any pretrained autoencoder can be used, and only require learning a mapping within the autoencoder's embedding space, training embedding-to-embedding (Emb2Emb). This reduces the need for labeled training data for the task and makes the training procedure more efficient. Crucial to the success of this method is a loss term for keeping the mapped embedding on the manifold of the autoencoder and a mapping which is trained to navigate the manifold by learning offset vectors. Evaluations on style transfer tasks both with and without sequence-to-sequence supervision show that our method performs better than or comparable to strong baselines while being up to four times faster.","Plug and Play Autoencoders for Conditional Text Generation Text autoencoders are commonly used for conditional generation tasks such as style transfer. We propose methods which are plug and play, where any pretrained autoencoder can be used, and only require learning a mapping within the autoencoder's embedding space, training embedding-to-embedding (Emb2Emb). This reduces the need for labeled training data for the task and makes the training procedure more efficient. Crucial to the success of this method is a loss term for keeping the mapped embedding on the manifold of the autoencoder and a mapping which is trained to navigate the manifold by learning offset vectors. Evaluations on style transfer tasks both with and without sequence-to-sequence supervision show that our method performs better than or comparable to strong baselines while being up to four times faster.","plug play autoencoder conditional text generation text autoencoder commonly conditional generation task style transfer . propose method plug play , pretraine autoencoder , require learn mapping autoencoder embedding space , training embedding - - embedding ( emb2emb ) . reduce need label training datum task make training procedure efficient . crucial success method loss term keep map embedding manifold autoencoder mapping train navigate manifold learn offset vector . evaluation style transfer task sequence - - sequence supervision method perform well comparable strong baseline time fast .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Embedding Words in Non-Vector Space with Unsupervised Graph Learning,"It has become a de-facto standard to represent words as elements of a vector space (word2vec, GloVe). While this approach is convenient, it is unnatural for language: words form a graph with a latent hierarchical structure, and this structure has to be revealed and encoded by word embeddings. We introduce Graph-Glove: unsupervised graph word representations which are learned end-to-end. In our setting, each word is a node in a weighted graph and the distance between words is the shortest path distance between the corresponding nodes. We adopt a recent method learning a representation of data in the form of a differentiable weighted graph and use it to modify the GloVe training algorithm. We show that our graph-based representations substantially outperform vector-based methods on word similarity and analogy tasks. Our analysis reveals that the structure of the learned graphs is hierarchical and similar to that of WordNet, the geometry is highly non-trivial and contains subgraphs with different local topology. 1","Embedding Words in Non-Vector Space with Unsupervised Graph Learning It has become a de-facto standard to represent words as elements of a vector space (word2vec, GloVe). While this approach is convenient, it is unnatural for language: words form a graph with a latent hierarchical structure, and this structure has to be revealed and encoded by word embeddings. We introduce Graph-Glove: unsupervised graph word representations which are learned end-to-end. In our setting, each word is a node in a weighted graph and the distance between words is the shortest path distance between the corresponding nodes. We adopt a recent method learning a representation of data in the form of a differentiable weighted graph and use it to modify the GloVe training algorithm. We show that our graph-based representations substantially outperform vector-based methods on word similarity and analogy tasks. Our analysis reveals that the structure of the learned graphs is hierarchical and similar to that of WordNet, the geometry is highly non-trivial and contains subgraphs with different local topology. 1","embed word non - vector space unsupervised graph learning de - facto standard represent word element vector space ( word2vec , glove ) . approach convenient , unnatural language : word form graph latent hierarchical structure , structure reveal encode word embedding . introduce graph - glove : unsupervised graph word representation learn end - - end . setting , word node weight graph distance word short path distance correspond node . adopt recent method learn representation datum form differentiable weight graph use modify glove training algorithm . graph - base representation substantially outperform vector - base method word similarity analogy task . analysis reveal structure learn graph hierarchical similar wordnet , geometry highly non - trivial contain subgraph different local topology . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 14, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Learning for NLP,BAE: BERT-based Adversarial Examples for Text Classification,"Modern text classification models are susceptible to adversarial examples, perturbed versions of the original text indiscernible by humans which get misclassified by the model. Recent works in NLP use rule-based synonym replacement strategies to generate adversarial examples. These strategies can lead to outof-context and unnaturally complex token replacements, which are easily identifiable by humans. We present BAE, a black box attack for generating adversarial examples using contextual perturbations from a BERT masked language model. BAE replaces and inserts tokens in the original text by masking a portion of the text and leveraging the BERT-MLM to generate alternatives for the masked tokens. Through automatic and human evaluations, we show that BAE performs a stronger attack, in addition to generating adversarial examples with improved grammaticality and semantic coherence as compared to prior work.","BAE: BERT-based Adversarial Examples for Text Classification Modern text classification models are susceptible to adversarial examples, perturbed versions of the original text indiscernible by humans which get misclassified by the model. Recent works in NLP use rule-based synonym replacement strategies to generate adversarial examples. These strategies can lead to outof-context and unnaturally complex token replacements, which are easily identifiable by humans. We present BAE, a black box attack for generating adversarial examples using contextual perturbations from a BERT masked language model. BAE replaces and inserts tokens in the original text by masking a portion of the text and leveraging the BERT-MLM to generate alternatives for the masked tokens. Through automatic and human evaluations, we show that BAE performs a stronger attack, in addition to generating adversarial examples with improved grammaticality and semantic coherence as compared to prior work.","bae : bert - base adversarial example text classification modern text classification model susceptible adversarial example , perturb version original text indiscernible human misclassifie model . recent work nlp use rule - base synonym replacement strategy generate adversarial example . strategy lead outof - context unnaturally complex token replacement , easily identifiable human . present bae , black box attack generate adversarial example contextual perturbation bert mask language model . bae replace insert token original text mask portion text leverage bert - mlm generate alternative mask token . automatic human evaluation , bae perform strong attack , addition generate adversarial example improve grammaticality semantic coherence compare prior work .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness,"Models that perform well on a training domain often fail to generalize to out-of-domain (OOD) examples. Data augmentation is a common method used to prevent overfitting and improve OOD generalization. However, in natural language, it is difficult to generate new examples that stay on the underlying data manifold. We introduce SSMBA, a data augmentation method for generating synthetic training examples by using a pair of corruption and reconstruction functions to move randomly on a data manifold. We investigate the use of SSMBA in the natural language domain, leveraging the manifold assumption to reconstruct corrupted text with masked language models. In experiments on robustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently outperforms existing data augmentation methods and baseline models on both in-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews, 1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English. 1","SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness Models that perform well on a training domain often fail to generalize to out-of-domain (OOD) examples. Data augmentation is a common method used to prevent overfitting and improve OOD generalization. However, in natural language, it is difficult to generate new examples that stay on the underlying data manifold. We introduce SSMBA, a data augmentation method for generating synthetic training examples by using a pair of corruption and reconstruction functions to move randomly on a data manifold. We investigate the use of SSMBA in the natural language domain, leveraging the manifold assumption to reconstruct corrupted text with masked language models. In experiments on robustness benchmarks across 3 tasks and 9 datasets, SSMBA consistently outperforms existing data augmentation methods and baseline models on both in-domain and OOD data, achieving gains of 0.8% accuracy on OOD Amazon reviews, 1.8% accuracy on OOD MNLI, and 1.4 BLEU on in-domain IWSLT14 German-English. 1","ssmba : self - supervise manifold base datum augmentation improve - - domain robustness model perform training domain fail generalize - - domain ( ood ) example . datum augmentation common method prevent overfitting improve ood generalization . , natural language , difficult generate new example stay underlie datum manifold . introduce ssmba , data augmentation method generate synthetic training example pair corruption reconstruction function randomly datum manifold . investigate use ssmba natural language domain , leverage manifold assumption reconstruct corrupted text mask language model . experiment robustness benchmark 3 task 9 dataset , ssmba consistently outperform exist data augmentation method baseline model - domain ood datum , achieve gain 0.8 % accuracy ood amazon review , 1.8 % accuracy ood mnli , 1.4 bleu - domain iwslt14 german - english . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,ETC: Encoding Long and Structured Inputs in Transformers,"Transformer models have advanced the state of the art in many Natural Language Processing (NLP) tasks. In this paper, we present a new Transformer architecture, Extended Transformer Construction (ETC), that addresses two key challenges of standard Transformer architectures, namely scaling input length and encoding structured inputs. To scale attention to longer inputs, we introduce a novel global-local attention mechanism between global tokens and regular input tokens. We also show that combining global-local attention with relative position encodings and a Contrastive Predictive Coding (CPC) pretraining objective allows ETC to encode structured inputs. We achieve state-of-the-art results on four natural language datasets requiring long and/or structured inputs.","ETC: Encoding Long and Structured Inputs in Transformers Transformer models have advanced the state of the art in many Natural Language Processing (NLP) tasks. In this paper, we present a new Transformer architecture, Extended Transformer Construction (ETC), that addresses two key challenges of standard Transformer architectures, namely scaling input length and encoding structured inputs. To scale attention to longer inputs, we introduce a novel global-local attention mechanism between global tokens and regular input tokens. We also show that combining global-local attention with relative position encodings and a Contrastive Predictive Coding (CPC) pretraining objective allows ETC to encode structured inputs. We achieve state-of-the-art results on four natural language datasets requiring long and/or structured inputs.","etc : encode long structured input transformers transformer model advance state art natural language processing ( nlp ) task . paper , present new transformer architecture , extended transformer construction ( etc ) , address key challenge standard transformer architecture , scale input length encode structure input . scale attention long input , introduce novel global - local attention mechanism global token regular input token . combine global - local attention relative position encoding contrastive predictive coding ( cpc ) pretraine objective allow etc encode structure input . achieve state - - - art result natural language dataset require long and/or structured input .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Learning for NLP,Improving Grammatical Error Correction Models with Purpose-Built Adversarial Examples,"A sequence-to-sequence (seq2seq) learning with neural networks empirically shows to be an effective framework for grammatical error correction (GEC), which takes a sentence with errors as input and outputs the corrected one. However, the performance of GEC models with the seq2seq framework heavily relies on the size and quality of the corpus on hand. We propose a method inspired by adversarial training to generate more meaningful and valuable training examples by continually identifying the weak spots of a model, and to enhance the model by gradually adding the generated adversarial examples to the training set. Extensive experimental results show that such adversarial training can improve both the generalization and robustness of GEC models.","Improving Grammatical Error Correction Models with Purpose-Built Adversarial Examples A sequence-to-sequence (seq2seq) learning with neural networks empirically shows to be an effective framework for grammatical error correction (GEC), which takes a sentence with errors as input and outputs the corrected one. However, the performance of GEC models with the seq2seq framework heavily relies on the size and quality of the corpus on hand. We propose a method inspired by adversarial training to generate more meaningful and valuable training examples by continually identifying the weak spots of a model, and to enhance the model by gradually adding the generated adversarial examples to the training set. Extensive experimental results show that such adversarial training can improve both the generalization and robustness of GEC models.","improve grammatical error correction model purpose - build adversarial example sequence - - sequence ( seq2seq ) learning neural network empirically show effective framework grammatical error correction ( gec ) , take sentence error input output correct . , performance gec model seq2seq framework heavily rely size quality corpus hand . propose method inspire adversarial training generate meaningful valuable training example continually identify weak spot model , enhance model gradually add generate adversarial example training set . extensive experimental result adversarial training improve generalization robustness gec model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,On Losses for Modern Language Models,"BERT set many state-of-the-art results over varied NLU benchmarks by pre-training over two tasks: masked language modelling (MLM) and next sentence prediction (NSP), the latter of which has been highly criticized. In this paper, we 1) clarify NSP's effect on BERT pre-training, 2) explore fourteen possible auxiliary pre-training tasks, of which seven are novel to modern language models, and 3) investigate different ways to include multiple tasks into pre-training. We show that NSP is detrimental to training due to its context splitting and shallow semantic signal. We also identify six auxiliary pre-training tasks -sentence ordering, adjacent sentence prediction, TF prediction, TF-IDF prediction, a Fast-Sent variant, and a Quick Thoughts variant -that outperform a pure MLM baseline. Finally, we demonstrate that using multiple tasks in a multi-task pre-training framework provides better results than using any single auxiliary task. Using these methods, we outperform BERT Base on the GLUE benchmark using fewer than a quarter of the training tokens.","On Losses for Modern Language Models BERT set many state-of-the-art results over varied NLU benchmarks by pre-training over two tasks: masked language modelling (MLM) and next sentence prediction (NSP), the latter of which has been highly criticized. In this paper, we 1) clarify NSP's effect on BERT pre-training, 2) explore fourteen possible auxiliary pre-training tasks, of which seven are novel to modern language models, and 3) investigate different ways to include multiple tasks into pre-training. We show that NSP is detrimental to training due to its context splitting and shallow semantic signal. We also identify six auxiliary pre-training tasks -sentence ordering, adjacent sentence prediction, TF prediction, TF-IDF prediction, a Fast-Sent variant, and a Quick Thoughts variant -that outperform a pure MLM baseline. Finally, we demonstrate that using multiple tasks in a multi-task pre-training framework provides better results than using any single auxiliary task. Using these methods, we outperform BERT Base on the GLUE benchmark using fewer than a quarter of the training tokens.","losses modern language models bert set state - - - art result varied nlu benchmark pre - training task : mask language modelling ( mlm ) sentence prediction ( nsp ) , highly criticize . paper , 1 ) clarify nsp effect bert pre - training , 2 ) explore fourteen possible auxiliary pre - training task , seven novel modern language model , 3 ) investigate different way include multiple task pre - training . nsp detrimental training context splitting shallow semantic signal . identify auxiliary pre - training task -sentence ordering , adjacent sentence prediction , tf prediction , tf - idf prediction , fast - sent variant , quick thought variant -that outperform pure mlm baseline . finally , demonstrate multiple task multi - task pre - training framework provide well result single auxiliary task . method , outperform bert base glue benchmark few quarter training token .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,True
Machine Learning for NLP,A Simple Approach to Learning Unsupervised Multilingual Embeddings,"Recent progress on unsupervised cross-lingual embeddings in the bilingual setting has given the impetus to learning a shared embedding space for several languages. A popular framework to solve the latter problem is to solve the following two sub-problems jointly: 1) learning unsupervised word alignment between several language pairs, and 2) learning how to map the monolingual embeddings of every language to shared multilingual space. In contrast, we propose a simple approach by decoupling the above two sub-problems and solving them separately, one after another, using existing techniques. We show that this proposed approach obtains surprisingly good performance in tasks such as bilingual lexicon induction, cross-lingual word similarity, multilingual document classification, and multilingual dependency parsing. When distant languages are involved, the proposed approach shows robust behavior and outperforms existing unsupervised multilingual word embedding approaches.","A Simple Approach to Learning Unsupervised Multilingual Embeddings Recent progress on unsupervised cross-lingual embeddings in the bilingual setting has given the impetus to learning a shared embedding space for several languages. A popular framework to solve the latter problem is to solve the following two sub-problems jointly: 1) learning unsupervised word alignment between several language pairs, and 2) learning how to map the monolingual embeddings of every language to shared multilingual space. In contrast, we propose a simple approach by decoupling the above two sub-problems and solving them separately, one after another, using existing techniques. We show that this proposed approach obtains surprisingly good performance in tasks such as bilingual lexicon induction, cross-lingual word similarity, multilingual document classification, and multilingual dependency parsing. When distant languages are involved, the proposed approach shows robust behavior and outperforms existing unsupervised multilingual word embedding approaches.","simple approach learn unsupervised multilingual embedding recent progress unsupervised cross - lingual embedding bilingual setting give impetus learn share embedding space language . popular framework solve problem solve follow sub - problem jointly : 1 ) learn unsupervised word alignment language pair , 2 ) learn map monolingual embedding language share multilingual space . contrast , propose simple approach decouple sub - problem solve separately , , exist technique . propose approach obtain surprisingly good performance task bilingual lexicon induction , cross - lingual word similarity , multilingual document classification , multilingual dependency parsing . distant language involve , propose approach show robust behavior outperform exist unsupervised multilingual word embedding approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Improving Bilingual Lexicon Induction for Low Frequency Words,"This paper designs a Monolingual Lexicon Induction task and observes that two factors accompany the degraded accuracy of bilingual lexicon induction for rare words. First, a diminishing margin between similarities in low frequency regime, and secondly, exacerbated hubness at low frequency. Based on the observation, we further propose two methods to address these two factors, respectively. The larger issue is hubness. Addressing that improves induction accuracy significantly, especially for low-frequency words.","Improving Bilingual Lexicon Induction for Low Frequency Words This paper designs a Monolingual Lexicon Induction task and observes that two factors accompany the degraded accuracy of bilingual lexicon induction for rare words. First, a diminishing margin between similarities in low frequency regime, and secondly, exacerbated hubness at low frequency. Based on the observation, we further propose two methods to address these two factors, respectively. The larger issue is hubness. Addressing that improves induction accuracy significantly, especially for low-frequency words.","improve bilingual lexicon induction low frequency word paper design monolingual lexicon induction task observe factor accompany degrade accuracy bilingual lexicon induction rare word . , diminish margin similarity low frequency regime , secondly , exacerbate hubness low frequency . base observation , propose method address factor , respectively . large issue hubness . address improve induction accuracy significantly , especially low - frequency word .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Learning for NLP,Transformer Based Multi-Source Domain Adaptation,"In practical machine learning settings, the data on which a model must make predictions often come from a different distribution than the data it was trained on. Here, we investigate the problem of unsupervised multi-source domain adaptation, where a model is trained on labelled data from multiple source domains and must make predictions on a domain for which no labelled data has been seen. Prior work with CNNs and RNNs has demonstrated the benefit of mixture of experts, where the predictions of multiple domain expert classifiers are combined; as well as domain adversarial training, to induce a domain agnostic representation space. Inspired by this, we investigate how such methods can be effectively applied to large pretrained transformer models. We find that domain adversarial training has an effect on the learned representations of these models while having little effect on their performance, suggesting that large transformer-based models are already relatively robust across domains. Additionally, we show that mixture of experts leads to significant performance improvements by comparing several variants of mixing functions, including one novel mixture based on attention. Finally, we demonstrate that the predictions of large pretrained transformer based domain experts are highly homogenous, making it challenging to learn effective functions for mixing their predictions.","Transformer Based Multi-Source Domain Adaptation In practical machine learning settings, the data on which a model must make predictions often come from a different distribution than the data it was trained on. Here, we investigate the problem of unsupervised multi-source domain adaptation, where a model is trained on labelled data from multiple source domains and must make predictions on a domain for which no labelled data has been seen. Prior work with CNNs and RNNs has demonstrated the benefit of mixture of experts, where the predictions of multiple domain expert classifiers are combined; as well as domain adversarial training, to induce a domain agnostic representation space. Inspired by this, we investigate how such methods can be effectively applied to large pretrained transformer models. We find that domain adversarial training has an effect on the learned representations of these models while having little effect on their performance, suggesting that large transformer-based models are already relatively robust across domains. Additionally, we show that mixture of experts leads to significant performance improvements by comparing several variants of mixing functions, including one novel mixture based on attention. Finally, we demonstrate that the predictions of large pretrained transformer based domain experts are highly homogenous, making it challenging to learn effective functions for mixing their predictions.","transformer base multi - source domain adaptation practical machine learning setting , datum model prediction come different distribution datum train . , investigate problem unsupervised multi - source domain adaptation , model train label datum multiple source domain prediction domain label data see . prior work cnns rnns demonstrate benefit mixture expert , prediction multiple domain expert classifier combine ; domain adversarial training , induce domain agnostic representation space . inspire , investigate method effectively apply large pretrained transformer model . find domain adversarial training effect learn representation model have little effect performance , suggest large transformer - base model relatively robust domain . additionally , mixture expert lead significant performance improvement compare variant mix function , include novel mixture base attention . finally , demonstrate prediction large pretrained transformer base domain expert highly homogenous , make challenging learn effective function mix prediction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 7, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,True
Machine Learning for NLP,Sparse Parallel Training of Hierarchical Dirichlet Process Topic Models,"To scale non-parametric extensions of probabilistic topic models such as Latent Dirichlet allocation to larger data sets, practitioners rely increasingly on parallel and distributed systems. In this work, we study data-parallel training for the hierarchical Dirichlet process (HDP) topic model. Based upon a representation of certain conditional distributions within an HDP, we propose a doubly sparse data-parallel sampler for the HDP topic model. This sampler utilizes all available sources of sparsity found in natural language-an important way to make computation efficient. We benchmark our method on a well-known corpus (PubMed) with 8m documents and 768m tokens, using a single multi-core machine in under four days.","Sparse Parallel Training of Hierarchical Dirichlet Process Topic Models To scale non-parametric extensions of probabilistic topic models such as Latent Dirichlet allocation to larger data sets, practitioners rely increasingly on parallel and distributed systems. In this work, we study data-parallel training for the hierarchical Dirichlet process (HDP) topic model. Based upon a representation of certain conditional distributions within an HDP, we propose a doubly sparse data-parallel sampler for the HDP topic model. This sampler utilizes all available sources of sparsity found in natural language-an important way to make computation efficient. We benchmark our method on a well-known corpus (PubMed) with 8m documents and 768m tokens, using a single multi-core machine in under four days.","sparse parallel training hierarchical dirichlet process topic model scale non - parametric extension probabilistic topic model latent dirichlet allocation large data set , practitioner rely increasingly parallel distributed system . work , study data - parallel training hierarchical dirichlet process ( hdp ) topic model . base representation certain conditional distribution hdp , propose doubly sparse data - parallel sampler hdp topic model . sampler utilize available source sparsity find natural language - important way computation efficient . benchmark method - know corpus ( pubmed ) 8 m document 768 m token , single multi - core machine day .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 11, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 5, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Learning for NLP,Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction,"Semi-supervision is a promising paradigm for Bilingual Lexicon Induction (BLI) with limited annotations. However, previous semisupervised methods do not fully utilize the knowledge hidden in annotated and nonannotated data, which hinders further improvement of their performance. In this paper, we propose a new semi-supervised BLI framework to encourage the interaction between the supervised signal and unsupervised alignment. We design two message-passing mechanisms to transfer knowledge between annotated and non-annotated data, named prior optimal transport and bi-directional lexicon update respectively. Then, we perform semi-supervised learning based on a cyclic or a parallel parameter feeding routine to update our models. Our framework is a general framework that can incorporate any supervised and unsupervised BLI methods based on optimal transport. Experimental results on MUSE and VecMap datasets show significant improvement of our models. Ablation study also proves that the two-way interaction between the supervised signal and unsupervised alignment accounts for the gain of the overall performance. Results on distant language pairs further illustrate the advantage and robustness of our proposed method.","Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction Semi-supervision is a promising paradigm for Bilingual Lexicon Induction (BLI) with limited annotations. However, previous semisupervised methods do not fully utilize the knowledge hidden in annotated and nonannotated data, which hinders further improvement of their performance. In this paper, we propose a new semi-supervised BLI framework to encourage the interaction between the supervised signal and unsupervised alignment. We design two message-passing mechanisms to transfer knowledge between annotated and non-annotated data, named prior optimal transport and bi-directional lexicon update respectively. Then, we perform semi-supervised learning based on a cyclic or a parallel parameter feeding routine to update our models. Our framework is a general framework that can incorporate any supervised and unsupervised BLI methods based on optimal transport. Experimental results on MUSE and VecMap datasets show significant improvement of our models. Ablation study also proves that the two-way interaction between the supervised signal and unsupervised alignment accounts for the gain of the overall performance. Results on distant language pairs further illustrate the advantage and robustness of our proposed method.","semi - supervised bilingual lexicon induction - way interaction semi - supervision promising paradigm bilingual lexicon induction ( bli ) limited annotation . , previous semisupervised method fully utilize knowledge hide annotated nonannotated datum , hinder improvement performance . paper , propose new semi - supervised bli framework encourage interaction supervised signal unsupervised alignment . design message - pass mechanism transfer knowledge annotated non - annotated datum , name prior optimal transport bi - directional lexicon update respectively . , perform semi - supervised learning base cyclic parallel parameter feeding routine update model . framework general framework incorporate supervised unsupervised bli method base optimal transport . experimental result muse vecmap dataset significant improvement model . ablation study prove - way interaction supervised signal unsupervised alignment account gain overall performance . result distant language pair illustrate advantage robustness propose method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Learning for NLP,KERMIT: Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations,"Syntactic parsers have dominated natural language understanding for decades. Yet, their syntactic interpretations are losing centrality in downstream tasks due to the success of large-scale textual representation learners. In this paper, we propose KERMIT (Kernelinspired Encoder with Recursive Mechanism for Interpretable Trees) to embed symbolic syntactic parse trees into artificial neural networks and to visualize how syntax is used in inference. We experimented with KERMIT paired with two state-of-the-art transformerbased universal sentence encoders (BERT and XLNet) and we showed that KERMIT can indeed boost their performance by effectively embedding human-coded universal syntactic representations in neural networks.","KERMIT: Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations Syntactic parsers have dominated natural language understanding for decades. Yet, their syntactic interpretations are losing centrality in downstream tasks due to the success of large-scale textual representation learners. In this paper, we propose KERMIT (Kernelinspired Encoder with Recursive Mechanism for Interpretable Trees) to embed symbolic syntactic parse trees into artificial neural networks and to visualize how syntax is used in inference. We experimented with KERMIT paired with two state-of-the-art transformerbased universal sentence encoders (BERT and XLNet) and we showed that KERMIT can indeed boost their performance by effectively embedding human-coded universal syntactic representations in neural networks.","kermit : complement transformer architecture encoder explicit syntactic interpretation syntactic parser dominate natural language understanding decade . , syntactic interpretation lose centrality downstream task success large - scale textual representation learner . paper , propose kermit ( kernelinspired encoder recursive mechanism interpretable trees ) embed symbolic syntactic parse tree artificial neural network visualize syntax inference . experiment kermit pair state - - - art transformerbase universal sentence encoder ( bert xlnet ) show kermit boost performance effectively embed human - code universal syntactic representation neural network .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,True
Machine Learning for NLP,Learning Explainable Linguistic Expressions with Neural Inductive Logic Programming for Sentence Classification,"Interpretability of predictive models is becoming increasingly important with growing adoption in the real-world. We present RuleNN, a neural network architecture for learning transparent models for sentence classification. The models are in the form of rules expressed in first-order logic, a dialect with well-defined, human-understandable semantics. More precisely, RuleNN learns linguistic expressions (LE) built on top of predicates extracted using shallow natural language understanding. Our experimental results show that RuleNN outperforms statistical relational learning and other neuro-symbolic methods, and performs comparably with black-box recurrent neural networks. Our user studies confirm that the learned LEs are explainable and capture domain semantics. Moreover, allowing domain experts to modify LEs and instill more domain knowledge leads to human-machine cocreation of models with better performance. Inductive logic programming (ILP) (Muggleton, 1996) learns rules that perfectly entail the positive examples and reject all negatives. Top-down ILP systems (","Learning Explainable Linguistic Expressions with Neural Inductive Logic Programming for Sentence Classification Interpretability of predictive models is becoming increasingly important with growing adoption in the real-world. We present RuleNN, a neural network architecture for learning transparent models for sentence classification. The models are in the form of rules expressed in first-order logic, a dialect with well-defined, human-understandable semantics. More precisely, RuleNN learns linguistic expressions (LE) built on top of predicates extracted using shallow natural language understanding. Our experimental results show that RuleNN outperforms statistical relational learning and other neuro-symbolic methods, and performs comparably with black-box recurrent neural networks. Our user studies confirm that the learned LEs are explainable and capture domain semantics. Moreover, allowing domain experts to modify LEs and instill more domain knowledge leads to human-machine cocreation of models with better performance. Inductive logic programming (ILP) (Muggleton, 1996) learns rules that perfectly entail the positive examples and reject all negatives. Top-down ILP systems (","learn explainable linguistic expression neural inductive logic programming sentence classification interpretability predictive model increasingly important grow adoption real - world . present rulenn , neural network architecture learn transparent model sentence classification . model form rule express - order logic , dialect - define , human - understandable semantic . precisely , rulenn learn linguistic expression ( le ) build predicate extract shallow natural language understanding . experimental result rulenn outperform statistical relational learning neuro - symbolic method , perform comparably black - box recurrent neural network . user study confirm learn le explainable capture domain semantic . , allow domain expert modify le instill domain knowledge lead human - machine cocreation model well performance . inductive logic programming ( ilp ) ( muggleton , 1996 ) learn rule perfectly entail positive example reject negative . - ilp system (","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Bootstrapped Q-learning with Context Relevant Observation Pruning to Generalize in Text-based Games,"We show that Reinforcement Learning (RL) methods for solving Text-Based Games (TBGs) often fail to generalize on unseen games, especially in small data regimes. To address this issue, we propose Context Relevant Episodic State Truncation (CREST) for irrelevant token removal in observation text for improved generalization. Our method first trains a base model using Q-learning, which typically overfits the training games. The base model's action token distribution is used to perform observation pruning that removes irrelevant tokens. A second bootstrapped model is then retrained on the pruned observation text. Our bootstrapped agent shows improved generalization in solving unseen TextWorld games, using 10x-20x fewer training games compared to previous state-of-the-art (SOTA) methods despite requiring fewer number of training episodes. 1","Bootstrapped Q-learning with Context Relevant Observation Pruning to Generalize in Text-based Games We show that Reinforcement Learning (RL) methods for solving Text-Based Games (TBGs) often fail to generalize on unseen games, especially in small data regimes. To address this issue, we propose Context Relevant Episodic State Truncation (CREST) for irrelevant token removal in observation text for improved generalization. Our method first trains a base model using Q-learning, which typically overfits the training games. The base model's action token distribution is used to perform observation pruning that removes irrelevant tokens. A second bootstrapped model is then retrained on the pruned observation text. Our bootstrapped agent shows improved generalization in solving unseen TextWorld games, using 10x-20x fewer training games compared to previous state-of-the-art (SOTA) methods despite requiring fewer number of training episodes. 1","bootstrappe q - learning context relevant observation pruning generalize text - base game reinforcement learning ( rl ) method solve text - base games ( tbgs ) fail generalize unseen game , especially small datum regime . address issue , propose context relevant episodic state truncation ( crest ) irrelevant token removal observation text improve generalization . method train base model q - learning , typically overfit training game . base model action token distribution perform observation pruning remove irrelevant token . second bootstrappe model retrain prune observation text . bootstrappe agent show improve generalization solve unseen textworld game , 10x-20x few training game compare previous state - - - art ( sota ) method despite require few number training episode . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,An Exploration of Arbitrary-Order Sequence Labeling via Energy-Based Inference Networks,"Many tasks in natural language processing involve predicting structured outputs, e.g., sequence labeling, semantic role labeling, parsing, and machine translation. Researchers are increasingly applying deep representation learning to these problems, but the structured component of these approaches is usually quite simplistic. In this work, we propose several high-order energy terms to capture complex dependencies among labels in sequence labeling, including several that consider the entire label sequence. We use neural parameterizations for these energy terms, drawing from convolutional, recurrent, and selfattention networks. We use the framework of learning energy-based inference networks (Tu and Gimpel, 2018) for dealing with the difficulties of training and inference with such models. We empirically demonstrate that this approach achieves substantial improvement using a variety of high-order energy terms on four sequence labeling tasks, while having the same decoding speed as simple, local classifiers. We also find high-order energies to help in noisy data conditions. 1","An Exploration of Arbitrary-Order Sequence Labeling via Energy-Based Inference Networks Many tasks in natural language processing involve predicting structured outputs, e.g., sequence labeling, semantic role labeling, parsing, and machine translation. Researchers are increasingly applying deep representation learning to these problems, but the structured component of these approaches is usually quite simplistic. In this work, we propose several high-order energy terms to capture complex dependencies among labels in sequence labeling, including several that consider the entire label sequence. We use neural parameterizations for these energy terms, drawing from convolutional, recurrent, and selfattention networks. We use the framework of learning energy-based inference networks (Tu and Gimpel, 2018) for dealing with the difficulties of training and inference with such models. We empirically demonstrate that this approach achieves substantial improvement using a variety of high-order energy terms on four sequence labeling tasks, while having the same decoding speed as simple, local classifiers. We also find high-order energies to help in noisy data conditions. 1","exploration arbitrary - order sequence labeling energy - base inference network task natural language processing involve predict structured output , e.g. , sequence labeling , semantic role labeling , parsing , machine translation . researcher increasingly apply deep representation learning problem , structured component approach usually simplistic . work , propose high - order energy term capture complex dependency label sequence labeling , include consider entire label sequence . use neural parameterization energy term , draw convolutional , recurrent , selfattention network . use framework learn energy - base inference network ( tu gimpel , 2018 ) deal difficulty train inference model . empirically demonstrate approach achieve substantial improvement variety high - order energy term sequence labeling task , have decoding speed simple , local classifier . find high - order energy help noisy data condition . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Adversarial Self-Supervised Data-Free Distillation for Text Classification,"Large pre-trained transformer-based language models have achieved impressive results on a wide range of NLP tasks. In the past few years, Knowledge Distillation(KD) has become a popular paradigm to compress a computationally expensive model to a resource-efficient lightweight model. However, most KD algorithms, especially in NLP, rely on the accessibility of the original training dataset, which may be unavailable due to privacy issues. To tackle this problem, we propose a novel twostage data-free distillation method, named Adversarial self-Supervised Data-Free Distillation (AS-DFD), which is designed for compressing large-scale transformer-based models (e.g., BERT). To avoid text generation in discrete space, we introduce a Plug & Play Embedding Guessing method to craft pseudo embeddings from the teacher's hidden knowledge. Meanwhile, with a self-supervised module to quantify the student's ability, we adapt the difficulty of pseudo embeddings in an adversarial training manner. To the best of our knowledge, our framework is the first data-free distillation framework designed for NLP tasks. We verify the effectiveness of our method on several text classification datasets.","Adversarial Self-Supervised Data-Free Distillation for Text Classification Large pre-trained transformer-based language models have achieved impressive results on a wide range of NLP tasks. In the past few years, Knowledge Distillation(KD) has become a popular paradigm to compress a computationally expensive model to a resource-efficient lightweight model. However, most KD algorithms, especially in NLP, rely on the accessibility of the original training dataset, which may be unavailable due to privacy issues. To tackle this problem, we propose a novel twostage data-free distillation method, named Adversarial self-Supervised Data-Free Distillation (AS-DFD), which is designed for compressing large-scale transformer-based models (e.g., BERT). To avoid text generation in discrete space, we introduce a Plug & Play Embedding Guessing method to craft pseudo embeddings from the teacher's hidden knowledge. Meanwhile, with a self-supervised module to quantify the student's ability, we adapt the difficulty of pseudo embeddings in an adversarial training manner. To the best of our knowledge, our framework is the first data-free distillation framework designed for NLP tasks. We verify the effectiveness of our method on several text classification datasets.","adversarial self - supervised data - free distillation text classification large pre - trained transformer - base language model achieve impressive result wide range nlp task . past year , knowledge distillation(kd ) popular paradigm compress computationally expensive model resource - efficient lightweight model . , kd algorithm , especially nlp , rely accessibility original training dataset , unavailable privacy issue . tackle problem , propose novel twostage data - free distillation method , name adversarial self - supervised data - free distillation ( - dfd ) , design compress large - scale transformer - base model ( e.g. , bert ) . avoid text generation discrete space , introduce plug & play embedding guessing method craft pseudo embedding teacher hide knowledge . , self - supervise module quantify student ability , adapt difficulty pseudo embedding adversarial training manner . good knowledge , framework data - free distillation framework design nlp task . verify effectiveness method text classification dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Autoregressive Knowledge Distillation through Imitation Learning,"The performance of autoregressive models on natural language generation tasks has dramatically improved due to the adoption of deep, self-attentive architectures. However, these gains have come at the cost of hindering inference speed, making state-of-the-art models cumbersome to deploy in real-world, timesensitive settings. We develop a compression technique for autoregressive models that is driven by an imitation learning perspective on knowledge distillation. The algorithm is designed to address the exposure bias problem. On prototypical language generation tasks such as translation and summarization, our method consistently outperforms other distillation algorithms, such as sequence-level knowledge distillation. Student models trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those trained from scratch, while increasing inference speed by up to 14 times in comparison to the teacher model. 1","Autoregressive Knowledge Distillation through Imitation Learning The performance of autoregressive models on natural language generation tasks has dramatically improved due to the adoption of deep, self-attentive architectures. However, these gains have come at the cost of hindering inference speed, making state-of-the-art models cumbersome to deploy in real-world, timesensitive settings. We develop a compression technique for autoregressive models that is driven by an imitation learning perspective on knowledge distillation. The algorithm is designed to address the exposure bias problem. On prototypical language generation tasks such as translation and summarization, our method consistently outperforms other distillation algorithms, such as sequence-level knowledge distillation. Student models trained with our method attain 1.4 to 4.8 BLEU/ROUGE points higher than those trained from scratch, while increasing inference speed by up to 14 times in comparison to the teacher model. 1","autoregressive knowledge distillation imitation learning performance autoregressive model natural language generation task dramatically improve adoption deep , self - attentive architecture . , gain come cost hinder inference speed , make state - - - art model cumbersome deploy real - world , timesensitive setting . develop compression technique autoregressive model drive imitation learning perspective knowledge distillation . algorithm design address exposure bias problem . prototypical language generation task translation summarization , method consistently outperform distillation algorithm , sequence - level knowledge distillation . student model train method attain 1.4 4.8 bleu / rouge point high train scratch , increase inference speed 14 time comparison teacher model . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,TernaryBERT: Distillation-aware Ultra-low Bit BERT,"Transformer-based pre-training models like BERT have achieved remarkable performance in many natural language processing tasks. However, these models are both computation and memory expensive, hindering their deployment to resource-constrained devices. In this work, we propose TernaryBERT, which ternarizes the weights in a fine-tuned BERT model. Specifically, we use both approximation-based and loss-aware ternarization methods and empirically investigate the ternarization granularity of different parts of BERT. Moreover, to reduce the accuracy degradation caused by the lower capacity of low bits, we leverage the knowledge distillation technique (Jiao et al., 2019) in the training process. Experiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT outperforms the other BERT quantization methods, and even achieves comparable performance as the fullprecision model while being 14.9x smaller.","TernaryBERT: Distillation-aware Ultra-low Bit BERT Transformer-based pre-training models like BERT have achieved remarkable performance in many natural language processing tasks. However, these models are both computation and memory expensive, hindering their deployment to resource-constrained devices. In this work, we propose TernaryBERT, which ternarizes the weights in a fine-tuned BERT model. Specifically, we use both approximation-based and loss-aware ternarization methods and empirically investigate the ternarization granularity of different parts of BERT. Moreover, to reduce the accuracy degradation caused by the lower capacity of low bits, we leverage the knowledge distillation technique (Jiao et al., 2019) in the training process. Experiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT outperforms the other BERT quantization methods, and even achieves comparable performance as the fullprecision model while being 14.9x smaller.","ternarybert : distillation - aware ultra - low bit bert transformer - base pre - training model like bert achieve remarkable performance natural language processing task . , model computation memory expensive , hinder deployment resource - constrain device . work , propose ternarybert , ternarize weight fine - tune bert model . specifically , use approximation - base loss - aware ternarization method empirically investigate ternarization granularity different part bert . , reduce accuracy degradation cause low capacity low bit , leverage knowledge distillation technique ( jiao et al . , 2019 ) training process . experiment glue benchmark squad propose ternarybert outperform bert quantization method , achieve comparable performance fullprecision model 14.9x small .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Contrastive Distillation on Intermediate Representations for Language Model Compression,"Existing language model compression methods mostly use a simple L 2 loss to distill knowledge in the intermediate representations of a large BERT model to a smaller one. Although widely used, this objective by design assumes that all the dimensions of hidden representations are independent, failing to capture important structural knowledge in the intermediate layers of the teacher network. To achieve better distillation efficacy, we propose Contrastive Distillation on Intermediate Representations (CODIR), a principled knowledge distillation framework where the student is trained to distill knowledge through intermediate layers of the teacher via a contrastive objective. By learning to distinguish positive sample from a large set of negative samples, CoDIR facilitates the student's exploitation of rich information in teacher's hidden layers. CoDIR can be readily applied to compress large-scale language models in both pretraining and finetuning stages, and achieves superb performance on the GLUE benchmark, outperforming state-of-the-art compression methods. 1  Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In ICCV.","Contrastive Distillation on Intermediate Representations for Language Model Compression Existing language model compression methods mostly use a simple L 2 loss to distill knowledge in the intermediate representations of a large BERT model to a smaller one. Although widely used, this objective by design assumes that all the dimensions of hidden representations are independent, failing to capture important structural knowledge in the intermediate layers of the teacher network. To achieve better distillation efficacy, we propose Contrastive Distillation on Intermediate Representations (CODIR), a principled knowledge distillation framework where the student is trained to distill knowledge through intermediate layers of the teacher via a contrastive objective. By learning to distinguish positive sample from a large set of negative samples, CoDIR facilitates the student's exploitation of rich information in teacher's hidden layers. CoDIR can be readily applied to compress large-scale language models in both pretraining and finetuning stages, and achieves superb performance on the GLUE benchmark, outperforming state-of-the-art compression methods. 1  Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. In ICCV.","contrastive distillation intermediate representations language model compression exist language model compression method use simple l 2 loss distill knowledge intermediate representation large bert model small . widely , objective design assume dimension hide representation independent , fail capture important structural knowledge intermediate layer teacher network . achieve well distillation efficacy , propose contrastive distillation intermediate representations ( codir ) , principled knowledge distillation framework student train distill knowledge intermediate layer teacher contrastive objective . learn distinguish positive sample large set negative sample , codir facilitate student exploitation rich information teacher hide layer . codir readily apply compress large - scale language model pretraine finetune stage , achieve superb performance glue benchmark , outperform state - - - art compression method . 1   yukun zhu , ryan kiros , rich zemel , ruslan salakhutdinov , raquel urtasun , antonio torralba , sanja fidler . 2015 . align book movie : story - like visual explanation watch movie read book . iccv .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Sequence-Level Mixed Sample Data Augmentation,"Despite their empirical success, neural networks still have difficulty capturing compositional aspects of natural language. This work proposes a simple data augmentation approach to encourage compositional behavior in neural models for sequence-to-sequence problems. Our approach, SeqMix, creates new synthetic examples by softly combining input/output sequences from the training set. We connect this approach to existing techniques such as SwitchOut (Wang et al., 2018) and word dropout (Sennrich et al., 2016) , and show that these techniques are all approximating variants of a single objective. SeqMix consistently yields approximately 1.0 BLEU improvement on five different translation datasets over strong Transformer baselines. On tasks that require strong compositional generalization such as SCAN and semantic parsing, Se-qMix also offers further improvements.","Sequence-Level Mixed Sample Data Augmentation Despite their empirical success, neural networks still have difficulty capturing compositional aspects of natural language. This work proposes a simple data augmentation approach to encourage compositional behavior in neural models for sequence-to-sequence problems. Our approach, SeqMix, creates new synthetic examples by softly combining input/output sequences from the training set. We connect this approach to existing techniques such as SwitchOut (Wang et al., 2018) and word dropout (Sennrich et al., 2016) , and show that these techniques are all approximating variants of a single objective. SeqMix consistently yields approximately 1.0 BLEU improvement on five different translation datasets over strong Transformer baselines. On tasks that require strong compositional generalization such as SCAN and semantic parsing, Se-qMix also offers further improvements.","sequence - level mixed sample datum augmentation despite empirical success , neural network difficulty capture compositional aspect natural language . work propose simple data augmentation approach encourage compositional behavior neural model sequence - - sequence problem . approach , seqmix , create new synthetic example softly combine input / output sequence training set . connect approach exist technique switchout ( wang et al . , 2018 ) word dropout ( sennrich et al . , 2016 ) , technique approximate variant single objective . seqmix consistently yield approximately 1.0 bleu improvement different translation dataset strong transformer baseline . task require strong compositional generalization scan semantic parsing , se - qmix offer improvement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Machine Learning for NLP,Structure Aware Negative Sampling in Knowledge Graphs,"Learning low-dimensional representations for entities and relations in knowledge graphs using contrastive estimation represents a scalable and effective method for inferring connectivity patterns. A crucial aspect of contrastive learning approaches is the choice of corruption distribution that generates hard negative samples, which force the embedding model to learn discriminative representations and find critical characteristics of observed data. While earlier methods either employ too simple corruption distributions, i.e. uniform, yielding easy uninformative negatives or sophisticated adversarial distributions with challenging optimization schemes, they do not explicitly incorporate known graph structure resulting in suboptimal negatives. In this paper, we propose Structure Aware Negative Sampling (SANS), an inexpensive negative sampling strategy that utilizes the rich graph structure by selecting negative samples from a node's k-hop neighborhood. Empirically, we demonstrate that SANS finds semantically meaningful negatives and is competitive with SOTA approaches while requires no additional parameters nor difficult adversarial optimization.","Structure Aware Negative Sampling in Knowledge Graphs Learning low-dimensional representations for entities and relations in knowledge graphs using contrastive estimation represents a scalable and effective method for inferring connectivity patterns. A crucial aspect of contrastive learning approaches is the choice of corruption distribution that generates hard negative samples, which force the embedding model to learn discriminative representations and find critical characteristics of observed data. While earlier methods either employ too simple corruption distributions, i.e. uniform, yielding easy uninformative negatives or sophisticated adversarial distributions with challenging optimization schemes, they do not explicitly incorporate known graph structure resulting in suboptimal negatives. In this paper, we propose Structure Aware Negative Sampling (SANS), an inexpensive negative sampling strategy that utilizes the rich graph structure by selecting negative samples from a node's k-hop neighborhood. Empirically, we demonstrate that SANS finds semantically meaningful negatives and is competitive with SOTA approaches while requires no additional parameters nor difficult adversarial optimization.","structure aware negative sampling knowledge graph learn low - dimensional representation entity relation knowledge graph contrastive estimation represent scalable effective method infer connectivity pattern . crucial aspect contrastive learning approach choice corruption distribution generate hard negative sample , force embed model learn discriminative representation find critical characteristic observe datum . early method employ simple corruption distribution , i.e. uniform , yield easy uninformative negative sophisticated adversarial distribution challenging optimization scheme , explicitly incorporate know graph structure result suboptimal negative . paper , propose structure aware negative sampling ( sans ) , inexpensive negative sampling strategy utilize rich graph structure select negative sample node k - hop neighborhood . empirically , demonstrate sans find semantically meaningful negative competitive sota approach require additional parameter difficult adversarial optimization .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Grounded Compositional Outputs for Adaptive Language Modeling,"Language models have emerged as a central component across NLP, and a great deal of progress depends on the ability to cheaply adapt them (e.g., through finetuning) to new domains and tasks. A language model's vocabulary-typically selected before training and permanently fixed later-affects its size and is part of what makes it resistant to such adaptation. Prior work has used compositional input embeddings based on surface forms to ameliorate this issue. In this work, we go one step beyond and propose a fully compositional output embedding layer for language models, which is further grounded in information from a structured lexicon (WordNet), namely semantically related words and free-text definitions. To our knowledge, the result is the first word-level language model with a size that does not depend on the training vocabulary. We evaluate the model on conventional language modeling as well as challenging cross-domain settings with an open vocabulary, finding that it matches or outperforms previous state-of-theart output embedding methods and adaptation approaches. Our analysis attributes the improvements to sample efficiency: our model is more accurate for low-frequency words.","Grounded Compositional Outputs for Adaptive Language Modeling Language models have emerged as a central component across NLP, and a great deal of progress depends on the ability to cheaply adapt them (e.g., through finetuning) to new domains and tasks. A language model's vocabulary-typically selected before training and permanently fixed later-affects its size and is part of what makes it resistant to such adaptation. Prior work has used compositional input embeddings based on surface forms to ameliorate this issue. In this work, we go one step beyond and propose a fully compositional output embedding layer for language models, which is further grounded in information from a structured lexicon (WordNet), namely semantically related words and free-text definitions. To our knowledge, the result is the first word-level language model with a size that does not depend on the training vocabulary. We evaluate the model on conventional language modeling as well as challenging cross-domain settings with an open vocabulary, finding that it matches or outperforms previous state-of-theart output embedding methods and adaptation approaches. Our analysis attributes the improvements to sample efficiency: our model is more accurate for low-frequency words.","grounded compositional output adaptive language modeling language model emerge central component nlp , great deal progress depend ability cheaply adapt ( e.g. , finetuning ) new domain task . language model vocabulary - typically select training permanently fix later - affect size make resistant adaptation . prior work compositional input embedding base surface form ameliorate issue . work , step propose fully compositional output embedding layer language model , ground information structured lexicon ( wordnet ) , semantically relate word free - text definition . knowledge , result word - level language model size depend training vocabulary . evaluate model conventional language modeling challenge cross - domain setting open vocabulary , find match outperform previous state - - theart output embedding method adaptation approach . analysis attribute improvement sample efficiency : model accurate low - frequency word .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks,"Self-supervised pre-training of transformer models has revolutionized NLP applications. Such pre-training with language modeling objectives provides a useful initial point for parameters that generalize well to new tasks with fine-tuning. However, fine-tuning is still data inefficient -when there are few labeled examples, accuracy can be low. Data efficiency can be improved by optimizing pre-training directly for future fine-tuning with few examples; this can be treated as a meta-learning problem. However, standard meta-learning techniques require many training tasks in order to generalize; unfortunately, finding a diverse set of such supervised tasks is usually difficult. This paper proposes a self-supervised approach to generate a large, rich, metalearning task distribution from unlabeled text. This is achieved using a cloze-style objective, but creating separate multi-class classification tasks by gathering tokens-to-be blanked from among only a handful of vocabulary terms. This yields as many unique meta-training tasks as the number of subsets of vocabulary terms. We meta-train a transformer model on this distribution of tasks using a recent meta-learning framework. On 17 NLP tasks, we show that this meta-training leads to better few-shot generalization than language-model pre-training followed by finetuning. Furthermore, we show how the self-supervised tasks can be combined with supervised tasks for meta-learning, providing substantial accuracy gains over previous supervised meta-learning.","Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks Self-supervised pre-training of transformer models has revolutionized NLP applications. Such pre-training with language modeling objectives provides a useful initial point for parameters that generalize well to new tasks with fine-tuning. However, fine-tuning is still data inefficient -when there are few labeled examples, accuracy can be low. Data efficiency can be improved by optimizing pre-training directly for future fine-tuning with few examples; this can be treated as a meta-learning problem. However, standard meta-learning techniques require many training tasks in order to generalize; unfortunately, finding a diverse set of such supervised tasks is usually difficult. This paper proposes a self-supervised approach to generate a large, rich, metalearning task distribution from unlabeled text. This is achieved using a cloze-style objective, but creating separate multi-class classification tasks by gathering tokens-to-be blanked from among only a handful of vocabulary terms. This yields as many unique meta-training tasks as the number of subsets of vocabulary terms. We meta-train a transformer model on this distribution of tasks using a recent meta-learning framework. On 17 NLP tasks, we show that this meta-training leads to better few-shot generalization than language-model pre-training followed by finetuning. Furthermore, we show how the self-supervised tasks can be combined with supervised tasks for meta-learning, providing substantial accuracy gains over previous supervised meta-learning.","self - supervised meta - learning - shot natural language classification task self - supervised pre - training transformer model revolutionize nlp application . pre - training language modeling objective provide useful initial point parameter generalize new task fine - tuning . , fine - tuning data inefficient -when label example , accuracy low . data efficiency improve optimize pre - train directly future fine - tuning example ; treat meta - learning problem . , standard meta - learn technique require training task order generalize ; unfortunately , find diverse set supervise task usually difficult . paper propose self - supervise approach generate large , rich , metalearning task distribution unlabeled text . achieve cloze - style objective , create separate multi - class classification task gather token - - blank handful vocabulary term . yield unique meta - training task number subset vocabulary term . meta - train transformer model distribution task recent meta - learning framework . 17 nlp task , meta - training lead well - shot generalization language - model pre - training follow finetuning . furthermore , self - supervise task combine supervise task meta - learning , provide substantial accuracy gain previous supervised meta - learning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Scaling Hidden Markov Language Models,"The hidden Markov model (HMM) is a fundamental tool for sequence modeling that cleanly separates the hidden state from the emission structure. However, this separation makes it difficult to fit HMMs to large datasets in modern NLP, and they have fallen out of use due to very poor performance compared to fully observed models. This work revisits the challenge of scaling HMMs to language modeling datasets, taking ideas from recent approaches to neural modeling. We propose methods for scaling HMMs to massive state spaces while maintaining efficient exact inference, a compact parameterization, and effective regularization. Experiments show that this approach leads to models that are more accurate than previous HMM and n-gram-based methods, making progress towards the performance of state-of-the-art neural models.","Scaling Hidden Markov Language Models The hidden Markov model (HMM) is a fundamental tool for sequence modeling that cleanly separates the hidden state from the emission structure. However, this separation makes it difficult to fit HMMs to large datasets in modern NLP, and they have fallen out of use due to very poor performance compared to fully observed models. This work revisits the challenge of scaling HMMs to language modeling datasets, taking ideas from recent approaches to neural modeling. We propose methods for scaling HMMs to massive state spaces while maintaining efficient exact inference, a compact parameterization, and effective regularization. Experiments show that this approach leads to models that are more accurate than previous HMM and n-gram-based methods, making progress towards the performance of state-of-the-art neural models.","scale hide markov language model hidden markov model ( hmm ) fundamental tool sequence modeling cleanly separate hidden state emission structure . , separation make difficult fit hmms large dataset modern nlp , fall use poor performance compare fully observe model . work revisit challenge scale hmms language modeling dataset , take idea recent approach neural modeling . propose method scale hmms massive state space maintain efficient exact inference , compact parameterization , effective regularization . experiment approach lead model accurate previous hmm n - gram - base method , make progress performance state - - - art neural model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Learning for NLP,Learning from Task Descriptions,"Typically, machine learning systems solve new tasks by training on thousands of examples. In contrast, humans can solve new tasks by reading some instructions, with perhaps an example or two. To take a step toward closing this gap, we introduce a framework for developing NLP systems that solve new tasks after reading their descriptions, synthesizing prior work in this area. We instantiate this framework with a new English language dataset, ZEST, structured for task-oriented evaluation on unseen tasks. Formulating task descriptions as questions, we ensure each is general enough to apply to many possible inputs, thus comprehensively evaluating a model's ability to solve each task. Moreover, the dataset's structure tests specific types of systematic generalization. We find that the state-of-the-art T5 model achieves a score of 12% on ZEST, leaving a significant challenge for NLP researchers. 1","Learning from Task Descriptions Typically, machine learning systems solve new tasks by training on thousands of examples. In contrast, humans can solve new tasks by reading some instructions, with perhaps an example or two. To take a step toward closing this gap, we introduce a framework for developing NLP systems that solve new tasks after reading their descriptions, synthesizing prior work in this area. We instantiate this framework with a new English language dataset, ZEST, structured for task-oriented evaluation on unseen tasks. Formulating task descriptions as questions, we ensure each is general enough to apply to many possible inputs, thus comprehensively evaluating a model's ability to solve each task. Moreover, the dataset's structure tests specific types of systematic generalization. We find that the state-of-the-art T5 model achieves a score of 12% on ZEST, leaving a significant challenge for NLP researchers. 1","learn task description typically , machine learning system solve new task train thousand example . contrast , human solve new task read instruction , example . step close gap , introduce framework develop nlp system solve new task read description , synthesize prior work area . instantiate framework new english language dataset , zest , structure task - orient evaluation unseen task . formulate task description question , ensure general apply possible input , comprehensively evaluate model ability solve task . , dataset structure test specific type systematic generalization . find state - - - art t5 model achieve score 12 % zest , leave significant challenge nlp researcher . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Machine Learning for NLP,Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation,"Bolukbasi et al. (2016) presents one of the first gender bias mitigation techniques for word embeddings. Their method takes pre-trained word embeddings as input and attempts to isolate a linear subspace that captures most of the gender bias in the embeddings. As judged by an analogical evaluation task, their method virtually eliminates gender bias in the embeddings. However, an implicit and untested assumption of their method is that the bias subspace is actually linear. In this work, we generalize their method to a kernelized, non-linear version. We take inspiration from kernel principal component analysis and derive a nonlinear bias isolation technique. We discuss and overcome some of the practical drawbacks of our method for non-linear gender bias mitigation in word embeddings and analyze empirically whether the bias subspace is actually linear. Our analysis shows that gender bias is in fact well captured by a linear subspace, justifying the assumption of Bolukbasi et al. (2016) .","Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation Bolukbasi et al. (2016) presents one of the first gender bias mitigation techniques for word embeddings. Their method takes pre-trained word embeddings as input and attempts to isolate a linear subspace that captures most of the gender bias in the embeddings. As judged by an analogical evaluation task, their method virtually eliminates gender bias in the embeddings. However, an implicit and untested assumption of their method is that the bias subspace is actually linear. In this work, we generalize their method to a kernelized, non-linear version. We take inspiration from kernel principal component analysis and derive a nonlinear bias isolation technique. We discuss and overcome some of the practical drawbacks of our method for non-linear gender bias mitigation in word embeddings and analyze empirically whether the bias subspace is actually linear. Our analysis shows that gender bias is in fact well captured by a linear subspace, justifying the assumption of Bolukbasi et al. (2016) .","explore linear subspace hypothesis gender bias mitigation bolukbasi et al . ( 2016 ) present gender bias mitigation technique word embedding . method take pre - trained word embedding input attempt isolate linear subspace capture gender bias embedding . judge analogical evaluation task , method virtually eliminate gender bias embedding . , implicit untested assumption method bias subspace actually linear . work , generalize method kernelize , non - linear version . inspiration kernel principal component analysis derive nonlinear bias isolation technique . discuss overcome practical drawback method non - linear gender bias mitigation word embedding analyze empirically bias subspace actually linear . analysis show gender bias fact capture linear subspace , justify assumption bolukbasi et al . ( 2016 ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 27, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Machine Learning for NLP,T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack,"Adversarial attacks against natural language processing systems, which perform seemingly innocuous modifications to inputs, can induce arbitrary mistakes to the target models. Though raised great concerns, such adversarial attacks can be leveraged to estimate the robustness of NLP models. Compared with the adversarial example generation in continuous data domain (e.g., image), generating adversarial text that preserves the original meaning is challenging since the text space is discrete and non-differentiable. To handle these challenges, we propose a target-controllable adversarial attack framework T3, which is applicable to a range of NLP tasks. In particular, we propose a tree-based autoencoder to embed the discrete text data into a continuous representation space, upon which we optimize the adversarial perturbation. A novel tree-based decoder is then applied to regularize the syntactic correctness of the generated text and manipulate it on either sentence (T3(SENT)) or word (T3(WORD)) level. We consider two most representative NLP tasks: sentiment analysis and question answering (QA). Extensive experimental results and human studies show that T3 generated adversarial texts can successfully manipulate the NLP models to output the targeted incorrect answer without misleading the human. Moreover, we show that the generated adversarial texts have high transferability which enables the black-box attacks in practice. Our work sheds light on an effective and general way to examine the robustness of NLP models. Our code is publicly available at https://github.com/AI-secure/T3/.","T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack Adversarial attacks against natural language processing systems, which perform seemingly innocuous modifications to inputs, can induce arbitrary mistakes to the target models. Though raised great concerns, such adversarial attacks can be leveraged to estimate the robustness of NLP models. Compared with the adversarial example generation in continuous data domain (e.g., image), generating adversarial text that preserves the original meaning is challenging since the text space is discrete and non-differentiable. To handle these challenges, we propose a target-controllable adversarial attack framework T3, which is applicable to a range of NLP tasks. In particular, we propose a tree-based autoencoder to embed the discrete text data into a continuous representation space, upon which we optimize the adversarial perturbation. A novel tree-based decoder is then applied to regularize the syntactic correctness of the generated text and manipulate it on either sentence (T3(SENT)) or word (T3(WORD)) level. We consider two most representative NLP tasks: sentiment analysis and question answering (QA). Extensive experimental results and human studies show that T3 generated adversarial texts can successfully manipulate the NLP models to output the targeted incorrect answer without misleading the human. Moreover, we show that the generated adversarial texts have high transferability which enables the black-box attacks in practice. Our work sheds light on an effective and general way to examine the robustness of NLP models. Our code is publicly available at https://github.com/AI-secure/T3/.","t3 : tree - autoencoder constrain adversarial text generation target attack adversarial attack natural language process system , perform seemingly innocuous modification input , induce arbitrary mistake target model . raise great concern , adversarial attack leverage estimate robustness nlp model . compare adversarial example generation continuous datum domain ( e.g. , image ) , generate adversarial text preserve original meaning challenging text space discrete non - differentiable . handle challenge , propose target - controllable adversarial attack framework t3 , applicable range nlp task . particular , propose tree - base autoencoder embed discrete text datum continuous representation space , optimize adversarial perturbation . novel tree - base decoder apply regularize syntactic correctness generate text manipulate sentence ( t3(sent ) ) word ( t3(word ) ) level . consider representative nlp task : sentiment analysis question answering ( qa ) . extensive experimental result human study t3 generate adversarial text successfully manipulate nlp model output target incorrect answer mislead human . , generate adversarial text high transferability enable black - box attack practice . work shed light effective general way examine robustness nlp model . code publicly available https://github.com/ai-secure/t3/.","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 14, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 7, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 1, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Be More with Less: Hypergraph Attention Networks for Inductive Text Classification,"Text classification is a critical research topic with broad applications in natural language processing. Recently, graph neural networks (GNNs) have received increasing attention in the research community and demonstrated their promising results on this canonical task. Despite the success, their performance could be largely jeopardized in practice since they are: (1) unable to capture high-order interaction between words; (2) inefficient to handle large datasets and new documents. To address those issues, in this paper, we propose a principled model -hypergraph attention networks (HyperGAT), which can obtain more expressive power with less computational consumption for text representation learning. Extensive experiments on various benchmark datasets demonstrate the efficacy of the proposed approach on the text classification task.","Be More with Less: Hypergraph Attention Networks for Inductive Text Classification Text classification is a critical research topic with broad applications in natural language processing. Recently, graph neural networks (GNNs) have received increasing attention in the research community and demonstrated their promising results on this canonical task. Despite the success, their performance could be largely jeopardized in practice since they are: (1) unable to capture high-order interaction between words; (2) inefficient to handle large datasets and new documents. To address those issues, in this paper, we propose a principled model -hypergraph attention networks (HyperGAT), which can obtain more expressive power with less computational consumption for text representation learning. Extensive experiments on various benchmark datasets demonstrate the efficacy of the proposed approach on the text classification task.",": hypergraph attention networks inductive text classification text classification critical research topic broad application natural language processing . recently , graph neural network ( gnns ) receive increase attention research community demonstrate promising result canonical task . despite success , performance largely jeopardize practice : ( 1 ) unable capture high - order interaction word ; ( 2 ) inefficient handle large dataset new document . address issue , paper , propose principled model -hypergraph attention network ( hypergat ) , obtain expressive power computational consumption text representation learning . extensive experiment benchmark dataset demonstrate efficacy propose approach text classification task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Learning for NLP,Word Rotator's Distance,"A key principle in assessing textual similarity is measuring the degree of semantic overlap between two texts by considering the word alignment. Such alignment-based approaches are intuitive and interpretable; however, they are empirically inferior to the simple cosine similarity between general-purpose sentence vectors. To address this issue, we focus on and demonstrate the fact that the norm of word vectors is a good proxy for word importance, and their angle is a good proxy for word similarity. Alignment-based approaches do not distinguish them, whereas sentence-vector approaches automatically use the norm as the word importance. Accordingly, we propose a method that first decouples word vectors into their norm and direction, and then computes alignment-based similarity using earth mover's distance (i.e., optimal transport cost), which we refer to as word rotator's distance. Besides, we find how to ""grow"" the norm and direction of word vectors (vector converter), which is a new systematic approach derived from sentence-vector estimation methods. On several textual similarity datasets, the combination of these simple proposed methods outperformed not only alignment-based approaches but also strong baselines. 1","Word Rotator's Distance A key principle in assessing textual similarity is measuring the degree of semantic overlap between two texts by considering the word alignment. Such alignment-based approaches are intuitive and interpretable; however, they are empirically inferior to the simple cosine similarity between general-purpose sentence vectors. To address this issue, we focus on and demonstrate the fact that the norm of word vectors is a good proxy for word importance, and their angle is a good proxy for word similarity. Alignment-based approaches do not distinguish them, whereas sentence-vector approaches automatically use the norm as the word importance. Accordingly, we propose a method that first decouples word vectors into their norm and direction, and then computes alignment-based similarity using earth mover's distance (i.e., optimal transport cost), which we refer to as word rotator's distance. Besides, we find how to ""grow"" the norm and direction of word vectors (vector converter), which is a new systematic approach derived from sentence-vector estimation methods. On several textual similarity datasets, the combination of these simple proposed methods outperformed not only alignment-based approaches but also strong baselines. 1","word rotator distance key principle assess textual similarity measure degree semantic overlap text consider word alignment . alignment - base approach intuitive interpretable ; , empirically inferior simple cosine similarity general - purpose sentence vector . address issue , focus demonstrate fact norm word vector good proxy word importance , angle good proxy word similarity . alignment - base approach distinguish , sentence - vector approach automatically use norm word importance . accordingly , propose method decouple word vector norm direction , compute alignment - base similarity earth mover distance ( i.e. , optimal transport cost ) , refer word rotator distance . , find "" grow "" norm direction word vector ( vector converter ) , new systematic approach derive sentence - vector estimation method . textual similarity dataset , combination simple propose method outperform alignment - base approach strong baseline . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 16, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Learning for NLP,The Thieves on Sesame Street are Polyglots - Extracting Multilingual Models from Monolingual APIs,"Pre-training in natural language processing makes it easier for an adversary with only query access to a victim model to reconstruct a local copy of the victim by training with gibberish input data paired with the victim's labels for that data. We discover that this extraction process extends to local copies initialized from a pre-trained, multilingual model while the victim remains monolingual. The extracted model learns the task from the monolingual victim, but it generalizes far better than the victim to several other languages. This is done without ever showing the multilingual, extracted model a well-formed input in any of the languages for the target task. We also demonstrate that a few real examples can greatly improve performance, and we analyze how these results shed light on how such extraction methods succeed.","The Thieves on Sesame Street are Polyglots - Extracting Multilingual Models from Monolingual APIs Pre-training in natural language processing makes it easier for an adversary with only query access to a victim model to reconstruct a local copy of the victim by training with gibberish input data paired with the victim's labels for that data. We discover that this extraction process extends to local copies initialized from a pre-trained, multilingual model while the victim remains monolingual. The extracted model learns the task from the monolingual victim, but it generalizes far better than the victim to several other languages. This is done without ever showing the multilingual, extracted model a well-formed input in any of the languages for the target task. We also demonstrate that a few real examples can greatly improve performance, and we analyze how these results shed light on how such extraction methods succeed.","thief sesame street polyglot - extract multilingual model monolingual apis pre - training natural language processing make easy adversary query access victim model reconstruct local copy victim train gibberish input datum pair victim label datum . discover extraction process extend local copy initialize pre - trained , multilingual model victim remain monolingual . extract model learn task monolingual victim , generalize far well victim language . show multilingual , extract model - form input language target task . demonstrate real example greatly improve performance , analyze result shed light extraction method succeed .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,DORB: Dynamically Optimizing Multiple Rewards with Bandits,"Policy gradients-based reinforcement learning has proven to be a promising approach for directly optimizing non-differentiable evaluation metrics for language generation tasks. However, optimizing for a specific metric reward leads to improvements in mostly that metric only, suggesting that the model is gaming the formulation of that metric in a particular way without often achieving real qualitative improvements. Hence, it is more beneficial to make the model optimize multiple diverse metric rewards jointly. While appealing, this is challenging because one needs to manually decide the importance and scaling weights of these metric rewards. Further, it is important to consider using a dynamic combination and curriculum of metric rewards that flexibly changes over time. Considering the above aspects, in our work, we automate the optimization of multiple metric rewards simultaneously via a multi-armed bandit approach (DORB), where at each round, the bandit chooses which metric reward to optimize next, based on expected arm gains. We use the Exp3 algorithm for bandits and formulate two approaches for bandit rewards: (1) Single Multi-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit (HM-Bandit). We empirically show the effectiveness of our approaches via various automatic metrics and human evaluation on two important NLG tasks: question generation and data-to-text generation. Finally, we present interpretable analyses of the learned bandit curriculum over the optimized rewards.","DORB: Dynamically Optimizing Multiple Rewards with Bandits Policy gradients-based reinforcement learning has proven to be a promising approach for directly optimizing non-differentiable evaluation metrics for language generation tasks. However, optimizing for a specific metric reward leads to improvements in mostly that metric only, suggesting that the model is gaming the formulation of that metric in a particular way without often achieving real qualitative improvements. Hence, it is more beneficial to make the model optimize multiple diverse metric rewards jointly. While appealing, this is challenging because one needs to manually decide the importance and scaling weights of these metric rewards. Further, it is important to consider using a dynamic combination and curriculum of metric rewards that flexibly changes over time. Considering the above aspects, in our work, we automate the optimization of multiple metric rewards simultaneously via a multi-armed bandit approach (DORB), where at each round, the bandit chooses which metric reward to optimize next, based on expected arm gains. We use the Exp3 algorithm for bandits and formulate two approaches for bandit rewards: (1) Single Multi-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit (HM-Bandit). We empirically show the effectiveness of our approaches via various automatic metrics and human evaluation on two important NLG tasks: question generation and data-to-text generation. Finally, we present interpretable analyses of the learned bandit curriculum over the optimized rewards.","dorb : dynamically optimize multiple reward bandit policy gradient - base reinforcement learning prove promising approach directly optimize non - differentiable evaluation metric language generation task . , optimize specific metric reward lead improvement metric , suggest model game formulation metric particular way achieve real qualitative improvement . , beneficial model optimize multiple diverse metric reward jointly . appeal , challenging need manually decide importance scale weight metric reward . , important consider dynamic combination curriculum metric reward flexibly change time . consider aspect , work , automate optimization multiple metric reward simultaneously multi - armed bandit approach ( dorb ) , round , bandit choose metric reward optimize , base expect arm gain . use exp3 algorithm bandit formulate approach bandit reward : ( 1 ) single multi - reward bandit ( sm - bandit ) ; ( 2 ) hierarchical multi - reward bandit ( hm - bandit ) . empirically effectiveness approach automatic metric human evaluation important nlg task : question generation data - - text generation . finally , present interpretable analysis learn bandit curriculum optimize reward .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 13, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Learning for NLP,Pre-Training Transformers as Energy-Based Cloze Models,"We introduce Electric, an energy-based cloze model for representation learning over text. Like BERT, it is a conditional generative model of tokens given their contexts. However, Electric does not use masking or output a full distribution over tokens that could occur in a context. Instead, it assigns a scalar energy score to each input token indicating how likely it is given its context. We train Electric using an algorithm based on noise-contrastive estimation and elucidate how this learning objective is closely related to the recently proposed ELECTRA pre-training method. Electric performs well when transferred to downstream tasks and is particularly effective at producing likelihood scores for text: it reranks speech recognition n-best lists better than language models and much faster than masked language models. Furthermore, it offers a clearer and more principled view of what ELECTRA learns during pre-training.","Pre-Training Transformers as Energy-Based Cloze Models We introduce Electric, an energy-based cloze model for representation learning over text. Like BERT, it is a conditional generative model of tokens given their contexts. However, Electric does not use masking or output a full distribution over tokens that could occur in a context. Instead, it assigns a scalar energy score to each input token indicating how likely it is given its context. We train Electric using an algorithm based on noise-contrastive estimation and elucidate how this learning objective is closely related to the recently proposed ELECTRA pre-training method. Electric performs well when transferred to downstream tasks and is particularly effective at producing likelihood scores for text: it reranks speech recognition n-best lists better than language models and much faster than masked language models. Furthermore, it offers a clearer and more principled view of what ELECTRA learns during pre-training.","pre - training transformer energy - base cloze model introduce electric , energy - base cloze model representation learning text . like bert , conditional generative model token give context . , electric use masking output distribution token occur context . instead , assign scalar energy score input token indicate likely give context . train electric algorithm base noise - contrastive estimation elucidate learning objective closely relate recently propose electra pre - training method . electric perform transfer downstream task particularly effective produce likelihood score text : rerank speech recognition n - best list well language model fast mask language model . furthermore , offer clear principled view electra learn pre - training .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Lifelong Language Knowledge Distillation,"It is challenging to perform lifelong language learning (LLL) on a stream of different tasks without any performance degradation comparing to the multi-task counterparts. To address this issue, we present Lifelong Language Knowledge Distillation (L2KD), a simple but efficient method that can be easily applied to existing LLL architectures in order to mitigate the degradation. Specifically, when the LLL model is trained on a new task, we assign a teacher model to first learn the new task, and pass the knowledge to the LLL model via knowledge distillation. Therefore, the LLL model can better adapt to the new task while keeping the previously learned knowledge. Experiments show that the proposed L2KD consistently improves previous state-ofthe-art models, and the degradation comparing to multi-task models in LLL tasks is well mitigated for both sequence generation and text classification tasks. 1","Lifelong Language Knowledge Distillation It is challenging to perform lifelong language learning (LLL) on a stream of different tasks without any performance degradation comparing to the multi-task counterparts. To address this issue, we present Lifelong Language Knowledge Distillation (L2KD), a simple but efficient method that can be easily applied to existing LLL architectures in order to mitigate the degradation. Specifically, when the LLL model is trained on a new task, we assign a teacher model to first learn the new task, and pass the knowledge to the LLL model via knowledge distillation. Therefore, the LLL model can better adapt to the new task while keeping the previously learned knowledge. Experiments show that the proposed L2KD consistently improves previous state-ofthe-art models, and the degradation comparing to multi-task models in LLL tasks is well mitigated for both sequence generation and text classification tasks. 1","lifelong language knowledge distillation challenging perform lifelong language learning ( lll ) stream different task performance degradation compare multi - task counterpart . address issue , present lifelong language knowledge distillation ( l2kd ) , simple efficient method easily apply exist lll architecture order mitigate degradation . specifically , lll model train new task , assign teacher model learn new task , pass knowledge lll model knowledge distillation . , lll model well adapt new task keep previously learn knowledge . experiment propose l2kd consistently improve previous state - ofthe - art model , degradation compare multi - task model lll task mitigate sequence generation text classification task . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Learning VAE-LDA Models with Rounded Reparameterization Trick,"The introduction of VAE provides an efficient framework for the learning of generative models, including generative topic models. However, when the topic model is a Latent Dirichlet Allocation (LDA) model, a central technique of VAE, the reparameterization trick, fails to be applicable. This is because no reparameterization form of Dirichlet distributions is known to date that allows the use of the reparameterization trick. In this work, we propose a new method, which we call Rounded Reparameterization Trick (RRT), to reparameterize Dirichlet distributions for the learning of VAE-LDA models. This method, when applied to a VAE-LDA model, is shown experimentally to outperform the existing neural topic models on several benchmark datasets and on a synthetic dataset.","Learning VAE-LDA Models with Rounded Reparameterization Trick The introduction of VAE provides an efficient framework for the learning of generative models, including generative topic models. However, when the topic model is a Latent Dirichlet Allocation (LDA) model, a central technique of VAE, the reparameterization trick, fails to be applicable. This is because no reparameterization form of Dirichlet distributions is known to date that allows the use of the reparameterization trick. In this work, we propose a new method, which we call Rounded Reparameterization Trick (RRT), to reparameterize Dirichlet distributions for the learning of VAE-LDA models. This method, when applied to a VAE-LDA model, is shown experimentally to outperform the existing neural topic models on several benchmark datasets and on a synthetic dataset.","learn vae - lda model round reparameterization trick introduction vae provide efficient framework learning generative model , include generative topic model . , topic model latent dirichlet allocation ( lda ) model , central technique vae , reparameterization trick , fail applicable . reparameterization form dirichlet distribution know date allow use reparameterization trick . work , propose new method , round reparameterization trick ( rrt ) , reparameterize dirichlet distribution learning vae - lda model . method , apply vae - lda model , show experimentally outperform exist neural topic model benchmark dataset synthetic dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Learning for NLP,Calibration of Pre-trained Transformers,"Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT (Devlin et al., 2019)  and RoBERTa (Liu et al., 2019) in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging outof-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pretrained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5× lower; (2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain. 1","Calibration of Pre-trained Transformers Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT (Devlin et al., 2019)  and RoBERTa (Liu et al., 2019) in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging outof-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pretrained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5× lower; (2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain. 1","calibration pre - trained transformers pre - trained transformers ubiquitous natural language processing , despite high end - task performance , little know empirically calibrate . specifically , model ' posterior probability provide accurate empirical measure likely model correct give example ? focus bert ( devlin et al . , 2019 )   roberta ( liu et al . , 2019 ) work , analyze calibration task : natural language inference , paraphrase detection , commonsense reasoning . task , consider - domain challenging outof - domain setting , model face example uncertain . : ( 1 ) - - - box , pretraine model calibrate - domain , compare baseline , calibration error - - domain 3.5× low ; ( 2 ) temperature scaling effective reduce calibration error - domain , label smoothing deliberately increase empirical uncertainty help calibrate posterior - - domain . 1","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for Temporal Knowledge Graph Completion,"There has recently been increasing interest in learning representations of temporal knowledge graphs (KGs), which record the dynamic relationships between entities over time. Temporal KGs often exhibit multiple simultaneous non-Euclidean structures, such as hierarchical and cyclic structures. However, existing embedding approaches for temporal KGs typically learn entity representations and their dynamic evolution in the Euclidean space, which might not capture such intrinsic structures very well. To this end, we propose Dy-ERNIE, a non-Euclidean embedding approach that learns evolving entity representations in a product of Riemannian manifolds, where the composed spaces are estimated from the sectional curvatures of underlying data. Product manifolds enable our approach to better reflect a wide variety of geometric structures on temporal KGs. Besides, to capture the evolutionary dynamics of temporal KGs, we let the entity representations evolve according to a velocity vector defined in the tangent space at each timestamp. We analyze in detail the contribution of geometric spaces to representation learning of temporal KGs and evaluate our model on temporal knowledge graph completion tasks. Extensive experiments on three real-world datasets demonstrate significantly improved performance, indicating that the dynamics of multi-relational graph data can be more properly modeled by the evolution of embeddings on Riemannian manifolds.","DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for Temporal Knowledge Graph Completion There has recently been increasing interest in learning representations of temporal knowledge graphs (KGs), which record the dynamic relationships between entities over time. Temporal KGs often exhibit multiple simultaneous non-Euclidean structures, such as hierarchical and cyclic structures. However, existing embedding approaches for temporal KGs typically learn entity representations and their dynamic evolution in the Euclidean space, which might not capture such intrinsic structures very well. To this end, we propose Dy-ERNIE, a non-Euclidean embedding approach that learns evolving entity representations in a product of Riemannian manifolds, where the composed spaces are estimated from the sectional curvatures of underlying data. Product manifolds enable our approach to better reflect a wide variety of geometric structures on temporal KGs. Besides, to capture the evolutionary dynamics of temporal KGs, we let the entity representations evolve according to a velocity vector defined in the tangent space at each timestamp. We analyze in detail the contribution of geometric spaces to representation learning of temporal KGs and evaluate our model on temporal knowledge graph completion tasks. Extensive experiments on three real-world datasets demonstrate significantly improved performance, indicating that the dynamics of multi-relational graph data can be more properly modeled by the evolution of embeddings on Riemannian manifolds.","dyernie : dynamic evolution riemannian manifold embedding temporal knowledge graph completion recently increase interest learn representation temporal knowledge graph ( kgs ) , record dynamic relationship entity time . temporal kg exhibit multiple simultaneous non - euclidean structure , hierarchical cyclic structure . , exist embed approach temporal kg typically learn entity representation dynamic evolution euclidean space , capture intrinsic structure . end , propose dy - ernie , non - euclidean embedding approach learn evolve entity representation product riemannian manifold , compose space estimate sectional curvature underlie datum . product manifold enable approach well reflect wide variety geometric structure temporal kg . , capture evolutionary dynamic temporal kg , let entity representation evolve accord velocity vector define tangent space timestamp . analyze detail contribution geometric space representation learning temporal kg evaluate model temporal knowledge graph completion task . extensive experiment real - world dataset demonstrate significantly improve performance , indicate dynamic multi - relational graph datum properly model evolution embedding riemannian manifold .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Active Learning for BERT: An Empirical Study,"Real world scenarios present a challenge for text classification, since labels are usually expensive and the data is often characterized by class imbalance. Active Learning (AL) is a ubiquitous paradigm to cope with data scarcity. Recently, pre-trained NLP models, and BERT in particular, are receiving massive attention due to their outstanding performance in various NLP tasks. However, the use of AL with deep pre-trained models has so far received little consideration. Here, we present a large-scale empirical study on active learning techniques for BERT-based classification, addressing a diverse set of AL strategies and datasets. We focus on practical scenarios of binary text classification, where the annotation budget is very small, and the data is often skewed. Our results demonstrate that AL can boost BERT performance, especially in the most realistic scenario in which the initial set of labeled examples is created using keyword-based queries, resulting in a biased sample of the minority class. We release our research framework, aiming to facilitate future research along the lines explored here.","Active Learning for BERT: An Empirical Study Real world scenarios present a challenge for text classification, since labels are usually expensive and the data is often characterized by class imbalance. Active Learning (AL) is a ubiquitous paradigm to cope with data scarcity. Recently, pre-trained NLP models, and BERT in particular, are receiving massive attention due to their outstanding performance in various NLP tasks. However, the use of AL with deep pre-trained models has so far received little consideration. Here, we present a large-scale empirical study on active learning techniques for BERT-based classification, addressing a diverse set of AL strategies and datasets. We focus on practical scenarios of binary text classification, where the annotation budget is very small, and the data is often skewed. Our results demonstrate that AL can boost BERT performance, especially in the most realistic scenario in which the initial set of labeled examples is created using keyword-based queries, resulting in a biased sample of the minority class. We release our research framework, aiming to facilitate future research along the lines explored here.","active learning bert : empirical study real world scenario present challenge text classification , label usually expensive data characterize class imbalance . active learning ( al ) ubiquitous paradigm cope datum scarcity . recently , pre - train nlp model , bert particular , receive massive attention outstanding performance nlp task . , use al deep pre - trained model far receive little consideration . , present large - scale empirical study active learning technique bert - base classification , address diverse set al strategy dataset . focus practical scenario binary text classification , annotation budget small , data skewed . result demonstrate al boost bert performance , especially realistic scenario initial set label example create keyword - base query , result biased sample minority class . release research framework , aim facilitate future research line explore .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Cold-start Active Learning through Self-supervised Language Modeling,"Active learning strives to reduce annotation costs by choosing the most critical examples to label. Typically, the active learning strategy is contingent on the classification model. For instance, uncertainty sampling depends on poorly calibrated model confidence scores. In the cold-start setting, active learning is impractical because of model instability and data scarcity. Fortunately, modern NLP provides an additional source of information: pretrained language models. The pre-training loss can find examples that surprise the model and should be labeled for efficient fine-tuning. Therefore, we treat the language modeling loss as a proxy for classification uncertainty. With BERT, we develop a simple strategy based on the masked language modeling loss that minimizes labeling costs for text classification. Compared to other baselines, our approach reaches higher accuracy within less sampling iterations and computation time.","Cold-start Active Learning through Self-supervised Language Modeling Active learning strives to reduce annotation costs by choosing the most critical examples to label. Typically, the active learning strategy is contingent on the classification model. For instance, uncertainty sampling depends on poorly calibrated model confidence scores. In the cold-start setting, active learning is impractical because of model instability and data scarcity. Fortunately, modern NLP provides an additional source of information: pretrained language models. The pre-training loss can find examples that surprise the model and should be labeled for efficient fine-tuning. Therefore, we treat the language modeling loss as a proxy for classification uncertainty. With BERT, we develop a simple strategy based on the masked language modeling loss that minimizes labeling costs for text classification. Compared to other baselines, our approach reaches higher accuracy within less sampling iterations and computation time.","cold - start active learning self - supervised language modeling active learning strive reduce annotation cost choose critical example label . typically , active learning strategy contingent classification model . instance , uncertainty sampling depend poorly calibrate model confidence score . cold - start setting , active learning impractical model instability data scarcity . fortunately , modern nlp provide additional source information : pretrained language model . pre - training loss find example surprise model label efficient fine - tuning . , treat language modeling loss proxy classification uncertainty . bert , develop simple strategy base mask language modeling loss minimize labeling cost text classification . compare baseline , approach reach high accuracy sampling iteration computation time .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Masking as an Efficient Alternative to Finetuning for Pretrained Language Models,"We present an efficient method of utilizing pretrained language models, where we learn selective binary masks for pretrained weights in lieu of modifying them through finetuning. Extensive evaluations of masking BERT, RoBERTa, and DistilBERT on eleven diverse NLP tasks show that our masking scheme yields performance comparable to finetuning, yet has a much smaller memory footprint when several tasks need to be inferred. Intrinsic evaluations show that representations computed by our binary masked language models encode information necessary for solving downstream tasks. Analyzing the loss landscape, we show that masking and finetuning produce models that reside in minima that can be connected by a line segment with nearly constant test accuracy. This confirms that masking can be utilized as an efficient alternative to finetuning.","Masking as an Efficient Alternative to Finetuning for Pretrained Language Models We present an efficient method of utilizing pretrained language models, where we learn selective binary masks for pretrained weights in lieu of modifying them through finetuning. Extensive evaluations of masking BERT, RoBERTa, and DistilBERT on eleven diverse NLP tasks show that our masking scheme yields performance comparable to finetuning, yet has a much smaller memory footprint when several tasks need to be inferred. Intrinsic evaluations show that representations computed by our binary masked language models encode information necessary for solving downstream tasks. Analyzing the loss landscape, we show that masking and finetuning produce models that reside in minima that can be connected by a line segment with nearly constant test accuracy. This confirms that masking can be utilized as an efficient alternative to finetuning.","masking efficient alternative finetuning pretrained language model present efficient method utilize pretrained language model , learn selective binary mask pretrained weight lieu modify finetuning . extensive evaluation mask bert , roberta , distilbert diverse nlp task masking scheme yield performance comparable finetuning , small memory footprint task need infer . intrinsic evaluation representation compute binary mask language model encode information necessary solve downstream task . analyze loss landscape , masking finetuning produce model reside minimum connect line segment nearly constant test accuracy . confirm masking utilize efficient alternative finetuning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Multilevel Text Alignment with Cross-Document Attention,"Text alignment finds application in tasks such as citation recommendation and plagiarism detection. Existing alignment methods operate at a single, predefined level and cannot learn to align texts at, for example, sentence and document levels. We propose a new learning approach that equips previously established hierarchical attention encoders for representing documents with a cross-document attention component, enabling structural comparisons across different levels (document-to-document and sentence-to-document). Our component is weakly supervised from document pairs and can align at multiple levels. Our evaluation on predicting document-to-document relationships and sentence-to-document relationships on the tasks of citation recommendation and plagiarism detection shows that our approach outperforms previously established hierarchical, attention encoders based on recurrent and transformer contextualization that are unaware of structural correspondence between documents.","Multilevel Text Alignment with Cross-Document Attention Text alignment finds application in tasks such as citation recommendation and plagiarism detection. Existing alignment methods operate at a single, predefined level and cannot learn to align texts at, for example, sentence and document levels. We propose a new learning approach that equips previously established hierarchical attention encoders for representing documents with a cross-document attention component, enabling structural comparisons across different levels (document-to-document and sentence-to-document). Our component is weakly supervised from document pairs and can align at multiple levels. Our evaluation on predicting document-to-document relationships and sentence-to-document relationships on the tasks of citation recommendation and plagiarism detection shows that our approach outperforms previously established hierarchical, attention encoders based on recurrent and transformer contextualization that are unaware of structural correspondence between documents.","multilevel text alignment cross - document attention text alignment find application task citation recommendation plagiarism detection . exist alignment method operate single , predefine level learn align text , example , sentence document level . propose new learning approach equip previously establish hierarchical attention encoder represent document cross - document attention component , enable structural comparison different level ( document - - document sentence - - document ) . component weakly supervise document pair align multiple level . evaluation predict document - - document relationship sentence - - document relationship task citation recommendation plagiarism detection show approach outperform previously establish hierarchical , attention encoder base recurrent transformer contextualization unaware structural correspondence document .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 14, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 12, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Learning for NLP,Effective Unsupervised Domain Adaptation with Adversarially Trained Language Models,"Recent work has shown the importance of adaptation of broad-coverage contextualised embedding models on the domain of the target task of interest. Current self-supervised adaptation methods are simplistic, as the training signal comes from a small percentage of randomly masked-out tokens. In this paper, we show that careful masking strategies can bridge the knowledge gap of masked language models (MLMs) about the domains more effectively by allocating self-supervision where it is needed. Furthermore, we propose an effective training strategy by adversarially masking out those tokens which are harder to reconstruct by the underlying MLM. The adversarial objective leads to a challenging combinatorial optimisation problem over subsets of tokens, which we tackle efficiently through relaxation to a variational lower-bound and dynamic programming. On six unsupervised domain adaptation tasks involving named entity recognition, our method strongly outperforms the random masking strategy and achieves up to +1.64 F1 score improvements.","Effective Unsupervised Domain Adaptation with Adversarially Trained Language Models Recent work has shown the importance of adaptation of broad-coverage contextualised embedding models on the domain of the target task of interest. Current self-supervised adaptation methods are simplistic, as the training signal comes from a small percentage of randomly masked-out tokens. In this paper, we show that careful masking strategies can bridge the knowledge gap of masked language models (MLMs) about the domains more effectively by allocating self-supervision where it is needed. Furthermore, we propose an effective training strategy by adversarially masking out those tokens which are harder to reconstruct by the underlying MLM. The adversarial objective leads to a challenging combinatorial optimisation problem over subsets of tokens, which we tackle efficiently through relaxation to a variational lower-bound and dynamic programming. On six unsupervised domain adaptation tasks involving named entity recognition, our method strongly outperforms the random masking strategy and achieves up to +1.64 F1 score improvements.","effective unsupervised domain adaptation adversarially train language model recent work show importance adaptation broad - coverage contextualise embedding model domain target task interest . current self - supervise adaptation method simplistic , training signal come small percentage randomly mask - token . paper , careful masking strategy bridge knowledge gap mask language model ( mlms ) domain effectively allocate self - supervision need . furthermore , propose effective training strategy adversarially mask token hard reconstruct underlie mlm . adversarial objective lead challenging combinatorial optimisation problem subset token , tackle efficiently relaxation variational lower - bind dynamic programming . unsupervised domain adaptation task involve name entity recognition , method strongly outperform random masking strategy achieve +1.64 f1 score improvement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference,"The neural attention mechanism plays an important role in many natural language processing applications. In particular, multi-head attention extends single-head attention by allowing a model to jointly attend information from different perspectives. However, without explicit constraining, multi-head attention may suffer from attention collapse, an issue that makes different heads extract similar attentive features, thus limiting the model's representation power. In this paper, for the first time, we provide a novel understanding of multi-head attention from a Bayesian perspective. Based on the recently developed particleoptimization sampling techniques, we propose a non-parametric approach that explicitly improves the repulsiveness in multi-head attention and consequently strengthens model's expressiveness. Remarkably, our Bayesian interpretation provides theoretical inspirations on the not-well-understood questions: why and how one uses multi-head attention. Extensive experiments on various attention models and applications demonstrate that the proposed repulsive attention can improve the learned feature diversity, leading to more informative representations with consistent performance improvement on multiple tasks.","Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference The neural attention mechanism plays an important role in many natural language processing applications. In particular, multi-head attention extends single-head attention by allowing a model to jointly attend information from different perspectives. However, without explicit constraining, multi-head attention may suffer from attention collapse, an issue that makes different heads extract similar attentive features, thus limiting the model's representation power. In this paper, for the first time, we provide a novel understanding of multi-head attention from a Bayesian perspective. Based on the recently developed particleoptimization sampling techniques, we propose a non-parametric approach that explicitly improves the repulsiveness in multi-head attention and consequently strengthens model's expressiveness. Remarkably, our Bayesian interpretation provides theoretical inspirations on the not-well-understood questions: why and how one uses multi-head attention. Extensive experiments on various attention models and applications demonstrate that the proposed repulsive attention can improve the learned feature diversity, leading to more informative representations with consistent performance improvement on multiple tasks.","repulsive attention : rethink multi - head attention bayesian inference neural attention mechanism play important role natural language processing application . particular , multi - head attention extend single - head attention allow model jointly attend information different perspective . , explicit constrain , multi - head attention suffer attention collapse , issue make different head extract similar attentive feature , limit model representation power . paper , time , provide novel understanding multi - head attention bayesian perspective . base recently develop particleoptimization sampling technique , propose non - parametric approach explicitly improve repulsiveness multi - head attention consequently strengthen model expressiveness . remarkably , bayesian interpretation provide theoretical inspiration - - understand question : use multi - head attention . extensive experiment attention model application demonstrate propose repulsive attention improve learn feature diversity , lead informative representation consistent performance improvement multiple task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 12, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Interpretability and Analysis of Models for NLP,False
Machine Learning for NLP,Multi-label Few/Zero-shot Learning with Knowledge Aggregated from Multiple Label Graphs,"Few/Zero-shot learning is a big challenge of many classifications tasks, where a classifier is required to recognise instances of classes that have very few or even no training samples. It becomes more difficult in multilabel classification, where each instance is labelled with more than one class. In this paper, we present a simple multi-graph aggregation model that fuses knowledge from multiple label graphs encoding different semantic label relationships in order to study how the aggregated knowledge can benefit multi-label zero/few-shot document classification. The model utilises three kinds of semantic information, i.e., the pre-trained word embeddings, label description, and pre-defined label relations. Experimental results derived on two large clinical datasets (i.e., MIMIC-II and MIMIC-III ) and the EU legislation dataset show that methods equipped with the multi-graph knowledge aggregation achieve significant performance improvement across almost all the measures on few/zero-shot labels.","Multi-label Few/Zero-shot Learning with Knowledge Aggregated from Multiple Label Graphs Few/Zero-shot learning is a big challenge of many classifications tasks, where a classifier is required to recognise instances of classes that have very few or even no training samples. It becomes more difficult in multilabel classification, where each instance is labelled with more than one class. In this paper, we present a simple multi-graph aggregation model that fuses knowledge from multiple label graphs encoding different semantic label relationships in order to study how the aggregated knowledge can benefit multi-label zero/few-shot document classification. The model utilises three kinds of semantic information, i.e., the pre-trained word embeddings, label description, and pre-defined label relations. Experimental results derived on two large clinical datasets (i.e., MIMIC-II and MIMIC-III ) and the EU legislation dataset show that methods equipped with the multi-graph knowledge aggregation achieve significant performance improvement across almost all the measures on few/zero-shot labels.","multi - label / zero - shot learning knowledge aggregate multiple label graph / zero - shot learning big challenge classification task , classifier require recognise instance class training sample . difficult multilabel classification , instance label class . paper , present simple multi - graph aggregation model fuse knowledge multiple label graph encode different semantic label relationship order study aggregate knowledge benefit multi - label zero / - shot document classification . model utilise kind semantic information , i.e. , pre - trained word embedding , label description , pre - defined label relation . experimental result derive large clinical dataset ( i.e. , mimic - ii mimic - iii ) eu legislation dataset method equip multi - graph knowledge aggregation achieve significant performance improvement measure / zero - shot label .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Debiasing knowledge graph embeddings,"It has been shown that knowledge graph embeddings encode potentially harmful social biases, such as the information that women are more likely to be nurses, and men more likely to be bankers. As graph embeddings begin to be used more widely in NLP pipelines, there is a need to develop training methods which remove such biases. Previous approaches to this problem both significantly increase the training time, by a factor of eight or more, and decrease the accuracy of the model substantially. We present a novel approach, in which all embeddings are trained to be neutral to sensitive attributes such as gender by default using an adversarial loss. We then add sensitive attributes back on in whitelisted cases. Training time only marginally increases over a baseline model, and the debiased embeddings perform almost as accurately in the triple prediction task as their non-debiased counterparts.","Debiasing knowledge graph embeddings It has been shown that knowledge graph embeddings encode potentially harmful social biases, such as the information that women are more likely to be nurses, and men more likely to be bankers. As graph embeddings begin to be used more widely in NLP pipelines, there is a need to develop training methods which remove such biases. Previous approaches to this problem both significantly increase the training time, by a factor of eight or more, and decrease the accuracy of the model substantially. We present a novel approach, in which all embeddings are trained to be neutral to sensitive attributes such as gender by default using an adversarial loss. We then add sensitive attributes back on in whitelisted cases. Training time only marginally increases over a baseline model, and the debiased embeddings perform almost as accurately in the triple prediction task as their non-debiased counterparts.","debiase knowledge graph embedding show knowledge graph embedding encode potentially harmful social bias , information woman likely nurse , man likely banker . graph embedding begin widely nlp pipeline , need develop training method remove bias . previous approach problem significantly increase training time , factor , decrease accuracy model substantially . present novel approach , embedding train neutral sensitive attribute gender default adversarial loss . add sensitive attribute whiteliste case . training time marginally increase baseline model , debiased embedding perform accurately triple prediction task non - debiased counterpart .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 11, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Machine Learning for NLP,Semantic Label Smoothing for Sequence to Sequence Problems,"Label smoothing has been shown to be an effective regularization strategy in classification, that prevents overfitting and helps in label denoising. However, extending such methods directly to seq2seq settings, such as Machine Translation, is challenging: the large target output space of such problems makes it intractable to apply label smoothing over all possible outputs. Most existing approaches for seq2seq settings either do token level smoothing, or smooth over sequences generated by randomly substituting tokens in the target sequence. Unlike these works, in this paper, we propose a technique that smooths over well formed relevant sequences that not only have sufficient n-gram overlap with the target sequence, but are also semantically similar. Our method shows a consistent and significant improvement over the state-of-the-art techniques on different datasets.","Semantic Label Smoothing for Sequence to Sequence Problems Label smoothing has been shown to be an effective regularization strategy in classification, that prevents overfitting and helps in label denoising. However, extending such methods directly to seq2seq settings, such as Machine Translation, is challenging: the large target output space of such problems makes it intractable to apply label smoothing over all possible outputs. Most existing approaches for seq2seq settings either do token level smoothing, or smooth over sequences generated by randomly substituting tokens in the target sequence. Unlike these works, in this paper, we propose a technique that smooths over well formed relevant sequences that not only have sufficient n-gram overlap with the target sequence, but are also semantically similar. Our method shows a consistent and significant improvement over the state-of-the-art techniques on different datasets.","semantic label smoothing sequence sequence problem label smoothing show effective regularization strategy classification , prevent overfitting help label denoising . , extend method directly seq2seq setting , machine translation , challenging : large target output space problem make intractable apply label smoothing possible output . exist approach seq2seq setting token level smoothing , smooth sequence generate randomly substitute token target sequence . unlike work , paper , propose technique smooth form relevant sequence sufficient n - gram overlap target sequence , semantically similar . method show consistent significant improvement state - - - art technique different dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Machine Learning for NLP,Variational Hierarchical Dialog Autoencoder for Dialog State Tracking Data Augmentation,"Recent works have shown that generative data augmentation, where synthetic samples generated from deep generative models complement the training dataset, benefit NLP tasks. In this work, we extend this approach to the task of dialog state tracking for goaloriented dialogs. Due to the inherent hierarchical structure of goal-oriented dialogs over utterances and related annotations, the deep generative model must be capable of capturing the coherence among different hierarchies and types of dialog features. We propose the Variational Hierarchical Dialog Autoencoder (VHDA) for modeling the complete aspects of goal-oriented dialogs, including linguistic features and underlying structured annotations, namely speaker information, dialog acts, and goals. The proposed architecture is designed to model each aspect of goal-oriented dialogs using inter-connected latent variables and learns to generate coherent goal-oriented dialogs from the latent spaces. To overcome training issues that arise from training complex variational models, we propose appropriate training strategies. Experiments on various dialog datasets show that our model improves the downstream dialog trackers' robustness via generative data augmentation. We also discover additional benefits of our unified approach to modeling goal-oriented dialogsdialog response generation and user simulation, where our model outperforms previous strong baselines.","Variational Hierarchical Dialog Autoencoder for Dialog State Tracking Data Augmentation Recent works have shown that generative data augmentation, where synthetic samples generated from deep generative models complement the training dataset, benefit NLP tasks. In this work, we extend this approach to the task of dialog state tracking for goaloriented dialogs. Due to the inherent hierarchical structure of goal-oriented dialogs over utterances and related annotations, the deep generative model must be capable of capturing the coherence among different hierarchies and types of dialog features. We propose the Variational Hierarchical Dialog Autoencoder (VHDA) for modeling the complete aspects of goal-oriented dialogs, including linguistic features and underlying structured annotations, namely speaker information, dialog acts, and goals. The proposed architecture is designed to model each aspect of goal-oriented dialogs using inter-connected latent variables and learns to generate coherent goal-oriented dialogs from the latent spaces. To overcome training issues that arise from training complex variational models, we propose appropriate training strategies. Experiments on various dialog datasets show that our model improves the downstream dialog trackers' robustness via generative data augmentation. We also discover additional benefits of our unified approach to modeling goal-oriented dialogsdialog response generation and user simulation, where our model outperforms previous strong baselines.","variational hierarchical dialog autoencoder dialog state tracking datum augmentation recent work show generative datum augmentation , synthetic sample generate deep generative model complement training dataset , benefit nlp task . work , extend approach task dialog state tracking goaloriented dialog . inherent hierarchical structure goal - orient dialog utterance related annotation , deep generative model capable capture coherence different hierarchy type dialog feature . propose variational hierarchical dialog autoencoder ( vhda ) model complete aspect goal - orient dialog , include linguistic feature underlie structured annotation , speaker information , dialog act , goal . propose architecture design model aspect goal - orient dialog inter - connected latent variable learn generate coherent goal - orient dialog latent space . overcome training issue arise train complex variational model , propose appropriate training strategy . experiment dialog dataset model improve downstream dialog tracker ' robustness generative datum augmentation . discover additional benefit unified approach model goal - orient dialogsdialog response generation user simulation , model outperform previous strong baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 22, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Dialogue and Interactive Systems,False
Machine Learning for NLP,Neural Mask Generator: Learning to Generate Adaptive Word Maskings for Language Model Adaptation,"We propose a method to automatically generate a domain-and task-adaptive maskings of the given text for self-supervised pre-training, such that we can effectively adapt the language model to a particular target task (e.g. question answering). Specifically, we present a novel reinforcement learning-based framework which learns the masking policy, such that using the generated masks for further pre-training of the target language model helps improve task performance on unseen texts. We use off-policy actor-critic with entropy regularization and experience replay for reinforcement learning, and propose a Transformer-based policy network that can consider the relative importance of words in a given text. We validate our Neural Mask Generator (NMG) on several question answering and text classification datasets using BERT and DistilBERT as the language models, on which it outperforms rule-based masking strategies, by automatically learning optimal adaptive maskings. 1 * Equal contribution. 1 Code is available at github.com/Nardien/NMG.","Neural Mask Generator: Learning to Generate Adaptive Word Maskings for Language Model Adaptation We propose a method to automatically generate a domain-and task-adaptive maskings of the given text for self-supervised pre-training, such that we can effectively adapt the language model to a particular target task (e.g. question answering). Specifically, we present a novel reinforcement learning-based framework which learns the masking policy, such that using the generated masks for further pre-training of the target language model helps improve task performance on unseen texts. We use off-policy actor-critic with entropy regularization and experience replay for reinforcement learning, and propose a Transformer-based policy network that can consider the relative importance of words in a given text. We validate our Neural Mask Generator (NMG) on several question answering and text classification datasets using BERT and DistilBERT as the language models, on which it outperforms rule-based masking strategies, by automatically learning optimal adaptive maskings. 1 * Equal contribution. 1 Code is available at github.com/Nardien/NMG.","neural mask generator : learn generate adaptive word masking language model adaptation propose method automatically generate domain - task - adaptive masking give text self - supervise pre - training , effectively adapt language model particular target task ( e.g. question answering ) . specifically , present novel reinforcement learning - base framework learn masking policy , generate mask pre - training target language model help improve task performance unseen text . use - policy actor - critic entropy regularization experience replay reinforcement learning , propose transformer - base policy network consider relative importance word give text . validate neural mask generator ( nmg ) question answering text classification dataset bert distilbert language model , outperform rule - base masking strategy , automatically learn optimal adaptive masking . 1 * equal contribution . 1 code available github.com/nardien/nmg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 10, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Machine Learning for NLP,"PatchBERT: Just-in-Time, Out-of-Vocabulary Patching","Large scale pre-trained language models have shown groundbreaking performance improvements for transfer learning in the domain of natural language processing. In our paper, we study a pre-trained multilingual BERT model and analyze the OOV rate on downstream tasks, how it introduces information loss, and as a side-effect, obstructs the potential of the underlying model. We then propose multiple approaches for mitigation and demonstrate that it improves performance with the same parameter count when combined with finetuning.","PatchBERT: Just-in-Time, Out-of-Vocabulary Patching Large scale pre-trained language models have shown groundbreaking performance improvements for transfer learning in the domain of natural language processing. In our paper, we study a pre-trained multilingual BERT model and analyze the OOV rate on downstream tasks, how it introduces information loss, and as a side-effect, obstructs the potential of the underlying model. We then propose multiple approaches for mitigation and demonstrate that it improves performance with the same parameter count when combined with finetuning.","patchbert : - - time , - - vocabulary patching large scale pre - trained language model show groundbreaking performance improvement transfer learning domain natural language processing . paper , study pre - trained multilingual bert model analyze oov rate downstream task , introduce information loss , - effect , obstruct potential underlie model . propose multiple approach mitigation demonstrate improve performance parameter count combine finetuning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,BERT-of-Theseus: Compressing BERT by Progressive Module Replacing,"In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models. Compared to the previous knowledge distillation approaches for BERT compression, our approach does not introduce any additional loss function. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression. 1","BERT-of-Theseus: Compressing BERT by Progressive Module Replacing In this paper, we propose a novel model compression approach to effectively compress BERT by progressive module replacing. Our approach first divides the original BERT into several modules and builds their compact substitutes. Then, we randomly replace the original modules with their substitutes to train the compact modules to mimic the behavior of the original modules. We progressively increase the probability of replacement through the training. In this way, our approach brings a deeper level of interaction between the original and compact models. Compared to the previous knowledge distillation approaches for BERT compression, our approach does not introduce any additional loss function. Our approach outperforms existing knowledge distillation approaches on GLUE benchmark, showing a new perspective of model compression. 1","bert - - theseus : compress bert progressive module replacing paper , propose novel model compression approach effectively compress bert progressive module replacing . approach divide original bert module build compact substitute . , randomly replace original module substitute train compact module mimic behavior original module . progressively increase probability replacement training . way , approach bring deep level interaction original compact model . compare previous knowledge distillation approach bert compression , approach introduce additional loss function . approach outperform exist knowledge distillation approach glue benchmark , show new perspective model compression . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Exploring and Predicting Transferability across NLP Tasks,"Recent advances in NLP demonstrate the effectiveness of training large-scale language models and transferring them to downstream tasks. Can fine-tuning these models on tasks other than language modeling further improve performance? In this paper, we conduct an extensive study of the transferability between 33 NLP tasks across three broad classes of problems (text classification, question answering, and sequence labeling). Our results show that transfer learning is more beneficial than previously thought, especially when target task data is scarce, and can improve performance even with low-data source tasks that differ substantially from the target task (e.g., part-ofspeech tagging transfers well to the DROP QA dataset). We also develop task embeddings that can be used to predict the most transferable source tasks for a given target task, and we validate their effectiveness in experiments controlled for source and target data size. Overall, our experiments reveal that factors such as data size, task and domain similarity, and task complexity all play a role in determining transferability.","Exploring and Predicting Transferability across NLP Tasks Recent advances in NLP demonstrate the effectiveness of training large-scale language models and transferring them to downstream tasks. Can fine-tuning these models on tasks other than language modeling further improve performance? In this paper, we conduct an extensive study of the transferability between 33 NLP tasks across three broad classes of problems (text classification, question answering, and sequence labeling). Our results show that transfer learning is more beneficial than previously thought, especially when target task data is scarce, and can improve performance even with low-data source tasks that differ substantially from the target task (e.g., part-ofspeech tagging transfers well to the DROP QA dataset). We also develop task embeddings that can be used to predict the most transferable source tasks for a given target task, and we validate their effectiveness in experiments controlled for source and target data size. Overall, our experiments reveal that factors such as data size, task and domain similarity, and task complexity all play a role in determining transferability.","explore predict transferability nlp task recent advance nlp demonstrate effectiveness train large - scale language model transfer downstream task . fine - tune model task language modeling improve performance ? paper , conduct extensive study transferability 33 nlp task broad class problem ( text classification , question answering , sequence labeling ) . result transfer learning beneficial previously think , especially target task data scarce , improve performance low - data source task differ substantially target task ( e.g. , - ofspeech tagging transfer drop qa dataset ) . develop task embedding predict transferable source task give target task , validate effectiveness experiment control source target data size . overall , experiment reveal factor data size , task domain similarity , task complexity play role determine transferability .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 6, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Machine Learning for NLP,Efficient Meta Lifelong-Learning with Limited Memory,"Current natural language processing models work well on a single task, yet they often fail to continuously learn new tasks without forgetting previous ones as they are re-trained throughout their lifetime, a challenge known as lifelong learning. State-of-the-art lifelong language learning methods store past examples in episodic memory and replay them at both training and inference time. However, as we show later in our experiments, there are three significant impediments: (1) needing unrealistically large memory module to achieve good performance, (2) suffering from negative transfer, (3) requiring multiple local adaptation steps for each test example that significantly slows down the inference speed. In this paper, we identify three common principles of lifelong learning methods and propose an efficient meta-lifelong framework that combines them in a synergistic fashion. To achieve sample efficiency, our method trains the model in a manner that it learns a better initialization for local adaptation. Extensive experiments on text classification and question answering benchmarks demonstrate the effectiveness of our framework by achieving state-of-the-art performance using merely 1% memory size and narrowing the gap with multi-task learning. We further show that our method alleviates both catastrophic forgetting and negative transfer at the same time.","Efficient Meta Lifelong-Learning with Limited Memory Current natural language processing models work well on a single task, yet they often fail to continuously learn new tasks without forgetting previous ones as they are re-trained throughout their lifetime, a challenge known as lifelong learning. State-of-the-art lifelong language learning methods store past examples in episodic memory and replay them at both training and inference time. However, as we show later in our experiments, there are three significant impediments: (1) needing unrealistically large memory module to achieve good performance, (2) suffering from negative transfer, (3) requiring multiple local adaptation steps for each test example that significantly slows down the inference speed. In this paper, we identify three common principles of lifelong learning methods and propose an efficient meta-lifelong framework that combines them in a synergistic fashion. To achieve sample efficiency, our method trains the model in a manner that it learns a better initialization for local adaptation. Extensive experiments on text classification and question answering benchmarks demonstrate the effectiveness of our framework by achieving state-of-the-art performance using merely 1% memory size and narrowing the gap with multi-task learning. We further show that our method alleviates both catastrophic forgetting and negative transfer at the same time.","efficient meta lifelong - learning limited memory current natural language processing model work single task , fail continuously learn new task forget previous one - train lifetime , challenge know lifelong learning . state - - - art lifelong language learning method store past example episodic memory replay training inference time . , later experiment , significant impediment : ( 1 ) need unrealistically large memory module achieve good performance , ( 2 ) suffer negative transfer , ( 3 ) require multiple local adaptation step test example significantly slow inference speed . paper , identify common principle lifelong learning method propose efficient meta - lifelong framework combine synergistic fashion . achieve sample efficiency , method train model manner learn well initialization local adaptation . extensive experiment text classification question answer benchmark demonstrate effectiveness framework achieve state - - - art performance merely 1 % memory size narrow gap multi - task learning . method alleviate catastrophic forgetting negative transfer time .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 3, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Machine Learning for NLP,Structured Pruning of Large Language Models,"Large language models have recently achieved state of the art performance across a wide variety of natural language tasks. Meanwhile, the size of these models and their latency have significantly increased, which makes their usage costly, and raises an interesting question: do language models need to be large? We study this question through the lens of model compression. We present a generic, structured pruning approach by parameterizing each weight matrix using its low-rank factorization, and adaptively removing rank-1 components during training. On language modeling tasks, our structured approach outperforms other unstructured and block-structured pruning baselines at various compression levels, while achieving significant speedups during both training and inference. We also demonstrate that our method can be applied to pruning adaptive word embeddings in large language models, and to pruning the BERT model on several downstream fine-tuning classification benchmarks. 1 * Denotes equal contribution.","Structured Pruning of Large Language Models Large language models have recently achieved state of the art performance across a wide variety of natural language tasks. Meanwhile, the size of these models and their latency have significantly increased, which makes their usage costly, and raises an interesting question: do language models need to be large? We study this question through the lens of model compression. We present a generic, structured pruning approach by parameterizing each weight matrix using its low-rank factorization, and adaptively removing rank-1 components during training. On language modeling tasks, our structured approach outperforms other unstructured and block-structured pruning baselines at various compression levels, while achieving significant speedups during both training and inference. We also demonstrate that our method can be applied to pruning adaptive word embeddings in large language models, and to pruning the BERT model on several downstream fine-tuning classification benchmarks. 1 * Denotes equal contribution.","structured pruning large language model large language model recently achieve state art performance wide variety natural language task . , size model latency significantly increase , make usage costly , raise interesting question : language model need large ? study question lens model compression . present generic , structured pruning approach parameterize weight matrix low - rank factorization , adaptively remove rank-1 component training . language modeling task , structured approach outperform unstructured block - structured prune baseline compression level , achieve significant speedup training inference . demonstrate method apply prune adaptive word embedding large language model , prune bert model downstream fine - tuning classification benchmark . 1 * denote equal contribution .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 2, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Seq2Edits: Sequence Transduction Using Span-level Edit Operations,"We propose Seq2Edits, an open-vocabulary approach to sequence editing for natural language processing (NLP) tasks with a high degree of overlap between input and output texts. In this approach, each sequence-to-sequence transduction is represented as a sequence of edit operations, where each operation either replaces an entire source span with target tokens or keeps it unchanged. We evaluate our method on five NLP tasks (text normalization, sentence fusion, sentence splitting & rephrasing, text simplification, and grammatical error correction) and report competitive results across the board. For grammatical error correction, our method speeds up inference by up to 5.2x compared to full sequence models because inference time depends on the number of edits rather than the number of target tokens. For text normalization, sentence fusion, and grammatical error correction, our approach improves explainability by associating each edit operation with a human-readable tag.","Seq2Edits: Sequence Transduction Using Span-level Edit Operations We propose Seq2Edits, an open-vocabulary approach to sequence editing for natural language processing (NLP) tasks with a high degree of overlap between input and output texts. In this approach, each sequence-to-sequence transduction is represented as a sequence of edit operations, where each operation either replaces an entire source span with target tokens or keeps it unchanged. We evaluate our method on five NLP tasks (text normalization, sentence fusion, sentence splitting & rephrasing, text simplification, and grammatical error correction) and report competitive results across the board. For grammatical error correction, our method speeds up inference by up to 5.2x compared to full sequence models because inference time depends on the number of edits rather than the number of target tokens. For text normalization, sentence fusion, and grammatical error correction, our approach improves explainability by associating each edit operation with a human-readable tag.","seq2edits : sequence transduction span - level edit operation propose seq2edits , open - vocabulary approach sequence editing natural language processing ( nlp ) task high degree overlap input output text . approach , sequence - - sequence transduction represent sequence edit operation , operation replace entire source span target token keep unchanged . evaluate method nlp task ( text normalization , sentence fusion , sentence splitting & rephrasing , text simplification , grammatical error correction ) report competitive result board . grammatical error correction , method speed inference 5.2x compare sequence model inference time depend number edit number target token . text normalization , sentence fusion , grammatical error correction , approach improve explainability associate edit operation human - readable tag .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting,"Deep pretrained language models have achieved great success in the way of pretraining first and then fine-tuning. But such a sequential transfer learning paradigm often confronts the catastrophic forgetting problem and leads to sub-optimal performance. To fine-tune with less forgetting, we propose a recall and learn mechanism, which adopts the idea of multi-task learning and jointly learns pretraining tasks and downstream tasks. Specifically, we introduce a Pretraining Simulation mechanism to recall the knowledge from pretraining tasks without data, and an Objective Shifting mechanism to focus the learning on downstream tasks gradually. Experiments show that our method achieves state-of-the-art performance on the GLUE benchmark. Our method also enables BERTbase to achieve better average performance than directly fine-tuning of BERT-large. Further, we provide the open-source RECADAM optimizer, which integrates the proposed mechanisms into Adam optimizer, to facility the NLP community. 1","Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting Deep pretrained language models have achieved great success in the way of pretraining first and then fine-tuning. But such a sequential transfer learning paradigm often confronts the catastrophic forgetting problem and leads to sub-optimal performance. To fine-tune with less forgetting, we propose a recall and learn mechanism, which adopts the idea of multi-task learning and jointly learns pretraining tasks and downstream tasks. Specifically, we introduce a Pretraining Simulation mechanism to recall the knowledge from pretraining tasks without data, and an Objective Shifting mechanism to focus the learning on downstream tasks gradually. Experiments show that our method achieves state-of-the-art performance on the GLUE benchmark. Our method also enables BERTbase to achieve better average performance than directly fine-tuning of BERT-large. Further, we provide the open-source RECADAM optimizer, which integrates the proposed mechanisms into Adam optimizer, to facility the NLP community. 1","recall learn : fine - tune deep pretrained language model forgetting deep pretrained language model achieve great success way pretraine fine - tune . sequential transfer learning paradigm confront catastrophic forgetting problem lead sub - optimal performance . fine - tune forgetting , propose recall learn mechanism , adopt idea multi - task learning jointly learn pretraine task downstream task . specifically , introduce pretraining simulation mechanism recall knowledge pretraine task datum , objective shifting mechanism focus learning downstream task gradually . experiment method achieve state - - - art performance glue benchmark . method enable bertbase achieve well average performance directly fine - tuning bert - large . , provide open - source recadam optimizer , integrate propose mechanism adam optimizer , facility nlp community . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Message Passing for Hyper-Relational Knowledge Graphs,"Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. In this work, we propose a message passing based graph encoder -STARE capable of modeling such hyper-relational KGs. Unlike existing approaches, STARE can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. We also demonstrate that existing benchmarks for evaluating link prediction (LP) performance on hyper-relational KGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset -WD50K. Our experiments demonstrate that STARE based LP model outperforms existing approaches across multiple benchmarks. We also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 MRR points compared to triple-based representations.","Message Passing for Hyper-Relational Knowledge Graphs Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating additional key-value pairs along with the main triple to disambiguate, or restrict the validity of a fact. In this work, we propose a message passing based graph encoder -STARE capable of modeling such hyper-relational KGs. Unlike existing approaches, STARE can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. We also demonstrate that existing benchmarks for evaluating link prediction (LP) performance on hyper-relational KGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset -WD50K. Our experiments demonstrate that STARE based LP model outperforms existing approaches across multiple benchmarks. We also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 MRR points compared to triple-based representations.","message passing hyper - relational knowledge graphs hyper - relational knowledge graph ( kg ) ( e.g. , wikidata ) enable associate additional key - value pair main triple disambiguate , restrict validity fact . work , propose message passing base graph encoder -stare capable model hyper - relational kg . unlike exist approach , stare encode arbitrary number additional information ( qualifier ) main triple keep semantic role qualifier triple intact . demonstrate exist benchmark evaluate link prediction ( lp ) performance hyper - relational kg suffer fundamental flaw develop new wikidata - base dataset -wd50k. experiment demonstrate stare base lp model outperform exist approach multiple benchmark . confirm leverage qualifier vital link prediction gain 25 mrr point compare triple - base representation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Machine Learning for NLP,Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with Reinforcement Learning,"Interactive Fiction (IF) games with real humanwritten natural language texts provide a new natural evaluation for language understanding techniques. In contrast to previous text games with mostly synthetic texts, IF games pose language understanding challenges on the humanwritten textual descriptions of diverse and sophisticated game worlds and language generation challenges on the action command generation from less restricted combinatorial space. We take a novel perspective of IF game solving and re-formulate it as Multi-Passage Reading Comprehension (MPRC) tasks. Our approaches utilize the context-query attention mechanisms and the structured prediction in MPRC to efficiently generate and evaluate action outputs and apply an object-centric historical observation retrieval strategy to mitigate the partial observability of the textual observations. Extensive experiments on the recent IF benchmark (Jericho) demonstrate clear advantages of our approaches achieving high winning rates and low data requirements compared to all previous approaches. 1","Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with Reinforcement Learning Interactive Fiction (IF) games with real humanwritten natural language texts provide a new natural evaluation for language understanding techniques. In contrast to previous text games with mostly synthetic texts, IF games pose language understanding challenges on the humanwritten textual descriptions of diverse and sophisticated game worlds and language generation challenges on the action command generation from less restricted combinatorial space. We take a novel perspective of IF game solving and re-formulate it as Multi-Passage Reading Comprehension (MPRC) tasks. Our approaches utilize the context-query attention mechanisms and the structured prediction in MPRC to efficiently generate and evaluate action outputs and apply an object-centric historical observation retrieval strategy to mitigate the partial observability of the textual observations. Extensive experiments on the recent IF benchmark (Jericho) demonstrate clear advantages of our approaches achieving high winning rates and low data requirements compared to all previous approaches. 1","interactive fiction game play multi - paragraph reading comprehension reinforcement learning interactive fiction ( ) game real humanwritten natural language text provide new natural evaluation language understanding technique . contrast previous text game synthetic text , game pose language understanding challenge humanwritten textual description diverse sophisticated game world language generation challenge action command generation restricted combinatorial space . novel perspective game solving - formulate multi - passage reading comprehension ( mprc ) task . approach utilize context - query attention mechanism structure prediction mprc efficiently generate evaluate action output apply object - centric historical observation retrieval strategy mitigate partial observability textual observation . extensive experiment recent benchmark ( jericho ) demonstrate clear advantage approach achieve high winning rate low data requirement compare previous approach . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 6, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,SetConv: A New Approach for Learning from Imbalanced Data,"For many real-world classification problems, e.g., sentiment classification, most existing machine learning methods are biased towards the majority class when the Imbalance Ratio (IR) is high. To address this problem, we propose a set convolution (SetConv) operation and an episodic training strategy to extract a single representative for each class, so that classifiers can later be trained on a balanced class distribution. We prove that our proposed algorithm is permutation-invariant despite the order of inputs, and experiments on multiple large-scale benchmark text datasets show the superiority of our proposed framework when compared to other SOTA methods.","SetConv: A New Approach for Learning from Imbalanced Data For many real-world classification problems, e.g., sentiment classification, most existing machine learning methods are biased towards the majority class when the Imbalance Ratio (IR) is high. To address this problem, we propose a set convolution (SetConv) operation and an episodic training strategy to extract a single representative for each class, so that classifiers can later be trained on a balanced class distribution. We prove that our proposed algorithm is permutation-invariant despite the order of inputs, and experiments on multiple large-scale benchmark text datasets show the superiority of our proposed framework when compared to other SOTA methods.","setconv : new approach learn imbalanced datum real - world classification problem , e.g. , sentiment classification , exist machine learning method bias majority class imbalance ratio ( ir ) high . address problem , propose set convolution ( setconv ) operation episodic training strategy extract single representative class , classifier later train balanced class distribution . prove propose algorithm permutation - invariant despite order input , experiment multiple large - scale benchmark text dataset superiority propose framework compare sota method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,BERT-ATTACK: Adversarial Attack Against BERT Using BERT,"Adversarial attacks for discrete data (such as texts) have been proved significantly more challenging than continuous data (such as images) since it is difficult to generate adversarial samples with gradient-based methods. Current successful attack methods for texts usually adopt heuristic replacement strategies on the character or word level, which remains challenging to find the optimal solution in the massive space of possible combinations of replacements while preserving semantic consistency and language fluency. In this paper, we propose BERT-Attack, a high-quality and effective method to generate adversarial samples using pre-trained masked language models exemplified by BERT. We turn BERT against its fine-tuned models and other deep neural models in downstream tasks so that we can successfully mislead the target models to predict incorrectly. Our method outperforms state-of-theart attack strategies in both success rate and perturb percentage, while the generated adversarial samples are fluent and semantically preserved. Also, the cost of calculation is low, thus possible for large-scale generations. The code is available at https://github.com/ LinyangLee/BERT-Attack.","BERT-ATTACK: Adversarial Attack Against BERT Using BERT Adversarial attacks for discrete data (such as texts) have been proved significantly more challenging than continuous data (such as images) since it is difficult to generate adversarial samples with gradient-based methods. Current successful attack methods for texts usually adopt heuristic replacement strategies on the character or word level, which remains challenging to find the optimal solution in the massive space of possible combinations of replacements while preserving semantic consistency and language fluency. In this paper, we propose BERT-Attack, a high-quality and effective method to generate adversarial samples using pre-trained masked language models exemplified by BERT. We turn BERT against its fine-tuned models and other deep neural models in downstream tasks so that we can successfully mislead the target models to predict incorrectly. Our method outperforms state-of-theart attack strategies in both success rate and perturb percentage, while the generated adversarial samples are fluent and semantically preserved. Also, the cost of calculation is low, thus possible for large-scale generations. The code is available at https://github.com/ LinyangLee/BERT-Attack.","bert - attack : adversarial attack bert bert adversarial attack discrete datum ( text ) prove significantly challenging continuous datum ( image ) difficult generate adversarial sample gradient - base method . current successful attack method text usually adopt heuristic replacement strategy character word level , remain challenging find optimal solution massive space possible combination replacement preserve semantic consistency language fluency . paper , propose bert - attack , high - quality effective method generate adversarial sample pre - trained mask language model exemplify bert . turn bert fine - tune model deep neural model downstream task successfully mislead target model predict incorrectly . method outperform state - - theart attack strategy success rate perturb percentage , generate adversarial sample fluent semantically preserve . , cost calculation low , possible large - scale generation . code available https://github.com/ linyanglee / bert - attack .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Translation and Multilinguality,Multi-Unit Transformers for Neural Machine Translation,"Transformer models (Vaswani et al., 2017) achieve remarkable success in Neural Machine Translation. Many efforts have been devoted to deepening the Transformer by stacking several units (i.e., a combination of Multihead Attentions and FFN) in a cascade, while the investigation over multiple parallel units draws little attention. In this paper, we propose the Multi-Unit TransformErs (MUTE), which aim to promote the expressiveness of the Transformer by introducing diverse and complementary units. Specifically, we use several parallel units and show that modeling with multiple units improves model performance and introduces diversity. Further, to better leverage the advantage of the multi-unit setting, we design biased module and sequential dependency that guide and encourage complementariness among different units. Experimental results on three machine translation tasks, the NIST Chinese-to-English, WMT'14 English-to-German and WMT'18 Chinese-to-English, show that the MUTE models significantly outperform the Transformer-Base, by up to +1.52, +1.90 and +1.10 BLEU points, with only a mild drop in inference speed (about 3.1%). In addition, our methods also surpass the Transformer-Big model, with only 54% of its parameters. These results demonstrate the effectiveness of the MUTE, as well as its efficiency in both the inference process and parameter usage. 1","Multi-Unit Transformers for Neural Machine Translation Transformer models (Vaswani et al., 2017) achieve remarkable success in Neural Machine Translation. Many efforts have been devoted to deepening the Transformer by stacking several units (i.e., a combination of Multihead Attentions and FFN) in a cascade, while the investigation over multiple parallel units draws little attention. In this paper, we propose the Multi-Unit TransformErs (MUTE), which aim to promote the expressiveness of the Transformer by introducing diverse and complementary units. Specifically, we use several parallel units and show that modeling with multiple units improves model performance and introduces diversity. Further, to better leverage the advantage of the multi-unit setting, we design biased module and sequential dependency that guide and encourage complementariness among different units. Experimental results on three machine translation tasks, the NIST Chinese-to-English, WMT'14 English-to-German and WMT'18 Chinese-to-English, show that the MUTE models significantly outperform the Transformer-Base, by up to +1.52, +1.90 and +1.10 BLEU points, with only a mild drop in inference speed (about 3.1%). In addition, our methods also surpass the Transformer-Big model, with only 54% of its parameters. These results demonstrate the effectiveness of the MUTE, as well as its efficiency in both the inference process and parameter usage. 1","multi - unit transformers neural machine translation transformer model ( vaswani et al . , 2017 ) achieve remarkable success neural machine translation . effort devote deepen transformer stack unit ( i.e. , combination multihead attentions ffn ) cascade , investigation multiple parallel unit draw little attention . paper , propose multi - unit transformers ( mute ) , aim promote expressiveness transformer introduce diverse complementary unit . specifically , use parallel unit model multiple unit improve model performance introduce diversity . , well leverage advantage multi - unit setting , design biased module sequential dependency guide encourage complementariness different unit . experimental result machine translation task , nist chinese - - english , wmt'14 english - - german wmt'18 chinese - - english , mute model significantly outperform transformer - base , +1.52 , +1.90 +1.10 bleu point , mild drop inference speed ( 3.1 % ) . addition , method surpass transformer - big model , 54 % parameter . result demonstrate effectiveness mute , efficiency inference process parameter usage . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 11, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Uncertainty-Aware Semantic Augmentation for Neural Machine Translation,"As a sequence-to-sequence generation task, neural machine translation (NMT) naturally contains intrinsic uncertainty, where a single sentence in one language has multiple valid counterparts in the other. However, the dominant methods for NMT only observe one of them from the parallel corpora for the model training but have to deal with adequate variations under the same meaning at inference. This leads to a discrepancy of the data distribution between the training and the inference phases. To address this problem, we propose uncertainty-aware semantic augmentation, which explicitly captures the universal semantic information among multiple semantically-equivalent source sentences and enhances the hidden representations with this information for better translations. Extensive experiments on various translation tasks reveal that our approach significantly outperforms the strong baselines and the existing methods.","Uncertainty-Aware Semantic Augmentation for Neural Machine Translation As a sequence-to-sequence generation task, neural machine translation (NMT) naturally contains intrinsic uncertainty, where a single sentence in one language has multiple valid counterparts in the other. However, the dominant methods for NMT only observe one of them from the parallel corpora for the model training but have to deal with adequate variations under the same meaning at inference. This leads to a discrepancy of the data distribution between the training and the inference phases. To address this problem, we propose uncertainty-aware semantic augmentation, which explicitly captures the universal semantic information among multiple semantically-equivalent source sentences and enhances the hidden representations with this information for better translations. Extensive experiments on various translation tasks reveal that our approach significantly outperforms the strong baselines and the existing methods.","uncertainty - aware semantic augmentation neural machine translation sequence - - sequence generation task , neural machine translation ( nmt ) naturally contain intrinsic uncertainty , single sentence language multiple valid counterpart . , dominant method nmt observe parallel corpora model training deal adequate variation meaning inference . lead discrepancy datum distribution training inference phase . address problem , propose uncertainty - aware semantic augmentation , explicitly capture universal semantic information multiple semantically - equivalent source sentence enhance hidden representation information well translation . extensive experiment translation task reveal approach significantly outperform strong baseline exist method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Long-Short Term Masking Transformer: A Simple but Effective Baseline for Document-level Neural Machine Translation,"Many document-level neural machine translation (NMT) systems have explored the utility of context-aware architecture, usually requiring an increasing number of parameters and computational complexity. However, few attention is paid to the baseline model. In this paper, we research extensively the pros and cons of the standard transformer in document-level translation, and find that the auto-regressive property can simultaneously bring both the advantage of the consistency and the disadvantage of error accumulation. Therefore, we propose a surprisingly simple long-short term masking self-attention on top of the standard transformer to both effectively capture the long-range dependence and reduce the propagation of errors. We examine our approach on the two publicly available document-level datasets. We can achieve a strong result in BLEU and capture discourse phenomena.","Long-Short Term Masking Transformer: A Simple but Effective Baseline for Document-level Neural Machine Translation Many document-level neural machine translation (NMT) systems have explored the utility of context-aware architecture, usually requiring an increasing number of parameters and computational complexity. However, few attention is paid to the baseline model. In this paper, we research extensively the pros and cons of the standard transformer in document-level translation, and find that the auto-regressive property can simultaneously bring both the advantage of the consistency and the disadvantage of error accumulation. Therefore, we propose a surprisingly simple long-short term masking self-attention on top of the standard transformer to both effectively capture the long-range dependence and reduce the propagation of errors. We examine our approach on the two publicly available document-level datasets. We can achieve a strong result in BLEU and capture discourse phenomena.","long - short term masking transformer : simple effective baseline document - level neural machine translation document - level neural machine translation ( nmt ) system explore utility context - aware architecture , usually require increase number parameter computational complexity . , attention pay baseline model . paper , research extensively pro con standard transformer document - level translation , find auto - regressive property simultaneously bring advantage consistency disadvantage error accumulation . , propose surprisingly simple long - short term mask self - attention standard transformer effectively capture long - range dependence reduce propagation error . examine approach publicly available document - level dataset . achieve strong result bleu capture discourse phenomenon .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Simulated multiple reference training improves low-resource machine translation,"Many valid translations exist for a given sentence, yet machine translation (MT) is trained with a single reference translation, exacerbating data sparsity in low-resource settings. We introduce Simulated Multiple Reference Training (SMRT), a novel MT training method that approximates the full space of possible translations by sampling a paraphrase of the reference sentence from a paraphraser and training the MT model to predict the paraphraser's distribution over possible tokens. We demonstrate the effectiveness of SMRT in low-resource settings when translating to English, with improvements of 1.2 to 7.0 BLEU. We also find SMRT is complementary to back-translation.","Simulated multiple reference training improves low-resource machine translation Many valid translations exist for a given sentence, yet machine translation (MT) is trained with a single reference translation, exacerbating data sparsity in low-resource settings. We introduce Simulated Multiple Reference Training (SMRT), a novel MT training method that approximates the full space of possible translations by sampling a paraphrase of the reference sentence from a paraphraser and training the MT model to predict the paraphraser's distribution over possible tokens. We demonstrate the effectiveness of SMRT in low-resource settings when translating to English, with improvements of 1.2 to 7.0 BLEU. We also find SMRT is complementary to back-translation.","simulate multiple reference training improve low - resource machine translation valid translation exist give sentence , machine translation ( mt ) train single reference translation , exacerbate data sparsity low - resource setting . introduce simulated multiple reference training ( smrt ) , novel mt training method approximate space possible translation sample paraphrase reference sentence paraphraser train mt model predict paraphraser distribution possible token . demonstrate effectiveness smrt low - resource setting translate english , improvement 1.2 7.0 bleu . find smrt complementary - translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Self-Induced Curriculum Learning in Self-Supervised Neural Machine Translation,"Self-supervised neural machine translation (SSNMT) jointly learns to identify and select suitable training data from comparable (rather than parallel) corpora and to translate, in a way that the two tasks support each other in a virtuous circle. In this study, we provide an in-depth analysis of the sampling choices the SSNMT model makes during training. We show how, without it having been told to do so, the model self-selects samples of increasing (i) complexity and (ii) task-relevance in combination with (iii) performing a denoising curriculum. We observe that the dynamics of the mutual-supervision signals of both system internal representation types are vital for the extraction and translation performance. We show that in terms of the Gunning-Fog Readability index, SSNMT starts extracting and learning from Wikipedia data suitable for high school students and quickly moves towards content suitable for first year undergraduate students.","Self-Induced Curriculum Learning in Self-Supervised Neural Machine Translation Self-supervised neural machine translation (SSNMT) jointly learns to identify and select suitable training data from comparable (rather than parallel) corpora and to translate, in a way that the two tasks support each other in a virtuous circle. In this study, we provide an in-depth analysis of the sampling choices the SSNMT model makes during training. We show how, without it having been told to do so, the model self-selects samples of increasing (i) complexity and (ii) task-relevance in combination with (iii) performing a denoising curriculum. We observe that the dynamics of the mutual-supervision signals of both system internal representation types are vital for the extraction and translation performance. We show that in terms of the Gunning-Fog Readability index, SSNMT starts extracting and learning from Wikipedia data suitable for high school students and quickly moves towards content suitable for first year undergraduate students.","self - induce curriculum learning self - supervised neural machine translation self - supervised neural machine translation ( ssnmt ) jointly learn identify select suitable training datum comparable ( parallel ) corpus translate , way task support virtuous circle . study , provide - depth analysis sampling choice ssnmt model make training . , have tell , model self - select sample increase ( ) complexity ( ii ) task - relevance combination ( iii ) perform denoise curriculum . observe dynamic mutual - supervision signal system internal representation type vital extraction translation performance . term gunning - fog readability index , ssnmt start extract learn wikipedia datum suitable high school student quickly move content suitable year undergraduate student .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning,"In order to simulate human language capacity, natural language processing systems must be able to reason about the dynamics of everyday situations, including their possible causes and effects. Moreover, they should be able to generalise the acquired world knowledge to new languages, modulo cultural differences. Advances in machine reasoning and cross-lingual transfer depend on the availability of challenging evaluation benchmarks. Motivated by both demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a typologically diverse multilingual dataset for causal commonsense reasoning in 11 languages, which includes resource-poor languages like Eastern Apurímac Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on this novel dataset, revealing that the performance of current methods based on multilingual pretraining and zero-shot fine-tuning falls short compared to translation-based transfer. Finally, we propose strategies to adapt multilingual models to out-of-sample resource-lean languages where only a small corpus or a bilingual dictionary is available, and report substantial improvements over the random baseline. The XCOPA dataset is freely available at github.com/cambridgeltl/xcopa.","XCOPA: A Multilingual Dataset for Causal Commonsense Reasoning In order to simulate human language capacity, natural language processing systems must be able to reason about the dynamics of everyday situations, including their possible causes and effects. Moreover, they should be able to generalise the acquired world knowledge to new languages, modulo cultural differences. Advances in machine reasoning and cross-lingual transfer depend on the availability of challenging evaluation benchmarks. Motivated by both demands, we introduce Cross-lingual Choice of Plausible Alternatives (XCOPA), a typologically diverse multilingual dataset for causal commonsense reasoning in 11 languages, which includes resource-poor languages like Eastern Apurímac Quechua and Haitian Creole. We evaluate a range of state-of-the-art models on this novel dataset, revealing that the performance of current methods based on multilingual pretraining and zero-shot fine-tuning falls short compared to translation-based transfer. Finally, we propose strategies to adapt multilingual models to out-of-sample resource-lean languages where only a small corpus or a bilingual dictionary is available, and report substantial improvements over the random baseline. The XCOPA dataset is freely available at github.com/cambridgeltl/xcopa.","xcopa : multilingual dataset causal commonsense reasoning order simulate human language capacity , natural language processing system able reason dynamic everyday situation , include possible cause effect . , able generalise acquire world knowledge new language , modulo cultural difference . advance machine reasoning cross - lingual transfer depend availability challenge evaluation benchmark . motivate demand , introduce cross - lingual choice plausible alternatives ( xcopa ) , typologically diverse multilingual dataset causal commonsense reasoning 11 language , include resource - poor language like eastern apurímac quechua haitian creole . evaluate range state - - - art model novel dataset , reveal performance current method base multilingual pretraining zero - shot fine - tuning fall short compare translation - base transfer . finally , propose strategy adapt multilingual model - - sample resource - lean language small corpus bilingual dictionary available , report substantial improvement random baseline . xcopa dataset freely available github.com/cambridgeltl/xcopa .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Translation and Multilinguality,Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers,"With the growth of computing power neural machine translation (NMT) models also grow accordingly and become better. However, they also become harder to deploy on edge devices due to memory constraints. To cope with this problem, a common practice is to distill knowledge from a large and accurately-trained teacher network (T ) into a compact student network (S). Although knowledge distillation (KD) is useful in most cases, our study shows that existing KD techniques might not be suitable enough for deep NMT engines, so we propose a novel alternative. In our model, besides matching T and S predictions we have a combinatorial mechanism to inject layer-level supervision from T to S. In this paper, we target low-resource settings and evaluate our translation engines for Portuguese→English, Turkish→English, and English→German directions. Students trained using our technique have 50% fewer parameters and can still deliver comparable results to those of 12-layer teachers.","Why Skip If You Can Combine: A Simple Knowledge Distillation Technique for Intermediate Layers With the growth of computing power neural machine translation (NMT) models also grow accordingly and become better. However, they also become harder to deploy on edge devices due to memory constraints. To cope with this problem, a common practice is to distill knowledge from a large and accurately-trained teacher network (T ) into a compact student network (S). Although knowledge distillation (KD) is useful in most cases, our study shows that existing KD techniques might not be suitable enough for deep NMT engines, so we propose a novel alternative. In our model, besides matching T and S predictions we have a combinatorial mechanism to inject layer-level supervision from T to S. In this paper, we target low-resource settings and evaluate our translation engines for Portuguese→English, Turkish→English, and English→German directions. Students trained using our technique have 50% fewer parameters and can still deliver comparable results to those of 12-layer teachers.","skip combine : simple knowledge distillation technique intermediate layer growth compute power neural machine translation ( nmt ) model grow accordingly well . , hard deploy edge device memory constraint . cope problem , common practice distill knowledge large accurately - train teacher network ( t ) compact student network ( s ) . knowledge distillation ( kd ) useful case , study show exist kd technique suitable deep nmt engine , propose novel alternative . model , match t s prediction combinatorial mechanism inject layer - level supervision t s. paper , target low - resource setting evaluate translation engine portuguese→english , turkish→english , english→german direction . student train technique 50 % few parameter deliver comparable result 12 - layer teacher .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Self-Paced Learning for Neural Machine Translation,"Recent studies have proven that the training of neural machine translation (NMT) can be facilitated by mimicking the learning process of humans. Nevertheless, achievements of such kind of curriculum learning rely on the quality of artificial schedule drawn up with the handcrafted features, e.g. sentence length or word rarity. We ameliorate this procedure with a more flexible manner by proposing self-paced learning, where NMT model is allowed to 1) automatically quantify the learning confidence over training examples; and 2) flexibly govern its learning via regulating the loss in each iteration step. Experimental results over multiple translation tasks demonstrate that the proposed model yields better performance than strong baselines and those models trained with human-designed curricula on both translation quality and convergence speed. 1","Self-Paced Learning for Neural Machine Translation Recent studies have proven that the training of neural machine translation (NMT) can be facilitated by mimicking the learning process of humans. Nevertheless, achievements of such kind of curriculum learning rely on the quality of artificial schedule drawn up with the handcrafted features, e.g. sentence length or word rarity. We ameliorate this procedure with a more flexible manner by proposing self-paced learning, where NMT model is allowed to 1) automatically quantify the learning confidence over training examples; and 2) flexibly govern its learning via regulating the loss in each iteration step. Experimental results over multiple translation tasks demonstrate that the proposed model yields better performance than strong baselines and those models trained with human-designed curricula on both translation quality and convergence speed. 1","self - paced learning neural machine translation recent study prove training neural machine translation ( nmt ) facilitate mimic learning process human . , achievement kind curriculum learning rely quality artificial schedule draw handcraft feature , e.g. sentence length word rarity . ameliorate procedure flexible manner propose self - pace learning , nmt model allow 1 ) automatically quantify learning confidence training example ; 2 ) flexibly govern learning regulate loss iteration step . experimental result multiple translation task demonstrate propose model yield well performance strong baseline model train human - design curricula translation quality convergence speed . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Learn to Cross-lingual Transfer with Meta Graph Learning Across Heterogeneous Languages,"The recent emergence of multilingual pretraining language model (mPLM) has enabled breakthroughs on various downstream crosslingual transfer (CLT) tasks. However, mPLMbased methods usually involve two problems: (1) simply fine-tuning may not adapt generalpurpose multilingual representations to be task-aware on low-resource languages; (2) ignore how cross-lingual adaptation happens for downstream tasks. To address the issues, we propose a meta graph learning (MGL) method. Unlike prior works that transfer from scratch, MGL can learn to cross-lingual transfer by extracting meta-knowledge from historical CLT experiences (tasks), making mPLM insensitive to low-resource languages. Besides, for each CLT task, MGL formulates its transfer process as information propagation over a dynamic graph, where the geometric structure can automatically capture intrinsic language relationships to guide cross-lingual transfer explicitly. Empirically, extensive experiments on both public and real-world datasets demonstrate the effectiveness of the MGL method. * The work was done when Zheng Li was an intern at Amazon.com Inc. We thank the support of Hong Kong CERG  grants (16209715 & 16244616)  and NSFC 61673202.","Learn to Cross-lingual Transfer with Meta Graph Learning Across Heterogeneous Languages The recent emergence of multilingual pretraining language model (mPLM) has enabled breakthroughs on various downstream crosslingual transfer (CLT) tasks. However, mPLMbased methods usually involve two problems: (1) simply fine-tuning may not adapt generalpurpose multilingual representations to be task-aware on low-resource languages; (2) ignore how cross-lingual adaptation happens for downstream tasks. To address the issues, we propose a meta graph learning (MGL) method. Unlike prior works that transfer from scratch, MGL can learn to cross-lingual transfer by extracting meta-knowledge from historical CLT experiences (tasks), making mPLM insensitive to low-resource languages. Besides, for each CLT task, MGL formulates its transfer process as information propagation over a dynamic graph, where the geometric structure can automatically capture intrinsic language relationships to guide cross-lingual transfer explicitly. Empirically, extensive experiments on both public and real-world datasets demonstrate the effectiveness of the MGL method. * The work was done when Zheng Li was an intern at Amazon.com Inc. We thank the support of Hong Kong CERG  grants (16209715 & 16244616)  and NSFC 61673202.","learn cross - lingual transfer meta graph learning heterogeneous language recent emergence multilingual pretraine language model ( mplm ) enable breakthrough downstream crosslingual transfer ( clt ) task . , mplmbased method usually involve problem : ( 1 ) simply fine - tuning adapt generalpurpose multilingual representation task - aware low - resource language ; ( 2 ) ignore cross - lingual adaptation happen downstream task . address issue , propose meta graph learning ( mgl ) method . unlike prior work transfer scratch , mgl learn cross - lingual transfer extract meta - knowledge historical clt experience ( task ) , make mplm insensitive low - resource language . , clt task , mgl formulate transfer process information propagation dynamic graph , geometric structure automatically capture intrinsic language relationship guide cross - lingual transfer explicitly . empirically , extensive experiment public real - world dataset demonstrate effectiveness mgl method . * work zheng li intern amazon.com inc. thank support hong kong cerg   grant ( 16209715 & 16244616 )   nsfc 61673202 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Machine Translation and Multilinguality,ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization,"Cherokee is a highly endangered Native American language spoken by the Cherokee people. The Cherokee culture is deeply embedded in its language. However, there are approximately only 2,000 fluent first language Cherokee speakers remaining in the world, and the number is declining every year. To help save this endangered language, we introduce ChrEn, a Cherokee-English parallel dataset, to facilitate machine translation research between Cherokee and English. Compared to some popular machine translation language pairs, ChrEn is extremely low-resource, only containing 14k sentence pairs in total. We split our parallel data in ways that facilitate both in-domain and out-of-domain evaluation. We also collect 5k Cherokee monolingual data to enable semi-supervised learning. Besides these datasets, we propose several Cherokee-English and English-Cherokee machine translation systems. We compare SMT (phrase-based) versus NMT (RNN-based and Transformer-based) systems; supervised versus semi-supervised (via language model, back-translation, and BERT/Multilingual-BERT) methods; as well as transfer learning versus multilingual joint training with 4 other languages. Our best results are 15.8/12.7 BLEU for in-domain and 6.5/5.0 BLEU for out-of-domain Chr-En/En-Chr translations, respectively, and we hope that our dataset and systems will encourage future work by the community for Cherokee language revitalization. 1","ChrEn: Cherokee-English Machine Translation for Endangered Language Revitalization Cherokee is a highly endangered Native American language spoken by the Cherokee people. The Cherokee culture is deeply embedded in its language. However, there are approximately only 2,000 fluent first language Cherokee speakers remaining in the world, and the number is declining every year. To help save this endangered language, we introduce ChrEn, a Cherokee-English parallel dataset, to facilitate machine translation research between Cherokee and English. Compared to some popular machine translation language pairs, ChrEn is extremely low-resource, only containing 14k sentence pairs in total. We split our parallel data in ways that facilitate both in-domain and out-of-domain evaluation. We also collect 5k Cherokee monolingual data to enable semi-supervised learning. Besides these datasets, we propose several Cherokee-English and English-Cherokee machine translation systems. We compare SMT (phrase-based) versus NMT (RNN-based and Transformer-based) systems; supervised versus semi-supervised (via language model, back-translation, and BERT/Multilingual-BERT) methods; as well as transfer learning versus multilingual joint training with 4 other languages. Our best results are 15.8/12.7 BLEU for in-domain and 6.5/5.0 BLEU for out-of-domain Chr-En/En-Chr translations, respectively, and we hope that our dataset and systems will encourage future work by the community for Cherokee language revitalization. 1","chren : cherokee - english machine translation endangered language revitalization cherokee highly endanger native american language speak cherokee people . cherokee culture deeply embed language . , approximately 2,000 fluent language cherokee speaker remain world , number decline year . help save endanger language , introduce chren , cherokee - english parallel dataset , facilitate machine translation research cherokee english . compare popular machine translation language pair , chren extremely low - resource , contain 14k sentence pair total . split parallel datum way facilitate - domain - - domain evaluation . collect 5k cherokee monolingual datum enable semi - supervised learning . dataset , propose cherokee - english english - cherokee machine translation system . compare smt ( phrase - base ) versus nmt ( rnn - base transformer - base ) system ; supervised versus semi - supervised ( language model , - translation , bert / multilingual - bert ) method ; transfer learning versus multilingual joint training 4 language . good result 15.8/12.7 bleu - domain 6.5/5.0 bleu - - domain chr - en / en - chr translation , respectively , hope dataset system encourage future work community cherokee language revitalization . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation,"We propose an efficient inference procedure for non-autoregressive machine translation that iteratively refines translation purely in the continuous space. Given a continuous latent variable model for machine translation (Shu et al., 2020) , we train an inference network to approximate the gradient of the marginal log probability of the target sentence, using only the latent variable as input. This allows us to use gradient-based optimization to find the target sentence at inference time that approximately maximizes its marginal probability. As each refinement step only involves computation in the latent space of low dimensionality (we use 8 in our experiments), we avoid computational overhead incurred by existing non-autoregressive inference procedures that often refine in token space. We compare our approach to a recently proposed EM-like inference procedure (Shu et al., 2020 ) that optimizes in a hybrid space, consisting of both discrete and continuous variables. We evaluate our approach on WMT'14 En→De, WMT'16 Ro→En and IWSLT'16 De→En, and observe two advantages over the EM-like inference: (1) it is computationally efficient, i.e. each refinement step is twice as fast, and (2) it is more effective, resulting in higher marginal probabilities and BLEU scores with the same number of refinement steps. On WMT'14 En→De, for instance, our approach is able to decode 6.2 times faster than the autoregressive model with minimal degradation to translation quality (0.9 BLEU).","Iterative Refinement in the Continuous Space for Non-Autoregressive Neural Machine Translation We propose an efficient inference procedure for non-autoregressive machine translation that iteratively refines translation purely in the continuous space. Given a continuous latent variable model for machine translation (Shu et al., 2020) , we train an inference network to approximate the gradient of the marginal log probability of the target sentence, using only the latent variable as input. This allows us to use gradient-based optimization to find the target sentence at inference time that approximately maximizes its marginal probability. As each refinement step only involves computation in the latent space of low dimensionality (we use 8 in our experiments), we avoid computational overhead incurred by existing non-autoregressive inference procedures that often refine in token space. We compare our approach to a recently proposed EM-like inference procedure (Shu et al., 2020 ) that optimizes in a hybrid space, consisting of both discrete and continuous variables. We evaluate our approach on WMT'14 En→De, WMT'16 Ro→En and IWSLT'16 De→En, and observe two advantages over the EM-like inference: (1) it is computationally efficient, i.e. each refinement step is twice as fast, and (2) it is more effective, resulting in higher marginal probabilities and BLEU scores with the same number of refinement steps. On WMT'14 En→De, for instance, our approach is able to decode 6.2 times faster than the autoregressive model with minimal degradation to translation quality (0.9 BLEU).","iterative refinement continuous space non - autoregressive neural machine translation propose efficient inference procedure non - autoregressive machine translation iteratively refine translation purely continuous space . give continuous latent variable model machine translation ( shu et al . , 2020 ) , train inference network approximate gradient marginal log probability target sentence , latent variable input . allow use gradient - base optimization find target sentence inference time approximately maximize marginal probability . refinement step involve computation latent space low dimensionality ( use 8 experiment ) , avoid computational overhead incur exist non - autoregressive inference procedure refine token space . compare approach recently propose em - like inference procedure ( shu et al . , 2020 ) optimize hybrid space , consist discrete continuous variable . evaluate approach wmt'14 en→de , wmt'16 ro→en iwslt'16 de→en , observe advantage em - like inference : ( 1 ) computationally efficient , i.e. refinement step twice fast , ( 2 ) effective , result high marginal probability bleu score number refinement step . wmt'14 en→de , instance , approach able decode 6.2 time fast autoregressive model minimal degradation translation quality ( 0.9 bleu ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 15, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing,"We frame the task of machine translation evaluation as one of scoring machine translation output with a sequence-to-sequence paraphraser, conditioned on a human reference. We propose training the paraphraser as a multilingual NMT system, treating paraphrasing as a zero-shot translation task (e.g., Czech to Czech). This results in the paraphraser's output mode being centered around a copy of the input sequence, which represents the best case scenario where the MT system output matches a human reference. Our method is simple and intuitive, and does not require human judgements for training. Our single model (trained in 39 languages) outperforms or statistically ties with all prior metrics on the WMT 2019 segment-level shared metrics task in all languages (excluding Gujarati where the model had no training data). We also explore using our model for the task of quality estimation as a metric-conditioning on the source instead of the reference-and find that it significantly outperforms every submission to the WMT 2019 shared task on quality estimation in every language pair. Word-level paraphraser log probabilities H(out|in) sBLEU LASER Copy Jason went to school at the University of Madrid . <EOS> -0.","Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing We frame the task of machine translation evaluation as one of scoring machine translation output with a sequence-to-sequence paraphraser, conditioned on a human reference. We propose training the paraphraser as a multilingual NMT system, treating paraphrasing as a zero-shot translation task (e.g., Czech to Czech). This results in the paraphraser's output mode being centered around a copy of the input sequence, which represents the best case scenario where the MT system output matches a human reference. Our method is simple and intuitive, and does not require human judgements for training. Our single model (trained in 39 languages) outperforms or statistically ties with all prior metrics on the WMT 2019 segment-level shared metrics task in all languages (excluding Gujarati where the model had no training data). We also explore using our model for the task of quality estimation as a metric-conditioning on the source instead of the reference-and find that it significantly outperforms every submission to the WMT 2019 shared task on quality estimation in every language pair. Word-level paraphraser log probabilities H(out|in) sBLEU LASER Copy Jason went to school at the University of Madrid . <EOS> -0.","automatic machine translation evaluation language zero - shot paraphrasing frame task machine translation evaluation score machine translation output sequence - - sequence paraphraser , condition human reference . propose train paraphraser multilingual nmt system , treat paraphrasing zero - shot translation task ( e.g. , czech czech ) . result paraphraser output mode center copy input sequence , represent good case scenario mt system output match human reference . method simple intuitive , require human judgement training . single model ( train 39 language ) outperform statistically tie prior metric wmt 2019 segment - level share metric task language ( exclude gujarati model training datum ) . explore model task quality estimation metric - conditioning source instead reference - find significantly outperform submission wmt 2019 share task quality estimation language pair . word - level paraphraser log probability h(out|in ) sbleu laser copy jason go school university madrid . < eos > -0 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 8, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,"XGLUE: A New Benchmark Datasetfor Cross-lingual Pre-training, Understanding and Generation","In this paper, we introduce XGLUE, a new benchmark dataset that can be used to train large-scale cross-lingual pre-trained models using multilingual and bilingual corpora and evaluate their performance across a diverse set of cross-lingual tasks. Comparing to GLUE (Wang et al., 2019), which is labeled in English for natural language understanding tasks only, XGLUE has two main advantages: (1) it provides 11 diversified tasks that cover both natural language understanding and generation scenarios; (2) for each task, it provides labeled data in multiple languages. We extend a recent cross-lingual pre-trained model Unicoder (Huang et al., 2019)  to cover both understanding and generation tasks, which is evaluated on XGLUE as a strong baseline. We also evaluate the base versions (12-layer) of Multilingual BERT, XLM and XLM-R for comparison.","XGLUE: A New Benchmark Datasetfor Cross-lingual Pre-training, Understanding and Generation In this paper, we introduce XGLUE, a new benchmark dataset that can be used to train large-scale cross-lingual pre-trained models using multilingual and bilingual corpora and evaluate their performance across a diverse set of cross-lingual tasks. Comparing to GLUE (Wang et al., 2019), which is labeled in English for natural language understanding tasks only, XGLUE has two main advantages: (1) it provides 11 diversified tasks that cover both natural language understanding and generation scenarios; (2) for each task, it provides labeled data in multiple languages. We extend a recent cross-lingual pre-trained model Unicoder (Huang et al., 2019)  to cover both understanding and generation tasks, which is evaluated on XGLUE as a strong baseline. We also evaluate the base versions (12-layer) of Multilingual BERT, XLM and XLM-R for comparison.","xglue : new benchmark datasetfor cross - lingual pre - training , understanding generation paper , introduce xglue , new benchmark dataset train large - scale cross - lingual pre - trained model multilingual bilingual corpus evaluate performance diverse set cross - lingual task . compare glue ( wang et al . , 2019 ) , label english natural language understanding task , xglue main advantage : ( 1 ) provide 11 diversified task cover natural language understanding generation scenario ; ( 2 ) task , provide label datum multiple language . extend recent cross - lingual pre - trained model unicoder ( huang et al . , 2019 )   cover understanding generation task , evaluate xglue strong baseline . evaluate base version ( 12 - layer ) multilingual bert , xlm xlm - r comparison .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,False
Machine Translation and Multilinguality,Zero-Shot Cross-Lingual Transfer with Meta Learning,"Learning what to share between tasks has become a topic of great importance, as strategic sharing of knowledge has been shown to improve downstream task performance. This is particularly important for multilingual applications, as most languages in the world are under-resourced. Here, we consider the setting of training models on multiple different languages at the same time, when little or no data is available for languages other than English. We show that this challenging setup can be approached using meta-learning: in addition to training a source language model, another model learns to select which training instances are the most beneficial to the first. We experiment using standard supervised, zero-shot cross-lingual, as well as fewshot cross-lingual settings for different natural language understanding tasks (natural language inference, question answering). Our extensive experimental setup demonstrates the consistent effectiveness of meta-learning for a total of 15 languages. We improve upon the state-of-the-art for zero-shot and few-shot NLI (on MultiNLI and XNLI) and QA (on the MLQA dataset). A comprehensive error analysis indicates that the correlation of typological features between languages can partly explain when parameter sharing learned via meta-learning is beneficial.","Zero-Shot Cross-Lingual Transfer with Meta Learning Learning what to share between tasks has become a topic of great importance, as strategic sharing of knowledge has been shown to improve downstream task performance. This is particularly important for multilingual applications, as most languages in the world are under-resourced. Here, we consider the setting of training models on multiple different languages at the same time, when little or no data is available for languages other than English. We show that this challenging setup can be approached using meta-learning: in addition to training a source language model, another model learns to select which training instances are the most beneficial to the first. We experiment using standard supervised, zero-shot cross-lingual, as well as fewshot cross-lingual settings for different natural language understanding tasks (natural language inference, question answering). Our extensive experimental setup demonstrates the consistent effectiveness of meta-learning for a total of 15 languages. We improve upon the state-of-the-art for zero-shot and few-shot NLI (on MultiNLI and XNLI) and QA (on the MLQA dataset). A comprehensive error analysis indicates that the correlation of typological features between languages can partly explain when parameter sharing learned via meta-learning is beneficial.","zero - shot cross - lingual transfer meta learn learn share task topic great importance , strategic sharing knowledge show improve downstream task performance . particularly important multilingual application , language world - resource . , consider setting training model multiple different language time , little data available language english . challenging setup approach meta - learning : addition train source language model , model learn select training instance beneficial . experiment standard supervise , zero - shot cross - lingual , fewshot cross - lingual setting different natural language understanding task ( natural language inference , question answering ) . extensive experimental setup demonstrate consistent effectiveness meta - learning total 15 language . improve state - - - art zero - shot - shot nli ( multinli xnli ) qa ( mlqa dataset ) . comprehensive error analysis indicate correlation typological feature language partly explain parameter sharing learn meta - learning beneficial .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 7, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Machine Translation and Multilinguality,"Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation","Despite being the seventh most widely spoken language in the world, Bengali has received much less attention in machine translation literature due to being low in resources. Most publicly available parallel corpora for Bengali are not large enough; and have rather poor quality, mostly because of incorrect sentence alignments resulting from erroneous sentence segmentation, and also because of a high volume of noise present in them. In this work, we build a customized sentence segmenter for Bengali and propose two novel methods for parallel corpus creation on low-resource setups: aligner ensembling and batch filtering. With the segmenter and the two methods combined, we compile a high-quality Bengali-English parallel corpus comprising of 2.75 million sentence pairs, more than 2 million of which were not available before. Training on neural models, we achieve an improvement of more than 9 BLEU score over previous approaches to Bengali-English machine translation. We also evaluate on a new test set of 1000 pairs made with extensive quality control. We release the segmenter, parallel corpus, and the evaluation set, thus elevating Bengali from its low-resource status. To the best of our knowledge, this is the first ever large scale study on Bengali-English machine translation. We believe our study will pave the way for future research on Bengali-English machine translation as well as other low-resource languages. Our data and code are available at https: //github.com/csebuetnlp/banglanmt.","Not Low-Resource Anymore: Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation Despite being the seventh most widely spoken language in the world, Bengali has received much less attention in machine translation literature due to being low in resources. Most publicly available parallel corpora for Bengali are not large enough; and have rather poor quality, mostly because of incorrect sentence alignments resulting from erroneous sentence segmentation, and also because of a high volume of noise present in them. In this work, we build a customized sentence segmenter for Bengali and propose two novel methods for parallel corpus creation on low-resource setups: aligner ensembling and batch filtering. With the segmenter and the two methods combined, we compile a high-quality Bengali-English parallel corpus comprising of 2.75 million sentence pairs, more than 2 million of which were not available before. Training on neural models, we achieve an improvement of more than 9 BLEU score over previous approaches to Bengali-English machine translation. We also evaluate on a new test set of 1000 pairs made with extensive quality control. We release the segmenter, parallel corpus, and the evaluation set, thus elevating Bengali from its low-resource status. To the best of our knowledge, this is the first ever large scale study on Bengali-English machine translation. We believe our study will pave the way for future research on Bengali-English machine translation as well as other low-resource languages. Our data and code are available at https: //github.com/csebuetnlp/banglanmt.","low - resource anymore : aligner ensembling , batch filtering , new dataset bengali - english machine translation despite seventh widely speak language world , bengali receive attention machine translation literature low resource . publicly available parallel corpus bengali large ; poor quality , incorrect sentence alignment result erroneous sentence segmentation , high volume noise present . work , build customize sentence segmenter bengali propose novel method parallel corpus creation low - resource setup : aligner ensembling batch filtering . segmenter method combine , compile high - quality bengali - english parallel corpus comprise 2.75 million sentence pair , 2 million available . train neural model , achieve improvement 9 bleu score previous approach bengali - english machine translation . evaluate new test set 1000 pair extensive quality control . release segmenter , parallel corpus , evaluation set , elevate bengali low - resource status . good knowledge , large scale study bengali - english machine translation . believe study pave way future research bengali - english machine translation low - resource language . datum code available https : //github.com / csebuetnlp / banglanmt .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 9, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Pre-tokenization of Multi-word Expressions in Cross-lingual Word Embeddings,"Cross-lingual word embedding (CWE) algorithms represent words in multiple languages in a unified vector space. Multi-Word Expressions (MWE) are common in every language. When training word embeddings, each component word of an MWE gets its own separate embedding, and thus, MWEs are not translated by CWEs. We propose a simple method for word translation of MWEs to and from English in ten languages: we first compile lists of MWEs in each language and then tokenize the MWEs as single tokens before training word embeddings. CWEs are trained on a wordtranslation task using the dictionaries that only contain single words. In order to evaluate MWE translation, we created bilingual word lists from multilingual WordNet that include single-token words and MWEs, and most importantly, include MWEs that correspond to single words in another language. We show that the pre-tokenization of MWEs as single tokens performs better than averaging the embeddings of the individual tokens of the MWE. We can translate MWEs at a top-10 precision of 30-60%. The tokenization of MWEs makes the occurrences of single words in a training corpus more sparse, but we show that it does not pose negative impacts on single-word translations.","Pre-tokenization of Multi-word Expressions in Cross-lingual Word Embeddings Cross-lingual word embedding (CWE) algorithms represent words in multiple languages in a unified vector space. Multi-Word Expressions (MWE) are common in every language. When training word embeddings, each component word of an MWE gets its own separate embedding, and thus, MWEs are not translated by CWEs. We propose a simple method for word translation of MWEs to and from English in ten languages: we first compile lists of MWEs in each language and then tokenize the MWEs as single tokens before training word embeddings. CWEs are trained on a wordtranslation task using the dictionaries that only contain single words. In order to evaluate MWE translation, we created bilingual word lists from multilingual WordNet that include single-token words and MWEs, and most importantly, include MWEs that correspond to single words in another language. We show that the pre-tokenization of MWEs as single tokens performs better than averaging the embeddings of the individual tokens of the MWE. We can translate MWEs at a top-10 precision of 30-60%. The tokenization of MWEs makes the occurrences of single words in a training corpus more sparse, but we show that it does not pose negative impacts on single-word translations.","pre - tokenization multi - word expression cross - lingual word embedding cross - lingual word embedding ( cwe ) algorithm represent word multiple language unified vector space . multi - word expressions ( mwe ) common language . train word embedding , component word mwe get separate embedding , , mwes translate cwes . propose simple method word translation mwes english language : compile list mwes language tokenize mwes single token train word embedding . cwes train wordtranslation task dictionary contain single word . order evaluate mwe translation , create bilingual word list multilingual wordnet include single - token word mwes , importantly , include mwe correspond single word language . pre - tokenization mwes single token perform well average embedding individual token mwe . translate mwes top-10 precision 30 - 60 % . tokenization mwes make occurrence single word training corpus sparse , pose negative impact single - word translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 22, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 13, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Translation and Multilinguality,CSP:Code-Switching Pre-training for Neural Machine Translation,"This paper proposes a new pre-training method, called Code-Switching Pre-training (CSP for short) for Neural Machine Translation (NMT). Unlike traditional pre-training method which randomly masks some fragments of the input sentence, the proposed CSP randomly replaces some words in the source sentence with their translation words in the target language. Specifically, we firstly perform lexicon induction with unsupervised word embedding mapping between the source and target languages, and then randomly replace some words in the input sentence with their translation words according to the extracted translation lexicons. CSP adopts the encoderdecoder framework: its encoder takes the codemixed sentence as input, and its decoder predicts the replaced fragment of the input sentence. In this way, CSP is able to pre-train the NMT model by explicitly making the most of the cross-lingual alignment information extracted from the source and target monolingual corpus. Additionally, we relieve the pretrainfinetune discrepancy caused by the artificial symbols like [mask]. To verify the effectiveness of the proposed method, we conduct extensive experiments on unsupervised and supervised NMT. Experimental results show that CSP achieves significant improvements over baselines without pre-training or with other pre-training methods.","CSP:Code-Switching Pre-training for Neural Machine Translation This paper proposes a new pre-training method, called Code-Switching Pre-training (CSP for short) for Neural Machine Translation (NMT). Unlike traditional pre-training method which randomly masks some fragments of the input sentence, the proposed CSP randomly replaces some words in the source sentence with their translation words in the target language. Specifically, we firstly perform lexicon induction with unsupervised word embedding mapping between the source and target languages, and then randomly replace some words in the input sentence with their translation words according to the extracted translation lexicons. CSP adopts the encoderdecoder framework: its encoder takes the codemixed sentence as input, and its decoder predicts the replaced fragment of the input sentence. In this way, CSP is able to pre-train the NMT model by explicitly making the most of the cross-lingual alignment information extracted from the source and target monolingual corpus. Additionally, we relieve the pretrainfinetune discrepancy caused by the artificial symbols like [mask]. To verify the effectiveness of the proposed method, we conduct extensive experiments on unsupervised and supervised NMT. Experimental results show that CSP achieves significant improvements over baselines without pre-training or with other pre-training methods.","csp : code - switching pre - training neural machine translation paper propose new pre - training method , call code - switching pre - training ( csp short ) neural machine translation ( nmt ) . unlike traditional pre - training method randomly mask fragment input sentence , propose csp randomly replace word source sentence translation word target language . specifically , firstly perform lexicon induction unsupervised word embedding mapping source target language , randomly replace word input sentence translation word accord extract translation lexicon . csp adopt encoderdecoder framework : encoder take codemixe sentence input , decoder predict replace fragment input sentence . way , csp able pre - train nmt model explicitly make cross - lingual alignment information extract source target monolingual corpus . additionally , relieve pretrainfinetune discrepancy cause artificial symbol like [ mask ] . verify effectiveness propose method , conduct extensive experiment unsupervised supervised nmt . experimental result csp achieve significant improvement baseline pre - training pre - training method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Monolingual Adapters for Zero-Shot Neural Machine Translation,"We propose a novel adapter layer formalism for adapting multilingual models. They are more parameter-efficient than existing adapter layers while obtaining as good or better performance. The layers are specific to one language (as opposed to bilingual adapters) allowing to compose them and generalize to unseen language-pairs. In this zero-shot setting, they obtain a median improvement of +2.77 BLEU points over a strong 20-language multilingual Transformer baseline trained on TED talks.","Monolingual Adapters for Zero-Shot Neural Machine Translation We propose a novel adapter layer formalism for adapting multilingual models. They are more parameter-efficient than existing adapter layers while obtaining as good or better performance. The layers are specific to one language (as opposed to bilingual adapters) allowing to compose them and generalize to unseen language-pairs. In this zero-shot setting, they obtain a median improvement of +2.77 BLEU points over a strong 20-language multilingual Transformer baseline trained on TED talks.","monolingual adapter zero - shot neural machine translation propose novel adapter layer formalism adapt multilingual model . parameter - efficient exist adapter layer obtain good well performance . layer specific language ( oppose bilingual adapter ) allow compose generalize unseen language - pair . zero - shot setting , obtain median improvement +2.77 bleu point strong 20 - language multilingual transformer baseline train ted talk .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Don't Use English Dev: On the Zero-Shot Cross-Lingual Evaluation of Contextual Embeddings,"Multilingual contextual embeddings have demonstrated state-of-the-art performance in zero-shot cross-lingual transfer learning, where multilingual BERT is fine-tuned on one source language and evaluated on a different target language. However, published results for mBERT zero-shot accuracy vary as much as 17 points on the MLDoc classification task across four papers. We show that the standard practice of using English dev accuracy for model selection in the zero-shot setting makes it difficult to obtain reproducible results on the MLDoc and XNLI tasks. English dev accuracy is often uncorrelated (or even anti-correlated) with target language accuracy, and zero-shot performance varies greatly at different points in the same fine-tuning run and between different fine-tuning runs. These reproducibility issues are also present for other tasks with different pre-trained embeddings (e.g., MLQA with XLM-R). We recommend providing oracle scores alongside zero-shot results: still fine-tune using English data, but choose a checkpoint with the target dev set. Reporting this upper bound makes results more consistent by avoiding arbitrarily bad checkpoints.","Don't Use English Dev: On the Zero-Shot Cross-Lingual Evaluation of Contextual Embeddings Multilingual contextual embeddings have demonstrated state-of-the-art performance in zero-shot cross-lingual transfer learning, where multilingual BERT is fine-tuned on one source language and evaluated on a different target language. However, published results for mBERT zero-shot accuracy vary as much as 17 points on the MLDoc classification task across four papers. We show that the standard practice of using English dev accuracy for model selection in the zero-shot setting makes it difficult to obtain reproducible results on the MLDoc and XNLI tasks. English dev accuracy is often uncorrelated (or even anti-correlated) with target language accuracy, and zero-shot performance varies greatly at different points in the same fine-tuning run and between different fine-tuning runs. These reproducibility issues are also present for other tasks with different pre-trained embeddings (e.g., MLQA with XLM-R). We recommend providing oracle scores alongside zero-shot results: still fine-tune using English data, but choose a checkpoint with the target dev set. Reporting this upper bound makes results more consistent by avoiding arbitrarily bad checkpoints.","use english dev : zero - shot cross - lingual evaluation contextual embedding multilingual contextual embedding demonstrate state - - - art performance zero - shot cross - lingual transfer learning , multilingual bert fine - tune source language evaluate different target language . , publish result mbert zero - shot accuracy vary 17 point mldoc classification task paper . standard practice english dev accuracy model selection zero - shot setting make difficult obtain reproducible result mldoc xnli task . english dev accuracy uncorrelated ( anti - correlated ) target language accuracy , zero - shot performance vary greatly different point fine - tune run different fine - tune run . reproducibility issue present task different pre - trained embedding ( e.g. , mlqa xlm - r ) . recommend provide oracle score alongside zero - shot result : fine - tune english datum , choose checkpoint target dev set . report upper bound make result consistent avoid arbitrarily bad checkpoint .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Direct Segmentation Models for Streaming Speech Translation,"The cascade approach to Speech Translation (ST) is based on a pipeline that concatenates an Automatic Speech Recognition (ASR) system followed by a Machine Translation (MT) system. These systems are usually connected by a segmenter that splits the ASR output into, hopefully, semantically self-contained chunks to be fed into the MT system. This is specially challenging in the case of streaming ST, where latency requirements must also be taken into account. This work proposes novel segmentation models for streaming ST that incorporate not only textual, but also acoustic information to decide when the ASR output is split into a chunk. An extensive and thorough experimental setup is carried out on the Europarl-ST dataset to prove the contribution of acoustic information to the performance of the segmentation model in terms of BLEU score in a streaming ST scenario. Finally, comparative results with previous work also show the superiority of the segmentation models proposed in this work.","Direct Segmentation Models for Streaming Speech Translation The cascade approach to Speech Translation (ST) is based on a pipeline that concatenates an Automatic Speech Recognition (ASR) system followed by a Machine Translation (MT) system. These systems are usually connected by a segmenter that splits the ASR output into, hopefully, semantically self-contained chunks to be fed into the MT system. This is specially challenging in the case of streaming ST, where latency requirements must also be taken into account. This work proposes novel segmentation models for streaming ST that incorporate not only textual, but also acoustic information to decide when the ASR output is split into a chunk. An extensive and thorough experimental setup is carried out on the Europarl-ST dataset to prove the contribution of acoustic information to the performance of the segmentation model in terms of BLEU score in a streaming ST scenario. Finally, comparative results with previous work also show the superiority of the segmentation models proposed in this work.","direct segmentation model stream speech translation cascade approach speech translation ( st ) base pipeline concatenate automatic speech recognition ( asr ) system follow machine translation ( mt ) system . system usually connect segmenter split asr output , hopefully , semantically self - contain chunk feed mt system . specially challenging case stream st , latency requirement take account . work propose novel segmentation model stream st incorporate textual , acoustic information decide asr output split chunk . extensive thorough experimental setup carry europarl - st dataset prove contribution acoustic information performance segmentation model term bleu score stream st scenario . finally , comparative result previous work superiority segmentation model propose work .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 8, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Machine Translation and Multilinguality,Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning,"Document-level neural machine translation has yielded attractive improvements. However, majority of existing methods roughly use all context sentences in a fixed scope. They neglect the fact that different source sentences need different sizes of context. To address this problem, we propose an effective approach to select dynamic context so that the document-level translation model can utilize the more useful selected context sentences to produce better translations. Specifically, we introduce a selection module that is independent of the translation module to score each candidate context sentence. Then, we propose two strategies to explicitly select a variable number of context sentences and feed them into the translation module. We train the two modules end-to-end via reinforcement learning. A novel reward is proposed to encourage the selection and utilization of dynamic context sentences. Experiments demonstrate that our approach can select adaptive context sentences for different source sentences, and significantly improves the performance of document-level translation methods.","Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning Document-level neural machine translation has yielded attractive improvements. However, majority of existing methods roughly use all context sentences in a fixed scope. They neglect the fact that different source sentences need different sizes of context. To address this problem, we propose an effective approach to select dynamic context so that the document-level translation model can utilize the more useful selected context sentences to produce better translations. Specifically, we introduce a selection module that is independent of the translation module to score each candidate context sentence. Then, we propose two strategies to explicitly select a variable number of context sentences and feed them into the translation module. We train the two modules end-to-end via reinforcement learning. A novel reward is proposed to encourage the selection and utilization of dynamic context sentences. Experiments demonstrate that our approach can select adaptive context sentences for different source sentences, and significantly improves the performance of document-level translation methods.","dynamic context selection document - level neural machine translation reinforcement learning document - level neural machine translation yield attractive improvement . , majority exist method roughly use context sentence fix scope . neglect fact different source sentence need different size context . address problem , propose effective approach select dynamic context document - level translation model utilize useful select context sentence produce well translation . specifically , introduce selection module independent translation module score candidate context sentence . , propose strategy explicitly select variable number context sentence feed translation module . train module end - - end reinforcement learning . novel reward propose encourage selection utilization dynamic context sentence . experiment demonstrate approach select adaptive context sentence different source sentence , significantly improve performance document - level translation method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation,"The attention mechanism is the crucial component of the transformer architecture. Recent research shows that most attention heads are not confident in their decisions and can be pruned after training. However, removing them before training a model results in lower quality. In this paper, we apply the lottery ticket hypothesis to prune heads in the early stages of training, instead of doing so on a fully converged model. Our experiments on machine translation show that it is possible to remove up to three-quarters of all attention heads from a transformer-big model with an average −0.1 change in BLEU for Turkish→English. The pruned model is 1.5 times as fast at inference, albeit at the cost of longer training. The method is complementary to other approaches, such as teacher-student, with our English→German student losing 0.2 BLEU at 75% encoder attention sparsity.","Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation The attention mechanism is the crucial component of the transformer architecture. Recent research shows that most attention heads are not confident in their decisions and can be pruned after training. However, removing them before training a model results in lower quality. In this paper, we apply the lottery ticket hypothesis to prune heads in the early stages of training, instead of doing so on a fully converged model. Our experiments on machine translation show that it is possible to remove up to three-quarters of all attention heads from a transformer-big model with an average −0.1 change in BLEU for Turkish→English. The pruned model is 1.5 times as fast at inference, albeit at the cost of longer training. The method is complementary to other approaches, such as teacher-student, with our English→German student losing 0.2 BLEU at 75% encoder attention sparsity.","lose head lottery : prune transformer attention neural machine translation attention mechanism crucial component transformer architecture . recent research show attention head confident decision prune training . , remove train model result low quality . paper , apply lottery ticket hypothesis prune head early stage training , instead fully converge model . experiment machine translation possible remove - quarter attention head transformer - big model average −0.1 change bleu turkish→english . prune model 1.5 time fast inference , albeit cost long training . method complementary approach , teacher - student , english→german student lose 0.2 bleu 75 % encoder attention sparsity .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,From Zero to Hero: On the Limitations of Zero-Shot Language Transfer with Multilingual Transformers,"Massively multilingual transformers (MMTs) pretrained via language modeling (e.g., mBERT, XLM-R) have become a default paradigm for zero-shot language transfer in NLP, offering unmatched transfer performance. Current evaluations, however, verify their efficacy in transfers (a) to languages with sufficiently large pretraining corpora, and (b) between close languages. In this work, we analyze the limitations of downstream language transfer with MMTs, showing that, much like cross-lingual word embeddings, they are substantially less effective in resource-lean scenarios and for distant languages. Our experiments, encompassing three lower-level tasks (POS tagging, dependency parsing, NER) and two high-level tasks (NLI, QA), empirically correlate transfer performance with linguistic proximity between source and target languages, but also with the size of target language corpora used in MMT pretraining. Most importantly, we demonstrate that the inexpensive few-shot transfer (i.e., additional fine-tuning on a few target-language instances) is surprisingly effective across the board, warranting more research efforts reaching beyond the limiting zero-shot conditions.","From Zero to Hero: On the Limitations of Zero-Shot Language Transfer with Multilingual Transformers Massively multilingual transformers (MMTs) pretrained via language modeling (e.g., mBERT, XLM-R) have become a default paradigm for zero-shot language transfer in NLP, offering unmatched transfer performance. Current evaluations, however, verify their efficacy in transfers (a) to languages with sufficiently large pretraining corpora, and (b) between close languages. In this work, we analyze the limitations of downstream language transfer with MMTs, showing that, much like cross-lingual word embeddings, they are substantially less effective in resource-lean scenarios and for distant languages. Our experiments, encompassing three lower-level tasks (POS tagging, dependency parsing, NER) and two high-level tasks (NLI, QA), empirically correlate transfer performance with linguistic proximity between source and target languages, but also with the size of target language corpora used in MMT pretraining. Most importantly, we demonstrate that the inexpensive few-shot transfer (i.e., additional fine-tuning on a few target-language instances) is surprisingly effective across the board, warranting more research efforts reaching beyond the limiting zero-shot conditions.","zero hero : limitation zero - shot language transfer multilingual transformer massively multilingual transformer ( mmts ) pretraine language modeling ( e.g. , mbert , xlm - r ) default paradigm zero - shot language transfer nlp , offer unmatched transfer performance . current evaluation , , verify efficacy transfer ( ) language sufficiently large pretraine corpus , ( b ) close language . work , analyze limitation downstream language transfer mmts , show , like cross - lingual word embedding , substantially effective resource - lean scenario distant language . experiment , encompass low - level task ( pos tagging , dependency parsing , ner ) high - level task ( nli , qa ) , empirically correlate transfer performance linguistic proximity source target language , size target language corpus mmt pretraining . importantly , demonstrate inexpensive - shot transfer ( i.e. , additional fine - tuning target - language instance ) surprisingly effective board , warrant research effort reach limit zero - shot condition .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 1, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Iterative Domain-Repaired Back-Translation,"In this paper, we focus on the domain-specific translation with low resources, where indomain parallel corpora are scarce or nonexistent. One common and effective strategy for this case is exploiting in-domain monolingual data with the back-translation method. However, the synthetic parallel data is very noisy because they are generated by imperfect out-of-domain systems, resulting in the poor performance of domain adaptation. To address this issue, we propose a novel iterative domain-repaired back-translation framework, which introduces the Domain-Repair (DR) model to refine translations in synthetic bilingual data. To this end, we construct corresponding data for the DR model training by round-trip translating the monolingual sentences, and then design the unified training framework to optimize paired DR and NMT models jointly. Experiments on adapting NMT models between specific domains and from the general domain to specific domains demonstrate the effectiveness of our proposed approach, achieving 15.79 and 4.47 BLEU improvements on average over unadapted models and back-translation. 1","Iterative Domain-Repaired Back-Translation In this paper, we focus on the domain-specific translation with low resources, where indomain parallel corpora are scarce or nonexistent. One common and effective strategy for this case is exploiting in-domain monolingual data with the back-translation method. However, the synthetic parallel data is very noisy because they are generated by imperfect out-of-domain systems, resulting in the poor performance of domain adaptation. To address this issue, we propose a novel iterative domain-repaired back-translation framework, which introduces the Domain-Repair (DR) model to refine translations in synthetic bilingual data. To this end, we construct corresponding data for the DR model training by round-trip translating the monolingual sentences, and then design the unified training framework to optimize paired DR and NMT models jointly. Experiments on adapting NMT models between specific domains and from the general domain to specific domains demonstrate the effectiveness of our proposed approach, achieving 15.79 and 4.47 BLEU improvements on average over unadapted models and back-translation. 1","iterative domain - repaired - translation paper , focus domain - specific translation low resource , indomain parallel corpus scarce nonexistent . common effective strategy case exploit - domain monolingual datum - translation method . , synthetic parallel datum noisy generate imperfect - - domain system , result poor performance domain adaptation . address issue , propose novel iterative domain - repair - translation framework , introduce domain - repair ( dr ) model refine translation synthetic bilingual datum . end , construct corresponding datum dr model training round - trip translate monolingual sentence , design unified training framework optimize pair dr nmt model jointly . experiment adapt nmt model specific domain general domain specific domain demonstrate effectiveness propose approach , achieve 15.79 4.47 bleu improvement average unadapted model - translation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 6, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Streaming Approach For Efficient Batched Beam Search,"We propose an efficient batching strategy for variable-length decoding on GPU architectures. During decoding, when candidates terminate or are pruned according to heuristics, our streaming approach periodically ""refills"" the batch before proceeding with a selected subset of candidates. We apply our method to variable-width beam search on a state-of-theart machine translation model. Our method decreases runtime by up to 71% compared to a fixed-width beam search baseline and 17% compared to a variable-width baseline, while matching baselines' BLEU. Finally, experiments show that our method can speed up decoding in other domains, such as semantic and syntactic parsing.","A Streaming Approach For Efficient Batched Beam Search We propose an efficient batching strategy for variable-length decoding on GPU architectures. During decoding, when candidates terminate or are pruned according to heuristics, our streaming approach periodically ""refills"" the batch before proceeding with a selected subset of candidates. We apply our method to variable-width beam search on a state-of-theart machine translation model. Our method decreases runtime by up to 71% compared to a fixed-width beam search baseline and 17% compared to a variable-width baseline, while matching baselines' BLEU. Finally, experiments show that our method can speed up decoding in other domains, such as semantic and syntactic parsing.","streaming approach efficient batch beam search propose efficient batching strategy variable - length decoding gpu architecture . decoding , candidate terminate prune accord heuristic , stream approach periodically "" refill "" batch proceed select subset candidate . apply method variable - width beam search state - - theart machine translation model . method decrease runtime 71 % compare fix - width beam search baseline 17 % compare variable - width baseline , match baseline ' bleu . finally , experiment method speed decoding domain , semantic syntactic parsing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,BLEU might be Guilty but References are not Innocent,"The quality of automatic metrics for machine translation has been increasingly called into question, especially for high-quality systems. This paper demonstrates that, while choice of metric is important, the nature of the references is also critical. We study different methods to collect references and compare their value in automated evaluation by reporting correlation with human evaluation for a variety of systems and metrics. Motivated by the finding that typical references exhibit poor diversity, concentrating around translationese language, we develop a paraphrasing task for linguists to perform on existing reference translations, which counteracts this bias. Our method yields higher correlation with human judgment not only for the submissions of WMT 2019 English→German, but also for Back-translation and APE augmented MT output, which have been shown to have low correlation with automatic metrics using standard references. We demonstrate that our methodology improves correlation with all modern evaluation metrics we look at, including embedding-based methods. To complete this picture, we reveal that multireference BLEU does not improve the correlation for high quality output, and present an alternative multi-reference formulation that is more effective.","BLEU might be Guilty but References are not Innocent The quality of automatic metrics for machine translation has been increasingly called into question, especially for high-quality systems. This paper demonstrates that, while choice of metric is important, the nature of the references is also critical. We study different methods to collect references and compare their value in automated evaluation by reporting correlation with human evaluation for a variety of systems and metrics. Motivated by the finding that typical references exhibit poor diversity, concentrating around translationese language, we develop a paraphrasing task for linguists to perform on existing reference translations, which counteracts this bias. Our method yields higher correlation with human judgment not only for the submissions of WMT 2019 English→German, but also for Back-translation and APE augmented MT output, which have been shown to have low correlation with automatic metrics using standard references. We demonstrate that our methodology improves correlation with all modern evaluation metrics we look at, including embedding-based methods. To complete this picture, we reveal that multireference BLEU does not improve the correlation for high quality output, and present an alternative multi-reference formulation that is more effective.","bleu guilty reference innocent quality automatic metric machine translation increasingly call question , especially high - quality system . paper demonstrate , choice metric important , nature reference critical . study different method collect reference compare value automate evaluation report correlation human evaluation variety system metric . motivate finding typical reference exhibit poor diversity , concentrate translationese language , develop paraphrasing task linguist perform exist reference translation , counteract bias . method yield high correlation human judgment submission wmt 2019 english→german , - translation ape augment mt output , show low correlation automatic metric standard reference . demonstrate methodology improve correlation modern evaluation metric look , include embedding - base method . complete picture , reveal multireference bleu improve correlation high quality output , present alternative multi - reference formulation effective .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 16, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Translation and Multilinguality,The Secret is in the Spectra: Predicting Cross-lingual Task Performance with Spectral Similarity Measures,"Performance in cross-lingual NLP tasks is impacted by the (dis)similarity of languages at hand: e.g., previous work has suggested there is a connection between the expected success of bilingual lexicon induction (BLI) and the assumption of (approximate) isomorphism between monolingual embedding spaces. In this work we present a large-scale study focused on the correlations between monolingual embedding space similarity and task performance, covering thousands of language pairs and four different tasks: BLI, parsing, POS tagging and MT. We hypothesize that statistics of the spectrum of each monolingual embedding space indicate how well they can be aligned. We then introduce several isomorphism measures between two embedding spaces, based on the relevant statistics of their individual spectra. We empirically show that 1) language similarity scores derived from such spectral isomorphism measures are strongly associated with performance observed in different crosslingual tasks, and 2) our spectral-based measures consistently outperform previous standard isomorphism measures, while being computationally more tractable and easier to interpret. Finally, our measures capture complementary information to typologically driven language distance measures, and the combination of measures from the two families yields even higher task performance correlations. 1 X is mean-centered, column means have been subtracted and are equal to zero.","The Secret is in the Spectra: Predicting Cross-lingual Task Performance with Spectral Similarity Measures Performance in cross-lingual NLP tasks is impacted by the (dis)similarity of languages at hand: e.g., previous work has suggested there is a connection between the expected success of bilingual lexicon induction (BLI) and the assumption of (approximate) isomorphism between monolingual embedding spaces. In this work we present a large-scale study focused on the correlations between monolingual embedding space similarity and task performance, covering thousands of language pairs and four different tasks: BLI, parsing, POS tagging and MT. We hypothesize that statistics of the spectrum of each monolingual embedding space indicate how well they can be aligned. We then introduce several isomorphism measures between two embedding spaces, based on the relevant statistics of their individual spectra. We empirically show that 1) language similarity scores derived from such spectral isomorphism measures are strongly associated with performance observed in different crosslingual tasks, and 2) our spectral-based measures consistently outperform previous standard isomorphism measures, while being computationally more tractable and easier to interpret. Finally, our measures capture complementary information to typologically driven language distance measures, and the combination of measures from the two families yields even higher task performance correlations. 1 X is mean-centered, column means have been subtracted and are equal to zero.","secret spectra : predict cross - lingual task performance spectral similarity measure performance cross - lingual nlp task impact ( dis)similarity language hand : e.g. , previous work suggest connection expect success bilingual lexicon induction ( bli ) assumption ( approximate ) isomorphism monolingual embed space . work present large - scale study focus correlation monolingual embedding space similarity task performance , cover thousand language pair different task : bli , parsing , pos tagging mt . hypothesize statistic spectrum monolingual embed space indicate align . introduce isomorphism measure embedding space , base relevant statistic individual spectra . empirically 1 ) language similarity score derive spectral isomorphism measure strongly associate performance observe different crosslingual task , 2 ) spectral - base measure consistently outperform previous standard isomorphism measure , computationally tractable easy interpret . finally , measure capture complementary information typologically drive language distance measure , combination measure family yield high task performance correlation . 1 x mean - center , column mean subtract equal zero .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Shallow-to-Deep Training for Neural Machine Translation,"Deep encoders have been proven to be effective in improving neural machine translation (NMT) systems, but training an extremely deep encoder is time consuming. Moreover, why deep models help NMT is an open question. In this paper, we investigate the behavior of a well-tuned deep Transformer system. We find that stacking layers is helpful in improving the representation ability of N-MT models and adjacent layers perform similarly. This inspires us to develop a shallowto-deep training method that learns deep models by stacking shallow models. In this way, we successfully train a Transformer system with a 54-layer encoder. Experimental results on WMT'16 English-German and WMT'14 English-French translation tasks show that it is 1.4 × faster than training from scratch, and achieves a BLEU score of 30.33 and 43.29 on two tasks. The code is publicly available at https://github.com/libeineu/ SDT-Training.","Shallow-to-Deep Training for Neural Machine Translation Deep encoders have been proven to be effective in improving neural machine translation (NMT) systems, but training an extremely deep encoder is time consuming. Moreover, why deep models help NMT is an open question. In this paper, we investigate the behavior of a well-tuned deep Transformer system. We find that stacking layers is helpful in improving the representation ability of N-MT models and adjacent layers perform similarly. This inspires us to develop a shallowto-deep training method that learns deep models by stacking shallow models. In this way, we successfully train a Transformer system with a 54-layer encoder. Experimental results on WMT'16 English-German and WMT'14 English-French translation tasks show that it is 1.4 × faster than training from scratch, and achieves a BLEU score of 30.33 and 43.29 on two tasks. The code is publicly available at https://github.com/libeineu/ SDT-Training.","shallow - - deep training neural machine translation deep encoder prove effective improve neural machine translation ( nmt ) system , train extremely deep encoder time consume . , deep model help nmt open question . paper , investigate behavior - tune deep transformer system . find stack layer helpful improve representation ability n - mt model adjacent layer perform similarly . inspire develop shallowto - deep training method learn deep model stack shallow model . way , successfully train transformer system 54 - layer encoder . experimental result wmt'16 english - german wmt'14 english - french translation task 1.4 × fast train scratch , achieve bleu score 30.33 43.29 task . code publicly available https://github.com/libeineu/ sdt - training .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 15, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Dynamic Data Selection and Weighting for Iterative Back-Translation,"Back-translation has proven to be an effective method to utilize monolingual data in neural machine translation (NMT), and iteratively conducting back-translation can further improve the model performance. Selecting which monolingual data to back-translate is crucial, as we require that the resulting synthetic data are of high quality and reflect the target domain. To achieve these two goals, data selection and weighting strategies have been proposed, with a common practice being to select samples close to the target domain but also dissimilar to the average general-domain text. In this paper, we provide insights into this commonly used approach and generalize it to a dynamic curriculum learning strategy, which is applied to iterative back-translation models. In addition, we propose weighting strategies based on both the current quality of the sentence and its improvement over the previous iteration. We evaluate our models on domain adaptation, low-resource, and high-resource MT settings and on two language pairs. Experimental results demonstrate that our methods achieve improvements of up to 1.8 BLEU points over competitive baselines. 1","Dynamic Data Selection and Weighting for Iterative Back-Translation Back-translation has proven to be an effective method to utilize monolingual data in neural machine translation (NMT), and iteratively conducting back-translation can further improve the model performance. Selecting which monolingual data to back-translate is crucial, as we require that the resulting synthetic data are of high quality and reflect the target domain. To achieve these two goals, data selection and weighting strategies have been proposed, with a common practice being to select samples close to the target domain but also dissimilar to the average general-domain text. In this paper, we provide insights into this commonly used approach and generalize it to a dynamic curriculum learning strategy, which is applied to iterative back-translation models. In addition, we propose weighting strategies based on both the current quality of the sentence and its improvement over the previous iteration. We evaluate our models on domain adaptation, low-resource, and high-resource MT settings and on two language pairs. Experimental results demonstrate that our methods achieve improvements of up to 1.8 BLEU points over competitive baselines. 1","dynamic data selection weighting iterative - translation - translation prove effective method utilize monolingual datum neural machine translation ( nmt ) , iteratively conduct - translation improve model performance . select monolingual datum - translate crucial , require result synthetic datum high quality reflect target domain . achieve goal , datum selection weighting strategy propose , common practice select sample close target domain dissimilar average general - domain text . paper , provide insight commonly approach generalize dynamic curriculum learning strategy , apply iterative - translation model . addition , propose weight strategy base current quality sentence improvement previous iteration . evaluate model domain adaptation , low - resource , high - resource mt setting language pair . experimental result demonstrate method achieve improvement 1.8 bleu point competitive baseline . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,An Empirical Study of Generation Order for Machine Translation,"In this work, we present an empirical study of generation order for machine translation. Building on recent advances in insertion-based modeling, we first introduce a soft orderreward framework that enables us to train models to follow arbitrary oracle generation policies. We then make use of this framework to explore a large variety of generation orders, including uninformed orders, locationbased orders, frequency-based orders, contentbased orders, and model-based orders. Curiously, we find that for the WMT'14 English → German and WMT'18 English → Chinese translation tasks, order does not have a substantial impact on output quality. Moreover, for English → German, we even discover that unintuitive orderings such as alphabetical and shortest-first can match the performance of a standard Transformer, suggesting that traditional left-to-right generation may not be necessary to achieve high performance.","An Empirical Study of Generation Order for Machine Translation In this work, we present an empirical study of generation order for machine translation. Building on recent advances in insertion-based modeling, we first introduce a soft orderreward framework that enables us to train models to follow arbitrary oracle generation policies. We then make use of this framework to explore a large variety of generation orders, including uninformed orders, locationbased orders, frequency-based orders, contentbased orders, and model-based orders. Curiously, we find that for the WMT'14 English → German and WMT'18 English → Chinese translation tasks, order does not have a substantial impact on output quality. Moreover, for English → German, we even discover that unintuitive orderings such as alphabetical and shortest-first can match the performance of a standard Transformer, suggesting that traditional left-to-right generation may not be necessary to achieve high performance.","empirical study generation order machine translation work , present empirical study generation order machine translation . build recent advance insertion - base modeling , introduce soft orderreward framework enable train model follow arbitrary oracle generation policy . use framework explore large variety generation order , include uninformed order , locationbased order , frequency - base order , contentbased order , model - base order . curiously , find wmt'14 english → german wmt'18 english → chinese translation task , order substantial impact output quality . , english → german , discover unintuitive ordering alphabetical short - match performance standard transformer , suggest traditional left - - right generation necessary achieve high performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,On the Sparsity of Neural Machine Translation Models,"Modern neural machine translation (NMT) models employ a large number of parameters, which leads to serious over-parameterization and typically causes the underutilization of computational resources. In response to this problem, we empirically investigate whether the redundant parameters can be reused to achieve better performance. Experiments and analyses are systematically conducted on different datasets and NMT architectures. We show that: 1) the pruned parameters can be rejuvenated to improve the baseline model by up to +0.8 BLEU points; 2) the rejuvenated parameters are reallocated to enhance the ability of modeling low-level lexical information.","On the Sparsity of Neural Machine Translation Models Modern neural machine translation (NMT) models employ a large number of parameters, which leads to serious over-parameterization and typically causes the underutilization of computational resources. In response to this problem, we empirically investigate whether the redundant parameters can be reused to achieve better performance. Experiments and analyses are systematically conducted on different datasets and NMT architectures. We show that: 1) the pruned parameters can be rejuvenated to improve the baseline model by up to +0.8 BLEU points; 2) the rejuvenated parameters are reallocated to enhance the ability of modeling low-level lexical information.","sparsity neural machine translation models modern neural machine translation ( nmt ) model employ large number parameter , lead - parameterization typically cause underutilization computational resource . response problem , empirically investigate redundant parameter reuse achieve well performance . experiment analysis systematically conduct different dataset nmt architecture . : 1 ) prune parameter rejuvenate improve baseline model +0.8 bleu point ; 2 ) rejuvenate parameter reallocate enhance ability model low - level lexical information .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Learning Adaptive Segmentation Policy for Simultaneous Translation,"Balancing accuracy and latency is a great challenge for simultaneous translation. To achieve high accuracy, the model usually needs to wait for more streaming text before translation, which results in increased latency. However, keeping low latency would probably hurt accuracy. Therefore, it is essential to segment the ASR output into appropriate units for translation. Inspired by human interpreters, we propose a novel adaptive segmentation policy for simultaneous translation. The policy learns to segment the source text by considering possible translations produced by the translation model, maintaining consistency between the segmentation and translation. Experimental results on Chinese-English and German-English translation show that our method achieves a better accuracy-latency trade-off over recently proposed state-of-the-art methods.","Learning Adaptive Segmentation Policy for Simultaneous Translation Balancing accuracy and latency is a great challenge for simultaneous translation. To achieve high accuracy, the model usually needs to wait for more streaming text before translation, which results in increased latency. However, keeping low latency would probably hurt accuracy. Therefore, it is essential to segment the ASR output into appropriate units for translation. Inspired by human interpreters, we propose a novel adaptive segmentation policy for simultaneous translation. The policy learns to segment the source text by considering possible translations produced by the translation model, maintaining consistency between the segmentation and translation. Experimental results on Chinese-English and German-English translation show that our method achieves a better accuracy-latency trade-off over recently proposed state-of-the-art methods.","learn adaptive segmentation policy simultaneous translation balance accuracy latency great challenge simultaneous translation . achieve high accuracy , model usually need wait stream text translation , result increase latency . , keep low latency probably hurt accuracy . , essential segment asr output appropriate unit translation . inspire human interpreter , propose novel adaptive segmentation policy simultaneous translation . policy learn segment source text consider possible translation produce translation model , maintain consistency segmentation translation . experimental result chinese - english german - english translation method achieve well accuracy - latency trade - recently propose state - - - art method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Accurate Word Alignment Induction from Neural Machine Translation,"Despite its original goal to jointly learn to align and translate, prior researches suggest that Transformer captures poor word alignments through its attention mechanism. In this paper, we show that attention weights DO capture accurate word alignments and propose two novel word alignment induction methods SHIFT-ATT and SHIFT-AET. The main idea is to induce alignments at the step when the to-be-aligned target token is the decoder input rather than the decoder output as in previous work. SHIFT-ATT is an interpretation method that induces alignments from the attention weights of Transformer and does not require parameter update or architecture change. SHIFT-AET extracts alignments from an additional alignment module which is tightly integrated into Transformer and trained in isolation with supervision from symmetrized SHIFT-ATT alignments. Experiments on three publicly available datasets demonstrate that both methods perform better than their corresponding neural baselines and SHIFT-AET significantly outperforms GIZA++ by 1.4-4.8 AER points. 1","Accurate Word Alignment Induction from Neural Machine Translation Despite its original goal to jointly learn to align and translate, prior researches suggest that Transformer captures poor word alignments through its attention mechanism. In this paper, we show that attention weights DO capture accurate word alignments and propose two novel word alignment induction methods SHIFT-ATT and SHIFT-AET. The main idea is to induce alignments at the step when the to-be-aligned target token is the decoder input rather than the decoder output as in previous work. SHIFT-ATT is an interpretation method that induces alignments from the attention weights of Transformer and does not require parameter update or architecture change. SHIFT-AET extracts alignments from an additional alignment module which is tightly integrated into Transformer and trained in isolation with supervision from symmetrized SHIFT-ATT alignments. Experiments on three publicly available datasets demonstrate that both methods perform better than their corresponding neural baselines and SHIFT-AET significantly outperforms GIZA++ by 1.4-4.8 AER points. 1","accurate word alignment induction neural machine translation despite original goal jointly learn align translate , prior research suggest transformer capture poor word alignment attention mechanism . paper , attention weight capture accurate word alignment propose novel word alignment induction method shift - att shift - aet . main idea induce alignment step - - align target token decoder input decoder output previous work . shift - att interpretation method induce alignment attention weight transformer require parameter update architecture change . shift - aet extract alignment additional alignment module tightly integrate transformer train isolation supervision symmetrize shift - att alignment . experiment publicly available dataset demonstrate method perform well correspond neural baseline shift - aet significantly outperform giza++ 1.4 - 4.8 aer point . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
Machine Translation and Multilinguality,Towards Enhancing Faithfulness for Neural Machine Translation,"Neural machine translation (NMT) has achieved great success due to the ability to generate high-quality sentences. Compared with human translations, one of the drawbacks of current NMT is that translations are not usually faithful to the input, e.g., omitting information or generating unrelated fragments, which inevitably decreases the overall quality, especially for human readers. In this paper, we propose a novel training strategy with a multi-task learning paradigm to build a faithfulness enhanced NMT model (named FENMT). During the NMT training process, we sample a subset from the training set and translate them to get fragments that have been mistranslated. Afterward, the proposed multi-task learning paradigm is employed on both encoder and decoder to guide NMT to correctly translate these fragments. Both automatic and human evaluations verify that our FENMT could improve translation quality by effectively reducing unfaithful translations.","Towards Enhancing Faithfulness for Neural Machine Translation Neural machine translation (NMT) has achieved great success due to the ability to generate high-quality sentences. Compared with human translations, one of the drawbacks of current NMT is that translations are not usually faithful to the input, e.g., omitting information or generating unrelated fragments, which inevitably decreases the overall quality, especially for human readers. In this paper, we propose a novel training strategy with a multi-task learning paradigm to build a faithfulness enhanced NMT model (named FENMT). During the NMT training process, we sample a subset from the training set and translate them to get fragments that have been mistranslated. Afterward, the proposed multi-task learning paradigm is employed on both encoder and decoder to guide NMT to correctly translate these fragments. Both automatic and human evaluations verify that our FENMT could improve translation quality by effectively reducing unfaithful translations.","enhance faithfulness neural machine translation neural machine translation ( nmt ) achieve great success ability generate high - quality sentence . compare human translation , drawback current nmt translation usually faithful input , e.g. , omit information generate unrelated fragment , inevitably decrease overall quality , especially human reader . paper , propose novel training strategy multi - task learning paradigm build faithfulness enhance nmt model ( name fenmt ) . nmt training process , sample subset training set translate fragment mistranslate . afterward , propose multi - task learning paradigm employ encoder decoder guide nmt correctly translate fragment . automatic human evaluation verify fenmt improve translation quality effectively reduce unfaithful translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 22, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Improving Multilingual Models with Language-Clustered Vocabularies,"State-of-the-art multilingual models depend on vocabularies that cover all of the languages the model will expect to see at inference time, but the standard methods for generating those vocabularies are not ideal for massively multilingual applications. In this work, we introduce a novel procedure for multilingual vocabulary generation that combines the separately trained vocabularies of several automatically derived language clusters, thus balancing the trade-off between cross-lingual subword sharing and language-specific vocabularies. Our experiments show improvements across languages on key multilingual benchmark tasks TYDI QA (+2.9 F1), XNLI (+2.1%), and WikiAnn NER (+2.8 F1) and factor of 8 reduction in out-of-vocabulary rate, all without increasing the size of the model or data.","Improving Multilingual Models with Language-Clustered Vocabularies State-of-the-art multilingual models depend on vocabularies that cover all of the languages the model will expect to see at inference time, but the standard methods for generating those vocabularies are not ideal for massively multilingual applications. In this work, we introduce a novel procedure for multilingual vocabulary generation that combines the separately trained vocabularies of several automatically derived language clusters, thus balancing the trade-off between cross-lingual subword sharing and language-specific vocabularies. Our experiments show improvements across languages on key multilingual benchmark tasks TYDI QA (+2.9 F1), XNLI (+2.1%), and WikiAnn NER (+2.8 F1) and factor of 8 reduction in out-of-vocabulary rate, all without increasing the size of the model or data.","improve multilingual model language - cluster vocabulary state - - - art multilingual model depend vocabulary cover language model expect inference time , standard method generate vocabulary ideal massively multilingual application . work , introduce novel procedure multilingual vocabulary generation combine separately train vocabulary automatically derive language cluster , balance trade - cross - lingual subword sharing language - specific vocabulary . experiment improvement language key multilingual benchmark task tydi qa ( +2.9 f1 ) , xnli ( +2.1 % ) , wikiann ner ( +2.8 f1 ) factor 8 reduction - - vocabulary rate , increase size model datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Translation and Multilinguality,Distilling Multiple Domains for Neural Machine Translation,"Neural machine translation achieves impressive results in high-resource conditions, but performance often suffers when the input domain is low-resource. The standard practice of adapting a separate model for each domain of interest does not scale well in practice from both a quality perspective (brittleness under domain shift) as well as a cost perspective (added maintenance and inference complexity). In this paper, we propose a framework for training a single multi-domain neural machine translation model that is able to translate several domains without increasing inference time or memory usage. We show that this model can improve translation on both highand low-resource domains over strong multidomain baselines. In addition, our proposed model is effective when domain labels are unknown during training, as well as robust under noisy data conditions.","Distilling Multiple Domains for Neural Machine Translation Neural machine translation achieves impressive results in high-resource conditions, but performance often suffers when the input domain is low-resource. The standard practice of adapting a separate model for each domain of interest does not scale well in practice from both a quality perspective (brittleness under domain shift) as well as a cost perspective (added maintenance and inference complexity). In this paper, we propose a framework for training a single multi-domain neural machine translation model that is able to translate several domains without increasing inference time or memory usage. We show that this model can improve translation on both highand low-resource domains over strong multidomain baselines. In addition, our proposed model is effective when domain labels are unknown during training, as well as robust under noisy data conditions.","distil multiple domain neural machine translation neural machine translation achieve impressive result high - resource condition , performance suffer input domain low - resource . standard practice adapt separate model domain interest scale practice quality perspective ( brittleness domain shift ) cost perspective ( add maintenance inference complexity ) . paper , propose framework train single multi - domain neural machine translation model able translate domain increase inference time memory usage . model improve translation highand low - resource domain strong multidomain baseline . addition , propose model effective domain label unknown training , robust noisy data condition .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Towards Reasonably-Sized Character-Level Transformer NMT by Finetuning Subword Systems,"Applying the Transformer architecture on the character level usually requires very deep architectures that are difficult and slow to train. These problems can be partially overcome by incorporating a segmentation into tokens in the model. We show that by initially training a subword model and then finetuning it on characters, we can obtain a neural machine translation model that works at the character level without requiring token segmentation. We use only the vanilla 6-layer Transformer Base architecture. Our character-level models better capture morphological phenomena and show more robustness to noise at the expense of somewhat worse overall translation quality. Our study is a significant step towards highperformance and easy to train character-based models that are not extremely large.","Towards Reasonably-Sized Character-Level Transformer NMT by Finetuning Subword Systems Applying the Transformer architecture on the character level usually requires very deep architectures that are difficult and slow to train. These problems can be partially overcome by incorporating a segmentation into tokens in the model. We show that by initially training a subword model and then finetuning it on characters, we can obtain a neural machine translation model that works at the character level without requiring token segmentation. We use only the vanilla 6-layer Transformer Base architecture. Our character-level models better capture morphological phenomena and show more robustness to noise at the expense of somewhat worse overall translation quality. Our study is a significant step towards highperformance and easy to train character-based models that are not extremely large.","reasonably - size character - level transformer nmt finetune subword system apply transformer architecture character level usually require deep architecture difficult slow train . problem partially overcome incorporate segmentation token model . initially train subword model finetune character , obtain neural machine translation model work character level require token segmentation . use vanilla 6 - layer transformer base architecture . character - level model well capture morphological phenomenon robustness noise expense somewhat bad overall translation quality . study significant step highperformance easy train character - base model extremely large .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 11, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,Translation Artifacts in Cross-lingual Transfer Learning,"Both human and machine translation play a central role in cross-lingual transfer learning: many multilingual datasets have been created through professional translation services, and using machine translation to translate either the test set or the training set is a widely used transfer technique. In this paper, we show that such translation process can introduce subtle artifacts that have a notable impact in existing cross-lingual models. For instance, in natural language inference, translating the premise and the hypothesis independently can reduce the lexical overlap between them, which current models are highly sensitive to. We show that some previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively.","Translation Artifacts in Cross-lingual Transfer Learning Both human and machine translation play a central role in cross-lingual transfer learning: many multilingual datasets have been created through professional translation services, and using machine translation to translate either the test set or the training set is a widely used transfer technique. In this paper, we show that such translation process can introduce subtle artifacts that have a notable impact in existing cross-lingual models. For instance, in natural language inference, translating the premise and the hypothesis independently can reduce the lexical overlap between them, which current models are highly sensitive to. We show that some previous findings in cross-lingual transfer learning need to be reconsidered in the light of this phenomenon. Based on the gained insights, we also improve the state-of-the-art in XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points, respectively.","translation artifact cross - lingual transfer learning human machine translation play central role cross - lingual transfer learning : multilingual dataset create professional translation service , machine translation translate test set training set widely transfer technique . paper , translation process introduce subtle artifact notable impact exist cross - lingual model . instance , natural language inference , translate premise hypothesis independently reduce lexical overlap , current model highly sensitive . previous finding cross - lingual transfer learning need reconsider light phenomenon . base gain insight , improve state - - - art xnli translate - test zero - shot approach 4.3 2.8 point , respectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Incorporating a Local Translation Mechanism into Non-autoregressive Translation,"In this work, we introduce a novel local autoregressive translation (LAT) mechanism into non-autoregressive translation (NAT) models so as to capture local dependencies among target outputs. Specifically, for each target decoding position, instead of only one token, we predict a short sequence of tokens in an autoregressive way. We further design an efficient merging algorithm to align and merge the output pieces into one final output sequence. We integrate LAT into the conditional masked language model (CMLM; Ghazvininejad et al., 2019) and similarly adopt iterative decoding. Empirical results on five translation tasks show that compared with CMLM, our method achieves comparable or better performance with fewer decoding iterations, bringing a 2.5x speedup. Further analysis indicates that our method reduces repeated translations and performs better at longer sentences.","Incorporating a Local Translation Mechanism into Non-autoregressive Translation In this work, we introduce a novel local autoregressive translation (LAT) mechanism into non-autoregressive translation (NAT) models so as to capture local dependencies among target outputs. Specifically, for each target decoding position, instead of only one token, we predict a short sequence of tokens in an autoregressive way. We further design an efficient merging algorithm to align and merge the output pieces into one final output sequence. We integrate LAT into the conditional masked language model (CMLM; Ghazvininejad et al., 2019) and similarly adopt iterative decoding. Empirical results on five translation tasks show that compared with CMLM, our method achieves comparable or better performance with fewer decoding iterations, bringing a 2.5x speedup. Further analysis indicates that our method reduces repeated translations and performs better at longer sentences.","incorporate local translation mechanism non - autoregressive translation work , introduce novel local autoregressive translation ( lat ) mechanism non - autoregressive translation ( nat ) model capture local dependency target output . specifically , target decode position , instead token , predict short sequence token autoregressive way . design efficient merge algorithm align merge output piece final output sequence . integrate lat conditional masked language model ( cmlm ; ghazvininejad et al . , 2019 ) similarly adopt iterative decoding . empirical result translation task compare cmlm , method achieve comparable well performance few decoding iteration , bring 2.5x speedup . analysis indicate method reduce repeat translation perform well long sentence .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Statistical Power and Translationese in Machine Translation Evaluation,"The term translationese has been used to describe features of translated text, and in this paper, we provide detailed analysis of potential adverse effects of translationese on machine translation evaluation. Our analysis shows differences in conclusions drawn from evaluations that include translationese in test data compared to experiments that tested only with text originally composed in that language. For this reason we recommend that reverse-created test data be omitted from future machine translation test sets. In addition, we provide a reevaluation of a past machine translation evaluation claiming human-parity of MT. One important issue not previously considered is statistical power of significance tests applied to comparison of human and machine translation. Since the very aim of past evaluations was the investigation of ties between human and MT systems, power analysis is of particular importance, to avoid, for example, claims of human parity simply corresponding to Type II error resulting from the application of a low powered test. We provide detailed analysis of tests used in such evaluations to provide an indication of a suitable minimum sample size for future studies.","Statistical Power and Translationese in Machine Translation Evaluation The term translationese has been used to describe features of translated text, and in this paper, we provide detailed analysis of potential adverse effects of translationese on machine translation evaluation. Our analysis shows differences in conclusions drawn from evaluations that include translationese in test data compared to experiments that tested only with text originally composed in that language. For this reason we recommend that reverse-created test data be omitted from future machine translation test sets. In addition, we provide a reevaluation of a past machine translation evaluation claiming human-parity of MT. One important issue not previously considered is statistical power of significance tests applied to comparison of human and machine translation. Since the very aim of past evaluations was the investigation of ties between human and MT systems, power analysis is of particular importance, to avoid, for example, claims of human parity simply corresponding to Type II error resulting from the application of a low powered test. We provide detailed analysis of tests used in such evaluations to provide an indication of a suitable minimum sample size for future studies.","statistical power translationese machine translation evaluation term translationese describe feature translate text , paper , provide detailed analysis potential adverse effect translationese machine translation evaluation . analysis show difference conclusion draw evaluation include translationese test datum compare experiment test text originally compose language . reason recommend reverse - create test datum omit future machine translation test set . addition , provide reevaluation past machine translation evaluation claim human - parity mt . important issue previously consider statistical power significance test apply comparison human machine translation . aim past evaluation investigation tie human mt system , power analysis particular importance , avoid , example , claim human parity simply correspond type ii error result application low powered test . provide detailed analysis test evaluation provide indication suitable minimum sample size future study .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 19, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Inference Strategies for Machine Translation with Conditional Masking,"Conditional masked language model (CMLM) training has proven successful for nonautoregressive and semi-autoregressive sequence generation tasks, such as machine translation. Given a trained CMLM, however, it is not clear what the best inference strategy is. We formulate masked inference as a factorization of conditional probabilities of partial sequences, show that this does not harm performance, and investigate a number of simple heuristics motivated by this perspective. We identify a thresholding strategy that has advantages over the standard ""mask-predict"" algorithm, and provide analyses of its behavior on machine translation tasks.","Inference Strategies for Machine Translation with Conditional Masking Conditional masked language model (CMLM) training has proven successful for nonautoregressive and semi-autoregressive sequence generation tasks, such as machine translation. Given a trained CMLM, however, it is not clear what the best inference strategy is. We formulate masked inference as a factorization of conditional probabilities of partial sequences, show that this does not harm performance, and investigate a number of simple heuristics motivated by this perspective. We identify a thresholding strategy that has advantages over the standard ""mask-predict"" algorithm, and provide analyses of its behavior on machine translation tasks.","inference strategy machine translation conditional masking conditional masked language model ( cmlm ) training prove successful nonautoregressive semi - autoregressive sequence generation task , machine translation . give train cmlm , , clear good inference strategy . formulate mask inference factorization conditional probability partial sequence , harm performance , investigate number simple heuristic motivate perspective . identify thresholding strategy advantage standard "" mask - predict "" algorithm , provide analysis behavior machine translation task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Token-level Adaptive Training for Neural Machine Translation,"There exists a token imbalance phenomenon in natural language as different tokens appear with different frequencies, which leads to different learning difficulties for tokens in Neural Machine Translation (NMT). The vanilla NMT model usually adopts trivial equal-weighted objectives for target tokens with different frequencies and tends to generate more high-frequency tokens and less lowfrequency tokens compared with the golden token distribution. However, low-frequency tokens may carry critical semantic information that will affect the translation quality once they are neglected. In this paper, we explored target token-level adaptive objectives based on token frequencies to assign appropriate weights for each target token during training. We aimed that those meaningful but relatively low-frequency words could be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. Our method yields consistent improvements in translation quality on ZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases compared with baseline, respectively. Further analyses show that our method can also improve the lexical diversity of translation.","Token-level Adaptive Training for Neural Machine Translation There exists a token imbalance phenomenon in natural language as different tokens appear with different frequencies, which leads to different learning difficulties for tokens in Neural Machine Translation (NMT). The vanilla NMT model usually adopts trivial equal-weighted objectives for target tokens with different frequencies and tends to generate more high-frequency tokens and less lowfrequency tokens compared with the golden token distribution. However, low-frequency tokens may carry critical semantic information that will affect the translation quality once they are neglected. In this paper, we explored target token-level adaptive objectives based on token frequencies to assign appropriate weights for each target token during training. We aimed that those meaningful but relatively low-frequency words could be assigned with larger weights in objectives to encourage the model to pay more attention to these tokens. Our method yields consistent improvements in translation quality on ZH-EN, EN-RO, and EN-DE translation tasks, especially on sentences that contain more low-frequency tokens where we can get 1.68, 1.02, and 0.52 BLEU increases compared with baseline, respectively. Further analyses show that our method can also improve the lexical diversity of translation.","token - level adaptive training neural machine translation exist token imbalance phenomenon natural language different token appear different frequency , lead different learning difficulty token neural machine translation ( nmt ) . vanilla nmt model usually adopt trivial equal - weighted objective target token different frequency tend generate high - frequency token lowfrequency token compare golden token distribution . , low - frequency token carry critical semantic information affect translation quality neglect . paper , explore target token - level adaptive objective base token frequency assign appropriate weight target token training . aim meaningful relatively low - frequency word assign large weight objective encourage model pay attention token . method yield consistent improvement translation quality zh - en , en - ro , en - de translation task , especially sentence contain low - frequency token 1.68 , 1.02 , 0.52 bleu increase compare baseline , respectively . analysis method improve lexical diversity translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 18, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT,"We present a novel supervised word alignment method based on cross-language span prediction. We first formalize a word alignment problem as a collection of independent predictions from a token in the source sentence to a span in the target sentence. Since this step is equivalent to a SQuAD v2.0 style question answering task, we solve it using the multilingual BERT, which is fine-tuned on manually created gold word alignment data. It is nontrivial to obtain accurate alignment from a set of independently predicted spans. We greatly improved the word alignment accuracy by adding to the question the source token's context and symmetrizing two directional predictions. In experiments using five word alignment datasets from among Chinese, Japanese, German, Romanian, French, and English, we show that our proposed method significantly outperformed previous supervised and unsupervised word alignment methods without any bitexts for pretraining. For example, we achieved 86.7 F1 score for the Chinese-English data, which is 13.3 points higher than the previous state-of-the-art supervised method. 1","A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT We present a novel supervised word alignment method based on cross-language span prediction. We first formalize a word alignment problem as a collection of independent predictions from a token in the source sentence to a span in the target sentence. Since this step is equivalent to a SQuAD v2.0 style question answering task, we solve it using the multilingual BERT, which is fine-tuned on manually created gold word alignment data. It is nontrivial to obtain accurate alignment from a set of independently predicted spans. We greatly improved the word alignment accuracy by adding to the question the source token's context and symmetrizing two directional predictions. In experiments using five word alignment datasets from among Chinese, Japanese, German, Romanian, French, and English, we show that our proposed method significantly outperformed previous supervised and unsupervised word alignment methods without any bitexts for pretraining. For example, we achieved 86.7 F1 score for the Chinese-English data, which is 13.3 points higher than the previous state-of-the-art supervised method. 1","supervised word alignment method base cross - language span prediction multilingual bert present novel supervise word alignment method base cross - language span prediction . formalize word alignment problem collection independent prediction token source sentence span target sentence . step equivalent squad v2.0 style question answering task , solve multilingual bert , fine - tune manually create gold word alignment datum . nontrivial obtain accurate alignment set independently predict span . greatly improve word alignment accuracy add question source token context symmetrize directional prediction . experiment word alignment dataset chinese , japanese , german , romanian , french , english , propose method significantly outperform previous supervised unsupervised word alignment method bitext pretraine . example , achieve 86.7 f1 score chinese - english datum , 13.3 point high previous state - - - art supervise method . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 6, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Exploiting Sentence Order in Document Alignment,"We present a simple document alignment method that incorporates sentence order information in both candidate generation and candidate re-scoring. Our method results in 61% relative reduction in error compared to the best previously published result on the WMT16 document alignment shared task. Our method improves downstream MT performance on web-scraped Sinhala-English documents from ParaCrawl, outperforming the document alignment method used in the most recent ParaCrawl release. It also outperforms a comparable corpora method which uses the same multilingual embeddings, demonstrating that exploiting sentence order is beneficial even if the end goal is sentence-level bitext.","Exploiting Sentence Order in Document Alignment We present a simple document alignment method that incorporates sentence order information in both candidate generation and candidate re-scoring. Our method results in 61% relative reduction in error compared to the best previously published result on the WMT16 document alignment shared task. Our method improves downstream MT performance on web-scraped Sinhala-English documents from ParaCrawl, outperforming the document alignment method used in the most recent ParaCrawl release. It also outperforms a comparable corpora method which uses the same multilingual embeddings, demonstrating that exploiting sentence order is beneficial even if the end goal is sentence-level bitext.","exploit sentence order document alignment present simple document alignment method incorporate sentence order information candidate generation candidate - scoring . method result 61 % relative reduction error compare good previously publish result wmt16 document alignment share task . method improve downstream mt performance web - scrape sinhala - english document paracrawl , outperform document alignment method recent paracrawl release . outperform comparable corpora method use multilingual embedding , demonstrate exploit sentence order beneficial end goal sentence - level bitext .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Translation and Multilinguality,Generating Diverse Translation from Model Distribution with Dropout,"Despite the improvement of translation quality, neural machine translation (NMT) often suffers from the lack of diversity in its generation. In this paper, we propose to generate diverse translations by deriving a large number of possible models with Bayesian modelling and sampling models from them for inference. The possible models are obtained by applying concrete dropout to the NMT model and each of them has specific confidence for its prediction, which corresponds to a posterior model distribution under specific training data in the principle of Bayesian modeling. With variational inference, the posterior model distribution can be approximated with a variational distribution, from which the final models for inference are sampled. We conducted experiments on Chinese-English and English-German translation tasks and the results shows that our method makes a better trade-off between diversity and accuracy.","Generating Diverse Translation from Model Distribution with Dropout Despite the improvement of translation quality, neural machine translation (NMT) often suffers from the lack of diversity in its generation. In this paper, we propose to generate diverse translations by deriving a large number of possible models with Bayesian modelling and sampling models from them for inference. The possible models are obtained by applying concrete dropout to the NMT model and each of them has specific confidence for its prediction, which corresponds to a posterior model distribution under specific training data in the principle of Bayesian modeling. With variational inference, the posterior model distribution can be approximated with a variational distribution, from which the final models for inference are sampled. We conducted experiments on Chinese-English and English-German translation tasks and the results shows that our method makes a better trade-off between diversity and accuracy.","generate diverse translation model distribution dropout despite improvement translation quality , neural machine translation ( nmt ) suffer lack diversity generation . paper , propose generate diverse translation derive large number possible model bayesian modelling sampling model inference . possible model obtain apply concrete dropout nmt model specific confidence prediction , correspond posterior model distribution specific training datum principle bayesian modeling . variational inference , posterior model distribution approximate variational distribution , final model inference sample . conduct experiment chinese - english english - german translation task result show method make well trade - diversity accuracy .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Bridging Linguistic Typology and Multilingual Machine Translation with Multi-View Language Representations,"Sparse language vectors from linguistic typology databases and learned embeddings from tasks like multilingual machine translation have been investigated in isolation, without analysing how they could benefit from each other's language characterisation. We propose to fuse both views using singular vector canonical correlation analysis and study what kind of information is induced from each source. By inferring typological features and language phylogenies, we observe that our representations embed typology and strengthen correlations with language relationships. We then take advantage of our multi-view language vector space for multilingual machine translation, where we achieve competitive overall translation accuracy in tasks that require information about language similarities, such as language clustering and ranking candidates for multilingual transfer. With our method, which is also released as a tool, we can easily project and assess new languages without expensive retraining of massive multilingual or ranking models, which are major disadvantages of related approaches.","Bridging Linguistic Typology and Multilingual Machine Translation with Multi-View Language Representations Sparse language vectors from linguistic typology databases and learned embeddings from tasks like multilingual machine translation have been investigated in isolation, without analysing how they could benefit from each other's language characterisation. We propose to fuse both views using singular vector canonical correlation analysis and study what kind of information is induced from each source. By inferring typological features and language phylogenies, we observe that our representations embed typology and strengthen correlations with language relationships. We then take advantage of our multi-view language vector space for multilingual machine translation, where we achieve competitive overall translation accuracy in tasks that require information about language similarities, such as language clustering and ranking candidates for multilingual transfer. With our method, which is also released as a tool, we can easily project and assess new languages without expensive retraining of massive multilingual or ranking models, which are major disadvantages of related approaches.","bridge linguistic typology multilingual machine translation multi - view language representation sparse language vector linguistic typology database learn embedding task like multilingual machine translation investigate isolation , analyse benefit language characterisation . propose fuse view singular vector canonical correlation analysis study kind information induce source . infer typological feature language phylogeny , observe representation embed typology strengthen correlation language relationship . advantage multi - view language vector space multilingual machine translation , achieve competitive overall translation accuracy task require information language similarity , language clustering rank candidate multilingual transfer . method , release tool , easily project assess new language expensive retraining massive multilingual ranking model , major disadvantage related approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Language Model Prior for Low-Resource Neural Machine Translation,"The scarcity of large parallel corpora is an important obstacle for neural machine translation. A common solution is to exploit the knowledge of language models (LM) trained on abundant monolingual data. In this work, we propose a novel approach to incorporate a LM as prior in a neural translation model (TM). Specifically, we add a regularization term, which pushes the output distributions of the TM to be probable under the LM prior, while avoiding wrong predictions when the TM ""disagrees"" with the LM. This objective relates to knowledge distillation, where the LM can be viewed as teaching the TM about the target language. The proposed approach does not compromise decoding speed, because the LM is used only at training time, unlike previous work that requires it during inference. We present an analysis on the effects that different methods have on the distributions of the TM. Results on two low-resource machine translation datasets show clear improvements even with limited monolingual data.","Language Model Prior for Low-Resource Neural Machine Translation The scarcity of large parallel corpora is an important obstacle for neural machine translation. A common solution is to exploit the knowledge of language models (LM) trained on abundant monolingual data. In this work, we propose a novel approach to incorporate a LM as prior in a neural translation model (TM). Specifically, we add a regularization term, which pushes the output distributions of the TM to be probable under the LM prior, while avoiding wrong predictions when the TM ""disagrees"" with the LM. This objective relates to knowledge distillation, where the LM can be viewed as teaching the TM about the target language. The proposed approach does not compromise decoding speed, because the LM is used only at training time, unlike previous work that requires it during inference. We present an analysis on the effects that different methods have on the distributions of the TM. Results on two low-resource machine translation datasets show clear improvements even with limited monolingual data.","language model prior low - resource neural machine translation scarcity large parallel corpus important obstacle neural machine translation . common solution exploit knowledge language model ( lm ) train abundant monolingual datum . work , propose novel approach incorporate lm prior neural translation model ( tm ) . specifically , add regularization term , push output distribution tm probable lm prior , avoid wrong prediction tm "" disagree "" lm . objective relate knowledge distillation , lm view teach tm target language . propose approach compromise decoding speed , lm training time , unlike previous work require inference . present analysis effect different method distribution tm . result low - resource machine translation dataset clear improvement limited monolingual datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs,"Cross-lingual document alignment aims to identify pairs of documents in two distinct languages that are of comparable content or translations of each other. In this paper, we exploit the signals embedded in URLs to label web documents at scale with an average precision of 94.5% across different language pairs. We mine sixty-eight snapshots of the Common Crawl corpus and identify web document pairs that are translations of each other. We release a new web dataset consisting of over 392 million URL pairs from Common Crawl covering documents in 8144 language pairs of which 137 pairs include English. In addition to curating this massive dataset, we introduce baseline methods that leverage crosslingual representations to identify aligned documents based on their textual content. Finally, we demonstrate the value of this parallel documents dataset through a downstream task of mining parallel sentences and measuring the quality of machine translations from models trained on this mined data. Our objective in releasing this dataset is to foster new research in cross-lingual NLP across a variety of low, medium, and high-resource languages.","CCAligned: A Massive Collection of Cross-Lingual Web-Document Pairs Cross-lingual document alignment aims to identify pairs of documents in two distinct languages that are of comparable content or translations of each other. In this paper, we exploit the signals embedded in URLs to label web documents at scale with an average precision of 94.5% across different language pairs. We mine sixty-eight snapshots of the Common Crawl corpus and identify web document pairs that are translations of each other. We release a new web dataset consisting of over 392 million URL pairs from Common Crawl covering documents in 8144 language pairs of which 137 pairs include English. In addition to curating this massive dataset, we introduce baseline methods that leverage crosslingual representations to identify aligned documents based on their textual content. Finally, we demonstrate the value of this parallel documents dataset through a downstream task of mining parallel sentences and measuring the quality of machine translations from models trained on this mined data. Our objective in releasing this dataset is to foster new research in cross-lingual NLP across a variety of low, medium, and high-resource languages.","ccaligned : massive collection cross - lingual web - document pair cross - lingual document alignment aim identify pair document distinct language comparable content translation . paper , exploit signal embed url label web document scale average precision 94.5 % different language pair . - snapshot common crawl corpus identify web document pair translation . release new web dataset consist 392 million url pair common crawl cover document 8144 language pair 137 pair include english . addition curate massive dataset , introduce baseline method leverage crosslingual representation identify align document base textual content . finally , demonstrate value parallel document dataset downstream task mine parallel sentence measure quality machine translation model train mine datum . objective release dataset foster new research cross - lingual nlp variety low , medium , high - resource language .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Translation and Multilinguality,Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT,"Using a language model (LM) pretrained on two languages with large monolingual data in order to initialize an unsupervised neural machine translation (UNMT) system yields stateof-the-art results. When limited data is available for one language, however, this method leads to poor translations. We present an effective approach that reuses an LM that is pretrained only on a high-resource language. The monolingual LM is fine-tuned on both languages and is then used to initialize a UNMT model. To reuse the pretrained LM, we have to modify its predefined vocabulary, to account for the new language. We therefore propose a novel vocabulary extension method. Our approach, RE-LM, outperforms a competitive cross-lingual pretraining model (XLM) in English-Macedonian (En-Mk) and English-Albanian (En-Sq), yielding more than +8.3 BLEU points for all four translation directions.","Reusing a Pretrained Language Model on Languages with Limited Corpora for Unsupervised NMT Using a language model (LM) pretrained on two languages with large monolingual data in order to initialize an unsupervised neural machine translation (UNMT) system yields stateof-the-art results. When limited data is available for one language, however, this method leads to poor translations. We present an effective approach that reuses an LM that is pretrained only on a high-resource language. The monolingual LM is fine-tuned on both languages and is then used to initialize a UNMT model. To reuse the pretrained LM, we have to modify its predefined vocabulary, to account for the new language. We therefore propose a novel vocabulary extension method. Our approach, RE-LM, outperforms a competitive cross-lingual pretraining model (XLM) in English-Macedonian (En-Mk) and English-Albanian (En-Sq), yielding more than +8.3 BLEU points for all four translation directions.","reuse pretrained language model language limited corpora unsupervised nmt language model ( lm ) pretraine language large monolingual datum order initialize unsupervised neural machine translation ( unmt ) system yield stateof - - art result . limited data available language , , method lead poor translation . present effective approach reuse lm pretraine high - resource language . monolingual lm fine - tune language initialize unmt model . reuse pretraine lm , modify predefine vocabulary , account new language . propose novel vocabulary extension method . approach , - lm , outperform competitive cross - lingual pretraining model ( xlm ) english - macedonian ( en - mk ) english - albanian ( en - sq ) , yield +8.3 bleu point translation direction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Interactive Refinement of Cross-Lingual Word Embeddings,"Cross-lingual word embeddings transfer knowledge between languages: models trained on high-resource languages can predict in low-resource languages. We introduce CLIME, an interactive system to quickly refine cross-lingual word embeddings for a given classification problem. First, CLIME ranks words by their salience to the downstream task. Then, users mark similarity between keywords and their nearest neighbors in the embedding space. Finally, CLIME updates the embeddings using the annotations. We evaluate CLIME on identifying health-related text in four low-resource languages: Ilocano, Sinhalese, Tigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word semantics and have higher test accuracy than the original embeddings. CLIME often improves accuracy faster than an active learning baseline and can be easily combined with active learning to improve results.","Interactive Refinement of Cross-Lingual Word Embeddings Cross-lingual word embeddings transfer knowledge between languages: models trained on high-resource languages can predict in low-resource languages. We introduce CLIME, an interactive system to quickly refine cross-lingual word embeddings for a given classification problem. First, CLIME ranks words by their salience to the downstream task. Then, users mark similarity between keywords and their nearest neighbors in the embedding space. Finally, CLIME updates the embeddings using the annotations. We evaluate CLIME on identifying health-related text in four low-resource languages: Ilocano, Sinhalese, Tigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word semantics and have higher test accuracy than the original embeddings. CLIME often improves accuracy faster than an active learning baseline and can be easily combined with active learning to improve results.","interactive refinement cross - lingual word embedding cross - lingual word embedding transfer knowledge language : model train high - resource language predict low - resource language . introduce clime , interactive system quickly refine cross - lingual word embedding give classification problem . , clime rank word salience downstream task . , user mark similarity keyword near neighbor embedding space . finally , clime update embedding annotation . evaluate clime identify health - relate text low - resource language : ilocano , sinhalese , tigrinya , uyghur . embedding refine clime capture nuanced word semantic high test accuracy original embedding . clime improve accuracy fast active learning baseline easily combine active learning improve result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 9, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Translation Quality Estimation by Jointly Learning to Score and Rank,"The translation quality estimation (QE) task, particularly the QE as a Metric task, aims to evaluate the general quality of a translation based on the translation and the source sentence without using reference translations. Supervised learning of this QE task requires human evaluation of translation quality as training data. Human evaluation of translation quality can be performed in different ways, including assigning an absolute score to a translation or ranking different translations. In order to make use of different types of human evaluation data for supervised learning, we present a multi-task learning QE model that jointly learns two tasks: score a translation and rank two translations. Our QE model exploits crosslingual sentence embeddings from pretrained multilingual language models. We obtain new state-of-the-art results on the WMT 2019 QE as a Metric task and outperform sentBLEU on the WMT 2019 Metrics task.","Translation Quality Estimation by Jointly Learning to Score and Rank The translation quality estimation (QE) task, particularly the QE as a Metric task, aims to evaluate the general quality of a translation based on the translation and the source sentence without using reference translations. Supervised learning of this QE task requires human evaluation of translation quality as training data. Human evaluation of translation quality can be performed in different ways, including assigning an absolute score to a translation or ranking different translations. In order to make use of different types of human evaluation data for supervised learning, we present a multi-task learning QE model that jointly learns two tasks: score a translation and rank two translations. Our QE model exploits crosslingual sentence embeddings from pretrained multilingual language models. We obtain new state-of-the-art results on the WMT 2019 QE as a Metric task and outperform sentBLEU on the WMT 2019 Metrics task.","translation quality estimation jointly learn score rank translation quality estimation ( qe ) task , particularly qe metric task , aim evaluate general quality translation base translation source sentence reference translation . supervised learning qe task require human evaluation translation quality training datum . human evaluation translation quality perform different way , include assign absolute score translation rank different translation . order use different type human evaluation datum supervise learning , present multi - task learn qe model jointly learn task : score translation rank translation . qe model exploit crosslingual sentence embedding pretrained multilingual language model . obtain new state - - - art result wmt 2019 qe metric task outperform sentbleu wmt 2019 metrics task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 16, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Multi-task Learning for Multilingual Neural Machine Translation,"While monolingual data has been shown to be useful in improving bilingual neural machine translation (NMT), effectively and efficiently leveraging monolingual data for Multilingual NMT (MNMT) systems is a less explored area. In this work, we propose a multi-task learning (MTL) framework that jointly trains the model with the translation task on bitext data and two denoising tasks on the monolingual data. We conduct extensive empirical studies on MNMT systems with 10 language pairs from WMT datasets. We show that the proposed approach can effectively improve the translation quality for both high-resource and low-resource languages with large margin, achieving significantly better results than the individual bilingual models. We also demonstrate the efficacy of the proposed approach in the zero-shot setup for language pairs without bitext training data. Furthermore, we show the effectiveness of MTL over pre-training approaches for both NMT and cross-lingual transfer learning NLU tasks; the proposed approach outperforms massive scale models trained on single task.","Multi-task Learning for Multilingual Neural Machine Translation While monolingual data has been shown to be useful in improving bilingual neural machine translation (NMT), effectively and efficiently leveraging monolingual data for Multilingual NMT (MNMT) systems is a less explored area. In this work, we propose a multi-task learning (MTL) framework that jointly trains the model with the translation task on bitext data and two denoising tasks on the monolingual data. We conduct extensive empirical studies on MNMT systems with 10 language pairs from WMT datasets. We show that the proposed approach can effectively improve the translation quality for both high-resource and low-resource languages with large margin, achieving significantly better results than the individual bilingual models. We also demonstrate the efficacy of the proposed approach in the zero-shot setup for language pairs without bitext training data. Furthermore, we show the effectiveness of MTL over pre-training approaches for both NMT and cross-lingual transfer learning NLU tasks; the proposed approach outperforms massive scale models trained on single task.","multi - task learning multilingual neural machine translation monolingual datum show useful improve bilingual neural machine translation ( nmt ) , effectively efficiently leverage monolingual datum multilingual nmt ( mnmt ) system explore area . work , propose multi - task learning ( mtl ) framework jointly train model translation task bitext datum denoise task monolingual datum . conduct extensive empirical study mnmt system 10 language pair wmt dataset . propose approach effectively improve translation quality high - resource low - resource language large margin , achieve significantly well result individual bilingual model . demonstrate efficacy propose approach zero - shot setup language pair bitext training datum . furthermore , effectiveness mtl pre - training approach nmt cross - lingual transfer learning nlu task ; propose approach outperform massive scale model train single task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 16, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation,"We present an easy and efficient method to extend existing sentence embedding models to new languages. This allows to create multilingual versions from previously monolingual models. The training is based on the idea that a translated sentence should be mapped to the same location in the vector space as the original sentence. We use the original (monolingual) model to generate sentence embeddings for the source language and then train a new system on translated sentences to mimic the original model. Compared to other methods for training multilingual sentence embeddings, this approach has several advantages: It is easy to extend existing models with relatively few samples to new languages, it is easier to ensure desired properties for the vector space, and the hardware requirements for training are lower. We demonstrate the effectiveness of our approach for 50+ languages from various language families. Code to extend sentence embeddings models to more than 400 languages is publicly available. 1","Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation We present an easy and efficient method to extend existing sentence embedding models to new languages. This allows to create multilingual versions from previously monolingual models. The training is based on the idea that a translated sentence should be mapped to the same location in the vector space as the original sentence. We use the original (monolingual) model to generate sentence embeddings for the source language and then train a new system on translated sentences to mimic the original model. Compared to other methods for training multilingual sentence embeddings, this approach has several advantages: It is easy to extend existing models with relatively few samples to new languages, it is easier to ensure desired properties for the vector space, and the hardware requirements for training are lower. We demonstrate the effectiveness of our approach for 50+ languages from various language families. Code to extend sentence embeddings models to more than 400 languages is publicly available. 1","make monolingual sentence embedding multilingual knowledge distillation present easy efficient method extend exist sentence embedding model new language . allow create multilingual version previously monolingual model . training base idea translate sentence map location vector space original sentence . use original ( monolingual ) model generate sentence embedding source language train new system translate sentence mimic original model . compare method train multilingual sentence embedding , approach advantage : easy extend exist model relatively sample new language , easy ensure desire property vector space , hardware requirement train low . demonstrate effectiveness approach 50 + language language family . code extend sentence embedding model 400 language publicly available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Can Automatic Post-Editing Improve NMT?,"Automatic post-editing (APE) aims to improve machine translations, thereby reducing human post-editing effort. APE has had notable success when used with statistical machine translation (SMT) systems but has not been as successful over neural machine translation (NMT) systems. This has raised questions on the relevance of APE task in the current scenario. However, the training of APE models has been heavily reliant on large-scale artificial corpora combined with only limited human post-edited data. We hypothesize that APE models have been underperforming in improving NMT translations due to the lack of adequate supervision. To ascertain our hypothesis, we compile a larger corpus of human post-edits of English to German NMT. We empirically show that a state-of-art neural APE model trained on this corpus can significantly improve a strong in-domain NMT system, challenging the current understanding in the field. We further investigate the effects of varying training data sizes, using artificial training data, and domain specificity for the APE task. We release this new corpus under CC BY-NC-SA 4.0 license at https:// github.com/shamilcm/pedra.","Can Automatic Post-Editing Improve NMT? Automatic post-editing (APE) aims to improve machine translations, thereby reducing human post-editing effort. APE has had notable success when used with statistical machine translation (SMT) systems but has not been as successful over neural machine translation (NMT) systems. This has raised questions on the relevance of APE task in the current scenario. However, the training of APE models has been heavily reliant on large-scale artificial corpora combined with only limited human post-edited data. We hypothesize that APE models have been underperforming in improving NMT translations due to the lack of adequate supervision. To ascertain our hypothesis, we compile a larger corpus of human post-edits of English to German NMT. We empirically show that a state-of-art neural APE model trained on this corpus can significantly improve a strong in-domain NMT system, challenging the current understanding in the field. We further investigate the effects of varying training data sizes, using artificial training data, and domain specificity for the APE task. We release this new corpus under CC BY-NC-SA 4.0 license at https:// github.com/shamilcm/pedra.","automatic post - editing improve nmt ? automatic post - editing ( ape ) aim improve machine translation , reduce human post - editing effort . ape notable success statistical machine translation ( smt ) system successful neural machine translation ( nmt ) system . raise question relevance ape task current scenario . , training ape model heavily reliant large - scale artificial corpora combine limited human post - edited datum . hypothesize ape model underperform improve nmt translation lack adequate supervision . ascertain hypothesis , compile large corpus human post - edit english german nmt . empirically state - - art neural ape model train corpus significantly improve strong - domain nmt system , challenge current understanding field . investigate effect vary training datum size , artificial training datum , domain specificity ape task . release new corpus cc - nc - sa 4.0 license https:// github.com/shamilcm/pedra .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 16, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Localizing Open-Ontology QA Semantic Parsers in a Day Using Machine Translation,"We propose Semantic Parser Localizer (SPL), a toolkit that leverages Neural Machine Translation (NMT) systems to localize a semantic parser for a new language. Our methodology is to (1) generate training data automatically in the target language by augmenting machine-translated datasets with local entities scraped from public websites, (2) add a fewshot boost of human-translated sentences and train a novel XLMR-LSTM semantic parser, and (3) test the model on natural utterances curated using human translators. We assess the effectiveness of our approach by extending the current capabilities of Schema2QA, a system for English Question Answering (QA) on the open web, to 10 new languages for the restaurants and hotels domains. Our models achieve an overall test accuracy ranging between 61% and 69% for the hotels domain and between 64% and 78% for restaurants domain, which compares favorably to 69% and 80% obtained for English parser trained on gold English data and a few examples from validation set. We show our approach outperforms the previous state-of-theart methodology by more than 30% for hotels and 40% for restaurants with localized ontologies for the subset of languages tested. Our methodology enables any software developer to add a new language capability to a QA system for a new domain, leveraging machine translation, in less than 24 hours. Our code is released open-source. 1","Localizing Open-Ontology QA Semantic Parsers in a Day Using Machine Translation We propose Semantic Parser Localizer (SPL), a toolkit that leverages Neural Machine Translation (NMT) systems to localize a semantic parser for a new language. Our methodology is to (1) generate training data automatically in the target language by augmenting machine-translated datasets with local entities scraped from public websites, (2) add a fewshot boost of human-translated sentences and train a novel XLMR-LSTM semantic parser, and (3) test the model on natural utterances curated using human translators. We assess the effectiveness of our approach by extending the current capabilities of Schema2QA, a system for English Question Answering (QA) on the open web, to 10 new languages for the restaurants and hotels domains. Our models achieve an overall test accuracy ranging between 61% and 69% for the hotels domain and between 64% and 78% for restaurants domain, which compares favorably to 69% and 80% obtained for English parser trained on gold English data and a few examples from validation set. We show our approach outperforms the previous state-of-theart methodology by more than 30% for hotels and 40% for restaurants with localized ontologies for the subset of languages tested. Our methodology enables any software developer to add a new language capability to a QA system for a new domain, leveraging machine translation, in less than 24 hours. Our code is released open-source. 1","localize open - ontology qa semantic parser day machine translation propose semantic parser localizer ( spl ) , toolkit leverage neural machine translation ( nmt ) system localize semantic parser new language . methodology ( 1 ) generate train datum automatically target language augment machine - translate dataset local entity scrape public website , ( 2 ) add fewshot boost human - translate sentence train novel xlmr - lstm semantic parser , ( 3 ) test model natural utterance curate human translator . assess effectiveness approach extend current capability schema2qa , system english question answering ( qa ) open web , 10 new language restaurant hotel domain . model achieve overall test accuracy range 61 % 69 % hotel domain 64 % 78 % restaurant domain , compare favorably 69 % 80 % obtain english parser train gold english datum example validation set . approach outperform previous state - - theart methodology 30 % hotel 40 % restaurant localize ontology subset language test . methodology enable software developer add new language capability qa system new domain , leverage machine translation , 24 hour . code release open - source . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 9, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,OCR Post Correction for Endangered Language Texts,"There is little to no data available to build natural language processing models for most endangered languages. However, textual data in these languages often exists in formats that are not machine-readable, such as paper books and scanned images. In this work, we address the task of extracting text from these resources. We create a benchmark dataset of transcriptions for scanned books in three critically endangered languages and present a systematic analysis of how general-purpose OCR tools are not robust to the data-scarce setting of endangered languages. We develop an OCR postcorrection method tailored to ease training in this data-scarce setting, reducing the recognition error rate by 34% on average across the three languages.","OCR Post Correction for Endangered Language Texts There is little to no data available to build natural language processing models for most endangered languages. However, textual data in these languages often exists in formats that are not machine-readable, such as paper books and scanned images. In this work, we address the task of extracting text from these resources. We create a benchmark dataset of transcriptions for scanned books in three critically endangered languages and present a systematic analysis of how general-purpose OCR tools are not robust to the data-scarce setting of endangered languages. We develop an OCR postcorrection method tailored to ease training in this data-scarce setting, reducing the recognition error rate by 34% on average across the three languages.","ocr post correction endangered language text little datum available build natural language processing model endanger language . , textual data language exist format machine - readable , paper book scan image . work , address task extract text resource . create benchmark dataset transcription scan book critically endanger language present systematic analysis general - purpose ocr tool robust data - scarce setting endanger language . develop ocr postcorrection method tailor ease training data - scarce setting , reduce recognition error rate 34 % average language .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Machine Translation and Multilinguality,LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction Through Non-Linear Mapping in Latent Space,"Most of the successful and predominant methods for Bilingual Lexicon Induction (BLI) are mapping-based, where a linear mapping function is learned with the assumption that the word embedding spaces of different languages exhibit similar geometric structures (i.e., approximately isomorphic). However, several recent studies have criticized this simplified assumption showing that it does not hold in general even for closely related languages. In this work, we propose a novel semi-supervised method to learn cross-lingual word embeddings for BLI. Our model is independent of the isomorphic assumption and uses non-linear mapping in the latent space of two independently pre-trained autoencoders. Through extensive experiments on fifteen (15) different language pairs (in both directions) comprising resource-rich and low-resource languages from two different datasets, we demonstrate that our method outperforms existing models by a good margin. Ablation studies show the importance of different model components and the necessity of non-linear mapping.","LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon Induction Through Non-Linear Mapping in Latent Space Most of the successful and predominant methods for Bilingual Lexicon Induction (BLI) are mapping-based, where a linear mapping function is learned with the assumption that the word embedding spaces of different languages exhibit similar geometric structures (i.e., approximately isomorphic). However, several recent studies have criticized this simplified assumption showing that it does not hold in general even for closely related languages. In this work, we propose a novel semi-supervised method to learn cross-lingual word embeddings for BLI. Our model is independent of the isomorphic assumption and uses non-linear mapping in the latent space of two independently pre-trained autoencoders. Through extensive experiments on fifteen (15) different language pairs (in both directions) comprising resource-rich and low-resource languages from two different datasets, we demonstrate that our method outperforms existing models by a good margin. Ablation studies show the importance of different model components and the necessity of non-linear mapping.","lnmap : departure isomorphic assumption bilingual lexicon induction non - linear mapping latent space successful predominant method bilingual lexicon induction ( bli ) mapping - base , linear mapping function learn assumption word embed space different language exhibit similar geometric structure ( i.e. , approximately isomorphic ) . , recent study criticize simplified assumption show hold general closely relate language . work , propose novel semi - supervised method learn cross - lingual word embedding bli . model independent isomorphic assumption use non - linear mapping latent space independently pre - train autoencoder . extensive experiment ( 15 ) different language pair ( direction ) comprise resource - rich low - resource language different dataset , demonstrate method outperform exist model good margin . ablation study importance different model component necessity non - linear mapping .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,LAReQA: Language-Agnostic Answer Retrieval from a Multilingual Pool,"We present LAReQA, a challenging new benchmark for language-agnostic answer retrieval from a multilingual candidate pool. Unlike previous cross-lingual tasks, LAReQA tests for ""strong"" cross-lingual alignment, requiring semantically related cross-language pairs to be closer in representation space than unrelated same-language pairs. This level of alignment is important for the practical task of cross-lingual information retrieval. Building on multilingual BERT (mBERT), we study different strategies for achieving strong alignment. We find that augmenting training data via machine translation is effective, and improves significantly over using mBERT outof-the-box. Interestingly, model performance on zero-shot variants of our task that only target ""weak"" alignment is not predictive of performance on LAReQA. This finding underscores our claim that language-agnostic retrieval is a substantively new kind of crosslingual evaluation, and suggests that measuring both weak and strong alignment will be important for improving cross-lingual systems going forward. We release our dataset and evaluation code at https://github.com/ google-research-datasets/lareqa.","LAReQA: Language-Agnostic Answer Retrieval from a Multilingual Pool We present LAReQA, a challenging new benchmark for language-agnostic answer retrieval from a multilingual candidate pool. Unlike previous cross-lingual tasks, LAReQA tests for ""strong"" cross-lingual alignment, requiring semantically related cross-language pairs to be closer in representation space than unrelated same-language pairs. This level of alignment is important for the practical task of cross-lingual information retrieval. Building on multilingual BERT (mBERT), we study different strategies for achieving strong alignment. We find that augmenting training data via machine translation is effective, and improves significantly over using mBERT outof-the-box. Interestingly, model performance on zero-shot variants of our task that only target ""weak"" alignment is not predictive of performance on LAReQA. This finding underscores our claim that language-agnostic retrieval is a substantively new kind of crosslingual evaluation, and suggests that measuring both weak and strong alignment will be important for improving cross-lingual systems going forward. We release our dataset and evaluation code at https://github.com/ google-research-datasets/lareqa.","lareqa : language - agnostic answer retrieval multilingual pool present lareqa , challenge new benchmark language - agnostic answer retrieval multilingual candidate pool . unlike previous cross - lingual task , lareqa test "" strong "" cross - lingual alignment , require semantically related cross - language pair close representation space unrelated - language pair . level alignment important practical task cross - lingual information retrieval . build multilingual bert ( mbert ) , study different strategy achieve strong alignment . find augment training datum machine translation effective , improve significantly mbert outof - - box . interestingly , model performance zero - shot variant task target "" weak "" alignment predictive performance lareqa . finding underscore claim language - agnostic retrieval substantively new kind crosslingual evaluation , suggest measure weak strong alignment important improve cross - lingual system go forward . release dataset evaluation code https://github.com/ google - research - dataset / lareqa .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 7, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer,"The main goal behind state-of-the-art pretrained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot crosslingual transfer. However, due to limited model capacity, their transfer performance is the weakest exactly on such low-resource languages and languages unseen during pretraining. We propose MAD-X, an adapter-based framework that enables high portability and parameter-efficient transfer to arbitrary tasks and languages by learning modular language and task representations. In addition, we introduce a novel invertible adapter architecture and a strong baseline method for adapting a pretrained multilingual model to a new language. MAD-X outperforms the state of the art in cross-lingual transfer across a representative set of typologically diverse languages on named entity recognition and causal commonsense reasoning, and achieves competitive results on question answering. Our code and adapters are available at AdapterHub.ml. Gurevych. 2020. AdapterDrop: On the Efficiency of Adapters in Transformers. arXiv preprint.","MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer The main goal behind state-of-the-art pretrained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot crosslingual transfer. However, due to limited model capacity, their transfer performance is the weakest exactly on such low-resource languages and languages unseen during pretraining. We propose MAD-X, an adapter-based framework that enables high portability and parameter-efficient transfer to arbitrary tasks and languages by learning modular language and task representations. In addition, we introduce a novel invertible adapter architecture and a strong baseline method for adapting a pretrained multilingual model to a new language. MAD-X outperforms the state of the art in cross-lingual transfer across a representative set of typologically diverse languages on named entity recognition and causal commonsense reasoning, and achieves competitive results on question answering. Our code and adapters are available at AdapterHub.ml. Gurevych. 2020. AdapterDrop: On the Efficiency of Adapters in Transformers. arXiv preprint.","mad - x : adapter - base framework multi - task cross - lingual transfer main goal state - - - art pretraine multilingual model multilingual bert xlm - r enable bootstrappe nlp application low - resource language zero - shot - shot crosslingual transfer . , limited model capacity , transfer performance weak exactly low - resource language language unseen pretraining . propose mad - x , adapter - base framework enable high portability parameter - efficient transfer arbitrary task language learn modular language task representation . addition , introduce novel invertible adapter architecture strong baseline method adapt pretrained multilingual model new language . mad - x outperform state art cross - lingual transfer representative set typologically diverse language name entity recognition causal commonsense reasoning , achieve competitive result question answering . code adapter available adapterhub.ml . gurevych . 2020 . adapterdrop : efficiency adapter transformers . arxiv preprint .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,The Multilingual Amazon Reviews Corpus,"We present the Multilingual Amazon Reviews Corpus (MARC), a large-scale collection of Amazon reviews for multilingual text classification. The corpus contains reviews in English, Japanese, German, French, Spanish, and Chinese, which were collected between 2015 and 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID, and the coarse-grained product category (e.g., 'books', 'appliances', etc.) The corpus is balanced across the 5 possible star ratings, so each rating constitutes 20% of the reviews in each language. For each language, there are 200,000, 5,000, and 5,000 reviews in the training, development, and test sets, respectively. We report baseline results for supervised text classification and zero-shot crosslingual transfer learning by fine-tuning a multilingual BERT model on reviews data. We propose the use of mean absolute error (MAE) instead of classification accuracy for this task, since MAE accounts for the ordinal nature of the ratings.","The Multilingual Amazon Reviews Corpus We present the Multilingual Amazon Reviews Corpus (MARC), a large-scale collection of Amazon reviews for multilingual text classification. The corpus contains reviews in English, Japanese, German, French, Spanish, and Chinese, which were collected between 2015 and 2019. Each record in the dataset contains the review text, the review title, the star rating, an anonymized reviewer ID, an anonymized product ID, and the coarse-grained product category (e.g., 'books', 'appliances', etc.) The corpus is balanced across the 5 possible star ratings, so each rating constitutes 20% of the reviews in each language. For each language, there are 200,000, 5,000, and 5,000 reviews in the training, development, and test sets, respectively. We report baseline results for supervised text classification and zero-shot crosslingual transfer learning by fine-tuning a multilingual BERT model on reviews data. We propose the use of mean absolute error (MAE) instead of classification accuracy for this task, since MAE accounts for the ordinal nature of the ratings.","multilingual amazon reviews corpus present multilingual amazon reviews corpus ( marc ) , large - scale collection amazon review multilingual text classification . corpus contain review english , japanese , german , french , spanish , chinese , collect 2015 2019 . record dataset contain review text , review title , star rating , anonymized reviewer id , anonymized product id , coarse - grained product category ( e.g. , ' book ' , ' appliance ' , etc . ) corpus balance 5 possible star rating , rating constitute 20 % review language . language , 200,000 , 5,000 , 5,000 review training , development , test set , respectively . report baseline result supervise text classification zero - shot crosslingual transfer learning fine - tune multilingual bert model review datum . propose use mean absolute error ( mae ) instead classification accuracy task , mae account ordinal nature rating .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 5, 'Summarization': 10, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,False
Machine Translation and Multilinguality,COMET: A Neural Framework for MT Evaluation,"We present COMET, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-theart levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metrics. Our models achieve new state-ofthe-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems.","COMET: A Neural Framework for MT Evaluation We present COMET, a neural framework for training multilingual machine translation evaluation models which obtains new state-of-theart levels of correlation with human judgements. Our framework leverages recent breakthroughs in cross-lingual pretrained language modeling resulting in highly multilingual and adaptable MT evaluation models that exploit information from both the source input and a target-language reference translation in order to more accurately predict MT quality. To showcase our framework, we train three models with different types of human judgements: Direct Assessments, Human-mediated Translation Edit Rate and Multidimensional Quality Metrics. Our models achieve new state-ofthe-art performance on the WMT 2019 Metrics shared task and demonstrate robustness to high-performing systems.","comet : neural framework mt evaluation present comet , neural framework train multilingual machine translation evaluation model obtain new state - - theart level correlation human judgement . framework leverage recent breakthrough cross - lingual pretrained language modeling result highly multilingual adaptable mt evaluation model exploit information source input target - language reference translation order accurately predict mt quality . showcase framework , train model different type human judgement : direct assessment , human - mediate translation edit rate multidimensional quality metrics . model achieve new state - ofthe - art performance wmt 2019 metric share task demonstrate robustness high - perform system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Translation and Multilinguality,Identifying Elements Essential for BERT's Multilinguality,"It has been shown that multilingual BERT (mBERT) yields high quality multilingual representations and enables effective zero-shot transfer. This is surprising given that mBERT does not use any crosslingual signal during training. While recent literature has studied this phenomenon, the reasons for the multilinguality are still somewhat obscure. We aim to identify architectural properties of BERT and linguistic properties of languages that are necessary for BERT to become multilingual. To allow for fast experimentation we propose an efficient setup with small BERT models trained on a mix of synthetic and natural data. Overall, we identify four architectural and two linguistic elements that influence multilinguality. Based on our insights, we experiment with a multilingual pretraining setup that modifies the masking strategy using VecMap, i.e., unsupervised embedding alignment. Experiments on XNLI with three languages indicate that our findings transfer from our small setup to larger scale settings. 0 original .70 1.00 .00 .16 .02 .88 .02 1.00 .00 .97 .01 .79 .03 9 00.2 217 07.8 1 lang-pos .30 .87 .05 .33 .13 .40 .09 .89 .05 .39 .15 .09 .05 9 00.1 216 09.0 2 shift-special .66 1.00 .00 .15 .02 .88 .01 1.00 .00 .97 .02 .63 .13 9 00.1 227 17.9 4 no-random .68 1.00 .00 .19 .03 .87 .02 1.00 .00 .85 .07 .82 .04 9 00.6 273 07.7 5 lang-pos;shift-special .20 .62 .19 .22 .19 .27 .20 .72 .22 .27 .21 .05 .04 10 00.5 205 07.6 6 lang-pos;no-random .30 .91 .04 .29 .10 .36 .12 .89 .05 .32 .15 .25 .12 10 00.4 271 08.6 7 shift-special;no-random .68 1.00 .00 .21 .03 .85 .01 1.00 .00 .89 .06 .79 .04 8 00.3 259 15.6 8 lang-pos;shift-special;no-random .12 .46 .26 .09 .09 .18 .22 .54 .31 .11 .11 .11 .13 10 00.6 254 15.9 15 overparam .58 1.00 .00 .27 .03 .63 .05 1.00 .00 .97 .01 .47 .06 2 00.1 261 04.5 16 lang-pos;overparam .01 .25 .10 .01 .00 .01 .00 .37 .13 .01 .00 .00 .00 3 00.0 254 04.9 17 lang-pos;shift-special;no-random;overparam .00 .05 .02 .00 .00 .00 .00 .05 .04 .00 .00 .00 .00 1 00.0 307 07.7 3 inv-order .01 .02 .00 .00 .00 .01 .00 .02 .00 .01 .01 .00 .00 11 00.3 209 14.4 9 lang-pos;inv-order;shift-special;no-random .00 .04 .01 .00 .00 .00 .00 .03 .01 .00 .00 .00 .00 10 00.4 270 20.1 18 untrained .00 .97 .01 .00 .00 .00 .00 .96 .01 .00 .00 .00 .00 3484 44.1 4128 42.7 19 untrained;lang-pos .00 .02 .00 .00 .00 .00 .00 .02 .00 .00 .00 .00 .00 3488 41.4 4133 50.3 30 knn-replace .74 1.00 .00 .31 .08 .88 .00 1.00 .00 .97 .01 .81 .01 11 00.3 225 12.4","Identifying Elements Essential for BERT's Multilinguality It has been shown that multilingual BERT (mBERT) yields high quality multilingual representations and enables effective zero-shot transfer. This is surprising given that mBERT does not use any crosslingual signal during training. While recent literature has studied this phenomenon, the reasons for the multilinguality are still somewhat obscure. We aim to identify architectural properties of BERT and linguistic properties of languages that are necessary for BERT to become multilingual. To allow for fast experimentation we propose an efficient setup with small BERT models trained on a mix of synthetic and natural data. Overall, we identify four architectural and two linguistic elements that influence multilinguality. Based on our insights, we experiment with a multilingual pretraining setup that modifies the masking strategy using VecMap, i.e., unsupervised embedding alignment. Experiments on XNLI with three languages indicate that our findings transfer from our small setup to larger scale settings. 0 original .70 1.00 .00 .16 .02 .88 .02 1.00 .00 .97 .01 .79 .03 9 00.2 217 07.8 1 lang-pos .30 .87 .05 .33 .13 .40 .09 .89 .05 .39 .15 .09 .05 9 00.1 216 09.0 2 shift-special .66 1.00 .00 .15 .02 .88 .01 1.00 .00 .97 .02 .63 .13 9 00.1 227 17.9 4 no-random .68 1.00 .00 .19 .03 .87 .02 1.00 .00 .85 .07 .82 .04 9 00.6 273 07.7 5 lang-pos;shift-special .20 .62 .19 .22 .19 .27 .20 .72 .22 .27 .21 .05 .04 10 00.5 205 07.6 6 lang-pos;no-random .30 .91 .04 .29 .10 .36 .12 .89 .05 .32 .15 .25 .12 10 00.4 271 08.6 7 shift-special;no-random .68 1.00 .00 .21 .03 .85 .01 1.00 .00 .89 .06 .79 .04 8 00.3 259 15.6 8 lang-pos;shift-special;no-random .12 .46 .26 .09 .09 .18 .22 .54 .31 .11 .11 .11 .13 10 00.6 254 15.9 15 overparam .58 1.00 .00 .27 .03 .63 .05 1.00 .00 .97 .01 .47 .06 2 00.1 261 04.5 16 lang-pos;overparam .01 .25 .10 .01 .00 .01 .00 .37 .13 .01 .00 .00 .00 3 00.0 254 04.9 17 lang-pos;shift-special;no-random;overparam .00 .05 .02 .00 .00 .00 .00 .05 .04 .00 .00 .00 .00 1 00.0 307 07.7 3 inv-order .01 .02 .00 .00 .00 .01 .00 .02 .00 .01 .01 .00 .00 11 00.3 209 14.4 9 lang-pos;inv-order;shift-special;no-random .00 .04 .01 .00 .00 .00 .00 .03 .01 .00 .00 .00 .00 10 00.4 270 20.1 18 untrained .00 .97 .01 .00 .00 .00 .00 .96 .01 .00 .00 .00 .00 3484 44.1 4128 42.7 19 untrained;lang-pos .00 .02 .00 .00 .00 .00 .00 .02 .00 .00 .00 .00 .00 3488 41.4 4133 50.3 30 knn-replace .74 1.00 .00 .31 .08 .88 .00 1.00 .00 .97 .01 .81 .01 11 00.3 225 12.4","identify element essential bert multilinguality show multilingual bert ( mbert ) yield high quality multilingual representation enable effective zero - shot transfer . surprising give mbert use crosslingual signal training . recent literature study phenomenon , reason multilinguality somewhat obscure . aim identify architectural property bert linguistic property language necessary bert multilingual . allow fast experimentation propose efficient setup small bert model train mix synthetic natural datum . overall , identify architectural linguistic element influence multilinguality . base insight , experiment multilingual pretraine setup modify masking strategy vecmap , i.e. , unsupervised embedding alignment . experiment xnli language indicate finding transfer small setup large scale setting . 0 original .70 1.00 .00 .16 .02 .88 .02 1.00 .00 .97 .01 .79 .03 9 00.2 217 07.8 1 lang - pos .30 .87 .05 .33 .13 .40 .09 .89 .05 .39 .15 .09 .05 9 00.1 216 09.0 2 shift - special .66 1.00 .00 .15 .02 .88 .01 1.00 .00 .97 .02 .63 .13 9 00.1 227 17.9 4 - random .68 1.00 .00 .19 .03 .87 .02 1.00 .00 .85 .07 .82 .04 9 00.6 273 07.7 5 lang - pos;shift - special .20 .62 .19 .22 .19 .27 .20 .72 .22 .27 .21 .05 .04 10 00.5 205 07.6 6 lang - pos;no - random .30 .91 .04 .29 .10 .36 .12 .89 .05 .32 .15 .25 .12 10 00.4 271 08.6 7 shift - special;no - random .68 1.00 .00 .21 .03 .85 .01 1.00 .00 .89 .06 .79 .04 8 00.3 259 15.6 8 lang - pos;shift - special;no - random .12 .46 .26 .09 .09 .18 .22 .54 .31 .11 .11 .11 .13 10 00.6 254 15.9 15 overparam .58 1.00 .00 .27 .03 .63 .05 1.00 .00 .97 .01 .47 .06 2 00.1 261 04.5 16 lang - pos;overparam .01 .25 .10 .01 .00 .01 .00 .37 .13 .01 .00 .00 .00 3 00.0 254 04.9 17 lang - pos;shift - special;no - random;overparam .00 .05 .02 .00 .00 .00 .00 .05 .04 .00 .00 .00 .00 1 00.0 307 07.7 3 inv - order .01 .02 .00 .00 .00 .01 .00 .02 .00 .01 .01 .00 .00 11 00.3 209 14.4 9 lang - pos;inv - order;shift - special;no - random .00 .04 .01 .00 .00 .00 .00 .03 .01 .00 .00 .00 .00 10 00.4 270 20.1 18 untrained .00 .97 .01 .00 .00 .00 .00 .96 .01 .00 .00 .00 .00 3484 44.1 4128 42.7 19 untrained;lang - pos .00 .02 .00 .00 .00 .00 .00 .02 .00 .00 .00 .00 .00 3488 41.4 4133 50.3 30 knn - replace .74 1.00 .00 .31 .08 .88 .00 1.00 .00 .97 .01 .81 .01 11 00.3 225 12.4","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Understanding the Difficulty of Training Transformers,"Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding carefully designing cutting-edge optimizers and learning rate schedulers (e.g., conventional SGD fails to train Transformers effectively). Our objective here is to understand what complicates Transformer training from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences training substantially-for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies small parameter perturbations (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin (Adaptive model initialization) to stabilize the early stage's training and unleash its full potential in the late stage. Extensive experiments show that Admin is more stable, converges faster, and leads to better performance 1 .","Understanding the Difficulty of Training Transformers Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding carefully designing cutting-edge optimizers and learning rate schedulers (e.g., conventional SGD fails to train Transformers effectively). Our objective here is to understand what complicates Transformer training from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences training substantially-for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies small parameter perturbations (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin (Adaptive model initialization) to stabilize the early stage's training and unleash its full potential in the late stage. Extensive experiments show that Admin is more stable, converges faster, and leads to better performance 1 .","understand difficulty train transformers transformers prove effective nlp task . , training require non - trivial effort carefully design cutting - edge optimizer learning rate scheduler ( e.g. , conventional sgd fail train transformers effectively ) . objective understand complicate transformer training empirical theoretical perspective . analysis reveal unbalanced gradient root cause instability training . instead , identify amplification effect influence training substantially - layer multi - layer transformer model , heavy dependency residual branch make training unstable , amplify small parameter perturbation ( e.g. , parameter update ) result significant disturbance model output . observe light dependency limit model potential lead inferior train model . inspire analysis , propose admin ( adaptive model initialization ) stabilize early stage training unleash potential late stage . extensive experiment admin stable , converge fast , lead well performance 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models,"Language models (LMs) have proven surprisingly successful at capturing factual knowledge by completing cloze-style fill-in-theblank questions such as ""Punta Cana is located in _."" However, while knowledge is both written and queried in many languages, studies on LMs' factual representation ability have almost invariably been performed on English. To assess factual knowledge retrieval in LMs in different languages, we create a multilingual benchmark of cloze-style probes for 23 typologically diverse languages. To properly handle language variations, we expand probing methods from single-to multi-word entities, and develop several decoding algorithms to generate multi-token predictions. Extensive experimental results provide insights about how well (or poorly) current state-of-theart LMs perform at this task in languages with more or fewer available resources. We further propose a code-switching-based method to improve the ability of multilingual LMs to access knowledge, and verify its effectiveness on several benchmark languages. Benchmark data and code have be released at https: //x-factr.github.io.","X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models Language models (LMs) have proven surprisingly successful at capturing factual knowledge by completing cloze-style fill-in-theblank questions such as ""Punta Cana is located in _."" However, while knowledge is both written and queried in many languages, studies on LMs' factual representation ability have almost invariably been performed on English. To assess factual knowledge retrieval in LMs in different languages, we create a multilingual benchmark of cloze-style probes for 23 typologically diverse languages. To properly handle language variations, we expand probing methods from single-to multi-word entities, and develop several decoding algorithms to generate multi-token predictions. Extensive experimental results provide insights about how well (or poorly) current state-of-theart LMs perform at this task in languages with more or fewer available resources. We further propose a code-switching-based method to improve the ability of multilingual LMs to access knowledge, and verify its effectiveness on several benchmark languages. Benchmark data and code have be released at https: //x-factr.github.io.","x - factr : multilingual factual knowledge retrieval pretrained language models language model ( lms ) prove surprisingly successful capture factual knowledge complete cloze - style fill - - theblank question "" punta cana locate _ . "" , knowledge write query language , study lms ' factual representation ability invariably perform english . assess factual knowledge retrieval lms different language , create multilingual benchmark cloze - style probe 23 typologically diverse language . properly handle language variation , expand probe method single - multi - word entity , develop decode algorithm generate multi - token prediction . extensive experimental result provide insight ( poorly ) current state - - theart lm perform task language few available resource . propose code - switching - base method improve ability multilingual lm access knowledge , verify effectiveness benchmark language . benchmark datum code release https : //x - factr.github.io .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Machine Translation and Multilinguality,Do Explicit Alignments Robustly Improve Multilingual Encoders?,"Multilingual BERT (Devlin et al., 2019,  mBERT), XLM-RoBERTa (Conneau et al.,  2019, XLMR)  and other unsupervised multilingual encoders can effectively learn crosslingual representation. Explicit alignment objectives based on bitexts like Europarl or Mul-tiUN have been shown to further improve these representations. However, word-level alignments are often suboptimal and such bitexts are unavailable for many languages. In this paper, we propose a new contrastive alignment objective that can better utilize such signal, and examine whether these previous alignment methods can be adapted to noisier sources of aligned data: a randomly sampled 1 million pair subset of the OPUS collection. Additionally, rather than report results on a single dataset with a single model run, we report the mean and standard derivation of multiple runs with different seeds, on four datasets and tasks. Our more extensive analysis finds that, while our new objective outperforms previous work, overall these methods do not improve performance with a more robust evaluation framework. Furthermore, the gains from using a better underlying model eclipse any benefits from alignment training. These negative results dictate more care in evaluating these methods and suggest limitations in applying explicit alignment objectives.","Do Explicit Alignments Robustly Improve Multilingual Encoders? Multilingual BERT (Devlin et al., 2019,  mBERT), XLM-RoBERTa (Conneau et al.,  2019, XLMR)  and other unsupervised multilingual encoders can effectively learn crosslingual representation. Explicit alignment objectives based on bitexts like Europarl or Mul-tiUN have been shown to further improve these representations. However, word-level alignments are often suboptimal and such bitexts are unavailable for many languages. In this paper, we propose a new contrastive alignment objective that can better utilize such signal, and examine whether these previous alignment methods can be adapted to noisier sources of aligned data: a randomly sampled 1 million pair subset of the OPUS collection. Additionally, rather than report results on a single dataset with a single model run, we report the mean and standard derivation of multiple runs with different seeds, on four datasets and tasks. Our more extensive analysis finds that, while our new objective outperforms previous work, overall these methods do not improve performance with a more robust evaluation framework. Furthermore, the gains from using a better underlying model eclipse any benefits from alignment training. These negative results dictate more care in evaluating these methods and suggest limitations in applying explicit alignment objectives.","explicit alignment robustly improve multilingual encoder ? multilingual bert ( devlin et al . , 2019 ,   mbert ) , xlm - roberta ( conneau et al . ,   2019 , xlmr )   unsupervised multilingual encoder effectively learn crosslingual representation . explicit alignment objective base bitext like europarl mul - tiun show improve representation . , word - level alignment suboptimal bitext unavailable language . paper , propose new contrastive alignment objective well utilize signal , examine previous alignment method adapt noisy source align datum : randomly sample 1 million pair subset opus collection . additionally , report result single dataset single model run , report mean standard derivation multiple run different seed , dataset task . extensive analysis find , new objective outperform previous work , overall method improve performance robust evaluation framework . furthermore , gain well underlie model eclipse benefit alignment training . negative result dictate care evaluate method suggest limitation apply explicit alignment objective .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Data Rejuvenation: Exploiting Inactive Training Examples for Neural Machine Translation,"Large-scale training datasets lie at the core of the recent success of neural machine translation (NMT) models. However, the complex patterns and potential noises in the large-scale data make training NMT models difficult. In this work, we explore to identify the inactive training examples which contribute less to the model performance, and show that the existence of inactive examples depends on the data distribution. We further introduce data rejuvenation to improve the training of NMT models on large-scale datasets by exploiting inactive examples. The proposed framework consists of three phases. First, we train an identification model on the original training data, and use it to distinguish inactive examples and active examples by their sentence-level output probabilities. Then, we train a rejuvenation model on the active examples, which is used to re-label the inactive examples with forwardtranslation. Finally, the rejuvenated examples and the active examples are combined to train the final NMT model. Experimental results on WMT14 English-German and English-French datasets show that the proposed data rejuvenation consistently and significantly improves performance for several strong NMT models. Extensive analyses reveal that our approach stabilizes and accelerates the training process of NMT models, resulting in final models with better generalization capability. 1","Data Rejuvenation: Exploiting Inactive Training Examples for Neural Machine Translation Large-scale training datasets lie at the core of the recent success of neural machine translation (NMT) models. However, the complex patterns and potential noises in the large-scale data make training NMT models difficult. In this work, we explore to identify the inactive training examples which contribute less to the model performance, and show that the existence of inactive examples depends on the data distribution. We further introduce data rejuvenation to improve the training of NMT models on large-scale datasets by exploiting inactive examples. The proposed framework consists of three phases. First, we train an identification model on the original training data, and use it to distinguish inactive examples and active examples by their sentence-level output probabilities. Then, we train a rejuvenation model on the active examples, which is used to re-label the inactive examples with forwardtranslation. Finally, the rejuvenated examples and the active examples are combined to train the final NMT model. Experimental results on WMT14 English-German and English-French datasets show that the proposed data rejuvenation consistently and significantly improves performance for several strong NMT models. Extensive analyses reveal that our approach stabilizes and accelerates the training process of NMT models, resulting in final models with better generalization capability. 1","data rejuvenation : exploit inactive training example neural machine translation large - scale training dataset lie core recent success neural machine translation ( nmt ) model . , complex pattern potential noise large - scale datum training nmt model difficult . work , explore identify inactive training example contribute model performance , existence inactive example depend datum distribution . introduce datum rejuvenation improve training nmt model large - scale dataset exploit inactive example . propose framework consist phase . , train identification model original training datum , use distinguish inactive example active example sentence - level output probability . , train rejuvenation model active example , - label inactive example forwardtranslation . finally , rejuvenate example active example combine train final nmt model . experimental result wmt14 english - german english - french dataset propose data rejuvenation consistently significantly improve performance strong nmt model . extensive analysis reveal approach stabilize accelerate training process nmt model , result final model well generalization capability . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 20, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Revisiting Modularized Multilingual NMT to Meet Industrial Demands,"The complete sharing of parameters for multilingual translation (1-1) has been the mainstream approach in current research. However, degraded performance due to the capacity bottleneck and low maintainability hinders its extensive adoption in industries. In this study, we revisit the multilingual neural machine translation model that only share modules among the same languages (M2) as a practical alternative to 1-1 to satisfy industrial requirements. Through comprehensive experiments, we identify the benefits of multi-way training and demonstrate that the M2 can enjoy these benefits without suffering from the capacity bottleneck. Furthermore, the interlingual space of the M2 allows convenient modification of the model. By leveraging trained modules, we find that incrementally added modules exhibit better performance than singly trained models. The zero-shot performance of the added modules is even comparable to supervised models. Our findings suggest that the M2 can be a competent candidate for multilingual translation in industries.","Revisiting Modularized Multilingual NMT to Meet Industrial Demands The complete sharing of parameters for multilingual translation (1-1) has been the mainstream approach in current research. However, degraded performance due to the capacity bottleneck and low maintainability hinders its extensive adoption in industries. In this study, we revisit the multilingual neural machine translation model that only share modules among the same languages (M2) as a practical alternative to 1-1 to satisfy industrial requirements. Through comprehensive experiments, we identify the benefits of multi-way training and demonstrate that the M2 can enjoy these benefits without suffering from the capacity bottleneck. Furthermore, the interlingual space of the M2 allows convenient modification of the model. By leveraging trained modules, we find that incrementally added modules exhibit better performance than singly trained models. The zero-shot performance of the added modules is even comparable to supervised models. Our findings suggest that the M2 can be a competent candidate for multilingual translation in industries.","revisit modularize multilingual nmt meet industrial demand complete sharing parameter multilingual translation ( 1 - 1 ) mainstream approach current research . , degraded performance capacity bottleneck low maintainability hinder extensive adoption industry . study , revisit multilingual neural machine translation model share module language ( m2 ) practical alternative 1 - 1 satisfy industrial requirement . comprehensive experiment , identify benefit multi - way training demonstrate m2 enjoy benefit suffer capacity bottleneck . furthermore , interlingual space m2 allow convenient modification model . leverage train module , find incrementally add module exhibit well performance singly train model . zero - shot performance add module comparable supervise model . finding suggest m2 competent candidate multilingual translation industry .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information,"We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-train a universal multilingual neural machine translation model. Our key idea in mRASP is its novel technique of random aligned substitution, which brings words and phrases with similar meanings across multiple languages closer in the representation space. We pre-train a mRASP model on 32 language pairs jointly with only public datasets. The model is then fine-tuned on downstream language pairs to obtain specialized MT models. We carry out extensive experiments on 42 translation directions across a diverse settings, including low, medium, rich resource, and as well as transferring to exotic language pairs. Experimental results demonstrate that mRASP achieves significant performance improvement compared to directly training on those target pairs. It is the first time to verify that multiple lowresource language pairs can be utilized to improve rich resource MT. Surprisingly, mRASP is even able to improve the translation quality on exotic languages that never occur in the pretraining corpus. Code, data, and pre-trained models are available at https://github. com/linzehui/mRASP. * Equal contribution. The work was done when the first author was an intern at ByteDance.","Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-train a universal multilingual neural machine translation model. Our key idea in mRASP is its novel technique of random aligned substitution, which brings words and phrases with similar meanings across multiple languages closer in the representation space. We pre-train a mRASP model on 32 language pairs jointly with only public datasets. The model is then fine-tuned on downstream language pairs to obtain specialized MT models. We carry out extensive experiments on 42 translation directions across a diverse settings, including low, medium, rich resource, and as well as transferring to exotic language pairs. Experimental results demonstrate that mRASP achieves significant performance improvement compared to directly training on those target pairs. It is the first time to verify that multiple lowresource language pairs can be utilized to improve rich resource MT. Surprisingly, mRASP is even able to improve the translation quality on exotic languages that never occur in the pretraining corpus. Code, data, and pre-trained models are available at https://github. com/linzehui/mRASP. * Equal contribution. The work was done when the first author was an intern at ByteDance.","pre - training multilingual neural machine translation leverage alignment information investigate follow question machine translation ( mt ): develop single universal mt model serve common seed obtain derivative improved model arbitrary language pair ? propose mrasp , approach pre - train universal multilingual neural machine translation model . key idea mrasp novel technique random align substitution , bring word phrase similar meaning multiple language close representation space . pre - train mrasp model 32 language pair jointly public dataset . model fine - tune downstream language pair obtain specialized mt model . carry extensive experiment 42 translation direction diverse setting , include low , medium , rich resource , transfer exotic language pair . experimental result demonstrate mrasp achieve significant performance improvement compare directly train target pair . time verify multiple lowresource language pair utilize improve rich resource mt . surprisingly , mrasp able improve translation quality exotic language occur pretraine corpus . code , datum , pre - trained model available https://github . com / linzehui / mrasp . * equal contribution . work author intern bytedance .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Non-Autoregressive Machine Translation with Latent Alignments,"This paper presents two strong methods, CTC and Imputer, for non-autoregressive machine translation that model latent alignments with dynamic programming. We revisit CTC for machine translation and demonstrate that a simple CTC model can achieve state-of-theart for single-step non-autoregressive machine translation, contrary to what prior work indicates. In addition, we adapt the Imputer model for non-autoregressive machine translation and demonstrate that Imputer with just 4 generation steps can match the performance of an autoregressive Transformer baseline. Our latent alignment models are simpler than many existing non-autoregressive translation baselines; for example, we do not require target length prediction or re-scoring with an autoregressive model. On the competitive WMT'14 En→De task, our CTC model achieves 25.7 BLEU with a single generation step, while Imputer achieves 27.5 BLEU with 2 generation steps, and 28.0 BLEU with 4 generation steps. This compares favourably to the autoregressive Transformer baseline at 27.8 BLEU.","Non-Autoregressive Machine Translation with Latent Alignments This paper presents two strong methods, CTC and Imputer, for non-autoregressive machine translation that model latent alignments with dynamic programming. We revisit CTC for machine translation and demonstrate that a simple CTC model can achieve state-of-theart for single-step non-autoregressive machine translation, contrary to what prior work indicates. In addition, we adapt the Imputer model for non-autoregressive machine translation and demonstrate that Imputer with just 4 generation steps can match the performance of an autoregressive Transformer baseline. Our latent alignment models are simpler than many existing non-autoregressive translation baselines; for example, we do not require target length prediction or re-scoring with an autoregressive model. On the competitive WMT'14 En→De task, our CTC model achieves 25.7 BLEU with a single generation step, while Imputer achieves 27.5 BLEU with 2 generation steps, and 28.0 BLEU with 4 generation steps. This compares favourably to the autoregressive Transformer baseline at 27.8 BLEU.","non - autoregressive machine translation latent alignment paper present strong method , ctc imputer , non - autoregressive machine translation model latent alignment dynamic programming . revisit ctc machine translation demonstrate simple ctc model achieve state - - theart single - step non - autoregressive machine translation , contrary prior work indicate . addition , adapt imputer model non - autoregressive machine translation demonstrate imputer 4 generation step match performance autoregressive transformer baseline . latent alignment model simple exist non - autoregressive translation baseline ; example , require target length prediction - scoring autoregressive model . competitive wmt'14 en→de task , ctc model achieve 25.7 bleu single generation step , imputer achieve 27.5 bleu 2 generation step , 28.0 bleu 4 generation step . compare favourably autoregressive transformer baseline 27.8 bleu .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 20, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
NLP Applications,DGST: a Dual-Generator Network for Text Style Transfer,"We propose DGST, a novel and simple Dual-Generator network architecture for text Style Transfer. Our model employs two generators only, and does not rely on any discriminators or parallel corpus for training. Both quantitative and qualitative experiments on the Yelp and IMDb datasets show that our model gives competitive performance compared to several strong baselines with more complicated architecture designs.","DGST: a Dual-Generator Network for Text Style Transfer We propose DGST, a novel and simple Dual-Generator network architecture for text Style Transfer. Our model employs two generators only, and does not rely on any discriminators or parallel corpus for training. Both quantitative and qualitative experiments on the Yelp and IMDb datasets show that our model gives competitive performance compared to several strong baselines with more complicated architecture designs.","dgst : dual - generator network text style transfer propose dgst , novel simple dual - generator network architecture text style transfer . model employ generator , rely discriminator parallel corpus training . quantitative qualitative experiment yelp imdb dataset model give competitive performance compare strong baseline complicated architecture design .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Generating Radiology Reports via Memory-driven Transformer,"Medical imaging is frequently used in clinical practice and trials for diagnosis and treatment. Writing imaging reports is time-consuming and can be error-prone for inexperienced radiologists. Therefore, automatically generating radiology reports is highly desired to lighten the workload of radiologists and accordingly promote clinical automation, which is an essential task to apply artificial intelligence to the medical domain. In this paper, we propose to generate radiology reports with memorydriven Transformer, where a relational memory is designed to record key information of the generation process and a memory-driven conditional layer normalization is applied to incorporating the memory into the decoder of Transformer. Experimental results on two prevailing radiology report datasets, IU X-Ray and MIMIC-CXR, show that our proposed approach outperforms previous models with respect to both language generation metrics and clinical evaluations. Particularly, this is the first work reporting the generation results on MIMIC-CXR to the best of our knowledge. Further analyses also demonstrate that our approach is able to generate long reports with necessary medical terms as well as meaningful image-text attention mappings. 1","Generating Radiology Reports via Memory-driven Transformer Medical imaging is frequently used in clinical practice and trials for diagnosis and treatment. Writing imaging reports is time-consuming and can be error-prone for inexperienced radiologists. Therefore, automatically generating radiology reports is highly desired to lighten the workload of radiologists and accordingly promote clinical automation, which is an essential task to apply artificial intelligence to the medical domain. In this paper, we propose to generate radiology reports with memorydriven Transformer, where a relational memory is designed to record key information of the generation process and a memory-driven conditional layer normalization is applied to incorporating the memory into the decoder of Transformer. Experimental results on two prevailing radiology report datasets, IU X-Ray and MIMIC-CXR, show that our proposed approach outperforms previous models with respect to both language generation metrics and clinical evaluations. Particularly, this is the first work reporting the generation results on MIMIC-CXR to the best of our knowledge. Further analyses also demonstrate that our approach is able to generate long reports with necessary medical terms as well as meaningful image-text attention mappings. 1","generate radiology report memory - drive transformer medical imaging frequently clinical practice trial diagnosis treatment . write imaging report time - consume error - prone inexperienced radiologist . , automatically generate radiology report highly desire lighten workload radiologist accordingly promote clinical automation , essential task apply artificial intelligence medical domain . paper , propose generate radiology report memorydriven transformer , relational memory design record key information generation process memory - drive conditional layer normalization apply incorporate memory decoder transformer . experimental result prevail radiology report dataset , iu x - ray mimic - cxr , propose approach outperform previous model respect language generation metric clinical evaluation . particularly , work report generation result mimic - cxr good knowledge . analysis demonstrate approach able generate long report necessary medical term meaningful image - text attention mapping . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Explainable Automated Fact-Checking for Public Health Claims,"Fact-checking is the task of verifying the veracity of claims by assessing their assertions against credible evidence. The vast majority of fact-checking studies focus exclusively on political claims. Very little research explores fact-checking for other topics, specifically subject matters for which expertise is required. We present the first study of explainable fact-checking for claims which require specific expertise. For our case study we choose the setting of public health. To support this case study we construct a new dataset PUBHEALTH of 11.8K claims accompanied by journalist crafted, gold standard explanations (i.e., judgments) to support the fact-check labels for claims 1 . We explore two tasks: veracity prediction and explanation generation. We also define and evaluate, with humans and computationally, three coherence properties of explanation quality. Our results indicate that, by training on in-domain data, gains can be made in explainable, automated fact-checking for claims which require specific expertise.","Explainable Automated Fact-Checking for Public Health Claims Fact-checking is the task of verifying the veracity of claims by assessing their assertions against credible evidence. The vast majority of fact-checking studies focus exclusively on political claims. Very little research explores fact-checking for other topics, specifically subject matters for which expertise is required. We present the first study of explainable fact-checking for claims which require specific expertise. For our case study we choose the setting of public health. To support this case study we construct a new dataset PUBHEALTH of 11.8K claims accompanied by journalist crafted, gold standard explanations (i.e., judgments) to support the fact-check labels for claims 1 . We explore two tasks: veracity prediction and explanation generation. We also define and evaluate, with humans and computationally, three coherence properties of explanation quality. Our results indicate that, by training on in-domain data, gains can be made in explainable, automated fact-checking for claims which require specific expertise.","explainable automate fact - checking public health claim fact - checking task verify veracity claim assess assertion credible evidence . vast majority fact - checking study focus exclusively political claim . little research explore fact - checking topic , specifically subject matter expertise require . present study explainable fact - checking claim require specific expertise . case study choose setting public health . support case study construct new dataset pubhealth 11.8 k claim accompany journalist craft , gold standard explanation ( i.e. , judgment ) support fact - check label claim 1 . explore task : veracity prediction explanation generation . define evaluate , human computationally , coherence property explanation quality . result indicate , train - domain datum , gain explainable , automate fact - checking claim require specific expertise .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
NLP Applications,Multi-resolution Annotations for Emoji Prediction,"Emojis are able to express various linguistic components, including emotions, sentiments, events, etc. Predicting the proper emojis associated with text provides a way to summarize the text accurately, and it has been proven to be a good auxiliary task to many Natural Language Understanding (NLU) tasks. Labels in existing emoji prediction datasets are all passage-based and are usually under the multi-class classification setting. However, in many cases, one single emoji cannot fully cover the theme of a piece of text. It is thus useful to infer the part of text related to each emoji. The lack of multi-label and aspectlevel emoji prediction datasets is one of the bottlenecks for this task. This paper annotates an emoji prediction dataset with passage-level multi-class/multi-label, and aspect-level multiclass annotations. We also present a novel annotation method with which we generate the aspect-level annotations. The annotations are generated heuristically, taking advantage of the self-attention mechanism in Transformer networks. We validate the annotations both automatically and manually to ensure their quality. We also benchmark the dataset with a pretrained BERT model.","Multi-resolution Annotations for Emoji Prediction Emojis are able to express various linguistic components, including emotions, sentiments, events, etc. Predicting the proper emojis associated with text provides a way to summarize the text accurately, and it has been proven to be a good auxiliary task to many Natural Language Understanding (NLU) tasks. Labels in existing emoji prediction datasets are all passage-based and are usually under the multi-class classification setting. However, in many cases, one single emoji cannot fully cover the theme of a piece of text. It is thus useful to infer the part of text related to each emoji. The lack of multi-label and aspectlevel emoji prediction datasets is one of the bottlenecks for this task. This paper annotates an emoji prediction dataset with passage-level multi-class/multi-label, and aspect-level multiclass annotations. We also present a novel annotation method with which we generate the aspect-level annotations. The annotations are generated heuristically, taking advantage of the self-attention mechanism in Transformer networks. We validate the annotations both automatically and manually to ensure their quality. We also benchmark the dataset with a pretrained BERT model.","multi - resolution annotation emoji prediction emoji able express linguistic component , include emotion , sentiment , event , etc . predict proper emoji associate text provide way summarize text accurately , prove good auxiliary task natural language understanding ( nlu ) task . label exist emoji prediction dataset passage - base usually multi - class classification setting . , case , single emoji fully cover theme piece text . useful infer text relate emoji . lack multi - label aspectlevel emoji prediction dataset bottleneck task . paper annotate emoji prediction dataset passage - level multi - class / multi - label , aspect - level multiclass annotation . present novel annotation method generate aspect - level annotation . annotation generate heuristically , take advantage self - attention mechanism transformer network . validate annotation automatically manually ensure quality . benchmark dataset pretrained bert model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Methods for Numeracy-Preserving Word Embeddings,"Word embedding models are typically able to capture the semantics of words via the distributional hypothesis, but fail to capture the numerical properties of numbers that appear in a text. This leads to problems with numerical reasoning involving tasks such as question answering. We propose a new methodology to assign and learn embeddings for numbers. Our approach creates Deterministic, Independentof-Corpus Embeddings (referred to as DICE) for numbers, such that their cosine similarity reflects the actual distance on the number line. DICE outperforms a wide range of pre-trained word embedding models across multiple examples of two tasks: (i) evaluating the ability to capture numeration and magnitude; and (ii) to perform list maximum, decoding, and addition. We further explore the utility of these embeddings in downstream applications by initializing numbers with our approach for the task of magnitude prediction. We also introduce a regularization approach to learn model-based embeddings of numbers in a contextual setting.","Methods for Numeracy-Preserving Word Embeddings Word embedding models are typically able to capture the semantics of words via the distributional hypothesis, but fail to capture the numerical properties of numbers that appear in a text. This leads to problems with numerical reasoning involving tasks such as question answering. We propose a new methodology to assign and learn embeddings for numbers. Our approach creates Deterministic, Independentof-Corpus Embeddings (referred to as DICE) for numbers, such that their cosine similarity reflects the actual distance on the number line. DICE outperforms a wide range of pre-trained word embedding models across multiple examples of two tasks: (i) evaluating the ability to capture numeration and magnitude; and (ii) to perform list maximum, decoding, and addition. We further explore the utility of these embeddings in downstream applications by initializing numbers with our approach for the task of magnitude prediction. We also introduce a regularization approach to learn model-based embeddings of numbers in a contextual setting.","method numeracy - preserve word embedding word embedding model typically able capture semantic word distributional hypothesis , fail capture numerical property number appear text . lead problem numerical reasoning involve task question answering . propose new methodology assign learn embedding number . approach create deterministic , independentof - corpus embedding ( refer dice ) number , cosine similarity reflect actual distance number line . dice outperform wide range pre - trained word embedding model multiple example task : ( ) evaluate ability capture numeration magnitude ; ( ii ) perform list maximum , decoding , addition . explore utility embedding downstream application initialize number approach task magnitude prediction . introduce regularization approach learn model - base embedding number contextual setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Recurrent Event Network: Autoregressive Structure Inferenceover Temporal Knowledge Graphs,"Knowledge graph reasoning is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-NET), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a probability distribution conditioned on temporal sequences of past knowledge graphs. Specifically, our RE-NET employs a recurrent event encoder to encode past facts, and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two modules. We evaluate our proposed method via link prediction at future times on five public datasets. Through extensive experiments, we demonstrate the strength of RE-NET, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all five datasets 1 . Recent attempts to solve the extrapolation TKG reasoning problem are Know-Evolve (Trivedi et al., 2017) and its extension DyRep (Trivedi","Recurrent Event Network: Autoregressive Structure Inferenceover Temporal Knowledge Graphs Knowledge graph reasoning is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-NET), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a probability distribution conditioned on temporal sequences of past knowledge graphs. Specifically, our RE-NET employs a recurrent event encoder to encode past facts, and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two modules. We evaluate our proposed method via link prediction at future times on five public datasets. Through extensive experiments, we demonstrate the strength of RE-NET, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all five datasets 1 . Recent attempts to solve the extrapolation TKG reasoning problem are Know-Evolve (Trivedi et al., 2017) and its extension DyRep (Trivedi","recurrent event network : autoregressive structure inferenceover temporal knowledge graph knowledge graph reasoning critical task natural language processing . task challenging temporal knowledge graph , fact associate timestamp . exist method focus reason past timestamp able predict fact happen future . paper propose recurrent event network ( - net ) , novel autoregressive architecture predict future interaction . occurrence fact ( event ) model probability distribution condition temporal sequence past knowledge graph . specifically , - net employ recurrent event encoder encode past fact , use neighborhood aggregator model connection fact timestamp . future fact infer sequential manner base module . evaluate propose method link prediction future time public dataset . extensive experiment , demonstrate strength - net , especially multi - step inference future timestamp , achieve state - - - art performance dataset 1 . recent attempt solve extrapolation tkg reasoning problem know - evolve ( trivedi et al . , 2017 ) extension dyrep ( trivedi","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 12, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
NLP Applications,Form2Seq : A Framework for Higher-Order Form Structure Extraction,"Document structure extraction has been a widely researched area for decades with recent works performing it as a semantic segmentation task over document images using fullyconvolution networks. Such methods are limited by image resolution due to which they fail to disambiguate structures in dense regions which appear commonly in forms. To mitigate this, we propose Form2Seq, a novel sequenceto-sequence (Seq2Seq) inspired framework for structure extraction using text, with a specific focus on forms, which leverages relative spatial arrangement of structures. We discuss two tasks; 1) Classification of low-level constituent elements (TextBlock and empty fillable Widget) into ten types such as field captions, list items, and others; 2) Grouping lower-level elements into higher-order constructs, such as Text Fields, ChoiceFields and ChoiceGroups, used as information collection mechanism in forms. To achieve this, we arrange the constituent elements linearly in natural reading order, feed their spatial and textual representations to Seq2Seq framework, which sequentially outputs prediction of each element depending on the final task. We modify Seq2Seq for grouping task and discuss improvements obtained through cascaded end-to-end training of two tasks versus training in isolation. Experimental results show the effectiveness of our text-based approach achieving an accuracy of 90% on classification task and an F1 of 75.82, 86.01, 61.63 on groups discussed above respectively, outperforming segmentation baselines. Further we show our framework achieves state of the results for table structure recognition on ICDAR 2013 dataset.","Form2Seq : A Framework for Higher-Order Form Structure Extraction Document structure extraction has been a widely researched area for decades with recent works performing it as a semantic segmentation task over document images using fullyconvolution networks. Such methods are limited by image resolution due to which they fail to disambiguate structures in dense regions which appear commonly in forms. To mitigate this, we propose Form2Seq, a novel sequenceto-sequence (Seq2Seq) inspired framework for structure extraction using text, with a specific focus on forms, which leverages relative spatial arrangement of structures. We discuss two tasks; 1) Classification of low-level constituent elements (TextBlock and empty fillable Widget) into ten types such as field captions, list items, and others; 2) Grouping lower-level elements into higher-order constructs, such as Text Fields, ChoiceFields and ChoiceGroups, used as information collection mechanism in forms. To achieve this, we arrange the constituent elements linearly in natural reading order, feed their spatial and textual representations to Seq2Seq framework, which sequentially outputs prediction of each element depending on the final task. We modify Seq2Seq for grouping task and discuss improvements obtained through cascaded end-to-end training of two tasks versus training in isolation. Experimental results show the effectiveness of our text-based approach achieving an accuracy of 90% on classification task and an F1 of 75.82, 86.01, 61.63 on groups discussed above respectively, outperforming segmentation baselines. Further we show our framework achieves state of the results for table structure recognition on ICDAR 2013 dataset.","form2seq : framework high - order form structure extraction document structure extraction widely research area decade recent work perform semantic segmentation task document image fullyconvolution network . method limit image resolution fail disambiguate structure dense region appear commonly form . mitigate , propose form2seq , novel sequenceto - sequence ( seq2seq ) inspire framework structure extraction text , specific focus form , leverage relative spatial arrangement structure . discuss task ; 1 ) classification low - level constituent element ( textblock fillable widget ) type field caption , list item , ; 2 ) group low - level element high - order construct , text fields , choicefields choicegroups , information collection mechanism form . achieve , arrange constituent element linearly natural reading order , feed spatial textual representation seq2seq framework , sequentially output prediction element depend final task . modify seq2seq grouping task discuss improvement obtain cascade end - - end training task versus train isolation . experimental result effectiveness text - base approach achieve accuracy 90 % classification task f1 75.82 , 86.01 , 61.63 group discuss respectively , outperform segmentation baseline . framework achieve state result table structure recognition icdar 2013 dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
NLP Applications,NwQM: A neural quality assessment framework for Wikipedia,"Millions of people irrespective of socioeconomic and demographic backgrounds, depend on Wikipedia articles everyday for keeping themselves informed regarding popular as well as obscure topics. Articles have been categorized by editors into several quality classes, which indicate their reliability as encyclopedic content. This manual designation is an onerous task because it necessitates profound knowledge about encyclopedic language, as well navigating circuitous set of wiki guidelines. In this paper we propose Neural wikipedia Quality Monitor (NwQM), a novel deep learning model which accumulates signals from several key information sources such as article text, meta data and images to obtain improved Wikipedia article representation. We present comparison of our approach against a plethora of available solutions and show 8% improvement over state-of-the-art approaches with detailed ablation studies.","NwQM: A neural quality assessment framework for Wikipedia Millions of people irrespective of socioeconomic and demographic backgrounds, depend on Wikipedia articles everyday for keeping themselves informed regarding popular as well as obscure topics. Articles have been categorized by editors into several quality classes, which indicate their reliability as encyclopedic content. This manual designation is an onerous task because it necessitates profound knowledge about encyclopedic language, as well navigating circuitous set of wiki guidelines. In this paper we propose Neural wikipedia Quality Monitor (NwQM), a novel deep learning model which accumulates signals from several key information sources such as article text, meta data and images to obtain improved Wikipedia article representation. We present comparison of our approach against a plethora of available solutions and show 8% improvement over state-of-the-art approaches with detailed ablation studies.","nwqm : neural quality assessment framework wikipedia million people irrespective socioeconomic demographic background , depend wikipedia article everyday keep informed popular obscure topic . article categorize editor quality class , indicate reliability encyclopedic content . manual designation onerous task necessitate profound knowledge encyclopedic language , navigate circuitous set wiki guideline . paper propose neural wikipedia quality monitor ( nwqm ) , novel deep learning model accumulate signal key information source article text , meta datum image obtain improved wikipedia article representation . present comparison approach plethora available solution 8 % improvement state - - - art approach detailed ablation study .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,MultiCQA: Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale,"We study the zero-shot transfer capabilities of text matching models on a massive scale, by self-supervised training on 140 source domains from community question answering forums in English. We investigate the model performances on nine benchmarks of answer selection and question similarity tasks, and show that all 140 models transfer surprisingly well, where the large majority of models substantially outperforms common IR baselines. We also demonstrate that considering a broad selection of source domains is crucial for obtaining the best zero-shot transfer performances, which contrasts the standard procedure that merely relies on the largest and most similar domains. In addition, we extensively study how to best combine multiple source domains. We propose to incorporate self-supervised with supervised multi-task learning on all available source domains. Our best zero-shot transfer model considerably outperforms in-domain BERT and the previous state of the art on six benchmarks. Fine-tuning of our model with in-domain data results in additional large gains and achieves the new state of the art on all nine benchmarks.","MultiCQA: Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale We study the zero-shot transfer capabilities of text matching models on a massive scale, by self-supervised training on 140 source domains from community question answering forums in English. We investigate the model performances on nine benchmarks of answer selection and question similarity tasks, and show that all 140 models transfer surprisingly well, where the large majority of models substantially outperforms common IR baselines. We also demonstrate that considering a broad selection of source domains is crucial for obtaining the best zero-shot transfer performances, which contrasts the standard procedure that merely relies on the largest and most similar domains. In addition, we extensively study how to best combine multiple source domains. We propose to incorporate self-supervised with supervised multi-task learning on all available source domains. Our best zero-shot transfer model considerably outperforms in-domain BERT and the previous state of the art on six benchmarks. Fine-tuning of our model with in-domain data results in additional large gains and achieves the new state of the art on all nine benchmarks.","multicqa : zero - shot transfer self - supervise text matching model massive scale study zero - shot transfer capability text matching model massive scale , self - supervise training 140 source domain community question answer forum english . investigate model performance benchmark answer selection question similarity task , 140 model transfer surprisingly , large majority model substantially outperform common ir baseline . demonstrate consider broad selection source domain crucial obtain good zero - shot transfer performance , contrast standard procedure merely rely large similar domain . addition , extensively study well combine multiple source domain . propose incorporate self - supervise supervised multi - task learning available source domain . good zero - shot transfer model considerably outperform - domain bert previous state art benchmark . fine - tuning model - domain datum result additional large gain achieve new state art benchmark .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 6, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
NLP Applications,Planning and Generating Natural and Diverse Disfluent Texts as Augmentation for Disfluency Detection,"Existing approaches to disfluency detection heavily depend on human-annotated data. Numbers of data augmentation methods have been proposed to alleviate the dependence on labeled data. However, current augmentation approaches such as random insertion or repetition fail to resemble training corpus well and usually resulted in unnatural and limited types of disfluencies. In this work, we propose a simple Planner-Generator based disfluency generation model to generate natural and diverse disfluent texts as augmented data, where the Planner decides on where to insert disfluent segments and the Generator follows the prediction to generate corresponding disfluent segments. We further utilize this augmented data for pretraining and leverage it for the task of disfluency detection. Experiments demonstrated that our two-stage disfluency generation model outperforms existing baselines; those disfluent sentences generated significantly aided the task of disfluency detection and led to state-of-the-art performance on Switchboard corpus. We have publicly released our code at https://github.com/GT-SALT/ Disfluency-Generation-and-Detection.","Planning and Generating Natural and Diverse Disfluent Texts as Augmentation for Disfluency Detection Existing approaches to disfluency detection heavily depend on human-annotated data. Numbers of data augmentation methods have been proposed to alleviate the dependence on labeled data. However, current augmentation approaches such as random insertion or repetition fail to resemble training corpus well and usually resulted in unnatural and limited types of disfluencies. In this work, we propose a simple Planner-Generator based disfluency generation model to generate natural and diverse disfluent texts as augmented data, where the Planner decides on where to insert disfluent segments and the Generator follows the prediction to generate corresponding disfluent segments. We further utilize this augmented data for pretraining and leverage it for the task of disfluency detection. Experiments demonstrated that our two-stage disfluency generation model outperforms existing baselines; those disfluent sentences generated significantly aided the task of disfluency detection and led to state-of-the-art performance on Switchboard corpus. We have publicly released our code at https://github.com/GT-SALT/ Disfluency-Generation-and-Detection.","plan generate natural diverse disfluent text augmentation disfluency detection exist approach disfluency detection heavily depend human - annotated datum . number data augmentation method propose alleviate dependence label datum . , current augmentation approach random insertion repetition fail resemble train corpus usually result unnatural limited type disfluency . work , propose simple planner - generator base disfluency generation model generate natural diverse disfluent text augment datum , planner decide insert disfluent segment generator follow prediction generate corresponding disfluent segment . utilize augment data pretraining leverage task disfluency detection . experiment demonstrate - stage disfluency generation model outperform exist baseline ; disfluent sentence generate significantly aid task disfluency detection lead state - - - art performance switchboard corpus . publicly release code https://github.com/gt-salt/ disfluency - generation - - detection .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 17, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,An Element-aware Multi-representation Model for Law Article Prediction,"Existing works have proved that using law articles as external knowledge can improve the performance of the Legal Judgment Prediction. However, they do not fully use law article information and most of the current work is only for single label samples. In this paper, we propose a Law Article Element-aware Multi-representation Model (LEMM), which can make full use of law article information and can be used for multi-label samples. The model uses the labeled elements of law articles to extract fact description features from multiple angles. It generates multiple representations of a fact for classification. Every label has a law-aware fact representation to encode more information. To capture the dependencies between law articles, the model also introduces a self-attention mechanism between multiple representations. Compared with baseline models like TopJudge, this model improves the accuracy of 5.84%, the macro F1 of 6.42%, and the micro F1 of 4.28%.","An Element-aware Multi-representation Model for Law Article Prediction Existing works have proved that using law articles as external knowledge can improve the performance of the Legal Judgment Prediction. However, they do not fully use law article information and most of the current work is only for single label samples. In this paper, we propose a Law Article Element-aware Multi-representation Model (LEMM), which can make full use of law article information and can be used for multi-label samples. The model uses the labeled elements of law articles to extract fact description features from multiple angles. It generates multiple representations of a fact for classification. Every label has a law-aware fact representation to encode more information. To capture the dependencies between law articles, the model also introduces a self-attention mechanism between multiple representations. Compared with baseline models like TopJudge, this model improves the accuracy of 5.84%, the macro F1 of 6.42%, and the micro F1 of 4.28%.","element - aware multi - representation model law article prediction exist work prove law article external knowledge improve performance legal judgment prediction . , fully use law article information current work single label sample . paper , propose law article element - aware multi - representation model ( lemm ) , use law article information multi - label sample . model use label element law article extract fact description feature multiple angle . generate multiple representation fact classification . label law - aware fact representation encode information . capture dependency law article , model introduce self - attention mechanism multiple representation . compare baseline model like topjudge , model improve accuracy 5.84 % , macro f1 6.42 % , micro f1 4.28 % .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Authorship Attribution for Neural Text Generation,"In recent years, the task of generating realistic short and long texts have made tremendous advancements. In particular, several recently proposed neural network-based language models have demonstrated their astonishing capabilities to generate texts that are challenging to distinguish from human-written texts with the naked eye. Despite many benefits and utilities of such neural methods, in some applications, being able to tell the ""author"" of a text in question becomes critically important. In this work, in the context of this Turing Test, we investigate the so-called authorship attribution problem in three versions: (1) given two texts T 1 and T 2 , are both generated by the same method or not? (2) is the given text T written by a human or machine? (3) given a text T and k candidate neural methods, can we single out the method (among k alternatives) that generated T ? Against one humanwritten and eight machine-generated texts (i.e., CTRL, GPT, GPT2, GROVER, XLM, XL-NET, PPLM, FAIR), we empirically experiment with the performance of various models in three problems. By and large, we find that most generators still generate texts significantly different from human-written ones, thereby making three problems easier to solve. However, the qualities of texts generated by GPT2, GROVER, and FAIR are better, often confusing machine classifiers in solving three problems.","Authorship Attribution for Neural Text Generation In recent years, the task of generating realistic short and long texts have made tremendous advancements. In particular, several recently proposed neural network-based language models have demonstrated their astonishing capabilities to generate texts that are challenging to distinguish from human-written texts with the naked eye. Despite many benefits and utilities of such neural methods, in some applications, being able to tell the ""author"" of a text in question becomes critically important. In this work, in the context of this Turing Test, we investigate the so-called authorship attribution problem in three versions: (1) given two texts T 1 and T 2 , are both generated by the same method or not? (2) is the given text T written by a human or machine? (3) given a text T and k candidate neural methods, can we single out the method (among k alternatives) that generated T ? Against one humanwritten and eight machine-generated texts (i.e., CTRL, GPT, GPT2, GROVER, XLM, XL-NET, PPLM, FAIR), we empirically experiment with the performance of various models in three problems. By and large, we find that most generators still generate texts significantly different from human-written ones, thereby making three problems easier to solve. However, the qualities of texts generated by GPT2, GROVER, and FAIR are better, often confusing machine classifiers in solving three problems.","authorship attribution neural text generation recent year , task generate realistic short long text tremendous advancement . particular , recently propose neural network - base language model demonstrate astonishing capability generate text challenging distinguish human - write text naked eye . despite benefit utility neural method , application , able tell "" author "" text question critically important . work , context turing test , investigate - call authorship attribution problem version : ( 1 ) give text t 1 t 2 , generate method ? ( 2 ) give text t write human machine ? ( 3 ) give text t k candidate neural method , single method ( k alternative ) generate t ? humanwritten machine - generate text ( i.e. , ctrl , gpt , gpt2 , grover , xlm , xl - net , pplm , fair ) , empirically experiment performance model problem . large , find generator generate text significantly different human - write one , make problem easy solve . , quality text generate gpt2 , grover , fair well , confuse machine classifier solve problem .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 21, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Selection and Generation: Learning towards Multi-Product Advertisement Post Generation,"As the E-commerce thrives, high-quality online advertising copywriting has attracted more and more attention. Different from the advertising copywriting for a single product, an advertisement (AD) post includes an attractive topic that meets the customer needs and description copywriting about several products under its topic. A good AD post can highlight the characteristics of each product, thus helps customers make a good choice among candidate products. Hence, multi-product AD post generation is meaningful and important. We propose a novel end-to-end model named S-MG Net to generate the AD post. Targeted at such a challenging real-world problem, we split the AD post generation task into two subprocesses: (1) select a set of products via the SelectNet (Selection Network). ( 2 ) generate a post including selected products via the MGenNet (Multi-Generator Network). Concretely, SelectNet first captures the post topic and the relationship among the products to output the representative products. Then, MGen-Net generates the description copywriting of each product. Experiments conducted on a large-scale real-world AD post dataset demonstrate that our proposed model achieves impressive performance in terms of both automatic metrics as well as human evaluations.","Selection and Generation: Learning towards Multi-Product Advertisement Post Generation As the E-commerce thrives, high-quality online advertising copywriting has attracted more and more attention. Different from the advertising copywriting for a single product, an advertisement (AD) post includes an attractive topic that meets the customer needs and description copywriting about several products under its topic. A good AD post can highlight the characteristics of each product, thus helps customers make a good choice among candidate products. Hence, multi-product AD post generation is meaningful and important. We propose a novel end-to-end model named S-MG Net to generate the AD post. Targeted at such a challenging real-world problem, we split the AD post generation task into two subprocesses: (1) select a set of products via the SelectNet (Selection Network). ( 2 ) generate a post including selected products via the MGenNet (Multi-Generator Network). Concretely, SelectNet first captures the post topic and the relationship among the products to output the representative products. Then, MGen-Net generates the description copywriting of each product. Experiments conducted on a large-scale real-world AD post dataset demonstrate that our proposed model achieves impressive performance in terms of both automatic metrics as well as human evaluations.","selection generation : learn multi - product advertisement post generation e - commerce thrive , high - quality online advertising copywriting attract attention . different advertising copywriting single product , advertisement ( ad ) post include attractive topic meet customer need description copywriting product topic . good ad post highlight characteristic product , help customer good choice candidate product . , multi - product ad post generation meaningful important . propose novel end - - end model name s - mg net generate ad post . target challenging real - world problem , split ad post generation task subprocesse : ( 1 ) select set product selectnet ( selection network ) . ( 2 ) generate post include select product mgennet ( multi - generator network ) . concretely , selectnet capture post topic relationship product output representative product . , mgen - net generate description copywriting product . experiment conduct large - scale real - world ad post dataset demonstrate propose model achieve impressive performance term automatic metric human evaluation .","{'Computational Social Science and Social Media': 9, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 10, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Neural Topic Modeling by Incorporating Document Relationship Graph,"Graph Neural Networks (GNNs) that capture the relationships between graph nodes via message passing have been a hot research direction in the natural language processing community. In this paper, we propose Graph Topic Model (GTM), a GNN based neural topic model that represents a corpus as a document relationship graph. Documents and words in the corpus become nodes in the graph and are connected based on document-word cooccurrences. By introducing the graph structure, the relationships between documents are established through their shared words and thus the topical representation of a document is enriched by aggregating information from its neighboring nodes using graph convolution. Extensive experiments on three datasets were conducted and the results demonstrate the effectiveness of the proposed approach.","Neural Topic Modeling by Incorporating Document Relationship Graph Graph Neural Networks (GNNs) that capture the relationships between graph nodes via message passing have been a hot research direction in the natural language processing community. In this paper, we propose Graph Topic Model (GTM), a GNN based neural topic model that represents a corpus as a document relationship graph. Documents and words in the corpus become nodes in the graph and are connected based on document-word cooccurrences. By introducing the graph structure, the relationships between documents are established through their shared words and thus the topical representation of a document is enriched by aggregating information from its neighboring nodes using graph convolution. Extensive experiments on three datasets were conducted and the results demonstrate the effectiveness of the proposed approach.","neural topic modeling incorporate document relationship graph graph neural network ( gnns ) capture relationship graph node message passing hot research direction natural language processing community . paper , propose graph topic model ( gtm ) , gnn base neural topic model represent corpus document relationship graph . document word corpus node graph connect base document - word cooccurrence . introduce graph structure , relationship document establish share word topical representation document enrich aggregate information neighbor node graph convolution . extensive experiment dataset conduct result demonstrate effectiveness propose approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 13, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 6, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
NLP Applications,An Empirical Investigation of Contextualized Number Prediction,"We conduct a large scale empirical investigation of contextualized number prediction in running text. Specifically, we consider two tasks: (1) masked number prediction -predicting a missing numerical value within a sentence, and (2) numerical anomaly detectiondetecting an errorful numeric value within a sentence. We experiment with novel combinations of contextual encoders and output distributions over the real number line. Specifically, we introduce a suite of output distribution parameterizations that incorporate latent variables to add expressivity and better fit the natural distribution of numeric values in running text, and combine them with both recurrent and transformer-based encoder architectures. We evaluate these models on two numeric datasets in the financial and scientific domain. Our findings show that output distributions that incorporate discrete latent variables and allow for multiple modes outperform simple flow-based counterparts on all datasets, yielding more accurate numerical prediction and anomaly detection. We also show that our models effectively utilize textual context and benefit from general-purpose unsupervised pretraining. 1","An Empirical Investigation of Contextualized Number Prediction We conduct a large scale empirical investigation of contextualized number prediction in running text. Specifically, we consider two tasks: (1) masked number prediction -predicting a missing numerical value within a sentence, and (2) numerical anomaly detectiondetecting an errorful numeric value within a sentence. We experiment with novel combinations of contextual encoders and output distributions over the real number line. Specifically, we introduce a suite of output distribution parameterizations that incorporate latent variables to add expressivity and better fit the natural distribution of numeric values in running text, and combine them with both recurrent and transformer-based encoder architectures. We evaluate these models on two numeric datasets in the financial and scientific domain. Our findings show that output distributions that incorporate discrete latent variables and allow for multiple modes outperform simple flow-based counterparts on all datasets, yielding more accurate numerical prediction and anomaly detection. We also show that our models effectively utilize textual context and benefit from general-purpose unsupervised pretraining. 1","empirical investigation contextualized number prediction conduct large scale empirical investigation contextualize number prediction run text . specifically , consider task : ( 1 ) mask number prediction -predicte missing numerical value sentence , ( 2 ) numerical anomaly detectiondetecte errorful numeric value sentence . experiment novel combination contextual encoder output distribution real number line . specifically , introduce suite output distribution parameterization incorporate latent variable add expressivity well fit natural distribution numeric value run text , combine recurrent transformer - base encoder architecture . evaluate model numeric dataset financial scientific domain . finding output distribution incorporate discrete latent variable allow multiple mode outperform simple flow - base counterpart dataset , yield accurate numerical prediction anomaly detection . model effectively utilize textual context benefit general - purpose unsupervised pretraining . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Predicting Clinical Trial Results by Implicit Evidence Integration,"Clinical trials provide essential guidance for practicing Evidence-Based Medicine, though often accompanying with unendurable costs and risks. To optimize the design of clinical trials, we introduce a novel Clinical Trial Result Prediction (CTRP) task. In the CTRP framework, a model takes a PICO-formatted clinical trial proposal with its background as input and predicts the result, i.e. how the Intervention group compares with the Comparison group in terms of the measured Outcome in the studied Population. While structured clinical evidence is prohibitively expensive for manual collection, we exploit large-scale unstructured sentences from medical literature that implicitly contain PICOs and results as evidence. Specifically, we pre-train a model to predict the disentangled results from such implicit evidence and fine-tune the model with limited data on the downstream datasets. Experiments on the benchmark Evidence Integration dataset show that the proposed model outperforms the baselines by large margins, e.g., with a 10.7% relative gain over BioBERT in macro-F1. Moreover, the performance improvement is also validated on another dataset composed of clinical trials related to COVID-19.","Predicting Clinical Trial Results by Implicit Evidence Integration Clinical trials provide essential guidance for practicing Evidence-Based Medicine, though often accompanying with unendurable costs and risks. To optimize the design of clinical trials, we introduce a novel Clinical Trial Result Prediction (CTRP) task. In the CTRP framework, a model takes a PICO-formatted clinical trial proposal with its background as input and predicts the result, i.e. how the Intervention group compares with the Comparison group in terms of the measured Outcome in the studied Population. While structured clinical evidence is prohibitively expensive for manual collection, we exploit large-scale unstructured sentences from medical literature that implicitly contain PICOs and results as evidence. Specifically, we pre-train a model to predict the disentangled results from such implicit evidence and fine-tune the model with limited data on the downstream datasets. Experiments on the benchmark Evidence Integration dataset show that the proposed model outperforms the baselines by large margins, e.g., with a 10.7% relative gain over BioBERT in macro-F1. Moreover, the performance improvement is also validated on another dataset composed of clinical trials related to COVID-19.","predict clinical trial result implicit evidence integration clinical trial provide essential guidance practice evidence - base medicine , accompany unendurable cost risk . optimize design clinical trial , introduce novel clinical trial result prediction ( ctrp ) task . ctrp framework , model take pico - format clinical trial proposal background input predict result , i.e. intervention group compare comparison group term measure outcome study population . structured clinical evidence prohibitively expensive manual collection , exploit large - scale unstructured sentence medical literature implicitly contain pico result evidence . specifically , pre - train model predict disentangled result implicit evidence fine - tune model limited datum downstream dataset . experiment benchmark evidence integration dataset propose model outperform baseline large margin , e.g. , 10.7 % relative gain biobert macro - f1 . , performance improvement validate dataset compose clinical trial relate covid-19 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 7, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
NLP Applications,Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text,"Machine reading comprehension (MRC) has achieved significant progress on the open domain in recent years, mainly due to large-scale pre-trained language models. However, it performs much worse in specific domains such as the medical field due to the lack of extensive training data and professional structural knowledge neglect. As an effort, we first collect a large scale medical multi-choice question dataset (more than 21k instances) for the National Licensed Pharmacist Examination in China. It is a challenging medical examination with a passing rate of less than 14.2% in 2018. Then we propose a novel reading comprehension model KMQA, which can fully exploit the structural medical knowledge (i.e., medical knowledge graph) and the reference medical plain text (i.e., text snippets retrieved from reference books). The experimental results indicate that the KMQA outperforms existing competitive models with a large margin and passes the exam with 61.8% accuracy rate on the test set.","Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text Machine reading comprehension (MRC) has achieved significant progress on the open domain in recent years, mainly due to large-scale pre-trained language models. However, it performs much worse in specific domains such as the medical field due to the lack of extensive training data and professional structural knowledge neglect. As an effort, we first collect a large scale medical multi-choice question dataset (more than 21k instances) for the National Licensed Pharmacist Examination in China. It is a challenging medical examination with a passing rate of less than 14.2% in 2018. Then we propose a novel reading comprehension model KMQA, which can fully exploit the structural medical knowledge (i.e., medical knowledge graph) and the reference medical plain text (i.e., text snippets retrieved from reference books). The experimental results indicate that the KMQA outperforms existing competitive models with a large margin and passes the exam with 61.8% accuracy rate on the test set.","medical machine reading comprehension structural knowledge plain text machine reading comprehension ( mrc ) achieve significant progress open domain recent year , mainly large - scale pre - trained language model . , perform worse specific domain medical field lack extensive training datum professional structural knowledge neglect . effort , collect large scale medical multi - choice question dataset ( 21k instance ) national licensed pharmacist examination china . challenging medical examination passing rate 14.2 % 2018 . propose novel reading comprehension model kmqa , fully exploit structural medical knowledge ( i.e. , medical knowledge graph ) reference medical plain text ( i.e. , text snippet retrieve reference book ) . experimental result indicate kmqa outperform exist competitive model large margin pass exam 61.8 % accuracy rate test set .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 14, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
NLP Applications,HSCNN: A Hybrid-Siamese Convolutional Neural Network for Extremely Imbalanced Multi-label Text Classification,"The data imbalance problem is a crucial issue for the multi-label text classification. Some existing works tackle it by proposing imbalanced loss objectives instead of the vanilla cross-entropy loss, but their performances remain limited in the cases of extremely imbalanced data. We propose a hybrid solution which adapts general networks for the head categories, and few-shot techniques for the tail categories. We propose a Hybrid-Siamese Convolutional Neural Network (HSCNN) with additional technical attributes, i.e., a multi-task architecture based on Single and Siamese networks; a category-specific similarity in the Siamese structure; a specific sampling method for training HSCNN. The results using two benchmark datasets and three loss objectives show that our method can improve the performance of Single networks with diverse loss objectives on the tail or entire categories.","HSCNN: A Hybrid-Siamese Convolutional Neural Network for Extremely Imbalanced Multi-label Text Classification The data imbalance problem is a crucial issue for the multi-label text classification. Some existing works tackle it by proposing imbalanced loss objectives instead of the vanilla cross-entropy loss, but their performances remain limited in the cases of extremely imbalanced data. We propose a hybrid solution which adapts general networks for the head categories, and few-shot techniques for the tail categories. We propose a Hybrid-Siamese Convolutional Neural Network (HSCNN) with additional technical attributes, i.e., a multi-task architecture based on Single and Siamese networks; a category-specific similarity in the Siamese structure; a specific sampling method for training HSCNN. The results using two benchmark datasets and three loss objectives show that our method can improve the performance of Single networks with diverse loss objectives on the tail or entire categories.","hscnn : hybrid - siamese convolutional neural network extremely imbalanced multi - label text classification datum imbalance problem crucial issue multi - label text classification . exist work tackle propose imbalanced loss objective instead vanilla cross - entropy loss , performance remain limited case extremely imbalanced datum . propose hybrid solution adapt general network head category , - shot technique tail category . propose hybrid - siamese convolutional neural network ( hscnn ) additional technical attribute , i.e. , multi - task architecture base single siamese network ; category - specific similarity siamese structure ; specific sampling method train hscnn . result benchmark dataset loss objective method improve performance single network diverse loss objective tail entire category .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
NLP Applications,A Knowledge-Aware Sequence-to-Tree Network for Math Word Problem Solving,"With the advancements in natural language processing tasks, math word problem solving has received increasing attention. Previous methods have achieved promising results but ignore background common-sense knowledge not directly provided by the problem. In addition, during generation, they focus on local features while neglecting global information. To incorporate external knowledge and global expression information, we propose a novel knowledge-aware sequence-to-tree (KA-S2T) network in which the entities in the problem sequences and their categories are modeled as an entity graph. Based on this entity graph, a graph attention network is used to capture knowledge-aware problem representations. Further, we use a tree-structured decoder with a state aggregation mechanism to capture the long-distance dependency and global expression information. Experimental results on the Math23K dataset revealed that the KA-S2T model can achieve better performance than previously reported best results.","A Knowledge-Aware Sequence-to-Tree Network for Math Word Problem Solving With the advancements in natural language processing tasks, math word problem solving has received increasing attention. Previous methods have achieved promising results but ignore background common-sense knowledge not directly provided by the problem. In addition, during generation, they focus on local features while neglecting global information. To incorporate external knowledge and global expression information, we propose a novel knowledge-aware sequence-to-tree (KA-S2T) network in which the entities in the problem sequences and their categories are modeled as an entity graph. Based on this entity graph, a graph attention network is used to capture knowledge-aware problem representations. Further, we use a tree-structured decoder with a state aggregation mechanism to capture the long-distance dependency and global expression information. Experimental results on the Math23K dataset revealed that the KA-S2T model can achieve better performance than previously reported best results.","knowledge - aware sequence - - tree network math word problem solving advancement natural language processing task , math word problem solving receive increase attention . previous method achieve promising result ignore background common - sense knowledge directly provide problem . addition , generation , focus local feature neglect global information . incorporate external knowledge global expression information , propose novel knowledge - aware sequence - - tree ( ka - s2 t ) network entity problem sequence category model entity graph . base entity graph , graph attention network capture knowledge - aware problem representation . , use tree - structured decoder state aggregation mechanism capture long - distance dependency global expression information . experimental result math23 k dataset reveal ka - s2 t model achieve well performance previously report good result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Utility is in the Eye of the User: A Critique of NLP Leaderboards,"Benchmarks such as GLUE have helped drive advances in NLP by incentivizing the creation of more accurate models. While this leaderboard paradigm has been remarkably successful, a historical focus on performance-based evaluation has been at the expense of other qualities that the NLP community values in models, such as compactness, fairness, and energy efficiency. In this opinion paper, we study the divergence between what is incentivized by leaderboards and what is useful in practice through the lens of microeconomic theory. We frame both the leaderboard and NLP practitioners as consumers and the benefit they get from a model as its utility to them. With this framing, we formalize how leaderboards -in their current form -can be poor proxies for the NLP community at large. For example, a highly inefficient model would provide less utility to practitioners but not to a leaderboard, since it is a cost that only the former must bear. To allow practitioners to better estimate a model's utility to them, we advocate for more transparency on leaderboards, such as the reporting of statistics that are of practical concern (e.g., model size, energy efficiency, and inference latency).","Utility is in the Eye of the User: A Critique of NLP Leaderboards Benchmarks such as GLUE have helped drive advances in NLP by incentivizing the creation of more accurate models. While this leaderboard paradigm has been remarkably successful, a historical focus on performance-based evaluation has been at the expense of other qualities that the NLP community values in models, such as compactness, fairness, and energy efficiency. In this opinion paper, we study the divergence between what is incentivized by leaderboards and what is useful in practice through the lens of microeconomic theory. We frame both the leaderboard and NLP practitioners as consumers and the benefit they get from a model as its utility to them. With this framing, we formalize how leaderboards -in their current form -can be poor proxies for the NLP community at large. For example, a highly inefficient model would provide less utility to practitioners but not to a leaderboard, since it is a cost that only the former must bear. To allow practitioners to better estimate a model's utility to them, we advocate for more transparency on leaderboards, such as the reporting of statistics that are of practical concern (e.g., model size, energy efficiency, and inference latency).","utility eye user : critique nlp leaderboard benchmark glue help drive advance nlp incentivize creation accurate model . leaderboard paradigm remarkably successful , historical focus performance - base evaluation expense quality nlp community value model , compactness , fairness , energy efficiency . opinion paper , study divergence incentivize leaderboard useful practice lens microeconomic theory . frame leaderboard nlp practitioner consumer benefit model utility . framing , formalize leaderboard -in current form -can poor proxy nlp community large . example , highly inefficient model provide utility practitioner leaderboard , cost bear . allow practitioner well estimate model utility , advocate transparency leaderboard , reporting statistic practical concern ( e.g. , model size , energy efficiency , inference latency ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Theme,False
NLP Applications,Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space,"When trained effectively, the Variational Autoencoder (VAE) (Kingma and Welling, 2013; Bowman et al., 2016) can be both a powerful generative model and an effective representation learning framework for natural language. In this paper, we propose the first large-scale language VAE model OPTIMUS 1 . A universal latent embedding space for sentences is first pre-trained on large text corpus, and then fine-tuned for various language generation and understanding tasks. Compared with GPT-2, OPTIMUS enables guided language generation from an abstract level using the latent vectors. Compared with BERT, OPTIMUS can generalize better on low-resource language understanding tasks due to the smooth latent space structure. Extensive experimental results on a wide range of language tasks demonstrate the effectiveness of OPTIMUS. It achieves new state-of-the-art on VAE language modeling benchmarks.","Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space When trained effectively, the Variational Autoencoder (VAE) (Kingma and Welling, 2013; Bowman et al., 2016) can be both a powerful generative model and an effective representation learning framework for natural language. In this paper, we propose the first large-scale language VAE model OPTIMUS 1 . A universal latent embedding space for sentences is first pre-trained on large text corpus, and then fine-tuned for various language generation and understanding tasks. Compared with GPT-2, OPTIMUS enables guided language generation from an abstract level using the latent vectors. Compared with BERT, OPTIMUS can generalize better on low-resource language understanding tasks due to the smooth latent space structure. Extensive experimental results on a wide range of language tasks demonstrate the effectiveness of OPTIMUS. It achieves new state-of-the-art on VAE language modeling benchmarks.","optimus : organize sentence pre - trained modeling latent space train effectively , variational autoencoder ( vae ) ( kingma welling , 2013 ; bowman et al . , 2016 ) powerful generative model effective representation learning framework natural language . paper , propose large - scale language vae model optimus 1 . universal latent embedding space sentence pre - train large text corpus , fine - tune language generation understanding task . compare gpt-2 , optimus enable guide language generation abstract level latent vector . compare bert , optimus generalize well low - resource language understanding task smooth latent space structure . extensive experimental result wide range language task demonstrate effectiveness optimus . achieve new state - - - art vae language modeling benchmark .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 15, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Multi-Stage Pre-training for Automated Chinese Essay Scoring,"This paper proposes a pre-training based automated Chinese essay scoring method. The method involves three components: weakly supervised pre-training, supervised crossprompt fine-tuning and supervised targetprompt fine-tuning. An essay scorer is first pretrained on a large essay dataset covering diverse topics and with coarse ratings, i.e., good and poor, which are used as a kind of weak supervision. The pre-trained essay scorer would be further fine-tuned on previously rated essays from existing prompts, which have the same score range with the target prompt and provide extra supervision. At last, the scorer is fine-tuned on the target-prompt training data. The evaluation on four prompts shows that this method can improve a state-of-the-art neural essay scorer in terms of effectiveness and domain adaptation ability, while in-depth analysis also reveals its limitations.","Multi-Stage Pre-training for Automated Chinese Essay Scoring This paper proposes a pre-training based automated Chinese essay scoring method. The method involves three components: weakly supervised pre-training, supervised crossprompt fine-tuning and supervised targetprompt fine-tuning. An essay scorer is first pretrained on a large essay dataset covering diverse topics and with coarse ratings, i.e., good and poor, which are used as a kind of weak supervision. The pre-trained essay scorer would be further fine-tuned on previously rated essays from existing prompts, which have the same score range with the target prompt and provide extra supervision. At last, the scorer is fine-tuned on the target-prompt training data. The evaluation on four prompts shows that this method can improve a state-of-the-art neural essay scorer in terms of effectiveness and domain adaptation ability, while in-depth analysis also reveals its limitations.","multi - stage pre - training automated chinese essay scoring paper propose pre - training base automate chinese essay scoring method . method involve component : weakly supervise pre - training , supervise crossprompt fine - tuning supervise targetprompt fine - tuning . essay scorer pretraine large essay dataset cover diverse topic coarse rating , i.e. , good poor , kind weak supervision . pre - trained essay scorer fine - tune previously rate essay exist prompt , score range target prompt provide extra supervision . , scorer fine - tune target - prompt training datum . evaluation prompt show method improve state - - - art neural essay scorer term effectiveness domain adaptation ability , - depth analysis reveal limitation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Routing Enforced Generative Model for Recipe Generation,"One of the most challenging part of recipe generation is to deal with the complex restrictions among the input ingredients. Previous researches simplify the problem by treating the inputs independently and generating recipes containing as much information as possible. In this work, we propose a routing method to dive into the content selection under the internal restrictions. The routing enforced generative model (RGM) can generate appropriate recipes according to the given ingredients and user preferences. Our model yields new stateof-the-art results on the recipe generation task with significant improvements on BLEU, F1 and human evaluation.","Routing Enforced Generative Model for Recipe Generation One of the most challenging part of recipe generation is to deal with the complex restrictions among the input ingredients. Previous researches simplify the problem by treating the inputs independently and generating recipes containing as much information as possible. In this work, we propose a routing method to dive into the content selection under the internal restrictions. The routing enforced generative model (RGM) can generate appropriate recipes according to the given ingredients and user preferences. Our model yields new stateof-the-art results on the recipe generation task with significant improvements on BLEU, F1 and human evaluation.","routing enforced generative model recipe generation challenging recipe generation deal complex restriction input ingredient . previous research simplify problem treat input independently generate recipe contain information possible . work , propose routing method dive content selection internal restriction . routing enforce generative model ( rgm ) generate appropriate recipe accord give ingredient user preference . model yield new stateof - - art result recipe generation task significant improvement bleu , f1 human evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 8, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
NLP Applications,Multi-Dimensional Gender Bias Classification,"Machine learning models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a novel, general framework that decomposes gender bias in text along several pragmatic and semantic dimensions: bias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker. Using this fine-grained framework, we automatically annotate eight large scale datasets with gender information. In addition, we collect a new, crowdsourced evaluation benchmark. Distinguishing between gender bias along multiple dimensions enables us to train better and more fine-grained gender bias classifiers. We show our classifiers are valuable for a variety of applications, like controlling for gender bias in generative models, detecting gender bias in arbitrary text, and classifying text as offensive based on its genderedness.","Multi-Dimensional Gender Bias Classification Machine learning models are trained to find patterns in data. NLP models can inadvertently learn socially undesirable patterns when training on gender biased text. In this work, we propose a novel, general framework that decomposes gender bias in text along several pragmatic and semantic dimensions: bias from the gender of the person being spoken about, bias from the gender of the person being spoken to, and bias from the gender of the speaker. Using this fine-grained framework, we automatically annotate eight large scale datasets with gender information. In addition, we collect a new, crowdsourced evaluation benchmark. Distinguishing between gender bias along multiple dimensions enables us to train better and more fine-grained gender bias classifiers. We show our classifiers are valuable for a variety of applications, like controlling for gender bias in generative models, detecting gender bias in arbitrary text, and classifying text as offensive based on its genderedness.","multi - dimensional gender bias classification machine learning model train find pattern datum . nlp model inadvertently learn socially undesirable pattern train gender biased text . work , propose novel , general framework decompose gender bias text pragmatic semantic dimension : bias gender person speak , bias gender person speak , bias gender speaker . fine - grained framework , automatically annotate large scale dataset gender information . addition , collect new , crowdsource evaluation benchmark . distinguish gender bias multiple dimension enable train well fine - grained gender bias classifier . classifier valuable variety application , like control gender bias generative model , detect gender bias arbitrary text , classify text offensive base genderedness .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 30, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 12, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
NLP Applications,PathQG: Neural Question Generation from Facts,"Existing research for question generation encodes the input text as a sequence of tokens without explicitly modeling fact information. These models tend to generate irrelevant and uninformative questions. In this paper, we explore to incorporate facts in the text for question generation in a comprehensive way. We present a novel task of question generation given a query path in the knowledge graph constructed from the input text. We divide the task into two steps, namely, query representation learning and query-based question generation. We formulate query representation learning as a sequence labeling problem for identifying the involved facts to form a query and employ an RNN-based generator for question generation. We first train the two modules jointly in an end-to-end fashion, and further enforce the interaction between these two modules in a variational framework. We construct the experimental datasets on top of SQuAD and results show that our model outperforms other state-of-the-art approaches, and the performance margin is larger when target questions are complex. Human evaluation also proves that our model is able to generate relevant and informative questions. 1","PathQG: Neural Question Generation from Facts Existing research for question generation encodes the input text as a sequence of tokens without explicitly modeling fact information. These models tend to generate irrelevant and uninformative questions. In this paper, we explore to incorporate facts in the text for question generation in a comprehensive way. We present a novel task of question generation given a query path in the knowledge graph constructed from the input text. We divide the task into two steps, namely, query representation learning and query-based question generation. We formulate query representation learning as a sequence labeling problem for identifying the involved facts to form a query and employ an RNN-based generator for question generation. We first train the two modules jointly in an end-to-end fashion, and further enforce the interaction between these two modules in a variational framework. We construct the experimental datasets on top of SQuAD and results show that our model outperforms other state-of-the-art approaches, and the performance margin is larger when target questions are complex. Human evaluation also proves that our model is able to generate relevant and informative questions. 1","pathqg : neural question generation fact exist research question generation encode input text sequence token explicitly model fact information . model tend generate irrelevant uninformative question . paper , explore incorporate fact text question generation comprehensive way . present novel task question generation give query path knowledge graph construct input text . divide task step , , query representation learning query - base question generation . formulate query representation learning sequence labeling problem identify involved fact form query employ rnn - base generator question generation . train module jointly end - - end fashion , enforce interaction module variational framework . construct experimental dataset squad result model outperform state - - - art approach , performance margin large target question complex . human evaluation prove model able generate relevant informative question . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 18, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 9, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Generation,False
NLP Applications,BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover's Distance,"Pre-trained language models (e.g., BERT) have achieved significant success in various natural language processing (NLP) tasks. However, high storage and computational costs obstruct pre-trained language models to be effectively deployed on resourceconstrained devices. In this paper, we propose a novel BERT distillation method based on many-to-many layer mapping, which allows each intermediate student layer to learn from any intermediate teacher layers. In this way, our model can learn from different teacher layers adaptively for various NLP tasks. In addition, we leverage Earth Mover's Distance (EMD) to compute the minimum cumulative cost that must be paid to transform knowledge from teacher network to student network. EMD enables the effective matching for many-to-many layer mapping. Furthermore, we propose a cost attention mechanism to learn the layer weights used in EMD automatically, which is supposed to further improve the model's performance and accelerate convergence time. Extensive experiments on GLUE benchmark demonstrate that our model achieves competitive performance compared to strong competitors in terms of both accuracy and model compression. For reproducibility, we release the code and data at https: //github.com/lxk00/BERT-EMD.","BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth Mover's Distance Pre-trained language models (e.g., BERT) have achieved significant success in various natural language processing (NLP) tasks. However, high storage and computational costs obstruct pre-trained language models to be effectively deployed on resourceconstrained devices. In this paper, we propose a novel BERT distillation method based on many-to-many layer mapping, which allows each intermediate student layer to learn from any intermediate teacher layers. In this way, our model can learn from different teacher layers adaptively for various NLP tasks. In addition, we leverage Earth Mover's Distance (EMD) to compute the minimum cumulative cost that must be paid to transform knowledge from teacher network to student network. EMD enables the effective matching for many-to-many layer mapping. Furthermore, we propose a cost attention mechanism to learn the layer weights used in EMD automatically, which is supposed to further improve the model's performance and accelerate convergence time. Extensive experiments on GLUE benchmark demonstrate that our model achieves competitive performance compared to strong competitors in terms of both accuracy and model compression. For reproducibility, we release the code and data at https: //github.com/lxk00/BERT-EMD.","bert - emd : - - layer mapping bert compression earth mover distance pre - trained language model ( e.g. , bert ) achieve significant success natural language processing ( nlp ) task . , high storage computational cost obstruct pre - trained language model effectively deploy resourceconstrained device . paper , propose novel bert distillation method base - - layer mapping , allow intermediate student layer learn intermediate teacher layer . way , model learn different teacher layer adaptively nlp task . addition , leverage earth mover distance ( emd ) compute minimum cumulative cost pay transform knowledge teacher network student network . emd enable effective matching - - layer mapping . furthermore , propose cost attention mechanism learn layer weight emd automatically , suppose improve model performance accelerate convergence time . extensive experiment glue benchmark demonstrate model achieve competitive performance compare strong competitor term accuracy model compression . reproducibility , release code datum https : //github.com / lxk00 / bert - emd .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,An Empirical Study of Pre-trained Transformers for Arabic Information Extraction,"Multilingual pre-trained Transformers, such as mBERT (Devlin et al., 2019) and XLM-RoBERTa (Conneau et al., 2020a), have been shown to enable the effective cross-lingual zero-shot transfer. However, their performance on Arabic information extraction (IE) tasks is not very well studied. In this paper, we pre-train a customized bilingual BERT, dubbed GigaBERT, that is designed specifically for Arabic NLP and English-to-Arabic zero-shot transfer learning. We study Giga-BERT's effectiveness on zero-short transfer across four IE tasks: named entity recognition, part-of-speech tagging, argument role labeling, and relation extraction. Our best model significantly outperforms mBERT, XLM-RoBERTa, and AraBERT (Antoun et al., 2020)  in both the supervised and zero-shot transfer settings. We have made our pre-trained models publicly available at https://github.com/ lanwuwei/GigaBERT.","An Empirical Study of Pre-trained Transformers for Arabic Information Extraction Multilingual pre-trained Transformers, such as mBERT (Devlin et al., 2019) and XLM-RoBERTa (Conneau et al., 2020a), have been shown to enable the effective cross-lingual zero-shot transfer. However, their performance on Arabic information extraction (IE) tasks is not very well studied. In this paper, we pre-train a customized bilingual BERT, dubbed GigaBERT, that is designed specifically for Arabic NLP and English-to-Arabic zero-shot transfer learning. We study Giga-BERT's effectiveness on zero-short transfer across four IE tasks: named entity recognition, part-of-speech tagging, argument role labeling, and relation extraction. Our best model significantly outperforms mBERT, XLM-RoBERTa, and AraBERT (Antoun et al., 2020)  in both the supervised and zero-shot transfer settings. We have made our pre-trained models publicly available at https://github.com/ lanwuwei/GigaBERT.","empirical study pre - trained transformer arabic information extraction multilingual pre - trained transformer , mbert ( devlin et al . , 2019 ) xlm - roberta ( conneau et al . , 2020a ) , show enable effective cross - lingual zero - shot transfer . , performance arabic information extraction ( ie ) task study . paper , pre - train customize bilingual bert , dub gigabert , design specifically arabic nlp english - - arabic zero - shot transfer learning . study giga - bert effectiveness zero - short transfer ie task : name entity recognition , - - speech tagging , argument role labeling , relation extraction . good model significantly outperform mbert , xlm - roberta , arabert ( antoun et al . , 2020 )   supervised zero - shot transfer setting . pre - trained model publicly available https://github.com/ lanwuwei / gigabert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 2, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for Low-Latency Inference in NLP Applications,"Deep neural networks have become the standard approach to building reliable Natural Language Processing (NLP) applications, ranging from Neural Machine Translation (NMT) to dialogue systems. However, improving accuracy by increasing the model size requires a large number of hardware computations, which can slow down NLP applications significantly at inference time. To address this issue, we propose a novel vector-vector-matrix architecture (VVMA), which greatly reduces the latency at inference time for NMT. This architecture takes advantage of specialized hardware that has low-latency vector-vector operations and higher-latency vector-matrix operations. It also reduces the number of parameters and FLOPs for virtually all models that rely on efficient matrix multipliers without significantly impacting accuracy. We present empirical results suggesting that our framework can reduce the latency of sequence-to-sequence and Transformer models used for NMT by a factor of four. Finally, we show evidence suggesting that our VVMA extends to other domains, and we discuss novel hardware for its efficient use.","Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for Low-Latency Inference in NLP Applications Deep neural networks have become the standard approach to building reliable Natural Language Processing (NLP) applications, ranging from Neural Machine Translation (NMT) to dialogue systems. However, improving accuracy by increasing the model size requires a large number of hardware computations, which can slow down NLP applications significantly at inference time. To address this issue, we propose a novel vector-vector-matrix architecture (VVMA), which greatly reduces the latency at inference time for NMT. This architecture takes advantage of specialized hardware that has low-latency vector-vector operations and higher-latency vector-matrix operations. It also reduces the number of parameters and FLOPs for virtually all models that rely on efficient matrix multipliers without significantly impacting accuracy. We present empirical results suggesting that our framework can reduce the latency of sequence-to-sequence and Transformer models used for NMT by a factor of four. Finally, we show evidence suggesting that our VVMA extends to other domains, and we discuss novel hardware for its efficient use.","vector - vector - matrix architecture : novel hardware - aware framework low - latency inference nlp application deep neural network standard approach build reliable natural language processing ( nlp ) application , range neural machine translation ( nmt ) dialogue system . , improve accuracy increase model size require large number hardware computation , slow nlp application significantly inference time . address issue , propose novel vector - vector - matrix architecture ( vvma ) , greatly reduce latency inference time nmt . architecture take advantage specialized hardware low - latency vector - vector operation high - latency vector - matrix operation . reduce number parameter flop virtually model rely efficient matrix multiplier significantly impact accuracy . present empirical result suggest framework reduce latency sequence - - sequence transformer model nmt factor . finally , evidence suggest vvma extend domain , discuss novel hardware efficient use .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
NLP Applications,Explainable Clinical Decision Support from Text,"Clinical prediction models often use structured variables and provide outcomes that are not readily interpretable by clinicians. Further, free-text medical notes may contain information not immediately available in structured variables. We propose a hierarchical CNNtransformer model with explicit attention as an interpretable, multi-task clinical language model, which achieves an AUROC of 0.75 and 0.78 on sepsis and mortality prediction on the English MIMIC-III dataset, respectively. We also explore the relationships between learned features from structured and unstructured variables using projection-weighted canonical correlation analysis. Finally, we outline a protocol to evaluate model usability in a clinical decision support context. From domain-expert evaluations, our model generates informative rationales that have promising real-life applications. Related work 2.1 Transformers in the clinical domain Transformers (Vaswani et al., 2017) have gained popularity given their strong performance and parallelizability. The success of the transformer-based BERT (Devlin et al., 2019)  has inspired numerous studies to apply it in various domains. For example, BioBERT was pretrained on PubMed abstracts and articles and was able to better identify biomedical entities and boundaries than base BERT (Lee et al.,  2020","Explainable Clinical Decision Support from Text Clinical prediction models often use structured variables and provide outcomes that are not readily interpretable by clinicians. Further, free-text medical notes may contain information not immediately available in structured variables. We propose a hierarchical CNNtransformer model with explicit attention as an interpretable, multi-task clinical language model, which achieves an AUROC of 0.75 and 0.78 on sepsis and mortality prediction on the English MIMIC-III dataset, respectively. We also explore the relationships between learned features from structured and unstructured variables using projection-weighted canonical correlation analysis. Finally, we outline a protocol to evaluate model usability in a clinical decision support context. From domain-expert evaluations, our model generates informative rationales that have promising real-life applications. Related work 2.1 Transformers in the clinical domain Transformers (Vaswani et al., 2017) have gained popularity given their strong performance and parallelizability. The success of the transformer-based BERT (Devlin et al., 2019)  has inspired numerous studies to apply it in various domains. For example, BioBERT was pretrained on PubMed abstracts and articles and was able to better identify biomedical entities and boundaries than base BERT (Lee et al.,  2020","explainable clinical decision support text clinical prediction model use structured variable provide outcome readily interpretable clinician . , free - text medical note contain information immediately available structure variable . propose hierarchical cnntransformer model explicit attention interpretable , multi - task clinical language model , achieve auroc 0.75 0.78 sepsis mortality prediction english mimic - iii dataset , respectively . explore relationship learn feature structured unstructured variable projection - weight canonical correlation analysis . finally , outline protocol evaluate model usability clinical decision support context . domain - expert evaluation , model generate informative rationale promising real - life application . related work 2.1 transformer clinical domain transformers ( vaswani et al . , 2017 ) gain popularity give strong performance parallelizability . success transformer - base bert ( devlin et al . , 2019 )   inspire numerous study apply domain . example , biobert pretraine pubmed abstract article able well identify biomedical entity boundary base bert ( lee et al . ,   2020","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,An Empirical Study on Large-Scale Multi-Label Text Classification Including Few and Zero-Shot Labels,"Large-scale Multi-label Text Classification (LMTC) has a wide range of Natural Language Processing (NLP) applications and presents interesting challenges. First, not all labels are well represented in the training set, due to the very large label set and the skewed label distributions of LMTC datasets. Also, label hierarchies and differences in human labelling guidelines may affect graph-aware annotation proximity. Finally, the label hierarchies are periodically updated, requiring LMTC models capable of zero-shot generalization. Current state-of-the-art LMTC models employ Label-Wise Attention Networks (LWANs), which (1) typically treat LMTC as flat multi-label classification; (2) may use the label hierarchy to improve zero-shot learning, although this practice is vastly understudied; and (3) have not been combined with pre-trained Transformers (e.g. BERT), which have led to state-of-the-art results in several NLP benchmarks. Here, for the first time, we empirically evaluate a battery of LMTC methods from vanilla LWANs to hierarchical classification approaches and transfer learning, on frequent, few, and zero-shot learning on three datasets from different domains. We show that hierarchical methods based on Probabilistic Label Trees (PLTs) outperform LWANs. Furthermore, we show that Transformer-based approaches outperform the state-of-the-art in two of the datasets, and we propose a new state-of-the-art method which combines BERT with LWAN. Finally, we propose new models that leverage the label hierarchy to improve few and zero-shot learning, considering on each dataset a graph-aware annotation proximity measure that we introduce.","An Empirical Study on Large-Scale Multi-Label Text Classification Including Few and Zero-Shot Labels Large-scale Multi-label Text Classification (LMTC) has a wide range of Natural Language Processing (NLP) applications and presents interesting challenges. First, not all labels are well represented in the training set, due to the very large label set and the skewed label distributions of LMTC datasets. Also, label hierarchies and differences in human labelling guidelines may affect graph-aware annotation proximity. Finally, the label hierarchies are periodically updated, requiring LMTC models capable of zero-shot generalization. Current state-of-the-art LMTC models employ Label-Wise Attention Networks (LWANs), which (1) typically treat LMTC as flat multi-label classification; (2) may use the label hierarchy to improve zero-shot learning, although this practice is vastly understudied; and (3) have not been combined with pre-trained Transformers (e.g. BERT), which have led to state-of-the-art results in several NLP benchmarks. Here, for the first time, we empirically evaluate a battery of LMTC methods from vanilla LWANs to hierarchical classification approaches and transfer learning, on frequent, few, and zero-shot learning on three datasets from different domains. We show that hierarchical methods based on Probabilistic Label Trees (PLTs) outperform LWANs. Furthermore, we show that Transformer-based approaches outperform the state-of-the-art in two of the datasets, and we propose a new state-of-the-art method which combines BERT with LWAN. Finally, we propose new models that leverage the label hierarchy to improve few and zero-shot learning, considering on each dataset a graph-aware annotation proximity measure that we introduce.","empirical study large - scale multi - label text classification include zero - shot label large - scale multi - label text classification ( lmtc ) wide range natural language processing ( nlp ) application present interesting challenge . , label represent training set , large label set skewed label distribution lmtc dataset . , label hierarchy difference human labelling guideline affect graph - aware annotation proximity . finally , label hierarchy periodically update , require lmtc model capable zero - shot generalization . current state - - - art lmtc model employ label - wise attention networks ( lwans ) , ( 1 ) typically treat lmtc flat multi - label classification ; ( 2 ) use label hierarchy improve zero - shot learning , practice vastly understudy ; ( 3 ) combine pre - train transformers ( e.g. bert ) , lead state - - - art result nlp benchmark . , time , empirically evaluate battery lmtc method vanilla lwans hierarchical classification approach transfer learning , frequent , , zero - shot learning dataset different domain . hierarchical method base probabilistic label trees ( plts ) outperform lwans . furthermore , transformer - base approach outperform state - - - art dataset , propose new state - - - art method combine bert lwan . finally , propose new model leverage label hierarchy improve zero - shot learning , consider dataset graph - aware annotation proximity measure introduce .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 13, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 4}",Information Retrieval and Text Mining,False
NLP Applications,Data Boost: Text Data Augmentation Through Reinforcement Learning Guided Conditional Generation,"Data augmentation is proven to be effective in many NLU tasks, especially for those suffering from data scarcity. In this paper, we present a powerful and easy to deploy text augmentation framework, Data Boost, which augments data through reinforcement learning guided conditional generation. We evaluate Data Boost on three diverse text classification tasks under five different classifier architectures. The result shows that Data Boost can boost the performance of classifiers especially in low-resource data scenarios. For instance, Data Boost improves F1 for the three tasks by 8.7% on average when given only 10% of the whole data for training. We also compare Data Boost with six prior text augmentation methods. Through human evaluations (N =178), we confirm that Data Boost augmentation has comparable quality as the original data with respect to readability and class consistency.","Data Boost: Text Data Augmentation Through Reinforcement Learning Guided Conditional Generation Data augmentation is proven to be effective in many NLU tasks, especially for those suffering from data scarcity. In this paper, we present a powerful and easy to deploy text augmentation framework, Data Boost, which augments data through reinforcement learning guided conditional generation. We evaluate Data Boost on three diverse text classification tasks under five different classifier architectures. The result shows that Data Boost can boost the performance of classifiers especially in low-resource data scenarios. For instance, Data Boost improves F1 for the three tasks by 8.7% on average when given only 10% of the whole data for training. We also compare Data Boost with six prior text augmentation methods. Through human evaluations (N =178), we confirm that Data Boost augmentation has comparable quality as the original data with respect to readability and class consistency.","data boost : text datum augmentation reinforcement learning guide conditional generation data augmentation prove effective nlu task , especially suffer datum scarcity . paper , present powerful easy deploy text augmentation framework , data boost , augment datum reinforcement learning guide conditional generation . evaluate data boost diverse text classification task different classifier architecture . result show data boost boost performance classifier especially low - resource datum scenario . instance , data boost improve f1 task 8.7 % average give 10 % datum training . compare data boost prior text augmentation method . human evaluation ( n = 178 ) , confirm data boost augmentation comparable quality original datum respect readability class consistency .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,BioMegatron: Larger Biomedical Domain Language Model,"There has been an influx of biomedical domain-specific language models, showing language models pre-trained on biomedical text perform better on biomedical domain benchmarks than those trained on general domain text corpora such as Wikipedia and Books. Yet, most works do not study the factors affecting each domain language application deeply. Additionally, the study of model size on domain-specific models has been mostly missing. We empirically study and evaluate several factors that can affect performance on domain language applications, such as the sub-word vocabulary set, model size, pre-training corpus, and domain transfer. We show consistent improvements on benchmarks with our larger BioMegatron model trained on a larger domain corpus, contributing to our understanding of domain language model applications. We demonstrate noticeable improvements over the previous state-ofthe-art (SOTA) on standard biomedical NLP benchmarks of question answering, named entity recognition, and relation extraction. Code and checkpoints to reproduce our experiments are available at github.com/NVIDIA/NeMo.","BioMegatron: Larger Biomedical Domain Language Model There has been an influx of biomedical domain-specific language models, showing language models pre-trained on biomedical text perform better on biomedical domain benchmarks than those trained on general domain text corpora such as Wikipedia and Books. Yet, most works do not study the factors affecting each domain language application deeply. Additionally, the study of model size on domain-specific models has been mostly missing. We empirically study and evaluate several factors that can affect performance on domain language applications, such as the sub-word vocabulary set, model size, pre-training corpus, and domain transfer. We show consistent improvements on benchmarks with our larger BioMegatron model trained on a larger domain corpus, contributing to our understanding of domain language model applications. We demonstrate noticeable improvements over the previous state-ofthe-art (SOTA) on standard biomedical NLP benchmarks of question answering, named entity recognition, and relation extraction. Code and checkpoints to reproduce our experiments are available at github.com/NVIDIA/NeMo.","biomegatron : large biomedical domain language model influx biomedical domain - specific language model , show language model pre - train biomedical text perform well biomedical domain benchmark train general domain text corpora wikipedia books . , work study factor affect domain language application deeply . additionally , study model size domain - specific model miss . empirically study evaluate factor affect performance domain language application , sub - word vocabulary set , model size , pre - training corpus , domain transfer . consistent improvement benchmark large biomegatron model train large domain corpus , contribute understanding domain language model application . demonstrate noticeable improvement previous state - ofthe - art ( sota ) standard biomedical nlp benchmark question answering , name entity recognition , relation extraction . code checkpoint reproduce experiment available github.com/nvidia/nemo .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 5, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Towards Modeling Revision Requirements in wikiHow Instructions,"wikiHow is a resource of how-to guides that describe the steps necessary to accomplish a goal. Guides in this resource are regularly edited by a community of users, who try to improve instructions in terms of style, clarity and correctness. In this work, we test whether the need for such edits can be predicted automatically. For this task, we extend an existing resource of textual edits with a complementary set of approx. 4 million sentences that remain unedited over time and report on the outcome of two revision modeling experiments.","Towards Modeling Revision Requirements in wikiHow Instructions wikiHow is a resource of how-to guides that describe the steps necessary to accomplish a goal. Guides in this resource are regularly edited by a community of users, who try to improve instructions in terms of style, clarity and correctness. In this work, we test whether the need for such edits can be predicted automatically. For this task, we extend an existing resource of textual edits with a complementary set of approx. 4 million sentences that remain unedited over time and report on the outcome of two revision modeling experiments.","modeling revision requirement wikihow instruction wikihow resource - guide describe step necessary accomplish goal . guide resource regularly edit community user , try improve instruction term style , clarity correctness . work , test need edit predict automatically . task , extend exist resource textual edit complementary set approx . 4 million sentence remain unedited time report outcome revision modeling experiment .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Natural Language Processing for Achieving Sustainable Development: the Case of Neural Labelling to Enhance Community Profiling,"In recent years, there has been an increasing interest in the application of Artificial Intelligence -and especially Machine Learningto the field of Sustainable Development (SD). However, until now, NLP has not been systematically applied in this context. In this paper, we show the high potential of NLP to enhance project sustainability. In particular, we focus on the case of community profiling in developing countries, where, in contrast to the developed world, a notable data gap exists. Here, NLP could help to address the cost and time barrier of structuring qualitative data that prohibits its widespread use and associated benefits. We propose the new extreme multi-class multi-label Automatic User-Perceived Value classification task. We release Stories2Insights (S2I), an expertannotated dataset of interviews carried out in Uganda, we provide a detailed corpus analysis, and we implement a number of strong neural baselines to address the task. Experimental results show that the problem is challenging, and leaves considerable room for future research at the intersection of NLP and SD.","Natural Language Processing for Achieving Sustainable Development: the Case of Neural Labelling to Enhance Community Profiling In recent years, there has been an increasing interest in the application of Artificial Intelligence -and especially Machine Learningto the field of Sustainable Development (SD). However, until now, NLP has not been systematically applied in this context. In this paper, we show the high potential of NLP to enhance project sustainability. In particular, we focus on the case of community profiling in developing countries, where, in contrast to the developed world, a notable data gap exists. Here, NLP could help to address the cost and time barrier of structuring qualitative data that prohibits its widespread use and associated benefits. We propose the new extreme multi-class multi-label Automatic User-Perceived Value classification task. We release Stories2Insights (S2I), an expertannotated dataset of interviews carried out in Uganda, we provide a detailed corpus analysis, and we implement a number of strong neural baselines to address the task. Experimental results show that the problem is challenging, and leaves considerable room for future research at the intersection of NLP and SD.","natural language processing achieve sustainable development : case neural labelling enhance community profiling recent year , increase interest application artificial intelligence -and especially machine learningto field sustainable development ( sd ) . , , nlp systematically apply context . paper , high potential nlp enhance project sustainability . particular , focus case community profiling develop country , , contrast developed world , notable data gap exist . , nlp help address cost time barrier structure qualitative datum prohibit widespread use associated benefit . propose new extreme multi - class multi - label automatic user - perceived value classification task . release stories2insights ( s2i ) , expertannotated dataset interview carry uganda , provide detailed corpus analysis , implement number strong neural baseline address task . experimental result problem challenge , leave considerable room future research intersection nlp sd .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,False
NLP Applications,What time is it? Temporal Analysis of Novels,"Recognizing the flow of time in a story is a crucial aspect of understanding it. Prior work related to time has primarily focused on identifying temporal expressions or relative sequencing of events, but here we propose computationally annotating each line of a book with wall clock times, even in the absence of explicit time-descriptive phrases. To do so, we construct a data set of hourly time phrases from 52,183 fictional books. We then construct a time-of-day classification model that achieves an average error of 2.27 hours. Furthermore, we show that by analyzing a book in whole using dynamic programming of breakpoints, we can roughly partition a book into segments that each correspond to a particular time-of-day. This approach improves upon baselines by over two hour. Finally, we apply our model to a corpus of literature categorized by different periods in history, to show interesting trends of hourly activity throughout the past. Among several observations we find that the fraction of events taking place past 10 P.M jumps past 1880 -coincident with the advent of the electric light bulb and city lights.","What time is it? Temporal Analysis of Novels Recognizing the flow of time in a story is a crucial aspect of understanding it. Prior work related to time has primarily focused on identifying temporal expressions or relative sequencing of events, but here we propose computationally annotating each line of a book with wall clock times, even in the absence of explicit time-descriptive phrases. To do so, we construct a data set of hourly time phrases from 52,183 fictional books. We then construct a time-of-day classification model that achieves an average error of 2.27 hours. Furthermore, we show that by analyzing a book in whole using dynamic programming of breakpoints, we can roughly partition a book into segments that each correspond to a particular time-of-day. This approach improves upon baselines by over two hour. Finally, we apply our model to a corpus of literature categorized by different periods in history, to show interesting trends of hourly activity throughout the past. Among several observations we find that the fraction of events taking place past 10 P.M jumps past 1880 -coincident with the advent of the electric light bulb and city lights.","time ? temporal analysis novels recognize flow time story crucial aspect understand . prior work relate time primarily focus identify temporal expression relative sequencing event , propose computationally annotate line book wall clock time , absence explicit time - descriptive phrase . , construct data set hourly time phrase 52,183 fictional book . construct time - - day classification model achieve average error 2.27 hour . furthermore , analyze book dynamic programming breakpoint , roughly partition book segment correspond particular time - - day . approach improve baseline hour . finally , apply model corpus literature categorize different period history , interesting trend hourly activity past . observation find fraction event take place past 10 p.m jump past 1880 -coincident advent electric light bulb city light .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing,"Knowledge graphs (KGs) can vary greatly from one domain to another. Therefore supervised approaches to both graph-to-text generation and text-to-graph knowledge extraction (semantic parsing) will always suffer from a shortage of domain-specific parallel graphtext data; at the same time, adapting a model trained on a different domain is often impossible due to little or no overlap in entities and relations. This situation calls for an approach that (1) does not need large amounts of annotated data and thus (2) does not need to rely on domain adaptation techniques to work well in different domains. To this end, we present the first approach to unsupervised text generation from KGs and show simultaneously how it can be used for unsupervised semantic parsing. We evaluate our approach on WebNLG v2.1 and a new benchmark leveraging scene graphs from Visual Genome. Our system outperforms strong baselines for both text↔graph conversion tasks without any manual adaptation from one dataset to the other. In additional experiments, we investigate the impact of using different unsupervised objectives. 1","An Unsupervised Joint System for Text Generation from Knowledge Graphs and Semantic Parsing Knowledge graphs (KGs) can vary greatly from one domain to another. Therefore supervised approaches to both graph-to-text generation and text-to-graph knowledge extraction (semantic parsing) will always suffer from a shortage of domain-specific parallel graphtext data; at the same time, adapting a model trained on a different domain is often impossible due to little or no overlap in entities and relations. This situation calls for an approach that (1) does not need large amounts of annotated data and thus (2) does not need to rely on domain adaptation techniques to work well in different domains. To this end, we present the first approach to unsupervised text generation from KGs and show simultaneously how it can be used for unsupervised semantic parsing. We evaluate our approach on WebNLG v2.1 and a new benchmark leveraging scene graphs from Visual Genome. Our system outperforms strong baselines for both text↔graph conversion tasks without any manual adaptation from one dataset to the other. In additional experiments, we investigate the impact of using different unsupervised objectives. 1","unsupervised joint system text generation knowledge graph semantic parsing knowledge graph ( kgs ) vary greatly domain . supervise approach graph - - text generation text - - graph knowledge extraction ( semantic parsing ) suffer shortage domain - specific parallel graphtext datum ; time , adapt model train different domain impossible little overlap entity relation . situation call approach ( 1 ) need large amount annotate datum ( 2 ) need rely domain adaptation technique work different domain . end , present approach unsupervised text generation kgs simultaneously unsupervised semantic parsing . evaluate approach webnlg v2.1 new benchmark leverage scene graph visual genome . system outperform strong baseline text↔graph conversion task manual adaptation dataset . additional experiment , investigate impact different unsupervised objective . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 19, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 16, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Conversational Document Prediction to Assist Customer Care Agents,"A frequent pattern in customer care conversations is the agents responding with appropriate webpage URLs that address users' needs. We study the task of predicting the documents that customer care agents can use to facilitate users' needs. We also introduce a new public dataset 1 which supports the aforementioned problem. Using this dataset and two others, we investigate state-of-the-art deep learning (DL) and information retrieval (IR) models for the task. We also analyze the practicality of such systems in terms of inference time complexity. Our results show that an hybrid IR+DL approach provides the best of both worlds.","Conversational Document Prediction to Assist Customer Care Agents A frequent pattern in customer care conversations is the agents responding with appropriate webpage URLs that address users' needs. We study the task of predicting the documents that customer care agents can use to facilitate users' needs. We also introduce a new public dataset 1 which supports the aforementioned problem. Using this dataset and two others, we investigate state-of-the-art deep learning (DL) and information retrieval (IR) models for the task. We also analyze the practicality of such systems in terms of inference time complexity. Our results show that an hybrid IR+DL approach provides the best of both worlds.","conversational document prediction assist customer care agent frequent pattern customer care conversation agent respond appropriate webpage url address user ' need . study task predict document customer care agent use facilitate user ' need . introduce new public dataset 1 support aforementioned problem . dataset , investigate state - - - art deep learning ( dl ) information retrieval ( ir ) model task . analyze practicality system term inference time complexity . result hybrid ir+dl approach provide good world .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
NLP Applications,Public Sentiment Drift Analysis Based on Hierarchical Variational Auto-encoder,"Detecting public sentiment drift is a challenging task due to sentiment change over time. Existing methods first build a classification model using historical data and subsequently detect drift if the model performs much worse on new data. In this paper, we focus on distribution learning by proposing a novel Hierarchical Variational Auto-Encoder (HVAE) model to learn better distribution representation, and design a new drift measure to directly evaluate distribution changes between historical data and new data. Our experimental results demonstrate that our proposed model achieves better results than three existing state-of-theart methods.","Public Sentiment Drift Analysis Based on Hierarchical Variational Auto-encoder Detecting public sentiment drift is a challenging task due to sentiment change over time. Existing methods first build a classification model using historical data and subsequently detect drift if the model performs much worse on new data. In this paper, we focus on distribution learning by proposing a novel Hierarchical Variational Auto-Encoder (HVAE) model to learn better distribution representation, and design a new drift measure to directly evaluate distribution changes between historical data and new data. Our experimental results demonstrate that our proposed model achieves better results than three existing state-of-theart methods.","public sentiment drift analysis base hierarchical variational auto - encoder detect public sentiment drift challenging task sentiment change time . exist method build classification model historical datum subsequently detect drift model perform worse new datum . paper , focus distribution learning propose novel hierarchical variational auto - encoder ( hvae ) model learn well distribution representation , design new drift measure directly evaluate distribution change historical datum new datum . experimental result demonstrate propose model achieve well result exist state - - theart method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
NLP Applications,PyMT5: multi-mode translation of natural language and Python code with transformers,"Simultaneously modeling source code and natural language has many exciting applications in automated software development and understanding. Pursuant to achieving such technology, we introduce PYMT5, the PYTHON method text-to-text transfer transformer, which is trained to translate between all pairs of PYTHON method feature combinations: a single model that can both predict whole methods from natural language documentation strings (docstrings) and summarize code into docstrings of any common style. We present an analysis and modeling effort of a large-scale parallel corpus of 26 million PYTHON methods and 7.7 million method-docstring pairs, demonstrating that for docstring and method generation, PYMT5 outperforms similarlysized auto-regressive language models (GPT2) which were English pre-trained or randomly initialized. On the CODE-SEARCHNET test set, our best model predicts 92.1% syntactically correct method bodies, achieved a BLEU score of 8.59 for method generation and 16.3 for docstring * Corresponding author † Work done during a Microsoft internship generation (summarization), and achieved a ROUGE-L F-score of 24.8 for method generation and 36.7 for docstring generation.","PyMT5: multi-mode translation of natural language and Python code with transformers Simultaneously modeling source code and natural language has many exciting applications in automated software development and understanding. Pursuant to achieving such technology, we introduce PYMT5, the PYTHON method text-to-text transfer transformer, which is trained to translate between all pairs of PYTHON method feature combinations: a single model that can both predict whole methods from natural language documentation strings (docstrings) and summarize code into docstrings of any common style. We present an analysis and modeling effort of a large-scale parallel corpus of 26 million PYTHON methods and 7.7 million method-docstring pairs, demonstrating that for docstring and method generation, PYMT5 outperforms similarlysized auto-regressive language models (GPT2) which were English pre-trained or randomly initialized. On the CODE-SEARCHNET test set, our best model predicts 92.1% syntactically correct method bodies, achieved a BLEU score of 8.59 for method generation and 16.3 for docstring * Corresponding author † Work done during a Microsoft internship generation (summarization), and achieved a ROUGE-L F-score of 24.8 for method generation and 36.7 for docstring generation.","pymt5 : multi - mode translation natural language python code transformer simultaneously model source code natural language exciting application automate software development understanding . pursuant achieve technology , introduce pymt5 , python method text - - text transfer transformer , train translate pair python method feature combination : single model predict method natural language documentation string ( docstring ) summarize code docstring common style . present analysis modeling effort large - scale parallel corpus 26 million python method 7.7 million method - docstring pair , demonstrate docstring method generation , pymt5 outperform similarlysized auto - regressive language model ( gpt2 ) english pre - train randomly initialize . code - searchnet test set , good model predict 92.1 % syntactically correct method body , achieve bleu score 8.59 method generation 16.3 docstring * correspond author † work microsoft internship generation ( summarization ) , achieve rouge - l f - score 24.8 method generation 36.7 docstring generation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,A Knowledge-driven Generative Model for Multi-implication Chinese Medical Procedure Entity Normalization,"Medical entity normalization, which links medical mentions in the text to entities in knowledge bases, is an important research topic in medical natural language processing. In this paper, we focus on Chinese medical procedure entity normalization. However, nonstandard Chinese expressions and combined procedures present challenges in our problem. The existing strategies relying on the discriminative model are poorly to cope with normalizing combined procedure mentions. We propose a sequence generative framework to directly generate all the corresponding medical procedure entities. we adopt two strategies: category-based constraint decoding and category-based model refining to avoid unrealistic results. The method is capable of linking entities when a mention contains multiple procedure concepts and our comprehensive experiments demonstrate that the proposed model can achieve remarkable improvements over existing baselines, particularly significant in the case of multi-implication Chinese medical procedures.","A Knowledge-driven Generative Model for Multi-implication Chinese Medical Procedure Entity Normalization Medical entity normalization, which links medical mentions in the text to entities in knowledge bases, is an important research topic in medical natural language processing. In this paper, we focus on Chinese medical procedure entity normalization. However, nonstandard Chinese expressions and combined procedures present challenges in our problem. The existing strategies relying on the discriminative model are poorly to cope with normalizing combined procedure mentions. We propose a sequence generative framework to directly generate all the corresponding medical procedure entities. we adopt two strategies: category-based constraint decoding and category-based model refining to avoid unrealistic results. The method is capable of linking entities when a mention contains multiple procedure concepts and our comprehensive experiments demonstrate that the proposed model can achieve remarkable improvements over existing baselines, particularly significant in the case of multi-implication Chinese medical procedures.","knowledge - drive generative model multi - implication chinese medical procedure entity normalization medical entity normalization , link medical mention text entity knowledge basis , important research topic medical natural language processing . paper , focus chinese medical procedure entity normalization . , nonstandard chinese expression combine procedure present challenge problem . exist strategy rely discriminative model poorly cope normalize combine procedure mention . propose sequence generative framework directly generate corresponding medical procedure entity . adopt strategy : category - base constraint decoding category - base model refining avoid unrealistic result . method capable link entity mention contain multiple procedure concept comprehensive experiment demonstrate propose model achieve remarkable improvement exist baseline , particularly significant case multi - implication chinese medical procedure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT,"The extraction of labels from radiology text reports enables large-scale training of medical imaging models. Existing approaches to report labeling typically rely either on sophisticated feature engineering based on medical domain knowledge or manual annotations by experts. In this work, we introduce a BERTbased approach to medical image report labeling that exploits both the scale of available rule-based systems and the quality of expert annotations. We demonstrate superior performance of a biomedically pretrained BERT model first trained on annotations of a rulebased labeler and then fine-tuned on a small set of expert annotations augmented with automated backtranslation. We find that our final model, CheXbert, is able to outperform the previous best rule-based labeler with statistical significance, setting a new SOTA for report labeling on one of the largest datasets of chest x-rays.","Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT The extraction of labels from radiology text reports enables large-scale training of medical imaging models. Existing approaches to report labeling typically rely either on sophisticated feature engineering based on medical domain knowledge or manual annotations by experts. In this work, we introduce a BERTbased approach to medical image report labeling that exploits both the scale of available rule-based systems and the quality of expert annotations. We demonstrate superior performance of a biomedically pretrained BERT model first trained on annotations of a rulebased labeler and then fine-tuned on a small set of expert annotations augmented with automated backtranslation. We find that our final model, CheXbert, is able to outperform the previous best rule-based labeler with statistical significance, setting a new SOTA for report labeling on one of the largest datasets of chest x-rays.","combine automatic labeler expert annotation accurate radiology report labeling bert extraction label radiology text report enable large - scale training medical imaging model . exist approach report labeling typically rely sophisticated feature engineering base medical domain knowledge manual annotation expert . work , introduce bertbased approach medical image report labeling exploit scale available rule - base system quality expert annotation . demonstrate superior performance biomedically pretraine bert model train annotation rulebase labeler fine - tune small set expert annotation augment automate backtranslation . find final model , chexbert , able outperform previous good rule - base labeler statistical significance , set new sota report labeling large dataset chest x - ray .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Generating Fact Checking Briefs,"Fact checking at scale is difficult-while the number of active fact checking websites is growing, it remains too small for the needs of the contemporary media ecosystem. However, despite good intentions, contributions from volunteers are often error-prone, and thus in practice restricted to claim detection. We investigate how to increase the accuracy and efficiency of fact checking by providing information about the claim before performing the check, in the form of natural language briefs. We investigate passage-based briefs, containing a relevant passage from Wikipedia, entitycentric ones consisting of Wikipedia pages of mentioned entities, and Question-Answering Briefs, with questions decomposing the claim, and their answers. To produce QABriefs, we develop QABRIEFER, a model that generates a set of questions conditioned on the claim, searches the web for evidence, and generates answers. To train its components, we introduce QABRIEFDATASET which we collected via crowdsourcing. We show that fact checking with briefs -in particular QABriefs -increases the accuracy of crowdworkers by 10% while slightly decreasing the time taken. For volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and reduce the time required by around 20%.","Generating Fact Checking Briefs Fact checking at scale is difficult-while the number of active fact checking websites is growing, it remains too small for the needs of the contemporary media ecosystem. However, despite good intentions, contributions from volunteers are often error-prone, and thus in practice restricted to claim detection. We investigate how to increase the accuracy and efficiency of fact checking by providing information about the claim before performing the check, in the form of natural language briefs. We investigate passage-based briefs, containing a relevant passage from Wikipedia, entitycentric ones consisting of Wikipedia pages of mentioned entities, and Question-Answering Briefs, with questions decomposing the claim, and their answers. To produce QABriefs, we develop QABRIEFER, a model that generates a set of questions conditioned on the claim, searches the web for evidence, and generates answers. To train its components, we introduce QABRIEFDATASET which we collected via crowdsourcing. We show that fact checking with briefs -in particular QABriefs -increases the accuracy of crowdworkers by 10% while slightly decreasing the time taken. For volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and reduce the time required by around 20%.","generate fact checking brief fact checking scale difficult - number active fact checking website grow , remain small need contemporary medium ecosystem . , despite good intention , contribution volunteer error - prone , practice restrict claim detection . investigate increase accuracy efficiency fact checking provide information claim perform check , form natural language brief . investigate passage - base brief , contain relevant passage wikipedia , entitycentric one consist wikipedia page mention entity , question - answering briefs , question decompose claim , answer . produce qabrief , develop qabriefer , model generate set question condition claim , search web evidence , generate answer . train component , introduce qabriefdataset collect crowdsourcing . fact checking brief -in particular qabriefs -increase accuracy crowdworker 10 % slightly decrease time take . volunteer ( unpaid ) fact checker , qabriefs slightly increase accuracy reduce time require 20 % .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 12, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
NLP Applications,HABERTOR: An Efficient and Effective Deep Hatespeech Detector,"We present our HABERTOR model for detecting hatespeech in large scale user-generated content. Inspired by the recent success of the BERT model, we propose several modifications to BERT to enhance the performance on the downstream hatespeech classification task. HABERTOR inherits BERT's architecture, but is different in four aspects: (i) it generates its own vocabularies and is pre-trained from the scratch using the largest scale hatespeech dataset; (ii) it consists of Quaternionbased factorized components, resulting in a much smaller number of parameters, faster training and inferencing, as well as less memory usage; (iii) it uses our proposed multisource ensemble heads with a pooling layer for separate input sources, to further enhance its effectiveness; and (iv) it uses a regularized adversarial training with our proposed finegrained and adaptive noise magnitude to enhance its robustness. Through experiments on the large-scale real-world hatespeech dataset with 1.4M annotated comments, we show that HABERTOR works better than 15 state-ofthe-art hatespeech detection methods, including fine-tuning Language Models. In particular, comparing with BERT, our HABERTOR is 4∼5 times faster in the training/inferencing phase, uses less than 1/3 of the memory, and has better performance, even though we pretrain it by using less than 1% of the number of words. Our generalizability analysis shows that HABERTOR transfers well to other unseen hatespeech datasets and is a more efficient and effective alternative to BERT for the hatespeech classification.","HABERTOR: An Efficient and Effective Deep Hatespeech Detector We present our HABERTOR model for detecting hatespeech in large scale user-generated content. Inspired by the recent success of the BERT model, we propose several modifications to BERT to enhance the performance on the downstream hatespeech classification task. HABERTOR inherits BERT's architecture, but is different in four aspects: (i) it generates its own vocabularies and is pre-trained from the scratch using the largest scale hatespeech dataset; (ii) it consists of Quaternionbased factorized components, resulting in a much smaller number of parameters, faster training and inferencing, as well as less memory usage; (iii) it uses our proposed multisource ensemble heads with a pooling layer for separate input sources, to further enhance its effectiveness; and (iv) it uses a regularized adversarial training with our proposed finegrained and adaptive noise magnitude to enhance its robustness. Through experiments on the large-scale real-world hatespeech dataset with 1.4M annotated comments, we show that HABERTOR works better than 15 state-ofthe-art hatespeech detection methods, including fine-tuning Language Models. In particular, comparing with BERT, our HABERTOR is 4∼5 times faster in the training/inferencing phase, uses less than 1/3 of the memory, and has better performance, even though we pretrain it by using less than 1% of the number of words. Our generalizability analysis shows that HABERTOR transfers well to other unseen hatespeech datasets and is a more efficient and effective alternative to BERT for the hatespeech classification.","habertor : efficient effective deep hatespeech detector present habertor model detect hatespeech large scale user - generate content . inspire recent success bert model , propose modification bert enhance performance downstream hatespeech classification task . habertor inherit bert architecture , different aspect : ( ) generate vocabulary pre - train scratch large scale hatespeech dataset ; ( ii ) consist quaternionbased factorize component , result small number parameter , fast training inferencing , memory usage ; ( iii ) use propose multisource ensemble head pool layer separate input source , enhance effectiveness ; ( iv ) use regularized adversarial training propose finegrained adaptive noise magnitude enhance robustness . experiment large - scale real - world hatespeech dataset 1.4 m annotate comment , habertor work well 15 state - ofthe - art hatespeech detection method , include fine - tune language models . particular , compare bert , habertor 4∼5 time fast training / inferencing phase , use 1/3 memory , well performance , pretrain 1 % number word . generalizability analysis show habertor transfer unseen hatespeech dataset efficient effective alternative bert hatespeech classification .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 8, 'Machine Learning for NLP': 17, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 8, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Point to the Expression: Solving Algebraic Word Problems using the Expression-Pointer Transformer Model,"Solving algebraic word problems has recently emerged as an important natural language processing task. To solve algebraic word problems, recent studies suggested neural models that generate solution equations by using 'Op (operator/operand)' tokens as a unit of input/output. However, such a neural model suffered two issues: expression fragmentation and operand-context separation. To address each of these two issues, we propose a pure neural model, Expression-Pointer Transformer (EPT), which uses (1) 'Expression' token and (2) operand-context pointers when generating solution equations. The performance of the EPT model is tested on three datasets: ALG514, DRAW-1K, and MAWPS. Compared to the state-of-the-art (SoTA) models, the EPT model achieved a comparable performance accuracy in each of the three datasets; 81.3% on ALG514, 59.5% on DRAW-1K, and 84.5% on MAWPS. The contribution of this paper is two-fold; (1) We propose a pure neural model, EPT, which can address the expression fragmentation and the operandcontext separation. (2) The fully automatic EPT model, which does not use hand-crafted features, yields comparable performance to existing models using hand-crafted features, and achieves better performance than existing pure neural models by at most 40%.","Point to the Expression: Solving Algebraic Word Problems using the Expression-Pointer Transformer Model Solving algebraic word problems has recently emerged as an important natural language processing task. To solve algebraic word problems, recent studies suggested neural models that generate solution equations by using 'Op (operator/operand)' tokens as a unit of input/output. However, such a neural model suffered two issues: expression fragmentation and operand-context separation. To address each of these two issues, we propose a pure neural model, Expression-Pointer Transformer (EPT), which uses (1) 'Expression' token and (2) operand-context pointers when generating solution equations. The performance of the EPT model is tested on three datasets: ALG514, DRAW-1K, and MAWPS. Compared to the state-of-the-art (SoTA) models, the EPT model achieved a comparable performance accuracy in each of the three datasets; 81.3% on ALG514, 59.5% on DRAW-1K, and 84.5% on MAWPS. The contribution of this paper is two-fold; (1) We propose a pure neural model, EPT, which can address the expression fragmentation and the operandcontext separation. (2) The fully automatic EPT model, which does not use hand-crafted features, yields comparable performance to existing models using hand-crafted features, and achieves better performance than existing pure neural models by at most 40%.","point expression : solve algebraic word problem expression - pointer transformer model solve algebraic word problem recently emerge important natural language processing task . solve algebraic word problem , recent study suggest neural model generate solution equation ' op ( operator / operand ) ' token unit input / output . , neural model suffer issue : expression fragmentation operand - context separation . address issue , propose pure neural model , expression - pointer transformer ( ept ) , use ( 1 ) ' expression ' token ( 2 ) operand - context pointer generate solution equation . performance ept model test dataset : alg514 , draw-1 k , mawps . compare state - - - art ( sota ) model , ept model achieve comparable performance accuracy dataset ; 81.3 % alg514 , 59.5 % draw-1 k , 84.5 % mawps . contribution paper - fold ; ( 1 ) propose pure neural model , ept , address expression fragmentation operandcontext separation . ( 2 ) fully automatic ept model , use hand - craft feature , yield comparable performance exist model hand - craft feature , achieve well performance exist pure neural model 40 % .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Which *BERT? A Survey Organizing Contextualized Encoders,"Pretrained contextualized text encoders are now a staple of the NLP community. We present a survey on language representation learning with the aim of consolidating a series of shared lessons learned across a variety of recent efforts. While significant advancements continue at a rapid pace, we find that enough has now been discovered, in different directions, that we can begin to organize advances according to common themes. Through this organization, we highlight important considerations when interpreting recent contributions and choosing which model to use.","Which *BERT? A Survey Organizing Contextualized Encoders Pretrained contextualized text encoders are now a staple of the NLP community. We present a survey on language representation learning with the aim of consolidating a series of shared lessons learned across a variety of recent efforts. While significant advancements continue at a rapid pace, we find that enough has now been discovered, in different directions, that we can begin to organize advances according to common themes. Through this organization, we highlight important considerations when interpreting recent contributions and choosing which model to use.","* bert ? survey organize contextualize encoder pretraine contextualized text encoder staple nlp community . present survey language representation learning aim consolidate series share lesson learn variety recent effort . significant advancement continue rapid pace , find discover , different direction , begin organize advance accord common theme . organization , highlight important consideration interpret recent contribution choose model use .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Grammatical Error Correction in Low Error Density Domains: A New Benchmark and Analyses,"Evaluation of grammatical error correction (GEC) systems has primarily focused on essays written by non-native learners of English, which however is only part of the full spectrum of GEC applications. We aim to broaden the target domain of GEC and release CWEB, a new benchmark for GEC consisting of website text generated by English speakers of varying levels of proficiency. Website data is a common and important domain that contains far fewer grammatical errors than learner essays, which we show presents a challenge to stateof-the-art GEC systems. We demonstrate that a factor behind this is the inability of systems to rely on a strong internal language model in low error density domains. We hope this work shall facilitate the development of opendomain GEC models that generalize to different topics and genres.","Grammatical Error Correction in Low Error Density Domains: A New Benchmark and Analyses Evaluation of grammatical error correction (GEC) systems has primarily focused on essays written by non-native learners of English, which however is only part of the full spectrum of GEC applications. We aim to broaden the target domain of GEC and release CWEB, a new benchmark for GEC consisting of website text generated by English speakers of varying levels of proficiency. Website data is a common and important domain that contains far fewer grammatical errors than learner essays, which we show presents a challenge to stateof-the-art GEC systems. We demonstrate that a factor behind this is the inability of systems to rely on a strong internal language model in low error density domains. We hope this work shall facilitate the development of opendomain GEC models that generalize to different topics and genres.","grammatical error correction low error density domain : new benchmark analyses evaluation grammatical error correction ( gec ) system primarily focus essay write non - native learner english , spectrum gec application . aim broaden target domain gec release cweb , new benchmark gec consist website text generate english speaker vary level proficiency . website datum common important domain contain far few grammatical error learner essay , present challenge stateof - - art gec system . demonstrate factor inability system rely strong internal language model low error density domain . hope work shall facilitate development opendomain gec model generalize different topic genre .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages,"Multilingual transformer models like mBERT and XLM-RoBERTa have obtained great improvements for many NLP tasks on a variety of languages. However, recent works also showed that results from high-resource languages could not be easily transferred to realistic, low-resource scenarios. In this work, we study trends in performance for different amounts of available resources for the three African languages Hausa, isiXhosa and Yorùbá on both NER and topic classification. We show that in combination with transfer learning or distant supervision, these models can achieve with as little as 10 or 100 labeled sentences the same performance as baselines with much more supervised training data. However, we also find settings where this does not hold. Our discussions and additional experiments on assumptions such as time and hardware restrictions highlight challenges and opportunities in low-resource learning.","Transfer Learning and Distant Supervision for Multilingual Transformer Models: A Study on African Languages Multilingual transformer models like mBERT and XLM-RoBERTa have obtained great improvements for many NLP tasks on a variety of languages. However, recent works also showed that results from high-resource languages could not be easily transferred to realistic, low-resource scenarios. In this work, we study trends in performance for different amounts of available resources for the three African languages Hausa, isiXhosa and Yorùbá on both NER and topic classification. We show that in combination with transfer learning or distant supervision, these models can achieve with as little as 10 or 100 labeled sentences the same performance as baselines with much more supervised training data. However, we also find settings where this does not hold. Our discussions and additional experiments on assumptions such as time and hardware restrictions highlight challenges and opportunities in low-resource learning.","transfer learning distant supervision multilingual transformer model : study african languages multilingual transformer model like mbert xlm - roberta obtain great improvement nlp task variety language . , recent work show result high - resource language easily transfer realistic , low - resource scenario . work , study trend performance different amount available resource african language hausa , isixhosa yorùbá ner topic classification . combination transfer learning distant supervision , model achieve little 10 100 label sentence performance baseline supervised training datum . , find setting hold . discussion additional experiment assumption time hardware restriction highlight challenge opportunity low - resource learning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
NLP Applications,Fact or Fiction: Verifying Scientific Claims,"We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUP-PORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SCI-FACT, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SCIFACT, and demonstrate that simple domain adaptation techniques substantially improve performance compared to models trained on Wikipedia or political news. We show that our system is able to verify claims related to COVID-19 by identifying evidence from the CORD-19 corpus. Our experiments indicate that SCIFACT will provide a challenging testbed for the development of new systems designed to retrieve and reason over corpora containing specialized domain knowledge. Data and code for this new task are publicly available at https:// github.com/allenai/scifact. A leaderboard and COVID-19 fact-checking demo are available at https://scifact.apps. allenai.org. * Work performed during internship with the Allen Institute for Artificial Intelligence. More severe COVID-19 infection is associated with higher mean troponin (SMD 0.53, 95% CI 0.30 to 0.75, p < 0.001) Decision: SUPPORTS Claim Fact-checker Rationale Corpus Cardiac injury is common in critical cases of COVID-19.","Fact or Fiction: Verifying Scientific Claims We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUP-PORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SCI-FACT, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SCIFACT, and demonstrate that simple domain adaptation techniques substantially improve performance compared to models trained on Wikipedia or political news. We show that our system is able to verify claims related to COVID-19 by identifying evidence from the CORD-19 corpus. Our experiments indicate that SCIFACT will provide a challenging testbed for the development of new systems designed to retrieve and reason over corpora containing specialized domain knowledge. Data and code for this new task are publicly available at https:// github.com/allenai/scifact. A leaderboard and COVID-19 fact-checking demo are available at https://scifact.apps. allenai.org. * Work performed during internship with the Allen Institute for Artificial Intelligence. More severe COVID-19 infection is associated with higher mean troponin (SMD 0.53, 95% CI 0.30 to 0.75, p < 0.001) Decision: SUPPORTS Claim Fact-checker Rationale Corpus Cardiac injury is common in critical cases of COVID-19.","fact fiction : verify scientific claim introduce scientific claim verification , new task select abstract research literature contain evidence sup - port refute give scientific claim , identify rationale justify decision . study task , construct sci - fact , dataset 1.4 k expert - write scientific claim pair evidence - contain abstract annotate label rationale . develop baseline model scifact , demonstrate simple domain adaptation technique substantially improve performance compare model train wikipedia political news . system able verify claim relate covid-19 identify evidence cord-19 corpus . experiment indicate scifact provide challenging testbed development new system design retrieve reason corpus contain specialized domain knowledge . datum code new task publicly available https:// github.com/allenai/scifact . leaderboard covid-19 fact - checking demo available https://scifact.apps . allenai.org . * work perform internship allen institute artificial intelligence . severe covid-19 infection associate high mean troponin ( smd 0.53 , 95 % ci 0.30 0.75 , p < 0.001 ) decision : support claim fact - checker rationale corpus cardiac injury common critical case covid-19 .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
NLP Applications,Chapter Captor: Text Segmentation in Novels,"Books are typically segmented into chapters and sections, representing coherent subnarratives and topics. We investigate the task of predicting chapter boundaries, as a proxy for the general task of segmenting long texts. We build a Project Gutenberg chapter segmentation data set of 9,126 English novels, using a hybrid approach combining neural inference and rule matching to recognize chapter title headers in books, achieving an F1-score of 0.77 on this task. Using this annotated data as ground truth after removing structural cues, we present cut-based and neural methods for chapter segmentation, achieving an F1-score of 0.453 on the challenging task of exact break prediction over book-length documents. Finally, we reveal interesting historical trends in the chapter structure of novels.","Chapter Captor: Text Segmentation in Novels Books are typically segmented into chapters and sections, representing coherent subnarratives and topics. We investigate the task of predicting chapter boundaries, as a proxy for the general task of segmenting long texts. We build a Project Gutenberg chapter segmentation data set of 9,126 English novels, using a hybrid approach combining neural inference and rule matching to recognize chapter title headers in books, achieving an F1-score of 0.77 on this task. Using this annotated data as ground truth after removing structural cues, we present cut-based and neural methods for chapter segmentation, achieving an F1-score of 0.453 on the challenging task of exact break prediction over book-length documents. Finally, we reveal interesting historical trends in the chapter structure of novels.","chapter captor : text segmentation novels book typically segment chapter section , represent coherent subnarrative topic . investigate task predict chapter boundary , proxy general task segment long text . build project gutenberg chapter segmentation datum set 9,126 english novel , hybrid approach combine neural inference rule matching recognize chapter title header book , achieve f1 - score 0.77 task . annotate datum ground truth remove structural cue , present cut - base neural method chapter segmentation , achieve f1 - score 0.453 challenging task exact break prediction book - length document . finally , reveal interesting historical trend chapter structure novel .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,TNT: Text Normalization based Pre-training of Transformers for Content Moderation,"In this work, we present a new language pre-training model TNT (Text Normalization based pre-training of Transformers) for content moderation. Inspired by the masking strategy and text normalization, TNT is developed to learn language representation by training transformers to reconstruct text from four operation types typically seen in text manipulation: substitution, transposition, deletion, and insertion. Furthermore, the normalization involves the prediction of both operation types and token labels, enabling TNT to learn from more challenging tasks than the standard task of masked word recovery. As a result, the experiments demonstrate that TNT outperforms strong baselines on the hate speech classification task. Additional text normalization experiments and case studies show that TNT is a new potential approach to misspelling correction.","TNT: Text Normalization based Pre-training of Transformers for Content Moderation In this work, we present a new language pre-training model TNT (Text Normalization based pre-training of Transformers) for content moderation. Inspired by the masking strategy and text normalization, TNT is developed to learn language representation by training transformers to reconstruct text from four operation types typically seen in text manipulation: substitution, transposition, deletion, and insertion. Furthermore, the normalization involves the prediction of both operation types and token labels, enabling TNT to learn from more challenging tasks than the standard task of masked word recovery. As a result, the experiments demonstrate that TNT outperforms strong baselines on the hate speech classification task. Additional text normalization experiments and case studies show that TNT is a new potential approach to misspelling correction.","tnt : text normalization base pre - training transformers content moderation work , present new language pre - training model tnt ( text normalization base pre - training transformers ) content moderation . inspire masking strategy text normalization , tnt develop learn language representation train transformer reconstruct text operation type typically see text manipulation : substitution , transposition , deletion , insertion . furthermore , normalization involve prediction operation type token label , enable tnt learn challenging task standard task mask word recovery . result , experiment demonstrate tnt outperform strong baseline hate speech classification task . additional text normalization experiment case study tnt new potential approach misspell correction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Improving the Efficiency of Grammatical Error Correction with Erroneous Span Detection and Correction,"We propose a novel language-independent approach to improve the efficiency for Grammatical Error Correction (GEC) by dividing the task into two subtasks: Erroneous Span Detection (ESD) and Erroneous Span Correction (ESC). ESD identifies grammatically incorrect text spans with an efficient sequence tagging model. Then, ESC leverages a seq2seq model to take the sentence with annotated erroneous spans as input and only outputs the corrected text for these spans. Experiments show our approach performs comparably to conventional seq2seq approaches in both English and Chinese GEC benchmarks with less than 50% time cost for inference.","Improving the Efficiency of Grammatical Error Correction with Erroneous Span Detection and Correction We propose a novel language-independent approach to improve the efficiency for Grammatical Error Correction (GEC) by dividing the task into two subtasks: Erroneous Span Detection (ESD) and Erroneous Span Correction (ESC). ESD identifies grammatically incorrect text spans with an efficient sequence tagging model. Then, ESC leverages a seq2seq model to take the sentence with annotated erroneous spans as input and only outputs the corrected text for these spans. Experiments show our approach performs comparably to conventional seq2seq approaches in both English and Chinese GEC benchmarks with less than 50% time cost for inference.","improve efficiency grammatical error correction erroneous span detection correction propose novel language - independent approach improve efficiency grammatical error correction ( gec ) divide task subtask : erroneous span detection ( esd ) erroneous span correction ( esc ) . esd identify grammatically incorrect text span efficient sequence tagging model . , esc leverage seq2seq model sentence annotate erroneous span input output correct text span . experiment approach perform comparably conventional seq2seq approach english chinese gec benchmark 50 % time cost inference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Near-imperceptible Neural Linguistic Steganography via Self-Adjusting Arithmetic Coding,"Linguistic steganography studies how to hide secret messages in natural language cover texts. Traditional methods aim to transform a secret message into an innocent text via lexical substitution or syntactical modification. Recently, advances in neural language models (LMs) enable us to directly generate cover text conditioned on the secret message. In this study, we present a new linguistic steganography method which encodes secret messages using self-adjusting arithmetic coding based on a neural language model. We formally analyze the statistical imperceptibility of this method and empirically show it outperforms the previous state-of-the-art methods on four datasets by 15.3% and 38.9% in terms of bits/word and KL metrics, respectively. Finally, human evaluations show that 51% of generated cover texts can indeed fool eavesdroppers. 1","Near-imperceptible Neural Linguistic Steganography via Self-Adjusting Arithmetic Coding Linguistic steganography studies how to hide secret messages in natural language cover texts. Traditional methods aim to transform a secret message into an innocent text via lexical substitution or syntactical modification. Recently, advances in neural language models (LMs) enable us to directly generate cover text conditioned on the secret message. In this study, we present a new linguistic steganography method which encodes secret messages using self-adjusting arithmetic coding based on a neural language model. We formally analyze the statistical imperceptibility of this method and empirically show it outperforms the previous state-of-the-art methods on four datasets by 15.3% and 38.9% in terms of bits/word and KL metrics, respectively. Finally, human evaluations show that 51% of generated cover texts can indeed fool eavesdroppers. 1","near - imperceptible neural linguistic steganography self - adjust arithmetic coding linguistic steganography study hide secret message natural language cover text . traditional method aim transform secret message innocent text lexical substitution syntactical modification . recently , advance neural language model ( lms ) enable directly generate cover text condition secret message . study , present new linguistic steganography method encode secret message self - adjust arithmetic coding base neural language model . formally analyze statistical imperceptibility method empirically outperform previous state - - - art method dataset 15.3 % 38.9 % term bit / word kl metric , respectively . finally , human evaluation 51 % generate cover text fool eavesdropper . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Generation,False
NLP Applications,Semantically-Aligned Universal Tree-Structured Solver for Math Word Problems,"A practical automatic textual math word problems (MWPs) solver should be able to solve various textual MWPs while most existing works only focused on one-unknown linear MWPs. Herein, we propose a simple but efficient method called Universal Expression Tree (UET) to make the first attempt to represent the equations of various MWPs uniformly. Then a semantically-aligned universal tree-structured solver (SAU-Solver) based on an encoder-decoder framework is proposed to resolve multiple types of MWPs in a unified model, benefiting from our UET representation. Our SAU-Solver generates a universal expression tree explicitly by deciding which symbol to generate according to the generated symbols' semantic meanings like human solving MWPs. Besides, our SAU-Solver also includes a novel subtree-level semanticallyaligned regularization to further enforce the semantic constraints and rationality of the generated expression tree by aligning with the contextual information. Finally, to validate the universality of our solver and extend the research boundary of MWPs, we introduce a new challenging Hybrid Math Word Problems dataset (HMWP), consisting of three types of MWPs. Experimental results on several MWPs datasets show that our model can solve universal types of MWPs and outperforms several state-of-the-art models 1 .","Semantically-Aligned Universal Tree-Structured Solver for Math Word Problems A practical automatic textual math word problems (MWPs) solver should be able to solve various textual MWPs while most existing works only focused on one-unknown linear MWPs. Herein, we propose a simple but efficient method called Universal Expression Tree (UET) to make the first attempt to represent the equations of various MWPs uniformly. Then a semantically-aligned universal tree-structured solver (SAU-Solver) based on an encoder-decoder framework is proposed to resolve multiple types of MWPs in a unified model, benefiting from our UET representation. Our SAU-Solver generates a universal expression tree explicitly by deciding which symbol to generate according to the generated symbols' semantic meanings like human solving MWPs. Besides, our SAU-Solver also includes a novel subtree-level semanticallyaligned regularization to further enforce the semantic constraints and rationality of the generated expression tree by aligning with the contextual information. Finally, to validate the universality of our solver and extend the research boundary of MWPs, we introduce a new challenging Hybrid Math Word Problems dataset (HMWP), consisting of three types of MWPs. Experimental results on several MWPs datasets show that our model can solve universal types of MWPs and outperforms several state-of-the-art models 1 .","semantically - align universal tree - structure solver math word problem practical automatic textual math word problem ( mwps ) solver able solve textual mwp exist work focus - unknown linear mwp . , propose simple efficient method call universal expression tree ( uet ) attempt represent equation mwp uniformly . semantically - align universal tree - structure solver ( sau - solver ) base encoder - decoder framework propose resolve multiple type mwps unified model , benefit uet representation . sau - solver generate universal expression tree explicitly decide symbol generate accord generate symbol ' semantic meaning like human solve mwp . , sau - solver include novel subtree - level semanticallyaligned regularization enforce semantic constraint rationality generate expression tree align contextual information . finally , validate universality solver extend research boundary mwps , introduce new challenging hybrid math word problems dataset ( hmwp ) , consist type mwp . experimental result mwps dataset model solve universal type mwp outperform state - - - art model 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 12, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
NLP Applications,MODE-LSTM: A Parameter-efficient Recurrent Network with Multi-Scale for Sentence Classification,"The central problem of sentence classification is to extract multi-scale n-gram features for understanding the semantic meaning of sentences. Most existing models tackle this problem by stacking CNN and RNN models, which easily leads to feature redundancy and overfitting because of relatively limited datasets. In this paper, we propose a simple yet effective model called Multi-scale Orthogonal inDependEnt LSTM (MODE-LSTM), which not only has effective parameters and good generalization ability, but also considers multiscale n-gram features. We disentangle the hidden state of the LSTM into several independently updated small hidden states and apply an orthogonal constraint on their recurrent matrices. We then equip this structure with sliding windows of different sizes for extracting multi-scale n-gram features. Extensive experiments demonstrate that our model achieves better or competitive performance against state-of-the-art baselines on eight benchmark datasets. We also combine our model with BERT to further boost the generalization performance.","MODE-LSTM: A Parameter-efficient Recurrent Network with Multi-Scale for Sentence Classification The central problem of sentence classification is to extract multi-scale n-gram features for understanding the semantic meaning of sentences. Most existing models tackle this problem by stacking CNN and RNN models, which easily leads to feature redundancy and overfitting because of relatively limited datasets. In this paper, we propose a simple yet effective model called Multi-scale Orthogonal inDependEnt LSTM (MODE-LSTM), which not only has effective parameters and good generalization ability, but also considers multiscale n-gram features. We disentangle the hidden state of the LSTM into several independently updated small hidden states and apply an orthogonal constraint on their recurrent matrices. We then equip this structure with sliding windows of different sizes for extracting multi-scale n-gram features. Extensive experiments demonstrate that our model achieves better or competitive performance against state-of-the-art baselines on eight benchmark datasets. We also combine our model with BERT to further boost the generalization performance.","mode - lstm : parameter - efficient recurrent network multi - scale sentence classification central problem sentence classification extract multi - scale n - gram feature understand semantic meaning sentence . exist model tackle problem stack cnn rnn model , easily lead feature redundancy overfitting relatively limited dataset . paper , propose simple effective model call multi - scale orthogonal independent lstm ( mode - lstm ) , effective parameter good generalization ability , consider multiscale n - gram feature . disentangle hidden state lstm independently update small hidden state apply orthogonal constraint recurrent matrix . equip structure sliding window different size extract multi - scale n - gram feature . extensive experiment demonstrate model achieve well competitive performance state - - - art baseline benchmark dataset . combine model bert boost generalization performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Resources and Evaluation,False
NLP Applications,Deep Attentive Learning for Stock Movement Prediction From Social Media Text and Company Correlations,"In the financial domain, risk modeling and profit generation heavily rely on the sophisticated and intricate stock movement prediction task. Stock forecasting is complex, given the stochastic dynamics and non-stationary behavior of the market. Stock movements are influenced by varied factors beyond the conventionally studied historical prices, such as social media and correlations among stocks. The rising ubiquity of online content and knowledge mandates an exploration of models that factor in such multimodal signals for accurate stock forecasting. We introduce an architecture that achieves a potent blend of chaotic temporal signals from financial data, social media, and inter-stock relationships via a graph neural network in a hierarchical temporal fashion. Through experiments on real-world S&P 500 index data and English tweets, we show the practical applicability of our model as a tool for investment decision making and trading. 1 https://medium.com/scoop-markets/7-tweets-whichwiped-40-billion-off-the-stock-market","Deep Attentive Learning for Stock Movement Prediction From Social Media Text and Company Correlations In the financial domain, risk modeling and profit generation heavily rely on the sophisticated and intricate stock movement prediction task. Stock forecasting is complex, given the stochastic dynamics and non-stationary behavior of the market. Stock movements are influenced by varied factors beyond the conventionally studied historical prices, such as social media and correlations among stocks. The rising ubiquity of online content and knowledge mandates an exploration of models that factor in such multimodal signals for accurate stock forecasting. We introduce an architecture that achieves a potent blend of chaotic temporal signals from financial data, social media, and inter-stock relationships via a graph neural network in a hierarchical temporal fashion. Through experiments on real-world S&P 500 index data and English tweets, we show the practical applicability of our model as a tool for investment decision making and trading. 1 https://medium.com/scoop-markets/7-tweets-whichwiped-40-billion-off-the-stock-market","deep attentive learning stock movement prediction social media text company correlation financial domain , risk modeling profit generation heavily rely sophisticated intricate stock movement prediction task . stock forecasting complex , give stochastic dynamic non - stationary behavior market . stock movement influence varied factor conventionally study historical price , social medium correlation stock . rise ubiquity online content knowledge mandate exploration model factor multimodal signal accurate stock forecasting . introduce architecture achieve potent blend chaotic temporal signal financial datum , social medium , inter - stock relationship graph neural network hierarchical temporal fashion . experiment real - world s&p 500 index datum english tweet , practical applicability model tool investment decision making trading . 1 https://medium.com/scoop-markets/7-tweets-whichwiped-40-billion-off-the-stock-market","{'Computational Social Science and Social Media': 11, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
NLP Applications,Assessing the Helpfulness of Learning Materials with Inference-Based Learner-Like Agent,"Many English-as-a-second language learners have trouble using near-synonym words (e.g., small vs. little; briefly vs. shortly) correctly, and often look for example sentences to learn how two nearly synonymous terms differ. Prior work uses hand-crafted scores to recommend sentences but have difficulty in adopting such scores to all the near-synonyms as near-synonyms differ in various ways. We notice that the helpfulness of the learning material would reflect on the learners' performance. Thus, we propose the inference-based learner-like agent to mimic learner behavior and identify good learning materials by examining the agent's performance. To enable the agent to behave like a learner, we leverages entailment modeling's capability of inferring answers from the provided materials. Experimental results show that the proposed agent is equipped with good learner-like behavior to achieve the best performance in both fill-inthe-blank (FITB) and good example sentence selection tasks. We further conduct a classroom user study with college ESL learners. The results of the user study show that the proposed agent can find out example sentences that help students learn more easily and efficiently. Compared to other models, the proposed agent improves the score of more than 17% of students after learning.","Assessing the Helpfulness of Learning Materials with Inference-Based Learner-Like Agent Many English-as-a-second language learners have trouble using near-synonym words (e.g., small vs. little; briefly vs. shortly) correctly, and often look for example sentences to learn how two nearly synonymous terms differ. Prior work uses hand-crafted scores to recommend sentences but have difficulty in adopting such scores to all the near-synonyms as near-synonyms differ in various ways. We notice that the helpfulness of the learning material would reflect on the learners' performance. Thus, we propose the inference-based learner-like agent to mimic learner behavior and identify good learning materials by examining the agent's performance. To enable the agent to behave like a learner, we leverages entailment modeling's capability of inferring answers from the provided materials. Experimental results show that the proposed agent is equipped with good learner-like behavior to achieve the best performance in both fill-inthe-blank (FITB) and good example sentence selection tasks. We further conduct a classroom user study with college ESL learners. The results of the user study show that the proposed agent can find out example sentences that help students learn more easily and efficiently. Compared to other models, the proposed agent improves the score of more than 17% of students after learning.","assess helpfulness learn material inference - base learner - like agent english - - - second language learner trouble near - synonym word ( e.g. , small vs. little ; briefly vs. shortly ) correctly , look example sentence learn nearly synonymous term differ . prior work use hand - craft score recommend sentence difficulty adopt score near - synonym near - synonym differ way . notice helpfulness learn material reflect learner ' performance . , propose inference - base learner - like agent mimic learner behavior identify good learning material examine agent performance . enable agent behave like learner , leverage entailment modeling capability infer answer provide material . experimental result propose agent equip good learner - like behavior achieve good performance fill - inthe - blank ( fitb ) good example sentence selection task . conduct classroom user study college esl learner . result user study propose agent find example sentence help student learn easily efficiently . compare model , propose agent improve score 17 % student learn .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Wasserstein Distance Regularized Sequence Representation for Text Matching in Asymmetrical Domains,"One approach to matching texts from asymmetrical domains is projecting the input sequences into a common semantic space as feature vectors upon which the matching function can be readily defined and learned. In realworld matching practices, it is often observed that with the training goes on, the feature vectors projected from different domains tend to be indistinguishable. The phenomenon, however, is often overlooked in existing matching models. As a result, the feature vectors are constructed without any regularization, which inevitably increases the difficulty of learning the downstream matching functions. In this paper, we propose a novel match method tailored for text matching in asymmetrical domains, called WD-Match. In WD-Match, a Wasserstein distance-based regularizer is defined to regularize the features vectors projected from different domains. As a result, the method enforces the feature projection function to generate vectors such that those correspond to different domains cannot be easily discriminated. The training process of WD-Match amounts to a game that minimizes the matching loss regularized by the Wasserstein distance. WD-Match can be used to improve different text matching methods, by using the method as its underlying matching model. Four popular text matching methods have been exploited in the paper. Experimental results based on four publicly available benchmarks showed that WD-Match consistently outperformed the underlying methods and the baselines.","Wasserstein Distance Regularized Sequence Representation for Text Matching in Asymmetrical Domains One approach to matching texts from asymmetrical domains is projecting the input sequences into a common semantic space as feature vectors upon which the matching function can be readily defined and learned. In realworld matching practices, it is often observed that with the training goes on, the feature vectors projected from different domains tend to be indistinguishable. The phenomenon, however, is often overlooked in existing matching models. As a result, the feature vectors are constructed without any regularization, which inevitably increases the difficulty of learning the downstream matching functions. In this paper, we propose a novel match method tailored for text matching in asymmetrical domains, called WD-Match. In WD-Match, a Wasserstein distance-based regularizer is defined to regularize the features vectors projected from different domains. As a result, the method enforces the feature projection function to generate vectors such that those correspond to different domains cannot be easily discriminated. The training process of WD-Match amounts to a game that minimizes the matching loss regularized by the Wasserstein distance. WD-Match can be used to improve different text matching methods, by using the method as its underlying matching model. Four popular text matching methods have been exploited in the paper. Experimental results based on four publicly available benchmarks showed that WD-Match consistently outperformed the underlying methods and the baselines.","wasserstein distance regularize sequence representation text matching asymmetrical domain approach match text asymmetrical domain project input sequence common semantic space feature vector match function readily define learn . realworld matching practice , observe training go , feature vector project different domain tend indistinguishable . phenomenon , , overlook exist match model . result , feature vector construct regularization , inevitably increase difficulty learn downstream matching function . paper , propose novel match method tailor text matching asymmetrical domain , call wd - match . wd - match , wasserstein distance - base regularizer define regularize feature vector project different domain . result , method enforce feature projection function generate vector correspond different domain easily discriminate . training process wd - match amount game minimize matching loss regularize wasserstein distance . wd - match improve different text matching method , method underlie matching model . popular text matching method exploit paper . experimental result base publicly available benchmark show wd - match consistently outperform underlie method baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Joint Estimation and Analysis of Risk Behavior Ratings in Movie Scripts,"Exposure to violent, sexual, or substanceabuse content in media increases the willingness of children and adolescents to imitate similar behaviors. Computational methods that identify portrayals of risk behaviors from audio-visual cues are limited in their applicability to films in post-production, where modifications might be prohibitively expensive. To address this limitation, we propose a model that estimates content ratings based on the language use in movie scripts, making our solution available at the earlier stages of creative production. Our model significantly improves the state-of-the-art by adapting novel techniques to learn better movie representations from the semantic and sentiment aspects of a character's language use, and by leveraging the co-occurrence of risk behaviors, following a multi-task approach. Additionally, we show how this approach can be useful to learn novel insights on the joint portrayal of these behaviors, and on the subtleties that filmmakers may otherwise not pick up on.","Joint Estimation and Analysis of Risk Behavior Ratings in Movie Scripts Exposure to violent, sexual, or substanceabuse content in media increases the willingness of children and adolescents to imitate similar behaviors. Computational methods that identify portrayals of risk behaviors from audio-visual cues are limited in their applicability to films in post-production, where modifications might be prohibitively expensive. To address this limitation, we propose a model that estimates content ratings based on the language use in movie scripts, making our solution available at the earlier stages of creative production. Our model significantly improves the state-of-the-art by adapting novel techniques to learn better movie representations from the semantic and sentiment aspects of a character's language use, and by leveraging the co-occurrence of risk behaviors, following a multi-task approach. Additionally, we show how this approach can be useful to learn novel insights on the joint portrayal of these behaviors, and on the subtleties that filmmakers may otherwise not pick up on.","joint estimation analysis risk behavior rating movie script exposure violent , sexual , substanceabuse content medium increase willingness child adolescent imitate similar behavior . computational method identify portrayal risk behavior audio - visual cue limited applicability film post - production , modification prohibitively expensive . address limitation , propose model estimate content rating base language use movie script , make solution available early stage creative production . model significantly improve state - - - art adapt novel technique learn well movie representation semantic sentiment aspect character language use , leverage co - occurrence risk behavior , follow multi - task approach . additionally , approach useful learn novel insight joint portrayal behavior , subtlety filmmaker pick .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
NLP Applications,Text Segmentation by Cross Segment Attention,"Document and discourse segmentation are two fundamental NLP tasks pertaining to breaking up text into constituents, which are commonly used to help downstream tasks such as information retrieval or text summarization. In this work, we propose three transformer-based architectures and provide comprehensive comparisons with previously proposed approaches on three standard datasets. We establish a new state-of-the-art, reducing in particular the error rates by a large margin in all cases. We further analyze model sizes and find that we can build models with many fewer parameters while keeping good performance, thus facilitating real-world applications.","Text Segmentation by Cross Segment Attention Document and discourse segmentation are two fundamental NLP tasks pertaining to breaking up text into constituents, which are commonly used to help downstream tasks such as information retrieval or text summarization. In this work, we propose three transformer-based architectures and provide comprehensive comparisons with previously proposed approaches on three standard datasets. We establish a new state-of-the-art, reducing in particular the error rates by a large margin in all cases. We further analyze model sizes and find that we can build models with many fewer parameters while keeping good performance, thus facilitating real-world applications.","text segmentation cross segment attention document discourse segmentation fundamental nlp task pertain break text constituent , commonly help downstream task information retrieval text summarization . work , propose transformer - base architecture provide comprehensive comparison previously propose approach standard dataset . establish new state - - - art , reduce particular error rate large margin case . analyze model size find build model few parameter keep good performance , facilitate real - world application .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,To Schedule or not to Schedule: Extracting Task Specific Temporal Entities and Associated Negation Constraints,"State of the art research for date-time 1 entity extraction from text is task agnostic. Consequently, while the methods proposed in literature perform well for generic date-time extraction from texts, they don't fare as well on task specific date-time entity extraction where only a subset of the date-time entities present in the text are pertinent to solving the task. Furthermore, some tasks require identifying negation constraints associated with the date-time entities to correctly reason over time. We showcase a novel model for extracting task-specific date-time entities along with their negation constraints. We show the efficacy of our method on the task of date-time understanding in the context of scheduling meetings for an email-based digital AI scheduling assistant. Our method achieves an absolute gain of 19% f-score points compared to baseline methods in detecting the date-time entities relevant to scheduling meetings and a 4% improvement over baseline methods for detecting negation constraints over date-time entities.","To Schedule or not to Schedule: Extracting Task Specific Temporal Entities and Associated Negation Constraints State of the art research for date-time 1 entity extraction from text is task agnostic. Consequently, while the methods proposed in literature perform well for generic date-time extraction from texts, they don't fare as well on task specific date-time entity extraction where only a subset of the date-time entities present in the text are pertinent to solving the task. Furthermore, some tasks require identifying negation constraints associated with the date-time entities to correctly reason over time. We showcase a novel model for extracting task-specific date-time entities along with their negation constraints. We show the efficacy of our method on the task of date-time understanding in the context of scheduling meetings for an email-based digital AI scheduling assistant. Our method achieves an absolute gain of 19% f-score points compared to baseline methods in detecting the date-time entities relevant to scheduling meetings and a 4% improvement over baseline methods for detecting negation constraints over date-time entities.","schedule schedule : extract task specific temporal entity associated negation constraint state art research date - time 1 entity extraction text task agnostic . consequently , method propose literature perform generic date - time extraction text , fare task specific date - time entity extraction subset date - time entity present text pertinent solve task . furthermore , task require identify negation constraint associate date - time entity correctly reason time . showcase novel model extract task - specific date - time entity negation constraint . efficacy method task date - time understanding context schedule meeting email - base digital ai scheduling assistant . method achieve absolute gain 19 % f - score point compare baseline method detect date - time entity relevant schedule meeting 4 % improvement baseline method detect negation constraint date - time entity .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Textual Data Augmentation for Efficient Active Learning on Tiny Datasets,"In this paper we propose a novel data augmentation approach where guided outputs of a language generation model, e.g. GPT-2, when labeled, can improve the performance of text classifiers through an active learning process. We transform the data generation task into an optimization problem which maximizes the usefulness of the generated output, using Monte Carlo Tree Search (MCTS) as the optimization strategy and incorporating entropy as one of the optimization criteria. We test our approach against a Non-Guided Data Generation (NGDG) process that does not optimize for a reward function. Starting with a small set of data, our results show an increased performance with MCTS of 26% on the TREC-6 Questions dataset, and 10% on the Stanford Sentiment Treebank SST-2 dataset. Compared with NGDG, we are able to achieve increases of 3% and 5% on TREC-6 and SST-2.","Textual Data Augmentation for Efficient Active Learning on Tiny Datasets In this paper we propose a novel data augmentation approach where guided outputs of a language generation model, e.g. GPT-2, when labeled, can improve the performance of text classifiers through an active learning process. We transform the data generation task into an optimization problem which maximizes the usefulness of the generated output, using Monte Carlo Tree Search (MCTS) as the optimization strategy and incorporating entropy as one of the optimization criteria. We test our approach against a Non-Guided Data Generation (NGDG) process that does not optimize for a reward function. Starting with a small set of data, our results show an increased performance with MCTS of 26% on the TREC-6 Questions dataset, and 10% on the Stanford Sentiment Treebank SST-2 dataset. Compared with NGDG, we are able to achieve increases of 3% and 5% on TREC-6 and SST-2.","textual data augmentation efficient active learning tiny dataset paper propose novel data augmentation approach guide output language generation model , e.g. gpt-2 , label , improve performance text classifier active learning process . transform datum generation task optimization problem maximize usefulness generate output , monte carlo tree search ( mcts ) optimization strategy incorporate entropy optimization criterion . test approach non - guided data generation ( ngdg ) process optimize reward function . start small set datum , result increase performance mct 26 % trec-6 questions dataset , 10 % stanford sentiment treebank sst-2 dataset . compare ngdg , able achieve increase 3 % 5 % trec-6 sst-2 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Modeling the Music Genre Perception across Language-Bound Cultures,"The music genre perception expressed through human annotations of artists or albums varies significantly across language-bound cultures. These variations cannot be modeled as mere translations since we also need to account for cultural differences in the music genre perception. In this work, we study the feasibility of obtaining relevant cross-lingual, culturespecific music genre annotations based only on language-specific semantic representations, namely distributed concept embeddings and ontologies. Our study, focused on six languages, shows that unsupervised cross-lingual music genre annotation is feasible with high accuracy, especially when combining both types of representations. This approach of studying music genres is the most extensive to date and has many implications in musicology and music information retrieval. Besides, we introduce a new, domain-dependent crosslingual corpus to benchmark state of the art multilingual pre-trained embedding models.","Modeling the Music Genre Perception across Language-Bound Cultures The music genre perception expressed through human annotations of artists or albums varies significantly across language-bound cultures. These variations cannot be modeled as mere translations since we also need to account for cultural differences in the music genre perception. In this work, we study the feasibility of obtaining relevant cross-lingual, culturespecific music genre annotations based only on language-specific semantic representations, namely distributed concept embeddings and ontologies. Our study, focused on six languages, shows that unsupervised cross-lingual music genre annotation is feasible with high accuracy, especially when combining both types of representations. This approach of studying music genres is the most extensive to date and has many implications in musicology and music information retrieval. Besides, we introduce a new, domain-dependent crosslingual corpus to benchmark state of the art multilingual pre-trained embedding models.","model music genre perception language - bind culture music genre perception express human annotation artist album vary significantly language - bind culture . variation model mere translation need account cultural difference music genre perception . work , study feasibility obtain relevant cross - lingual , culturespecific music genre annotation base language - specific semantic representation , distribute concept embedding ontology . study , focus language , show unsupervised cross - lingual music genre annotation feasible high accuracy , especially combine type representation . approach study music genre extensive date implication musicology music information retrieval . , introduce new , domain - dependent crosslingual corpus benchmark state art multilingual pre - trained embedding model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 6, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
"Phonology, Morphology and Word Segmentation",Coding Textual Inputs Boosts the Accuracy of Neural Networks,"Natural Language Processing (NLP) tasks are usually performed word by word on textual inputs. We can use arbitrary symbols to represent the linguistic meaning of a word and use these symbols as inputs. As ""alternatives"" to a text representation, we introduce Soundex, MetaPhone, NYSIIS, logogram to NLP, and develop fixed-output-length coding and its extension using Huffman coding. Each of those codings combines different character/digital sequences and constructs a new vocabulary based on codewords. We find that the integration of those codewords with text provides more reliable inputs to Neural-Networkbased NLP systems through redundancy than text-alone inputs. Experiments demonstrate that our approach outperforms the state-ofthe-art models on the application of machine translation, language modeling, and part-ofspeech tagging. The source code is available at https://github.com/abdulrafae/coding nmt.","Coding Textual Inputs Boosts the Accuracy of Neural Networks Natural Language Processing (NLP) tasks are usually performed word by word on textual inputs. We can use arbitrary symbols to represent the linguistic meaning of a word and use these symbols as inputs. As ""alternatives"" to a text representation, we introduce Soundex, MetaPhone, NYSIIS, logogram to NLP, and develop fixed-output-length coding and its extension using Huffman coding. Each of those codings combines different character/digital sequences and constructs a new vocabulary based on codewords. We find that the integration of those codewords with text provides more reliable inputs to Neural-Networkbased NLP systems through redundancy than text-alone inputs. Experiments demonstrate that our approach outperforms the state-ofthe-art models on the application of machine translation, language modeling, and part-ofspeech tagging. The source code is available at https://github.com/abdulrafae/coding nmt.","coding textual input boost accuracy neural networks natural language processing ( nlp ) task usually perform word word textual input . use arbitrary symbol represent linguistic meaning word use symbol input . "" alternative "" text representation , introduce soundex , metaphone , nysiis , logogram nlp , develop fix - output - length coding extension huffman coding . coding combine different character / digital sequence construct new vocabulary base codeword . find integration codeword text provide reliable input neural - networkbased nlp system redundancy text - input . experiment demonstrate approach outperform state - ofthe - art model application machine translation , language modeling , - ofspeech tagging . source code available https://github.com/abdulrafae/coding nmt .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Phonology, Morphology and Word Segmentation",A Joint Multiple Criteria Model in Transfer Learning for Cross-domain Chinese Word Segmentation,"Word-level information is important in natural language processing (NLP), especially for the Chinese language due to its high linguistic complexity. Chinese word segmentation (CWS) is an essential task for Chinese downstream NLP tasks. Existing methods have already achieved a competitive performance for CWS on large-scale annotated corpora. However, the accuracy of the method will drop dramatically when it handles an unsegmented text with lots of out-of-vocabulary (OOV) words. In addition, there are many different segmentation criteria for addressing different requirements of downstream NLP tasks. Excessive amounts of models with saving different criteria will generate the explosive growth of the total parameters. To this end, we propose a joint multiple criteria model that shares all parameters to integrate different segmentation criteria into one model. Besides, we utilize a transfer learning method to improve the performance of OOV words. Our proposed method is evaluated by designing comprehensive experiments on multiple benchmark datasets (e.g., Bakeoff 2005, Bakeoff 2008 and SIGHAN 2010). Our method achieves the state-of-the-art performances on all datasets. Importantly, our method also shows a competitive practicability and generalization ability for the CWS task.","A Joint Multiple Criteria Model in Transfer Learning for Cross-domain Chinese Word Segmentation Word-level information is important in natural language processing (NLP), especially for the Chinese language due to its high linguistic complexity. Chinese word segmentation (CWS) is an essential task for Chinese downstream NLP tasks. Existing methods have already achieved a competitive performance for CWS on large-scale annotated corpora. However, the accuracy of the method will drop dramatically when it handles an unsegmented text with lots of out-of-vocabulary (OOV) words. In addition, there are many different segmentation criteria for addressing different requirements of downstream NLP tasks. Excessive amounts of models with saving different criteria will generate the explosive growth of the total parameters. To this end, we propose a joint multiple criteria model that shares all parameters to integrate different segmentation criteria into one model. Besides, we utilize a transfer learning method to improve the performance of OOV words. Our proposed method is evaluated by designing comprehensive experiments on multiple benchmark datasets (e.g., Bakeoff 2005, Bakeoff 2008 and SIGHAN 2010). Our method achieves the state-of-the-art performances on all datasets. Importantly, our method also shows a competitive practicability and generalization ability for the CWS task.","joint multiple criteria model transfer learning cross - domain chinese word segmentation word - level information important natural language processing ( nlp ) , especially chinese language high linguistic complexity . chinese word segmentation ( cws ) essential task chinese downstream nlp task . exist method achieve competitive performance cws large - scale annotate corpus . , accuracy method drop dramatically handle unsegmented text lot - - vocabulary ( oov ) word . addition , different segmentation criterion address different requirement downstream nlp task . excessive amount model save different criterion generate explosive growth total parameter . end , propose joint multiple criterion model share parameter integrate different segmentation criterion model . , utilize transfer learning method improve performance oov word . propose method evaluate design comprehensive experiment multiple benchmark dataset ( e.g. , bakeoff 2005 , bakeoff 2008 sighan 2010 ) . method achieve state - - - art performance dataset . importantly , method show competitive practicability generalization ability cws task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 13, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",IGT2P: From Interlinear Glossed Texts to Paradigms,"An intermediate step in the linguistic analysis of an under-documented language is to find and organize inflected forms that are attested in natural speech. From this data, linguists generate unseen inflected word forms in order to test hypotheses about the language's inflectional patterns and to complete inflectional paradigm tables. To get the data linguists spend many hours manually creating interlinear glossed texts (IGTs). We introduce a new task that speeds this process and automatically generates new morphological resources for natural language processing systems: IGTto-paradigms (IGT2P). IGT2P generates entire morphological paradigms from IGT input. We show that existing morphological reinflection models can solve the task with 21% to 64% accuracy, depending on the language. We further find that (i) having a language expert spend only a few hours cleaning the noisy IGT data improves performance by as much as 21 percentage points, and (ii) POS tags, which are generally considered a necessary part of NLP morphological reinflection input, have no effect on the accuracy of the models considered here.","IGT2P: From Interlinear Glossed Texts to Paradigms An intermediate step in the linguistic analysis of an under-documented language is to find and organize inflected forms that are attested in natural speech. From this data, linguists generate unseen inflected word forms in order to test hypotheses about the language's inflectional patterns and to complete inflectional paradigm tables. To get the data linguists spend many hours manually creating interlinear glossed texts (IGTs). We introduce a new task that speeds this process and automatically generates new morphological resources for natural language processing systems: IGTto-paradigms (IGT2P). IGT2P generates entire morphological paradigms from IGT input. We show that existing morphological reinflection models can solve the task with 21% to 64% accuracy, depending on the language. We further find that (i) having a language expert spend only a few hours cleaning the noisy IGT data improves performance by as much as 21 percentage points, and (ii) POS tags, which are generally considered a necessary part of NLP morphological reinflection input, have no effect on the accuracy of the models considered here.","igt2p : interlinear gloss text paradigm intermediate step linguistic analysis - document language find organize inflected form attest natural speech . data , linguist generate unseen inflected word form order test hypothesis language inflectional pattern complete inflectional paradigm table . data linguist spend hour manually create interlinear glossed text ( igts ) . introduce new task speed process automatically generate new morphological resource natural language processing system : igtto - paradigm ( igt2p ) . igt2p generate entire morphological paradigm igt input . exist morphological reinflection model solve task 21 % 64 % accuracy , depend language . find ( ) have language expert spend hour clean noisy igt datum improve performance 21 percentage point , ( ii ) pos tag , generally consider necessary nlp morphological reinflection input , effect accuracy model consider .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 11, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Attention Is All You Need for Chinese Word Segmentation,"Taking greedy decoding algorithm as it should be, this work focuses on further strengthening the model itself for Chinese word segmentation (CWS), which results in an even more fast and more accurate CWS model. Our model consists of an attention only stacked encoder and a light enough decoder for the greedy segmentation plus two highway connections for smoother training, in which the encoder is composed of a newly proposed Transformer variant, Gaussian-masked Directional (GD) Transformer, and a biaffine attention scorer. With the effective encoder design, our model only needs to take unigram features for scoring. Our model is evaluated on SIGHAN Bakeoff benchmark datasets. The experimental results show that with the highest segmentation speed, the proposed model achieves new state-of-the-art or comparable performance against strong baselines in terms of strict closed test setting.","Attention Is All You Need for Chinese Word Segmentation Taking greedy decoding algorithm as it should be, this work focuses on further strengthening the model itself for Chinese word segmentation (CWS), which results in an even more fast and more accurate CWS model. Our model consists of an attention only stacked encoder and a light enough decoder for the greedy segmentation plus two highway connections for smoother training, in which the encoder is composed of a newly proposed Transformer variant, Gaussian-masked Directional (GD) Transformer, and a biaffine attention scorer. With the effective encoder design, our model only needs to take unigram features for scoring. Our model is evaluated on SIGHAN Bakeoff benchmark datasets. The experimental results show that with the highest segmentation speed, the proposed model achieves new state-of-the-art or comparable performance against strong baselines in terms of strict closed test setting.","attention need chinese word segmentation take greedy decoding algorithm , work focus strengthen model chinese word segmentation ( cws ) , result fast accurate cws model . model consist attention stack encoder light decoder greedy segmentation plus highway connection smooth training , encoder compose newly propose transformer variant , gaussian - masked directional ( gd ) transformer , biaffine attention scorer . effective encoder design , model need unigram feature scoring . model evaluate sighan bakeoff benchmark dataset . experimental result high segmentation speed , propose model achieve new state - - - art comparable performance strong baseline term strict closed test setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Mind Your Inflections! Improving NLP for Non-Standard Englishes with Base-Inflection Encoding,"Inflectional variation is a common feature of World Englishes such as Colloquial Singapore English and African American Vernacular English. Although comprehension by human readers is usually unimpaired by nonstandard inflections, current NLP systems are not yet robust. We propose Base-Inflection Encoding (BITE), a method to tokenize English text by reducing inflected words to their base forms before reinjecting the grammatical information as special symbols. Fine-tuning pretrained NLP models for downstream tasks using our encoding defends against inflectional adversaries while maintaining performance on clean data. Models using BITE generalize better to dialects with non-standard inflections without explicit training and translation models converge faster when trained with BITE. Finally, we show that our encoding improves the vocabulary efficiency of popular data-driven subword tokenizers. Since there has been no prior work on quantitatively evaluating vocabulary efficiency, we propose metrics to do so. 1","Mind Your Inflections! Improving NLP for Non-Standard Englishes with Base-Inflection Encoding Inflectional variation is a common feature of World Englishes such as Colloquial Singapore English and African American Vernacular English. Although comprehension by human readers is usually unimpaired by nonstandard inflections, current NLP systems are not yet robust. We propose Base-Inflection Encoding (BITE), a method to tokenize English text by reducing inflected words to their base forms before reinjecting the grammatical information as special symbols. Fine-tuning pretrained NLP models for downstream tasks using our encoding defends against inflectional adversaries while maintaining performance on clean data. Models using BITE generalize better to dialects with non-standard inflections without explicit training and translation models converge faster when trained with BITE. Finally, we show that our encoding improves the vocabulary efficiency of popular data-driven subword tokenizers. Since there has been no prior work on quantitatively evaluating vocabulary efficiency, we propose metrics to do so. 1","mind inflection ! improve nlp non - standard englishes base - inflection encoding inflectional variation common feature world englishes colloquial singapore english african american vernacular english . comprehension human reader usually unimpaired nonstandard inflection , current nlp system robust . propose base - inflection encoding ( bite ) , method tokenize english text reduce inflect word base form reinjecte grammatical information special symbol . fine - tune pretrained nlp model downstream task encoding defend inflectional adversary maintain performance clean datum . model bite generalize well dialect non - standard inflection explicit training translation model converge fast train bite . finally , encoding improve vocabulary efficiency popular data - drive subword tokenizer . prior work quantitatively evaluate vocabulary efficiency , propose metric . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Automatic Extraction of Rules Governing Morphological Agreement,"Creating a descriptive grammar of a language is an indispensable step for language documentation and preservation. However, at the same time it is a tedious, time-consuming task. In this paper, we take steps towards automating this process by devising an automated framework for extracting a first-pass grammatical specification from raw text in a concise, human-and machine-readable format. We focus on extracting rules describing agreement, a morphosyntactic phenomenon at the core of the grammars of many of the world's languages. We apply our framework to all languages included in the Universal Dependencies project, with promising results. Using cross-lingual transfer, even with no expert annotations in the language of interest, our framework extracts a grammatical specification which is nearly equivalent to those created with large amounts of gold-standard annotated data. We confirm this finding with human expert evaluations of the rules that our framework produces, which have an average accuracy of 78%. We release an interface demonstrating the extracted rules at https: //neulab.github.io/lase/. The code is publicly available here. 1","Automatic Extraction of Rules Governing Morphological Agreement Creating a descriptive grammar of a language is an indispensable step for language documentation and preservation. However, at the same time it is a tedious, time-consuming task. In this paper, we take steps towards automating this process by devising an automated framework for extracting a first-pass grammatical specification from raw text in a concise, human-and machine-readable format. We focus on extracting rules describing agreement, a morphosyntactic phenomenon at the core of the grammars of many of the world's languages. We apply our framework to all languages included in the Universal Dependencies project, with promising results. Using cross-lingual transfer, even with no expert annotations in the language of interest, our framework extracts a grammatical specification which is nearly equivalent to those created with large amounts of gold-standard annotated data. We confirm this finding with human expert evaluations of the rules that our framework produces, which have an average accuracy of 78%. We release an interface demonstrating the extracted rules at https: //neulab.github.io/lase/. The code is publicly available here. 1","automatic extraction rule govern morphological agreement create descriptive grammar language indispensable step language documentation preservation . , time tedious , time - consume task . paper , step automate process devise automate framework extract - pass grammatical specification raw text concise , human - machine - readable format . focus extract rule describe agreement , morphosyntactic phenomenon core grammar world language . apply framework language include universal dependencies project , promising result . cross - lingual transfer , expert annotation language interest , framework extract grammatical specification nearly equivalent create large amount gold - standard annotate datum . confirm finding human expert evaluation rule framework produce , average accuracy 78 % . release interface demonstrate extract rule https : //neulab.github.io / lase/. code publicly available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
"Phonology, Morphology and Word Segmentation",Unsupervised Cross-Lingual Part-of-Speech Tagging for Truly Low-Resource Scenarios,"We describe a fully unsupervised cross-lingual transfer approach for part-of-speech (POS) tagging under a truly low resource scenario. We assume access to parallel translations between the target language and one or more source languages for which POS taggers are available. We use the Bible as parallel data in our experiments: small size, out-of-domain and covering many diverse languages. Our approach innovates in three ways: 1) a robust approach of selecting training instances via cross-lingual annotation projection that exploits best practices of unsupervised type and token constraints, word-alignment confidence and density of projected POS, 2) a Bi-LSTM architecture that uses contextualized word embeddings, affix embeddings and hierarchical Brown clusters, and 3) an evaluation on 12 diverse languages in terms of language family and morphological typology. In spite of the use of limited and out-of-domain parallel data, our experiments demonstrate significant improvements in accuracy over previous work. In addition, we show that using multi-source information, either via projection or output combination, improves the performance for most target languages.","Unsupervised Cross-Lingual Part-of-Speech Tagging for Truly Low-Resource Scenarios We describe a fully unsupervised cross-lingual transfer approach for part-of-speech (POS) tagging under a truly low resource scenario. We assume access to parallel translations between the target language and one or more source languages for which POS taggers are available. We use the Bible as parallel data in our experiments: small size, out-of-domain and covering many diverse languages. Our approach innovates in three ways: 1) a robust approach of selecting training instances via cross-lingual annotation projection that exploits best practices of unsupervised type and token constraints, word-alignment confidence and density of projected POS, 2) a Bi-LSTM architecture that uses contextualized word embeddings, affix embeddings and hierarchical Brown clusters, and 3) an evaluation on 12 diverse languages in terms of language family and morphological typology. In spite of the use of limited and out-of-domain parallel data, our experiments demonstrate significant improvements in accuracy over previous work. In addition, we show that using multi-source information, either via projection or output combination, improves the performance for most target languages.","unsupervised cross - lingual - - speech tagging truly low - resource scenario describe fully unsupervised cross - lingual transfer approach - - speech ( pos ) tagging truly low resource scenario . assume access parallel translation target language source language pos tagger available . use bible parallel datum experiment : small size , - - domain cover diverse language . approach innovate way : 1 ) robust approach select training instance cross - lingual annotation projection exploit good practice unsupervised type token constraint , word - alignment confidence density project pos , 2 ) bi - lstm architecture use contextualized word embedding , affix embedding hierarchical brown cluster , 3 ) evaluation 12 diverse language term language family morphological typology . spite use limited - - domain parallel datum , experiment demonstrate significant improvement accuracy previous work . addition , multi - source information , projection output combination , improve performance target language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,False
"Phonology, Morphology and Word Segmentation",Tackling the Low-resource Challenge for Canonical Segmentation,"Canonical morphological segmentation consists of dividing words into their standardized morphemes. Here, we are interested in approaches for the task when training data is limited. We compare model performance in a simulated low-resource setting for the highresource languages German, English, and Indonesian to experiments on new datasets for the truly low-resource languages Popoluca and Tepehua. We explore two new models for the task, borrowing from the closely related area of morphological generation: an LSTM pointer-generator and a sequence-to-sequence model with hard monotonic attention trained with imitation learning. We find that, in the low-resource setting, the novel approaches outperform existing ones on all languages by up to 11.4% accuracy. However, while accuracy in emulated low-resource scenarios is over 50% for all languages, for the truly lowresource languages Popoluca and Tepehua, our best model only obtains 37.4% and 28.4% accuracy, respectively. Thus, we conclude that canonical segmentation is still a challenging task for low-resource languages.","Tackling the Low-resource Challenge for Canonical Segmentation Canonical morphological segmentation consists of dividing words into their standardized morphemes. Here, we are interested in approaches for the task when training data is limited. We compare model performance in a simulated low-resource setting for the highresource languages German, English, and Indonesian to experiments on new datasets for the truly low-resource languages Popoluca and Tepehua. We explore two new models for the task, borrowing from the closely related area of morphological generation: an LSTM pointer-generator and a sequence-to-sequence model with hard monotonic attention trained with imitation learning. We find that, in the low-resource setting, the novel approaches outperform existing ones on all languages by up to 11.4% accuracy. However, while accuracy in emulated low-resource scenarios is over 50% for all languages, for the truly lowresource languages Popoluca and Tepehua, our best model only obtains 37.4% and 28.4% accuracy, respectively. Thus, we conclude that canonical segmentation is still a challenging task for low-resource languages.","tackle low - resource challenge canonical segmentation canonical morphological segmentation consist divide word standardized morpheme . , interested approach task training data limited . compare model performance simulate low - resource setting highresource language german , english , indonesian experiment new dataset truly low - resource language popoluca tepehua . explore new model task , borrow closely related area morphological generation : lstm pointer - generator sequence - - sequence model hard monotonic attention train imitation learning . find , low - resource setting , novel approach outperform exist one language 11.4 % accuracy . , accuracy emulate low - resource scenario 50 % language , truly lowresource language popoluca tepehua , good model obtain 37.4 % 28.4 % accuracy , respectively . , conclude canonical segmentation challenging task low - resource language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Domain Adaptation of Thai Word Segmentation Models using Stacked Ensemble,"Like many Natural Language Processing tasks, Thai word segmentation is domain-dependent. Researchers have been relying on transfer learning to adapt an existing model to a new domain. However, this approach is inapplicable to cases where we can interact with only input and output layers of the models, also known as ""black boxes"". We propose a filter-and-refine solution based on the stackedensemble learning paradigm to address this black-box limitation. We conducted extensive experimental studies comparing our method against state-of-the-art models and transfer learning. Experimental results show that our proposed solution is an effective domain adaptation method and has a similar performance as the transfer learning method.","Domain Adaptation of Thai Word Segmentation Models using Stacked Ensemble Like many Natural Language Processing tasks, Thai word segmentation is domain-dependent. Researchers have been relying on transfer learning to adapt an existing model to a new domain. However, this approach is inapplicable to cases where we can interact with only input and output layers of the models, also known as ""black boxes"". We propose a filter-and-refine solution based on the stackedensemble learning paradigm to address this black-box limitation. We conducted extensive experimental studies comparing our method against state-of-the-art models and transfer learning. Experimental results show that our proposed solution is an effective domain adaptation method and has a similar performance as the transfer learning method.","domain adaptation thai word segmentation model stack ensemble like natural language processing task , thai word segmentation domain - dependent . researcher rely transfer learning adapt exist model new domain . , approach inapplicable case interact input output layer model , know "" black box "" . propose filter - - refine solution base stackedensemble learning paradigm address black - box limitation . conduct extensive experimental study compare method state - - - art model transfer learning . experimental result propose solution effective domain adaptation method similar performance transfer learning method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",DagoBERT: Generating Derivational Morphology with a Pretrained Language Model,"Can pretrained language models (PLMs) generate derivationally complex words? We present the first study investigating this question, taking BERT as the example PLM. We examine BERT's derivational capabilities in different settings, ranging from using the unmodified pretrained model to full finetuning. Our best model, DagoBERT (Derivationally and generatively optimized BERT), clearly outperforms the previous state of the art in derivation generation (DG). Furthermore, our experiments show that the input segmentation crucially impacts BERT's derivational knowledge, suggesting that the performance of PLMs could be further improved if a morphologically informed vocabulary of units were used.","DagoBERT: Generating Derivational Morphology with a Pretrained Language Model Can pretrained language models (PLMs) generate derivationally complex words? We present the first study investigating this question, taking BERT as the example PLM. We examine BERT's derivational capabilities in different settings, ranging from using the unmodified pretrained model to full finetuning. Our best model, DagoBERT (Derivationally and generatively optimized BERT), clearly outperforms the previous state of the art in derivation generation (DG). Furthermore, our experiments show that the input segmentation crucially impacts BERT's derivational knowledge, suggesting that the performance of PLMs could be further improved if a morphologically informed vocabulary of units were used.","dagobert : generate derivational morphology pretrained language model pretrained language model ( plms ) generate derivationally complex word ? present study investigate question , take bert example plm . examine bert derivational capability different setting , range unmodified pretrained model finetuning . good model , dagobert ( derivationally generatively optimize bert ) , clearly outperform previous state art derivation generation ( dg ) . furthermore , experiment input segmentation crucially impact bert derivational knowledge , suggest performance plms improve morphologically inform vocabulary unit .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Phonology, Morphology and Word Segmentation",Measuring the Similarity of Grammatical Gender Systems by Comparing Partitions,"A grammatical gender system divides a lexicon into a small number of relatively fixed grammatical categories. How similar are these gender systems across languages? To quantify the similarity, we define gender systems extensionally, thereby reducing the problem of comparisons between languages' gender systems to cluster evaluation. We borrow a rich inventory of statistical tools for cluster evaluation from the field of community detection (Driver and Kroeber, 1932; Cattell, 1945) , that enable us to craft novel information-theoretic metrics for measuring similarity between gender systems. We first validate our metrics, then use them to measure gender system similarity in 20 languages. Finally, we ask whether our gender system similarities alone are sufficient to reconstruct historical relationships between languages. Towards this end, we make phylogenetic predictions on the popular, but thorny, problem from historical linguistics of inducing a phylogenetic tree over extant Indo-European languages. Languages on the same branch of our phylogenetic tree are notably similar, whereas languages from separate branches are no more similar than chance.","Measuring the Similarity of Grammatical Gender Systems by Comparing Partitions A grammatical gender system divides a lexicon into a small number of relatively fixed grammatical categories. How similar are these gender systems across languages? To quantify the similarity, we define gender systems extensionally, thereby reducing the problem of comparisons between languages' gender systems to cluster evaluation. We borrow a rich inventory of statistical tools for cluster evaluation from the field of community detection (Driver and Kroeber, 1932; Cattell, 1945) , that enable us to craft novel information-theoretic metrics for measuring similarity between gender systems. We first validate our metrics, then use them to measure gender system similarity in 20 languages. Finally, we ask whether our gender system similarities alone are sufficient to reconstruct historical relationships between languages. Towards this end, we make phylogenetic predictions on the popular, but thorny, problem from historical linguistics of inducing a phylogenetic tree over extant Indo-European languages. Languages on the same branch of our phylogenetic tree are notably similar, whereas languages from separate branches are no more similar than chance.","measure similarity grammatical gender system compare partition grammatical gender system divide lexicon small number relatively fixed grammatical category . similar gender system language ? quantify similarity , define gender system extensionally , reduce problem comparison language ' gender system cluster evaluation . borrow rich inventory statistical tool cluster evaluation field community detection ( driver kroeber , 1932 ; cattell , 1945 ) , enable craft novel information - theoretic metric measure similarity gender system . validate metric , use measure gender system similarity 20 language . finally , ask gender system similarity sufficient reconstruct historical relationship language . end , phylogenetic prediction popular , thorny , problem historical linguistic induce phylogenetic tree extant indo - european language . language branch phylogenetic tree notably similar , language separate branch similar chance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 8, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 9, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 9, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
"Phonology, Morphology and Word Segmentation",Learning to Pronounce Chinese Without a Pronunciation Dictionary,"We demonstrate a program that learns to pronounce Chinese text in Mandarin, without a pronunciation dictionary. From non-parallel streams of Chinese characters and Chinese pinyin syllables, it establishes a many-to-many mapping between characters and pronunciations. Using unsupervised methods, the program effectively deciphers writing into speech. Its token-level character-to-syllable accuracy is 89%, which significantly exceeds the 22% accuracy of prior work.","Learning to Pronounce Chinese Without a Pronunciation Dictionary We demonstrate a program that learns to pronounce Chinese text in Mandarin, without a pronunciation dictionary. From non-parallel streams of Chinese characters and Chinese pinyin syllables, it establishes a many-to-many mapping between characters and pronunciations. Using unsupervised methods, the program effectively deciphers writing into speech. Its token-level character-to-syllable accuracy is 89%, which significantly exceeds the 22% accuracy of prior work.","learn pronounce chinese pronunciation dictionary demonstrate program learn pronounce chinese text mandarin , pronunciation dictionary . non - parallel stream chinese character chinese pinyin syllable , establish - - mapping character pronunciation . unsupervised method , program effectively decipher write speech . token - level character - - syllable accuracy 89 % , significantly exceed 22 % accuracy prior work .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
Question Answering,A Simple and Effective Model for Answering Multi-span Questions,"Models for reading comprehension (RC) commonly restrict their output space to the set of all single contiguous spans from the input, in order to alleviate the learning problem and avoid the need for a model that generates text explicitly. However, forcing an answer to be a single span can be restrictive, and some recent datasets also include multi-span questions, i.e., questions whose answer is a set of non-contiguous spans in the text. Naturally, models that return single spans cannot answer these questions. In this work, we propose a simple architecture for answering multi-span questions by casting the task as a sequence tagging problem, namely, predicting for each input token whether it should be part of the output or not. Our model substantially improves performance on span extraction questions from DROP and QUOREF by 9.9 and 5.5 EM points respectively.","A Simple and Effective Model for Answering Multi-span Questions Models for reading comprehension (RC) commonly restrict their output space to the set of all single contiguous spans from the input, in order to alleviate the learning problem and avoid the need for a model that generates text explicitly. However, forcing an answer to be a single span can be restrictive, and some recent datasets also include multi-span questions, i.e., questions whose answer is a set of non-contiguous spans in the text. Naturally, models that return single spans cannot answer these questions. In this work, we propose a simple architecture for answering multi-span questions by casting the task as a sequence tagging problem, namely, predicting for each input token whether it should be part of the output or not. Our model substantially improves performance on span extraction questions from DROP and QUOREF by 9.9 and 5.5 EM points respectively.","simple effective model answer multi - span question model reading comprehension ( rc ) commonly restrict output space set single contiguous span input , order alleviate learning problem avoid need model generate text explicitly . , force answer single span restrictive , recent dataset include multi - span question , i.e. , question answer set non - contiguous span text . naturally , model return single span answer question . work , propose simple architecture answer multi - span question cast task sequence tagging problem , , predict input token output . model substantially improve performance span extraction question drop quoref 9.9 5.5 em point respectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 15, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Hierarchical Graph Network for Multi-hop Question Answering,"In this paper, we present Hierarchical Graph Network (HGN) for multi-hop question answering. To aggregate clues from scattered texts across multiple paragraphs, a hierarchical graph is created by constructing nodes on different levels of granularity (questions, paragraphs, sentences, entities), the representations of which are initialized with pre-trained contextual encoders. Given this hierarchical graph, the initial node representations are updated through graph propagation, and multihop reasoning is performed via traversing through the graph edges for each subsequent sub-task (e.g., paragraph selection, supporting facts extraction, answer prediction). By weaving heterogeneous nodes into an integral unified graph, this hierarchical differentiation of node granularity enables HGN to support different question answering sub-tasks simultaneously. Experiments on the HotpotQA benchmark demonstrate that the proposed model achieves new state of the art, outperforming existing multi-hop QA approaches. 1","Hierarchical Graph Network for Multi-hop Question Answering In this paper, we present Hierarchical Graph Network (HGN) for multi-hop question answering. To aggregate clues from scattered texts across multiple paragraphs, a hierarchical graph is created by constructing nodes on different levels of granularity (questions, paragraphs, sentences, entities), the representations of which are initialized with pre-trained contextual encoders. Given this hierarchical graph, the initial node representations are updated through graph propagation, and multihop reasoning is performed via traversing through the graph edges for each subsequent sub-task (e.g., paragraph selection, supporting facts extraction, answer prediction). By weaving heterogeneous nodes into an integral unified graph, this hierarchical differentiation of node granularity enables HGN to support different question answering sub-tasks simultaneously. Experiments on the HotpotQA benchmark demonstrate that the proposed model achieves new state of the art, outperforming existing multi-hop QA approaches. 1","hierarchical graph network multi - hop question answering paper , present hierarchical graph network ( hgn ) multi - hop question answering . aggregate clue scatter text multiple paragraph , hierarchical graph create construct node different level granularity ( question , paragraph , sentence , entity ) , representation initialize pre - trained contextual encoder . give hierarchical graph , initial node representation update graph propagation , multihop reasoning perform traverse graph edge subsequent sub - task ( e.g. , paragraph selection , support fact extraction , answer prediction ) . weave heterogeneous node integral unified graph , hierarchical differentiation node granularity enable hgn support different question answer sub - task simultaneously . experiment hotpotqa benchmark demonstrate propose model achieve new state art , outperform existing multi - hop qa approach . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 17, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Few-Shot Complex Knowledge Base Question Answering via Meta Reinforcement Learning,"Complex question-answering (CQA) involves answering complex natural-language questions on a knowledge base (KB). However, the conventional neural program induction (NPI) approach exhibits uneven performance when the questions have different types, harboring inherently different characteristics, e.g., difficulty level. This paper proposes a metareinforcement learning approach to program induction in CQA to tackle the potential distributional bias in questions. Our method quickly and effectively adapts the meta-learned programmer to new questions based on the most similar questions retrieved from the training data. The meta-learned policy is then used to learn a good programming policy, utilizing the trial trajectories and their rewards for similar questions in the support set. Our method achieves state-of-the-art performance on the CQA dataset (Saha et al., 2018) while using only five trial trajectories for the top-5 retrieved questions in each support set, and metatraining on tasks constructed from only 1% of the training set. We have released our code at https://github.com/DevinJake/MRL-CQA.","Few-Shot Complex Knowledge Base Question Answering via Meta Reinforcement Learning Complex question-answering (CQA) involves answering complex natural-language questions on a knowledge base (KB). However, the conventional neural program induction (NPI) approach exhibits uneven performance when the questions have different types, harboring inherently different characteristics, e.g., difficulty level. This paper proposes a metareinforcement learning approach to program induction in CQA to tackle the potential distributional bias in questions. Our method quickly and effectively adapts the meta-learned programmer to new questions based on the most similar questions retrieved from the training data. The meta-learned policy is then used to learn a good programming policy, utilizing the trial trajectories and their rewards for similar questions in the support set. Our method achieves state-of-the-art performance on the CQA dataset (Saha et al., 2018) while using only five trial trajectories for the top-5 retrieved questions in each support set, and metatraining on tasks constructed from only 1% of the training set. We have released our code at https://github.com/DevinJake/MRL-CQA.","- shot complex knowledge base question answering meta reinforcement learning complex question - answering ( cqa ) involve answer complex natural - language question knowledge base ( kb ) . , conventional neural program induction ( npi ) approach exhibit uneven performance question different type , harbor inherently different characteristic , e.g. , difficulty level . paper propose metareinforcement learning approach program induction cqa tackle potential distributional bias question . method quickly effectively adapt meta - learned programmer new question base similar question retrieve training datum . meta - learn policy learn good programming policy , utilize trial trajectory reward similar question support set . method achieve state - - - art performance cqa dataset ( saha et al . , 2018 ) trial trajectory top-5 retrieve question support set , metatraine task construct 1 % training set . release code https://github.com/devinjake/mrl-cqa .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 20, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Unsupervised Adaptation of Question Answering Systems via Generative Self-training,"BERT-era question answering systems have recently achieved impressive performance on several question-answering (QA) tasks. These systems are based on representations that have been pre-trained on self-supervised tasks such as word masking and sentence entailment, using massive amounts of data. Nevertheless, additional pre-training closer to the end-task, such as training on synthetic QA pairs, has been shown to improve performance. While recent work has considered augmenting labelled data and leveraging large unlabelled datasets to generate synthetic QA data, directly adapting to target data has received little attention. In this paper we investigate the iterative generation of synthetic QA pairs as a way to realize unsupervised self adaptation. Motivated by the success of the roundtrip consistency method for filtering generated QA pairs, we present iterative generalizations of the approach, which maximize an approximation of a lower bound on the probability of the adaptation data. By adapting on synthetic QA pairs generated on the target data, our method is able to improve QA systems significantly, using an order of magnitude less synthetic data and training computation than existing augmentation approaches.","Unsupervised Adaptation of Question Answering Systems via Generative Self-training BERT-era question answering systems have recently achieved impressive performance on several question-answering (QA) tasks. These systems are based on representations that have been pre-trained on self-supervised tasks such as word masking and sentence entailment, using massive amounts of data. Nevertheless, additional pre-training closer to the end-task, such as training on synthetic QA pairs, has been shown to improve performance. While recent work has considered augmenting labelled data and leveraging large unlabelled datasets to generate synthetic QA data, directly adapting to target data has received little attention. In this paper we investigate the iterative generation of synthetic QA pairs as a way to realize unsupervised self adaptation. Motivated by the success of the roundtrip consistency method for filtering generated QA pairs, we present iterative generalizations of the approach, which maximize an approximation of a lower bound on the probability of the adaptation data. By adapting on synthetic QA pairs generated on the target data, our method is able to improve QA systems significantly, using an order of magnitude less synthetic data and training computation than existing augmentation approaches.","unsupervised adaptation question answer system generative self - training bert - era question answering system recently achieve impressive performance question - answer ( qa ) task . system base representation pre - train self - supervised task word masking sentence entailment , massive amount datum . , additional pre - training close end - task , training synthetic qa pair , show improve performance . recent work consider augment label datum leverage large unlabelled dataset generate synthetic qa datum , directly adapt target datum receive little attention . paper investigate iterative generation synthetic qa pair way realize unsupervised self adaptation . motivate success roundtrip consistency method filter generate qa pair , present iterative generalization approach , maximize approximation low bound probability adaptation datum . adapt synthetic qa pair generate target datum , method able improve qa system significantly , order magnitude synthetic datum training computation exist augmentation approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 17, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Training Question Answering Models From Synthetic Data,"Question and answer generation is a data augmentation method that aims to improve question answering (QA) models given the limited amount of human labeled data. However, a considerable gap remains between synthetic and human-generated question-answer pairs. This work aims to narrow this gap by taking advantage of large language models and explores several factors such as model size, quality of pretrained models, scale of data synthesized, and algorithmic choices. On the SQUAD1.1 question answering task, we achieve higher accuracy using solely synthetic questions and answers than when using the SQUAD1.1 training set questions alone. Removing access to real Wikipedia data, we synthesize questions and answers from a synthetic text corpus generated by an 8.3 billion parameter GPT-2 model and achieve 88.4 Exact Match (EM) and 93.9 F1 score on the SQUAD1.1 dev set. We further apply our methodology to SQUAD2.0 and show a 2.8 absolute gain on EM score compared to prior work using synthetic data.","Training Question Answering Models From Synthetic Data Question and answer generation is a data augmentation method that aims to improve question answering (QA) models given the limited amount of human labeled data. However, a considerable gap remains between synthetic and human-generated question-answer pairs. This work aims to narrow this gap by taking advantage of large language models and explores several factors such as model size, quality of pretrained models, scale of data synthesized, and algorithmic choices. On the SQUAD1.1 question answering task, we achieve higher accuracy using solely synthetic questions and answers than when using the SQUAD1.1 training set questions alone. Removing access to real Wikipedia data, we synthesize questions and answers from a synthetic text corpus generated by an 8.3 billion parameter GPT-2 model and achieve 88.4 Exact Match (EM) and 93.9 F1 score on the SQUAD1.1 dev set. We further apply our methodology to SQUAD2.0 and show a 2.8 absolute gain on EM score compared to prior work using synthetic data.","train question answer model synthetic data question answer generation data augmentation method aim improve question answering ( qa ) model give limited human label datum . , considerable gap remain synthetic human - generate question - answer pair . work aim narrow gap take advantage large language model explore factor model size , quality pretraine model , scale datum synthesize , algorithmic choice . squad1.1 question answer task , achieve high accuracy solely synthetic question answer squad1.1 training set question . remove access real wikipedia datum , synthesize question answer synthetic text corpus generate 8.3 billion parameter gpt-2 model achieve 88.4 exact match ( em ) 93.9 f1 score squad1.1 dev set . apply methodology squad2.0 2.8 absolute gain em score compare prior work synthetic datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 24, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Don't Read Too Much Into It: Adaptive Computation for Open-Domain Question Answering,"Most approaches to Open-Domain Question Answering consist of a light-weight retriever that selects a set of candidate passages, and a computationally expensive reader that examines the passages to identify the correct answer. Previous works have shown that as the number of retrieved passages increases, so does the performance of the reader. However, they assume all retrieved passages are of equal importance and allocate the same amount of computation to them, leading to a substantial increase in computational cost. To reduce this cost, we propose the use of adaptive computation to control the computational budget allocated for the passages to be read. We first introduce a technique operating on individual passages in isolation which relies on anytime prediction and a per-layer estimation of an early exit probability. We then introduce SKY-LINEBUILDER, an approach for dynamically deciding on which passage to allocate computation at each step, based on a resource allocation policy trained via reinforcement learning. Our results on SQuAD-Open show that adaptive computation with global prioritisation improves over several strong static and adaptive methods, leading to a 4.3x reduction in computation while retaining 95% performance of the full model.","Don't Read Too Much Into It: Adaptive Computation for Open-Domain Question Answering Most approaches to Open-Domain Question Answering consist of a light-weight retriever that selects a set of candidate passages, and a computationally expensive reader that examines the passages to identify the correct answer. Previous works have shown that as the number of retrieved passages increases, so does the performance of the reader. However, they assume all retrieved passages are of equal importance and allocate the same amount of computation to them, leading to a substantial increase in computational cost. To reduce this cost, we propose the use of adaptive computation to control the computational budget allocated for the passages to be read. We first introduce a technique operating on individual passages in isolation which relies on anytime prediction and a per-layer estimation of an early exit probability. We then introduce SKY-LINEBUILDER, an approach for dynamically deciding on which passage to allocate computation at each step, based on a resource allocation policy trained via reinforcement learning. Our results on SQuAD-Open show that adaptive computation with global prioritisation improves over several strong static and adaptive methods, leading to a 4.3x reduction in computation while retaining 95% performance of the full model.","read : adaptive computation open - domain question answering approach open - domain question answering consist light - weight retriever select set candidate passage , computationally expensive reader examine passage identify correct answer . previous work show number retrieve passage increase , performance reader . , assume retrieve passage equal importance allocate computation , lead substantial increase computational cost . reduce cost , propose use adaptive computation control computational budget allocate passage read . introduce technique operate individual passage isolation rely anytime prediction - layer estimation early exit probability . introduce sky - linebuilder , approach dynamically decide passage allocate computation step , base resource allocation policy train reinforcement learning . result squad - open adaptive computation global prioritisation improve strong static adaptive method , lead 4.3x reduction computation retain 95 % performance model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Don't Read Too Much Into It: Adaptive Computation for Open-Domain Question Answering,"Most approaches to Open-Domain Question Answering consist of a light-weight retriever that selects a set of candidate passages, and a computationally expensive reader that examines the passages to identify the correct answer. Previous works have shown that as the number of retrieved passages increases, so does the performance of the reader. However, they assume all retrieved passages are of equal importance and allocate the same amount of computation to them, leading to a substantial increase in computational cost. To reduce this cost, we propose the use of adaptive computation to control the computational budget allocated for the passages to be read. We first introduce a technique operating on individual passages in isolation which relies on anytime prediction and a per-layer estimation of an early exit probability. We then introduce SKY-LINEBUILDER, an approach for dynamically deciding on which passage to allocate computation at each step, based on a resource allocation policy trained via reinforcement learning. Our results on SQuAD-Open show that adaptive computation with global prioritisation improves over several strong static and adaptive methods, leading to a 4.3x reduction in computation while retaining 95% performance of the full model.","Don't Read Too Much Into It: Adaptive Computation for Open-Domain Question Answering Most approaches to Open-Domain Question Answering consist of a light-weight retriever that selects a set of candidate passages, and a computationally expensive reader that examines the passages to identify the correct answer. Previous works have shown that as the number of retrieved passages increases, so does the performance of the reader. However, they assume all retrieved passages are of equal importance and allocate the same amount of computation to them, leading to a substantial increase in computational cost. To reduce this cost, we propose the use of adaptive computation to control the computational budget allocated for the passages to be read. We first introduce a technique operating on individual passages in isolation which relies on anytime prediction and a per-layer estimation of an early exit probability. We then introduce SKY-LINEBUILDER, an approach for dynamically deciding on which passage to allocate computation at each step, based on a resource allocation policy trained via reinforcement learning. Our results on SQuAD-Open show that adaptive computation with global prioritisation improves over several strong static and adaptive methods, leading to a 4.3x reduction in computation while retaining 95% performance of the full model.","read : adaptive computation open - domain question answering approach open - domain question answering consist light - weight retriever select set candidate passage , computationally expensive reader examine passage identify correct answer . previous work show number retrieve passage increase , performance reader . , assume retrieve passage equal importance allocate computation , lead substantial increase computational cost . reduce cost , propose use adaptive computation control computational budget allocate passage read . introduce technique operate individual passage isolation rely anytime prediction - layer estimation early exit probability . introduce sky - linebuilder , approach dynamically decide passage allocate computation step , base resource allocation policy train reinforcement learning . result squad - open adaptive computation global prioritisation improve strong static adaptive method , lead 4.3x reduction computation retain 95 % performance model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,SubjQA: A Dataset for Subjectivity and Review Comprehension,"Subjectivity is the expression of internal opinions or beliefs which cannot be objectively observed or verified, and has been shown to be important for sentiment analysis and wordsense disambiguation. Furthermore, subjectivity is an important aspect of user-generated data. In spite of this, subjectivity has not been investigated in contexts where such data is widespread, such as in question answering (QA). We develop a new dataset which allows us to investigate this relationship. We find that subjectivity is an important feature in the case of QA, albeit with more intricate interactions between subjectivity and QA performance than found in previous work on sentiment analysis. For instance, a subjective question may or may not be associated with a subjective answer. We release an English QA dataset (SUBJQA) based on customer reviews, containing subjectivity annotations for questions and answer spans across 6 domains.","SubjQA: A Dataset for Subjectivity and Review Comprehension Subjectivity is the expression of internal opinions or beliefs which cannot be objectively observed or verified, and has been shown to be important for sentiment analysis and wordsense disambiguation. Furthermore, subjectivity is an important aspect of user-generated data. In spite of this, subjectivity has not been investigated in contexts where such data is widespread, such as in question answering (QA). We develop a new dataset which allows us to investigate this relationship. We find that subjectivity is an important feature in the case of QA, albeit with more intricate interactions between subjectivity and QA performance than found in previous work on sentiment analysis. For instance, a subjective question may or may not be associated with a subjective answer. We release an English QA dataset (SUBJQA) based on customer reviews, containing subjectivity annotations for questions and answer spans across 6 domains.","subjqa : dataset subjectivity review comprehension subjectivity expression internal opinion belief objectively observe verify , show important sentiment analysis wordsense disambiguation . furthermore , subjectivity important aspect user - generate datum . spite , subjectivity investigate context data widespread , question answering ( qa ) . develop new dataset allow investigate relationship . find subjectivity important feature case qa , albeit intricate interaction subjectivity qa performance find previous work sentiment analysis . instance , subjective question associate subjective answer . release english qa dataset ( subjqa ) base customer review , contain subjectivity annotation question answer span 6 domain .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 17, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 7, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,EXAMS: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering,"We propose Eχαµs -a new benchmark dataset for cross-lingual and multilingual question answering for high school examinations. We collected more than 24,000 highquality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others. Eχαµs offers a fine-grained evaluation framework across multiple languages and subjects, which allows precise analysis and comparison of various models. We perform various experiments with existing top-performing multilingual pre-trained models and we show that Eχαµs offers multiple challenges that require multilingual knowledge and reasoning in multiple domains. We hope that Eχαµs will enable researchers to explore challenging reasoning and knowledge transfer methods and pretrained models for school question answering in various languages which was not possible before. The data, code, pre-trained models, and evaluation are available at http:// github.com/mhardalov/exams-qa.","EXAMS: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering We propose Eχαµs -a new benchmark dataset for cross-lingual and multilingual question answering for high school examinations. We collected more than 24,000 highquality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others. Eχαµs offers a fine-grained evaluation framework across multiple languages and subjects, which allows precise analysis and comparison of various models. We perform various experiments with existing top-performing multilingual pre-trained models and we show that Eχαµs offers multiple challenges that require multilingual knowledge and reasoning in multiple domains. We hope that Eχαµs will enable researchers to explore challenging reasoning and knowledge transfer methods and pretrained models for school question answering in various languages which was not possible before. The data, code, pre-trained models, and evaluation are available at http:// github.com/mhardalov/exams-qa.","exams : multi - subject high school examination dataset cross - lingual multilingual question answering propose eχαµs -a new benchmark dataset cross - lingual multilingual question answering high school examination . collect 24,000 highquality high school exam question 16 language , cover 8 language family 24 school subject natural sciences social sciences , . eχαµs offer fine - grained evaluation framework multiple language subject , allow precise analysis comparison model . perform experiment exist - perform multilingual pre - trained model eχαµs offer multiple challenge require multilingual knowledge reasoning multiple domain . hope eχαµs enable researcher explore challenge reasoning knowledge transfer method pretraine model school question answering language possible . datum , code , pre - trained model , evaluation available http:// github.com/mhardalov/exams-qa .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 17, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Learning a Cost-Effective Annotation Policy for Question Answering,"State-of-the-art question answering (QA) relies upon large amounts of training data for which labeling is time consuming and thus expensive. For this reason, customizing QA systems is challenging. As a remedy, we propose a novel framework for annotating QA datasets that entails learning a cost-effective annotation policy and a semi-supervised annotation scheme. The latter reduces the human effort: it leverages the underlying QA system to suggest potential candidate annotations. Human annotators then simply provide binary feedback on these candidates. Our system is designed such that past annotations continuously improve the future performance and thus overall annotation cost. To the best of our knowledge, this is the first paper to address the problem of annotating questions with minimal annotation cost. We compare our framework against traditional manual annotations in an extensive set of experiments. We find that our approach can reduce up to 21.1% of the annotation cost.","Learning a Cost-Effective Annotation Policy for Question Answering State-of-the-art question answering (QA) relies upon large amounts of training data for which labeling is time consuming and thus expensive. For this reason, customizing QA systems is challenging. As a remedy, we propose a novel framework for annotating QA datasets that entails learning a cost-effective annotation policy and a semi-supervised annotation scheme. The latter reduces the human effort: it leverages the underlying QA system to suggest potential candidate annotations. Human annotators then simply provide binary feedback on these candidates. Our system is designed such that past annotations continuously improve the future performance and thus overall annotation cost. To the best of our knowledge, this is the first paper to address the problem of annotating questions with minimal annotation cost. We compare our framework against traditional manual annotations in an extensive set of experiments. We find that our approach can reduce up to 21.1% of the annotation cost.","learn cost - effective annotation policy question answering state - - - art question answering ( qa ) rely large amount training datum labeling time consume expensive . reason , customize qa system challenging . remedy , propose novel framework annotate qa dataset entail learn cost - effective annotation policy semi - supervised annotation scheme . reduce human effort : leverage underlie qa system suggest potential candidate annotation . human annotator simply provide binary feedback candidate . system design past annotation continuously improve future performance overall annotation cost . good knowledge , paper address problem annotate question minimal annotation cost . compare framework traditional manual annotation extensive set experiment . find approach reduce 21.1 % annotation cost .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 15, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Coreferential Reasoning Learning for Language Representation,"Language representation models such as BERT could effectively capture contextual semantic information from plain text, and have been proved to achieve promising results in lots of downstream NLP tasks with appropriate fine-tuning. However, most existing language representation models cannot explicitly handle coreference, which is essential to the coherent understanding of the whole discourse. To address this issue, we present CorefBERT, a novel language representation model that can capture the coreferential relations in context. The experimental results show that, compared with existing baseline models, CorefBERT can achieve significant improvements consistently on various downstream NLP tasks that require coreferential reasoning, while maintaining comparable performance to previous models on other common NLP tasks. The source code and experiment details of this paper can be obtained from https://github. com/thunlp/CorefBERT.","Coreferential Reasoning Learning for Language Representation Language representation models such as BERT could effectively capture contextual semantic information from plain text, and have been proved to achieve promising results in lots of downstream NLP tasks with appropriate fine-tuning. However, most existing language representation models cannot explicitly handle coreference, which is essential to the coherent understanding of the whole discourse. To address this issue, we present CorefBERT, a novel language representation model that can capture the coreferential relations in context. The experimental results show that, compared with existing baseline models, CorefBERT can achieve significant improvements consistently on various downstream NLP tasks that require coreferential reasoning, while maintaining comparable performance to previous models on other common NLP tasks. The source code and experiment details of this paper can be obtained from https://github. com/thunlp/CorefBERT.","coreferential reasoning learning language representation language representation model bert effectively capture contextual semantic information plain text , prove achieve promising result lot downstream nlp task appropriate fine - tuning . , exist language representation model explicitly handle coreference , essential coherent understanding discourse . address issue , present corefbert , novel language representation model capture coreferential relation context . experimental result , compare exist baseline model , corefbert achieve significant improvement consistently downstream nlp task require coreferential reasoning , maintain comparable performance previous model common nlp task . source code experiment detail paper obtain https://github . com / thunlp / corefbert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Question Answering,Dense Passage Retrieval for Open-Domain Question Answering,"Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dualencoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system greatly by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks. 1 * Equal contribution 1 The code and trained models have been released at https://github.com/facebookresearch/DPR.","Dense Passage Retrieval for Open-Domain Question Answering Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dualencoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system greatly by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks. 1 * Equal contribution 1 The code and trained models have been released at https://github.com/facebookresearch/DPR.","dense passage retrieval open - domain question answer open - domain question answering rely efficient passage retrieval select candidate context , traditional sparse vector space model , tf - idf bm25 , de facto method . work , retrieval practically implement dense representation , embedding learn small number question passage simple dualencoder framework . evaluate wide range open - domain qa dataset , dense retriever outperform strong lucene - bm25 system greatly 9%-19 % absolute term top-20 passage retrieval accuracy , help end - - end qa system establish new state - - - art multiple open - domain qa benchmark . 1 * equal contribution 1 code train model release https://github.com/facebookresearch/dpr .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 12, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Is Graph Structure Necessary for Multi-hop Question Answering?,"Recently, attempting to model texts as graph structure and introducing graph neural networks to deal with it has become a trend in many NLP research areas. In this paper, we investigate whether the graph structure is necessary for multi-hop question answering. Our analysis is centered on HotpotQA. We construct a strong baseline model to establish that, with the proper use of pre-trained models, graph structure may not be necessary for multi-hop question answering. We point out that both graph structure and adjacency matrix are task-related prior knowledge, and graphattention can be considered as a special case of self-attention. Experiments and visualized analysis demonstrate that graph-attention or the entire graph structure can be replaced by self-attention or Transformers.","Is Graph Structure Necessary for Multi-hop Question Answering? Recently, attempting to model texts as graph structure and introducing graph neural networks to deal with it has become a trend in many NLP research areas. In this paper, we investigate whether the graph structure is necessary for multi-hop question answering. Our analysis is centered on HotpotQA. We construct a strong baseline model to establish that, with the proper use of pre-trained models, graph structure may not be necessary for multi-hop question answering. We point out that both graph structure and adjacency matrix are task-related prior knowledge, and graphattention can be considered as a special case of self-attention. Experiments and visualized analysis demonstrate that graph-attention or the entire graph structure can be replaced by self-attention or Transformers.","graph structure necessary multi - hop question answering ? recently , attempt model text graph structure introduce graph neural network deal trend nlp research area . paper , investigate graph structure necessary multi - hop question answering . analysis center hotpotqa . construct strong baseline model establish , proper use pre - trained model , graph structure necessary multi - hop question answering . point graph structure adjacency matrix task - relate prior knowledge , graphattention consider special case self - attention . experiment visualize analysis demonstrate graph - attention entire graph structure replace self - attention transformers .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 16, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,More Bang for Your Buck: Natural Perturbation for Robust Question Answering,"Deep learning models for linguistic tasks require large training datasets, which are expensive to create. As an alternative to the traditional approach of creating new instances by repeating the process of creating one instance, we propose doing so by first collecting a set of seed examples and then applying humandriven natural perturbations (as opposed to rule-based machine perturbations), which often change the gold label as well. Such perturbations have the advantage of being relatively easier (and hence cheaper) to create than writing out completely new examples. Further, they help address the issue that even models achieving human-level scores on NLP datasets are known to be considerably sensitive to small changes in input. To evaluate the idea, we consider a recent question-answering dataset (BOOLQ) and study our approach as a function of the perturbation cost ratio, the relative cost of perturbing an existing question vs. creating a new one from scratch. We find that when natural perturbations are moderately cheaper to create (cost ratio under 60%), it is more effective to use them for training BOOLQ models: such models exhibit 9% higher robustness and 4.5% stronger generalization, while retaining performance on the original BOOLQ dataset.","More Bang for Your Buck: Natural Perturbation for Robust Question Answering Deep learning models for linguistic tasks require large training datasets, which are expensive to create. As an alternative to the traditional approach of creating new instances by repeating the process of creating one instance, we propose doing so by first collecting a set of seed examples and then applying humandriven natural perturbations (as opposed to rule-based machine perturbations), which often change the gold label as well. Such perturbations have the advantage of being relatively easier (and hence cheaper) to create than writing out completely new examples. Further, they help address the issue that even models achieving human-level scores on NLP datasets are known to be considerably sensitive to small changes in input. To evaluate the idea, we consider a recent question-answering dataset (BOOLQ) and study our approach as a function of the perturbation cost ratio, the relative cost of perturbing an existing question vs. creating a new one from scratch. We find that when natural perturbations are moderately cheaper to create (cost ratio under 60%), it is more effective to use them for training BOOLQ models: such models exhibit 9% higher robustness and 4.5% stronger generalization, while retaining performance on the original BOOLQ dataset.","bang buck : natural perturbation robust question answering deep learning model linguistic task require large training dataset , expensive create . alternative traditional approach create new instance repeat process create instance , propose collect set seed example apply humandriven natural perturbation ( oppose rule - base machine perturbation ) , change gold label . perturbation advantage relatively easy ( cheap ) create write completely new example . , help address issue model achieve human - level score nlp dataset know considerably sensitive small change input . evaluate idea , consider recent question - answer dataset ( boolq ) study approach function perturbation cost ratio , relative cost perturb exist question vs. create new scratch . find natural perturbation moderately cheap create ( cost ratio 60 % ) , effective use train boolq model : model exhibit 9 % high robustness 4.5 % strong generalization , retain performance original boolq dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 8, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,What do Models Learn from Question Answering Datasets?,"While models have reached superhuman performance on popular question answering (QA) datasets such as SQuAD, they have yet to outperform humans on the task of question answering itself. In this paper, we investigate if models are learning reading comprehension from QA datasets by evaluating BERT-based models across five datasets. We evaluate models on their generalizability to out-of-domain examples, responses to missing or incorrect data, and ability to handle question variations. We find that no single dataset is robust to all of our experiments and identify shortcomings in both datasets and evaluation methods. Following our analysis, we make recommendations for building future QA datasets that better evaluate the task of question answering through reading comprehension. We also release code to convert QA datasets to a shared format for easier experimentation at https: //github.com/amazon-research/ qa-dataset-converter.","What do Models Learn from Question Answering Datasets? While models have reached superhuman performance on popular question answering (QA) datasets such as SQuAD, they have yet to outperform humans on the task of question answering itself. In this paper, we investigate if models are learning reading comprehension from QA datasets by evaluating BERT-based models across five datasets. We evaluate models on their generalizability to out-of-domain examples, responses to missing or incorrect data, and ability to handle question variations. We find that no single dataset is robust to all of our experiments and identify shortcomings in both datasets and evaluation methods. Following our analysis, we make recommendations for building future QA datasets that better evaluate the task of question answering through reading comprehension. We also release code to convert QA datasets to a shared format for easier experimentation at https: //github.com/amazon-research/ qa-dataset-converter.","model learn question answer dataset ? model reach superhuman performance popular question answer ( qa ) dataset squad , outperform human task question answering . paper , investigate model learn reading comprehension qa dataset evaluate bert - base model dataset . evaluate model generalizability - - domain example , response miss incorrect datum , ability handle question variation . find single dataset robust experiment identify shortcoming dataset evaluation method . follow analysis , recommendation build future qa dataset well evaluate task question answering reading comprehension . release code convert qa dataset share format easy experimentation https : //github.com / amazon - research/ qa - dataset - converter .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 28, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,AmbigQA: Answering Ambiguous Open-domain Questions,"Ambiguity is inherent to open-domain question answering; especially when exploring new topics, it can be difficult to ask questions that have a single, unambiguous answer. In this paper, we introduce AMBIGQA, a new open-domain question answering task which involves finding every plausible answer, and then rewriting the question for each one to resolve the ambiguity. To study this task, we construct AMBIGNQ, a dataset covering 14,042 questions from NQ-OPEN, an existing opendomain QA benchmark. We find that over half of the questions in NQ-OPEN are ambiguous, with diverse sources of ambiguity such as event and entity references. We also present strong baseline models for AMBIGQA which we show benefit from weakly supervised learning that incorporates NQ-OPEN, strongly suggesting our new task and data will support significant future research effort. Our data and baselines are available at https://nlp.cs. washington.edu/ambigqa.","AmbigQA: Answering Ambiguous Open-domain Questions Ambiguity is inherent to open-domain question answering; especially when exploring new topics, it can be difficult to ask questions that have a single, unambiguous answer. In this paper, we introduce AMBIGQA, a new open-domain question answering task which involves finding every plausible answer, and then rewriting the question for each one to resolve the ambiguity. To study this task, we construct AMBIGNQ, a dataset covering 14,042 questions from NQ-OPEN, an existing opendomain QA benchmark. We find that over half of the questions in NQ-OPEN are ambiguous, with diverse sources of ambiguity such as event and entity references. We also present strong baseline models for AMBIGQA which we show benefit from weakly supervised learning that incorporates NQ-OPEN, strongly suggesting our new task and data will support significant future research effort. Our data and baselines are available at https://nlp.cs. washington.edu/ambigqa.","ambigqa : answer ambiguous open - domain question ambiguity inherent open - domain question answering ; especially explore new topic , difficult ask question single , unambiguous answer . paper , introduce ambigqa , new open - domain question answering task involve find plausible answer , rewrite question resolve ambiguity . study task , construct ambignq , dataset cover 14,042 question nq - open , exist opendomain qa benchmark . find half question nq - open ambiguous , diverse source ambiguity event entity reference . present strong baseline model ambigqa benefit weakly supervise learning incorporate nq - open , strongly suggest new task datum support significant future research effort . datum baseline available https://nlp.cs . washington.edu/ambigqa .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 23, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Towards Interpretable Reasoning over Paragraph Effects in Situation,"We focus on the task of reasoning over paragraph effects in situation, which requires a model to understand the cause and effect described in a background paragraph, and apply the knowledge to a novel situation. Existing works ignore the complicated reasoning process and solve it with a one-step ""black box"" model. Inspired by human cognitive processes, in this paper we propose a sequential approach for this task which explicitly models each step of the reasoning process with neural network modules. In particular, five reasoning modules are designed and learned in an end-to-end manner, which leads to a more interpretable model. Experimental results on the ROPES dataset demonstrate the effectiveness and explainability of our proposed approach.","Towards Interpretable Reasoning over Paragraph Effects in Situation We focus on the task of reasoning over paragraph effects in situation, which requires a model to understand the cause and effect described in a background paragraph, and apply the knowledge to a novel situation. Existing works ignore the complicated reasoning process and solve it with a one-step ""black box"" model. Inspired by human cognitive processes, in this paper we propose a sequential approach for this task which explicitly models each step of the reasoning process with neural network modules. In particular, five reasoning modules are designed and learned in an end-to-end manner, which leads to a more interpretable model. Experimental results on the ROPES dataset demonstrate the effectiveness and explainability of our proposed approach.","interpretable reasoning paragraph effect situation focus task reason paragraph effect situation , require model understand cause effect describe background paragraph , apply knowledge novel situation . exist work ignore complicated reasoning process solve - step "" black box "" model . inspire human cognitive process , paper propose sequential approach task explicitly model step reasoning process neural network module . particular , reasoning module design learn end - - end manner , lead interpretable model . experimental result ropes dataset demonstrate effectiveness explainability propose approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Question Answering,Distilling Structured Knowledge for Text-Based Relational Reasoning,"There is an increasing interest in developing text-based relational reasoning systems, which are capable of systematically reasoning about the relationships between entities mentioned in a text. However, there remains a substantial performance gap between NLP models for relational reasoning and models based on graph neural networks (GNNs), which have access to an underlying symbolic representation of the text. In this work, we investigate how the structured knowledge of a GNN can be distilled into various NLP models in order to improve their performance. We first pre-train a GNN on a reasoning task using structured inputs and then incorporate its knowledge into an NLP model (e.g., an LSTM) via knowledge distillation. To overcome the difficulty of crossmodal knowledge transfer, we also employ a contrastive learning based module to align the latent representations of NLP models and the GNN. We test our approach with two state-ofthe-art NLP models on 12 different inductive reasoning datasets from the CLUTRR benchmark and obtain significant improvements.","Distilling Structured Knowledge for Text-Based Relational Reasoning There is an increasing interest in developing text-based relational reasoning systems, which are capable of systematically reasoning about the relationships between entities mentioned in a text. However, there remains a substantial performance gap between NLP models for relational reasoning and models based on graph neural networks (GNNs), which have access to an underlying symbolic representation of the text. In this work, we investigate how the structured knowledge of a GNN can be distilled into various NLP models in order to improve their performance. We first pre-train a GNN on a reasoning task using structured inputs and then incorporate its knowledge into an NLP model (e.g., an LSTM) via knowledge distillation. To overcome the difficulty of crossmodal knowledge transfer, we also employ a contrastive learning based module to align the latent representations of NLP models and the GNN. We test our approach with two state-ofthe-art NLP models on 12 different inductive reasoning datasets from the CLUTRR benchmark and obtain significant improvements.","distil structured knowledge text - base relational reasoning increase interest develop text - base relational reasoning system , capable systematically reason relationship entity mention text . , remain substantial performance gap nlp model relational reasoning model base graph neural network ( gnns ) , access underlie symbolic representation text . work , investigate structure knowledge gnn distil nlp model order improve performance . pre - train gnn reasoning task structure input incorporate knowledge nlp model ( e.g. , lstm ) knowledge distillation . overcome difficulty crossmodal knowledge transfer , employ contrastive learning base module align latent representation nlp model gnn . test approach state - ofthe - art nlp model 12 different inductive reasoning dataset clutrr benchmark obtain significant improvement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Question Answering,PRover: Proof Generation for Interpretable Reasoning over Rules,"Recent work by Clark et al. (2020) shows that transformers can act as ""soft theorem provers"" by answering questions over explicitly provided knowledge in natural language. In our work, we take a step closer to emulating formal theorem provers, by proposing PROVER, an interpretable transformer-based model that jointly answers binary questions over rule-bases and generates the corresponding proofs. Our model learns to predict nodes and edges corresponding to proof graphs in an efficient constrained training paradigm. During inference, a valid proof, satisfying a set of global constraints is generated. We conduct experiments on synthetic, hand-authored, and human-paraphrased rule-bases to show promising results for QA and proof generation, with strong generalization performance. First, PROVER generates proofs with an accuracy of 87%, while retaining or improving performance on the QA task, compared to RuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trained on questions requiring lower depths of reasoning, it generalizes significantly better to higher depths (up to 15% improvement). Third, PROVER obtains near perfect QA accuracy of 98% using only 40% of the training data. However, generating proofs for questions requiring higher depths of reasoning becomes challenging, and the accuracy drops to 65% for ""depth 5"", indicating significant scope for future work. 1 Facts : F 1 : The bald eagle eats the lion. F2: The bald eagle sees the tiger. F3: The lion chases the bald eagle. F 4 : The lion eats the mouse. F5: The mouse eats the tiger. F6: The tiger eats the bald eagle. F 7 : The tiger is red. Rules : R1: If the lion is green and the lion is not kind then the lion sees the bald eagle. R2: If someone sees the lion then they eat the mouse. R 3 : If someone is kind and not green then they see the bald eagle. R4: If someone is rough then they see the lion. R5: If someone sees the lion and they do not eat the tiger then the tiger is rough. R 6 : If someone eats the bald eagle and the bald eagle is not kind then the bald eagle is rough. R7: If someone does not eat the lion then the lion is big. R8: If someone is kind then they do not eat the mouse.","PRover: Proof Generation for Interpretable Reasoning over Rules Recent work by Clark et al. (2020) shows that transformers can act as ""soft theorem provers"" by answering questions over explicitly provided knowledge in natural language. In our work, we take a step closer to emulating formal theorem provers, by proposing PROVER, an interpretable transformer-based model that jointly answers binary questions over rule-bases and generates the corresponding proofs. Our model learns to predict nodes and edges corresponding to proof graphs in an efficient constrained training paradigm. During inference, a valid proof, satisfying a set of global constraints is generated. We conduct experiments on synthetic, hand-authored, and human-paraphrased rule-bases to show promising results for QA and proof generation, with strong generalization performance. First, PROVER generates proofs with an accuracy of 87%, while retaining or improving performance on the QA task, compared to RuleTakers (up to 6% improvement on zero-shot evaluation). Second, when trained on questions requiring lower depths of reasoning, it generalizes significantly better to higher depths (up to 15% improvement). Third, PROVER obtains near perfect QA accuracy of 98% using only 40% of the training data. However, generating proofs for questions requiring higher depths of reasoning becomes challenging, and the accuracy drops to 65% for ""depth 5"", indicating significant scope for future work. 1 Facts : F 1 : The bald eagle eats the lion. F2: The bald eagle sees the tiger. F3: The lion chases the bald eagle. F 4 : The lion eats the mouse. F5: The mouse eats the tiger. F6: The tiger eats the bald eagle. F 7 : The tiger is red. Rules : R1: If the lion is green and the lion is not kind then the lion sees the bald eagle. R2: If someone sees the lion then they eat the mouse. R 3 : If someone is kind and not green then they see the bald eagle. R4: If someone is rough then they see the lion. R5: If someone sees the lion and they do not eat the tiger then the tiger is rough. R 6 : If someone eats the bald eagle and the bald eagle is not kind then the bald eagle is rough. R7: If someone does not eat the lion then the lion is big. R8: If someone is kind then they do not eat the mouse.","prover : proof generation interpretable reasoning rule recent work clark et al . ( 2020 ) show transformer act "" soft theorem prover "" answer question explicitly provide knowledge natural language . work , step close emulate formal theorem prover , propose prover , interpretable transformer - base model jointly answer binary question rule - basis generate correspond proof . model learn predict node edge correspond proof graph efficient constrained training paradigm . inference , valid proof , satisfy set global constraint generate . conduct experiment synthetic , hand - author , human - paraphrase rule - basis promising result qa proof generation , strong generalization performance . , prover generate proof accuracy 87 % , retain improve performance qa task , compare ruletakers ( 6 % improvement zero - shot evaluation ) . second , train question require low depth reasoning , generalize significantly well high depth ( 15 % improvement ) . , prover obtain near perfect qa accuracy 98 % 40 % training datum . , generate proof question require high depth reasoning challenging , accuracy drop 65 % "" depth 5 "" , indicate significant scope future work . 1 fact : f 1 : bald eagle eat lion . f2 : bald eagle see tiger . f3 : lion chase bald eagle . f 4 : lion eat mouse . f5 : mouse eat tiger . f6 : tiger eat bald eagle . f 7 : tiger red . rule : r1 : lion green lion kind lion see bald eagle . r2 : see lion eat mouse . r 3 : kind green bald eagle . r4 : rough lion . r5 : see lion eat tiger tiger rough . r 6 : eat bald eagle bald eagle kind bald eagle rough . r7 : eat lion lion big . r8 : kind eat mouse .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 9, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Question Answering,True
Question Answering,Scene Restoring for Narrative Machine Reading Comprehension,"This paper focuses on machine reading comprehension for narrative passages. Narrative passages usually describe a chain of events. When reading this kind of passage, humans tend to restore a scene according to the text with their prior knowledge, which helps them understand the passage comprehensively. Inspired by this behavior of humans, we propose a method to let the machine imagine a scene during reading narrative for better comprehension. Specifically, we build a scene graph by utilizing Atomic as the external knowledge and propose a novel Graph Dimensional-Iteration Network (GDIN) to encode the graph. We conduct experiments on the ROCStories, a dataset of Story Cloze Test (SCT), and Cos-mosQA, a dataset of multiple choice. Our method achieves state-of-the-art.","Scene Restoring for Narrative Machine Reading Comprehension This paper focuses on machine reading comprehension for narrative passages. Narrative passages usually describe a chain of events. When reading this kind of passage, humans tend to restore a scene according to the text with their prior knowledge, which helps them understand the passage comprehensively. Inspired by this behavior of humans, we propose a method to let the machine imagine a scene during reading narrative for better comprehension. Specifically, we build a scene graph by utilizing Atomic as the external knowledge and propose a novel Graph Dimensional-Iteration Network (GDIN) to encode the graph. We conduct experiments on the ROCStories, a dataset of Story Cloze Test (SCT), and Cos-mosQA, a dataset of multiple choice. Our method achieves state-of-the-art.","scene restoring narrative machine reading comprehension paper focus machine reading comprehension narrative passage . narrative passage usually describe chain event . read kind passage , human tend restore scene accord text prior knowledge , help understand passage comprehensively . inspire behavior human , propose method let machine imagine scene read narrative well comprehension . specifically , build scene graph utilize atomic external knowledge propose novel graph dimensional - iteration network ( gdin ) encode graph . conduct experiment rocstorie , dataset story cloze test ( sct ) , cos - mosqa , dataset multiple choice . method achieve state - - - art .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 10, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Unsupervised Question Decomposition for Question Answering,"We aim to improve question answering (QA) by decomposing hard questions into simpler sub-questions that existing QA systems are capable of answering. Since labeling questions with decompositions is cumbersome, we take an unsupervised approach to produce sub-questions, also enabling us to leverage millions of questions from the internet. Specifically, we propose an algorithm for One-to-N Unsupervised Sequence transduction (ONUS) that learns to map one hard, multi-hop question to many simpler, singlehop sub-questions. We answer sub-questions with an off-the-shelf QA model and give the resulting answers to a recomposition model that combines them into a final answer. We show large QA improvements on HOTPOTQA over a strong baseline on the original, out-ofdomain, and multi-hop dev sets. ONUS automatically learns to decompose different kinds of questions, while matching the utility of supervised and heuristic decomposition methods for QA and exceeding those methods in fluency. Qualitatively, we find that using subquestions is promising for shedding light on why a QA system makes a prediction. 1 * KC was a part-time research scientist at Facebook AI Research while working on this paper. 1 Our code, data, and pretrained models are available at https://github.com/facebookresearch/ UnsupervisedDecomposition.","Unsupervised Question Decomposition for Question Answering We aim to improve question answering (QA) by decomposing hard questions into simpler sub-questions that existing QA systems are capable of answering. Since labeling questions with decompositions is cumbersome, we take an unsupervised approach to produce sub-questions, also enabling us to leverage millions of questions from the internet. Specifically, we propose an algorithm for One-to-N Unsupervised Sequence transduction (ONUS) that learns to map one hard, multi-hop question to many simpler, singlehop sub-questions. We answer sub-questions with an off-the-shelf QA model and give the resulting answers to a recomposition model that combines them into a final answer. We show large QA improvements on HOTPOTQA over a strong baseline on the original, out-ofdomain, and multi-hop dev sets. ONUS automatically learns to decompose different kinds of questions, while matching the utility of supervised and heuristic decomposition methods for QA and exceeding those methods in fluency. Qualitatively, we find that using subquestions is promising for shedding light on why a QA system makes a prediction. 1 * KC was a part-time research scientist at Facebook AI Research while working on this paper. 1 Our code, data, and pretrained models are available at https://github.com/facebookresearch/ UnsupervisedDecomposition.","unsupervised question decomposition question answering aim improve question answering ( qa ) decompose hard question simple sub - question exist qa system capable answer . label question decomposition cumbersome , unsupervised approach produce sub - question , enable leverage million question internet . specifically , propose algorithm - - n unsupervised sequence transduction ( onus ) learn map hard , multi - hop question simple , singlehop sub - question . answer sub - question - - shelf qa model result answer recomposition model combine final answer . large qa improvement hotpotqa strong baseline original , - ofdomain , multi - hop dev set . onus automatically learn decompose different kind question , match utility supervised heuristic decomposition method qa exceed method fluency . qualitatively , find subquestion promising shed light qa system make prediction . 1 * kc - time research scientist facebook ai research work paper . 1 code , datum , pretrained model available https://github.com/facebookresearch/ unsuperviseddecomposition .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 32, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,IIRC: A Dataset of Incomplete Information Reading Comprehension Questions,"Humans often have to read multiple documents to address their information needs. However, most existing reading comprehension (RC) tasks only focus on questions for which the contexts provide all the information required to answer them, thus not evaluating a system's performance at identifying a potential lack of sufficient information and locating sources for that information. To fill this gap, we present a dataset, IIRC, with more than 13K questions over paragraphs from English Wikipedia that provide only partial information to answer them, with the missing information occurring in one or more linked documents. The questions were written by crowd workers who did not have access to any of the linked documents, leading to questions that have little lexical overlap with the contexts where the answers appear. This process also gave many questions without answers, and those that require discrete reasoning, increasing the difficulty of the task. We follow recent modeling work on various reading comprehension datasets to construct a baseline model for this dataset, finding that it achieves 31.1% F1 on this task, while estimated human performance is 88.4%. The dataset, code for the baseline system, and a leaderboard can be found at https://allennlp.org/iirc.","IIRC: A Dataset of Incomplete Information Reading Comprehension Questions Humans often have to read multiple documents to address their information needs. However, most existing reading comprehension (RC) tasks only focus on questions for which the contexts provide all the information required to answer them, thus not evaluating a system's performance at identifying a potential lack of sufficient information and locating sources for that information. To fill this gap, we present a dataset, IIRC, with more than 13K questions over paragraphs from English Wikipedia that provide only partial information to answer them, with the missing information occurring in one or more linked documents. The questions were written by crowd workers who did not have access to any of the linked documents, leading to questions that have little lexical overlap with the contexts where the answers appear. This process also gave many questions without answers, and those that require discrete reasoning, increasing the difficulty of the task. We follow recent modeling work on various reading comprehension datasets to construct a baseline model for this dataset, finding that it achieves 31.1% F1 on this task, while estimated human performance is 88.4%. The dataset, code for the baseline system, and a leaderboard can be found at https://allennlp.org/iirc.","iirc : dataset incomplete information reading comprehension question human read multiple document address information need . , exist reading comprehension ( rc ) task focus question context provide information require answer , evaluate system performance identify potential lack sufficient information locate source information . fill gap , present dataset , iirc , 13 k question paragraph english wikipedia provide partial information answer , miss information occur link document . question write crowd worker access link document , lead question little lexical overlap context answer appear . process give question answer , require discrete reasoning , increase difficulty task . follow recent modeling work reading comprehension dataset construct baseline model dataset , find achieve 31.1 % f1 task , estimate human performance 88.4 % . dataset , code baseline system , leaderboard find https://allennlp.org/iirc .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 20, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Self-Supervised Knowledge Triplet Learning for Zero-Shot Question Answering,"The aim of all Question Answering (QA) systems is to generalize to unseen questions. Current supervised methods are reliant on expensive data annotation. Moreover, such annotations can introduce unintended annotator bias, making systems focus more on the bias than the actual task. This work proposes Knowledge Triplet Learning (KTL), a self-supervised task over knowledge graphs. We propose heuristics to create synthetic graphs for commonsense and scientific knowledge. We propose using KTL to perform zero-shot question answering, and our experiments show considerable improvements over large pre-trained transformer language models.","Self-Supervised Knowledge Triplet Learning for Zero-Shot Question Answering The aim of all Question Answering (QA) systems is to generalize to unseen questions. Current supervised methods are reliant on expensive data annotation. Moreover, such annotations can introduce unintended annotator bias, making systems focus more on the bias than the actual task. This work proposes Knowledge Triplet Learning (KTL), a self-supervised task over knowledge graphs. We propose heuristics to create synthetic graphs for commonsense and scientific knowledge. We propose using KTL to perform zero-shot question answering, and our experiments show considerable improvements over large pre-trained transformer language models.","self - supervised knowledge triplet learning zero - shot question answering aim question answering ( qa ) system generalize unseen question . current supervise method reliant expensive datum annotation . , annotation introduce unintended annotator bias , make system focus bias actual task . work propose knowledge triplet learning ( ktl ) , self - supervise task knowledge graph . propose heuristic create synthetic graph commonsense scientific knowledge . propose ktl perform zero - shot question answering , experiment considerable improvement large pre - trained transformer language model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 17, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected Reasoning,"Has there been real progress in multi-hop question-answering? Models often exploit dataset artifacts to produce correct answers, without connecting information across multiple supporting facts. This limits our ability to measure true progress and defeats the purpose of building multi-hop QA datasets. We make three contributions towards addressing this. First, we formalize such undesirable behavior as disconnected reasoning across subsets of supporting facts. This allows developing a model-agnostic probe for measuring how much any model can cheat via disconnected reasoning. Second, using a notion of contrastive support sufficiency, we introduce an automatic transformation of existing datasets that reduces the amount of disconnected reasoning. Third, our experiments 1 suggest that there hasn't been much progress in multifact QA in the reading comprehension setting. For a recent large-scale model (XLNet), we show that only 18 points out of its answer F1 score of 72 on HotpotQA are obtained through multifact reasoning, roughly the same as that of a simpler RNN baseline. Our transformation substantially reduces disconnected reasoning (19 points in answer F1). It is complementary to adversarial approaches, yielding further reductions in conjunction.","Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected Reasoning Has there been real progress in multi-hop question-answering? Models often exploit dataset artifacts to produce correct answers, without connecting information across multiple supporting facts. This limits our ability to measure true progress and defeats the purpose of building multi-hop QA datasets. We make three contributions towards addressing this. First, we formalize such undesirable behavior as disconnected reasoning across subsets of supporting facts. This allows developing a model-agnostic probe for measuring how much any model can cheat via disconnected reasoning. Second, using a notion of contrastive support sufficiency, we introduce an automatic transformation of existing datasets that reduces the amount of disconnected reasoning. Third, our experiments 1 suggest that there hasn't been much progress in multifact QA in the reading comprehension setting. For a recent large-scale model (XLNet), we show that only 18 points out of its answer F1 score of 72 on HotpotQA are obtained through multifact reasoning, roughly the same as that of a simpler RNN baseline. Our transformation substantially reduces disconnected reasoning (19 points in answer F1). It is complementary to adversarial approaches, yielding further reductions in conjunction.","multihop qa dire condition ? measure reduce disconnected reasoning real progress multi - hop question - answering ? model exploit dataset artifact produce correct answer , connect information multiple support fact . limit ability measure true progress defeat purpose build multi - hop qa dataset . contribution address . , formalize undesirable behavior disconnected reasoning subset support fact . allow develop model - agnostic probe measure model cheat disconnected reasoning . second , notion contrastive support sufficiency , introduce automatic transformation exist dataset reduce disconnected reasoning . , experiment 1 suggest progress multifact qa reading comprehension setting . recent large - scale model ( xlnet ) , 18 point answer f1 score 72 hotpotqa obtain multifact reasoning , roughly simple rnn baseline . transformation substantially reduce disconnected reasoning ( 19 point answer f1 ) . complementary adversarial approach , yield reduction conjunction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 13, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Question Answering,True
Question Answering,TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions,"A critical part of reading is being able to understand the temporal relationships between events described in a passage of text, even when those relationships are not explicitly stated. However, current machine reading comprehension benchmarks have practically no questions that test temporal phenomena, so systems trained on these benchmarks have no capacity to answer questions such as ""what happened before/after [some event]?"" We introduce TORQUE, a new English reading comprehension benchmark built on 3.2k news snippets with 21k human-generated questions querying temporal relationships. Results show that RoBERTa-large achieves an exact-match score of 51% on the test set of TORQUE, about 30% behind human performance. 1","TORQUE: A Reading Comprehension Dataset of Temporal Ordering Questions A critical part of reading is being able to understand the temporal relationships between events described in a passage of text, even when those relationships are not explicitly stated. However, current machine reading comprehension benchmarks have practically no questions that test temporal phenomena, so systems trained on these benchmarks have no capacity to answer questions such as ""what happened before/after [some event]?"" We introduce TORQUE, a new English reading comprehension benchmark built on 3.2k news snippets with 21k human-generated questions querying temporal relationships. Results show that RoBERTa-large achieves an exact-match score of 51% on the test set of TORQUE, about 30% behind human performance. 1","torque : reading comprehension dataset temporal ordering question critical reading able understand temporal relationship event describe passage text , relationship explicitly state . , current machine reading comprehension benchmark practically question test temporal phenomenon , system train benchmark capacity answer question "" happen / [ event ] ? "" introduce torque , new english reading comprehension benchmark build 3.2k news snippet 21k human - generate question query temporal relationship . result roberta - large achieve exact - match score 51 % test set torque , 30 % human performance . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 16, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,End-to-End Synthetic Data Generation for Domain Adaptation of Question Answering Systems,"We propose an end-to-end approach for synthetic QA data generation. Our model comprises a single transformer-based encoderdecoder network that is trained end-to-end to generate both answers and questions. In a nutshell, we feed a passage to the encoder and ask the decoder to generate a question and an answer token-by-token. The likelihood produced in the generation process is used as a filtering score, which avoids the need for a separate filtering model. Our generator is trained by finetuning a pretrained LM using maximum likelihood estimation. The experimental results indicate significant improvements in the domain adaptation of QA models outperforming current state-of-the-art methods. * *equal contribution. † Siamak Shakeri is currently with Google. The work was done when he was at AWS AI.","End-to-End Synthetic Data Generation for Domain Adaptation of Question Answering Systems We propose an end-to-end approach for synthetic QA data generation. Our model comprises a single transformer-based encoderdecoder network that is trained end-to-end to generate both answers and questions. In a nutshell, we feed a passage to the encoder and ask the decoder to generate a question and an answer token-by-token. The likelihood produced in the generation process is used as a filtering score, which avoids the need for a separate filtering model. Our generator is trained by finetuning a pretrained LM using maximum likelihood estimation. The experimental results indicate significant improvements in the domain adaptation of QA models outperforming current state-of-the-art methods. * *equal contribution. † Siamak Shakeri is currently with Google. The work was done when he was at AWS AI.","end - - end synthetic datum generation domain adaptation question answering system propose end - - end approach synthetic qa datum generation . model comprise single transformer - base encoderdecoder network train end - - end generate answer question . nutshell , feed passage encoder ask decoder generate question answer token - - token . likelihood produce generation process filtering score , avoid need separate filtering model . generator train finetune pretraine lm maximum likelihood estimation . experimental result indicate significant improvement domain adaptation qa model outperform current state - - - art method . * * equal contribution . † siamak shakeri currently google . work aws ai .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 12, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Tell Me How to Ask Again: Question Data Augmentation with Controllable Rewriting in Continuous Space,"In this paper, we propose a novel data augmentation method, referred to as Controllable Rewriting based Question Data Augmentation (CRQDA), for machine reading comprehension (MRC), question generation, and question-answering natural language inference tasks. We treat the question data augmentation task as a constrained question rewriting problem to generate context-relevant, high-quality, and diverse question data samples. CRQDA utilizes a Transformer autoencoder to map the original discrete question into a continuous embedding space. It then uses a pre-trained MRC model to revise the question representation iteratively with gradientbased optimization. Finally, the revised question representations are mapped back into the discrete space, which serve as additional question data. Comprehensive experiments on SQuAD 2.0, SQuAD 1.1 question generation, and QNLI tasks demonstrate the effectiveness of CRQDA 1 .","Tell Me How to Ask Again: Question Data Augmentation with Controllable Rewriting in Continuous Space In this paper, we propose a novel data augmentation method, referred to as Controllable Rewriting based Question Data Augmentation (CRQDA), for machine reading comprehension (MRC), question generation, and question-answering natural language inference tasks. We treat the question data augmentation task as a constrained question rewriting problem to generate context-relevant, high-quality, and diverse question data samples. CRQDA utilizes a Transformer autoencoder to map the original discrete question into a continuous embedding space. It then uses a pre-trained MRC model to revise the question representation iteratively with gradientbased optimization. Finally, the revised question representations are mapped back into the discrete space, which serve as additional question data. Comprehensive experiments on SQuAD 2.0, SQuAD 1.1 question generation, and QNLI tasks demonstrate the effectiveness of CRQDA 1 .","tell ask : question datum augmentation controllable rewriting continuous space paper , propose novel data augmentation method , refer controllable rewriting base question data augmentation ( crqda ) , machine reading comprehension ( mrc ) , question generation , question - answer natural language inference task . treat question datum augmentation task constrained question rewriting problem generate context - relevant , high - quality , diverse question datum sample . crqda utilize transformer autoencoder map original discrete question continuous embed space . use pre - trained mrc model revise question representation iteratively gradientbased optimization . finally , revise question representation map discrete space , serve additional question datum . comprehensive experiment squad 2.0 , squad 1.1 question generation , qnli task demonstrate effectiveness crqda 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 17, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Multi-Step Inference for Reasoning Over Paragraphs,"Complex reasoning over text requires understanding and chaining together free-form predicates and logical connectives. Prior work has largely tried to do this either symbolically or with black-box transformers. We present a middle ground between these two extremes: a compositional model reminiscent of neural module networks that can perform chained logical reasoning. This model first finds relevant sentences in the context and then chains them together using neural modules. Our model gives significant performance improvements (up to 29% relative error reduction when combined with a reranker) on ROPES, a recentlyintroduced complex reasoning dataset.","Multi-Step Inference for Reasoning Over Paragraphs Complex reasoning over text requires understanding and chaining together free-form predicates and logical connectives. Prior work has largely tried to do this either symbolically or with black-box transformers. We present a middle ground between these two extremes: a compositional model reminiscent of neural module networks that can perform chained logical reasoning. This model first finds relevant sentences in the context and then chains them together using neural modules. Our model gives significant performance improvements (up to 29% relative error reduction when combined with a reranker) on ROPES, a recentlyintroduced complex reasoning dataset.","multi - step inference reasoning paragraph complex reasoning text require understand chain free - form predicate logical connective . prior work largely try symbolically black - box transformer . present middle ground extreme : compositional model reminiscent neural module network perform chain logical reasoning . model find relevant sentence context chain neural module . model give significant performance improvement ( 29 % relative error reduction combine reranker ) ropes , recentlyintroduce complex reasoning dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Question Answering,ISAAQ - Mastering Textbook Questions with Pre-trained Transformers and Bottom-Up and Top-Down Attention,"Textbook Question Answering is a complex task in the intersection of Machine Comprehension and Visual Question Answering that requires reasoning with multimodal information from text and diagrams. For the first time, this paper taps on the potential of transformer language models and bottom-up and top-down attention to tackle the language and visual understanding challenges this task entails. Rather than training a language-visual transformer from scratch we rely on pretrained transformers, fine-tuning and ensembling. We add bottom-up and top-down attention to identify regions of interest corresponding to diagram constituents and their relationships, improving the selection of relevant visual information for each question and answer options. Our system ISAAQ reports unprecedented success in all TQA question types, with accuracies of 81.36%, 71.11% and 55.12% on true/false, text-only and diagram multiple choice questions. ISAAQ also demonstrates its broad applicability, obtaining state-of-theart results in other demanding datasets.","ISAAQ - Mastering Textbook Questions with Pre-trained Transformers and Bottom-Up and Top-Down Attention Textbook Question Answering is a complex task in the intersection of Machine Comprehension and Visual Question Answering that requires reasoning with multimodal information from text and diagrams. For the first time, this paper taps on the potential of transformer language models and bottom-up and top-down attention to tackle the language and visual understanding challenges this task entails. Rather than training a language-visual transformer from scratch we rely on pretrained transformers, fine-tuning and ensembling. We add bottom-up and top-down attention to identify regions of interest corresponding to diagram constituents and their relationships, improving the selection of relevant visual information for each question and answer options. Our system ISAAQ reports unprecedented success in all TQA question types, with accuracies of 81.36%, 71.11% and 55.12% on true/false, text-only and diagram multiple choice questions. ISAAQ also demonstrates its broad applicability, obtaining state-of-theart results in other demanding datasets.","isaaq - master textbook question pre - trained transformer - - attention textbook question answering complex task intersection machine comprehension visual question answering require reason multimodal information text diagram . time , paper tap potential transformer language model - - attention tackle language visual understanding challenge task entail . train language - visual transformer scratch rely pretrained transformer , fine - tuning ensembling . add - - attention identify region interest correspond diagram constituent relationship , improve selection relevant visual information question answer option . system isaaq report unprecedented success tqa question type , accuracy 81.36 % , 71.11 % 55.12 % true / false , text - diagram multiple choice question . isaaq demonstrate broad applicability , obtain state - - theart result demanding dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 18, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,AnswerFact: Fact Checking in Product Question Answering,"Product-related question answering platforms nowadays are widely employed in many Ecommerce sites, providing a convenient way for potential customers to address their concerns during online shopping. However, the misinformation in the answers on those platforms poses unprecedented challenges for users to obtain reliable and truthful product information, which may even cause a commercial loss in E-commerce business. To tackle this issue, we investigate to predict the veracity of answers in this paper and introduce Answer-Fact, a large scale fact checking dataset from product question answering forums. Each answer is accompanied by its veracity label and associated evidence sentences, providing a valuable testbed for evidence-based fact checking tasks in QA settings. We further propose a novel neural model with tailored evidence ranking components to handle the concerned answer veracity prediction problem. Extensive experiments are conducted with our proposed model and various existing fact checking methods, showing that our method outperforms all baselines on this task.","AnswerFact: Fact Checking in Product Question Answering Product-related question answering platforms nowadays are widely employed in many Ecommerce sites, providing a convenient way for potential customers to address their concerns during online shopping. However, the misinformation in the answers on those platforms poses unprecedented challenges for users to obtain reliable and truthful product information, which may even cause a commercial loss in E-commerce business. To tackle this issue, we investigate to predict the veracity of answers in this paper and introduce Answer-Fact, a large scale fact checking dataset from product question answering forums. Each answer is accompanied by its veracity label and associated evidence sentences, providing a valuable testbed for evidence-based fact checking tasks in QA settings. We further propose a novel neural model with tailored evidence ranking components to handle the concerned answer veracity prediction problem. Extensive experiments are conducted with our proposed model and various existing fact checking methods, showing that our method outperforms all baselines on this task.","answerfact : fact checking product question answering product - relate question answering platform nowadays widely employ ecommerce site , provide convenient way potential customer address concern online shopping . , misinformation answer platform pose unprecedented challenge user obtain reliable truthful product information , cause commercial loss e - commerce business . tackle issue , investigate predict veracity answer paper introduce answer - fact , large scale fact checking dataset product question answering forum . answer accompany veracity label associate evidence sentence , provide valuable testbed evidence - base fact checking task qa setting . propose novel neural model tailored evidence rank component handle concerned answer veracity prediction problem . extensive experiment conduct propose model exist fact checking method , show method outperform baseline task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 22, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Multi-Stage Pre-training for Low-Resource Domain Adaptation,"Transfer learning techniques are particularly useful in NLP tasks where a sizable amount of high-quality annotated data is difficult to obtain. Current approaches directly adapt a pretrained language model (LM) on in-domain text before fine-tuning to downstream tasks. We show that extending the vocabulary of the LM with domain-specific terms leads to further gains. To a bigger effect, we utilize structure in the unlabeled data to create auxiliary synthetic tasks, which helps the LM transfer to downstream tasks. We apply these approaches incrementally on a pre-trained Roberta-large LM and show considerable performance gain on three tasks in the IT domain: Extractive Reading Comprehension, Document Ranking and Duplicate Question Detection.","Multi-Stage Pre-training for Low-Resource Domain Adaptation Transfer learning techniques are particularly useful in NLP tasks where a sizable amount of high-quality annotated data is difficult to obtain. Current approaches directly adapt a pretrained language model (LM) on in-domain text before fine-tuning to downstream tasks. We show that extending the vocabulary of the LM with domain-specific terms leads to further gains. To a bigger effect, we utilize structure in the unlabeled data to create auxiliary synthetic tasks, which helps the LM transfer to downstream tasks. We apply these approaches incrementally on a pre-trained Roberta-large LM and show considerable performance gain on three tasks in the IT domain: Extractive Reading Comprehension, Document Ranking and Duplicate Question Detection.","multi - stage pre - training low - resource domain adaptation transfer learning technique particularly useful nlp task sizable high - quality annotate datum difficult obtain . current approach directly adapt pretrained language model ( lm ) - domain text fine - tune downstream task . extend vocabulary lm domain - specific term lead gain . big effect , utilize structure unlabeled datum create auxiliary synthetic task , help lm transfer downstream task . apply approach incrementally pre - trained roberta - large lm considerable performance gain task domain : extractive reading comprehension , document ranking duplicate question detection .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 4, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Question Answering,ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning,"Given questions regarding some prototypical situation -such as Name something that people usually do before they leave the house for work? -a human can easily answer them via acquired experiences. There can be multiple right answers for such questions, with some more common for a situation than others. This paper introduces a new question answering dataset for training and evaluating common sense reasoning capabilities of artificial intelligence systems in such prototypical situations. The training set is gathered from an existing set of questions played in a longrunning international game show -FAMILY-FEUD. The hidden evaluation set is created by gathering answers for each question from 100 crowd-workers. We also propose a generative evaluation task where a model has to output a ranked list of answers, ideally covering all prototypical answers for a question. After presenting multiple competitive baseline models, we find that human performance still exceeds model scores on all evaluation metrics with a meaningful gap, supporting the challenging nature of the task. * Equal contribution.","ProtoQA: A Question Answering Dataset for Prototypical Common-Sense Reasoning Given questions regarding some prototypical situation -such as Name something that people usually do before they leave the house for work? -a human can easily answer them via acquired experiences. There can be multiple right answers for such questions, with some more common for a situation than others. This paper introduces a new question answering dataset for training and evaluating common sense reasoning capabilities of artificial intelligence systems in such prototypical situations. The training set is gathered from an existing set of questions played in a longrunning international game show -FAMILY-FEUD. The hidden evaluation set is created by gathering answers for each question from 100 crowd-workers. We also propose a generative evaluation task where a model has to output a ranked list of answers, ideally covering all prototypical answers for a question. After presenting multiple competitive baseline models, we find that human performance still exceeds model scores on all evaluation metrics with a meaningful gap, supporting the challenging nature of the task. * Equal contribution.","protoqa : question answer dataset prototypical common - sense reasoning give question prototypical situation -such people usually leave house work ? -a human easily answer acquire experience . multiple right answer question , common situation . paper introduce new question answer dataset train evaluate common sense reasoning capability artificial intelligence system prototypical situation . training set gather exist set question play longrunne international game -family - feud . hidden evaluation set create gather answer question 100 crowd - worker . propose generative evaluation task model output rank list answer , ideally cover prototypical answer question . present multiple competitive baseline model , find human performance exceed model score evaluation metric meaningful gap , support challenging nature task . * equal contribution .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 17, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Discern: Discourse-Aware Entailment Reasoning Network for Conversational Machine Reading,"Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose DISCERN, a discourse-aware entailment reasoning network to strengthen the connection and enhance the understanding for both document and dialog. Specifically, we split the document into clause-like elementary discourse units (EDU) using a pre-trained discourse segmentation model, and we train our model in a weakly-supervised manner to predict whether each EDU is entailed by the user feedback in a conversation. Based on the learned EDU and entailment representations, we either reply to the user our final decision ""yes/no/irrelevant"" of the initial question, or generate a follow-up question to inquiry more information. Our experiments on the ShARC benchmark (blind, held-out test set) show that DISCERN achieves state-ofthe-art results of 78.3% macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question generation. Code and models are released at https://github.com/ Yifan-Gao/Discern.","Discern: Discourse-Aware Entailment Reasoning Network for Conversational Machine Reading Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose DISCERN, a discourse-aware entailment reasoning network to strengthen the connection and enhance the understanding for both document and dialog. Specifically, we split the document into clause-like elementary discourse units (EDU) using a pre-trained discourse segmentation model, and we train our model in a weakly-supervised manner to predict whether each EDU is entailed by the user feedback in a conversation. Based on the learned EDU and entailment representations, we either reply to the user our final decision ""yes/no/irrelevant"" of the initial question, or generate a follow-up question to inquiry more information. Our experiments on the ShARC benchmark (blind, held-out test set) show that DISCERN achieves state-ofthe-art results of 78.3% macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question generation. Code and models are released at https://github.com/ Yifan-Gao/Discern.","discern : discourse - aware entailment reasoning network conversational machine reading document interpretation dialog understanding major challenge conversational machine reading . work , propose discern , discourse - aware entailment reasoning network strengthen connection enhance understanding document dialog . specifically , split document clause - like elementary discourse unit ( edu ) pre - trained discourse segmentation model , train model weakly - supervise manner predict edu entail user feedback conversation . base learn edu entailment representation , reply user final decision "" yes / / irrelevant "" initial question , generate follow - question inquiry information . experiment sharc benchmark ( blind , hold - test set ) discern achieve state - ofthe - art result 78.3 % macro - averaged accuracy decision making 64.0 bleu1 follow - question generation . code model release https://github.com/ yifan - gao / discern .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 5, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Question Directed Graph Attention Network for Numerical Reasoning over Text,"Numerical reasoning over texts, such as addition, subtraction, sorting and counting, is a challenging machine reading comprehension task, since it requires both natural language understanding and arithmetic computation. To address this challenge, we propose a heterogeneous graph representation for the context of the passage and question needed for such reasoning, and design a question directed graph attention network to drive multi-step numerical reasoning over this context graph. Our model, which combines deep learning and graph reasoning, achieves remarkable results in benchmark datasets such as DROP 1 . * Corresponding author 1 https://leaderboard.allenai.org/drop/submissions/public. As of September 08, 2020, our models are ranked first in the case of fair comparison using the identical pre-training model.","Question Directed Graph Attention Network for Numerical Reasoning over Text Numerical reasoning over texts, such as addition, subtraction, sorting and counting, is a challenging machine reading comprehension task, since it requires both natural language understanding and arithmetic computation. To address this challenge, we propose a heterogeneous graph representation for the context of the passage and question needed for such reasoning, and design a question directed graph attention network to drive multi-step numerical reasoning over this context graph. Our model, which combines deep learning and graph reasoning, achieves remarkable results in benchmark datasets such as DROP 1 . * Corresponding author 1 https://leaderboard.allenai.org/drop/submissions/public. As of September 08, 2020, our models are ranked first in the case of fair comparison using the identical pre-training model.","question direct graph attention network numerical reasoning text numerical reasoning text , addition , subtraction , sorting counting , challenging machine reading comprehension task , require natural language understanding arithmetic computation . address challenge , propose heterogeneous graph representation context passage question need reasoning , design question direct graph attention network drive multi - step numerical reasoning context graph . model , combine deep learning graph reasoning , achieve remarkable result benchmark dataset drop 1 . * correspond author 1 https://leaderboard.allenai.org/drop/submissions/public . september 08 , 2020 , model rank case fair comparison identical pre - training model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Question Answering,SRLGRN: Semantic Role Labeling Graph Reasoning Network,"This work deals with the challenge of learning and reasoning over multi-hop question answering (QA). We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed graph is a heterogeneous document-level graph that contains nodes of type sentence (question, title, and other sentences), and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models.","SRLGRN: Semantic Role Labeling Graph Reasoning Network This work deals with the challenge of learning and reasoning over multi-hop question answering (QA). We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed graph is a heterogeneous document-level graph that contains nodes of type sentence (question, title, and other sentences), and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models.","srlgrn : semantic role labeling graph reasoning network work deal challenge learn reason multi - hop question answering ( qa ) . propose graph reasoning network base semantic structure sentence learn cross paragraph reasoning path find support fact answer jointly . propose graph heterogeneous document - level graph contain node type sentence ( question , title , sentence ) , semantic role labeling sub - graph sentence contain argument node predicate edge . incorporate argument type , argument phrase , semantic edge originate srl predicate graph encoder help finding explainability reasoning path . propose approach show competitive performance hotpotqa distractor set benchmark compare recent state - - - art model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 9, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 14, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Question Answering,Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering,"Despite the rapid progress in multihop question-answering (QA), models still have trouble explaining why an answer is correct, with limited explanation training data available to learn from. To address this, we introduce three explanation datasets in which explanations formed from corpus facts are annotated. Our first dataset, eQASC, contains over 98K explanation annotations for the multihop question answering dataset QASC, and is the first that annotates multiple candidate explanations for each answer. The second dataset eQASC-perturbed is constructed by crowd-sourcing perturbations (while preserving their validity) of a subset of explanations in QASC, to test consistency and generalization of explanation prediction models. The third dataset eOBQA is constructed by adding explanation annotations to the OBQA dataset to test generalization of models trained on eQASC. We show that this data can be used to significantly improve explanation quality (+14% absolute F1 over a strong retrieval baseline) using a BERT-based classifier, but still behind the upper bound, offering a new challenge for future research. We also explore a delexicalized chain representation in which repeated noun phrases are replaced by variables, thus turning them into generalized reasoning chains (for example: ""X is a Y"" AND ""Y has Z"" IMPLIES ""X has Z""). We find that generalized chains maintain performance while also being more robust to certain perturbations. 1","Learning to Explain: Datasets and Models for Identifying Valid Reasoning Chains in Multihop Question-Answering Despite the rapid progress in multihop question-answering (QA), models still have trouble explaining why an answer is correct, with limited explanation training data available to learn from. To address this, we introduce three explanation datasets in which explanations formed from corpus facts are annotated. Our first dataset, eQASC, contains over 98K explanation annotations for the multihop question answering dataset QASC, and is the first that annotates multiple candidate explanations for each answer. The second dataset eQASC-perturbed is constructed by crowd-sourcing perturbations (while preserving their validity) of a subset of explanations in QASC, to test consistency and generalization of explanation prediction models. The third dataset eOBQA is constructed by adding explanation annotations to the OBQA dataset to test generalization of models trained on eQASC. We show that this data can be used to significantly improve explanation quality (+14% absolute F1 over a strong retrieval baseline) using a BERT-based classifier, but still behind the upper bound, offering a new challenge for future research. We also explore a delexicalized chain representation in which repeated noun phrases are replaced by variables, thus turning them into generalized reasoning chains (for example: ""X is a Y"" AND ""Y has Z"" IMPLIES ""X has Z""). We find that generalized chains maintain performance while also being more robust to certain perturbations. 1","learn explain : dataset model identify valid reasoning chain multihop question - answering despite rapid progress multihop question - answering ( qa ) , model trouble explain answer correct , limited explanation training datum available learn . address , introduce explanation dataset explanation form corpus fact annotate . dataset , eqasc , contain 98 k explanation annotation multihop question answering dataset qasc , annotate multiple candidate explanation answer . second dataset eqasc - perturb construct crowd - source perturbation ( preserve validity ) subset explanation qasc , test consistency generalization explanation prediction model . dataset eobqa construct add explanation annotation obqa dataset test generalization model train eqasc . datum significantly improve explanation quality ( +14 % absolute f1 strong retrieval baseline ) bert - base classifier , upper bound , offer new challenge future research . explore delexicalized chain representation repeat noun phrase replace variable , turn generalized reasoning chain ( example : "" x y "" "" y z "" imply "" x z "" ) . find generalize chain maintain performance robust certain perturbation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 10, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 21, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,A Simple Yet Strong Pipeline for HotpotQA,"State-of-the-art models for multi-hop question answering typically augment large-scale language models like BERT with additional, intuitively useful capabilities such as named entity recognition, graph-based reasoning, and question decomposition. However, does their strong performance on popular multihop datasets really justify this added design complexity? Our results suggest that the answer may be no, because even our simple pipeline based on BERT, named QUARK, performs surprisingly well. Specifically, on Hot-potQA, QUARK outperforms these models on both question answering and support identification (and achieves performance very close to a RoBERTa model). Our pipeline has three steps: 1) use BERT to identify potentially relevant sentences independently of each other; 2) feed the set of selected sentences as context into a standard BERT span prediction model to choose an answer; and 3) use the sentence selection model, now with the chosen answer, to produce supporting sentences. The strong performance of QUARK resurfaces the importance of carefully exploring simple model designs before using popular benchmarks to justify the value of complex techniques.","A Simple Yet Strong Pipeline for HotpotQA State-of-the-art models for multi-hop question answering typically augment large-scale language models like BERT with additional, intuitively useful capabilities such as named entity recognition, graph-based reasoning, and question decomposition. However, does their strong performance on popular multihop datasets really justify this added design complexity? Our results suggest that the answer may be no, because even our simple pipeline based on BERT, named QUARK, performs surprisingly well. Specifically, on Hot-potQA, QUARK outperforms these models on both question answering and support identification (and achieves performance very close to a RoBERTa model). Our pipeline has three steps: 1) use BERT to identify potentially relevant sentences independently of each other; 2) feed the set of selected sentences as context into a standard BERT span prediction model to choose an answer; and 3) use the sentence selection model, now with the chosen answer, to produce supporting sentences. The strong performance of QUARK resurfaces the importance of carefully exploring simple model designs before using popular benchmarks to justify the value of complex techniques.","simple strong pipeline hotpotqa state - - - art model multi - hop question answering typically augment large - scale language model like bert additional , intuitively useful capability name entity recognition , graph - base reasoning , question decomposition . , strong performance popular multihop dataset justify add design complexity ? result suggest answer , simple pipeline base bert , name quark , perform surprisingly . specifically , hot - potqa , quark outperform model question answering support identification ( achieve performance close roberta model ) . pipeline step : 1 ) use bert identify potentially relevant sentence independently ; 2 ) feed set select sentence context standard bert span prediction model choose answer ; 3 ) use sentence selection model , choose answer , produce support sentence . strong performance quark resurface importance carefully explore simple model design popular benchmark justify value complex technique .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 16, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,How Much Knowledge Can You Pack Into the Parameters of a Language Model?,"It has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales with model size and performs competitively with open-domain systems that explicitly retrieve answers from an external knowledge source when answering questions. To facilitate reproducibility and future work, we release our code and trained models. 1","How Much Knowledge Can You Pack Into the Parameters of a Language Model? It has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales with model size and performs competitively with open-domain systems that explicitly retrieve answers from an external knowledge source when answering questions. To facilitate reproducibility and future work, we release our code and trained models. 1","knowledge pack parameter language model ? recently observe neural language model train unstructured text implicitly store retrieve knowledge natural language query . short paper , measure practical utility approach fine - tune pre - train model answer question access external context knowledge . approach scale model size perform competitively open - domain system explicitly retrieve answer external knowledge source answer question . facilitate reproducibility future work , release code train model . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Look at the First Sentence: Position Bias in Question Answering,"Many extractive question answering models are trained to predict start and end positions of answers. The choice of predicting answers as positions is mainly due to its simplicity and effectiveness. In this study, we hypothesize that when the distribution of the answer positions is highly skewed in the training set (e.g., answers lie only in the k-th sentence of each passage), QA models predicting answers as positions can learn spurious positional cues and fail to give answers in different positions. We first illustrate this position bias in popular extractive QA models such as BiDAF and BERT and thoroughly examine how position bias propagates through each layer of BERT. To safely deliver position information without position bias, we train models with various de-biasing methods including entropy regularization and bias ensembling. Among them, we found that using the prior distribution of answer positions as a bias model is very effective at reducing position bias, recovering the performance of BERT from 37.48% to 81.64% when trained on a biased SQuAD dataset.","Look at the First Sentence: Position Bias in Question Answering Many extractive question answering models are trained to predict start and end positions of answers. The choice of predicting answers as positions is mainly due to its simplicity and effectiveness. In this study, we hypothesize that when the distribution of the answer positions is highly skewed in the training set (e.g., answers lie only in the k-th sentence of each passage), QA models predicting answers as positions can learn spurious positional cues and fail to give answers in different positions. We first illustrate this position bias in popular extractive QA models such as BiDAF and BERT and thoroughly examine how position bias propagates through each layer of BERT. To safely deliver position information without position bias, we train models with various de-biasing methods including entropy regularization and bias ensembling. Among them, we found that using the prior distribution of answer positions as a bias model is very effective at reducing position bias, recovering the performance of BERT from 37.48% to 81.64% when trained on a biased SQuAD dataset.","look sentence : position bias question answering extractive question answering model train predict start end position answer . choice predict answer position mainly simplicity effectiveness . study , hypothesize distribution answer position highly skewed training set ( e.g. , answer lie k - th sentence passage ) , qa model predict answer position learn spurious positional cue fail answer different position . illustrate position bias popular extractive qa model bidaf bert thoroughly examine position bias propagate layer bert . safely deliver position information position bias , train model de - bias method include entropy regularization bias ensembling . , find prior distribution answer position bias model effective reduce position bias , recover performance bert 37.48 % 81.64 % train biased squad dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 9, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 19, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Context-Aware Answer Extraction in Question Answering,"Extractive QA models have shown very promising performance in predicting the correct answer to a question for a given passage. However, they sometimes result in predicting the correct answer text but in a context irrelevant to the given question. This discrepancy becomes especially important as the number of occurrences of the answer text in a passage increases. To resolve this issue, we propose BLANC (BLock AttentioN for Context prediction) based on two main ideas: context prediction as an auxiliary task in multi-task learning manner, and a block attention method that learns the context prediction task. With experiments on reading comprehension, we show that BLANC outperforms the state-ofthe-art QA models, and the performance gap increases as the number of answer text occurrences increases. We also conduct an experiment of training the models using SQuAD and predicting the supporting facts on HotpotQA and show that BLANC outperforms all baseline models in this zero-shot setting.","Context-Aware Answer Extraction in Question Answering Extractive QA models have shown very promising performance in predicting the correct answer to a question for a given passage. However, they sometimes result in predicting the correct answer text but in a context irrelevant to the given question. This discrepancy becomes especially important as the number of occurrences of the answer text in a passage increases. To resolve this issue, we propose BLANC (BLock AttentioN for Context prediction) based on two main ideas: context prediction as an auxiliary task in multi-task learning manner, and a block attention method that learns the context prediction task. With experiments on reading comprehension, we show that BLANC outperforms the state-ofthe-art QA models, and the performance gap increases as the number of answer text occurrences increases. We also conduct an experiment of training the models using SQuAD and predicting the supporting facts on HotpotQA and show that BLANC outperforms all baseline models in this zero-shot setting.","context - aware answer extraction question answering extractive qa model show promising performance predict correct answer question give passage . , result predict correct answer text context irrelevant give question . discrepancy especially important number occurrence answer text passage increase . resolve issue , propose blanc ( block attention context prediction ) base main idea : context prediction auxiliary task multi - task learning manner , block attention method learn context prediction task . experiment reading comprehension , blanc outperform state - ofthe - art qa model , performance gap increase number answer text occurrence increase . conduct experiment train model squad predict support fact hotpotqa blanc outperform baseline model zero - shot setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 18, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Semantics: Lexical Semantics,Improving Word Sense Disambiguation with Translations,"It has been conjectured that multilingual information can help monolingual word sense disambiguation (WSD). However, existing WSD systems rarely consider multilingual information, and no effective method has been proposed for improving WSD by generating translations. In this paper, we present a novel approach that improves the performance of a base WSD system using machine translation. Since our approach is language independent, we perform WSD experiments on several languages. The results demonstrate that our methods can consistently improve the performance of WSD systems, and obtain state-ofthe-art results in both English and multilingual WSD. To facilitate the use of lexical translation information, we also propose BABALIGN, an precise bitext alignment algorithm which is guided by multilingual lexical correspondences from BabelNet.","Improving Word Sense Disambiguation with Translations It has been conjectured that multilingual information can help monolingual word sense disambiguation (WSD). However, existing WSD systems rarely consider multilingual information, and no effective method has been proposed for improving WSD by generating translations. In this paper, we present a novel approach that improves the performance of a base WSD system using machine translation. Since our approach is language independent, we perform WSD experiments on several languages. The results demonstrate that our methods can consistently improve the performance of WSD systems, and obtain state-ofthe-art results in both English and multilingual WSD. To facilitate the use of lexical translation information, we also propose BABALIGN, an precise bitext alignment algorithm which is guided by multilingual lexical correspondences from BabelNet.","improve word sense disambiguation translation conjecture multilingual information help monolingual word sense disambiguation ( wsd ) . , exist wsd system rarely consider multilingual information , effective method propose improve wsd generate translation . paper , present novel approach improve performance base wsd system machine translation . approach language independent , perform wsd experiment language . result demonstrate method consistently improve performance wsd system , obtain state - ofthe - art result english multilingual wsd . facilitate use lexical translation information , propose babalign , precise bitext alignment algorithm guide multilingual lexical correspondence babelnet .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Towards Better Context-aware Lexical Semantics:Adjusting Contextualized Representations through Static Anchors,"One of the most powerful features of contextualized models is their dynamic embeddings for words in context, leading to state-ofthe-art representations for context-aware lexical semantics. In this paper, we present a post-processing technique that enhances these representations by learning a transformation through static anchors. Our method requires only another pre-trained model and no labeled data is needed. We show consistent improvement in a range of benchmark tasks that test contextual variations of meaning both across different usages of a word and across different words as they are used in context. We demonstrate that while the original contextual representations can be improved by another embedding space from either contextualized or static models, the static embeddings, which have lower computational requirements, provide the most gains.","Towards Better Context-aware Lexical Semantics:Adjusting Contextualized Representations through Static Anchors One of the most powerful features of contextualized models is their dynamic embeddings for words in context, leading to state-ofthe-art representations for context-aware lexical semantics. In this paper, we present a post-processing technique that enhances these representations by learning a transformation through static anchors. Our method requires only another pre-trained model and no labeled data is needed. We show consistent improvement in a range of benchmark tasks that test contextual variations of meaning both across different usages of a word and across different words as they are used in context. We demonstrate that while the original contextual representations can be improved by another embedding space from either contextualized or static models, the static embeddings, which have lower computational requirements, provide the most gains.","well context - aware lexical semantic : adjust contextualize representation static anchor powerful feature contextualize model dynamic embedding word context , lead state - ofthe - art representation context - aware lexical semantic . paper , present post - process technique enhance representation learn transformation static anchor . method require pre - trained model label data need . consistent improvement range benchmark task test contextual variation meaning different usage word different word context . demonstrate original contextual representation improve embedding space contextualized static model , static embedding , low computational requirement , provide gain .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,Compositional Demographic Word Embeddings,"Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve language model performance and other language processing tasks, they can only be computed for people with a large amount of longitudinal data, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for English: language modeling and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them.","Compositional Demographic Word Embeddings Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve language model performance and other language processing tasks, they can only be computed for people with a large amount of longitudinal data, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for English: language modeling and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them.","compositional demographic word embedding word embedding usually derive corpus contain text individual , lead general purpose representation individually personalize representation . personalized embedding useful improve language model performance language processing task , compute people large longitudinal datum , case new user . propose new form personalized word embedding use demographic - specific word representation derive compositionally partial demographic information user ( i.e. , gender , age , location , religion ) . result demographic - aware word representation outperform generic word representation task english : language modeling word association . explore trade - number available attribute relative effectiveness discuss ethical implication .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 10, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,With More Contexts Comes Better Performance: Contextualized Sense Embeddings for All-Round Word Sense Disambiguation,"Contextualized word embeddings have been employed effectively across several tasks in Natural Language Processing, as they have proved to carry useful semantic information. However, it is still hard to link them to structured sources of knowledge. In this paper we present ARES (context-AwaRe Embeddings of Senses), a semi-supervised approach to producing sense embeddings for the lexical meanings within a lexical knowledge base that lie in a space that is comparable to that of contextualized word vectors. ARES representations enable a simple 1-Nearest-Neighbour algorithm to outperform state-of-the-art models, not only in the English Word Sense Disambiguation task, but also in the multilingual one, whilst training on sense-annotated data in English only. We further assess the quality of our embeddings in the Word-in-Context task, where, when used as an external source of knowledge, they consistently improve the performance of a neural model, leading it to compete with other more complex architectures. ARES embeddings for all WordNet concepts and the automatically-extracted contexts used for creating the sense representations are freely available at http://sensembert.org/ares.","With More Contexts Comes Better Performance: Contextualized Sense Embeddings for All-Round Word Sense Disambiguation Contextualized word embeddings have been employed effectively across several tasks in Natural Language Processing, as they have proved to carry useful semantic information. However, it is still hard to link them to structured sources of knowledge. In this paper we present ARES (context-AwaRe Embeddings of Senses), a semi-supervised approach to producing sense embeddings for the lexical meanings within a lexical knowledge base that lie in a space that is comparable to that of contextualized word vectors. ARES representations enable a simple 1-Nearest-Neighbour algorithm to outperform state-of-the-art models, not only in the English Word Sense Disambiguation task, but also in the multilingual one, whilst training on sense-annotated data in English only. We further assess the quality of our embeddings in the Word-in-Context task, where, when used as an external source of knowledge, they consistently improve the performance of a neural model, leading it to compete with other more complex architectures. ARES embeddings for all WordNet concepts and the automatically-extracted contexts used for creating the sense representations are freely available at http://sensembert.org/ares.","context come well performance : contextualize sense embedding - round word sense disambiguation contextualize word embedding employ effectively task natural language processing , prove carry useful semantic information . , hard link structured source knowledge . paper present ares ( context - aware embeddings senses ) , semi - supervised approach produce sense embedding lexical meaning lexical knowledge base lie space comparable contextualize word vector . ares representation enable simple 1 - nearest - neighbour algorithm outperform state - - - art model , english word sense disambiguation task , multilingual , whilst train sense - annotate datum english . assess quality embedding word - - context task , , external source knowledge , consistently improve performance neural model , lead compete complex architecture . ares embedding wordnet concept automatically - extract context create sense representation freely available http://sensembert.org/ares .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 18, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Sequential Modelling of the Evolution of Word Representations for Semantic Change Detection,"Semantic change detection concerns the task of identifying words whose meaning has changed over time. Current state-of-the-art approaches operating on neural embeddings detect the level of semantic change in a word by comparing its vector representation in two distinct time periods, without considering its evolution through time. In this work, we propose three variants of sequential models for detecting semantically shifted words, effectively accounting for the changes in the word representations over time. Through extensive experimentation under various settings with synthetic and real data we showcase the importance of sequential modelling of word vectors through time for semantic change detection. Finally, we compare different approaches in a quantitative manner, demonstrating that temporal modelling of word representations yields a clear-cut advantage in performance.","Sequential Modelling of the Evolution of Word Representations for Semantic Change Detection Semantic change detection concerns the task of identifying words whose meaning has changed over time. Current state-of-the-art approaches operating on neural embeddings detect the level of semantic change in a word by comparing its vector representation in two distinct time periods, without considering its evolution through time. In this work, we propose three variants of sequential models for detecting semantically shifted words, effectively accounting for the changes in the word representations over time. Through extensive experimentation under various settings with synthetic and real data we showcase the importance of sequential modelling of word vectors through time for semantic change detection. Finally, we compare different approaches in a quantitative manner, demonstrating that temporal modelling of word representations yields a clear-cut advantage in performance.","sequential modelling evolution word representation semantic change detection semantic change detection concern task identify word meaning change time . current state - - - art approach operate neural embedding detect level semantic change word compare vector representation distinct time period , consider evolution time . work , propose variant sequential model detect semantically shift word , effectively account change word representation time . extensive experimentation setting synthetic real datum showcase importance sequential modelling word vector time semantic change detection . finally , compare different approach quantitative manner , demonstrate temporal modelling word representation yield clear - cut advantage performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 9, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Task-oriented Domain-specific Meta-Embedding for Text Classification,"Meta-embedding learning, which combines complementary information in different word embeddings, have shown superior performances across different Natural Language Processing tasks. However, domain-specific knowledge is still ignored by existing metaembedding methods, which results in unstable performances across specific domains. Moreover, the importance of general and domain word embeddings is related to downstream tasks, how to regularize meta-embedding to adapt downstream tasks is an unsolved problem. In this paper, we propose a method to incorporate both domain-specific and taskoriented information into meta-embeddings. We conducted extensive experiments on four text classification datasets and the results show the effectiveness of our proposed method.","Task-oriented Domain-specific Meta-Embedding for Text Classification Meta-embedding learning, which combines complementary information in different word embeddings, have shown superior performances across different Natural Language Processing tasks. However, domain-specific knowledge is still ignored by existing metaembedding methods, which results in unstable performances across specific domains. Moreover, the importance of general and domain word embeddings is related to downstream tasks, how to regularize meta-embedding to adapt downstream tasks is an unsolved problem. In this paper, we propose a method to incorporate both domain-specific and taskoriented information into meta-embeddings. We conducted extensive experiments on four text classification datasets and the results show the effectiveness of our proposed method.","task - orient domain - specific meta - embedding text classification meta - embedding learning , combine complementary information different word embedding , show superior performance different natural language processing task . , domain - specific knowledge ignore exist metaembedding method , result unstable performance specific domain . , importance general domain word embedding relate downstream task , regularize meta - embedding adapt downstream task unsolved problem . paper , propose method incorporate domain - specific taskoriented information meta - embedding . conduct extensive experiment text classification dataset result effectiveness propose method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,"BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking Scalar Adjectives with Contextualised Representations","Adjectives like pretty, beautiful and gorgeous describe positive properties of the nouns they modify but with different intensity. These differences are important for natural language understanding and reasoning. We propose a novel BERT-based approach to intensity detection for scalar adjectives. We model intensity by vectors directly derived from contextualised representations and show they can successfully rank scalar adjectives. We evaluate our models both intrinsically, on gold standard datasets, and on an Indirect Question Answering task. Our results demonstrate that BERT encodes rich knowledge about the semantics of scalar adjectives, and is able to provide better quality intensity rankings than static embeddings and previous models with access to dedicated resources.","BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking Scalar Adjectives with Contextualised Representations Adjectives like pretty, beautiful and gorgeous describe positive properties of the nouns they modify but with different intensity. These differences are important for natural language understanding and reasoning. We propose a novel BERT-based approach to intensity detection for scalar adjectives. We model intensity by vectors directly derived from contextualised representations and show they can successfully rank scalar adjectives. We evaluate our models both intrinsically, on gold standard datasets, and on an Indirect Question Answering task. Our results demonstrate that BERT encodes rich knowledge about the semantics of scalar adjectives, and is able to provide better quality intensity rankings than static embeddings and previous models with access to dedicated resources.","bert know punta cana beautiful , gorgeous : rank scalar adjective contextualised representation adjective like pretty , beautiful gorgeous describe positive property noun modify different intensity . difference important natural language understanding reasoning . propose novel bert - base approach intensity detection scalar adjective . model intensity vector directly derive contextualise representation successfully rank scalar adjective . evaluate model intrinsically , gold standard dataset , indirect question answering task . result demonstrate bert encode rich knowledge semantic scalar adjective , able provide well quality intensity ranking static embedding previous model access dedicated resource .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 5, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,XL-WiC: A Multilingual Benchmark for Evaluating Semantic Contextualization,"The ability to correctly model distinct meanings of a word is crucial for the effectiveness of semantic representation techniques. However, most existing evaluation benchmarks for assessing this criterion are tied to sense inventories (usually WordNet), restricting their usage to a small subset of knowledge-based representation techniques. The Word-in-Context dataset (WiC) addresses the dependence on sense inventories by reformulating the standard disambiguation task as a binary classification problem; but, it is limited to the English language. We put forward a large multilingual benchmark, XL-WiC, featuring gold standards in 12 new languages from varied language families and with different degrees of resource availability, opening room for evaluation scenarios such as zero-shot cross-lingual transfer. We perform a series of experiments to determine the reliability of the datasets and to set performance baselines for several recent contextualized multilingual models. Experimental results show that even when no tagged instances are available for a target language, models trained solely on the English data can attain competitive performance in the task of distinguishing different meanings of a word, even for distant languages. XL-WiC is available at https://pilehvar.github.io/xlwic/.","XL-WiC: A Multilingual Benchmark for Evaluating Semantic Contextualization The ability to correctly model distinct meanings of a word is crucial for the effectiveness of semantic representation techniques. However, most existing evaluation benchmarks for assessing this criterion are tied to sense inventories (usually WordNet), restricting their usage to a small subset of knowledge-based representation techniques. The Word-in-Context dataset (WiC) addresses the dependence on sense inventories by reformulating the standard disambiguation task as a binary classification problem; but, it is limited to the English language. We put forward a large multilingual benchmark, XL-WiC, featuring gold standards in 12 new languages from varied language families and with different degrees of resource availability, opening room for evaluation scenarios such as zero-shot cross-lingual transfer. We perform a series of experiments to determine the reliability of the datasets and to set performance baselines for several recent contextualized multilingual models. Experimental results show that even when no tagged instances are available for a target language, models trained solely on the English data can attain competitive performance in the task of distinguishing different meanings of a word, even for distant languages. XL-WiC is available at https://pilehvar.github.io/xlwic/.","xl - wic : multilingual benchmark evaluate semantic contextualization ability correctly model distinct meaning word crucial effectiveness semantic representation technique . , exist evaluation benchmark assess criterion tie sense inventory ( usually wordnet ) , restrict usage small subset knowledge - base representation technique . word - - context dataset ( wic ) address dependence sense inventory reformulate standard disambiguation task binary classification problem ; , limit english language . forward large multilingual benchmark , xl - wic , feature gold standard 12 new language varied language family different degree resource availability , open room evaluation scenario zero - shot cross - lingual transfer . perform series experiment determine reliability dataset set performance baseline recent contextualized multilingual model . experimental result tag instance available target language , model train solely english datum attain competitive performance task distinguish different meaning word , distant language . xl - wic available https://pilehvar.github.io/xlwic/.","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Probing Pretrained Language Models for Lexical Semantics,"The success of large pretrained language models (LMs) such as BERT and RoBERTa has sparked interest in probing their representations, in order to unveil what types of knowledge they implicitly capture. While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context. In this work, we present a systematic empirical analysis across six typologically diverse languages and five different lexical tasks, addressing the following questions: 1) How do different lexical knowledge extraction strategies (monolingual versus multilingual source LM, out-ofcontext versus in-context encoding, inclusion of special tokens, and layer-wise averaging) impact performance? How consistent are the observed effects across tasks and languages? 2) Is lexical knowledge stored in few parameters, or is it scattered throughout the network? 3) How do these representations fare against traditional static word vectors in lexical tasks? 4) Does the lexical information emerging from independently trained monolingual LMs display latent similarities? Our main results indicate patterns and best practices that hold universally, but also point to prominent variations across languages and tasks. Moreover, we validate the claim that lower Transformer layers carry more type-level lexical knowledge, but also show that this knowledge is distributed across multiple layers.","Probing Pretrained Language Models for Lexical Semantics The success of large pretrained language models (LMs) such as BERT and RoBERTa has sparked interest in probing their representations, in order to unveil what types of knowledge they implicitly capture. While prior research focused on morphosyntactic, semantic, and world knowledge, it remains unclear to which extent LMs also derive lexical type-level knowledge from words in context. In this work, we present a systematic empirical analysis across six typologically diverse languages and five different lexical tasks, addressing the following questions: 1) How do different lexical knowledge extraction strategies (monolingual versus multilingual source LM, out-ofcontext versus in-context encoding, inclusion of special tokens, and layer-wise averaging) impact performance? How consistent are the observed effects across tasks and languages? 2) Is lexical knowledge stored in few parameters, or is it scattered throughout the network? 3) How do these representations fare against traditional static word vectors in lexical tasks? 4) Does the lexical information emerging from independently trained monolingual LMs display latent similarities? Our main results indicate patterns and best practices that hold universally, but also point to prominent variations across languages and tasks. Moreover, we validate the claim that lower Transformer layers carry more type-level lexical knowledge, but also show that this knowledge is distributed across multiple layers.","probe pretrained language model lexical semantic success large pretrained language model ( lms ) bert roberta spark interest probe representation , order unveil type knowledge implicitly capture . prior research focus morphosyntactic , semantic , world knowledge , remain unclear extent lms derive lexical type - level knowledge word context . work , present systematic empirical analysis typologically diverse language different lexical task , address following question : 1 ) different lexical knowledge extraction strategy ( monolingual versus multilingual source lm , - ofcontext versus - context encoding , inclusion special token , layer - wise averaging ) impact performance ? consistent observed effect task language ? 2 ) lexical knowledge store parameter , scatter network ? 3 ) representation fare traditional static word vector lexical task ? 4 ) lexical information emerge independently train monolingual lm display latent similarity ? main result indicate pattern good practice hold universally , point prominent variation language task . , validate claim low transformer layer carry type - level lexical knowledge , knowledge distribute multiple layer .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,A Synset Relation-enhanced Framework with a Try-again Mechanism for Word Sense Disambiguation,"Contextual embeddings are proved to be overwhelmingly effective to the task of Word Sense Disambiguation (WSD) compared with other sense representation techniques. However, these embeddings fail to embed sense knowledge in semantic networks. In this paper, we propose a Synset Relation-Enhanced Framework (SREF) that leverages sense relations for both sense embedding enhancement and a try-again mechanism that implements WSD again, after obtaining basic sense embeddings from augmented WordNet glosses. Experiments on all-words and lexical sample datasets show that the proposed system achieves new state-ofthe-art results, defeating previous knowledge-based systems by at least 5.5 F1 measure. When the system utilizes sense embeddings learned from SemCor, it outperforms all previous supervised systems with only 20% SemCor data.","A Synset Relation-enhanced Framework with a Try-again Mechanism for Word Sense Disambiguation Contextual embeddings are proved to be overwhelmingly effective to the task of Word Sense Disambiguation (WSD) compared with other sense representation techniques. However, these embeddings fail to embed sense knowledge in semantic networks. In this paper, we propose a Synset Relation-Enhanced Framework (SREF) that leverages sense relations for both sense embedding enhancement and a try-again mechanism that implements WSD again, after obtaining basic sense embeddings from augmented WordNet glosses. Experiments on all-words and lexical sample datasets show that the proposed system achieves new state-ofthe-art results, defeating previous knowledge-based systems by at least 5.5 F1 measure. When the system utilizes sense embeddings learned from SemCor, it outperforms all previous supervised systems with only 20% SemCor data.","synset relation - enhance framework try - mechanism word sense disambiguation contextual embedding prove overwhelmingly effective task word sense disambiguation ( wsd ) compare sense representation technique . , embedding fail embed sense knowledge semantic network . paper , propose synset relation - enhanced framework ( sref ) leverage sense relation sense embedding enhancement try - mechanism implement wsd , obtain basic sense embedding augment wordnet gloss . experiment - word lexical sample dataset propose system achieve new state - ofthe - art result , defeat previous knowledge - base system 5.5 f1 measure . system utilize sense embedding learn semcor , outperform previous supervise system 20 % semcor datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 14, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Sparsity Makes Sense: Word Sense Disambiguation Using Sparse Contextualized Word Representations,"In this paper, we demonstrate that by utilizing sparse word representations, it becomes possible to surpass the results of more complex task-specific models on the task of finegrained all-words word sense disambiguation. Our proposed algorithm relies on an overcomplete set of semantic basis vectors that allows us to obtain sparse contextualized word representations. We introduce such an information theory-inspired synset representation based on the co-occurrence of word senses and nonzero coordinates for word forms which allows us to achieve an aggregated F-score of 78.8 over a combination of five standard word sense disambiguating benchmark datasets. We also demonstrate the general applicability of our proposed framework by evaluating it towards part-of-speech tagging on four different treebanks. Our results indicate a significant improvement over the application of the dense word representations.","Sparsity Makes Sense: Word Sense Disambiguation Using Sparse Contextualized Word Representations In this paper, we demonstrate that by utilizing sparse word representations, it becomes possible to surpass the results of more complex task-specific models on the task of finegrained all-words word sense disambiguation. Our proposed algorithm relies on an overcomplete set of semantic basis vectors that allows us to obtain sparse contextualized word representations. We introduce such an information theory-inspired synset representation based on the co-occurrence of word senses and nonzero coordinates for word forms which allows us to achieve an aggregated F-score of 78.8 over a combination of five standard word sense disambiguating benchmark datasets. We also demonstrate the general applicability of our proposed framework by evaluating it towards part-of-speech tagging on four different treebanks. Our results indicate a significant improvement over the application of the dense word representations.","sparsity make sense : word sense disambiguation sparse contextualize word representation paper , demonstrate utilize sparse word representation , possible surpass result complex task - specific model task finegrained - word word sense disambiguation . propose algorithm rely overcomplete set semantic basis vector allow obtain sparse contextualize word representation . introduce information theory - inspire synset representation base co - occurrence word sense nonzero coordinate word form allow achieve aggregate f - score 78.8 combination standard word sense disambiguate benchmark dataset . demonstrate general applicability propose framework evaluate - - speech tagging different treebank . result indicate significant improvement application dense word representation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 20, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Don't Neglect the Obvious: On the Role of Unambiguous Words in Word Sense Disambiguation,"State-of-the-art methods for Word Sense Disambiguation (WSD) combine two different features: the power of pre-trained language models and a propagation method to extend the coverage of such models. This propagation is needed as current sense-annotated corpora lack coverage of many instances in the underlying sense inventory (usually WordNet). At the same time, unambiguous words make for a large portion of all words in WordNet, while being poorly covered in existing senseannotated corpora. In this paper, we propose a simple method to provide annotations for most unambiguous words in a large corpus. We introduce the UWA (Unambiguous Word Annotations) dataset and show how a state-of-theart propagation-based model can use it to extend the coverage and quality of its word sense embeddings by a significant margin, improving on its original results on WSD.","Don't Neglect the Obvious: On the Role of Unambiguous Words in Word Sense Disambiguation State-of-the-art methods for Word Sense Disambiguation (WSD) combine two different features: the power of pre-trained language models and a propagation method to extend the coverage of such models. This propagation is needed as current sense-annotated corpora lack coverage of many instances in the underlying sense inventory (usually WordNet). At the same time, unambiguous words make for a large portion of all words in WordNet, while being poorly covered in existing senseannotated corpora. In this paper, we propose a simple method to provide annotations for most unambiguous words in a large corpus. We introduce the UWA (Unambiguous Word Annotations) dataset and show how a state-of-theart propagation-based model can use it to extend the coverage and quality of its word sense embeddings by a significant margin, improving on its original results on WSD.","neglect obvious : role unambiguous word word sense disambiguation state - - - art method word sense disambiguation ( wsd ) combine different feature : power pre - trained language model propagation method extend coverage model . propagation need current sense - annotate corpus lack coverage instance underlie sense inventory ( usually wordnet ) . time , unambiguous word large portion word wordnet , poorly cover exist senseannotate corpus . paper , propose simple method provide annotation unambiguous word large corpus . introduce uwa ( unambiguous word annotations ) dataset state - - theart propagation - base model use extend coverage quality word sense embedding significant margin , improve original result wsd .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 19, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Within-Between Lexical Relation Classification,"We propose the novel Within-Between Relation model for recognizing lexical-semantic relations between words. Our model integrates relational and distributional signals, forming an effective sub-space representation for each relation. We show that the proposed model is competitive and outperforms other baselines, across various benchmarks.","Within-Between Lexical Relation Classification We propose the novel Within-Between Relation model for recognizing lexical-semantic relations between words. Our model integrates relational and distributional signals, forming an effective sub-space representation for each relation. We show that the proposed model is competitive and outperforms other baselines, across various benchmarks.","- lexical relation classification propose novel - relation model recognize lexical - semantic relation word . model integrate relational distributional signal , form effective sub - space representation relation . propose model competitive outperform baseline , benchmark .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Semantics: Lexical Semantics,Exploring Semantic Capacity of Terms,"We introduce and study semantic capacity of terms. For example, the semantic capacity of artificial intelligence is higher than that of linear regression since artificial intelligence possesses a broader meaning scope. Understanding semantic capacity of terms will help many downstream tasks in natural language processing. For this purpose, we propose a two-step model to investigate semantic capacity of terms, which takes a large text corpus as input and can evaluate semantic capacity of terms if the text corpus can provide enough cooccurrence information of terms. Extensive experiments in three fields demonstrate the effectiveness and rationality of our model compared with well-designed baselines and human-level evaluations.","Exploring Semantic Capacity of Terms We introduce and study semantic capacity of terms. For example, the semantic capacity of artificial intelligence is higher than that of linear regression since artificial intelligence possesses a broader meaning scope. Understanding semantic capacity of terms will help many downstream tasks in natural language processing. For this purpose, we propose a two-step model to investigate semantic capacity of terms, which takes a large text corpus as input and can evaluate semantic capacity of terms if the text corpus can provide enough cooccurrence information of terms. Extensive experiments in three fields demonstrate the effectiveness and rationality of our model compared with well-designed baselines and human-level evaluations.","explore semantic capacity term introduce study semantic capacity term . example , semantic capacity artificial intelligence high linear regression artificial intelligence possess broad meaning scope . understand semantic capacity term help downstream task natural language processing . purpose , propose - step model investigate semantic capacity term , take large text corpus input evaluate semantic capacity term text corpus provide cooccurrence information term . extensive experiment field demonstrate effectiveness rationality model compare - design baseline human - level evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Semantics: Lexical Semantics,Deconstructing word embedding algorithms,"Word embeddings are reliable feature representations of words used to obtain high quality results for various NLP applications. Uncontextualized word embeddings are used in many NLP tasks today, especially in resourcelimited settings where high memory capacity and GPUs are not available. Given the historical success of word embeddings in NLP, we propose a retrospective on some of the most well-known word embedding algorithms. In this work, we deconstruct Word2vec, GloVe, and others, into a common form, unveiling some of the common conditions that seem to be required for making performant word embeddings. We believe that the theoretical findings in this paper can provide a basis for more informed development of future models. * Kian and Edward contributed equally. † This work was pursued while Kian was a member of Mila.","Deconstructing word embedding algorithms Word embeddings are reliable feature representations of words used to obtain high quality results for various NLP applications. Uncontextualized word embeddings are used in many NLP tasks today, especially in resourcelimited settings where high memory capacity and GPUs are not available. Given the historical success of word embeddings in NLP, we propose a retrospective on some of the most well-known word embedding algorithms. In this work, we deconstruct Word2vec, GloVe, and others, into a common form, unveiling some of the common conditions that seem to be required for making performant word embeddings. We believe that the theoretical findings in this paper can provide a basis for more informed development of future models. * Kian and Edward contributed equally. † This work was pursued while Kian was a member of Mila.","deconstruct word embedding algorithm word embedding reliable feature representation word obtain high quality result nlp application . uncontextualized word embedding nlp task today , especially resourcelimited setting high memory capacity gpu available . give historical success word embedding nlp , propose retrospective - know word embedding algorithm . work , deconstruct word2vec , glove , , common form , unveil common condition require make performant word embedding . believe theoretical finding paper provide basis informed development future model . * kian edward contribute equally . † work pursue kian member mila .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 14, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Interpreting Open-Domain Modifiers: Decomposition of Wikipedia Categories into Disambiguated Property-Value Pairs,"This paper proposes an open-domain method for automatically annotating modifier constituents (""20th-century"") within Wikipedia categories (""20th-century male writers"") with properties (""date of birth""). The annotations offer a semantically-anchored understanding of the role of the constituents in defining the underlying meaning of the categories. In experiments over an evaluation set of Wikipedia categories, the proposed method annotates constituent modifiers as semanticallyanchored properties, rather than as mere strings in a previous method. It does so at a better trade-off between precision and recall.","Interpreting Open-Domain Modifiers: Decomposition of Wikipedia Categories into Disambiguated Property-Value Pairs This paper proposes an open-domain method for automatically annotating modifier constituents (""20th-century"") within Wikipedia categories (""20th-century male writers"") with properties (""date of birth""). The annotations offer a semantically-anchored understanding of the role of the constituents in defining the underlying meaning of the categories. In experiments over an evaluation set of Wikipedia categories, the proposed method annotates constituent modifiers as semanticallyanchored properties, rather than as mere strings in a previous method. It does so at a better trade-off between precision and recall.","interpret open - domain modifier : decomposition wikipedia category disambiguated property - value pair paper propose open - domain method automatically annotate modifier constituent ( "" 20th - century "" ) wikipedia category ( "" 20th - century male writer "" ) property ( "" date birth "" ) . annotation offer semantically - anchor understanding role constituent define underlie meaning category . experiment evaluation set wikipedia category , propose method annotate constituent modifier semanticallyanchored property , mere string previous method . well trade - precision recall .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Table Fact Verification with Structure-Aware Transformer,"Verifying fact on semi-structured evidence like tables requires the ability to encode structural information and perform symbolic reasoning. Pre-trained language models trained on natural language could not be directly applied to encode tables, because simply linearizing tables into sequences will lose the cell alignment information. To better utilize pre-trained transformers for table representation, we propose a Structure-Aware Transformer (SAT), which injects the table structural information into the mask of the self-attention layer. A method to combine symbolic and linguistic reasoning is also explored for this task. Our method outperforms baseline with 4.93% on TabFact, a large scale table verification dataset.","Table Fact Verification with Structure-Aware Transformer Verifying fact on semi-structured evidence like tables requires the ability to encode structural information and perform symbolic reasoning. Pre-trained language models trained on natural language could not be directly applied to encode tables, because simply linearizing tables into sequences will lose the cell alignment information. To better utilize pre-trained transformers for table representation, we propose a Structure-Aware Transformer (SAT), which injects the table structural information into the mask of the self-attention layer. A method to combine symbolic and linguistic reasoning is also explored for this task. Our method outperforms baseline with 4.93% on TabFact, a large scale table verification dataset.","table fact verification structure - aware transformer verify fact semi - structured evidence like table require ability encode structural information perform symbolic reasoning . pre - trained language model train natural language directly apply encode table , simply linearize table sequence lose cell alignment information . well utilize pre - trained transformer table representation , propose structure - aware transformer ( sat ) , inject table structural information mask self - attention layer . method combine symbolic linguistic reasoning explore task . method outperform baseline 4.93 % tabfact , large scale table verification dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",X-SRL: A Parallel Cross-Lingual Semantic Role Labeling Dataset,"Even though SRL is researched for many languages, major improvements have mostly been obtained for English, for which more resources are available. In fact, existing multilingual SRL datasets contain disparate annotation styles or come from different domains, hampering generalization in multilingual learning. In this work we propose a method to automatically construct an SRL corpus that is parallel in four languages: English, French, German, Spanish, with unified predicate and role annotations that are fully comparable across languages. We apply high-quality machine translation to the English CoNLL-09 dataset and use multilingual BERT to project its highquality annotations to the target languages. We include human-validated test sets that we use to measure the projection quality, and show that projection is denser and more precise than a strong baseline. Finally, we train different SOTA models on our novel corpus for monoand multilingual SRL, showing that the multilingual annotations improve performance especially for the weaker languages.","X-SRL: A Parallel Cross-Lingual Semantic Role Labeling Dataset Even though SRL is researched for many languages, major improvements have mostly been obtained for English, for which more resources are available. In fact, existing multilingual SRL datasets contain disparate annotation styles or come from different domains, hampering generalization in multilingual learning. In this work we propose a method to automatically construct an SRL corpus that is parallel in four languages: English, French, German, Spanish, with unified predicate and role annotations that are fully comparable across languages. We apply high-quality machine translation to the English CoNLL-09 dataset and use multilingual BERT to project its highquality annotations to the target languages. We include human-validated test sets that we use to measure the projection quality, and show that projection is denser and more precise than a strong baseline. Finally, we train different SOTA models on our novel corpus for monoand multilingual SRL, showing that the multilingual annotations improve performance especially for the weaker languages.","x - srl : parallel cross - lingual semantic role labeling dataset srl research language , major improvement obtain english , resource available . fact , exist multilingual srl dataset contain disparate annotation style come different domain , hamper generalization multilingual learning . work propose method automatically construct srl corpus parallel language : english , french , german , spanish , unified predicate role annotation fully comparable language . apply high - quality machine translation english conll-09 dataset use multilingual bert project highquality annotation target language . include human - validate test set use measure projection quality , projection dense precise strong baseline . finally , train different sota model novel corpus monoand multilingual srl , show multilingual annotation improve performance especially weak language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Precise Task Formalization Matters in Winograd Schema Evaluations,"Performance on the Winograd Schema Challenge (WSC), a respected English commonsense reasoning benchmark, recently rocketed from chance accuracy to 89% on the Super-GLUE leaderboard, with relatively little corroborating evidence of a correspondingly large improvement in reasoning ability. We hypothesize that much of this improvement comes from recent changes in task formalizationthe combination of input specification, loss function, and reuse of pretrained parametersby users of the dataset, rather than improvements in the pretrained model's reasoning ability. We perform an ablation on two Winograd Schema datasets that interpolates between the formalizations used before and after this surge, and find (i) framing the task as multiple choice improves performance by 2-6 points and (ii) several additional techniques, including the reuse of a pretrained language modeling head, can mitigate the model's extreme sensitivity to hyperparameters. We urge future benchmark creators to impose additional structure to minimize the impact of formalization decisions on reported results.","Precise Task Formalization Matters in Winograd Schema Evaluations Performance on the Winograd Schema Challenge (WSC), a respected English commonsense reasoning benchmark, recently rocketed from chance accuracy to 89% on the Super-GLUE leaderboard, with relatively little corroborating evidence of a correspondingly large improvement in reasoning ability. We hypothesize that much of this improvement comes from recent changes in task formalizationthe combination of input specification, loss function, and reuse of pretrained parametersby users of the dataset, rather than improvements in the pretrained model's reasoning ability. We perform an ablation on two Winograd Schema datasets that interpolates between the formalizations used before and after this surge, and find (i) framing the task as multiple choice improves performance by 2-6 points and (ii) several additional techniques, including the reuse of a pretrained language modeling head, can mitigate the model's extreme sensitivity to hyperparameters. We urge future benchmark creators to impose additional structure to minimize the impact of formalization decisions on reported results.","precise task formalization matter winograd schema evaluations performance winograd schema challenge ( wsc ) , respected english commonsense reasoning benchmark , recently rocket chance accuracy 89 % super - glue leaderboard , relatively little corroborate evidence correspondingly large improvement reasoning ability . hypothesize improvement come recent change task formalizationthe combination input specification , loss function , reuse pretrained parametersby user dataset , improvement pretrained model reasoning ability . perform ablation winograd schema dataset interpolate formalization surge , find ( ) frame task multiple choice improve performance 2 - 6 point ( ii ) additional technique , include reuse pretrained language modeling head , mitigate model extreme sensitivity hyperparameter . urge future benchmark creator impose additional structure minimize impact formalization decision report result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 4}","Phonology, Morphology and Word Segmentation",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention,"Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer (Vaswani et al., 2017) . The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our model is trained using a new pretraining task based on the masked language model of BERT (Devlin et al., 2019). The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at https: //github.com/studio-ousia/luke.","LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention Entity representations are useful in natural language tasks involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer (Vaswani et al., 2017) . The proposed model treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our model is trained using a new pretraining task based on the masked language model of BERT (Devlin et al., 2019). The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from Wikipedia. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed model achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets: Open Entity (entity typing), TACRED (relation classification), CoNLL-2003 (named entity recognition), ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at https: //github.com/studio-ousia/luke.","luke : deep contextualize entity representation entity - aware self - attention entity representation useful natural language task involve entity . paper , propose new pretrained contextualized representation word entity base bidirectional transformer ( vaswani et al . , 2017 ) . propose model treat word entity give text independent token , output contextualize representation . model train new pretraine task base mask language model bert ( devlin et al . , 2019 ) . task involve predict randomly mask word entity large entity - annotate corpus retrieve wikipedia . propose entity - aware self - attention mechanism extension self - attention mechanism transformer , consider type token ( word entity ) compute attention score . propose model achieve impressive empirical performance wide range entity - relate task . particular , obtain state - - - art result - know dataset : open entity ( entity typing ) , tacred ( relation classification ) , conll-2003 ( name entity recognition ) , record ( cloze - style question answering ) , squad 1.1 ( extractive question answering ) . source code pretrained representation available https : //github.com / studio - ousia / luke .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 19, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 10, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Character-level Representations Improve DRS-based Semantic Parsing Even in the Age of BERT,"We combine character-level and contextual language model representations to improve performance on Discourse Representation Structure parsing. Character representations can easily be added in a sequence-to-sequence model in either one encoder or as a fully separate encoder, with improvements that are robust to different language models, languages and data sets. For English, these improvements are larger than adding individual sources of linguistic information or adding non-contextual embeddings. A new method of analysis based on semantic tags demonstrates that the character-level representations improve performance across a subset of selected semantic phenomena.","Character-level Representations Improve DRS-based Semantic Parsing Even in the Age of BERT We combine character-level and contextual language model representations to improve performance on Discourse Representation Structure parsing. Character representations can easily be added in a sequence-to-sequence model in either one encoder or as a fully separate encoder, with improvements that are robust to different language models, languages and data sets. For English, these improvements are larger than adding individual sources of linguistic information or adding non-contextual embeddings. A new method of analysis based on semantic tags demonstrates that the character-level representations improve performance across a subset of selected semantic phenomena.","character - level representation improve drs - base semantic parsing age bert combine character - level contextual language model representation improve performance discourse representation structure parsing . character representation easily add sequence - - sequence model encoder fully separate encoder , improvement robust different language model , language data set . english , improvement large add individual source linguistic information add non - contextual embedding . new method analysis base semantic tag demonstrate character - level representation improve performance subset select semantic phenomenon .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Neural Deepfake Detection with Factual Structure of Text,"Deepfake detection, the task of automatically discriminating machine-generated text, is increasingly critical with recent advances in natural language generative models. Existing approaches to deepfake detection typically represent documents with coarse-grained representations. However, they struggle to capture factual structures of documents, which is a discriminative factor between machinegenerated and human-written text according to our statistical analysis. To address this, we propose a graph-based model that utilizes the factual structure of a document for deepfake detection of text. Our approach represents the factual structure of a given document as an entity graph, which is further utilized to learn sentence representations with a graph neural network. Sentence representations are then composed to a document representation for making predictions, where consistent relations between neighboring sentences are sequentially modeled. Results of experiments on two public deepfake datasets show that our approach significantly improves strong base models built with RoBERTa. Model analysis further indicates that our model can distinguish the difference in the factual structure between machine-generated text and humanwritten text.","Neural Deepfake Detection with Factual Structure of Text Deepfake detection, the task of automatically discriminating machine-generated text, is increasingly critical with recent advances in natural language generative models. Existing approaches to deepfake detection typically represent documents with coarse-grained representations. However, they struggle to capture factual structures of documents, which is a discriminative factor between machinegenerated and human-written text according to our statistical analysis. To address this, we propose a graph-based model that utilizes the factual structure of a document for deepfake detection of text. Our approach represents the factual structure of a given document as an entity graph, which is further utilized to learn sentence representations with a graph neural network. Sentence representations are then composed to a document representation for making predictions, where consistent relations between neighboring sentences are sequentially modeled. Results of experiments on two public deepfake datasets show that our approach significantly improves strong base models built with RoBERTa. Model analysis further indicates that our model can distinguish the difference in the factual structure between machine-generated text and humanwritten text.","neural deepfake detection factual structure text deepfake detection , task automatically discriminate machine - generate text , increasingly critical recent advance natural language generative model . exist approach deepfake detection typically represent document coarse - grained representation . , struggle capture factual structure document , discriminative factor machinegenerate human - write text accord statistical analysis . address , propose graph - base model utilize factual structure document deepfake detection text . approach represent factual structure give document entity graph , utilize learn sentence representation graph neural network . sentence representation compose document representation make prediction , consistent relation neighbor sentence sequentially model . result experiment public deepfake dataset approach significantly improve strong base model build roberta . model analysis indicate model distinguish difference factual structure machine - generate text humanwritten text .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 10, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",PARADE: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge,"We present a new benchmark dataset called PARADE for paraphrase identification that requires specialized domain knowledge. PA-RADE contains paraphrases that overlap very little at the lexical and syntactic level but are semantically equivalent based on computer science domain knowledge, as well as nonparaphrases that overlap greatly at the lexical and syntactic level but are not semantically equivalent based on this domain knowledge. Experiments show that both state-of-the-art neural models and non-expert human annotators have poor performance on PARADE. For example, BERT after fine-tuning achieves an F1 score of 0.709, which is much lower than its performance on other paraphrase identification datasets. PARADE can serve as a resource for researchers interested in testing models that incorporate domain knowledge. We make our data and code freely available. 1","PARADE: A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge We present a new benchmark dataset called PARADE for paraphrase identification that requires specialized domain knowledge. PA-RADE contains paraphrases that overlap very little at the lexical and syntactic level but are semantically equivalent based on computer science domain knowledge, as well as nonparaphrases that overlap greatly at the lexical and syntactic level but are not semantically equivalent based on this domain knowledge. Experiments show that both state-of-the-art neural models and non-expert human annotators have poor performance on PARADE. For example, BERT after fine-tuning achieves an F1 score of 0.709, which is much lower than its performance on other paraphrase identification datasets. PARADE can serve as a resource for researchers interested in testing models that incorporate domain knowledge. We make our data and code freely available. 1","parade : new dataset paraphrase identification require computer science domain knowledge present new benchmark dataset call parade paraphrase identification require specialized domain knowledge . pa - rade contain paraphrase overlap little lexical syntactic level semantically equivalent base computer science domain knowledge , nonparaphrase overlap greatly lexical syntactic level semantically equivalent base domain knowledge . experiment state - - - art neural model non - expert human annotator poor performance parade . example , bert fine - tuning achieve f1 score 0.709 , low performance paraphrase identification dataset . parade serve resource researcher interested test model incorporate domain knowledge . datum code freely available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Semantically Inspired AMR Alignment for the Portuguese Language,"Meaning Representation (AMR) is a graph-based semantic formalism where the nodes are concepts and edges are relations among them. Most of AMR parsing methods require alignment between the nodes of the graph and the words of the sentence. However, this alignment is not provided by manual annotations and available automatic aligners focus only on the English language, not performing well for other languages. Aiming to fulfill this gap, we developed an alignment method for the Portuguese language based on a more semantically matched word-concept pair. We performed both intrinsic and extrinsic evaluations and showed that our alignment approach outperforms the alignment strategies developed for English, improving AMR parsers, and achieving competitive results with a parser designed for the Portuguese language.","Semantically Inspired AMR Alignment for the Portuguese Language Meaning Representation (AMR) is a graph-based semantic formalism where the nodes are concepts and edges are relations among them. Most of AMR parsing methods require alignment between the nodes of the graph and the words of the sentence. However, this alignment is not provided by manual annotations and available automatic aligners focus only on the English language, not performing well for other languages. Aiming to fulfill this gap, we developed an alignment method for the Portuguese language based on a more semantically matched word-concept pair. We performed both intrinsic and extrinsic evaluations and showed that our alignment approach outperforms the alignment strategies developed for English, improving AMR parsers, and achieving competitive results with a parser designed for the Portuguese language.","semantically inspire amr alignment portuguese language meaning representation ( amr ) graph - base semantic formalism node concept edge relation . amr parsing method require alignment node graph word sentence . , alignment provide manual annotation available automatic aligner focus english language , perform language . aim fulfill gap , develop alignment method portuguese language base semantically matched word - concept pair . perform intrinsic extrinsic evaluation show alignment approach outperform alignment strategy develop english , improve amr parser , achieve competitive result parser design portuguese language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Program Enhanced Fact Verification with Verbalization and Graph Attention Network,"Performing fact verification based on structured data is important for many real-life applications and is a challenging research problem, particularly when it involves both symbolic operations and informal inference based on language understanding. In this paper, we present a Program-enhanced Verbalization and Graph ATtention Network (ProgVGAT) to integrate programs and execution into textual inference models. Specifically, a verbalization with program execution model is proposed to accumulate evidences that are embedded in operations over the tables. Built on that, we construct the graph attention verification networks, which are designed to fuse different sources of evidences from verbalized program execution, program structures, and the original statements and tables, to make the final verification decision. To support the above framework, we propose a program selection module optimized with a new training strategy based on margin loss, to produce more accurate programs, which is shown to be effective in enhancing the final verification results. Experimental results show that the proposed framework achieves the new state-of-the-art performance, a 74.4% accuracy, on the benchmark dataset TABFACT. Our code is available at https://github.com/arielsho/Program-Enhanced-Table-Fact-Checking.","Program Enhanced Fact Verification with Verbalization and Graph Attention Network Performing fact verification based on structured data is important for many real-life applications and is a challenging research problem, particularly when it involves both symbolic operations and informal inference based on language understanding. In this paper, we present a Program-enhanced Verbalization and Graph ATtention Network (ProgVGAT) to integrate programs and execution into textual inference models. Specifically, a verbalization with program execution model is proposed to accumulate evidences that are embedded in operations over the tables. Built on that, we construct the graph attention verification networks, which are designed to fuse different sources of evidences from verbalized program execution, program structures, and the original statements and tables, to make the final verification decision. To support the above framework, we propose a program selection module optimized with a new training strategy based on margin loss, to produce more accurate programs, which is shown to be effective in enhancing the final verification results. Experimental results show that the proposed framework achieves the new state-of-the-art performance, a 74.4% accuracy, on the benchmark dataset TABFACT. Our code is available at https://github.com/arielsho/Program-Enhanced-Table-Fact-Checking.","program enhanced fact verification verbalization graph attention network perform fact verification base structure datum important real - life application challenge research problem , particularly involve symbolic operation informal inference base language understanding . paper , present program - enhance verbalization graph attention network ( progvgat ) integrate program execution textual inference model . specifically , verbalization program execution model propose accumulate evidence embed operation table . build , construct graph attention verification network , design fuse different source evidence verbalize program execution , program structure , original statement table , final verification decision . support framework , propose program selection module optimize new training strategy base margin loss , produce accurate program , show effective enhance final verification result . experimental result propose framework achieve new state - - - art performance , 74.4 % accuracy , benchmark dataset tabfact . code available https://github.com/arielsho/program-enhanced-table-fact-checking .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 12, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Leveraging Declarative Knowledge in Text and First-Order Logic for Fine-Grained Propaganda Detection,"We study the detection of propagandistic text fragments in news articles. Instead of merely learning from input-output datapoints in training data, we introduce an approach to inject declarative knowledge of fine-grained propaganda techniques. Specifically, we leverage the declarative knowledge expressed in both first-order logic and natural language. The former refers to the logical consistency between coarse-and fine-grained predictions, which is used to regularize the training process with propositional Boolean expressions. The latter refers to the literal definition of each propaganda technique, which is utilized to get class representations for regularizing the model parameters. We conduct experiments on Propaganda Techniques Corpus, a large manually annotated dataset for fine-grained propaganda detection. Experiments show that our method achieves superior performance, demonstrating that leveraging declarative knowledge can help the model to make more accurate predictions.","Leveraging Declarative Knowledge in Text and First-Order Logic for Fine-Grained Propaganda Detection We study the detection of propagandistic text fragments in news articles. Instead of merely learning from input-output datapoints in training data, we introduce an approach to inject declarative knowledge of fine-grained propaganda techniques. Specifically, we leverage the declarative knowledge expressed in both first-order logic and natural language. The former refers to the logical consistency between coarse-and fine-grained predictions, which is used to regularize the training process with propositional Boolean expressions. The latter refers to the literal definition of each propaganda technique, which is utilized to get class representations for regularizing the model parameters. We conduct experiments on Propaganda Techniques Corpus, a large manually annotated dataset for fine-grained propaganda detection. Experiments show that our method achieves superior performance, demonstrating that leveraging declarative knowledge can help the model to make more accurate predictions.","leverage declarative knowledge text - order logic fine - grained propaganda detection study detection propagandistic text fragment news article . instead merely learn input - output datapoint training datum , introduce approach inject declarative knowledge fine - grained propaganda technique . specifically , leverage declarative knowledge express - order logic natural language . refer logical consistency coarse - fine - grained prediction , regularize training process propositional boolean expression . refer literal definition propaganda technique , utilize class representation regularize model parameter . conduct experiment propaganda techniques corpus , large manually annotate dataset fine - grained propaganda detection . experiment method achieve superior performance , demonstrate leverage declarative knowledge help model accurate prediction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",DuSQL: A Large-Scale and Pragmatic Chinese Text-to-SQL Dataset,"Due to the lack of labeled data, previous research on text-to-SQL parsing mainly focuses on English. Representative English datasets include ATIS, WikiSQL, Spider, etc. This paper presents DuSQL, a larges-scale and pragmatic Chinese dataset for the cross-domain text-to-SQL task, containing 200 databases, 813 tables, and 23,797 question/SQL pairs. Our new dataset has three major characteristics. First, by manually analyzing questions from several representative applications, we try to figure out the true distribution of SQL queries in real-life needs. Second, DuSQL contains a considerable proportion of SQL queries involving row or column calculations, motivated by our analysis on the SQL query distributions. Finally, we adopt an effective data construction framework via human-computer collaboration. The basic idea is automatically generating SQL queries based on the SQL grammar and constrained by the given database. This paper describes in detail the construction process and data statistics of DuSQL. Moreover, we present and compare performance of several open-source textto-SQL parsers with minor modification to accommodate Chinese, including a simple yet effective extension to IRNet for handling calculation SQL queries.","DuSQL: A Large-Scale and Pragmatic Chinese Text-to-SQL Dataset Due to the lack of labeled data, previous research on text-to-SQL parsing mainly focuses on English. Representative English datasets include ATIS, WikiSQL, Spider, etc. This paper presents DuSQL, a larges-scale and pragmatic Chinese dataset for the cross-domain text-to-SQL task, containing 200 databases, 813 tables, and 23,797 question/SQL pairs. Our new dataset has three major characteristics. First, by manually analyzing questions from several representative applications, we try to figure out the true distribution of SQL queries in real-life needs. Second, DuSQL contains a considerable proportion of SQL queries involving row or column calculations, motivated by our analysis on the SQL query distributions. Finally, we adopt an effective data construction framework via human-computer collaboration. The basic idea is automatically generating SQL queries based on the SQL grammar and constrained by the given database. This paper describes in detail the construction process and data statistics of DuSQL. Moreover, we present and compare performance of several open-source textto-SQL parsers with minor modification to accommodate Chinese, including a simple yet effective extension to IRNet for handling calculation SQL queries.","dusql : large - scale pragmatic chinese text - - sql dataset lack label datum , previous research text - - sql parsing mainly focus english . representative english dataset include atis , wikisql , spider , etc . paper present dusql , larges - scale pragmatic chinese dataset cross - domain text - - sql task , contain 200 database , 813 table , 23,797 question / sql pair . new dataset major characteristic . , manually analyze question representative application , try figure true distribution sql query real - life need . second , dusql contain considerable proportion sql query involve row column calculation , motivate analysis sql query distribution . finally , adopt effective data construction framework human - computer collaboration . basic idea automatically generate sql query base sql grammar constrain give database . paper describe detail construction process datum statistic dusql . , present compare performance open - source textto - sql parser minor modification accommodate chinese , include simple effective extension irnet handle calculation sql query .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 2, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas","Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition","Knowledge of a disease includes information of various aspects of the disease, such as signs and symptoms, diagnosis and treatment. This disease knowledge is critical for many healthrelated and biomedical tasks, including consumer health question answering, medical language inference and disease name recognition. While pre-trained language models like BERT have shown success in capturing syntactic, semantic, and world knowledge from text, we find they can be further complemented by specific information like knowledge of symptoms, diagnoses, treatments, and other disease aspects. Hence, we integrate BERT with disease knowledge for improving these important tasks. Specifically, we propose a new disease knowledge infusion training procedure and evaluate it on a suite of BERT models including BERT, BioBERT, SciBERT, Clinical-BERT, BlueBERT, and ALBERT. Experiments over the three tasks show that these models can be enhanced in nearly all cases, demonstrating the viability of disease knowledge infusion. For example, accuracy of BioBERT on consumer health question answering is improved from 68.29% to 72.09%, while new SOTA results are observed in two datasets. We make our data and code freely available.","Infusing Disease Knowledge into BERT for Health Question Answering, Medical Inference and Disease Name Recognition Knowledge of a disease includes information of various aspects of the disease, such as signs and symptoms, diagnosis and treatment. This disease knowledge is critical for many healthrelated and biomedical tasks, including consumer health question answering, medical language inference and disease name recognition. While pre-trained language models like BERT have shown success in capturing syntactic, semantic, and world knowledge from text, we find they can be further complemented by specific information like knowledge of symptoms, diagnoses, treatments, and other disease aspects. Hence, we integrate BERT with disease knowledge for improving these important tasks. Specifically, we propose a new disease knowledge infusion training procedure and evaluate it on a suite of BERT models including BERT, BioBERT, SciBERT, Clinical-BERT, BlueBERT, and ALBERT. Experiments over the three tasks show that these models can be enhanced in nearly all cases, demonstrating the viability of disease knowledge infusion. For example, accuracy of BioBERT on consumer health question answering is improved from 68.29% to 72.09%, while new SOTA results are observed in two datasets. We make our data and code freely available.","infuse disease knowledge bert health question answering , medical inference disease recognition knowledge disease include information aspect disease , sign symptom , diagnosis treatment . disease knowledge critical healthrelated biomedical task , include consumer health question answering , medical language inference disease recognition . pre - train language model like bert show success capture syntactic , semantic , world knowledge text , find complement specific information like knowledge symptom , diagnosis , treatment , disease aspect . , integrate bert disease knowledge improve important task . specifically , propose new disease knowledge infusion training procedure evaluate suite bert model include bert , biobert , scibert , clinical - bert , bluebert , albert . experiment task model enhance nearly case , demonstrate viability disease knowledge infusion . example , accuracy biobert consumer health question answer improve 68.29 % 72.09 % , new sota result observe dataset . datum code freely available .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 13, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Discriminatively-Tuned Generative Classifiers for Robust Natural Language Inference,"While discriminative neural network classifiers are generally preferred, recent work has shown advantages of generative classifiers in term of data efficiency and robustness. In this paper, we focus on natural language inference (NLI). We propose GenNLI, a generative classifier for NLI tasks, and empirically characterize its performance by comparing it to five baselines, including discriminative models and large-scale pretrained language representation models like BERT. We explore training objectives for discriminative fine-tuning of our generative classifiers, showing improvements over log loss fine-tuning from prior work (Lewis and Fan, 2019) . In particular, we find strong results with a simple unbounded modification to log loss, which we call the ""infinilog loss"". Our experiments show that GenNLI outperforms both discriminative and pretrained baselines across several challenging NLI experimental settings, including small training sets, imbalanced label distributions, and label noise. * Equal contribution. † Contribution during visiting TTIC.","Discriminatively-Tuned Generative Classifiers for Robust Natural Language Inference While discriminative neural network classifiers are generally preferred, recent work has shown advantages of generative classifiers in term of data efficiency and robustness. In this paper, we focus on natural language inference (NLI). We propose GenNLI, a generative classifier for NLI tasks, and empirically characterize its performance by comparing it to five baselines, including discriminative models and large-scale pretrained language representation models like BERT. We explore training objectives for discriminative fine-tuning of our generative classifiers, showing improvements over log loss fine-tuning from prior work (Lewis and Fan, 2019) . In particular, we find strong results with a simple unbounded modification to log loss, which we call the ""infinilog loss"". Our experiments show that GenNLI outperforms both discriminative and pretrained baselines across several challenging NLI experimental settings, including small training sets, imbalanced label distributions, and label noise. * Equal contribution. † Contribution during visiting TTIC.","discriminatively - tune generative classifier robust natural language inference discriminative neural network classifier generally prefer , recent work show advantage generative classifier term datum efficiency robustness . paper , focus natural language inference ( nli ) . propose gennli , generative classifier nli task , empirically characterize performance compare baseline , include discriminative model large - scale pretrained language representation model like bert . explore training objective discriminative fine - tuning generative classifier , show improvement log loss fine - tuning prior work ( lewis fan , 2019 ) . particular , find strong result simple unbounded modification log loss , "" infinilog loss "" . experiment gennli outperform discriminative pretrained baseline challenging nli experimental setting , include small training set , imbalanced label distribution , label noise . * equal contribution . † contribution visit ttic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Analogous Process Structure Induction for Sub-event Sequence Prediction,"Computational and cognitive studies of event understanding suggest that identifying, comprehending, and predicting events depend on having structured representations of a sequence of events and on conceptualizing (abstracting) its components into (soft) event categories. Thus, knowledge about a known process such as ""buying a car"" can be used in the context of a new but analogous process such as ""buying a house"". Nevertheless, most event understanding work in NLP is still at the ground level and does not consider abstraction. In this paper, we propose an Analogous Process Structure Induction (APSI) framework, which leverages analogies among processes and conceptualization of sub-event instances to predict the whole sub-event sequence of previously unseen open-domain processes. As our experiments and analysis indicate, APSI 1 supports the generation of meaningful sub-event sequences for unseen processes and can help predict missing events.","Analogous Process Structure Induction for Sub-event Sequence Prediction Computational and cognitive studies of event understanding suggest that identifying, comprehending, and predicting events depend on having structured representations of a sequence of events and on conceptualizing (abstracting) its components into (soft) event categories. Thus, knowledge about a known process such as ""buying a car"" can be used in the context of a new but analogous process such as ""buying a house"". Nevertheless, most event understanding work in NLP is still at the ground level and does not consider abstraction. In this paper, we propose an Analogous Process Structure Induction (APSI) framework, which leverages analogies among processes and conceptualization of sub-event instances to predict the whole sub-event sequence of previously unseen open-domain processes. As our experiments and analysis indicate, APSI 1 supports the generation of meaningful sub-event sequences for unseen processes and can help predict missing events.","analogous process structure induction sub - event sequence prediction computational cognitive study event understanding suggest identify , comprehend , predict event depend have structure representation sequence event conceptualize ( abstract ) component ( soft ) event category . , knowledge know process "" buy car "" context new analogous process "" buy house "" . , event understanding work nlp ground level consider abstraction . paper , propose analogous process structure induction ( apsi ) framework , leverage analogy process conceptualization sub - event instance predict sub - event sequence previously unseen open - domain process . experiment analysis indicate , apsi 1 support generation meaningful sub - event sequence unseen process help predict miss event .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Causal Inference of Script Knowledge,"When does a sequence of events define an everyday scenario and how can this knowledge be induced from text? Prior works in inducing such scripts have relied on, in one form or another, measures of correlation between instances of events in a corpus. We argue from both a conceptual and practical sense that a purely correlation-based approach is insufficient, and instead propose an approach to script induction based on the causal effect between events, formally defined via interventions. Through both human and automatic evaluations, we show that the output of our method based on causal effects better matches the intuition of what a script represents.","Causal Inference of Script Knowledge When does a sequence of events define an everyday scenario and how can this knowledge be induced from text? Prior works in inducing such scripts have relied on, in one form or another, measures of correlation between instances of events in a corpus. We argue from both a conceptual and practical sense that a purely correlation-based approach is insufficient, and instead propose an approach to script induction based on the causal effect between events, formally defined via interventions. Through both human and automatic evaluations, we show that the output of our method based on causal effects better matches the intuition of what a script represents.","causal inference script knowledge sequence event define everyday scenario knowledge induce text ? prior work induce script rely , form , measure correlation instance event corpus . argue conceptual practical sense purely correlation - base approach insufficient , instead propose approach script induction base causal effect event , formally define intervention . human automatic evaluation , output method base causal effect well match intuition script represent .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Extraction,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",XL-AMR: Enabling Cross-Lingual AMR Parsing with Transfer Learning Techniques,"Meaning Representation (AMR) is a popular formalism of natural language that represents the meaning of a sentence as a semantic graph. It is agnostic about how to derive meanings from strings and for this reason it lends itself well to the encoding of semantics across languages. However, cross-lingual AMR parsing is a hard task, because training data are scarce in languages other than English and the existing English AMR parsers are not directly suited to being used in a cross-lingual setting. In this work we tackle these two problems so as to enable cross-lingual AMR parsing: we explore different transfer learning techniques for producing automatic AMR annotations across languages and develop a crosslingual AMR parser, XL-AMR. This can be trained on the produced data and does not rely on AMR aligners or source-copy mechanisms as is commonly the case in English AMR parsing. The results of XL-AMR significantly surpass those previously reported in Chinese, German, Italian and Spanish. Finally we provide a qualitative analysis which sheds light on the suitability of AMR across languages. We release XL-AMR at github.com/SapienzaNLP/xlamr.","XL-AMR: Enabling Cross-Lingual AMR Parsing with Transfer Learning Techniques Meaning Representation (AMR) is a popular formalism of natural language that represents the meaning of a sentence as a semantic graph. It is agnostic about how to derive meanings from strings and for this reason it lends itself well to the encoding of semantics across languages. However, cross-lingual AMR parsing is a hard task, because training data are scarce in languages other than English and the existing English AMR parsers are not directly suited to being used in a cross-lingual setting. In this work we tackle these two problems so as to enable cross-lingual AMR parsing: we explore different transfer learning techniques for producing automatic AMR annotations across languages and develop a crosslingual AMR parser, XL-AMR. This can be trained on the produced data and does not rely on AMR aligners or source-copy mechanisms as is commonly the case in English AMR parsing. The results of XL-AMR significantly surpass those previously reported in Chinese, German, Italian and Spanish. Finally we provide a qualitative analysis which sheds light on the suitability of AMR across languages. We release XL-AMR at github.com/SapienzaNLP/xlamr.","xl - amr : enable cross - lingual amr parsing transfer learning techniques meaning representation ( amr ) popular formalism natural language represent meaning sentence semantic graph . agnostic derive meaning string reason lend encoding semantic language . , cross - lingual amr parsing hard task , training datum scarce language english exist english amr parser directly suit cross - lingual setting . work tackle problem enable cross - lingual amr parsing : explore different transfer learning technique produce automatic amr annotation language develop crosslingual amr parser , xl - amr . train produce datum rely amr aligner source - copy mechanism commonly case english amr parsing . result xl - amr significantly surpass previously report chinese , german , italian spanish . finally provide qualitative analysis shed light suitability amr language . release xl - amr github.com/sapienzanlp/xlamr .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas","Reasoning about Goals, Steps, and Temporal Ordering with WikiHow","We propose a suite of reasoning tasks on two types of relations between procedural events: GOAL-STEP relations (""learn poses"" is a step in the larger goal of ""doing yoga"") and STEP-STEP TEMPORAL relations (""buy a yoga mat"" typically precedes ""learn poses""). We introduce a dataset targeting these two relations based on wikiHow, a website of instructional how-to articles. Our human-validated test set serves as a reliable benchmark for commonsense inference, with a gap of about 10% to 20% between the performance of state-ofthe-art transformer models and human performance. Our automatically-generated training set allows models to effectively transfer to outof-domain tasks requiring knowledge of procedural events, with greatly improved performances on SWAG, Snips, and Story Cloze Test in zero-and few-shot settings.","Reasoning about Goals, Steps, and Temporal Ordering with WikiHow We propose a suite of reasoning tasks on two types of relations between procedural events: GOAL-STEP relations (""learn poses"" is a step in the larger goal of ""doing yoga"") and STEP-STEP TEMPORAL relations (""buy a yoga mat"" typically precedes ""learn poses""). We introduce a dataset targeting these two relations based on wikiHow, a website of instructional how-to articles. Our human-validated test set serves as a reliable benchmark for commonsense inference, with a gap of about 10% to 20% between the performance of state-ofthe-art transformer models and human performance. Our automatically-generated training set allows models to effectively transfer to outof-domain tasks requiring knowledge of procedural events, with greatly improved performances on SWAG, Snips, and Story Cloze Test in zero-and few-shot settings.","reason goal , step , temporal ordering wikihow propose suite reasoning task type relation procedural event : goal - step relation ( "" learn pose "" step large goal "" yoga "" ) step - step temporal relation ( "" buy yoga mat "" typically precede "" learn pose "" ) . introduce dataset target relation base wikihow , website instructional - article . human - validate test set serve reliable benchmark commonsense inference , gap 10 % 20 % performance state - ofthe - art transformer model human performance . automatically - generate training set allow model effectively transfer outof - domain task require knowledge procedural event , greatly improve performance swag , snips , story cloze test zero - - shot setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas","The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions","We find that the performance of state-of-theart models on Natural Language Inference (NLI) and Reading Comprehension (RC) analysis/stress sets can be highly unstable. This raises three questions: (1) How will the instability affect the reliability of the conclusions drawn based on these analysis sets? (2) Where does this instability come from? (3) How should we handle this instability and what are some potential solutions? For the first question, we conduct a thorough empirical study over analysis sets and find that in addition to the unstable final performance, the instability exists all along the training curve. We also observe lower-than-expected correlations between the analysis validation set and standard validation set, questioning the effectiveness of the current model-selection routine. Next, to answer the second question, we give both theoretical explanations and empirical evidence regarding the source of the instability, demonstrating that the instability mainly comes from high inter-example correlations within analysis sets. Finally, for the third question, we discuss an initial attempt to mitigate the instability and suggest guidelines for future work such as reporting the decomposed variance for more interpretable results and fair comparison across models. 1","The Curse of Performance Instability in Analysis Datasets: Consequences, Source, and Suggestions We find that the performance of state-of-theart models on Natural Language Inference (NLI) and Reading Comprehension (RC) analysis/stress sets can be highly unstable. This raises three questions: (1) How will the instability affect the reliability of the conclusions drawn based on these analysis sets? (2) Where does this instability come from? (3) How should we handle this instability and what are some potential solutions? For the first question, we conduct a thorough empirical study over analysis sets and find that in addition to the unstable final performance, the instability exists all along the training curve. We also observe lower-than-expected correlations between the analysis validation set and standard validation set, questioning the effectiveness of the current model-selection routine. Next, to answer the second question, we give both theoretical explanations and empirical evidence regarding the source of the instability, demonstrating that the instability mainly comes from high inter-example correlations within analysis sets. Finally, for the third question, we discuss an initial attempt to mitigate the instability and suggest guidelines for future work such as reporting the decomposed variance for more interpretable results and fair comparison across models. 1","curse performance instability analysis dataset : consequence , source , suggestion find performance state - - theart model natural language inference ( nli ) reading comprehension ( rc ) analysis / stress set highly unstable . raise question : ( 1 ) instability affect reliability conclusion draw base analysis set ? ( 2 ) instability come ? ( 3 ) handle instability potential solution ? question , conduct thorough empirical study analysis set find addition unstable final performance , instability exist training curve . observe low - - expect correlation analysis validation set standard validation set , question effectiveness current model - selection routine . , answer second question , theoretical explanation empirical evidence source instability , demonstrate instability mainly come high inter - example correlation analysis set . finally , question , discuss initial attempt mitigate instability suggest guideline future work report decompose variance interpretable result fair comparison model . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 9, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Mention Extraction and Linking for SQL Query Generation,"On the WikiSQL benchmark, state-of-the-art text-to-SQL systems typically take a slotfilling approach by building several dedicated models for each type of slots. Such modularized systems are not only complex but also of limited capacity for capturing interdependencies among SQL clauses. To solve these problems, this paper proposes a novel extraction-linking approach, where a unified extractor recognizes all types of slot mentions appearing in the question sentence before a linker maps the recognized columns to the table schema to generate executable SQL queries. Trained with automatically generated annotations, the proposed method achieves the first place on the WikiSQL benchmark.","Mention Extraction and Linking for SQL Query Generation On the WikiSQL benchmark, state-of-the-art text-to-SQL systems typically take a slotfilling approach by building several dedicated models for each type of slots. Such modularized systems are not only complex but also of limited capacity for capturing interdependencies among SQL clauses. To solve these problems, this paper proposes a novel extraction-linking approach, where a unified extractor recognizes all types of slot mentions appearing in the question sentence before a linker maps the recognized columns to the table schema to generate executable SQL queries. Trained with automatically generated annotations, the proposed method achieves the first place on the WikiSQL benchmark.","mention extraction linking sql query generation wikisql benchmark , state - - - art text - - sql system typically slotfilling approach build dedicate model type slot . modularized system complex limited capacity capture interdependency sql clause . solve problem , paper propose novel extraction - linking approach , unified extractor recognize type slot mention appear question sentence linker map recognize column table schema generate executable sql query . train automatically generate annotation , propose method achieve place wikisql benchmark .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",AutoQA: From Databases To QA Semantic Parsers With Only Synthetic Training Data,"We propose AutoQA, a methodology and toolkit to generate semantic parsers that answer questions on databases, with no manual effort. Given a database schema and its data, AutoQA automatically generates a large set of high-quality questions for training that covers different database operations. It uses automatic paraphrasing combined with templatebased parsing to find alternative expressions of an attribute in different parts of speech. It also uses a novel filtered auto-paraphraser to generate correct paraphrases of entire sentences. We apply AutoQA to the Schema2QA dataset and obtain an average logical form accuracy of 62.9% when tested on natural questions, which is only 6.4% lower than a model trained with expert natural language annotations and paraphrase data collected from crowdworkers. To demonstrate the generality of AutoQA, we also apply it to the Overnight dataset. AutoQA achieves 69.8% answer accuracy, 16.4% higher than the state-of-the-art zero-shot models and only 5.2% lower than the same model trained with human data.","AutoQA: From Databases To QA Semantic Parsers With Only Synthetic Training Data We propose AutoQA, a methodology and toolkit to generate semantic parsers that answer questions on databases, with no manual effort. Given a database schema and its data, AutoQA automatically generates a large set of high-quality questions for training that covers different database operations. It uses automatic paraphrasing combined with templatebased parsing to find alternative expressions of an attribute in different parts of speech. It also uses a novel filtered auto-paraphraser to generate correct paraphrases of entire sentences. We apply AutoQA to the Schema2QA dataset and obtain an average logical form accuracy of 62.9% when tested on natural questions, which is only 6.4% lower than a model trained with expert natural language annotations and paraphrase data collected from crowdworkers. To demonstrate the generality of AutoQA, we also apply it to the Overnight dataset. AutoQA achieves 69.8% answer accuracy, 16.4% higher than the state-of-the-art zero-shot models and only 5.2% lower than the same model trained with human data.","autoqa : database qa semantic parser synthetic training datum propose autoqa , methodology toolkit generate semantic parser answer question database , manual effort . give database schema datum , autoqa automatically generate large set high - quality question training cover different database operation . use automatic paraphrasing combine templatebased parsing find alternative expression attribute different part speech . use novel filter auto - paraphraser generate correct paraphrase entire sentence . apply autoqa schema2qa dataset obtain average logical form accuracy 62.9 % test natural question , 6.4 % low model train expert natural language annotation paraphrase datum collect crowdworker . demonstrate generality autoqa , apply overnight dataset . autoqa achieve 69.8 % answer accuracy , 16.4 % high state - - - art zero - shot model 5.2 % low model train human datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 13, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Alignment-free Cross-lingual Semantic Role Labeling,"Cross-lingual semantic role labeling (SRL) aims at leveraging resources in a source language to minimize the effort required to construct annotations or models for a new target language. Recent approaches rely on word alignments, machine translation engines, or preprocessing tools such as parsers or taggers. We propose a cross-lingual SRL model which only requires annotations in a source language and access to raw text in the form of a parallel corpus. The backbone of our model is an LSTM-based semantic role labeler jointly trained with a semantic role compressor and multilingual word embeddings. The compressor collects useful information from the output of the semantic role labeler, filtering noisy and conflicting evidence. It lives in a multilingual embedding space and provides direct supervision for predicting semantic roles in the target language. Results on the Universal Proposition Bank and manually annotated datasets show that our method is highly effective, even against systems utilizing supervised features. 1","Alignment-free Cross-lingual Semantic Role Labeling Cross-lingual semantic role labeling (SRL) aims at leveraging resources in a source language to minimize the effort required to construct annotations or models for a new target language. Recent approaches rely on word alignments, machine translation engines, or preprocessing tools such as parsers or taggers. We propose a cross-lingual SRL model which only requires annotations in a source language and access to raw text in the form of a parallel corpus. The backbone of our model is an LSTM-based semantic role labeler jointly trained with a semantic role compressor and multilingual word embeddings. The compressor collects useful information from the output of the semantic role labeler, filtering noisy and conflicting evidence. It lives in a multilingual embedding space and provides direct supervision for predicting semantic roles in the target language. Results on the Universal Proposition Bank and manually annotated datasets show that our method is highly effective, even against systems utilizing supervised features. 1","alignment - free cross - lingual semantic role labeling cross - lingual semantic role labeling ( srl ) aim leverage resource source language minimize effort require construct annotation model new target language . recent approach rely word alignment , machine translation engine , preprocessing tool parser tagger . propose cross - lingual srl model require annotation source language access raw text form parallel corpus . backbone model lstm - base semantic role labeler jointly train semantic role compressor multilingual word embedding . compressor collect useful information output semantic role labeler , filter noisy conflicting evidence . live multilingual embedding space provide direct supervision predict semantic role target language . result universal proposition bank manually annotate dataset method highly effective , system utilize supervised feature . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",ConjNLI: Natural Language Inference Over Conjunctive Sentences,"Reasoning about conjuncts in conjunctive sentences is important for a deeper understanding of conjunctions in English and also how their usages and semantics differ from conjunctive and disjunctive boolean logic. Existing NLI stress tests do not consider non-boolean usages of conjunctions and use templates for testing such model knowledge. Hence, we introduce CONJNLI, a challenge stress-test for natural language inference over conjunctive sentences, where the premise differs from the hypothesis by conjuncts removed, added, or replaced. These sentences contain single and multiple instances of coordinating conjunctions (""and"", ""or"", ""but"", ""nor"") with quantifiers, negations, and requiring diverse boolean and non-boolean inferences over conjuncts. We find that large-scale pre-trained language models like RoBERTa do not understand conjunctive semantics well and resort to shallow heuristics to make inferences over such sentences. As some initial solutions, we first present an iterative adversarial fine-tuning method that uses synthetically created training data based on boolean and non-boolean heuristics. We also propose a direct model advancement by making RoBERTa aware of predicate semantic roles. While we observe some performance gains, CONJNLI is still challenging for current methods, thus encouraging interesting future work for better understanding of conjunctions. 1","ConjNLI: Natural Language Inference Over Conjunctive Sentences Reasoning about conjuncts in conjunctive sentences is important for a deeper understanding of conjunctions in English and also how their usages and semantics differ from conjunctive and disjunctive boolean logic. Existing NLI stress tests do not consider non-boolean usages of conjunctions and use templates for testing such model knowledge. Hence, we introduce CONJNLI, a challenge stress-test for natural language inference over conjunctive sentences, where the premise differs from the hypothesis by conjuncts removed, added, or replaced. These sentences contain single and multiple instances of coordinating conjunctions (""and"", ""or"", ""but"", ""nor"") with quantifiers, negations, and requiring diverse boolean and non-boolean inferences over conjuncts. We find that large-scale pre-trained language models like RoBERTa do not understand conjunctive semantics well and resort to shallow heuristics to make inferences over such sentences. As some initial solutions, we first present an iterative adversarial fine-tuning method that uses synthetically created training data based on boolean and non-boolean heuristics. We also propose a direct model advancement by making RoBERTa aware of predicate semantic roles. While we observe some performance gains, CONJNLI is still challenging for current methods, thus encouraging interesting future work for better understanding of conjunctions. 1","conjnli : natural language inference conjunctive sentence reason conjunct conjunctive sentence important deep understanding conjunction english usage semantic differ conjunctive disjunctive boolean logic . exist nli stress test consider non - boolean usage conjunction use template test model knowledge . , introduce conjnli , challenge stress - test natural language inference conjunctive sentence , premise differ hypothesis conjunct remove , add , replace . sentence contain single multiple instance coordinate conjunction ( "" "" , "" "" , "" "" , "" "" ) quantifier , negation , require diverse boolean non - boolean inference conjunct . find large - scale pre - trained language model like roberta understand conjunctive semantic resort shallow heuristic inference sentence . initial solution , present iterative adversarial fine - tuning method use synthetically create training datum base boolean non - boolean heuristic . propose direct model advancement make roberta aware predicate semantic role . observe performance gain , conjnli challenge current method , encourage interesting future work well understanding conjunction . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",An Analysis of Natural Language Inference Benchmarks through the Lens of Negation,"Negation is underrepresented in existing natural language inference benchmarks. Additionally, one can often ignore the few negations in existing benchmarks and still make the right inference judgments. In this paper, we present a new benchmark for natural language inference in which negation plays an important role. We also show that state-of-the-art transformers struggle making inference judgments with the new pairs.","An Analysis of Natural Language Inference Benchmarks through the Lens of Negation Negation is underrepresented in existing natural language inference benchmarks. Additionally, one can often ignore the few negations in existing benchmarks and still make the right inference judgments. In this paper, we present a new benchmark for natural language inference in which negation plays an important role. We also show that state-of-the-art transformers struggle making inference judgments with the new pairs.","analysis natural language inference benchmark lens negation negation underrepresente exist natural language inference benchmark . additionally , ignore negation exist benchmark right inference judgment . paper , present new benchmark natural language inference negation play important role . state - - - art transformer struggle make inference judgment new pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",What Can We Learn from Collective Human Opinions on Natural Language Inference Data?,"Despite the subjective nature of many NLP tasks, most NLU evaluations have focused on using the majority label with presumably high agreement as the ground truth. Less attention has been paid to the distribution of human opinions. We collect ChaosNLI, a dataset with a total of 464,500 annotations to study Collective HumAn OpinionS in oft-used NLI evaluation sets. This dataset is created by collecting 100 annotations per example for 3,113 examples in SNLI and MNLI and 1,532 examples in αNLI. Analysis reveals that: (1) high human disagreement exists in a noticeable amount of examples in these datasets; (2) the state-of-the-art models lack the ability to recover the distribution over human labels; (3) models achieve near-perfect accuracy on the subset of data with a high level of human agreement, whereas they can barely beat a random guess on the data with low levels of human agreement, which compose most of the common errors made by state-of-the-art models on the evaluation sets. This questions the validity of improving model performance on old metrics for the low-agreement part of evaluation datasets. Hence, we argue for a detailed examination of human agreement in future data collection efforts, and evaluating model outputs against the distribution over collective human opinions. 1","What Can We Learn from Collective Human Opinions on Natural Language Inference Data? Despite the subjective nature of many NLP tasks, most NLU evaluations have focused on using the majority label with presumably high agreement as the ground truth. Less attention has been paid to the distribution of human opinions. We collect ChaosNLI, a dataset with a total of 464,500 annotations to study Collective HumAn OpinionS in oft-used NLI evaluation sets. This dataset is created by collecting 100 annotations per example for 3,113 examples in SNLI and MNLI and 1,532 examples in αNLI. Analysis reveals that: (1) high human disagreement exists in a noticeable amount of examples in these datasets; (2) the state-of-the-art models lack the ability to recover the distribution over human labels; (3) models achieve near-perfect accuracy on the subset of data with a high level of human agreement, whereas they can barely beat a random guess on the data with low levels of human agreement, which compose most of the common errors made by state-of-the-art models on the evaluation sets. This questions the validity of improving model performance on old metrics for the low-agreement part of evaluation datasets. Hence, we argue for a detailed examination of human agreement in future data collection efforts, and evaluating model outputs against the distribution over collective human opinions. 1","learn collective human opinions natural language inference datum ? despite subjective nature nlp task , nlu evaluation focus majority label presumably high agreement ground truth . attention pay distribution human opinion . collect chaosnli , dataset total 464,500 annotation study collective human opinions oft - nli evaluation set . dataset create collect 100 annotation example 3,113 example snli mnli 1,532 example αnli . analysis reveal : ( 1 ) high human disagreement exist noticeable example dataset ; ( 2 ) state - - - art model lack ability recover distribution human label ; ( 3 ) model achieve near - perfect accuracy subset datum high level human agreement , barely beat random guess datum low level human agreement , compose common error state - - - art model evaluation set . question validity improve model performance old metric low - agreement evaluation dataset . , argue detailed examination human agreement future datum collection effort , evaluate model output distribution collective human opinion . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 7, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",A Dataset for Tracking Entities in Open Domain Procedural Text,"We present the first dataset for tracking state changes in procedural text from arbitrary domains by using an unrestricted (open) vocabulary. For example, in a text describing fog removal using potatoes, a car window may transition between being foggy, sticky, opaque, and clear. Previous formulations of this task provide the text and entities involved, and ask how those entities change for just a small, pre-defined set of attributes (e.g., location), limiting their fidelity. Our solution is a new task formulation where given just a procedural text as input, the task is to generate a set of state change tuples (entity, attribute, before-state, after-state) for each step, where the entity, attribute, and state values must be predicted from an open vocabulary. Using crowdsourcing, we create OPENPI 1 , a high-quality (91.5% coverage as judged by humans and completely vetted), and largescale dataset comprising 29,928 state changes over 4,050 sentences from 810 procedural realworld paragraphs from WikiHow.com. A current state-of-the-art generation model on this task achieves 16.1% F1 based on BLEU metric, leaving enough room for novel model architectures.","A Dataset for Tracking Entities in Open Domain Procedural Text We present the first dataset for tracking state changes in procedural text from arbitrary domains by using an unrestricted (open) vocabulary. For example, in a text describing fog removal using potatoes, a car window may transition between being foggy, sticky, opaque, and clear. Previous formulations of this task provide the text and entities involved, and ask how those entities change for just a small, pre-defined set of attributes (e.g., location), limiting their fidelity. Our solution is a new task formulation where given just a procedural text as input, the task is to generate a set of state change tuples (entity, attribute, before-state, after-state) for each step, where the entity, attribute, and state values must be predicted from an open vocabulary. Using crowdsourcing, we create OPENPI 1 , a high-quality (91.5% coverage as judged by humans and completely vetted), and largescale dataset comprising 29,928 state changes over 4,050 sentences from 810 procedural realworld paragraphs from WikiHow.com. A current state-of-the-art generation model on this task achieves 16.1% F1 based on BLEU metric, leaving enough room for novel model architectures.","dataset track entity open domain procedural text present dataset track state change procedural text arbitrary domain unrestricted ( open ) vocabulary . example , text describe fog removal potato , car window transition foggy , sticky , opaque , clear . previous formulation task provide text entity involve , ask entity change small , pre - defined set attribute ( e.g. , location ) , limit fidelity . solution new task formulation give procedural text input , task generate set state change tuple ( entity , attribute , - state , - state ) step , entity , attribute , state value predict open vocabulary . crowdsourcing , create openpi 1 , high - quality ( 91.5 % coverage judge human completely vet ) , largescale dataset comprise 29,928 state change 4,050 sentence 810 procedural realworld paragraph wikihow.com . current state - - - art generation model task achieve 16.1 % f1 base bleu metric , leave room novel model architecture .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 8, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",A Method for Building a Commonsense Inference Dataset based on Basic Events,"We present a scalable, low-bias, and low-cost method for building a commonsense inference dataset that combines automatic extraction from a corpus and crowdsourcing. Each problem is a multiple-choice question that asks contingency between basic events. We applied the proposed method to a Japanese corpus and acquired 104k problems. While humans can solve the resulting problems with high accuracy (88.9%), the accuracy of a highperformance transfer learning model is reasonably low (76.0%). We also confirmed through dataset analysis that the resulting dataset contains low bias. We released the datatset to facilitate language understanding research. 1","A Method for Building a Commonsense Inference Dataset based on Basic Events We present a scalable, low-bias, and low-cost method for building a commonsense inference dataset that combines automatic extraction from a corpus and crowdsourcing. Each problem is a multiple-choice question that asks contingency between basic events. We applied the proposed method to a Japanese corpus and acquired 104k problems. While humans can solve the resulting problems with high accuracy (88.9%), the accuracy of a highperformance transfer learning model is reasonably low (76.0%). We also confirmed through dataset analysis that the resulting dataset contains low bias. We released the datatset to facilitate language understanding research. 1","method build commonsense inference dataset base basic event present scalable , low - bias , low - cost method build commonsense inference dataset combine automatic extraction corpus crowdsourcing . problem multiple - choice question ask contingency basic event . apply propose method japanese corpus acquire 104k problem . human solve result problem high accuracy ( 88.9 % ) , accuracy highperformance transfer learning model reasonably low ( 76.0 % ) . confirm dataset analysis result dataset contain low bias . release datatset facilitate language understanding research . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Towards Debiasing NLU Models from Unknown Biases,"NLU models often exploit biases to achieve high dataset-specific performance without properly learning the intended task. Recently proposed debiasing methods are shown to be effective in mitigating this tendency. However, these methods rely on a major assumption that the types of bias should be known a-priori, which limits their application to many NLU tasks and datasets. In this work, we present the first step to bridge this gap by introducing a self-debiasing framework that prevents models from mainly utilizing biases without knowing them in advance. The proposed framework is general and complementary to the existing debiasing methods. We show that it allows these existing methods to retain the improvement on the challenge datasets (i.e., sets of examples designed to expose models' reliance on biases) without specifically targeting certain biases. Furthermore, the evaluation suggests that applying the framework results in improved overall robustness. 1","Towards Debiasing NLU Models from Unknown Biases NLU models often exploit biases to achieve high dataset-specific performance without properly learning the intended task. Recently proposed debiasing methods are shown to be effective in mitigating this tendency. However, these methods rely on a major assumption that the types of bias should be known a-priori, which limits their application to many NLU tasks and datasets. In this work, we present the first step to bridge this gap by introducing a self-debiasing framework that prevents models from mainly utilizing biases without knowing them in advance. The proposed framework is general and complementary to the existing debiasing methods. We show that it allows these existing methods to retain the improvement on the challenge datasets (i.e., sets of examples designed to expose models' reliance on biases) without specifically targeting certain biases. Furthermore, the evaluation suggests that applying the framework results in improved overall robustness. 1","debiase nlu model unknown bias nlu model exploit bias achieve high dataset - specific performance properly learn intend task . recently propose debiase method show effective mitigate tendency . , method rely major assumption type bias know - priori , limit application nlu task dataset . work , present step bridge gap introduce self - debiase framework prevent model mainly utilize bias know advance . propose framework general complementary exist debiase method . allow exist method retain improvement challenge dataset ( i.e. , set example design expose model ' reliance bias ) specifically target certain bias . furthermore , evaluation suggest apply framework result improve overall robustness . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 14, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Benchmarking Meaning Representations in Neural Semantic Parsing,"Meaning representation is an important component of semantic parsing. Although researchers have designed a lot of meaning representations, recent work focuses on only a few of them. Thus, the impact of meaning representation on semantic parsing is less understood. Furthermore, existing work's performance is often not comprehensively evaluated due to the lack of readily-available execution engines. Upon identifying these gaps, we propose UNIMER, a new unified benchmark on meaning representations, by integrating existing semantic parsing datasets, completing the missing logical forms, and implementing the missing execution engines. The resulting unified benchmark contains the complete enumeration of logical forms and execution engines over three datasets × four meaning representations. A thorough experimental study on UNIMER reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and grammar rules heavily impact the performance of different meaning representations. Our benchmark, execution engines and implementation can be found on: https: //github.com/JasperGuo/Unimer.","Benchmarking Meaning Representations in Neural Semantic Parsing Meaning representation is an important component of semantic parsing. Although researchers have designed a lot of meaning representations, recent work focuses on only a few of them. Thus, the impact of meaning representation on semantic parsing is less understood. Furthermore, existing work's performance is often not comprehensively evaluated due to the lack of readily-available execution engines. Upon identifying these gaps, we propose UNIMER, a new unified benchmark on meaning representations, by integrating existing semantic parsing datasets, completing the missing logical forms, and implementing the missing execution engines. The resulting unified benchmark contains the complete enumeration of logical forms and execution engines over three datasets × four meaning representations. A thorough experimental study on UNIMER reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and grammar rules heavily impact the performance of different meaning representations. Our benchmark, execution engines and implementation can be found on: https: //github.com/JasperGuo/Unimer.","benchmarke meaning representation neural semantic parsing meaning representation important component semantic parsing . researcher design lot meaning representation , recent work focus . , impact meaning representation semantic parsing understand . furthermore , exist work performance comprehensively evaluate lack readily - available execution engine . identify gap , propose unimer , new unified benchmark meaning representation , integrate exist semantic parsing dataset , complete miss logical form , implement miss execution engine . result unified benchmark contain complete enumeration logical form execution engine dataset × meaning representation . thorough experimental study unimer reveal neural semantic parsing approach exhibit notably different performance train generate different meaning representation . , program alias grammar rule heavily impact performance different meaning representation . benchmark , execution engine implementation find : https : //github.com / jasperguo / unimer .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 15, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Multitask Learning for Cross-Lingual Transfer of Broad-coverage Semantic Dependencies,We describe a method for developing broadcoverage semantic dependency parsers for languages for which no semantically annotated resource is available. We leverage a multitask learning framework coupled with annotation projection. We use syntactic parsing as the auxiliary task in our multitask setup. Our annotation projection experiments from English to Czech show that our multitask setup yields 3.1% (4.2%) improvement in labeled F1-score on in-domain (out-of-domain) test set compared to a single-task baseline.,Multitask Learning for Cross-Lingual Transfer of Broad-coverage Semantic Dependencies We describe a method for developing broadcoverage semantic dependency parsers for languages for which no semantically annotated resource is available. We leverage a multitask learning framework coupled with annotation projection. We use syntactic parsing as the auxiliary task in our multitask setup. Our annotation projection experiments from English to Czech show that our multitask setup yields 3.1% (4.2%) improvement in labeled F1-score on in-domain (out-of-domain) test set compared to a single-task baseline.,multitask learning cross - lingual transfer broad - coverage semantic dependency describe method develop broadcoverage semantic dependency parser language semantically annotate resource available . leverage multitask learning framework couple annotation projection . use syntactic parsing auxiliary task multitask setup . annotation projection experiment english czech multitask setup yield 3.1 % ( 4.2 % ) improvement label f1 - score - domain ( - - domain ) test set compare single - task baseline .,"{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Pre-training Mention Representations in Coreference Models,"Collecting labeled data for coreference resolution is a challenging task, requiring skilled annotators. It is thus desirable to develop coreference resolution models that can make use of unlabeled data. Here we provide such an approach for the powerful class of neural coreference models. These models rely on representations of mentions, and we show these representations can be learned in a self-supervised manner towards improving resolution accuracy. We propose two self-supervised tasks that are closely related to coreference resolution and thus improve mention representation. Applying this approach to the GAP dataset results in new state of the arts results.","Pre-training Mention Representations in Coreference Models Collecting labeled data for coreference resolution is a challenging task, requiring skilled annotators. It is thus desirable to develop coreference resolution models that can make use of unlabeled data. Here we provide such an approach for the powerful class of neural coreference models. These models rely on representations of mentions, and we show these representations can be learned in a self-supervised manner towards improving resolution accuracy. We propose two self-supervised tasks that are closely related to coreference resolution and thus improve mention representation. Applying this approach to the GAP dataset results in new state of the arts results.","pre - training mention representation coreference model collect label datum coreference resolution challenging task , require skilled annotator . desirable develop coreference resolution model use unlabeled datum . provide approach powerful class neural coreference model . model rely representation mention , representation learn self - supervise manner improve resolution accuracy . propose self - supervise task closely relate coreference resolution improve mention representation . apply approach gap dataset result new state art result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Modularized Syntactic Neural Networks for Sentence Classification,"This paper focuses on tree-based modeling for the sentence classification task. In existing works, aggregating on a syntax tree usually considers local information of sub-trees. In contrast, in addition to the local information, our proposed Modularized Syntactic Neural Network (MSNN) utilizes the syntax category labels and takes advantage of the global context while modeling sub-trees. In MSNN, each node of a syntax tree is modeled by a label-related syntax module. Each syntax module aggregates the outputs of lower-level modules, and finally, the root module provides the sentence representation. We design a tree-parallel mini-batch strategy for efficient training and predicting. Experimental results on four benchmark datasets show that our MSNN significantly outperforms previous state-of-the-art tree-based methods on the sentence classification task.","Modularized Syntactic Neural Networks for Sentence Classification This paper focuses on tree-based modeling for the sentence classification task. In existing works, aggregating on a syntax tree usually considers local information of sub-trees. In contrast, in addition to the local information, our proposed Modularized Syntactic Neural Network (MSNN) utilizes the syntax category labels and takes advantage of the global context while modeling sub-trees. In MSNN, each node of a syntax tree is modeled by a label-related syntax module. Each syntax module aggregates the outputs of lower-level modules, and finally, the root module provides the sentence representation. We design a tree-parallel mini-batch strategy for efficient training and predicting. Experimental results on four benchmark datasets show that our MSNN significantly outperforms previous state-of-the-art tree-based methods on the sentence classification task.","modularized syntactic neural networks sentence classification paper focus tree - base modeling sentence classification task . exist work , aggregate syntax tree usually consider local information sub - tree . contrast , addition local information , propose modularized syntactic neural network ( msnn ) utilize syntax category label take advantage global context model sub - tree . msnn , node syntax tree model label - relate syntax module . syntax module aggregate output low - level module , finally , root module provide sentence representation . design tree - parallel mini - batch strategy efficient training predicting . experimental result benchmark dataset msnn significantly outperform previous state - - - art tree - base method sentence classification task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 5}","Syntax: Tagging, Chunking and Parsing",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",IGSQL: Database Schema Interaction Graph Based Neural Model for Context-Dependent Text-to-SQL Generation,"Context-dependent text-to-SQL task has drawn much attention in recent years. Previous models on context-dependent text-to-SQL task only concentrate on utilizing historical user inputs. In this work, in addition to using encoders to capture historical information of user inputs, we propose a database schema interaction graph encoder to utilize historicalal information of database schema items. In decoding phase, we introduce a gate mechanism to weigh the importance of different vocabularies and then make the prediction of SQL tokens. We evaluate our model on the benchmark SParC and CoSQL datasets, which are two large complex context-dependent cross-domain text-to-SQL datasets. Our model outperforms previous state-of-the-art model by a large margin and achieves new state-of-the-art results on the two datasets. The comparison and ablation results demonstrate the efficacy of our model and the usefulness of the database schema interaction graph encoder.","IGSQL: Database Schema Interaction Graph Based Neural Model for Context-Dependent Text-to-SQL Generation Context-dependent text-to-SQL task has drawn much attention in recent years. Previous models on context-dependent text-to-SQL task only concentrate on utilizing historical user inputs. In this work, in addition to using encoders to capture historical information of user inputs, we propose a database schema interaction graph encoder to utilize historicalal information of database schema items. In decoding phase, we introduce a gate mechanism to weigh the importance of different vocabularies and then make the prediction of SQL tokens. We evaluate our model on the benchmark SParC and CoSQL datasets, which are two large complex context-dependent cross-domain text-to-SQL datasets. Our model outperforms previous state-of-the-art model by a large margin and achieves new state-of-the-art results on the two datasets. The comparison and ablation results demonstrate the efficacy of our model and the usefulness of the database schema interaction graph encoder.","igsql : database schema interaction graph base neural model context - dependent text - - sql generation context - dependent text - - sql task draw attention recent year . previous model context - dependent text - - sql task concentrate utilize historical user input . work , addition encoder capture historical information user input , propose database schema interaction graph encoder utilize historicalal information database schema item . decoding phase , introduce gate mechanism weigh importance different vocabulary prediction sql token . evaluate model benchmark sparc cosql dataset , large complex context - dependent cross - domain text - - sql dataset . model outperform previous state - - - art model large margin achieve new state - - - art result dataset . comparison ablation result demonstrate efficacy model usefulness database schema interaction graph encoder .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",New Protocols and Negative Results for Textual Entailment Data Collection,"Natural language inference (NLI) data has proven useful in benchmarking and, especially, as pretraining data for tasks requiring language understanding. However, the crowdsourcing protocol that was used to collect this data has known issues and was not explicitly optimized for either of these purposes, so it is likely far from ideal. We propose four alternative protocols, each aimed at improving either the ease with which annotators can produce sound training examples or the quality and diversity of those examples. Using these alternatives and a fifth baseline protocol, we collect and compare five new 8.5k-example training sets. In evaluations focused on transfer learning applications, our results are solidly negative, with models trained on our baseline dataset yielding good transfer performance to downstream tasks, but none of our four new methods (nor the recent ANLI) showing any improvements over that baseline. In a small silver lining, we observe that all four new protocols, especially those where annotators edit pre-filled text boxes, reduce previously observed issues with annotation artifacts.","New Protocols and Negative Results for Textual Entailment Data Collection Natural language inference (NLI) data has proven useful in benchmarking and, especially, as pretraining data for tasks requiring language understanding. However, the crowdsourcing protocol that was used to collect this data has known issues and was not explicitly optimized for either of these purposes, so it is likely far from ideal. We propose four alternative protocols, each aimed at improving either the ease with which annotators can produce sound training examples or the quality and diversity of those examples. Using these alternatives and a fifth baseline protocol, we collect and compare five new 8.5k-example training sets. In evaluations focused on transfer learning applications, our results are solidly negative, with models trained on our baseline dataset yielding good transfer performance to downstream tasks, but none of our four new methods (nor the recent ANLI) showing any improvements over that baseline. In a small silver lining, we observe that all four new protocols, especially those where annotators edit pre-filled text boxes, reduce previously observed issues with annotation artifacts.","new protocol negative result textual entailment datum collection natural language inference ( nli ) datum prove useful benchmarking , especially , pretraine datum task require language understanding . , crowdsourcing protocol collect datum know issue explicitly optimize purpose , likely far ideal . propose alternative protocol , aim improve ease annotator produce sound training example quality diversity example . alternative fifth baseline protocol , collect compare new 8.5k - example training set . evaluation focus transfer learning application , result solidly negative , model train baseline dataset yield good transfer performance downstream task , new method ( recent anli ) show improvement baseline . small silver lining , observe new protocol , especially annotator edit pre - filled text box , reduce previously observe issue annotation artifact .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Semantic Evaluation for Text-to-SQL with Distilled Test Suites,"We propose test suite accuracy to approximate semantic accuracy for Text-to-SQL models. Our method distills a small test suite of databases that achieves high code coverage for the gold query from a large number of randomly generated databases. At evaluation time, it computes the denotation accuracy of the predicted queries on the distilled test suite, hence calculating a tight upper-bound for semantic accuracy efficiently. We use our proposed method to evaluate 21 models submitted to the Spider leader board and manually verify that our method is always correct on 100 examples. In contrast, the current Spider metric leads to a 2.5% false negative rate on average and 8.1% in the worst case, indicating that test suite accuracy is needed. Our implementation, along with distilled test suites for eleven Textto-SQL datasets, is publicly available. 1","Semantic Evaluation for Text-to-SQL with Distilled Test Suites We propose test suite accuracy to approximate semantic accuracy for Text-to-SQL models. Our method distills a small test suite of databases that achieves high code coverage for the gold query from a large number of randomly generated databases. At evaluation time, it computes the denotation accuracy of the predicted queries on the distilled test suite, hence calculating a tight upper-bound for semantic accuracy efficiently. We use our proposed method to evaluate 21 models submitted to the Spider leader board and manually verify that our method is always correct on 100 examples. In contrast, the current Spider metric leads to a 2.5% false negative rate on average and 8.1% in the worst case, indicating that test suite accuracy is needed. Our implementation, along with distilled test suites for eleven Textto-SQL datasets, is publicly available. 1","semantic evaluation text - - sql distil test suite propose test suite accuracy approximate semantic accuracy text - - sql model . method distill small test suite database achieve high code coverage gold query large number randomly generate database . evaluation time , compute denotation accuracy predict query distil test suite , calculate tight upper - bound semantic accuracy efficiently . use propose method evaluate 21 model submit spider leader board manually verify method correct 100 example . contrast , current spider metric lead 2.5 % false negative rate average 8.1 % bad case , indicate test suite accuracy need . implementation , distil test suite textto - sql dataset , publicly available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Re-examining the Role of Schema Linking in Text-to-SQL,"In existing sophisticated text-to-SQL models, schema linking is often considered as a simple, minor component, belying its importance. By providing a schema linking corpus based on the Spider text-to-SQL dataset, we systematically study the role of schema linking. We also build a simple BERT-based baseline, called Schema-Linking SQL (SLSQL) to perform a data-driven study. We find when schema linking is done well, SLSQL demonstrates good performance on Spider despite its structural simplicity. Many remaining errors are attributable to corpus noise. This suggests schema linking is the crux for the current textto-SQL task. Our analytic studies provide insights on the characteristics of schema linking for future developments of text-to-SQL tasks. 1 * Equal contribution.","Re-examining the Role of Schema Linking in Text-to-SQL In existing sophisticated text-to-SQL models, schema linking is often considered as a simple, minor component, belying its importance. By providing a schema linking corpus based on the Spider text-to-SQL dataset, we systematically study the role of schema linking. We also build a simple BERT-based baseline, called Schema-Linking SQL (SLSQL) to perform a data-driven study. We find when schema linking is done well, SLSQL demonstrates good performance on Spider despite its structural simplicity. Many remaining errors are attributable to corpus noise. This suggests schema linking is the crux for the current textto-SQL task. Our analytic studies provide insights on the characteristics of schema linking for future developments of text-to-SQL tasks. 1 * Equal contribution.","- examine role schema linking text - - sql exist sophisticated text - - sql model , schema linking consider simple , minor component , belie importance . provide schema link corpus base spider text - - sql dataset , systematically study role schema linking . build simple bert - base baseline , call schema - linking sql ( slsql ) perform data - drive study . find schema linking , slsql demonstrate good performance spider despite structural simplicity . remain error attributable corpus noise . suggest schema linking crux current textto - sql task . analytic study provide insight characteristic schema linking future development text - - sql task . 1 * equal contribution .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Compositional Phrase Alignment and Beyond,"Phrase alignment is the basis for modelling sentence pair interactions, such as paraphrase and textual entailment recognition. Most phrase alignments are compositional processes such that an alignment of a phrase pair is constructed based on the alignments of their child phrases. Nonetheless, studies have revealed that non-compositional alignments involving long-distance phrase reordering are prevalent in practice. We address the phrase alignment problem by combining an unordered tree mapping algorithm and phrase representation modelling that explicitly embeds the similarity distribution in the sentences onto powerful contextualized representations. Experimental results demonstrate that our method effectively handles compositional and non-compositional global phrase alignments. Our method significantly outperforms that used in a previous study and achieves a performance competitive with that of experienced human annotators.","Compositional Phrase Alignment and Beyond Phrase alignment is the basis for modelling sentence pair interactions, such as paraphrase and textual entailment recognition. Most phrase alignments are compositional processes such that an alignment of a phrase pair is constructed based on the alignments of their child phrases. Nonetheless, studies have revealed that non-compositional alignments involving long-distance phrase reordering are prevalent in practice. We address the phrase alignment problem by combining an unordered tree mapping algorithm and phrase representation modelling that explicitly embeds the similarity distribution in the sentences onto powerful contextualized representations. Experimental results demonstrate that our method effectively handles compositional and non-compositional global phrase alignments. Our method significantly outperforms that used in a previous study and achieves a performance competitive with that of experienced human annotators.","compositional phrase alignment phrase alignment basis model sentence pair interaction , paraphrase textual entailment recognition . phrase alignment compositional process alignment phrase pair construct base alignment child phrase . nonetheless , study reveal non - compositional alignment involve long - distance phrase reordering prevalent practice . address phrase alignment problem combine unordered tree mapping algorithm phrase representation modelling explicitly embed similarity distribution sentence powerful contextualize representation . experimental result demonstrate method effectively handle compositional non - compositional global phrase alignment . method significantly outperform previous study achieve performance competitive experienced human annotator .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Fast semantic parsing with well-typedness guarantees,"AM dependency parsing is a linguistically principled method for neural semantic parsing with high accuracy across multiple graphbanks. It relies on a type system that models semantic valency but makes existing parsers slow. We describe an A* parser and a transition-based parser for AM dependency parsing which guarantee well-typedness and improve parsing speed by up to 3 orders of magnitude, while maintaining or improving accuracy.","Fast semantic parsing with well-typedness guarantees AM dependency parsing is a linguistically principled method for neural semantic parsing with high accuracy across multiple graphbanks. It relies on a type system that models semantic valency but makes existing parsers slow. We describe an A* parser and a transition-based parser for AM dependency parsing which guarantee well-typedness and improve parsing speed by up to 3 orders of magnitude, while maintaining or improving accuracy.","fast semantic parsing - typedness guarantee dependency parsing linguistically principled method neural semantic parsing high accuracy multiple graphbank . rely type system model semantic valency make exist parser slow . describe * parser transition - base parser dependency parsing guarantee - typedness improve parsing speed 3 order magnitude , maintain improve accuracy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 12, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Semantic Role Labeling as Syntactic Dependency Parsing,"We reduce the task of (span-based) PropBankstyle semantic role labeling (SRL) to syntactic dependency parsing. Our approach is motivated by our empirical analysis that shows three common syntactic patterns account for over 98% of the SRL annotations for both English and Chinese data. Based on this observation, we present a conversion scheme that packs SRL annotations into dependency tree representations through joint labels that permit highly accurate recovery back to the original format. This representation allows us to train statistical dependency parsers to tackle SRL and achieve competitive performance with the current state of the art. Our findings show the promise of syntactic dependency trees in encoding semantic role relations within their syntactic domain of locality, and point to potential further integration of syntactic methods into semantic role labeling in the future.","Semantic Role Labeling as Syntactic Dependency Parsing We reduce the task of (span-based) PropBankstyle semantic role labeling (SRL) to syntactic dependency parsing. Our approach is motivated by our empirical analysis that shows three common syntactic patterns account for over 98% of the SRL annotations for both English and Chinese data. Based on this observation, we present a conversion scheme that packs SRL annotations into dependency tree representations through joint labels that permit highly accurate recovery back to the original format. This representation allows us to train statistical dependency parsers to tackle SRL and achieve competitive performance with the current state of the art. Our findings show the promise of syntactic dependency trees in encoding semantic role relations within their syntactic domain of locality, and point to potential further integration of syntactic methods into semantic role labeling in the future.","semantic role labeling syntactic dependency parsing reduce task ( span - base ) propbankstyle semantic role labeling ( srl ) syntactic dependency parsing . approach motivate empirical analysis show common syntactic pattern account 98 % srl annotation english chinese datum . base observation , present conversion scheme pack srl annotation dependency tree representation joint label permit highly accurate recovery original format . representation allow train statistical dependency parser tackle srl achieve competitive performance current state art . finding promise syntactic dependency tree encode semantic role relation syntactic domain locality , point potential integration syntactic method semantic role labeling future .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 6, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 12, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification,"Automated fact extraction and verification is a challenging task that involves finding relevant evidence sentences from a reliable corpus to verify the truthfulness of a claim. Existing models either (i) concatenate all the evidence sentences, leading to the inclusion of redundant and noisy information; or (ii) process each claim-evidence sentence pair separately and aggregate all of them later, missing the early combination of related sentences for more accurate claim verification. Unlike the prior works, in this paper, we propose Hierarchical Evidence Set Modeling (HESM), a framework to extract evidence sets (each of which may contain multiple evidence sentences), and verify a claim to be supported, refuted or not enough info, by encoding and attending the claim and evidence sets at different levels of hierarchy. Our experimental results show that HESM outperforms 7 state-of-the-art methods for fact extraction and claim verification. Our source code is available at https://github.com/ ShyamSubramanian/HESM.","Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification Automated fact extraction and verification is a challenging task that involves finding relevant evidence sentences from a reliable corpus to verify the truthfulness of a claim. Existing models either (i) concatenate all the evidence sentences, leading to the inclusion of redundant and noisy information; or (ii) process each claim-evidence sentence pair separately and aggregate all of them later, missing the early combination of related sentences for more accurate claim verification. Unlike the prior works, in this paper, we propose Hierarchical Evidence Set Modeling (HESM), a framework to extract evidence sets (each of which may contain multiple evidence sentences), and verify a claim to be supported, refuted or not enough info, by encoding and attending the claim and evidence sets at different levels of hierarchy. Our experimental results show that HESM outperforms 7 state-of-the-art methods for fact extraction and claim verification. Our source code is available at https://github.com/ ShyamSubramanian/HESM.","hierarchical evidence set modeling automate fact extraction verification automate fact extraction verification challenging task involve find relevant evidence sentence reliable corpus verify truthfulness claim . exist model ( ) concatenate evidence sentence , lead inclusion redundant noisy information ; ( ii ) process claim - evidence sentence pair separately aggregate later , miss early combination related sentence accurate claim verification . unlike prior work , paper , propose hierarchical evidence set modeling ( hesm ) , framework extract evidence set ( contain multiple evidence sentence ) , verify claim support , refute info , encode attend claim evidence set different level hierarchy . experimental result hesm outperform 7 state - - - art method fact extraction claim verification . source code available https://github.com/ shyamsubramanian / hesm .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Computational Social Science and Social Media,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Unsupervised Commonsense Question Answering with Self-Talk,"Natural language understanding involves reading between the lines with implicit background knowledge. Current systems either rely on pretrained language models as the sole implicit source of world knowledge, or resort to external knowledge bases (KBs) to incorporate additional relevant knowledge. We propose an unsupervised framework based on self-talk as a novel alternative to multiple-choice commonsense tasks. Inspired by inquiry-based discovery learning (Bruner, 1961) , our approach inquires language models with a number of information seeking questions such as ""what is the definition of ..."" to discover additional background knowledge. Empirical results demonstrate that the self-talk procedure substantially improves the performance of zeroshot language model baselines on four out of six commonsense benchmarks, and competes with models that obtain knowledge from external KBs. While our approach improves performance on several benchmarks, the selftalk induced knowledge even when leading to correct answers is not always seen as helpful by human judges, raising interesting questions about the inner-workings of pre-trained language models for commonsense reasoning.","Unsupervised Commonsense Question Answering with Self-Talk Natural language understanding involves reading between the lines with implicit background knowledge. Current systems either rely on pretrained language models as the sole implicit source of world knowledge, or resort to external knowledge bases (KBs) to incorporate additional relevant knowledge. We propose an unsupervised framework based on self-talk as a novel alternative to multiple-choice commonsense tasks. Inspired by inquiry-based discovery learning (Bruner, 1961) , our approach inquires language models with a number of information seeking questions such as ""what is the definition of ..."" to discover additional background knowledge. Empirical results demonstrate that the self-talk procedure substantially improves the performance of zeroshot language model baselines on four out of six commonsense benchmarks, and competes with models that obtain knowledge from external KBs. While our approach improves performance on several benchmarks, the selftalk induced knowledge even when leading to correct answers is not always seen as helpful by human judges, raising interesting questions about the inner-workings of pre-trained language models for commonsense reasoning.","unsupervised commonsense question answer self - talk natural language understanding involve read line implicit background knowledge . current system rely pretrained language model sole implicit source world knowledge , resort external knowledge basis ( kb ) incorporate additional relevant knowledge . propose unsupervised framework base self - talk novel alternative multiple - choice commonsense task . inspire inquiry - base discovery learning ( bruner , 1961 ) , approach inquire language model number information seek question "" definition ... "" discover additional background knowledge . empirical result demonstrate self - talk procedure substantially improve performance zeroshot language model baseline commonsense benchmark , compete model obtain knowledge external kb . approach improve performance benchmark , selftalk induce knowledge lead correct answer see helpful human judge , raise interesting question inner - working pre - trained language model commonsense reasoning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 6, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Small but Mighty: New Benchmarks for Split and Rephrase,"Split and Rephrase is a text simplification task of rewriting a complex sentence into simpler ones. As a relatively new task, it is paramount to ensure the soundness of its evaluation benchmark and metric. We find that the widely used benchmark dataset universally contains easily exploitable syntactic cues caused by its automatic generation process. Taking advantage of such cues, we show that even a simple rule-based model can perform on par with the state-of-the-art model. To remedy such limitations, we collect and release two crowdsourced benchmark datasets. We not only make sure that they contain significantly more diverse syntax, but also carefully control for their quality according to a welldefined set of criteria. While no satisfactory automatic metric exists, we apply fine-grained manual evaluation based on these criteria using crowdsourcing, showing that our datasets better represent the task and are significantly more challenging for the models. 1 * Work done during internship at IBM Research.","Small but Mighty: New Benchmarks for Split and Rephrase Split and Rephrase is a text simplification task of rewriting a complex sentence into simpler ones. As a relatively new task, it is paramount to ensure the soundness of its evaluation benchmark and metric. We find that the widely used benchmark dataset universally contains easily exploitable syntactic cues caused by its automatic generation process. Taking advantage of such cues, we show that even a simple rule-based model can perform on par with the state-of-the-art model. To remedy such limitations, we collect and release two crowdsourced benchmark datasets. We not only make sure that they contain significantly more diverse syntax, but also carefully control for their quality according to a welldefined set of criteria. While no satisfactory automatic metric exists, we apply fine-grained manual evaluation based on these criteria using crowdsourcing, showing that our datasets better represent the task and are significantly more challenging for the models. 1 * Work done during internship at IBM Research.","small mighty : new benchmark split rephrase split rephrase text simplification task rewrite complex sentence simple one . relatively new task , paramount ensure soundness evaluation benchmark metric . find widely benchmark dataset universally contain easily exploitable syntactic cue cause automatic generation process . take advantage cue , simple rule - base model perform par state - - - art model . remedy limitation , collect release crowdsource benchmark dataset . sure contain significantly diverse syntax , carefully control quality accord welldefined set criterion . satisfactory automatic metric exist , apply fine - grained manual evaluation base criterion crowdsourcing , show dataset well represent task significantly challenging model . 1 * work internship ibm research .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Resources and Evaluation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",A Bilingual Generative Transformer for Semantic Sentence Embedding,"Semantic sentence embedding models encode natural language sentences into vectors, such that closeness in embedding space indicates closeness in the semantics between the sentences. Bilingual data offers a useful signal for learning such embeddings: properties shared by both sentences in a translation pair are likely semantic, while divergent properties are likely stylistic or language-specific. We propose a deep latent variable model that attempts to perform source separation on parallel sentences, isolating what they have in common in a latent semantic vector, and explaining what is left over with language-specific latent vectors. Our proposed approach differs from past work on semantic sentence encoding in two ways. First, by using a variational probabilistic framework, we introduce priors that encourage source separation, and can use our model's posterior to predict sentence embeddings for monolingual data at test time. Second, we use high-capacity transformers as both data generating distributions and inference networkscontrasting with most past work on sentence embeddings. In experiments, our approach substantially outperforms the state-of-the-art on a standard suite of unsupervised semantic similarity evaluations. Further, we demonstrate that our approach yields the largest gains on more difficult subsets of these evaluations where simple word overlap is not a good indicator of similarity. 1","A Bilingual Generative Transformer for Semantic Sentence Embedding Semantic sentence embedding models encode natural language sentences into vectors, such that closeness in embedding space indicates closeness in the semantics between the sentences. Bilingual data offers a useful signal for learning such embeddings: properties shared by both sentences in a translation pair are likely semantic, while divergent properties are likely stylistic or language-specific. We propose a deep latent variable model that attempts to perform source separation on parallel sentences, isolating what they have in common in a latent semantic vector, and explaining what is left over with language-specific latent vectors. Our proposed approach differs from past work on semantic sentence encoding in two ways. First, by using a variational probabilistic framework, we introduce priors that encourage source separation, and can use our model's posterior to predict sentence embeddings for monolingual data at test time. Second, we use high-capacity transformers as both data generating distributions and inference networkscontrasting with most past work on sentence embeddings. In experiments, our approach substantially outperforms the state-of-the-art on a standard suite of unsupervised semantic similarity evaluations. Further, we demonstrate that our approach yields the largest gains on more difficult subsets of these evaluations where simple word overlap is not a good indicator of similarity. 1","bilingual generative transformer semantic sentence embedding semantic sentence embedding model encode natural language sentence vector , closeness embed space indicate closeness semantic sentence . bilingual data offer useful signal learn embedding : property share sentence translation pair likely semantic , divergent property likely stylistic language - specific . propose deep latent variable model attempt perform source separation parallel sentence , isolate common latent semantic vector , explain leave language - specific latent vector . propose approach differ past work semantic sentence encoding way . , variational probabilistic framework , introduce prior encourage source separation , use model posterior predict sentence embedding monolingual datum test time . second , use high - capacity transformer datum generate distribution inference networkscontraste past work sentence embedding . experiment , approach substantially outperform state - - - art standard suite unsupervised semantic similarity evaluation . , demonstrate approach yield large gain difficult subset evaluation simple word overlap good indicator similarity . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Adaptive Attentional Network for Few-Shot Knowledge Graph Completion,"Few-shot Knowledge Graph (KG) completion is a focus of current research, where each task aims at querying unseen facts of a relation given its few-shot reference entity pairs. Recent attempts solve this problem by learning static representations of entities and references, ignoring their dynamic properties, i.e., entities may exhibit diverse roles within task relations, and references may make different contributions to queries. This work proposes an adaptive attentional network for few-shot KG completion by learning adaptive entity and reference representations. Specifically, entities are modeled by an adaptive neighbor encoder to discern their task-oriented roles, while references are modeled by an adaptive query-aware aggregator to differentiate their contributions. Through the attention mechanism, both entities and references can capture their fine-grained semantic meanings, and thus render more expressive representations. This will be more predictive for knowledge acquisition in the few-shot scenario. Evaluation in link prediction on two public datasets shows that our approach achieves new state-of-theart results with different few-shot sizes. The source code is available at https://github. com/JiaweiSheng/FAAN.","Adaptive Attentional Network for Few-Shot Knowledge Graph Completion Few-shot Knowledge Graph (KG) completion is a focus of current research, where each task aims at querying unseen facts of a relation given its few-shot reference entity pairs. Recent attempts solve this problem by learning static representations of entities and references, ignoring their dynamic properties, i.e., entities may exhibit diverse roles within task relations, and references may make different contributions to queries. This work proposes an adaptive attentional network for few-shot KG completion by learning adaptive entity and reference representations. Specifically, entities are modeled by an adaptive neighbor encoder to discern their task-oriented roles, while references are modeled by an adaptive query-aware aggregator to differentiate their contributions. Through the attention mechanism, both entities and references can capture their fine-grained semantic meanings, and thus render more expressive representations. This will be more predictive for knowledge acquisition in the few-shot scenario. Evaluation in link prediction on two public datasets shows that our approach achieves new state-of-theart results with different few-shot sizes. The source code is available at https://github. com/JiaweiSheng/FAAN.","adaptive attentional network - shot knowledge graph completion - shot knowledge graph ( kg ) completion focus current research , task aim query unseen fact relation give - shot reference entity pair . recent attempt solve problem learn static representation entity reference , ignore dynamic property , i.e. , entity exhibit diverse role task relation , reference different contribution query . work propose adaptive attentional network - shot kg completion learn adaptive entity reference representation . specifically , entity model adaptive neighbor encoder discern task - orient role , reference model adaptive query - aware aggregator differentiate contribution . attention mechanism , entity reference capture fine - grained semantic meaning , render expressive representation . predictive knowledge acquisition - shot scenario . evaluation link prediction public dataset show approach achieve new state - - theart result different - shot size . source code available https://github . com / jiaweisheng / faan .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 9, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",SLM: Learning a Discourse Language Representation with Sentence Unshuffling,"We introduce Sentence-level Language Modeling, a new pre-training objective for learning a discourse language representation in a fully self-supervised manner. Recent pre-training methods in NLP focus on learning either bottom or top-level language representations: contextualized word representations derived from language model objectives at one extreme and a whole sequence representation learned by order classification of two given textual segments at the other. However, these models are not directly encouraged to capture representations of intermediate-size structures that exist in natural languages such as sentences and the relationships among them. To that end, we propose a new approach to encourage learning of a contextualized sentence-level representation by shuffling the sequence of input sentences and training a hierarchical transformer model to reconstruct the original ordering. Through experiments on downstream tasks such as GLUE, SQuAD, and DiscoEval, we show that this feature of our model improves the performance of the original BERT by large margins.","SLM: Learning a Discourse Language Representation with Sentence Unshuffling We introduce Sentence-level Language Modeling, a new pre-training objective for learning a discourse language representation in a fully self-supervised manner. Recent pre-training methods in NLP focus on learning either bottom or top-level language representations: contextualized word representations derived from language model objectives at one extreme and a whole sequence representation learned by order classification of two given textual segments at the other. However, these models are not directly encouraged to capture representations of intermediate-size structures that exist in natural languages such as sentences and the relationships among them. To that end, we propose a new approach to encourage learning of a contextualized sentence-level representation by shuffling the sequence of input sentences and training a hierarchical transformer model to reconstruct the original ordering. Through experiments on downstream tasks such as GLUE, SQuAD, and DiscoEval, we show that this feature of our model improves the performance of the original BERT by large margins.","slm : learn discourse language representation sentence unshuffling introduce sentence - level language modeling , new pre - training objective learn discourse language representation fully self - supervise manner . recent pre - training method nlp focus learn - level language representation : contextualize word representation derive language model objective extreme sequence representation learn order classification give textual segment . , model directly encourage capture representation intermediate - size structure exist natural language sentence relationship . end , propose new approach encourage learning contextualize sentence - level representation shuffle sequence input sentence train hierarchical transformer model reconstruct original ordering . experiment downstream task glue , squad , discoeval , feature model improve performance original bert large margin .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank,"Detecting fine-grained differences in content conveyed in different languages matters for cross-lingual NLP and multilingual corpora analysis, but it is a challenging machine learning problem since annotation is expensive and hard to scale. This work improves the prediction and annotation of finegrained semantic divergences. We introduce a training strategy for multilingual BERT models by learning to rank synthetic divergent examples of varying granularity. We evaluate our models on the Rationalized English-French Semantic Divergences, a new dataset released with this work, consisting of English-French sentence-pairs annotated with semantic divergence classes and token-level rationales. Learning to rank helps detect finegrained sentence-level divergences more accurately than a strong sentence-level similarity model, while token-level predictions have the potential of further distinguishing between coarse and fine-grained divergences.","Detecting Fine-Grained Cross-Lingual Semantic Divergences without Supervision by Learning to Rank Detecting fine-grained differences in content conveyed in different languages matters for cross-lingual NLP and multilingual corpora analysis, but it is a challenging machine learning problem since annotation is expensive and hard to scale. This work improves the prediction and annotation of finegrained semantic divergences. We introduce a training strategy for multilingual BERT models by learning to rank synthetic divergent examples of varying granularity. We evaluate our models on the Rationalized English-French Semantic Divergences, a new dataset released with this work, consisting of English-French sentence-pairs annotated with semantic divergence classes and token-level rationales. Learning to rank helps detect finegrained sentence-level divergences more accurately than a strong sentence-level similarity model, while token-level predictions have the potential of further distinguishing between coarse and fine-grained divergences.","detect fine - grained cross - lingual semantic divergence supervision learn rank detect fine - grained difference content convey different language matter cross - lingual nlp multilingual corpora analysis , challenging machine learning problem annotation expensive hard scale . work improve prediction annotation finegrained semantic divergence . introduce training strategy multilingual bert model learn rank synthetic divergent example vary granularity . evaluate model rationalized english - french semantic divergences , new dataset release work , consist english - french sentence - pair annotate semantic divergence class token - level rationale . learn rank help detect finegrained sentence - level divergence accurately strong sentence - level similarity model , token - level prediction potential distinguish coarse fine - grained divergence .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Data and Representation for Turkish Natural Language Inference,"Large annotated datasets in NLP are overwhelmingly in English. This is an obstacle to progress in other languages. Unfortunately, obtaining new annotated resources for each task in each language would be prohibitively expensive. At the same time, commercial machine translation systems are now robust. Can we leverage these systems to translate Englishlanguage datasets automatically? In this paper, we offer a positive response for natural language inference (NLI) in Turkish. We translated two large English NLI datasets into Turkish and had a team of experts validate their translation quality and fidelity to the original labels. Using these datasets, we address core issues of representation for Turkish NLI. We find that in-language embeddings are essential and that morphological parsing can be avoided where the training set is large. Finally, we show that models trained on our machinetranslated datasets are successful on humantranslated evaluation sets. We share all code, models, and data publicly.","Data and Representation for Turkish Natural Language Inference Large annotated datasets in NLP are overwhelmingly in English. This is an obstacle to progress in other languages. Unfortunately, obtaining new annotated resources for each task in each language would be prohibitively expensive. At the same time, commercial machine translation systems are now robust. Can we leverage these systems to translate Englishlanguage datasets automatically? In this paper, we offer a positive response for natural language inference (NLI) in Turkish. We translated two large English NLI datasets into Turkish and had a team of experts validate their translation quality and fidelity to the original labels. Using these datasets, we address core issues of representation for Turkish NLI. We find that in-language embeddings are essential and that morphological parsing can be avoided where the training set is large. Finally, we show that models trained on our machinetranslated datasets are successful on humantranslated evaluation sets. We share all code, models, and data publicly.","datum representation turkish natural language inference large annotate dataset nlp overwhelmingly english . obstacle progress language . unfortunately , obtain new annotate resource task language prohibitively expensive . time , commercial machine translation system robust . leverage system translate englishlanguage dataset automatically ? paper , offer positive response natural language inference ( nli ) turkish . translate large english nli dataset turkish team expert validate translation quality fidelity original label . dataset , address core issue representation turkish nli . find - language embedding essential morphological parsing avoid training set large . finally , model train machinetranslated dataset successful humantranslated evaluation set . share code , model , datum publicly .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Cross-Thought for Sentence Encoder Pre-training,"In this paper, we propose Cross-Thought, a novel approach to pre-training sequence encoder, which is instrumental in building reusable sequence embeddings for large-scale NLP tasks such as question answering. Instead of using the original signals of full sentences, we train a Transformer-based sequence encoder over a large set of short sequences, which allows the model to automatically select the most useful information for predicting masked words. Experiments on question answering and textual entailment tasks demonstrate that our pre-trained encoder can outperform state-of-the-art encoders trained with continuous sentence signals as well as traditional masked language modeling baselines. Our proposed approach also achieves new state of the art on HotpotQA (full-wiki setting) by improving intermediate information retrieval performance. 1","Cross-Thought for Sentence Encoder Pre-training In this paper, we propose Cross-Thought, a novel approach to pre-training sequence encoder, which is instrumental in building reusable sequence embeddings for large-scale NLP tasks such as question answering. Instead of using the original signals of full sentences, we train a Transformer-based sequence encoder over a large set of short sequences, which allows the model to automatically select the most useful information for predicting masked words. Experiments on question answering and textual entailment tasks demonstrate that our pre-trained encoder can outperform state-of-the-art encoders trained with continuous sentence signals as well as traditional masked language modeling baselines. Our proposed approach also achieves new state of the art on HotpotQA (full-wiki setting) by improving intermediate information retrieval performance. 1","cross - thought sentence encoder pre - training paper , propose cross - thought , novel approach pre - training sequence encoder , instrumental build reusable sequence embedding large - scale nlp task question answering . instead original signal sentence , train transformer - base sequence encoder large set short sequence , allow model automatically select useful information predict mask word . experiment question answering textual entailment task demonstrate pre - trained encoder outperform state - - - art encoder train continuous sentence signal traditional mask language modeling baseline . propose approach achieve new state art hotpotqa ( - wiki setting ) improve intermediate information retrieval performance . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 11, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Grounded Adaptation for Zero-shot Executable Semantic Parsing,"We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycleconsistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose inputoutput consistency are verified. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms dataaugmentation in the training environment, performance increases with the amount of GAZPsynthesized data, and cycle-consistency is central to successful adaptation.","Grounded Adaptation for Zero-shot Executable Semantic Parsing We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycleconsistent examples to adapt the parser. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose inputoutput consistency are verified. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms dataaugmentation in the training environment, performance increases with the amount of GAZPsynthesized data, and cycle-consistency is central to successful adaptation.","ground adaptation zero - shot executable semantic parsing propose grounded adaptation zeroshot executable semantic parsing ( gazp ) adapt exist semantic parser new environment ( e.g. new database schema ) . gazp combine forward semantic parser backward utterance generator synthesize datum ( e.g. utterance sql query ) new environment , select cycleconsistent example adapt parser . unlike data - augmentation , typically synthesize unverified example training environment , gazp synthesize example new environment inputoutput consistency verify . spider , sparc , cosql zero - shot semantic parsing task , gazp improve logical form execution accuracy baseline parser . analysis gazp outperform dataaugmentation training environment , performance increase gazpsynthesized datum , cycle - consistency central successful adaptation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 14, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start,"A standard way to address different NLP problems is by first constructing a problem-specific dataset, then building a model to fit this dataset. To build the ultimate artificial intelligence, we desire a single machine that can handle diverse new problems, for which task-specific annotations are limited. We bring up textual entailment as a unified solver for such NLP problems. However, current research of textual entailment has not spilled much ink on the following questions: (i) How well does a pretrained textual entailment system generalize across domains with only a handful of domainspecific examples? and (ii) When is it worth transforming an NLP task into textual entailment? We argue that the transforming is unnecessary if we can obtain rich annotations for this task. Textual entailment really matters particularly when the target NLP task has insufficient annotations. Universal NLP 1 can be probably achieved through different routines. In this work, we introduce Universal Few-shot textual Entailment (UFO-ENTAIL). We demonstrate that this framework enables a pretrained entailment model to work well on new entailment domains in a few-shot setting, and show its effectiveness as a unified solver for several downstream NLP tasks such as question answering and coreference resolution when the end-task annotations are limited.","Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start A standard way to address different NLP problems is by first constructing a problem-specific dataset, then building a model to fit this dataset. To build the ultimate artificial intelligence, we desire a single machine that can handle diverse new problems, for which task-specific annotations are limited. We bring up textual entailment as a unified solver for such NLP problems. However, current research of textual entailment has not spilled much ink on the following questions: (i) How well does a pretrained textual entailment system generalize across domains with only a handful of domainspecific examples? and (ii) When is it worth transforming an NLP task into textual entailment? We argue that the transforming is unnecessary if we can obtain rich annotations for this task. Textual entailment really matters particularly when the target NLP task has insufficient annotations. Universal NLP 1 can be probably achieved through different routines. In this work, we introduce Universal Few-shot textual Entailment (UFO-ENTAIL). We demonstrate that this framework enables a pretrained entailment model to work well on new entailment domains in a few-shot setting, and show its effectiveness as a unified solver for several downstream NLP tasks such as question answering and coreference resolution when the end-task annotations are limited.","universal natural language processing limited annotation : try - shot textual entailment start standard way address different nlp problem construct problem - specific dataset , build model fit dataset . build ultimate artificial intelligence , desire single machine handle diverse new problem , task - specific annotation limited . bring textual entailment unified solver nlp problem . , current research textual entailment spill ink following question : ( ) pretrained textual entailment system generalize domain handful domainspecific example ? ( ii ) worth transform nlp task textual entailment ? argue transform unnecessary obtain rich annotation task . textual entailment matter particularly target nlp task insufficient annotation . universal nlp 1 probably achieve different routine . work , introduce universal - shot textual entailment ( ufo - entail ) . demonstrate framework enable pretrained entailment model work new entailment domain - shot setting , effectiveness unified solver downstream nlp task question answering coreference resolution end - task annotation limited .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 6, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 7, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",An Unsupervised Sentence Embedding Method by Mutual Information Maximization,"BERT is inefficient for sentence-pair tasks such as clustering or semantic search as it needs to evaluate combinatorially many sentence pairs which is very time-consuming. Sentence BERT (SBERT) attempted to solve this challenge by learning semantically meaningful representations of single sentences, such that similarity comparison can be easily accessed. However, SBERT is trained on corpus with high-quality labeled sentence pairs, which limits its application to tasks where labeled data is extremely scarce. In this paper, we propose a lightweight extension on top of BERT and a novel self-supervised learning objective based on mutual information maximization strategies to derive meaningful sentence embeddings in an unsupervised manner. Unlike SBERT, our method is not restricted by the availability of labeled data, such that it can be applied on different domain-specific corpus. Experimental results show that the proposed method significantly outperforms other unsupervised sentence embedding baselines on common semantic textual similarity (STS) tasks and downstream supervised tasks. It also outperforms SBERT in a setting where in-domain labeled data is not available, and achieves performance competitive with supervised methods on various tasks.","An Unsupervised Sentence Embedding Method by Mutual Information Maximization BERT is inefficient for sentence-pair tasks such as clustering or semantic search as it needs to evaluate combinatorially many sentence pairs which is very time-consuming. Sentence BERT (SBERT) attempted to solve this challenge by learning semantically meaningful representations of single sentences, such that similarity comparison can be easily accessed. However, SBERT is trained on corpus with high-quality labeled sentence pairs, which limits its application to tasks where labeled data is extremely scarce. In this paper, we propose a lightweight extension on top of BERT and a novel self-supervised learning objective based on mutual information maximization strategies to derive meaningful sentence embeddings in an unsupervised manner. Unlike SBERT, our method is not restricted by the availability of labeled data, such that it can be applied on different domain-specific corpus. Experimental results show that the proposed method significantly outperforms other unsupervised sentence embedding baselines on common semantic textual similarity (STS) tasks and downstream supervised tasks. It also outperforms SBERT in a setting where in-domain labeled data is not available, and achieves performance competitive with supervised methods on various tasks.","unsupervised sentence embedding method mutual information maximization bert inefficient sentence - pair task clustering semantic search need evaluate combinatorially sentence pair time - consume . sentence bert ( sbert ) attempt solve challenge learn semantically meaningful representation single sentence , similarity comparison easily access . , sbert train corpus high - quality label sentence pair , limit application task label data extremely scarce . paper , propose lightweight extension bert novel self - supervise learning objective base mutual information maximization strategy derive meaningful sentence embedding unsupervised manner . unlike sbert , method restrict availability label datum , apply different domain - specific corpus . experimental result propose method significantly outperform unsupervised sentence embedding baseline common semantic textual similarity ( sts ) task downstream supervise task . outperform sbert setting - domain label data available , achieve performance competitive supervise method task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",An Imitation Game for Learning Semantic Parsers from User Interaction,"Despite the widely successful applications, building a semantic parser is still a tedious process in practice with challenges from costly data annotation and privacy risks. We suggest an alternative, human-in-the-loop methodology for learning semantic parsers directly from users. A semantic parser should be introspective of its uncertainties and prompt for user demonstrations when uncertain. In doing so it also gets to imitate the user behavior and continue improving itself autonomously with the hope that eventually it may become as good as the user in interpreting their questions. To combat the sparsity of demonstrations, we propose a novel annotation-efficient imitation learning algorithm, which iteratively collects new datasets by mixing demonstrated states and confident predictions and retrains the semantic parser in a Dataset Aggregation fashion (Ross et al., 2011) . We provide a theoretical analysis of its cost bound and also empirically demonstrate its promising performance on the text-to-SQL problem. 1","An Imitation Game for Learning Semantic Parsers from User Interaction Despite the widely successful applications, building a semantic parser is still a tedious process in practice with challenges from costly data annotation and privacy risks. We suggest an alternative, human-in-the-loop methodology for learning semantic parsers directly from users. A semantic parser should be introspective of its uncertainties and prompt for user demonstrations when uncertain. In doing so it also gets to imitate the user behavior and continue improving itself autonomously with the hope that eventually it may become as good as the user in interpreting their questions. To combat the sparsity of demonstrations, we propose a novel annotation-efficient imitation learning algorithm, which iteratively collects new datasets by mixing demonstrated states and confident predictions and retrains the semantic parser in a Dataset Aggregation fashion (Ross et al., 2011) . We provide a theoretical analysis of its cost bound and also empirically demonstrate its promising performance on the text-to-SQL problem. 1","imitation game learn semantic parser user interaction despite widely successful application , build semantic parser tedious process practice challenge costly datum annotation privacy risk . suggest alternative , human - - - loop methodology learn semantic parser directly user . semantic parser introspective uncertainty prompt user demonstration uncertain . get imitate user behavior continue improve autonomously hope eventually good user interpret question . combat sparsity demonstration , propose novel annotation - efficient imitation learning algorithm , iteratively collect new dataset mix demonstrate state confident prediction retrain semantic parser dataset aggregation fashion ( ross et al . , 2011 ) . provide theoretical analysis cost bind empirically demonstrate promising performance text - - sql problem . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",NLP Applications,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",GLUCOSE: GeneraLized and COntextualized Story Explanations,"When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal minitheories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a storyspecific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions. First, we present our platform for effectively crowdsourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected a total of ˜670K specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models.","GLUCOSE: GeneraLized and COntextualized Story Explanations When humans read or listen, they make implicit commonsense inferences that frame their understanding of what happened and why. As a step toward AI systems that can build similar mental models, we introduce GLUCOSE, a large-scale dataset of implicit commonsense causal knowledge, encoded as causal minitheories about the world, each grounded in a narrative context. To construct GLUCOSE, we drew on cognitive psychology to identify ten dimensions of causal explanation, focusing on events, states, motivations, and emotions. Each GLUCOSE entry includes a storyspecific causal statement paired with an inference rule generalized from the statement. This paper details two concrete contributions. First, we present our platform for effectively crowdsourcing GLUCOSE data at scale, which uses semi-structured templates to elicit causal explanations. Using this platform, we collected a total of ˜670K specific statements and general rules that capture implicit commonsense knowledge about everyday situations. Second, we show that existing knowledge resources and pretrained language models do not include or readily predict GLUCOSE's rich inferential content. However, when state-of-the-art neural models are trained on this knowledge, they can start to make commonsense inferences on unseen stories that match humans' mental models.","glucose : generalize contextualize story explanation human read listen , implicit commonsense inference frame understanding happen . step ai system build similar mental model , introduce glucose , large - scale dataset implicit commonsense causal knowledge , encode causal minitheorie world , ground narrative context . construct glucose , draw cognitive psychology identify dimension causal explanation , focus event , state , motivation , emotion . glucose entry include storyspecific causal statement pair inference rule generalize statement . paper detail concrete contribution . , present platform effectively crowdsource glucose datum scale , use semi - structured template elicit causal explanation . platform , collect total ˜670 k specific statement general rule capture implicit commonsense knowledge everyday situation . second , exist knowledge resource pretrained language model include readily predict glucose rich inferential content . , state - - - art neural model train knowledge , start commonsense inference unseen story match human ' mental model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Graph Convolutions over Constituent Trees for Syntax-Aware Semantic Role Labeling,"Semantic role labeling (SRL) is the task of identifying predicates and labeling argument spans with semantic roles. Even though most semantic-role formalisms are built upon constituent syntax, and only syntactic constituents can be labeled as arguments (e.g., FrameNet and PropBank), all the recent work on syntaxaware SRL relies on dependency representations of syntax. In contrast, we show how graph convolutional networks (GCNs) can be used to encode constituent structures and inform an SRL system. Nodes in our SpanGCN correspond to constituents. The computation is done in 3 stages. First, initial node representations are produced by 'composing' word representations of the first and last words in the constituent. Second, graph convolutions relying on the constituent tree are performed, yielding syntacticallyinformed constituent representations. Finally, the constituent representations are 'decomposed' back into word representations, which are used as input to the SRL classifier. We evaluate SpanGCN against alternatives, including a model using GCNs over dependency trees, and show its effectiveness on standard English SRL benchmarks CoNLL-2005, CoNLL-2012, and FrameNet.","Graph Convolutions over Constituent Trees for Syntax-Aware Semantic Role Labeling Semantic role labeling (SRL) is the task of identifying predicates and labeling argument spans with semantic roles. Even though most semantic-role formalisms are built upon constituent syntax, and only syntactic constituents can be labeled as arguments (e.g., FrameNet and PropBank), all the recent work on syntaxaware SRL relies on dependency representations of syntax. In contrast, we show how graph convolutional networks (GCNs) can be used to encode constituent structures and inform an SRL system. Nodes in our SpanGCN correspond to constituents. The computation is done in 3 stages. First, initial node representations are produced by 'composing' word representations of the first and last words in the constituent. Second, graph convolutions relying on the constituent tree are performed, yielding syntacticallyinformed constituent representations. Finally, the constituent representations are 'decomposed' back into word representations, which are used as input to the SRL classifier. We evaluate SpanGCN against alternatives, including a model using GCNs over dependency trees, and show its effectiveness on standard English SRL benchmarks CoNLL-2005, CoNLL-2012, and FrameNet.","graph convolution constituent tree syntax - aware semantic role labeling semantic role labeling ( srl ) task identify predicate label argument span semantic role . semantic - role formalism build constituent syntax , syntactic constituent label argument ( e.g. , framenet propbank ) , recent work syntaxaware srl rely dependency representation syntax . contrast , graph convolutional network ( gcns ) encode constituent structure inform srl system . node spangcn correspond constituent . computation 3 stage . , initial node representation produce ' compose ' word representation word constituent . second , graph convolution rely constituent tree perform , yield syntacticallyinformed constituent representation . finally , constituent representation ' decompose ' word representation , input srl classifier . evaluate spangcn alternative , include model gcns dependency tree , effectiveness standard english srl benchmark conll-2005 , conll-2012 , framenet .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 12, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 5}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Improving AMR Parsing with Sequence-to-Sequence Pre-training,"In the literature, the research on abstract meaning representation (AMR) parsing is much restricted by the size of human-curated dataset which is critical to build an AMR parser with good performance. To alleviate such data size restriction, pre-trained models have been drawing more and more attention in AMR parsing. However, previous pre-trained models, like BERT, are implemented for general purpose which may not work as expected for the specific task of AMR parsing. In this paper, we focus on sequence-to-sequence (seq2seq) AMR parsing and propose a seq2seq pre-training approach to build pre-trained models in both single and joint way on three relevant tasks, i.e., machine translation, syntactic parsing, and AMR parsing itself. Moreover, we extend the vanilla fine-tuning method to a multi-task learning fine-tuning method that optimizes for the performance of AMR parsing while endeavors to preserve the response of pre-trained models. Extensive experimental results on two English benchmark datasets show that both the single and joint pre-trained models significantly improve the performance (e.g., from 71.5 to 80.2 on AMR 2.0), which reaches the state of the art. The result is very encouraging since we achieve this with seq2seq models rather than complex models. We make our code and model available at https:// github.com/xdqkid/S2S-AMR-Parser.","Improving AMR Parsing with Sequence-to-Sequence Pre-training In the literature, the research on abstract meaning representation (AMR) parsing is much restricted by the size of human-curated dataset which is critical to build an AMR parser with good performance. To alleviate such data size restriction, pre-trained models have been drawing more and more attention in AMR parsing. However, previous pre-trained models, like BERT, are implemented for general purpose which may not work as expected for the specific task of AMR parsing. In this paper, we focus on sequence-to-sequence (seq2seq) AMR parsing and propose a seq2seq pre-training approach to build pre-trained models in both single and joint way on three relevant tasks, i.e., machine translation, syntactic parsing, and AMR parsing itself. Moreover, we extend the vanilla fine-tuning method to a multi-task learning fine-tuning method that optimizes for the performance of AMR parsing while endeavors to preserve the response of pre-trained models. Extensive experimental results on two English benchmark datasets show that both the single and joint pre-trained models significantly improve the performance (e.g., from 71.5 to 80.2 on AMR 2.0), which reaches the state of the art. The result is very encouraging since we achieve this with seq2seq models rather than complex models. We make our code and model available at https:// github.com/xdqkid/S2S-AMR-Parser.","improve amr parsing sequence - - sequence pre - training literature , research abstract meaning representation ( amr ) parsing restricted size human - curate dataset critical build amr parser good performance . alleviate datum size restriction , pre - train model draw attention amr parsing . , previous pre - trained model , like bert , implement general purpose work expect specific task amr parsing . paper , focus sequence - - sequence ( seq2seq ) amr parsing propose seq2seq pre - training approach build pre - trained model single joint way relevant task , i.e. , machine translation , syntactic parsing , amr parsing . , extend vanilla fine - tuning method multi - task learning fine - tuning method optimize performance amr parsing endeavor preserve response pre - trained model . extensive experimental result english benchmark dataset single joint pre - trained model significantly improve performance ( e.g. , 71.5 80.2 amr 2.0 ) , reach state art . result encouraging achieve seq2seq model complex model . code model available https:// github.com/xdqkid/s2s-amr-parser .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 8, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 10, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Unsupervised stance detection for arguments from consequences,"Social media platforms have become an essential venue for online deliberation where users discuss arguments, debate, and form opinions. In this paper, we propose an unsupervised method to detect the stance of argumentative claims with respect to a topic. Most related work focuses on topic-specific supervised models that need to be trained for every emergent debate topic. To address this limitation, we propose a topic independent approach that focuses on a frequently encountered class of arguments, specifically, on arguments from consequences. We do this by extracting the effects that claims refer to, and proposing a means for inferring if the effect is a good or bad consequence. Our experiments provide promising results that are comparable to, and in particular regards even outperform BERT. Furthermore, we publish a novel dataset of arguments relating to consequences, annotated with Amazon Mechanical Turk.","Unsupervised stance detection for arguments from consequences Social media platforms have become an essential venue for online deliberation where users discuss arguments, debate, and form opinions. In this paper, we propose an unsupervised method to detect the stance of argumentative claims with respect to a topic. Most related work focuses on topic-specific supervised models that need to be trained for every emergent debate topic. To address this limitation, we propose a topic independent approach that focuses on a frequently encountered class of arguments, specifically, on arguments from consequences. We do this by extracting the effects that claims refer to, and proposing a means for inferring if the effect is a good or bad consequence. Our experiments provide promising results that are comparable to, and in particular regards even outperform BERT. Furthermore, we publish a novel dataset of arguments relating to consequences, annotated with Amazon Mechanical Turk.","unsupervised stance detection argument consequence social medium platform essential venue online deliberation user discuss argument , debate , form opinion . paper , propose unsupervised method detect stance argumentative claim respect topic . related work focus topic - specific supervise model need train emergent debate topic . address limitation , propose topic independent approach focus frequently encounter class argument , specifically , argument consequence . extract effect claim refer , propose means infer effect good bad consequence . experiment provide promising result comparable , particular regard outperform bert . furthermore , publish novel dataset argument relate consequence , annotate amazon mechanical turk .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 9, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Emotion-Cause Pair Extraction as Sequence Labeling Based on A Novel Tagging Scheme,"The task of emotion-cause pair extraction deals with finding all emotions and the corresponding causes in unannotated emotion texts. Most recent studies are based on the likelihood of Cartesian product among all clause candidates, resulting in a high computational cost. Targeting this issue, we regard the task as a sequence labeling problem and propose a novel tagging scheme with coding the distance between linked components into the tags, so that emotions and the corresponding causes can be extracted simultaneously. Accordingly, an end-to-end model is presented to process the input texts from left to right, always with linear time complexity, leading to a speed up. Experimental results show that our proposed model achieves the best performance, outperforming the state-of-the-art method by 2.26% (p < 0.001) in F 1 measure.","Emotion-Cause Pair Extraction as Sequence Labeling Based on A Novel Tagging Scheme The task of emotion-cause pair extraction deals with finding all emotions and the corresponding causes in unannotated emotion texts. Most recent studies are based on the likelihood of Cartesian product among all clause candidates, resulting in a high computational cost. Targeting this issue, we regard the task as a sequence labeling problem and propose a novel tagging scheme with coding the distance between linked components into the tags, so that emotions and the corresponding causes can be extracted simultaneously. Accordingly, an end-to-end model is presented to process the input texts from left to right, always with linear time complexity, leading to a speed up. Experimental results show that our proposed model achieves the best performance, outperforming the state-of-the-art method by 2.26% (p < 0.001) in F 1 measure.","emotion - cause pair extraction sequence labeling base novel tagging scheme task emotion - cause pair extraction deal find emotion corresponding cause unannotated emotion text . recent study base likelihood cartesian product clause candidate , result high computational cost . target issue , regard task sequence labeling problem propose novel tagging scheme code distance link component tag , emotion correspond cause extract simultaneously . accordingly , end - - end model present process input text left right , linear time complexity , lead speed . experimental result propose model achieve good performance , outperform state - - - art method 2.26 % ( p < 0.001 ) f 1 measure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 12, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Zero-Shot Stance Detection: A Dataset and Model using Generalized Topic Representations,"Stance detection is an important component of understanding hidden influences in everyday life. Since there are thousands of potential topics to take a stance on, most with little to no training data, we focus on zero-shot stance detection: classifying stance from no training examples. In this paper, we present a new dataset for zero-shot stance detection that captures a wider range of topics and lexical variation than in previous datasets. Additionally, we propose a new model for stance detection that implicitly captures relationships between topics using generalized topic representations and show that this model improves performance on a number of challenging linguistic phenomena.","Zero-Shot Stance Detection: A Dataset and Model using Generalized Topic Representations Stance detection is an important component of understanding hidden influences in everyday life. Since there are thousands of potential topics to take a stance on, most with little to no training data, we focus on zero-shot stance detection: classifying stance from no training examples. In this paper, we present a new dataset for zero-shot stance detection that captures a wider range of topics and lexical variation than in previous datasets. Additionally, we propose a new model for stance detection that implicitly captures relationships between topics using generalized topic representations and show that this model improves performance on a number of challenging linguistic phenomena.","zero - shot stance detection : dataset model generalized topic representations stance detection important component understand hide influence everyday life . thousand potential topic stance , little training datum , focus zero - shot stance detection : classify stance training example . paper , present new dataset zero - shot stance detection capture wide range topic lexical variation previous dataset . additionally , propose new model stance detection implicitly capture relationship topic generalized topic representation model improve performance number challenging linguistic phenomenon .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 7, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Feature Adaptation of Pre-Trained Language Models across Languages and Domains with Robust Self-Training,"Adapting pre-trained language models (PrLMs) (e.g., BERT) to new domains has gained much attention recently. Instead of fine-tuning PrLMs as done in most previous work, we investigate how to adapt the features of PrLMs to new domains without fine-tuning. We explore unsupervised domain adaptation (UDA) in this paper. With the features from PrLMs, we adapt the models trained with labeled data from the source domain to the unlabeled target domain. Self-training is widely used for UDA, and it predicts pseudo labels on the target domain data for training. However, the predicted pseudo labels inevitably include noise, which will negatively affect training a robust model. To improve the robustness of self-training, in this paper we present class-aware feature self-distillation (CFd) to learn discriminative features from PrLMs, in which PrLM features are self-distilled into a feature adaptation module and the features from the same class are more tightly clustered. We further extend CFd to a cross-language setting, in which language discrepancy is studied. Experiments on two monolingual and multilingual Amazon review datasets show that CFd can consistently improve the performance of self-training in cross-domain and cross-language settings.","Feature Adaptation of Pre-Trained Language Models across Languages and Domains with Robust Self-Training Adapting pre-trained language models (PrLMs) (e.g., BERT) to new domains has gained much attention recently. Instead of fine-tuning PrLMs as done in most previous work, we investigate how to adapt the features of PrLMs to new domains without fine-tuning. We explore unsupervised domain adaptation (UDA) in this paper. With the features from PrLMs, we adapt the models trained with labeled data from the source domain to the unlabeled target domain. Self-training is widely used for UDA, and it predicts pseudo labels on the target domain data for training. However, the predicted pseudo labels inevitably include noise, which will negatively affect training a robust model. To improve the robustness of self-training, in this paper we present class-aware feature self-distillation (CFd) to learn discriminative features from PrLMs, in which PrLM features are self-distilled into a feature adaptation module and the features from the same class are more tightly clustered. We further extend CFd to a cross-language setting, in which language discrepancy is studied. Experiments on two monolingual and multilingual Amazon review datasets show that CFd can consistently improve the performance of self-training in cross-domain and cross-language settings.","feature adaptation pre - trained language model language domain robust self - train adapt pre - trained language model ( prlms ) ( e.g. , bert ) new domain gain attention recently . instead fine - tune prlms previous work , investigate adapt feature prlms new domain fine - tuning . explore unsupervised domain adaptation ( uda ) paper . feature prlms , adapt model train label datum source domain unlabeled target domain . self - training widely uda , predict pseudo label target domain datum training . , predict pseudo label inevitably include noise , negatively affect train robust model . improve robustness self - training , paper present class - aware feature self - distillation ( cfd ) learn discriminative feature prlms , prlm feature self - distil feature adaptation module feature class tightly cluster . extend cfd cross - language setting , language discrepancy study . experiment monolingual multilingual amazon review dataset cfd consistently improve performance self - training cross - domain cross - language setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Exploring the Role of Argument Structure in Online Debate Persuasion,"Online debate forums provide users a platform to express their opinions on controversial topics while being exposed to opinions from diverse set of viewpoints. Existing work in Natural Language Processing (NLP) has shown that linguistic features extracted from the debate text and features encoding the characteristics of the audience are both critical in persuasion studies. In this paper, we aim to further investigate the role of discourse structure of the arguments from online debates in their persuasiveness. In particular, we use the factor graph model to obtain features for the argument structure of debates from an online debating platform and incorporate these features to an LSTM-based model to predict the debater that makes the most convincing arguments. We find that incorporating argument structure features play an essential role in achieving the better predictive performance in assessing the persuasiveness of the arguments in online debates.","Exploring the Role of Argument Structure in Online Debate Persuasion Online debate forums provide users a platform to express their opinions on controversial topics while being exposed to opinions from diverse set of viewpoints. Existing work in Natural Language Processing (NLP) has shown that linguistic features extracted from the debate text and features encoding the characteristics of the audience are both critical in persuasion studies. In this paper, we aim to further investigate the role of discourse structure of the arguments from online debates in their persuasiveness. In particular, we use the factor graph model to obtain features for the argument structure of debates from an online debating platform and incorporate these features to an LSTM-based model to predict the debater that makes the most convincing arguments. We find that incorporating argument structure features play an essential role in achieving the better predictive performance in assessing the persuasiveness of the arguments in online debates.","explore role argument structure online debate persuasion online debate forum provide user platform express opinion controversial topic expose opinion diverse set viewpoint . exist work natural language processing ( nlp ) show linguistic feature extract debate text feature encode characteristic audience critical persuasion study . paper , aim investigate role discourse structure argument online debate persuasiveness . particular , use factor graph model obtain feature argument structure debate online debating platform incorporate feature lstm - base model predict debater make convincing argument . find incorporate argument structure feature play essential role achieve well predictive performance assess persuasiveness argument online debate .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 9, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Relation-aware Graph Attention Networks with Relational Position Encodings for Emotion Recognition in Conversations,"Interest in emotion recognition in conversations (ERC) has been increasing in various fields, because it can be used to analyze user behaviors and detect fake news. Many recent ERC methods use graph-based neural networks to take the relationships between the utterances of the speakers into account. In particular, the state-of-the-art method considers self-and inter-speaker dependencies in conversations by using relational graph attention networks (RGAT). However, graph-based neural networks do not take sequential information into account. In this paper, we propose relational position encodings that provide RGAT with sequential information reflecting the relational graph structure. Accordingly, our RGAT model can capture both the speaker dependency and the sequential information. Experiments on four ERC datasets show that our model is beneficial to recognizing emotions expressed in conversations. In addition, our approach empirically outperforms the state-ofthe-art on all of the benchmark datasets.","Relation-aware Graph Attention Networks with Relational Position Encodings for Emotion Recognition in Conversations Interest in emotion recognition in conversations (ERC) has been increasing in various fields, because it can be used to analyze user behaviors and detect fake news. Many recent ERC methods use graph-based neural networks to take the relationships between the utterances of the speakers into account. In particular, the state-of-the-art method considers self-and inter-speaker dependencies in conversations by using relational graph attention networks (RGAT). However, graph-based neural networks do not take sequential information into account. In this paper, we propose relational position encodings that provide RGAT with sequential information reflecting the relational graph structure. Accordingly, our RGAT model can capture both the speaker dependency and the sequential information. Experiments on four ERC datasets show that our model is beneficial to recognizing emotions expressed in conversations. In addition, our approach empirically outperforms the state-ofthe-art on all of the benchmark datasets.","relation - aware graph attention network relational position encoding emotion recognition conversation interest emotion recognition conversation ( erc ) increase field , analyze user behavior detect fake news . recent erc method use graph - base neural network relationship utterance speaker account . particular , state - - - art method consider self - inter - speaker dependency conversation relational graph attention network ( rgat ) . , graph - base neural network sequential information account . paper , propose relational position encoding provide rgat sequential information reflect relational graph structure . accordingly , rgat model capture speaker dependency sequential information . experiment erc dataset model beneficial recognize emotion express conversation . addition , approach empirically outperform state - ofthe - art benchmark dataset .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 4, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Inducing Target-Specific Latent Structures for Aspect Sentiment Classification,"Aspect-level sentiment analysis aims to recognize the sentiment polarity of an aspect or a target in a comment. Recently, graph convolutional networks based on linguistic dependency trees have been studied for this task. However, the dependency parsing accuracy of commercial product comments or tweets might be unsatisfactory. To tackle this problem, we associate linguistic dependency trees with automatically induced aspectspecific graphs. We propose gating mechanisms to dynamically combine information from word dependency graphs and latent graphs which are learned by self-attention networks. Our model can complement supervised syntactic features with latent semantic dependencies. Experimental results on five benchmarks show the effectiveness of our proposed latent models, giving significantly better results than models without using latent graphs.","Inducing Target-Specific Latent Structures for Aspect Sentiment Classification Aspect-level sentiment analysis aims to recognize the sentiment polarity of an aspect or a target in a comment. Recently, graph convolutional networks based on linguistic dependency trees have been studied for this task. However, the dependency parsing accuracy of commercial product comments or tweets might be unsatisfactory. To tackle this problem, we associate linguistic dependency trees with automatically induced aspectspecific graphs. We propose gating mechanisms to dynamically combine information from word dependency graphs and latent graphs which are learned by self-attention networks. Our model can complement supervised syntactic features with latent semantic dependencies. Experimental results on five benchmarks show the effectiveness of our proposed latent models, giving significantly better results than models without using latent graphs.","induce target - specific latent structure aspect sentiment classification aspect - level sentiment analysis aim recognize sentiment polarity aspect target comment . recently , graph convolutional network base linguistic dependency tree study task . , dependency parse accuracy commercial product comment tweet unsatisfactory . tackle problem , associate linguistic dependency tree automatically induce aspectspecific graph . propose gating mechanism dynamically combine information word dependency graph latent graph learn self - attention network . model complement supervise syntactic feature latent semantic dependency . experimental result benchmark effectiveness propose latent model , give significantly well result model latent graph .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Introducing Syntactic Structures into Target Opinion Word Extraction with Deep Learning,"Targeted opinion word extraction (TOWE) is a sub-task of aspect based sentiment analysis (ABSA) which aims to find the opinion words for a given aspect-term in a sentence. Despite their success for TOWE, the current deep learning models fail to exploit the syntactic information of the sentences that have been proved to be useful for TOWE in the prior research. In this work, we propose to incorporate the syntactic structures of the sentences into the deep learning models for TOWE, leveraging the syntax-based opinion possibility scores and the syntactic connections between the words. We also introduce a novel regularization technique to improve the performance of the deep learning models based on the representation distinctions between the words in TOWE. The proposed model is extensively analyzed and achieves the state-of-the-art performance on four benchmark datasets.","Introducing Syntactic Structures into Target Opinion Word Extraction with Deep Learning Targeted opinion word extraction (TOWE) is a sub-task of aspect based sentiment analysis (ABSA) which aims to find the opinion words for a given aspect-term in a sentence. Despite their success for TOWE, the current deep learning models fail to exploit the syntactic information of the sentences that have been proved to be useful for TOWE in the prior research. In this work, we propose to incorporate the syntactic structures of the sentences into the deep learning models for TOWE, leveraging the syntax-based opinion possibility scores and the syntactic connections between the words. We also introduce a novel regularization technique to improve the performance of the deep learning models based on the representation distinctions between the words in TOWE. The proposed model is extensively analyzed and achieves the state-of-the-art performance on four benchmark datasets.","introduce syntactic structure target opinion word extraction deep learning target opinion word extraction ( towe ) sub - task aspect base sentiment analysis ( absa ) aim find opinion word give aspect - term sentence . despite success towe , current deep learning model fail exploit syntactic information sentence prove useful towe prior research . work , propose incorporate syntactic structure sentence deep learning model towe , leverage syntax - base opinion possibility score syntactic connection word . introduce novel regularization technique improve performance deep learning model base representation distinction word towe . propose model extensively analyze achieve state - - - art performance benchmark dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 10, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",SentiLARE: Sentiment-Aware Language Representation Learning with Linguistic Knowledge,"Most of the existing pre-trained language representation models neglect to consider the linguistic knowledge of texts, which can promote language understanding in NLP tasks. To benefit the downstream tasks in sentiment analysis, we propose a novel language representation model called SentiLARE, which introduces word-level linguistic knowledge including part-of-speech tag and sentiment polarity (inferred from SentiWordNet) into pretrained models. We first propose a contextaware sentiment attention mechanism to acquire the sentiment polarity of each word with its part-of-speech tag by querying SentiWord-Net. Then, we devise a new pre-training task called label-aware masked language model to construct knowledge-aware language representation. Experiments show that SentiLARE obtains new state-of-the-art performance on a variety of sentiment analysis tasks 1 .","SentiLARE: Sentiment-Aware Language Representation Learning with Linguistic Knowledge Most of the existing pre-trained language representation models neglect to consider the linguistic knowledge of texts, which can promote language understanding in NLP tasks. To benefit the downstream tasks in sentiment analysis, we propose a novel language representation model called SentiLARE, which introduces word-level linguistic knowledge including part-of-speech tag and sentiment polarity (inferred from SentiWordNet) into pretrained models. We first propose a contextaware sentiment attention mechanism to acquire the sentiment polarity of each word with its part-of-speech tag by querying SentiWord-Net. Then, we devise a new pre-training task called label-aware masked language model to construct knowledge-aware language representation. Experiments show that SentiLARE obtains new state-of-the-art performance on a variety of sentiment analysis tasks 1 .","sentilare : sentiment - aware language representation learning linguistic knowledge exist pre - trained language representation model neglect consider linguistic knowledge text , promote language understanding nlp task . benefit downstream task sentiment analysis , propose novel language representation model call sentilare , introduce word - level linguistic knowledge include - - speech tag sentiment polarity ( infer sentiwordnet ) pretrained model . propose contextaware sentiment attention mechanism acquire sentiment polarity word - - speech tag query sentiword - net . , devise new pre - training task call label - aware mask language model construct knowledge - aware language representation . experiment sentilare obtain new state - - - art performance variety sentiment analysis task 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Sentiment Analysis of Tweets using Heterogeneous Multi-layer Network Representation and Embedding,"Sentiment classification on tweets often needs to deal with the problems of under-specificity, noise, and multilingual content. This study proposes a heterogeneous multi-layer networkbased representation of tweets to generate multiple representations of a tweet and address the above issues. The generated representations are further ensembled and classified using a neural-based early fusion approach. Further, we propose a centrality aware random-walk for node embedding and tweet representations suitable for the multi-layer network. From various experimental analysis, it is evident that the proposed method can address the problem of under-specificity, noisy text, and multilingual content present in a tweet and provides better classification performance than the textbased counterparts. Further, the proposed centrality aware based random walk provides better representations than unbiased and other biased counterparts.","Sentiment Analysis of Tweets using Heterogeneous Multi-layer Network Representation and Embedding Sentiment classification on tweets often needs to deal with the problems of under-specificity, noise, and multilingual content. This study proposes a heterogeneous multi-layer networkbased representation of tweets to generate multiple representations of a tweet and address the above issues. The generated representations are further ensembled and classified using a neural-based early fusion approach. Further, we propose a centrality aware random-walk for node embedding and tweet representations suitable for the multi-layer network. From various experimental analysis, it is evident that the proposed method can address the problem of under-specificity, noisy text, and multilingual content present in a tweet and provides better classification performance than the textbased counterparts. Further, the proposed centrality aware based random walk provides better representations than unbiased and other biased counterparts.","sentiment analysis tweet heterogeneous multi - layer network representation embedding sentiment classification tweet need deal problem - specificity , noise , multilingual content . study propose heterogeneous multi - layer networkbased representation tweet generate multiple representation tweet address issue . generate representation ensemble classify neural - base early fusion approach . , propose centrality aware random - walk node embedding tweet representation suitable multi - layer network . experimental analysis , evident propose method address problem - specificity , noisy text , multilingual content present tweet provide well classification performance textbased counterpart . , propose centrality aware base random walk provide well representation unbiased biased counterpart .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",CancerEmo: A Dataset for Fine-Grained Emotion Detection,"Emotions are an important element of human nature, often affecting the overall wellbeing of a person. Therefore, it is no surprise that the health domain is a valuable area of interest for emotion detection, as it can provide medical staff or caregivers with essential information about patients. However, progress on this task has been hampered by the absence of large labeled datasets. To this end, we introduce CANCEREMO , an emotion dataset created from an online health community and annotated with eight fine-grained emotions. We perform a comprehensive analysis of these emotions and develop deep learning models on the newly created dataset. Our best BERT model achieves an average F1 of 71%, which we improve further using domain-specific pretraining.","CancerEmo: A Dataset for Fine-Grained Emotion Detection Emotions are an important element of human nature, often affecting the overall wellbeing of a person. Therefore, it is no surprise that the health domain is a valuable area of interest for emotion detection, as it can provide medical staff or caregivers with essential information about patients. However, progress on this task has been hampered by the absence of large labeled datasets. To this end, we introduce CANCEREMO , an emotion dataset created from an online health community and annotated with eight fine-grained emotions. We perform a comprehensive analysis of these emotions and develop deep learning models on the newly created dataset. Our best BERT model achieves an average F1 of 71%, which we improve further using domain-specific pretraining.","canceremo : dataset fine - grained emotion detection emotion important element human nature , affect overall wellbeing person . , surprise health domain valuable area interest emotion detection , provide medical staff caregiver essential information patient . , progress task hamper absence large label dataset . end , introduce canceremo , emotion dataset create online health community annotate fine - grained emotion . perform comprehensive analysis emotion develop deep learning model newly create dataset . good bert model achieve average f1 71 % , improve domain - specific pretraining .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Extracting Implicitly Asserted Propositions in Argumentation,"Argumentation accommodates various rhetorical devices, such as questions, reported speech, and imperatives. These rhetorical tools usually assert argumentatively relevant propositions rather implicitly, so understanding their true meaning is key to understanding certain arguments properly. However, most argument mining systems and computational linguistics research have paid little attention to implicitly asserted propositions in argumentation. In this paper, we examine a wide range of computational methods for extracting propositions that are implicitly asserted in questions, reported speech, and imperatives in argumentation. By evaluating the models on a corpus of 2016 U.S. presidential debates and online commentary, we demonstrate the effectiveness and limitations of the computational models. Our study may inform future research on argument mining and the semantics of these rhetorical devices in argumentation. 1","Extracting Implicitly Asserted Propositions in Argumentation Argumentation accommodates various rhetorical devices, such as questions, reported speech, and imperatives. These rhetorical tools usually assert argumentatively relevant propositions rather implicitly, so understanding their true meaning is key to understanding certain arguments properly. However, most argument mining systems and computational linguistics research have paid little attention to implicitly asserted propositions in argumentation. In this paper, we examine a wide range of computational methods for extracting propositions that are implicitly asserted in questions, reported speech, and imperatives in argumentation. By evaluating the models on a corpus of 2016 U.S. presidential debates and online commentary, we demonstrate the effectiveness and limitations of the computational models. Our study may inform future research on argument mining and the semantics of these rhetorical devices in argumentation. 1","extract implicitly assert propositions argumentation argumentation accommodate rhetorical device , question , report speech , imperative . rhetorical tool usually assert argumentatively relevant proposition implicitly , understand true meaning key understand certain argument properly . , argument mining system computational linguistic research pay little attention implicitly assert proposition argumentation . paper , examine wide range computational method extract proposition implicitly assert question , report speech , imperative argumentation . evaluate model corpus 2016 u.s. presidential debate online commentary , demonstrate effectiveness limitation computational model . study inform future research argument mining semantic rhetorical device argumentation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 2, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 9, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Affective Event Classification with Discourse-enhanced Self-training,"Prior research has recognized the need to associate affective polarities with events and has produced several techniques and lexical resources for identifying affective events. Our research introduces new classification models to assign affective polarity to event phrases. First, we present a BERT-based model for affective event classification and show that the classifier achieves substantially better performance than a large affective event knowledge base. Second, we present a discourse-enhanced selftraining method that iteratively improves the classifier with unlabeled data. The key idea is to exploit event phrases that occur with a coreferent sentiment expression. The discourseenhanced self-training algorithm iteratively labels new event phrases based on both the classifier's predictions and the polarities of the event's coreferent sentiment expressions. Our results show that discourse-enhanced selftraining further improves both recall and precision for affective event classification.","Affective Event Classification with Discourse-enhanced Self-training Prior research has recognized the need to associate affective polarities with events and has produced several techniques and lexical resources for identifying affective events. Our research introduces new classification models to assign affective polarity to event phrases. First, we present a BERT-based model for affective event classification and show that the classifier achieves substantially better performance than a large affective event knowledge base. Second, we present a discourse-enhanced selftraining method that iteratively improves the classifier with unlabeled data. The key idea is to exploit event phrases that occur with a coreferent sentiment expression. The discourseenhanced self-training algorithm iteratively labels new event phrases based on both the classifier's predictions and the polarities of the event's coreferent sentiment expressions. Our results show that discourse-enhanced selftraining further improves both recall and precision for affective event classification.","affective event classification discourse - enhance self - training prior research recognize need associate affective polarity event produce technique lexical resource identify affective event . research introduce new classification model assign affective polarity event phrase . , present bert - base model affective event classification classifier achieve substantially well performance large affective event knowledge base . second , present discourse - enhance selftraining method iteratively improve classifier unlabeled datum . key idea exploit event phrase occur coreferent sentiment expression . discourseenhance self - train algorithm iteratively label new event phrase base classifier prediction polarity event coreferent sentiment expression . result discourse - enhance selftraining improve recall precision affective event classification .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",APE: Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning,"Peer review and rebuttal, with rich interactions and argumentative discussions in between, are naturally a good resource to mine arguments. However, few works study both of them simultaneously. In this paper, we introduce a new argument pair extraction (APE) task on peer review and rebuttal in order to study the contents, the structure and the connections between them. We prepare a challenging dataset that contains 4,764 fully annotated review-rebuttal passage pairs from an open review platform to facilitate the study of this task. To automatically detect argumentative propositions and extract argument pairs from this corpus, we cast it as the combination of a sequence labeling task and a text relation classification task. Thus, we propose a multitask learning framework based on hierarchical LSTM networks. Extensive experiments and analysis demonstrate the effectiveness of our multi-task framework, and also show the challenges of the new task as well as motivate future research directions. 1","APE: Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning Peer review and rebuttal, with rich interactions and argumentative discussions in between, are naturally a good resource to mine arguments. However, few works study both of them simultaneously. In this paper, we introduce a new argument pair extraction (APE) task on peer review and rebuttal in order to study the contents, the structure and the connections between them. We prepare a challenging dataset that contains 4,764 fully annotated review-rebuttal passage pairs from an open review platform to facilitate the study of this task. To automatically detect argumentative propositions and extract argument pairs from this corpus, we cast it as the combination of a sequence labeling task and a text relation classification task. Thus, we propose a multitask learning framework based on hierarchical LSTM networks. Extensive experiments and analysis demonstrate the effectiveness of our multi-task framework, and also show the challenges of the new task as well as motivate future research directions. 1","ape : argument pair extraction peer review rebuttal multi - task learning peer review rebuttal , rich interaction argumentative discussion , naturally good resource argument . , work study simultaneously . paper , introduce new argument pair extraction ( ape ) task peer review rebuttal order study content , structure connection . prepare challenging dataset contain 4,764 fully annotate review - rebuttal passage pair open review platform facilitate study task . automatically detect argumentative proposition extract argument pair corpus , cast combination sequence labeling task text relation classification task . , propose multitask learning framework base hierarchical lstm network . extensive experiment analysis demonstrate effectiveness multi - task framework , challenge new task motivate future research direction . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Aspect Sentiment Classification with Aspect-Specific Opinion Spans,"Aspect sentiment classification, predicting the sentiment polarity of given aspects, has drawn extensive attention. Previous attention-based models emphasize using aspect semantics to help extract opinion features for classification. However, these works are either not able to capture opinion spans as a whole or capture variable-length opinion spans. In this paper, we present a neat and effective multiple CRFs based structured attention model that is capable of extracting aspect-specific opinion spans. The sentiment polarity of the target is then classified based on the extracted opinion features and contextual information. The experimental results on four datasets demonstrate the effectiveness of the proposed model, and our further analysis shows that our model can capture aspect-specific opinion spans. 1","Aspect Sentiment Classification with Aspect-Specific Opinion Spans Aspect sentiment classification, predicting the sentiment polarity of given aspects, has drawn extensive attention. Previous attention-based models emphasize using aspect semantics to help extract opinion features for classification. However, these works are either not able to capture opinion spans as a whole or capture variable-length opinion spans. In this paper, we present a neat and effective multiple CRFs based structured attention model that is capable of extracting aspect-specific opinion spans. The sentiment polarity of the target is then classified based on the extracted opinion features and contextual information. The experimental results on four datasets demonstrate the effectiveness of the proposed model, and our further analysis shows that our model can capture aspect-specific opinion spans. 1","aspect sentiment classification aspect - specific opinion span aspect sentiment classification , predict sentiment polarity give aspect , draw extensive attention . previous attention - base model emphasize aspect semantic help extract opinion feature classification . , work able capture opinion span capture variable - length opinion span . paper , present neat effective multiple crf base structure attention model capable extract aspect - specific opinion span . sentiment polarity target classify base extract opinion feature contextual information . experimental result dataset demonstrate effectiveness propose model , analysis show model capture aspect - specific opinion span . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 18, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Diversified Multiple Instance Learning for Document-Level Multi-Aspect Sentiment Classification,"Neural Document-level Multi-aspect Sentiment Classification (DMSC) usually requires a lot of manual aspect-level sentiment annotations, which is time-consuming and laborious. As document-level sentiment labeled data are widely available from online service, it is valuable to perform DMSC with such free document-level annotations. To this end, we propose a novel Diversified Multiple Instance Learning Network (D-MILN), which is able to achieve aspect-level sentiment classification with only document-level weak supervision. Specifically, we connect aspect-level and document-level sentiment by formulating this problem as multiple instance learning, providing a way to learn aspect-level classifier from the back propagation of document-level supervision. Two diversified regularizations are further introduced in order to avoid the overfitting on document-level signals during training. Diversified textual regularization encourages the classifier to select aspect-relevant snippets, and diversified sentimental regularization prevents the aspect-level sentiments from being overly consistent with document-level sentiment. Experimental results on TripAdvisor and BeerAdvocate datasets show that D-MILN remarkably outperforms recent weaklysupervised baselines, and is also comparable to the supervised method.","Diversified Multiple Instance Learning for Document-Level Multi-Aspect Sentiment Classification Neural Document-level Multi-aspect Sentiment Classification (DMSC) usually requires a lot of manual aspect-level sentiment annotations, which is time-consuming and laborious. As document-level sentiment labeled data are widely available from online service, it is valuable to perform DMSC with such free document-level annotations. To this end, we propose a novel Diversified Multiple Instance Learning Network (D-MILN), which is able to achieve aspect-level sentiment classification with only document-level weak supervision. Specifically, we connect aspect-level and document-level sentiment by formulating this problem as multiple instance learning, providing a way to learn aspect-level classifier from the back propagation of document-level supervision. Two diversified regularizations are further introduced in order to avoid the overfitting on document-level signals during training. Diversified textual regularization encourages the classifier to select aspect-relevant snippets, and diversified sentimental regularization prevents the aspect-level sentiments from being overly consistent with document-level sentiment. Experimental results on TripAdvisor and BeerAdvocate datasets show that D-MILN remarkably outperforms recent weaklysupervised baselines, and is also comparable to the supervised method.","diversified multiple instance learning document - level multi - aspect sentiment classification neural document - level multi - aspect sentiment classification ( dmsc ) usually require lot manual aspect - level sentiment annotation , time - consume laborious . document - level sentiment label datum widely available online service , valuable perform dmsc free document - level annotation . end , propose novel diversified multiple instance learning network ( d - miln ) , able achieve aspect - level sentiment classification document - level weak supervision . specifically , connect aspect - level document - level sentiment formulate problem multiple instance learning , provide way learn aspect - level classifier propagation document - level supervision . diversified regularization introduce order avoid overfitting document - level signal training . diversified textual regularization encourage classifier select aspect - relevant snippet , diversified sentimental regularization prevent aspect - level sentiment overly consistent document - level sentiment . experimental result tripadvisor beeradvocate dataset d - miln remarkably outperform recent weaklysupervised baseline , comparable supervise method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 12, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 20, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Deep Weighted MaxSAT for Aspect-based Opinion Extraction,"Though deep learning has achieved significant success in various NLP tasks, most deep learning models lack the capability of encoding explicit domain knowledge to model complex causal relationships among different types of variables. On the other hand, logic rules offer a compact expression to represent the causal relationships to guide the training process. Logic programs can be cast as a satisfiability problem which aims to find truth assignments to logic variables by maximizing the number of satisfiable clauses (MaxSAT). We adopt the MaxSAT semantics to model logic inference process and smoothly incorporate a weighted version of MaxSAT that connects deep neural networks and a graphical model in a joint framework. The joint model feeds deep learning outputs to a weighted MaxSAT layer to rectify the erroneous predictions and can be trained via end-to-end gradient descent. Our proposed model associates the benefits of highlevel feature learning, knowledge reasoning, and structured learning with observable performance gain for the task of aspect-based opinion extraction.","Deep Weighted MaxSAT for Aspect-based Opinion Extraction Though deep learning has achieved significant success in various NLP tasks, most deep learning models lack the capability of encoding explicit domain knowledge to model complex causal relationships among different types of variables. On the other hand, logic rules offer a compact expression to represent the causal relationships to guide the training process. Logic programs can be cast as a satisfiability problem which aims to find truth assignments to logic variables by maximizing the number of satisfiable clauses (MaxSAT). We adopt the MaxSAT semantics to model logic inference process and smoothly incorporate a weighted version of MaxSAT that connects deep neural networks and a graphical model in a joint framework. The joint model feeds deep learning outputs to a weighted MaxSAT layer to rectify the erroneous predictions and can be trained via end-to-end gradient descent. Our proposed model associates the benefits of highlevel feature learning, knowledge reasoning, and structured learning with observable performance gain for the task of aspect-based opinion extraction.","deep weighted maxsat aspect - base opinion extraction deep learning achieve significant success nlp task , deep learning model lack capability encode explicit domain knowledge model complex causal relationship different type variable . hand , logic rule offer compact expression represent causal relationship guide training process . logic program cast satisfiability problem aim find truth assignment logic variable maximize number satisfiable clause ( maxsat ) . adopt maxsat semantic model logic inference process smoothly incorporate weight version maxsat connect deep neural network graphical model joint framework . joint model feed deep learning output weighted maxsat layer rectify erroneous prediction train end - - end gradient descent . propose model associate benefit highlevel feature learning , knowledge reasoning , structured learning observable performance gain task aspect - base opinion extraction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",A Multi-Task Incremental Learning Framework with Category Name Embedding for Aspect-Category Sentiment Analysis,"T)ACSA tasks, including aspect-category sentiment analysis (ACSA) and targeted aspectcategory sentiment analysis (TACSA), aims at identifying sentiment polarity on predefined categories. Incremental learning on new categories is necessary for (T)ACSA real applications. Though current multi-task learning models achieve good performance in (T)ACSA tasks, they suffer from catastrophic forgetting problems in (T)ACSA incremental learning tasks. In this paper, to make multi-task learning feasible for incremental learning, we proposed Category Name Embedding network (CNE-net). We set both encoder and decoder shared among all categories to weaken the catastrophic forgetting problem. Besides the origin input sentence, we applied another input feature, i.e., category name, for task discrimination. Our model achieved state-of-theart on two (T)ACSA benchmark datasets. Furthermore, we proposed a dataset for (T)ACSA incremental learning and achieved the best performance compared with other strong baselines.","A Multi-Task Incremental Learning Framework with Category Name Embedding for Aspect-Category Sentiment Analysis T)ACSA tasks, including aspect-category sentiment analysis (ACSA) and targeted aspectcategory sentiment analysis (TACSA), aims at identifying sentiment polarity on predefined categories. Incremental learning on new categories is necessary for (T)ACSA real applications. Though current multi-task learning models achieve good performance in (T)ACSA tasks, they suffer from catastrophic forgetting problems in (T)ACSA incremental learning tasks. In this paper, to make multi-task learning feasible for incremental learning, we proposed Category Name Embedding network (CNE-net). We set both encoder and decoder shared among all categories to weaken the catastrophic forgetting problem. Besides the origin input sentence, we applied another input feature, i.e., category name, for task discrimination. Our model achieved state-of-theart on two (T)ACSA benchmark datasets. Furthermore, we proposed a dataset for (T)ACSA incremental learning and achieved the best performance compared with other strong baselines.","multi - task incremental learning framework category embedding aspect - category sentiment analysis t)acsa task , include aspect - category sentiment analysis ( acsa ) target aspectcategory sentiment analysis ( tacsa ) , aim identify sentiment polarity predefine category . incremental learning new category necessary ( t)acsa real application . current multi - task learning model achieve good performance ( t)acsa task , suffer catastrophic forgetting problem ( t)acsa incremental learning task . paper , multi - task learning feasible incremental learning , propose category embedding network ( cne - net ) . set encoder decoder share category weaken catastrophic forgetting problem . origin input sentence , apply input feature , i.e. , category , task discrimination . model achieve state - - theart ( t)acsa benchmark dataset . furthermore , propose dataset ( t)acsa incremental learning achieve good performance compare strong baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 10, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining","Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based Sentiment Analysis","Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards a specific aspect in the text. However, existing ABSA test sets cannot be used to probe whether a model can distinguish the sentiment of the target aspect from the non-target aspects. To solve this problem, we develop a simple but effective approach to enrich ABSA test sets. Specifically, we generate new examples to disentangle the confounding sentiments of the non-target aspects from the target aspect's sentiment. Based on the SemEval 2014 dataset, we construct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the aspect robustness of ABSA models. Over 92% data of ARTS show high fluency and desired sentiment on all aspects by human evaluation. Using ARTS, we analyze the robustness of nine ABSA models, and observe, surprisingly, that their accuracy drops by up to 69.73%. We explore several ways to improve aspect robustness, and find that adversarial training can improve models' performance on ARTS by up to 32.85%. 1","Tasty Burgers, Soggy Fries: Probing Aspect Robustness in Aspect-Based Sentiment Analysis Aspect-based sentiment analysis (ABSA) aims to predict the sentiment towards a specific aspect in the text. However, existing ABSA test sets cannot be used to probe whether a model can distinguish the sentiment of the target aspect from the non-target aspects. To solve this problem, we develop a simple but effective approach to enrich ABSA test sets. Specifically, we generate new examples to disentangle the confounding sentiments of the non-target aspects from the target aspect's sentiment. Based on the SemEval 2014 dataset, we construct the Aspect Robustness Test Set (ARTS) as a comprehensive probe of the aspect robustness of ABSA models. Over 92% data of ARTS show high fluency and desired sentiment on all aspects by human evaluation. Using ARTS, we analyze the robustness of nine ABSA models, and observe, surprisingly, that their accuracy drops by up to 69.73%. We explore several ways to improve aspect robustness, and find that adversarial training can improve models' performance on ARTS by up to 32.85%. 1","tasty burger , soggy fry : probe aspect robustness aspect - base sentiment analysis aspect - base sentiment analysis ( absa ) aim predict sentiment specific aspect text . , exist absa test set probe model distinguish sentiment target aspect non - target aspect . solve problem , develop simple effective approach enrich absa test set . specifically , generate new example disentangle confound sentiment non - target aspect target aspect sentiment . base semeval 2014 dataset , construct aspect robustness test set ( arts ) comprehensive probe aspect robustness absa model . 92 % datum arts high fluency desire sentiment aspect human evaluation . arts , analyze robustness absa model , observe , surprisingly , accuracy drop 69.73 % . explore way improve aspect robustness , find adversarial training improve model ' performance arts 32.85 % . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 21, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",End-to-End Emotion-Cause Pair Extraction based on Sliding Window Multi-Label Learning,"Emotion-cause pair extraction (ECPE) is a new task that aims to extract the potential pairs of emotions and their corresponding causes in a document. The existing methods first perform emotion extraction and cause extraction independently, and then perform emotion-cause pairing and filtering. However, the above methods ignore the fact that the cause and the emotion it triggers are inseparable, and the extraction of the cause without specifying the emotion is pathological, which greatly limits the performance of the above methods in the first step. To tackle these shortcomings, we propose two joint frameworks for ECPE: 1) multi-label learning for the extraction of the cause clauses corresponding to the specified emotion clause (CMLL) and 2) multi-label learning for the extraction of the emotion clauses corresponding to the specified cause clause (EMLL). The window of multilabel learning is centered on the specified emotion clause or cause clause and slides as their positions move. Finally, CMLL and EMLL are integrated to obtain the final result. We evaluate our model on a benchmark emotion cause corpus, the results show that our approach achieves the best performance among all compared systems on the ECPE task.","End-to-End Emotion-Cause Pair Extraction based on Sliding Window Multi-Label Learning Emotion-cause pair extraction (ECPE) is a new task that aims to extract the potential pairs of emotions and their corresponding causes in a document. The existing methods first perform emotion extraction and cause extraction independently, and then perform emotion-cause pairing and filtering. However, the above methods ignore the fact that the cause and the emotion it triggers are inseparable, and the extraction of the cause without specifying the emotion is pathological, which greatly limits the performance of the above methods in the first step. To tackle these shortcomings, we propose two joint frameworks for ECPE: 1) multi-label learning for the extraction of the cause clauses corresponding to the specified emotion clause (CMLL) and 2) multi-label learning for the extraction of the emotion clauses corresponding to the specified cause clause (EMLL). The window of multilabel learning is centered on the specified emotion clause or cause clause and slides as their positions move. Finally, CMLL and EMLL are integrated to obtain the final result. We evaluate our model on a benchmark emotion cause corpus, the results show that our approach achieves the best performance among all compared systems on the ECPE task.","end - - end emotion - cause pair extraction base slide window multi - label learning emotion - cause pair extraction ( ecpe ) new task aim extract potential pair emotion corresponding cause document . exist method perform emotion extraction cause extraction independently , perform emotion - cause pairing filtering . , method ignore fact cause emotion trigger inseparable , extraction cause specify emotion pathological , greatly limit performance method step . tackle shortcoming , propose joint framework ecpe : 1 ) multi - label learning extraction cause clause correspond specified emotion clause ( cmll ) 2 ) multi - label learning extraction emotion clause correspond specified cause clause ( emll ) . window multilabel learning center specified emotion clause cause clause slide position . finally , cmll emll integrate obtain final result . evaluate model benchmark emotion cause corpus , result approach achieve good performance compare system ecpe task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 30, 'Speech and Multimodality': 14, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Multi-Instance Multi-Label Learning Networks for Aspect-Category Sentiment Analysis,"Aspect-category sentiment analysis (ACSA) aims to predict sentiment polarities of sentences with respect to given aspect categories. To detect the sentiment toward a particular aspect category in a sentence, most previous methods first generate an aspect categoryspecific sentence representation for the aspect category, then predict the sentiment polarity based on the representation. These methods ignore the fact that the sentiment of an aspect category mentioned in a sentence is an aggregation of the sentiments of the words indicating the aspect category in the sentence, which leads to suboptimal performance. In this paper, we propose a Multi-Instance Multi-Label Learning Network for Aspect-Category sentiment analysis (AC-MIMLLN), which treats sentences as bags, words as instances, and the words indicating an aspect category as the key instances of the aspect category. Given a sentence and the aspect categories mentioned in the sentence, AC-MIMLLN first predicts the sentiments of the instances, then finds the key instances for the aspect categories, finally obtains the sentiments of the sentence toward the aspect categories by aggregating the key instance sentiments. Experimental results on three public datasets demonstrate the effectiveness of AC-MIMLLN 1 .","Multi-Instance Multi-Label Learning Networks for Aspect-Category Sentiment Analysis Aspect-category sentiment analysis (ACSA) aims to predict sentiment polarities of sentences with respect to given aspect categories. To detect the sentiment toward a particular aspect category in a sentence, most previous methods first generate an aspect categoryspecific sentence representation for the aspect category, then predict the sentiment polarity based on the representation. These methods ignore the fact that the sentiment of an aspect category mentioned in a sentence is an aggregation of the sentiments of the words indicating the aspect category in the sentence, which leads to suboptimal performance. In this paper, we propose a Multi-Instance Multi-Label Learning Network for Aspect-Category sentiment analysis (AC-MIMLLN), which treats sentences as bags, words as instances, and the words indicating an aspect category as the key instances of the aspect category. Given a sentence and the aspect categories mentioned in the sentence, AC-MIMLLN first predicts the sentiments of the instances, then finds the key instances for the aspect categories, finally obtains the sentiments of the sentence toward the aspect categories by aggregating the key instance sentiments. Experimental results on three public datasets demonstrate the effectiveness of AC-MIMLLN 1 .","multi - instance multi - label learning networks aspect - category sentiment analysis aspect - category sentiment analysis ( acsa ) aim predict sentiment polarity sentence respect give aspect category . detect sentiment particular aspect category sentence , previous method generate aspect categoryspecific sentence representation aspect category , predict sentiment polarity base representation . method ignore fact sentiment aspect category mention sentence aggregation sentiment word indicate aspect category sentence , lead suboptimal performance . paper , propose multi - instance multi - label learning network aspect - category sentiment analysis ( ac - mimlln ) , treat sentence bag , word instance , word indicate aspect category key instance aspect category . give sentence aspect category mention sentence , ac - mimlln predict sentiment instance , find key instance aspect category , finally obtain sentiment sentence aspect category aggregate key instance sentiment . experimental result public dataset demonstrate effectiveness ac - mimlln 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 35, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Detecting Attackable Sentences in Arguments,"Finding attackable sentences in an argument is the first step toward successful refutation in argumentation. We present a first large-scale analysis of sentence attackability in online arguments. We analyze driving reasons for attacks in argumentation and identify relevant characteristics of sentences. We demonstrate that a sentence's attackability is associated with many of these characteristics regarding the sentence's content, proposition types, and tone, and that an external knowledge source can provide useful information about attackability. Building on these findings, we demonstrate that machine learning models can automatically detect attackable sentences in arguments, significantly better than several baselines and comparably well to laypeople. 1","Detecting Attackable Sentences in Arguments Finding attackable sentences in an argument is the first step toward successful refutation in argumentation. We present a first large-scale analysis of sentence attackability in online arguments. We analyze driving reasons for attacks in argumentation and identify relevant characteristics of sentences. We demonstrate that a sentence's attackability is associated with many of these characteristics regarding the sentence's content, proposition types, and tone, and that an external knowledge source can provide useful information about attackability. Building on these findings, we demonstrate that machine learning models can automatically detect attackable sentences in arguments, significantly better than several baselines and comparably well to laypeople. 1","detect attackable sentence argument find attackable sentence argument step successful refutation argumentation . present large - scale analysis sentence attackability online argument . analyze drive reason attack argumentation identify relevant characteristic sentence . demonstrate sentence attackability associate characteristic sentence content , proposition type , tone , external knowledge source provide useful information attackability . build finding , demonstrate machine learning model automatically detect attackable sentence argument , significantly well baseline comparably laypeople . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Convolution over Hierarchical Syntactic and Lexical Graphs for Aspect Level Sentiment Analysis,"The state-of-the-art methods in aspect-level sentiment classification have leveraged the graph based models to incorporate the syntactic structure of a sentence. While being effective, these methods ignore the corpus level word co-occurrence information, which reflect the collocations in linguistics like ""nothing special"". Moreover, they do not distinguish the different types of syntactic dependency, e.g., a nominal subject relation ""food-was"" is treated equally as an adjectival complement relation ""was-okay"" in ""food was okay"". To tackle the above two limitations, we propose a novel architecture which convolutes over hierarchical syntactic and lexical graphs. Specifically, we employ a global lexical graph to encode the corpus level word co-occurrence information. Moreover, we build a concept hierarchy on both the syntactic and lexical graphs for differentiating various types of dependency relations or lexical word pairs. Finally, we design a bi-level interactive graph convolution network to fully exploit these two graphs. Extensive experiments on five benchmark datasets show that our method achieves the state-of-the-art performance.","Convolution over Hierarchical Syntactic and Lexical Graphs for Aspect Level Sentiment Analysis The state-of-the-art methods in aspect-level sentiment classification have leveraged the graph based models to incorporate the syntactic structure of a sentence. While being effective, these methods ignore the corpus level word co-occurrence information, which reflect the collocations in linguistics like ""nothing special"". Moreover, they do not distinguish the different types of syntactic dependency, e.g., a nominal subject relation ""food-was"" is treated equally as an adjectival complement relation ""was-okay"" in ""food was okay"". To tackle the above two limitations, we propose a novel architecture which convolutes over hierarchical syntactic and lexical graphs. Specifically, we employ a global lexical graph to encode the corpus level word co-occurrence information. Moreover, we build a concept hierarchy on both the syntactic and lexical graphs for differentiating various types of dependency relations or lexical word pairs. Finally, we design a bi-level interactive graph convolution network to fully exploit these two graphs. Extensive experiments on five benchmark datasets show that our method achieves the state-of-the-art performance.","convolution hierarchical syntactic lexical graph aspect level sentiment analysis state - - - art method aspect - level sentiment classification leverage graph base model incorporate syntactic structure sentence . effective , method ignore corpus level word co - occurrence information , reflect collocation linguistic like "" special "" . , distinguish different type syntactic dependency , e.g. , nominal subject relation "" food - "" treat equally adjectival complement relation "" - okay "" "" food okay "" . tackle limitation , propose novel architecture convolute hierarchical syntactic lexical graph . specifically , employ global lexical graph encode corpus level word co - occurrence information . , build concept hierarchy syntactic lexical graph differentiate type dependency relation lexical word pair . finally , design bi - level interactive graph convolution network fully exploit graph . extensive experiment benchmark dataset method achieve state - - - art performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Generation,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Quantitative argument summarization and beyond: Cross-domain key point analysis,"When summarizing a collection of views, arguments or opinions on some topic, it is often desirable not only to extract the most salient points, but also to quantify their prevalence. Work on multi-document summarization has traditionally focused on creating textual summaries, which lack this quantitative aspect. Recent work has proposed to summarize arguments by mapping them to a small set of expert-generated key points, where the salience of each key point corresponds to the number of its matching arguments. The current work advances key point analysis in two important respects: first, we develop a method for automatic extraction of key points, which enables fully automatic analysis, and is shown to achieve performance comparable to a human expert. Second, we demonstrate that the applicability of key point analysis goes well beyond argumentation data. Using models trained on publicly available argumentation datasets, we achieve promising results in two additional domains: municipal surveys and user reviews. An additional contribution is an in-depth evaluation of argument-to-key point matching models, where we substantially outperform previous results.","Quantitative argument summarization and beyond: Cross-domain key point analysis When summarizing a collection of views, arguments or opinions on some topic, it is often desirable not only to extract the most salient points, but also to quantify their prevalence. Work on multi-document summarization has traditionally focused on creating textual summaries, which lack this quantitative aspect. Recent work has proposed to summarize arguments by mapping them to a small set of expert-generated key points, where the salience of each key point corresponds to the number of its matching arguments. The current work advances key point analysis in two important respects: first, we develop a method for automatic extraction of key points, which enables fully automatic analysis, and is shown to achieve performance comparable to a human expert. Second, we demonstrate that the applicability of key point analysis goes well beyond argumentation data. Using models trained on publicly available argumentation datasets, we achieve promising results in two additional domains: municipal surveys and user reviews. An additional contribution is an in-depth evaluation of argument-to-key point matching models, where we substantially outperform previous results.","quantitative argument summarization : cross - domain key point analysis summarize collection view , argument opinion topic , desirable extract salient point , quantify prevalence . work multi - document summarization traditionally focus create textual summary , lack quantitative aspect . recent work propose summarize argument map small set expert - generate key point , salience key point correspond number match argument . current work advance key point analysis important respect : , develop method automatic extraction key point , enable fully automatic analysis , show achieve performance comparable human expert . second , demonstrate applicability key point analysis go argumentation datum . model train publicly available argumentation dataset , achieve promising result additional domain : municipal survey user review . additional contribution - depth evaluation argument - - key point matching model , substantially outperform previous result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 10, 'Speech and Multimodality': 0, 'Student Research Workshop': 8, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Multi-modal Multi-label Emotion Detection with Modality and Label Dependence,"As an important research issue in the natural language processing community, multi-label emotion detection has been drawing more and more attention in the last few years. However, almost all existing studies focus on one modality (e.g., textual modality). In this paper, we focus on multi-label emotion detection in a multi-modal scenario. In this scenario, we need to consider both the dependence among different labels (label dependence) and the dependence between each predicting label and different modalities (modality dependence). Particularly, we propose a multi-modal sequence-to-set approach to effectively model both kinds of dependence in multi-modal multi-label emotion detection. The detailed evaluation demonstrates the effectiveness of our approach.","Multi-modal Multi-label Emotion Detection with Modality and Label Dependence As an important research issue in the natural language processing community, multi-label emotion detection has been drawing more and more attention in the last few years. However, almost all existing studies focus on one modality (e.g., textual modality). In this paper, we focus on multi-label emotion detection in a multi-modal scenario. In this scenario, we need to consider both the dependence among different labels (label dependence) and the dependence between each predicting label and different modalities (modality dependence). Particularly, we propose a multi-modal sequence-to-set approach to effectively model both kinds of dependence in multi-modal multi-label emotion detection. The detailed evaluation demonstrates the effectiveness of our approach.","multi - modal multi - label emotion detection modality label dependence important research issue natural language processing community , multi - label emotion detection draw attention year . , exist study focus modality ( e.g. , textual modality ) . paper , focus multi - label emotion detection multi - modal scenario . scenario , need consider dependence different label ( label dependence ) dependence predict label different modality ( modality dependence ) . particularly , propose multi - modal sequence - - set approach effectively model kind dependence multi - modal multi - label emotion detection . detailed evaluation demonstrate effectiveness approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 15, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",MIME: MIMicking Emotions for Empathetic Response Generation,"Current approaches to empathetic response generation view the set of emotions expressed in the input text as a flat structure, where all the emotions are treated uniformly. We argue that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content. We show that the consideration of these polaritybased emotion clusters and emotional mimicry results in improved empathy and contextual relevance of the response as compared to the state-of-the-art. Also, we introduce stochasticity into the emotion mixture that yields emotionally more varied empathetic responses than the previous work. We demonstrate the importance of these factors to empathetic response generation using both automatic-and human-based evaluations. The implementation of MIME is publicly available at https: //github.com/declare-lab/MIME.","MIME: MIMicking Emotions for Empathetic Response Generation Current approaches to empathetic response generation view the set of emotions expressed in the input text as a flat structure, where all the emotions are treated uniformly. We argue that empathetic responses often mimic the emotion of the user to a varying degree, depending on its positivity or negativity and content. We show that the consideration of these polaritybased emotion clusters and emotional mimicry results in improved empathy and contextual relevance of the response as compared to the state-of-the-art. Also, we introduce stochasticity into the emotion mixture that yields emotionally more varied empathetic responses than the previous work. We demonstrate the importance of these factors to empathetic response generation using both automatic-and human-based evaluations. The implementation of MIME is publicly available at https: //github.com/declare-lab/MIME.","mime : mimicking emotion empathetic response generation current approach empathetic response generation view set emotion express input text flat structure , emotion treat uniformly . argue empathetic response mimic emotion user vary degree , depend positivity negativity content . consideration polaritybased emotion cluster emotional mimicry result improve empathy contextual relevance response compare state - - - art . , introduce stochasticity emotion mixture yield emotionally varied empathetic response previous work . demonstrate importance factor empathetic response generation automatic - human - base evaluation . implementation mime publicly available https : //github.com / declare - lab / mime .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 9, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Train No Evil: Selective Masking for Task-Guided Pre-Training,"Recently, pre-trained language models mostly follow the pre-train-then-fine-tuning paradigm and have achieved great performance on various downstream tasks. However, since the pretraining stage is typically task-agnostic and the fine-tuning stage usually suffers from insufficient supervised data, the models cannot always well capture the domain-specific and task-specific patterns. In this paper, we propose a three-stage framework by adding a task-guided pre-training stage with selective masking between general pre-training and finetuning. In this stage, the model is trained by masked language modeling on in-domain unsupervised data to learn domain-specific patterns and we propose a novel selective masking strategy to learn task-specific patterns. Specifically, we design a method to measure the importance of each token in sequences and selectively mask the important tokens. Experimental results on two sentiment analysis tasks show that our method can achieve comparable or even better performance with less than 50% of computation cost, which indicates our method is both effective and efficient. The source code of this paper can be obtained from https://github. com/thunlp/SelectiveMasking.","Train No Evil: Selective Masking for Task-Guided Pre-Training Recently, pre-trained language models mostly follow the pre-train-then-fine-tuning paradigm and have achieved great performance on various downstream tasks. However, since the pretraining stage is typically task-agnostic and the fine-tuning stage usually suffers from insufficient supervised data, the models cannot always well capture the domain-specific and task-specific patterns. In this paper, we propose a three-stage framework by adding a task-guided pre-training stage with selective masking between general pre-training and finetuning. In this stage, the model is trained by masked language modeling on in-domain unsupervised data to learn domain-specific patterns and we propose a novel selective masking strategy to learn task-specific patterns. Specifically, we design a method to measure the importance of each token in sequences and selectively mask the important tokens. Experimental results on two sentiment analysis tasks show that our method can achieve comparable or even better performance with less than 50% of computation cost, which indicates our method is both effective and efficient. The source code of this paper can be obtained from https://github. com/thunlp/SelectiveMasking.","train evil : selective masking task - guide pre - training recently , pre - trained language model follow pre - train - - fine - tuning paradigm achieve great performance downstream task . , pretraine stage typically task - agnostic fine - tuning stage usually suffer insufficient supervise datum , model capture domain - specific task - specific pattern . paper , propose - stage framework add task - guide pre - training stage selective masking general pre - training finetuning . stage , model train mask language modeling - domain unsupervised datum learn domain - specific pattern propose novel selective masking strategy learn task - specific pattern . specifically , design method measure importance token sequence selectively mask important token . experimental result sentiment analysis task method achieve comparable well performance 50 % computation cost , indicate method effective efficient . source code paper obtain https://github . com / thunlp / selectivemasking .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Unified Feature and Instance Based Domain Adaptation for Aspect-Based Sentiment Analysis,"The supervised models for aspect-based sentiment analysis (ABSA) rely heavily on labeled data. However, fine-grained labeled data are scarce for the ABSA task. To alleviate the dependence on labeled data, prior works mainly focused on feature-based adaptation, which used the domain-shared knowledge to construct auxiliary tasks or domain adversarial learning to bridge the gap between domains, while ignored the attribute of instance-based adaptation. To resolve this limitation, we propose an end-to-end framework to jointly perform feature and instance based adaptation for the ABSA task in this paper. Based on BERT, we learn domain-invariant feature representations by using part-of-speech features and syntactic dependency relations to construct auxiliary tasks, and jointly perform word-level instance weighting in the framework of sequence labeling. Experiment results on four benchmarks show that the proposed method can achieve significant improvements in comparison with the state-of-the-arts in both tasks of cross-domain End2End ABSA and crossdomain aspect extraction.","Unified Feature and Instance Based Domain Adaptation for Aspect-Based Sentiment Analysis The supervised models for aspect-based sentiment analysis (ABSA) rely heavily on labeled data. However, fine-grained labeled data are scarce for the ABSA task. To alleviate the dependence on labeled data, prior works mainly focused on feature-based adaptation, which used the domain-shared knowledge to construct auxiliary tasks or domain adversarial learning to bridge the gap between domains, while ignored the attribute of instance-based adaptation. To resolve this limitation, we propose an end-to-end framework to jointly perform feature and instance based adaptation for the ABSA task in this paper. Based on BERT, we learn domain-invariant feature representations by using part-of-speech features and syntactic dependency relations to construct auxiliary tasks, and jointly perform word-level instance weighting in the framework of sequence labeling. Experiment results on four benchmarks show that the proposed method can achieve significant improvements in comparison with the state-of-the-arts in both tasks of cross-domain End2End ABSA and crossdomain aspect extraction.","unified feature instance base domain adaptation aspect - base sentiment analysis supervise model aspect - base sentiment analysis ( absa ) rely heavily label datum . , fine - grained label datum scarce absa task . alleviate dependence label datum , prior work mainly focus feature - base adaptation , domain - share knowledge construct auxiliary task domain adversarial learning bridge gap domain , ignore attribute instance - base adaptation . resolve limitation , propose end - - end framework jointly perform feature instance base adaptation absa task paper . base bert , learn domain - invariant feature representation - - speech feature syntactic dependency relation construct auxiliary task , jointly perform word - level instance weighting framework sequence labeling . experiment result benchmark propose method achieve significant improvement comparison state - - - art task cross - domain end2end absa crossdomain aspect extraction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 12, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
Speech and Multimodality,Digital Voicing of Silent Speech,"In this paper, we consider the task of digitally voicing silent speech, where silently mouthed words are converted to audible speech based on electromyography (EMG) sensor measurements that capture muscle impulses. While prior work has focused on training speech synthesis models from EMG collected during vocalized speech, we are the first to train from EMG collected during silently articulated speech. We introduce a method of training on silent EMG by transferring audio targets from vocalized to silent signals. Our method greatly improves intelligibility of audio generated from silent EMG compared to a baseline that only trains with vocalized data, decreasing transcription word error rate from 64% to 4% in one data condition and 88% to 68% in another. To spur further development on this task, we share our new dataset of silent and vocalized facial EMG measurements.","Digital Voicing of Silent Speech In this paper, we consider the task of digitally voicing silent speech, where silently mouthed words are converted to audible speech based on electromyography (EMG) sensor measurements that capture muscle impulses. While prior work has focused on training speech synthesis models from EMG collected during vocalized speech, we are the first to train from EMG collected during silently articulated speech. We introduce a method of training on silent EMG by transferring audio targets from vocalized to silent signals. Our method greatly improves intelligibility of audio generated from silent EMG compared to a baseline that only trains with vocalized data, decreasing transcription word error rate from 64% to 4% in one data condition and 88% to 68% in another. To spur further development on this task, we share our new dataset of silent and vocalized facial EMG measurements.","digital voicing silent speech paper , consider task digitally voice silent speech , silently mouthed word convert audible speech base electromyography ( emg ) sensor measurement capture muscle impulse . prior work focus train speech synthesis model emg collect vocalize speech , train emg collect silently articulate speech . introduce method train silent emg transfer audio target vocalize silent signal . method greatly improve intelligibility audio generate silent emg compare baseline train vocalize datum , decrease transcription word error rate 64 % 4 % data condition 88 % 68 % . spur development task , share new dataset silent vocalized facial emg measurement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 6, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",False
Speech and Multimodality,Simultaneous Machine Translation with Visual Context,"Simultaneous machine translation (SiMT) aims to translate a continuous input text stream into another language with the lowest latency and highest quality possible. The translation thus has to start with an incomplete source text, which is read progressively, creating the need for anticipation. In this paper, we seek to understand whether the addition of visual information can compensate for the missing source context. To this end, we analyse the impact of different multimodal approaches and visual features on state-of-the-art SiMT frameworks. Our results show that visual context is helpful and that visually-grounded models based on explicit object region information are much better than commonly used global features, reaching up to 3 BLEU points improvement under low latency scenarios. Our qualitative analysis illustrates cases where only the multimodal systems are able to translate correctly from English into gender-marked languages, as well as deal with differences in word order, such as adjective-noun placement between English and French.","Simultaneous Machine Translation with Visual Context Simultaneous machine translation (SiMT) aims to translate a continuous input text stream into another language with the lowest latency and highest quality possible. The translation thus has to start with an incomplete source text, which is read progressively, creating the need for anticipation. In this paper, we seek to understand whether the addition of visual information can compensate for the missing source context. To this end, we analyse the impact of different multimodal approaches and visual features on state-of-the-art SiMT frameworks. Our results show that visual context is helpful and that visually-grounded models based on explicit object region information are much better than commonly used global features, reaching up to 3 BLEU points improvement under low latency scenarios. Our qualitative analysis illustrates cases where only the multimodal systems are able to translate correctly from English into gender-marked languages, as well as deal with differences in word order, such as adjective-noun placement between English and French.","simultaneous machine translation visual context simultaneous machine translation ( simt ) aim translate continuous input text stream language low latency high quality possible . translation start incomplete source text , read progressively , create need anticipation . paper , seek understand addition visual information compensate miss source context . end , analyse impact different multimodal approach visual feature state - - - art simt framework . result visual context helpful visually - ground model base explicit object region information well commonly global feature , reach 3 bleu point improvement low latency scenario . qualitative analysis illustrate case multimodal system able translate correctly english gender - mark language , deal difference word order , adjective - noun placement english french .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,False
Speech and Multimodality,Widget Captioning: Generating Natural Language Description for Mobile User Interface Elements,"Natural language descriptions of user interface (UI) elements such as alternative text are crucial for accessibility and language-based interaction in general. Yet, these descriptions are constantly missing in mobile UIs. We propose widget captioning, a novel task for automatically generating language descriptions for UI elements from multimodal input including both the image and the structural representations of user interfaces. We collected a largescale dataset for widget captioning with crowdsourcing. Our dataset contains 162,859 language phrases created by human workers for annotating 61,285 UI elements across 21,750 unique UI screens. We thoroughly analyze the dataset, and train and evaluate a set of deep model configurations to investigate how each feature modality as well as the choice of learning strategies impact the quality of predicted captions. The task formulation and the dataset as well as our benchmark models contribute a solid basis for this novel multimodal captioning task that connects language and user interfaces. * Equal contribution † Participated in the project during an internship at Google Research.","Widget Captioning: Generating Natural Language Description for Mobile User Interface Elements Natural language descriptions of user interface (UI) elements such as alternative text are crucial for accessibility and language-based interaction in general. Yet, these descriptions are constantly missing in mobile UIs. We propose widget captioning, a novel task for automatically generating language descriptions for UI elements from multimodal input including both the image and the structural representations of user interfaces. We collected a largescale dataset for widget captioning with crowdsourcing. Our dataset contains 162,859 language phrases created by human workers for annotating 61,285 UI elements across 21,750 unique UI screens. We thoroughly analyze the dataset, and train and evaluate a set of deep model configurations to investigate how each feature modality as well as the choice of learning strategies impact the quality of predicted captions. The task formulation and the dataset as well as our benchmark models contribute a solid basis for this novel multimodal captioning task that connects language and user interfaces. * Equal contribution † Participated in the project during an internship at Google Research.","widget captioning : generate natural language description mobile user interface element natural language description user interface ( ui ) element alternative text crucial accessibility language - base interaction general . , description constantly miss mobile ui . propose widget captioning , novel task automatically generate language description ui element multimodal input include image structural representation user interface . collect largescale dataset widget captioning crowdsourcing . dataset contain 162,859 language phrase create human worker annotate 61,285 ui element 21,750 unique ui screen . thoroughly analyze dataset , train evaluate set deep model configuration investigate feature modality choice learning strategy impact quality predict caption . task formulation dataset benchmark model contribute solid basis novel multimodal captioning task connect language user interface . * equal contribution † participate project internship google research .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 8, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 9, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Speech and Multimodality,The importance of fillers for text representations of speech transcripts,"While being an essential component of spoken language, fillers (e.g. ""um"" or ""uh"") often remain overlooked in Spoken Language Understanding (SLU) tasks. We explore the possibility of representing them with deep contextualised embeddings, showing improvements on modelling spoken language and two downstream tasks -predicting a speaker's stance and expressed confidence.","The importance of fillers for text representations of speech transcripts While being an essential component of spoken language, fillers (e.g. ""um"" or ""uh"") often remain overlooked in Spoken Language Understanding (SLU) tasks. We explore the possibility of representing them with deep contextualised embeddings, showing improvements on modelling spoken language and two downstream tasks -predicting a speaker's stance and expressed confidence.","importance filler text representation speech transcript essential component speak language , filler ( e.g. "" um "" "" uh "" ) remain overlooked spoken language understanding ( slu ) task . explore possibility represent deep contextualised embedding , show improvement model speak language downstream task -predicte speaker stance express confidence .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Speech and Multimodality,The role of context in neural pitch accent detection in English,"Prosody is a rich information source in natural language, serving as a marker for phenomena such as contrast. In order to make this information available to downstream tasks, we need a way to detect prosodic events in speech. We propose a new model for pitch accent detection, inspired by the work of Stehwien et al.  (2018), who presented a CNN-based model for this task. Our model makes greater use of context by using full utterances as input and adding an LSTM layer. We find that these innovations lead to an improvement from 87.5 percent to 88.7 percent accuracy on pitch accent detection on American English speech in the Boston University Radio News Corpus, a state-of-the-art result. We also find that a simple baseline that just predicts a pitch accent on every content word yields 82.2 percent accuracy, and we suggest that this is the appropriate baseline for this task. Finally, we conduct ablation tests that show pitch is the most important acoustic feature for this task and this corpus.","The role of context in neural pitch accent detection in English Prosody is a rich information source in natural language, serving as a marker for phenomena such as contrast. In order to make this information available to downstream tasks, we need a way to detect prosodic events in speech. We propose a new model for pitch accent detection, inspired by the work of Stehwien et al.  (2018), who presented a CNN-based model for this task. Our model makes greater use of context by using full utterances as input and adding an LSTM layer. We find that these innovations lead to an improvement from 87.5 percent to 88.7 percent accuracy on pitch accent detection on American English speech in the Boston University Radio News Corpus, a state-of-the-art result. We also find that a simple baseline that just predicts a pitch accent on every content word yields 82.2 percent accuracy, and we suggest that this is the appropriate baseline for this task. Finally, we conduct ablation tests that show pitch is the most important acoustic feature for this task and this corpus.","role context neural pitch accent detection english prosody rich information source natural language , serve marker phenomenon contrast . order information available downstream task , need way detect prosodic event speech . propose new model pitch accent detection , inspire work stehwien et al .   ( 2018 ) , present cnn - base model task . model make great use context utterance input add lstm layer . find innovation lead improvement 87.5 percent 88.7 percent accuracy pitch accent detection american english speech boston university radio news corpus , state - - - art result . find simple baseline predict pitch accent content word yield 82.2 percent accuracy , suggest appropriate baseline task . finally , conduct ablation test pitch important acoustic feature task corpus .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Unsupervised Natural Language Inference via Decoupled Multimodal Contrastive Learning,"We propose to solve the natural language inference problem without any supervision from the inference labels via task-agnostic multimodal pretraining. Although recent studies of multimodal self-supervised learning also represent the linguistic and visual context, their encoders for different modalities are coupled. Thus they cannot incorporate visual information when encoding plain text alone. In this paper, we propose Multimodal Aligned Contrastive Decoupled learning (MACD) network. MACD forces the decoupled text encoder to represent the visual information via contrastive learning. Therefore, it embeds visual knowledge even for plain text inference. We conducted comprehensive experiments over plain text inference datasets (i.e. SNLI and STS-B). The unsupervised MACD even outperforms the fully-supervised BiLST-M and BiLSTM+ELMO on STS-B.","Unsupervised Natural Language Inference via Decoupled Multimodal Contrastive Learning We propose to solve the natural language inference problem without any supervision from the inference labels via task-agnostic multimodal pretraining. Although recent studies of multimodal self-supervised learning also represent the linguistic and visual context, their encoders for different modalities are coupled. Thus they cannot incorporate visual information when encoding plain text alone. In this paper, we propose Multimodal Aligned Contrastive Decoupled learning (MACD) network. MACD forces the decoupled text encoder to represent the visual information via contrastive learning. Therefore, it embeds visual knowledge even for plain text inference. We conducted comprehensive experiments over plain text inference datasets (i.e. SNLI and STS-B). The unsupervised MACD even outperforms the fully-supervised BiLST-M and BiLSTM+ELMO on STS-B.","unsupervised natural language inference decouple multimodal contrastive learning propose solve natural language inference problem supervision inference label task - agnostic multimodal pretraining . recent study multimodal self - supervise learning represent linguistic visual context , encoder different modality couple . incorporate visual information encode plain text . paper , propose multimodal aligned contrastive decoupled learning ( macd ) network . macd force decouple text encoder represent visual information contrastive learning . , embed visual knowledge plain text inference . conduct comprehensive experiment plain text inference dataset ( i.e. snli sts - b ) . unsupervised macd outperform fully - supervise bilst - m bilstm+elmo sts - b.","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Speech and Multimodality,VolTAGE: Volatility Forecasting via Text Audio Fusion with Graph Convolution Networks for Earnings Calls,"Natural language processing has recently made stock movement forecasting and volatility forecasting advances, leading to improved financial forecasting. Transcripts of companies' earnings calls are well studied for risk modeling, offering unique investment insight into stock performance. However, vocal cues in the speech of company executives present an underexplored rich source of natural language data for estimating financial risk. Additionally, most existing approaches ignore the correlations between stocks. Building on existing work, we introduce a neural model for stock volatility prediction that accounts for stock interdependence via graph convolutions while fusing verbal, vocal, and financial features in a semi-supervised multi-task risk forecasting formulation. Our proposed model, VolTAGE, outperforms existing methods demonstrating the effectiveness of multimodal learning for volatility prediction.","VolTAGE: Volatility Forecasting via Text Audio Fusion with Graph Convolution Networks for Earnings Calls Natural language processing has recently made stock movement forecasting and volatility forecasting advances, leading to improved financial forecasting. Transcripts of companies' earnings calls are well studied for risk modeling, offering unique investment insight into stock performance. However, vocal cues in the speech of company executives present an underexplored rich source of natural language data for estimating financial risk. Additionally, most existing approaches ignore the correlations between stocks. Building on existing work, we introduce a neural model for stock volatility prediction that accounts for stock interdependence via graph convolutions while fusing verbal, vocal, and financial features in a semi-supervised multi-task risk forecasting formulation. Our proposed model, VolTAGE, outperforms existing methods demonstrating the effectiveness of multimodal learning for volatility prediction.","voltage : volatility forecasting text audio fusion graph convolution networks earning calls natural language processing recently stock movement forecasting volatility forecasting advance , lead improve financial forecasting . transcript company ' earning call study risk modeling , offer unique investment insight stock performance . , vocal cue speech company executive present underexplored rich source natural language datum estimate financial risk . additionally , exist approach ignore correlation stock . build exist work , introduce neural model stock volatility prediction account stock interdependence graph convolution fuse verbal , vocal , financial feature semi - supervised multi - task risk forecasting formulation . propose model , voltage , outperform exist method demonstrate effectiveness multimodal learning volatility prediction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Speech and Multimodality,Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection,"Most existing approaches to disfluency detection heavily rely on human-annotated corpora, which is expensive to obtain in practice. There have been several proposals to alleviate this issue with, for instance, self-supervised learning techniques, but they still require humanannotated corpora. In this work, we explore the unsupervised learning paradigm which can potentially work with unlabeled text corpora that are cheaper and easier to obtain. Our model builds upon the recent work on Noisy Student Training, a semi-supervised learning approach that extends the idea of self-training. Experimental results on the commonly used English Switchboard test set show that our approach achieves competitive performance compared to the previous state-of-the-art supervised systems using contextualized word embeddings (e.g. BERT and ELECTRA).","Combining Self-Training and Self-Supervised Learning for Unsupervised Disfluency Detection Most existing approaches to disfluency detection heavily rely on human-annotated corpora, which is expensive to obtain in practice. There have been several proposals to alleviate this issue with, for instance, self-supervised learning techniques, but they still require humanannotated corpora. In this work, we explore the unsupervised learning paradigm which can potentially work with unlabeled text corpora that are cheaper and easier to obtain. Our model builds upon the recent work on Noisy Student Training, a semi-supervised learning approach that extends the idea of self-training. Experimental results on the commonly used English Switchboard test set show that our approach achieves competitive performance compared to the previous state-of-the-art supervised systems using contextualized word embeddings (e.g. BERT and ELECTRA).","combine self - training self - supervised learning unsupervised disfluency detection exist approach disfluency detection heavily rely human - annotate corpora , expensive obtain practice . proposal alleviate issue , instance , self - supervised learning technique , require humanannotated corpora . work , explore unsupervised learning paradigm potentially work unlabeled text corpus cheap easy obtain . model build recent work noisy student training , semi - supervised learning approach extend idea self - training . experimental result commonly english switchboard test set approach achieve competitive performance compare previous state - - - art supervise system contextualize word embedding ( e.g. bert electra ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Speech and Multimodality,Effectively pretraining a speech translation decoder with Machine Translation data,"Directly translating from speech to text using an end-to-end approach is still challenging for many language pairs due to insufficient data. Although pretraining the encoder parameters using the Automatic Speech Recognition (ASR) task improves the results in low resource settings, attempting to use pretrained parameters from the Neural Machine Translation (NMT) task has been largely unsuccessful in previous works. In this paper, we will show that by using an adversarial regularizer, we can bring the encoder representations of the ASR and NMT tasks closer even though they are in different modalities, and how this helps us effectively use a pretrained NMT decoder for speech translation.","Effectively pretraining a speech translation decoder with Machine Translation data Directly translating from speech to text using an end-to-end approach is still challenging for many language pairs due to insufficient data. Although pretraining the encoder parameters using the Automatic Speech Recognition (ASR) task improves the results in low resource settings, attempting to use pretrained parameters from the Neural Machine Translation (NMT) task has been largely unsuccessful in previous works. In this paper, we will show that by using an adversarial regularizer, we can bring the encoder representations of the ASR and NMT tasks closer even though they are in different modalities, and how this helps us effectively use a pretrained NMT decoder for speech translation.","effectively pretraine speech translation decoder machine translation datum directly translate speech text end - - end approach challenging language pair insufficient datum . pretraine encoder parameter automatic speech recognition ( asr ) task improve result low resource setting , attempt use pretrained parameter neural machine translation ( nmt ) task largely unsuccessful previous work . paper , adversarial regularizer , bring encoder representation asr nmt task close different modality , help effectively use pretrained nmt decoder speech translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 11, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Summarization,TESA: A Task in Entity Semantic Aggregation for Abstractive Summarization,"Human-written texts contain frequent generalizations and semantic aggregation of content. In a document, they may refer to a pair of named entities such as 'London' and 'Paris' with different expressions: ""the major cities"", ""the capital cities"" and ""two European cities"". Yet generation, especially, abstractive summarization systems have so far focused heavily on paraphrasing and simplifying the source content, to the exclusion of such semantic abstraction capabilities. In this paper, we present a new dataset and task aimed at the semantic aggregation of entities. TESA contains a dataset of 5.3K crowd-sourced entity aggregations of PERSON, ORGANIZATION, and LO-CATION named entities. 1 The aggregations are document-appropriate, meaning that they are produced by annotators to match the situational context of a given news article from the New York Times. We then build baseline models for generating aggregations given a tuple of entities and document context. We finetune on TESA an encoder-decoder language model and compare it with simpler classification methods based on linguistically informed features. Our quantitative and qualitative evaluations show reasonable performance in making a choice from a given list of expressions, but free-form expressions are understandably harder to generate and evaluate.","TESA: A Task in Entity Semantic Aggregation for Abstractive Summarization Human-written texts contain frequent generalizations and semantic aggregation of content. In a document, they may refer to a pair of named entities such as 'London' and 'Paris' with different expressions: ""the major cities"", ""the capital cities"" and ""two European cities"". Yet generation, especially, abstractive summarization systems have so far focused heavily on paraphrasing and simplifying the source content, to the exclusion of such semantic abstraction capabilities. In this paper, we present a new dataset and task aimed at the semantic aggregation of entities. TESA contains a dataset of 5.3K crowd-sourced entity aggregations of PERSON, ORGANIZATION, and LO-CATION named entities. 1 The aggregations are document-appropriate, meaning that they are produced by annotators to match the situational context of a given news article from the New York Times. We then build baseline models for generating aggregations given a tuple of entities and document context. We finetune on TESA an encoder-decoder language model and compare it with simpler classification methods based on linguistically informed features. Our quantitative and qualitative evaluations show reasonable performance in making a choice from a given list of expressions, but free-form expressions are understandably harder to generate and evaluate.","tesa : task entity semantic aggregation abstractive summarization human - write text contain frequent generalization semantic aggregation content . document , refer pair name entity ' london ' ' paris ' different expression : "" major city "" , "" capital city "" "" european city "" . generation , especially , abstractive summarization system far focus heavily paraphrase simplify source content , exclusion semantic abstraction capability . paper , present new dataset task aim semantic aggregation entity . tesa contain dataset 5.3 k crowd - source entity aggregation person , organization , lo - cation name entity . 1 aggregation document - appropriate , mean produce annotator match situational context give news article new york times . build baseline model generate aggregation give tuple entity document context . finetune tesa encoder - decoder language model compare simple classification method base linguistically inform feature . quantitative qualitative evaluation reasonable performance make choice give list expression , free - form expression understandably hard generate evaluate .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Summarization,Pre-training for Abstractive Document Summarization by Reinstating Source Text,"Abstractive document summarization is usually modeled as a sequence-to-sequence (SEQ2SEQ) learning problem. Unfortunately, training large SEQ2SEQ based summarization models on limited supervised summarization data is challenging. This paper presents three sequence-to-sequence pre-training (in shorthand, STEP) objectives which allow us to pre-train a SEQ2SEQ based abstractive summarization model on unlabeled text. The main idea is that, given an input text artificially constructed from a document, a model is pre-trained to reinstate the original document. These objectives include sentence reordering, next sentence generation and masked document generation, which have close relations with the abstractive document summarization task. Experiments on two benchmark summarization datasets (i.e., CNN/DailyMail and New York Times) show that all three objectives can improve performance upon baselines. Compared to models pre-trained on large-scale data (≥160GB), our method, with only 19GB text for pre-training, achieves comparable results, which demonstrates its effectiveness. Code and models are public available at https://github.com/ zoezou2015/abs_pretraining.","Pre-training for Abstractive Document Summarization by Reinstating Source Text Abstractive document summarization is usually modeled as a sequence-to-sequence (SEQ2SEQ) learning problem. Unfortunately, training large SEQ2SEQ based summarization models on limited supervised summarization data is challenging. This paper presents three sequence-to-sequence pre-training (in shorthand, STEP) objectives which allow us to pre-train a SEQ2SEQ based abstractive summarization model on unlabeled text. The main idea is that, given an input text artificially constructed from a document, a model is pre-trained to reinstate the original document. These objectives include sentence reordering, next sentence generation and masked document generation, which have close relations with the abstractive document summarization task. Experiments on two benchmark summarization datasets (i.e., CNN/DailyMail and New York Times) show that all three objectives can improve performance upon baselines. Compared to models pre-trained on large-scale data (≥160GB), our method, with only 19GB text for pre-training, achieves comparable results, which demonstrates its effectiveness. Code and models are public available at https://github.com/ zoezou2015/abs_pretraining.","pre - training abstractive document summarization reinstate source text abstractive document summarization usually model sequence - - sequence ( seq2seq ) learning problem . unfortunately , train large seq2seq base summarization model limited supervise summarization datum challenging . paper present sequence - - sequence pre - training ( shorthand , step ) objective allow pre - train seq2seq base abstractive summarization model unlabeled text . main idea , give input text artificially construct document , model pre - train reinstate original document . objective include sentence reordering , sentence generation mask document generation , close relation abstractive document summarization task . experiment benchmark summarization dataset ( i.e. , cnn / dailymail new york times ) objective improve performance baseline . compare model pre - train large - scale datum ( ≥160 gb ) , method , 19 gb text pre - training , achieve comparable result , demonstrate effectiveness . code model public available https://github.com/ zoezou2015 / abs_pretraining .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 18, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Multi-hop Inference for Question-driven Summarization,"Question-driven summarization has been recently studied as an effective approach to summarizing the source document to produce concise but informative answers for nonfactoid questions. In this work, we propose a novel question-driven abstractive summarization method, Multi-hop Selective Generator (MSG), to incorporate multi-hop reasoning into question-driven summarization and, meanwhile, provide justifications for the generated summaries. Specifically, we jointly model the relevance to the question and the interrelation among different sentences via a human-like multi-hop inference module, which captures important sentences for justifying the summarized answer. A gated selective pointer generator network with a multi-view coverage mechanism is designed to integrate diverse information from different perspectives. Experimental results show that the proposed method consistently outperforms stateof-the-art methods on two non-factoid QA datasets, namely WikiHow and PubMedQA.","Multi-hop Inference for Question-driven Summarization Question-driven summarization has been recently studied as an effective approach to summarizing the source document to produce concise but informative answers for nonfactoid questions. In this work, we propose a novel question-driven abstractive summarization method, Multi-hop Selective Generator (MSG), to incorporate multi-hop reasoning into question-driven summarization and, meanwhile, provide justifications for the generated summaries. Specifically, we jointly model the relevance to the question and the interrelation among different sentences via a human-like multi-hop inference module, which captures important sentences for justifying the summarized answer. A gated selective pointer generator network with a multi-view coverage mechanism is designed to integrate diverse information from different perspectives. Experimental results show that the proposed method consistently outperforms stateof-the-art methods on two non-factoid QA datasets, namely WikiHow and PubMedQA.","multi - hop inference question - drive summarization question - drive summarization recently study effective approach summarize source document produce concise informative answer nonfactoid question . work , propose novel question - drive abstractive summarization method , multi - hop selective generator ( msg ) , incorporate multi - hop reasoning question - drive summarization , , provide justification generate summary . specifically , jointly model relevance question interrelation different sentence human - like multi - hop inference module , capture important sentence justify summarize answer . gate selective pointer generator network multi - view coverage mechanism design integrate diverse information different perspective . experimental result propose method consistently outperform stateof - - art method non - factoid qa dataset , wikihow pubmedqa .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 10, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Summarization,Re-evaluating Evaluation in Text Summarization,"Automated evaluation metrics as a stand-in for manual evaluation are an essential part of the development of text-generation tasks such as text summarization. However, while the field has progressed, our standard metrics have not -for nearly 20 years ROUGE has been the standard evaluation in most summarization papers. In this paper, we make an attempt to re-evaluate the evaluation method for text summarization: assessing the reliability of automatic metrics using top-scoring system outputs, both abstractive and extractive, on recently popular datasets for both systemlevel and summary-level evaluation settings. We find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems. We release a dataset of human judgments that are collected from 25 top-scoring neural summarization systems (14 abstractive and 11 extractive): https://github.com/neulab/REALSumm","Re-evaluating Evaluation in Text Summarization Automated evaluation metrics as a stand-in for manual evaluation are an essential part of the development of text-generation tasks such as text summarization. However, while the field has progressed, our standard metrics have not -for nearly 20 years ROUGE has been the standard evaluation in most summarization papers. In this paper, we make an attempt to re-evaluate the evaluation method for text summarization: assessing the reliability of automatic metrics using top-scoring system outputs, both abstractive and extractive, on recently popular datasets for both systemlevel and summary-level evaluation settings. We find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems. We release a dataset of human judgments that are collected from 25 top-scoring neural summarization systems (14 abstractive and 11 extractive): https://github.com/neulab/REALSumm","- evaluate evaluation text summarization automate evaluation metric stand - manual evaluation essential development text - generation task text summarization . , field progress , standard metric -for nearly 20 year rouge standard evaluation summarization paper . paper , attempt - evaluate evaluation method text summarization : assess reliability automatic metric - score system output , abstractive extractive , recently popular dataset systemlevel summary - level evaluation setting . find conclusion evaluation metric old dataset necessarily hold modern dataset system . release dataset human judgment collect 25 - score neural summarization system ( 14 abstractive 11 extractive ): https://github.com/neulab/realsumm","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 11, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 10, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Summarization,Intrinsic Evaluation of Summarization Datasets,"High quality data forms the bedrock for building meaningful statistical models in NLP. Consequently, data quality must be evaluated either during dataset construction or post hoc. Almost all popular summarization datasets are drawn from natural sources and do not come with inherent quality assurance guarantees. In spite of this, data quality has gone largely unquestioned for many recent summarization datasets. We perform the first large-scale evaluation of summarization datasets by introducing 5 intrinsic metrics and applying them to 10 popular datasets. We find that data usage in recent summarization research is sometimes inconsistent with the underlying properties of the datasets employed. Further, we discover that our metrics can serve the additional purpose of being inexpensive heuristics for detecting generically low quality examples.","Intrinsic Evaluation of Summarization Datasets High quality data forms the bedrock for building meaningful statistical models in NLP. Consequently, data quality must be evaluated either during dataset construction or post hoc. Almost all popular summarization datasets are drawn from natural sources and do not come with inherent quality assurance guarantees. In spite of this, data quality has gone largely unquestioned for many recent summarization datasets. We perform the first large-scale evaluation of summarization datasets by introducing 5 intrinsic metrics and applying them to 10 popular datasets. We find that data usage in recent summarization research is sometimes inconsistent with the underlying properties of the datasets employed. Further, we discover that our metrics can serve the additional purpose of being inexpensive heuristics for detecting generically low quality examples.","intrinsic evaluation summarization dataset high quality data form bedrock build meaningful statistical model nlp . consequently , data quality evaluate dataset construction post hoc . popular summarization dataset draw natural source come inherent quality assurance guarantee . spite , data quality go largely unquestioned recent summarization dataset . perform large - scale evaluation summarization dataset introduce 5 intrinsic metric apply 10 popular dataset . find datum usage recent summarization research inconsistent underlie property dataset employ . , discover metric serve additional purpose inexpensive heuristic detect generically low quality example .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Summarization,Neural Extractive Summarization with Hierarchical Attentive Heterogeneous Graph Network,"Sentence-level extractive text summarization is substantially a node classification task of network mining, adhering to the informative components and concise representations. There are lots of redundant phrases between extracted sentences, but it is difficult to model them exactly by the general supervised methods. Previous sentence encoders, especially BERT, specialize in modeling the relationship between source sentences. While, they have no ability to consider the overlaps of the target selected summary, and there are inherent dependencies among target labels of sentences. In this paper, we propose HAHSum (as shorthand for Hierarchical Attentive Heterogeneous Graph for Text Summarization), which well models different levels of information, including words and sentences, and spotlights redundancy dependencies between sentences. Our approach iteratively refines the sentence representations with redundancy-aware graph and delivers the label dependencies by message passing. Experiments on large scale benchmark corpus (CNN/DM, NYT, and NEWSROOM) demonstrate that HAHSum yields ground-breaking performance and outperforms previous extractive summarizers.","Neural Extractive Summarization with Hierarchical Attentive Heterogeneous Graph Network Sentence-level extractive text summarization is substantially a node classification task of network mining, adhering to the informative components and concise representations. There are lots of redundant phrases between extracted sentences, but it is difficult to model them exactly by the general supervised methods. Previous sentence encoders, especially BERT, specialize in modeling the relationship between source sentences. While, they have no ability to consider the overlaps of the target selected summary, and there are inherent dependencies among target labels of sentences. In this paper, we propose HAHSum (as shorthand for Hierarchical Attentive Heterogeneous Graph for Text Summarization), which well models different levels of information, including words and sentences, and spotlights redundancy dependencies between sentences. Our approach iteratively refines the sentence representations with redundancy-aware graph and delivers the label dependencies by message passing. Experiments on large scale benchmark corpus (CNN/DM, NYT, and NEWSROOM) demonstrate that HAHSum yields ground-breaking performance and outperforms previous extractive summarizers.","neural extractive summarization hierarchical attentive heterogeneous graph network sentence - level extractive text summarization substantially node classification task network mining , adhere informative component concise representation . lot redundant phrase extract sentence , difficult model exactly general supervise method . previous sentence encoder , especially bert , specialize model relationship source sentence . , ability consider overlap target select summary , inherent dependency target label sentence . paper , propose hahsum ( shorthand hierarchical attentive heterogeneous graph text summarization ) , model different level information , include word sentence , spotlight redundancy dependency sentence . approach iteratively refine sentence representation redundancy - aware graph deliver label dependency message passing . experiment large scale benchmark corpus ( cnn / dm , nyt , newsroom ) demonstrate hahsum yield ground - break performance outperform previous extractive summarizer .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,"Diverse, Controllable, and Keyphrase-Aware: A Corpus and Method for News Multi-Headline Generation","News headline generation aims to produce a short sentence to attract readers to read the news. One news article often contains multiple keyphrases that are of interest to different users, which can naturally have multiple reasonable headlines. However, most existing methods focus on the single headline generation. In this paper, we propose generating multiple headlines with keyphrases of user interests, whose main idea is to generate multiple keyphrases of interest to users for the news first, and then generate multiple keyphrase-relevant headlines. We propose a multi-source Transformer decoder, which takes three sources as inputs: (a) keyphrase, (b) keyphrase-filtered article, and (c) original article to generate keyphrase-relevant, highquality, and diverse headlines. Furthermore, we propose a simple and effective method to mine the keyphrases of interest in the news article and build a first large-scale keyphraseaware news headline corpus, which contains over 180K aligned triples of news article, headline, keyphrase . Extensive experimental comparisons on the real-world dataset show that the proposed method achieves state-of-theart results in terms of quality and diversity 1 .","Diverse, Controllable, and Keyphrase-Aware: A Corpus and Method for News Multi-Headline Generation News headline generation aims to produce a short sentence to attract readers to read the news. One news article often contains multiple keyphrases that are of interest to different users, which can naturally have multiple reasonable headlines. However, most existing methods focus on the single headline generation. In this paper, we propose generating multiple headlines with keyphrases of user interests, whose main idea is to generate multiple keyphrases of interest to users for the news first, and then generate multiple keyphrase-relevant headlines. We propose a multi-source Transformer decoder, which takes three sources as inputs: (a) keyphrase, (b) keyphrase-filtered article, and (c) original article to generate keyphrase-relevant, highquality, and diverse headlines. Furthermore, we propose a simple and effective method to mine the keyphrases of interest in the news article and build a first large-scale keyphraseaware news headline corpus, which contains over 180K aligned triples of news article, headline, keyphrase . Extensive experimental comparisons on the real-world dataset show that the proposed method achieves state-of-theart results in terms of quality and diversity 1 .","diverse , controllable , keyphrase - aware : corpus method news multi - headline generation news headline generation aim produce short sentence attract reader read news . news article contain multiple keyphrase interest different user , naturally multiple reasonable headline . , exist method focus single headline generation . paper , propose generate multiple headline keyphrase user interest , main idea generate multiple keyphrase interest user news , generate multiple keyphrase - relevant headline . propose multi - source transformer decoder , take source input : ( ) keyphrase , ( b ) keyphrase - filter article , ( c ) original article generate keyphrase - relevant , highquality , diverse headline . furthermore , propose simple effective method keyphrase interest news article build large - scale keyphraseaware news headline corpus , contain 180 k align triple news article , headline , keyphrase . extensive experimental comparison real - world dataset propose method achieve state - - theart result term quality diversity 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 11, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 12, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Summarization,Better Highlighting: Creating Sub-Sentence Summary Highlights,"Amongst the best means to summarize is highlighting. In this paper, we aim to generate summary highlights to be overlaid on the original documents to make it easier for readers to sift through a large amount of text. The method allows summaries to be understood in context to prevent a summarizer from distorting the original meaning, of which abstractive summarizers usually fall short. In particular, we present a new method to produce self-contained highlights that are understandable on their own to avoid confusion. Our method combines determinantal point processes and deep contextualized representations to identify an optimal set of sub-sentence segments that are both important and non-redundant to form summary highlights. To demonstrate the flexibility and modeling power of our method, we conduct extensive experiments on summarization datasets. Our analysis provides evidence that highlighting is a promising avenue of research towards future summarization.","Better Highlighting: Creating Sub-Sentence Summary Highlights Amongst the best means to summarize is highlighting. In this paper, we aim to generate summary highlights to be overlaid on the original documents to make it easier for readers to sift through a large amount of text. The method allows summaries to be understood in context to prevent a summarizer from distorting the original meaning, of which abstractive summarizers usually fall short. In particular, we present a new method to produce self-contained highlights that are understandable on their own to avoid confusion. Our method combines determinantal point processes and deep contextualized representations to identify an optimal set of sub-sentence segments that are both important and non-redundant to form summary highlights. To demonstrate the flexibility and modeling power of our method, we conduct extensive experiments on summarization datasets. Our analysis provides evidence that highlighting is a promising avenue of research towards future summarization.","well highlighting : create sub - sentence summary highlight good mean summarize highlighting . paper , aim generate summary highlight overlay original document easy reader sift large text . method allow summary understand context prevent summarizer distort original meaning , abstractive summarizer usually fall short . particular , present new method produce self - contain highlight understandable avoid confusion . method combine determinantal point process deep contextualize representation identify optimal set sub - sentence segment important non - redundant form summary highlight . demonstrate flexibility modeling power method , conduct extensive experiment summarization dataset . analysis provide evidence highlight promising avenue research future summarization .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Understanding Neural Abstractive Summarization Models via Uncertainty,"An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this flexibility makes it difficult to interpret model behavior. In this work, we analyze summarization decoders in both blackbox and whitebox ways by studying on the entropy, or uncertainty, of the model's token-level predictions. For two strong pretrained models, PEGASUS (Zhang et al., 2020) and BART (Lewis et al., 2020)  on two summarization datasets, we find a strong correlation between low prediction entropy and where the model copies tokens rather than generating novel text. The decoder's uncertainty also connects to factors like sentence position and syntactic distance between adjacent pairs of tokens, giving a sense of what factors make a context particularly selective for the model's next output token. Finally, we study the relationship of decoder uncertainty and attention behavior to understand how attention gives rise to these observed effects in the model. We show that uncertainty is a useful perspective for analyzing summarization and text generation models more broadly. 1","Understanding Neural Abstractive Summarization Models via Uncertainty An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this flexibility makes it difficult to interpret model behavior. In this work, we analyze summarization decoders in both blackbox and whitebox ways by studying on the entropy, or uncertainty, of the model's token-level predictions. For two strong pretrained models, PEGASUS (Zhang et al., 2020) and BART (Lewis et al., 2020)  on two summarization datasets, we find a strong correlation between low prediction entropy and where the model copies tokens rather than generating novel text. The decoder's uncertainty also connects to factors like sentence position and syntactic distance between adjacent pairs of tokens, giving a sense of what factors make a context particularly selective for the model's next output token. Finally, we study the relationship of decoder uncertainty and attention behavior to understand how attention gives rise to these observed effects in the model. We show that uncertainty is a useful perspective for analyzing summarization and text generation models more broadly. 1","understand neural abstractive summarization model uncertainty advantage seq2seq abstractive summarization model generate text free - form manner , flexibility make difficult interpret model behavior . work , analyze summarization decoder blackbox whitebox way study entropy , uncertainty , model token - level prediction . strong pretrained model , pegasus ( zhang et al . , 2020 ) bart ( lewis et al . , 2020 )   summarization dataset , find strong correlation low prediction entropy model copy token generate novel text . decoder uncertainty connect factor like sentence position syntactic distance adjacent pair token , give sense factor context particularly selective model output token . finally , study relationship decoder uncertainty attention behavior understand attention give rise observe effect model . uncertainty useful perspective analyze summarization text generation model broadly . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Factual Error Correction for Abstractive Summarization Models,"Neural abstractive summarization systems have achieved promising progress, thanks to the availability of large-scale datasets and models pre-trained with self-supervised methods. However, ensuring the factual consistency of the generated summaries for abstractive summarization systems is a challenge. We propose a post-editing corrector module to address this issue by identifying and correcting factual errors in generated summaries. The neural corrector model is pre-trained on artificial examples that are created by applying a series of heuristic transformations on reference summaries. These transformations are inspired by an error analysis of state-of-the-art summarization model outputs. Experimental results show that our model is able to correct factual errors in summaries generated by other neural summarization models and outperforms previous models on factual consistency evaluation on the CNN/DailyMail dataset. We also find that transferring from artificial error correction to downstream settings is still very challenging 1 .","Factual Error Correction for Abstractive Summarization Models Neural abstractive summarization systems have achieved promising progress, thanks to the availability of large-scale datasets and models pre-trained with self-supervised methods. However, ensuring the factual consistency of the generated summaries for abstractive summarization systems is a challenge. We propose a post-editing corrector module to address this issue by identifying and correcting factual errors in generated summaries. The neural corrector model is pre-trained on artificial examples that are created by applying a series of heuristic transformations on reference summaries. These transformations are inspired by an error analysis of state-of-the-art summarization model outputs. Experimental results show that our model is able to correct factual errors in summaries generated by other neural summarization models and outperforms previous models on factual consistency evaluation on the CNN/DailyMail dataset. We also find that transferring from artificial error correction to downstream settings is still very challenging 1 .","factual error correction abstractive summarization model neural abstractive summarization system achieve promising progress , thank availability large - scale dataset model pre - train self - supervise method . , ensure factual consistency generate summary abstractive summarization system challenge . propose post - editing corrector module address issue identify correct factual error generate summary . neural corrector model pre - train artificial example create apply series heuristic transformation reference summary . transformation inspire error analysis state - - - art summarization model output . experimental result model able correct factual error summary generate neural summarization model outperform previous model factual consistency evaluation cnn / dailymail dataset . find transfer artificial error correction downstream setting challenging 1 .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 22, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,MLSUM: The Multilingual Summarization Corpus,"We present MLSUM, the first large-scale Mul-tiLingual SUMmarization dataset. Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -namely, French, German, Spanish, Russian, Turkish. Together with English news articles from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community. We report cross-lingual comparative analyses based on state-of-the-art systems. These highlight existing biases which motivate the use of a multi-lingual dataset.","MLSUM: The Multilingual Summarization Corpus We present MLSUM, the first large-scale Mul-tiLingual SUMmarization dataset. Obtained from online newspapers, it contains 1.5M+ article/summary pairs in five different languages -namely, French, German, Spanish, Russian, Turkish. Together with English news articles from the popular CNN/Daily mail dataset, the collected data form a large scale multilingual dataset which can enable new research directions for the text summarization community. We report cross-lingual comparative analyses based on state-of-the-art systems. These highlight existing biases which motivate the use of a multi-lingual dataset.","mlsum : multilingual summarization corpus present mlsum , large - scale mul - tilingual summarization dataset . obtain online newspaper , contain 1.5m+ article / summary pair different language -namely , french , german , spanish , russian , turkish . english news article popular cnn / daily mail dataset , collect datum form large scale multilingual dataset enable new research direction text summarization community . report cross - lingual comparative analysis base state - - - art system . highlight exist bias motivate use multi - lingual dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Summarization,Few-Shot Learning for Opinion Summarization,"Opinion summarization is the automatic creation of text reflecting subjective information expressed in multiple documents, such as user reviews of a product. The task is practically important and has attracted a lot of attention. However, due to the high cost of summary production, datasets large enough for training supervised models are lacking. Instead, the task has been traditionally approached with extractive methods that learn to select text fragments in an unsupervised or weakly-supervised way. Recently, it has been shown that abstractive summaries, potentially more fluent and better at reflecting conflicting information, can also be produced in an unsupervised fashion. However, these models, not being exposed to actual summaries, fail to capture their essential properties. In this work, we show that even a handful of summaries is sufficient to bootstrap generation of the summary text with all expected properties, such as writing style, informativeness, fluency, and sentiment preservation. We start by training a conditional Transformer language model to generate a new product review given other available reviews of the product. The model is also conditioned on review properties that are directly related to summaries; the properties are derived from reviews with no manual effort. In the second stage, we fine-tune a plug-in module that learns to predict property values on a handful of summaries. This lets us switch the generator to the summarization mode. We show on Amazon and Yelp datasets that our approach substantially outperforms previous extractive and abstractive methods in automatic and human evaluation.","Few-Shot Learning for Opinion Summarization Opinion summarization is the automatic creation of text reflecting subjective information expressed in multiple documents, such as user reviews of a product. The task is practically important and has attracted a lot of attention. However, due to the high cost of summary production, datasets large enough for training supervised models are lacking. Instead, the task has been traditionally approached with extractive methods that learn to select text fragments in an unsupervised or weakly-supervised way. Recently, it has been shown that abstractive summaries, potentially more fluent and better at reflecting conflicting information, can also be produced in an unsupervised fashion. However, these models, not being exposed to actual summaries, fail to capture their essential properties. In this work, we show that even a handful of summaries is sufficient to bootstrap generation of the summary text with all expected properties, such as writing style, informativeness, fluency, and sentiment preservation. We start by training a conditional Transformer language model to generate a new product review given other available reviews of the product. The model is also conditioned on review properties that are directly related to summaries; the properties are derived from reviews with no manual effort. In the second stage, we fine-tune a plug-in module that learns to predict property values on a handful of summaries. This lets us switch the generator to the summarization mode. We show on Amazon and Yelp datasets that our approach substantially outperforms previous extractive and abstractive methods in automatic and human evaluation.","- shot learning opinion summarization opinion summarization automatic creation text reflect subjective information express multiple document , user review product . task practically important attract lot attention . , high cost summary production , dataset large train supervise model lack . instead , task traditionally approach extractive method learn select text fragment unsupervised weakly - supervise way . recently , show abstractive summary , potentially fluent well reflect conflict information , produce unsupervised fashion . , model , expose actual summary , fail capture essential property . work , handful summary sufficient bootstrap generation summary text expected property , writing style , informativeness , fluency , sentiment preservation . start train conditional transformer language model generate new product review give available review product . model condition review property directly relate summary ; property derive review manual effort . second stage , fine - tune plug - module learn predict property value handful summary . let switch generator summarization mode . amazon yelp dataset approach substantially outperform previous extractive abstractive method automatic human evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 20, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,What Have We Achieved on Text Summarization?,"Deep learning has led to significant improvement in text summarization with various methods investigated and improved ROUGE scores reported over the years. However, gaps still exist between summaries produced by automatic summarizers and human professionals. Aiming to gain more understanding of summarization systems with respect to their strengths and limits on a fine-grained syntactic and semantic level, we consult the Multidimensional Quality Metric 1 (MQM) and quantify 8 major sources of errors on 10 representative summarization models manually. Primarily, we find that 1) under similar settings, extractive summarizers are in general better than their abstractive counterparts thanks to strength in faithfulness and factual-consistency; 2) milestone techniques such as copy, coverage and hybrid extractive/abstractive methods do bring specific improvements but also demonstrate limitations; 3) pre-training techniques, and in particular sequence-to-sequence pre-training, are highly effective for improving text summarization, with BART giving the best results. * Equal contribution. † Corresponding author. 1 MQM is a framework for declaring and describing human writing quality which stipulates a hierarchical listing of error types restricted to human writing and translation.","What Have We Achieved on Text Summarization? Deep learning has led to significant improvement in text summarization with various methods investigated and improved ROUGE scores reported over the years. However, gaps still exist between summaries produced by automatic summarizers and human professionals. Aiming to gain more understanding of summarization systems with respect to their strengths and limits on a fine-grained syntactic and semantic level, we consult the Multidimensional Quality Metric 1 (MQM) and quantify 8 major sources of errors on 10 representative summarization models manually. Primarily, we find that 1) under similar settings, extractive summarizers are in general better than their abstractive counterparts thanks to strength in faithfulness and factual-consistency; 2) milestone techniques such as copy, coverage and hybrid extractive/abstractive methods do bring specific improvements but also demonstrate limitations; 3) pre-training techniques, and in particular sequence-to-sequence pre-training, are highly effective for improving text summarization, with BART giving the best results. * Equal contribution. † Corresponding author. 1 MQM is a framework for declaring and describing human writing quality which stipulates a hierarchical listing of error types restricted to human writing and translation.","achieve text summarization ? deep learning lead significant improvement text summarization method investigate improve rouge score report year . , gap exist summary produce automatic summarizer human professional . aim gain understanding summarization system respect strength limit fine - grained syntactic semantic level , consult multidimensional quality metric 1 ( mqm ) quantify 8 major source error 10 representative summarization model manually . primarily , find 1 ) similar setting , extractive summarizer general well abstractive counterpart thank strength faithfulness factual - consistency ; 2 ) milestone technique copy , coverage hybrid extractive / abstractive method bring specific improvement demonstrate limitation ; 3 ) pre - training technique , particular sequence - - sequence pre - training , highly effective improve text summarization , bart give good result . * equal contribution . † correspond author . 1 mqm framework declare describe human writing quality stipulate hierarchical listing error type restrict human writing translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 11, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles,"A popular multimedia news format nowadays is providing users with a lively video and a corresponding news article, which is employed by influential news media including CNN, BBC, and social media including Twitter and Weibo. In such a case, automatically choosing a proper cover frame of the video and generating an appropriate textual summary of the article can help editors save time, and readers make the decision more effectively. Hence, in this paper, we propose the task of Videobased Multimodal Summarization with Multimodal Output (VMSMO) to tackle such a problem. The main challenge in this task is to jointly model the temporal dependency of video with semantic meaning of article. To this end, we propose a Dual-Interaction-based Multimodal Summarizer (DIMS), consisting of a dual interaction module and multimodal generator. In the dual interaction module, we propose a conditional self-attention mechanism that captures local semantic information within video and a global-attention mechanism that handles the semantic relationship between news text and video from a high level. Extensive experiments conducted on a large-scale real-world VMSMO dataset 1 show that DIMS achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations.","VMSMO: Learning to Generate Multimodal Summary for Video-based News Articles A popular multimedia news format nowadays is providing users with a lively video and a corresponding news article, which is employed by influential news media including CNN, BBC, and social media including Twitter and Weibo. In such a case, automatically choosing a proper cover frame of the video and generating an appropriate textual summary of the article can help editors save time, and readers make the decision more effectively. Hence, in this paper, we propose the task of Videobased Multimodal Summarization with Multimodal Output (VMSMO) to tackle such a problem. The main challenge in this task is to jointly model the temporal dependency of video with semantic meaning of article. To this end, we propose a Dual-Interaction-based Multimodal Summarizer (DIMS), consisting of a dual interaction module and multimodal generator. In the dual interaction module, we propose a conditional self-attention mechanism that captures local semantic information within video and a global-attention mechanism that handles the semantic relationship between news text and video from a high level. Extensive experiments conducted on a large-scale real-world VMSMO dataset 1 show that DIMS achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations.","vmsmo : learn generate multimodal summary video - base news article popular multimedia news format nowadays provide user lively video corresponding news article , employ influential news medium include cnn , bbc , social medium include twitter weibo . case , automatically choose proper cover frame video generate appropriate textual summary article help editor save time , reader decision effectively . , paper , propose task videobased multimodal summarization multimodal output ( vmsmo ) tackle problem . main challenge task jointly model temporal dependency video semantic meaning article . end , propose dual - interaction - base multimodal summarizer ( dims ) , consist dual interaction module multimodal generator . dual interaction module , propose conditional self - attention mechanism capture local semantic information video global - attention mechanism handle semantic relationship news text video high level . extensive experiment conduct large - scale real - world vmsmo dataset 1 dims achieve state - - - art performance term automatic metric human evaluation .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 5, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 10, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Summarization,On Extractive and Abstractive Neural Document Summarization with Transformer Language Models,"We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher ROUGE scores. We provide extensive comparisons with strong baseline methods, prior state of the art work as well as multiple variants of our approach including those using only transformers, only extractive techniques and combinations of the two. We examine these models using four different summarization tasks and datasets: arXiv papers, PubMed papers, the Newsroom and BigPatent datasets. We find that transformer based methods produce summaries with fewer n-gram copies, leading to n-gram copying statistics that are more similar to human generated abstracts. We include a human evaluation, finding that transformers are ranked highly for coherence and fluency, but purely extractive methods score higher for informativeness and relevance. We hope that these architectures and experiments may serve as strong points of comparison for future work.","On Extractive and Abstractive Neural Document Summarization with Transformer Language Models We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher ROUGE scores. We provide extensive comparisons with strong baseline methods, prior state of the art work as well as multiple variants of our approach including those using only transformers, only extractive techniques and combinations of the two. We examine these models using four different summarization tasks and datasets: arXiv papers, PubMed papers, the Newsroom and BigPatent datasets. We find that transformer based methods produce summaries with fewer n-gram copies, leading to n-gram copying statistics that are more similar to human generated abstracts. We include a human evaluation, finding that transformers are ranked highly for coherence and fluency, but purely extractive methods score higher for informativeness and relevance. We hope that these architectures and experiments may serve as strong points of comparison for future work.","extractive abstractive neural document summarization transformer language model present method produce abstractive summary long document exceed thousand word neural abstractive summarization . perform simple extractive step generate summary , condition transformer language model relevant information task generate summary . approach produce abstractive summary compare prior work employ copy mechanism achieve high rouge score . provide extensive comparison strong baseline method , prior state art work multiple variant approach include transformer , extractive technique combination . examine model different summarization task dataset : arxiv paper , pubmed paper , newsroom bigpatent dataset . find transformer base method produce summary few n - gram copy , lead n - gram copying statistic similar human generate abstract . include human evaluation , find transformer rank highly coherence fluency , purely extractive method score higher informativeness relevance . hope architecture experiment serve strong point comparison future work .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 21, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Learning to Fuse Sentences with Transformers for Summarization,"The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning. In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer's performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion.","Learning to Fuse Sentences with Transformers for Summarization The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning. In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer's performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion.","learn fuse sentence transformers summarization ability fuse sentence highly attractive summarization system essential step produce succinct abstract . , date , summarizer fail fuse sentence . tend produce summary sentence fusion generate incorrect fusion lead summary fail retain original meaning . paper , explore ability transformers fuse sentence propose novel algorithm enhance ability perform sentence fusion leverage knowledge point correspondence sentence . extensive experiment , investigate effect different design choice transformer performance . finding highlight importance model point correspondence sentence effective sentence fusion .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Summarization,Q-learning with Language Model for Edit-based Unsupervised Summarization,"Unsupervised methods are promising for abstractive textsummarization in that the parallel corpora is not required. However, their performance is still far from being satisfied, therefore research on promising solutions is on-going. In this paper, we propose a new approach based on Q-learning with an edit-based summarization. The method combines two key modules to form an Editorial Agent and Language Model converter (EALM). The agent predicts edit actions (e.t., delete, keep, and replace), and then the LM converter deterministically generates a summary on the basis of the action signals. Qlearning is leveraged to train the agent to produce proper edit actions. Experimental results show that EALM delivered competitive performance compared with the previous encoderdecoder-based methods, even with truly zero paired data (i.e., no validation set). Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. We also conduct qualitative analysis, providing insights into future study on unsupervised summarizers. 1","Q-learning with Language Model for Edit-based Unsupervised Summarization Unsupervised methods are promising for abstractive textsummarization in that the parallel corpora is not required. However, their performance is still far from being satisfied, therefore research on promising solutions is on-going. In this paper, we propose a new approach based on Q-learning with an edit-based summarization. The method combines two key modules to form an Editorial Agent and Language Model converter (EALM). The agent predicts edit actions (e.t., delete, keep, and replace), and then the LM converter deterministically generates a summary on the basis of the action signals. Qlearning is leveraged to train the agent to produce proper edit actions. Experimental results show that EALM delivered competitive performance compared with the previous encoderdecoder-based methods, even with truly zero paired data (i.e., no validation set). Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. We also conduct qualitative analysis, providing insights into future study on unsupervised summarizers. 1","q - learning language model edit - base unsupervised summarization unsupervised method promising abstractive textsummarization parallel corpora require . , performance far satisfy , research promising solution - go . paper , propose new approach base q - learning edit - base summarization . method combine key module form editorial agent language model converter ( ealm ) . agent predict edit action ( e.t . , delete , , replace ) , lm converter deterministically generate summary basis action signal . qlearning leverage train agent produce proper edit action . experimental result ealm deliver competitive performance compare previous encoderdecoder - base method , truly zero pair datum ( i.e. , validation set ) . define task q - learning enable develop competitive method late technique reinforcement learning available unsupervised summarization . conduct qualitative analysis , provide insight future study unsupervised summarizer . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Summarization,Compressive Summarization with Plausibility and Salience Modeling,"Compressive summarization systems typically rely on a crafted set of syntactic rules to determine what spans of possible summary sentences can be deleted, then learn a model of what to actually delete by optimizing for content selection (ROUGE). In this work, we propose to relax the rigid syntactic constraints on candidate spans and instead leave compression decisions to two data-driven criteria: plausibility and salience. Deleting a span is plausible if removing it maintains the grammaticality and factuality of a sentence, and spans are salient if they contain important information from the summary. Each of these is judged by a pre-trained Transformer model, and only deletions that are both plausible and not salient can be applied. When integrated into a simple extraction-compression pipeline, our method achieves strong in-domain results on benchmark summarization datasets, and human evaluation shows that the plausibility model generally selects for grammatical and factual deletions. Furthermore, the flexibility of our approach allows it to generalize cross-domain: our system fine-tuned on only 500 samples from a new domain can match or exceed an in-domain extractive model trained on much more data. 1","Compressive Summarization with Plausibility and Salience Modeling Compressive summarization systems typically rely on a crafted set of syntactic rules to determine what spans of possible summary sentences can be deleted, then learn a model of what to actually delete by optimizing for content selection (ROUGE). In this work, we propose to relax the rigid syntactic constraints on candidate spans and instead leave compression decisions to two data-driven criteria: plausibility and salience. Deleting a span is plausible if removing it maintains the grammaticality and factuality of a sentence, and spans are salient if they contain important information from the summary. Each of these is judged by a pre-trained Transformer model, and only deletions that are both plausible and not salient can be applied. When integrated into a simple extraction-compression pipeline, our method achieves strong in-domain results on benchmark summarization datasets, and human evaluation shows that the plausibility model generally selects for grammatical and factual deletions. Furthermore, the flexibility of our approach allows it to generalize cross-domain: our system fine-tuned on only 500 samples from a new domain can match or exceed an in-domain extractive model trained on much more data. 1","compressive summarization plausibility salience modeling compressive summarization system typically rely craft set syntactic rule determine span possible summary sentence delete , learn model actually delete optimize content selection ( rouge ) . work , propose relax rigid syntactic constraint candidate span instead leave compression decision data - drive criterion : plausibility salience . delete span plausible remove maintain grammaticality factuality sentence , span salient contain important information summary . judge pre - trained transformer model , deletion plausible salient apply . integrate simple extraction - compression pipeline , method achieve strong - domain result benchmark summarization dataset , human evaluation show plausibility model generally select grammatical factual deletion . furthermore , flexibility approach allow generalize cross - domain : system fine - tune 500 sample new domain match exceed - domain extractive model train datum . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization,"Text summarization is one of the most challenging and interesting problems in NLP. Although much attention has been paid to summarizing structured text like news reports or encyclopedia articles, summarizing conversations-an essential part of humanhuman/machine interaction where most important pieces of information are scattered across various utterances of different speakersremains relatively under-investigated. This work proposes a multi-view sequence-tosequence model by first extracting conversational structures of unstructured daily chats from different views to represent conversations and then utilizing a multi-view decoder to incorporate different views to generate dialogue summaries. Experiments on a large-scale dialogue summarization corpus demonstrated that our methods significantly outperformed previous state-of-the-art models via both automatic evaluations and human judgment. We also discussed specific challenges that current approaches faced with this task. We have publicly released our code at https://github.com/GT-SALT/ Multi-View-Seq2Seq.","Multi-View Sequence-to-Sequence Models with Conversational Structure for Abstractive Dialogue Summarization Text summarization is one of the most challenging and interesting problems in NLP. Although much attention has been paid to summarizing structured text like news reports or encyclopedia articles, summarizing conversations-an essential part of humanhuman/machine interaction where most important pieces of information are scattered across various utterances of different speakersremains relatively under-investigated. This work proposes a multi-view sequence-tosequence model by first extracting conversational structures of unstructured daily chats from different views to represent conversations and then utilizing a multi-view decoder to incorporate different views to generate dialogue summaries. Experiments on a large-scale dialogue summarization corpus demonstrated that our methods significantly outperformed previous state-of-the-art models via both automatic evaluations and human judgment. We also discussed specific challenges that current approaches faced with this task. We have publicly released our code at https://github.com/GT-SALT/ Multi-View-Seq2Seq.","multi - view sequence - - sequence model conversational structure abstractive dialogue summarization text summarization challenging interesting problem nlp . attention pay summarize structured text like news report encyclopedia article , summarize conversation - essential humanhuman / machine interaction important piece information scatter utterance different speakersremain relatively - investigate . work propose multi - view sequence - tosequence model extract conversational structure unstructured daily chat different view represent conversation utilize multi - view decoder incorporate different view generate dialogue summary . experiment large - scale dialogue summarization corpus demonstrate method significantly outperform previous state - - - art model automatic evaluation human judgment . discuss specific challenge current approach face task . publicly release code https://github.com/gt-salt/ multi - view - seq2seq .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Summarization,Evaluating the Factual Consistency of Abstractive Text Summarization,"The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries. Training data is generated by applying a series of rule-based transformations to the sentences of source documents. The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.","Evaluating the Factual Consistency of Abstractive Text Summarization The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries. Training data is generated by applying a series of rule-based transformations to the sentences of source documents. The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.","evaluate factual consistency abstractive text summarization common metric assess summarization algorithm account summary factually consistent source document . propose weakly - supervise , model - base approach verify factual consistency identify conflict source document generate summary . training data generate apply series rule - base transformation sentence source document . factual consistency model train jointly task : 1 ) predict summary sentence factually consistent , 2 ) case , extract span source document support consistency prediction , 3 ) summary sentence deem inconsistent , extract inconsistent span . transfer model summary generate neural model reveal highly scalable approach outperform previous model , include train strong supervision dataset related domain , natural language inference fact checking . additionally , human evaluation show auxiliary span extraction task provide useful assistance process verify factual consistency . release manually annotate dataset factual consistency verification , code training datum generation , train model weight https://github.com/salesforce/factcc .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 20, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,A Preliminary Exploration of GANs for Keyphrase Generation,"We introduce a new keyphrase generation approach using Generative Adversarial Networks (GANs). For a given document, the generator produces a sequence of keyphrases, and the discriminator distinguishes between human-curated and machinegenerated keyphrases. We evaluated this approach on standard benchmark datasets. We observed that our model achieves state-of-theart performance in the generation of abstractive keyphrases and is comparable to the best performing extractive techniques. Although we achieve promising results using GANs, they are not significantly better than the stateof-the-art generative models. To our knowledge, this is one of the first works that use GANs for keyphrase generation. We present a detailed analysis of our observations and expect that these findings would help other researchers to further study the use of GANs for the task of keyphrase generation.","A Preliminary Exploration of GANs for Keyphrase Generation We introduce a new keyphrase generation approach using Generative Adversarial Networks (GANs). For a given document, the generator produces a sequence of keyphrases, and the discriminator distinguishes between human-curated and machinegenerated keyphrases. We evaluated this approach on standard benchmark datasets. We observed that our model achieves state-of-theart performance in the generation of abstractive keyphrases and is comparable to the best performing extractive techniques. Although we achieve promising results using GANs, they are not significantly better than the stateof-the-art generative models. To our knowledge, this is one of the first works that use GANs for keyphrase generation. We present a detailed analysis of our observations and expect that these findings would help other researchers to further study the use of GANs for the task of keyphrase generation.","preliminary exploration gans keyphrase generation introduce new keyphrase generation approach generative adversarial networks ( gans ) . give document , generator produce sequence keyphrase , discriminator distinguish human - curate machinegenerated keyphrase . evaluate approach standard benchmark dataset . observe model achieve state - - theart performance generation abstractive keyphrase comparable well perform extractive technique . achieve promising result gans , significantly well stateof - - art generative model . knowledge , work use gans keyphrase generation . present detailed analysis observation expect finding help researcher study use gans task keyphrase generation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Summarization,Multi-Fact Correction in Abstractive Text Summarization,"Pre-trained neural abstractive summarization systems have dominated extractive strategies on news summarization performance, at least in terms of ROUGE. However, systemgenerated abstractive summaries often face the pitfall of factual inconsistency: generating incorrect facts with respect to the source text. To address this challenge, we propose Span-Fact, a suite of two factual correction models that leverages knowledge learned from question answering models to make corrections in system-generated summaries via span selection. Our models employ single or multimasking strategies to either iteratively or autoregressively replace entities in order to ensure semantic consistency w.r.t. the source text, while retaining the syntactic structure of summaries generated by abstractive summarization models. Experiments show that our models significantly boost the factual consistency of system-generated summaries without sacrificing summary quality in terms of both automatic metrics and human evaluation.","Multi-Fact Correction in Abstractive Text Summarization Pre-trained neural abstractive summarization systems have dominated extractive strategies on news summarization performance, at least in terms of ROUGE. However, systemgenerated abstractive summaries often face the pitfall of factual inconsistency: generating incorrect facts with respect to the source text. To address this challenge, we propose Span-Fact, a suite of two factual correction models that leverages knowledge learned from question answering models to make corrections in system-generated summaries via span selection. Our models employ single or multimasking strategies to either iteratively or autoregressively replace entities in order to ensure semantic consistency w.r.t. the source text, while retaining the syntactic structure of summaries generated by abstractive summarization models. Experiments show that our models significantly boost the factual consistency of system-generated summaries without sacrificing summary quality in terms of both automatic metrics and human evaluation.","multi - fact correction abstractive text summarization pre - train neural abstractive summarization system dominate extractive strategy news summarization performance , term rouge . , systemgenerate abstractive summary face pitfall factual inconsistency : generate incorrect fact respect source text . address challenge , propose span - fact , suite factual correction model leverage knowledge learn question answer model correction system - generate summary span selection . model employ single multimasking strategy iteratively autoregressively replace entity order ensure semantic consistency w.r.t . source text , retain syntactic structure summary generate abstractive summarization model . experiment model significantly boost factual consistency system - generate summary sacrifice summary quality term automatic metric human evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 3, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 21, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles,"Multi-document summarization is a challenging task for which there exists little largescale datasets. We propose Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. Multi-XScience introduces a challenging multidocument summarization task: writing the related-work section of a paper based on its abstract and the articles it references. Our work is inspired by extreme summarization, a dataset construction protocol that favours abstractive modeling approaches. Descriptive statistics and empirical results-using several state-of-the-art models trained on the Multi-XScience dataset-reveal that Multi-XScience is well suited for abstractive models. 1","Multi-XScience: A Large-scale Dataset for Extreme Multi-document Summarization of Scientific Articles Multi-document summarization is a challenging task for which there exists little largescale datasets. We propose Multi-XScience, a large-scale multi-document summarization dataset created from scientific articles. Multi-XScience introduces a challenging multidocument summarization task: writing the related-work section of a paper based on its abstract and the articles it references. Our work is inspired by extreme summarization, a dataset construction protocol that favours abstractive modeling approaches. Descriptive statistics and empirical results-using several state-of-the-art models trained on the Multi-XScience dataset-reveal that Multi-XScience is well suited for abstractive models. 1","multi - xscience : large - scale dataset extreme multi - document summarization scientific article multi - document summarization challenging task exist little largescale dataset . propose multi - xscience , large - scale multi - document summarization dataset create scientific article . multi - xscience introduce challenging multidocument summarization task : write relate - work section paper base abstract article reference . work inspire extreme summarization , dataset construction protocol favour abstractive modeling approach . descriptive statistic empirical result - state - - - art model train multi - xscience dataset - reveal multi - xscience suited abstractive model . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 11, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Stepwise Extractive Summarization and Planning with Structured Transformers,"We propose encoder-centric stepwise models for extractive summarization using structured transformers -HiBERT (Zhang et al.,  2019) and Extended Transformers (Ainslie  et al., 2020). We enable stepwise summarization by injecting the previously generated summary into the structured transformer as an auxiliary sub-structure. Our models are not only efficient in modeling the structure of long inputs, but they also do not rely on task-specific redundancy-aware modeling, making them a general purpose extractive content planner for different tasks. When evaluated on CNN/DailyMail extractive summarization, stepwise models achieve state-of-the-art performance in terms of Rouge without any redundancy aware modeling or sentence filtering. This also holds true for Rotowire tableto-text generation, where our models surpass previously reported metrics for content selection, planning and ordering, highlighting the strength of stepwise modeling. Amongst the two structured transformers we test, stepwise Extended Transformers provides the best performance across both datasets and sets a new standard for these challenges. 1 * Equal contribution. 1 The code and data are available at https://github. com/google-research/google-research/ tree/master/etcsum.","Stepwise Extractive Summarization and Planning with Structured Transformers We propose encoder-centric stepwise models for extractive summarization using structured transformers -HiBERT (Zhang et al.,  2019) and Extended Transformers (Ainslie  et al., 2020). We enable stepwise summarization by injecting the previously generated summary into the structured transformer as an auxiliary sub-structure. Our models are not only efficient in modeling the structure of long inputs, but they also do not rely on task-specific redundancy-aware modeling, making them a general purpose extractive content planner for different tasks. When evaluated on CNN/DailyMail extractive summarization, stepwise models achieve state-of-the-art performance in terms of Rouge without any redundancy aware modeling or sentence filtering. This also holds true for Rotowire tableto-text generation, where our models surpass previously reported metrics for content selection, planning and ordering, highlighting the strength of stepwise modeling. Amongst the two structured transformers we test, stepwise Extended Transformers provides the best performance across both datasets and sets a new standard for these challenges. 1 * Equal contribution. 1 The code and data are available at https://github. com/google-research/google-research/ tree/master/etcsum.","stepwise extractive summarization planning structured transformers propose encoder - centric stepwise model extractive summarization structured transformer -hibert ( zhang et al . ,   2019 ) extended transformers ( ainslie   et al . , 2020 ) . enable stepwise summarization inject previously generate summary structure transformer auxiliary sub - structure . model efficient model structure long input , rely task - specific redundancy - aware modeling , make general purpose extractive content planner different task . evaluate cnn / dailymail extractive summarization , stepwise model achieve state - - - art performance term rouge redundancy aware modeling sentence filtering . hold true rotowire tableto - text generation , model surpass previously report metric content selection , planning ordering , highlight strength stepwise modeling . structured transformer test , stepwise extended transformers provide good performance dataset set new standard challenge . 1 * equal contribution . 1 code datum available https://github . com / google - research / google - research/ tree / master / etcsum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 10, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Coarse-to-Fine Query Focused Multi-Document Summarization,"We consider the problem of better modeling query-cluster interactions to facilitate query focused multi-document summarization. Due to the lack of training data, existing work relies heavily on retrieval-style methods for assembling query relevant summaries. We propose a coarse-to-fine modeling framework which employs progressively more accurate modules for estimating whether text segments are relevant, likely to contain an answer, and central. The modules can be independently developed and leverage training data if available. We present an instantiation of this framework with a trained evidence estimator which relies on distant supervision from question answering (where various resources exist) to identify segments which are likely to answer the query and should be included in the summary. Our framework 1 is robust across domains and query types (i.e., long vs short) and outperforms strong comparison systems on benchmark datasets.","Coarse-to-Fine Query Focused Multi-Document Summarization We consider the problem of better modeling query-cluster interactions to facilitate query focused multi-document summarization. Due to the lack of training data, existing work relies heavily on retrieval-style methods for assembling query relevant summaries. We propose a coarse-to-fine modeling framework which employs progressively more accurate modules for estimating whether text segments are relevant, likely to contain an answer, and central. The modules can be independently developed and leverage training data if available. We present an instantiation of this framework with a trained evidence estimator which relies on distant supervision from question answering (where various resources exist) to identify segments which are likely to answer the query and should be included in the summary. Our framework 1 is robust across domains and query types (i.e., long vs short) and outperforms strong comparison systems on benchmark datasets.","coarse - - fine query focus multi - document summarization consider problem well model query - cluster interaction facilitate query focus multi - document summarization . lack training datum , exist work rely heavily retrieval - style method assemble query relevant summary . propose coarse - - fine modeling framework employ progressively accurate module estimate text segment relevant , likely contain answer , central . module independently develop leverage training datum available . present instantiation framework train evidence estimator rely distant supervision question answering ( resource exist ) identify segment likely answer query include summary . framework 1 robust domain query type ( i.e. , long vs short ) outperform strong comparison system benchmark dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 7, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 6, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Summarization,Multistage Fusion with Forget Gate for Multimodal Summarization in Open-Domain Videos,"Multimodal summarization for open-domain videos is an emerging task, aiming to generate a summary from multisource information (video, audio, transcript). Despite the success of recent multiencoder-decoder frameworks on this task, existing methods lack finegrained multimodality interactions of multisource inputs. Besides, unlike other multimodal tasks, this task has longer multimodal sequences with more redundancy and noise. To address these two issues, we propose a multistage fusion network with the fusion forget gate module, which builds upon this approach by modeling fine-grained interactions between the multisource modalities through a multistep fusion schema and controlling the flow of redundant information between multimodal long sequences via a forgetting module. Experimental results on the How2 dataset show that our proposed model achieves a new state-of-the-art performance. Comprehensive analysis empirically verifies the effectiveness of our fusion schema and forgetting module on multiple encoder-decoder architectures. Specially, when using high noise ASR transcripts (W ER>30%), our model still achieves performance close to the ground-truth transcript model, which reduces manual annotation cost.","Multistage Fusion with Forget Gate for Multimodal Summarization in Open-Domain Videos Multimodal summarization for open-domain videos is an emerging task, aiming to generate a summary from multisource information (video, audio, transcript). Despite the success of recent multiencoder-decoder frameworks on this task, existing methods lack finegrained multimodality interactions of multisource inputs. Besides, unlike other multimodal tasks, this task has longer multimodal sequences with more redundancy and noise. To address these two issues, we propose a multistage fusion network with the fusion forget gate module, which builds upon this approach by modeling fine-grained interactions between the multisource modalities through a multistep fusion schema and controlling the flow of redundant information between multimodal long sequences via a forgetting module. Experimental results on the How2 dataset show that our proposed model achieves a new state-of-the-art performance. Comprehensive analysis empirically verifies the effectiveness of our fusion schema and forgetting module on multiple encoder-decoder architectures. Specially, when using high noise ASR transcripts (W ER>30%), our model still achieves performance close to the ground-truth transcript model, which reduces manual annotation cost.","multistage fusion forget gate multimodal summarization open - domain video multimodal summarization open - domain video emerge task , aim generate summary multisource information ( video , audio , transcript ) . despite success recent multiencoder - decoder framework task , exist method lack finegrained multimodality interaction multisource input . , unlike multimodal task , task long multimodal sequence redundancy noise . address issue , propose multistage fusion network fusion forget gate module , build approach model fine - grained interaction multisource modality multistep fusion schema control flow redundant information multimodal long sequence forget module . experimental result how2 dataset propose model achieve new state - - - art performance . comprehensive analysis empirically verify effectiveness fusion schema forgetting module multiple encoder - decoder architecture . specially , high noise asr transcript ( w er>30 % ) , model achieve performance close ground - truth transcript model , reduce manual annotation cost .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 9, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Summarization,Friendly Topic Assistant for Transformer Based Abstractive Summarization,"Abstractive document summarization is a comprehensive task including document understanding and summary generation, in which area Transformer-based models have achieved the state-of-the-art performance. Compared with Transformers, topic models are better at learning explicit document semantics, and hence could be integrated into Transformers to further boost their performance. To this end, we rearrange and explore the semantics learned by a topic model, and then propose a topic assistant (TA) including three modules. TA is compatible with various Transformerbased models and user-friendly since i) TA is a plug-and-play model that does not break any structure of the original Transformer network, making users easily fine-tune Transformer+TA based on a well pre-trained model; ii) TA only introduces a small number of extra parameters. Experimental results on three datasets demonstrate that TA is able to improve the performance of several Transformer-based models.","Friendly Topic Assistant for Transformer Based Abstractive Summarization Abstractive document summarization is a comprehensive task including document understanding and summary generation, in which area Transformer-based models have achieved the state-of-the-art performance. Compared with Transformers, topic models are better at learning explicit document semantics, and hence could be integrated into Transformers to further boost their performance. To this end, we rearrange and explore the semantics learned by a topic model, and then propose a topic assistant (TA) including three modules. TA is compatible with various Transformerbased models and user-friendly since i) TA is a plug-and-play model that does not break any structure of the original Transformer network, making users easily fine-tune Transformer+TA based on a well pre-trained model; ii) TA only introduces a small number of extra parameters. Experimental results on three datasets demonstrate that TA is able to improve the performance of several Transformer-based models.","friendly topic assistant transformer base abstractive summarization abstractive document summarization comprehensive task include document understanding summary generation , area transformer - base model achieve state - - - art performance . compare transformers , topic model well learn explicit document semantic , integrate transformers boost performance . end , rearrange explore semantic learn topic model , propose topic assistant ( ta ) include module . ta compatible transformerbased model user - friendly ) ta plug - - play model break structure original transformer network , make user easily fine - tune transformer+ta base pre - train model ; ii ) ta introduce small number extra parameter . experimental result dataset demonstrate ta able improve performance transformer - base model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 9, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 11, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Summarization,A Spectral Method for Unsupervised Multi-Document Summarization,"Multi-document summarization (MDS) aims at producing a good-quality summary for several related documents. In this paper, we propose a spectral-based hypothesis, which states that the goodness of summary candidate is closely linked to its so-called spectral impact. Here spectral impact considers the perturbation to the dominant eigenvalue of affinity matrix when dropping the summary candidate from the document cluster. The hypothesis is validated by three theoretical perspectives: semantic scaling, propagation dynamics and matrix perturbation. According to the hypothesis, we formulate the MDS task as the combinatorial optimization of spectral impact and propose an accelerated greedy solution based on a surrogate of spectral impact. The evaluation results on various datasets demonstrate: (1) The performance of the summary candidate is positively correlated with its spectral impact, which accords with our hypothesis; (2) Our spectral-based method has a competitive result as compared to state-of-the-art MDS systems.","A Spectral Method for Unsupervised Multi-Document Summarization Multi-document summarization (MDS) aims at producing a good-quality summary for several related documents. In this paper, we propose a spectral-based hypothesis, which states that the goodness of summary candidate is closely linked to its so-called spectral impact. Here spectral impact considers the perturbation to the dominant eigenvalue of affinity matrix when dropping the summary candidate from the document cluster. The hypothesis is validated by three theoretical perspectives: semantic scaling, propagation dynamics and matrix perturbation. According to the hypothesis, we formulate the MDS task as the combinatorial optimization of spectral impact and propose an accelerated greedy solution based on a surrogate of spectral impact. The evaluation results on various datasets demonstrate: (1) The performance of the summary candidate is positively correlated with its spectral impact, which accords with our hypothesis; (2) Our spectral-based method has a competitive result as compared to state-of-the-art MDS systems.","spectral method unsupervised multi - document summarization multi - document summarization ( mds ) aim produce good - quality summary related document . paper , propose spectral - base hypothesis , state goodness summary candidate closely link - call spectral impact . spectral impact consider perturbation dominant eigenvalue affinity matrix drop summary candidate document cluster . hypothesis validate theoretical perspective : semantic scaling , propagation dynamic matrix perturbation . accord hypothesis , formulate mds task combinatorial optimization spectral impact propose accelerate greedy solution base surrogate spectral impact . evaluation result dataset demonstrate : ( 1 ) performance summary candidate positively correlate spectral impact , accord hypothesis ; ( 2 ) spectral - base method competitive result compare state - - - art mds system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 10, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Summarization,True
Summarization,Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach,"Given a document and a target aspect (e.g., a topic of interest), aspect-based abstractive summarization attempts to generate a summary with respect to the aspect. Previous studies usually assume a small pre-defined set of aspects and fall short of summarizing on other diverse topics. In this work, we study summarizing on arbitrary aspects relevant to the document, which significantly expands the application of the task in practice. Due to the lack of supervision data, we develop a new weak supervision construction method and an aspect modeling scheme, both of which integrate rich external knowledge sources such as Concept-Net and Wikipedia. Experiments show our approach achieves performance boosts on summarizing both real and synthetic documents given pre-defined or arbitrary aspects. 1","Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach Given a document and a target aspect (e.g., a topic of interest), aspect-based abstractive summarization attempts to generate a summary with respect to the aspect. Previous studies usually assume a small pre-defined set of aspects and fall short of summarizing on other diverse topics. In this work, we study summarizing on arbitrary aspects relevant to the document, which significantly expands the application of the task in practice. Due to the lack of supervision data, we develop a new weak supervision construction method and an aspect modeling scheme, both of which integrate rich external knowledge sources such as Concept-Net and Wikipedia. Experiments show our approach achieves performance boosts on summarizing both real and synthetic documents given pre-defined or arbitrary aspects. 1","summarize text aspect : knowledge - inform weakly - supervise approach give document target aspect ( e.g. , topic interest ) , aspect - base abstractive summarization attempt generate summary respect aspect . previous study usually assume small pre - defined set aspect fall short summarize diverse topic . work , study summarize arbitrary aspect relevant document , significantly expand application task practice . lack supervision datum , develop new weak supervision construction method aspect modeling scheme , integrate rich external knowledge source concept - net wikipedia . experiment approach achieve performance boost summarize real synthetic document give pre - defined arbitrary aspect . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Summarization,Modeling Content Importance for Summarization with Pre-trained Language Models,"Modeling content importance is an essential yet challenging task for summarization. Previous work is mostly based on statistical methods that estimate word-level salience, which does not consider semantics and larger context when quantifying importance. It is thus hard for these methods to generalize to semantic units of longer text spans. In this work, we apply information theory on top of pretrained language models and define the concept of importance from the perspective of information amount. It considers both the semantics and context when evaluating the importance of each semantic unit. With the help of pre-trained language models, it can easily generalize to different kinds of semantic units (n-grams or sentences). Experiments on CNN/Daily Mail and New York Times datasets demonstrate that our method can better model the importance of content than prior work based on F1 and ROUGE scores.","Modeling Content Importance for Summarization with Pre-trained Language Models Modeling content importance is an essential yet challenging task for summarization. Previous work is mostly based on statistical methods that estimate word-level salience, which does not consider semantics and larger context when quantifying importance. It is thus hard for these methods to generalize to semantic units of longer text spans. In this work, we apply information theory on top of pretrained language models and define the concept of importance from the perspective of information amount. It considers both the semantics and context when evaluating the importance of each semantic unit. With the help of pre-trained language models, it can easily generalize to different kinds of semantic units (n-grams or sentences). Experiments on CNN/Daily Mail and New York Times datasets demonstrate that our method can better model the importance of content than prior work based on F1 and ROUGE scores.","model content importance summarization pre - trained language model model content importance essential challenging task summarization . previous work base statistical method estimate word - level salience , consider semantic large context quantify importance . hard method generalize semantic unit long text span . work , apply information theory pretrained language model define concept importance perspective information . consider semantic context evaluate importance semantic unit . help pre - trained language model , easily generalize different kind semantic unit ( n - gram sentence ) . experiment cnn / daily mail new york times dataset demonstrate method well model importance content prior work base f1 rouge score .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Summarization,Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning,"Evaluation of a document summarization system has been a critical factor to impact the success of the summarization task. Previous approaches, such as ROUGE, mainly consider the informativeness of the assessed summary and require human-generated references for each test summary. In this work, we propose to evaluate the summary qualities without reference summaries by unsupervised contrastive learning. Specifically, we design a new metric which covers both linguistic qualities and semantic informativeness based on BERT. To learn the metric, for each summary, we construct different types of negative samples with respect to different aspects of the summary qualities, and train our model with a ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method outperforms other metrics even without reference summaries. Furthermore, we show that our method is general and transferable across datasets.","Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning Evaluation of a document summarization system has been a critical factor to impact the success of the summarization task. Previous approaches, such as ROUGE, mainly consider the informativeness of the assessed summary and require human-generated references for each test summary. In this work, we propose to evaluate the summary qualities without reference summaries by unsupervised contrastive learning. Specifically, we design a new metric which covers both linguistic qualities and semantic informativeness based on BERT. To learn the metric, for each summary, we construct different types of negative samples with respect to different aspects of the summary qualities, and train our model with a ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method outperforms other metrics even without reference summaries. Furthermore, we show that our method is general and transferable across datasets.","unsupervised reference - free summary quality evaluation contrastive learning evaluation document summarization system critical factor impact success summarization task . previous approach , rouge , mainly consider informativeness assess summary require human - generate reference test summary . work , propose evaluate summary quality reference summary unsupervised contrastive learning . specifically , design new metric cover linguistic quality semantic informativeness base bert . learn metric , summary , construct different type negative sample respect different aspect summary quality , train model ranking loss . experiment newsroom cnn / daily mail demonstrate new evaluation method outperform metric reference summary . furthermore , method general transferable dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 11, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
"Syntax: Tagging, Chunking and Parsing",Unsupervised Parsing with S-DIORA: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders,"The deep inside-outside recursive autoencoder (DIORA; Drozdov et al. 2019a ) is a selfsupervised neural model that learns to induce syntactic tree structures for input sentences without access to labeled training data. In this paper, we discover that while DIORA exhaustively encodes all possible binary trees of a sentence with a soft dynamic program, its vector averaging approach is locally greedy and cannot recover from errors when computing the highest scoring parse tree in bottom-up chart parsing. To fix this issue, we introduce S-DIORA, an improved variant of DIORA that encodes a single tree rather than a softlyweighted mixture of trees by employing a hard argmax operation and a beam at each cell in the chart. Our experiments show that through fine-tuning a pre-trained DIORA with our new algorithm, we improve the state of the art in unsupervised constituency parsing on the English WSJ Penn Treebank by 2.2 6% F1, depending on the data used for fine-tuning.","Unsupervised Parsing with S-DIORA: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders The deep inside-outside recursive autoencoder (DIORA; Drozdov et al. 2019a ) is a selfsupervised neural model that learns to induce syntactic tree structures for input sentences without access to labeled training data. In this paper, we discover that while DIORA exhaustively encodes all possible binary trees of a sentence with a soft dynamic program, its vector averaging approach is locally greedy and cannot recover from errors when computing the highest scoring parse tree in bottom-up chart parsing. To fix this issue, we introduce S-DIORA, an improved variant of DIORA that encodes a single tree rather than a softlyweighted mixture of trees by employing a hard argmax operation and a beam at each cell in the chart. Our experiments show that through fine-tuning a pre-trained DIORA with our new algorithm, we improve the state of the art in unsupervised constituency parsing on the English WSJ Penn Treebank by 2.2 6% F1, depending on the data used for fine-tuning.","unsupervised parsing s - diora : single tree encoding deep inside - outside recursive autoencoder deep inside - outside recursive autoencoder ( diora ; drozdov et al . 2019a ) selfsupervised neural model learn induce syntactic tree structure input sentence access label training datum . paper , discover diora exhaustively encode possible binary tree sentence soft dynamic program , vector averaging approach locally greedy recover error compute highest score parse tree - chart parsing . fix issue , introduce s - diora , improved variant diora encode single tree softlyweighted mixture tree employ hard argmax operation beam cell chart . experiment fine - tune pre - train diora new algorithm , improve state art unsupervised constituency parsing english wsj penn treebank 2.2 6 % f1 , depend datum fine - tuning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 12, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Adversarial Attack and Defense of Structured Prediction Models,"Building an effective adversarial attacker and elaborating on countermeasures for adversarial attacks for natural language processing (NLP) have attracted a lot of research in recent years. However, most of the existing approaches focus on classification problems. In this paper, we investigate attacks and defenses for structured prediction tasks in NLP. Besides the difficulty of perturbing discrete words and the sentence fluency problem faced by attackers in any NLP tasks, there is a specific challenge to attackers of structured prediction models: the structured output of structured prediction models is sensitive to small perturbations in the input. To address these problems, we propose a novel and unified framework that learns to attack a structured prediction model using a sequence-to-sequence model with feedbacks from multiple reference models of the same structured prediction task. Based on the proposed attack, we further reinforce the victim model with adversarial training, making its prediction more robust and accurate. We evaluate the proposed framework in dependency parsing and part-of-speech tagging. Automatic and human evaluations show that our proposed framework succeeds in both attacking state-of-the-art structured prediction models and boosting them with adversarial training.","Adversarial Attack and Defense of Structured Prediction Models Building an effective adversarial attacker and elaborating on countermeasures for adversarial attacks for natural language processing (NLP) have attracted a lot of research in recent years. However, most of the existing approaches focus on classification problems. In this paper, we investigate attacks and defenses for structured prediction tasks in NLP. Besides the difficulty of perturbing discrete words and the sentence fluency problem faced by attackers in any NLP tasks, there is a specific challenge to attackers of structured prediction models: the structured output of structured prediction models is sensitive to small perturbations in the input. To address these problems, we propose a novel and unified framework that learns to attack a structured prediction model using a sequence-to-sequence model with feedbacks from multiple reference models of the same structured prediction task. Based on the proposed attack, we further reinforce the victim model with adversarial training, making its prediction more robust and accurate. We evaluate the proposed framework in dependency parsing and part-of-speech tagging. Automatic and human evaluations show that our proposed framework succeeds in both attacking state-of-the-art structured prediction models and boosting them with adversarial training.","adversarial attack defense structured prediction models build effective adversarial attacker elaborate countermeasure adversarial attack natural language processing ( nlp ) attract lot research recent year . , exist approach focus classification problem . paper , investigate attack defense structure prediction task nlp . difficulty perturb discrete word sentence fluency problem face attacker nlp task , specific challenge attacker structure prediction model : structured output structure prediction model sensitive small perturbation input . address problem , propose novel unified framework learn attack structure prediction model sequence - - sequence model feedback multiple reference model structure prediction task . base propose attack , reinforce victim model adversarial training , make prediction robust accurate . evaluate propose framework dependency parsing - - speech tagging . automatic human evaluation propose framework succeed attack state - - - art structure prediction model boost adversarial training .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 8, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 1, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Syntax: Tagging, Chunking and Parsing",UDapter: Language Adaptation for Truly Universal Dependency Parsing,"Recent advances in multilingual dependency parsing have brought the idea of a truly universal parser closer to reality. However, crosslanguage interference and restrained model capacity remain major obstacles. To address this, we propose a novel multilingual task adaptation approach based on contextual parameter generation and adapter modules. This approach enables to learn adapters via language embeddings while sharing model parameters across languages. It also allows for an easy but effective integration of existing linguistic typology features into the parsing network. The resulting parser, UDapter, outperforms strong monolingual and multilingual baselines on the majority of both high-resource and lowresource (zero-shot) languages, showing the success of the proposed adaptation approach. Our in-depth analyses show that soft parameter sharing via typological features is key to this success. 1","UDapter: Language Adaptation for Truly Universal Dependency Parsing Recent advances in multilingual dependency parsing have brought the idea of a truly universal parser closer to reality. However, crosslanguage interference and restrained model capacity remain major obstacles. To address this, we propose a novel multilingual task adaptation approach based on contextual parameter generation and adapter modules. This approach enables to learn adapters via language embeddings while sharing model parameters across languages. It also allows for an easy but effective integration of existing linguistic typology features into the parsing network. The resulting parser, UDapter, outperforms strong monolingual and multilingual baselines on the majority of both high-resource and lowresource (zero-shot) languages, showing the success of the proposed adaptation approach. Our in-depth analyses show that soft parameter sharing via typological features is key to this success. 1","udapter : language adaptation truly universal dependency parsing recent advance multilingual dependency parsing bring idea truly universal parser close reality . , crosslanguage interference restrain model capacity remain major obstacle . address , propose novel multilingual task adaptation approach base contextual parameter generation adapter module . approach enable learn adapter language embedding share model parameter language . allow easy effective integration existing linguistic typology feature parsing network . result parser , udapter , outperform strong monolingual multilingual baseline majority high - resource lowresource ( zero - shot ) language , show success propose adaptation approach . - depth analysis soft parameter sharing typological feature key success . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 9, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Interpretable Multi-dataset Evaluation for Named Entity Recognition,"With the proliferation of models for natural language processing tasks, it is even harder to understand the differences between models and their relative merits. Simply looking at differences between holistic metrics such as accuracy, BLEU, or F1 does not tell us why or how particular methods perform differently and how diverse datasets influence the model design choices. In this paper, we present a general methodology for interpretable evaluation for the named entity recognition (NER) task. The proposed evaluation method enables us to interpret the differences in models and datasets, as well as the interplay between them, identifying the strengths and weaknesses of current systems. By making our analysis tool available, we make it easy for future researchers to run similar analyses and drive progress in this area: https: //github.com/neulab/InterpretEval.","Interpretable Multi-dataset Evaluation for Named Entity Recognition With the proliferation of models for natural language processing tasks, it is even harder to understand the differences between models and their relative merits. Simply looking at differences between holistic metrics such as accuracy, BLEU, or F1 does not tell us why or how particular methods perform differently and how diverse datasets influence the model design choices. In this paper, we present a general methodology for interpretable evaluation for the named entity recognition (NER) task. The proposed evaluation method enables us to interpret the differences in models and datasets, as well as the interplay between them, identifying the strengths and weaknesses of current systems. By making our analysis tool available, we make it easy for future researchers to run similar analyses and drive progress in this area: https: //github.com/neulab/InterpretEval.","interpretable multi - dataset evaluation name entity recognition proliferation model natural language processing task , hard understand difference model relative merit . simply look difference holistic metric accuracy , bleu , f1 tell particular method perform differently diverse dataset influence model design choice . paper , present general methodology interpretable evaluation name entity recognition ( ner ) task . propose evaluation method enable interpret difference model dataset , interplay , identify strength weakness current system . make analysis tool available , easy future researcher run similar analysis drive progress area : https : //github.com / neulab / interpreteval .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Syntax: Tagging, Chunking and Parsing",HIT: Nested Named Entity Recognition via Head-Tail Pair and Token Interaction,"Named Entity Recognition (NER) is a fundamental task in natural language processing. In order to identify entities with nested structure, many sophisticated methods have been recently developed based on either the traditional sequence labeling approaches or directed hypergraph structures. Despite being successful, these methods often fall short in striking a good balance between the expression power for nested structure and the model complexity. To address this issue, we present a novel nested NER model named HIT. Our proposed HIT model leverages two key properties pertaining to the (nested) named entity, including (1) explicit boundary tokens and (2) tight internal connection between tokens within the boundary. Specifically, we design (1) Head-Tail Detector based on the multi-head selfattention mechanism and bi-affine classifier to detect boundary tokens, and (2) Token Interaction Tagger based on traditional sequence labeling approaches to characterize the internal token connection within the boundary. Experiments on three public NER datasets demonstrate that the proposed HIT achieves state-ofthe-art performance.","HIT: Nested Named Entity Recognition via Head-Tail Pair and Token Interaction Named Entity Recognition (NER) is a fundamental task in natural language processing. In order to identify entities with nested structure, many sophisticated methods have been recently developed based on either the traditional sequence labeling approaches or directed hypergraph structures. Despite being successful, these methods often fall short in striking a good balance between the expression power for nested structure and the model complexity. To address this issue, we present a novel nested NER model named HIT. Our proposed HIT model leverages two key properties pertaining to the (nested) named entity, including (1) explicit boundary tokens and (2) tight internal connection between tokens within the boundary. Specifically, we design (1) Head-Tail Detector based on the multi-head selfattention mechanism and bi-affine classifier to detect boundary tokens, and (2) Token Interaction Tagger based on traditional sequence labeling approaches to characterize the internal token connection within the boundary. Experiments on three public NER datasets demonstrate that the proposed HIT achieves state-ofthe-art performance.","hit : nest name entity recognition head - tail pair token interaction name entity recognition ( ner ) fundamental task natural language processing . order identify entity nest structure , sophisticated method recently develop base traditional sequence labeling approach direct hypergraph structure . despite successful , method fall short strike good balance expression power nest structure model complexity . address issue , present novel nest ner model name hit . propose hit model leverage key property pertain ( nested ) name entity , include ( 1 ) explicit boundary token ( 2 ) tight internal connection token boundary . specifically , design ( 1 ) head - tail detector base multi - head selfattention mechanism bi - affine classifier detect boundary token , ( 2 ) token interaction tagger base traditional sequence labeling approach characterize internal token connection boundary . experiment public ner dataset demonstrate propose hit achieve state - ofthe - art performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 18, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Syntax: Tagging, Chunking and Parsing",Supertagging Combinatory Categorial Grammar with Attentive Graph Convolutional Networks,"Supertagging is conventionally regarded as an important task for combinatory categorial grammar (CCG) parsing, where effective modeling of contextual information is highly important to this task. However, existing studies have made limited efforts to leverage contextual features except for applying powerful encoders (e.g., bi-LSTM). In this paper, we propose attentive graph convolutional networks to enhance neural CCG supertagging through a novel solution of leveraging contextual information. Specifically, we build the graph from chunks (n-grams) extracted from a lexicon and apply attention over the graph, so that different word pairs from the contexts within and across chunks are weighted in the model and facilitate the supertagging accordingly. The experiments performed on the CCGbank demonstrate that our approach outperforms all previous studies in terms of both supertagging and parsing. Further analyses illustrate the effectiveness of each component in our approach to discriminatively learn from word pairs to enhance CCG supertagging. 1 † Corresponding author. 1 Our code and models for CCG supertagging are released at https://github.com/cuhksz-nlp/NeST-CCG.","Supertagging Combinatory Categorial Grammar with Attentive Graph Convolutional Networks Supertagging is conventionally regarded as an important task for combinatory categorial grammar (CCG) parsing, where effective modeling of contextual information is highly important to this task. However, existing studies have made limited efforts to leverage contextual features except for applying powerful encoders (e.g., bi-LSTM). In this paper, we propose attentive graph convolutional networks to enhance neural CCG supertagging through a novel solution of leveraging contextual information. Specifically, we build the graph from chunks (n-grams) extracted from a lexicon and apply attention over the graph, so that different word pairs from the contexts within and across chunks are weighted in the model and facilitate the supertagging accordingly. The experiments performed on the CCGbank demonstrate that our approach outperforms all previous studies in terms of both supertagging and parsing. Further analyses illustrate the effectiveness of each component in our approach to discriminatively learn from word pairs to enhance CCG supertagging. 1 † Corresponding author. 1 Our code and models for CCG supertagging are released at https://github.com/cuhksz-nlp/NeST-CCG.","supertagge combinatory categorial grammar attentive graph convolutional network supertagging conventionally regard important task combinatory categorial grammar ( ccg ) parsing , effective modeling contextual information highly important task . , exist study limited effort leverage contextual feature apply powerful encoder ( e.g. , bi - lstm ) . paper , propose attentive graph convolutional network enhance neural ccg supertagging novel solution leverage contextual information . specifically , build graph chunk ( n - gram ) extract lexicon apply attention graph , different word pair context chunk weight model facilitate supertagging accordingly . experiment perform ccgbank demonstrate approach outperform previous study term supertagging parsing . analysis illustrate effectiveness component approach discriminatively learn word pair enhance ccg supertagging . 1 † corresponding author . 1 code model ccg supertagging release https://github.com/cuhksz-nlp/nest-ccg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Syntax: Tagging, Chunking and Parsing",Discontinuous Constituent Parsing as Sequence Labeling,"This paper reduces discontinuous parsing to sequence labeling. It first shows that existing reductions for constituent parsing as labeling do not support discontinuities. Second, it fills this gap and proposes to encode tree discontinuities as nearly ordered permutations of the input sequence. Third, it studies whether such discontinuous representations are learnable. The experiments show that despite the architectural simplicity, under the right representation, the models are fast and accurate. 1","Discontinuous Constituent Parsing as Sequence Labeling This paper reduces discontinuous parsing to sequence labeling. It first shows that existing reductions for constituent parsing as labeling do not support discontinuities. Second, it fills this gap and proposes to encode tree discontinuities as nearly ordered permutations of the input sequence. Third, it studies whether such discontinuous representations are learnable. The experiments show that despite the architectural simplicity, under the right representation, the models are fast and accurate. 1","discontinuous constituent parsing sequence labeling paper reduce discontinuous parsing sequence labeling . show exist reduction constituent parsing labeling support discontinuity . second , fill gap propose encode tree discontinuity nearly ordered permutation input sequence . , study discontinuous representation learnable . experiment despite architectural simplicity , right representation , model fast accurate . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Unsupervised Parsing via Constituency Tests,"We propose a method for unsupervised parsing based on the linguistic notion of a constituency test. One type of constituency test involves modifying the sentence via some transformation (e.g. replacing the span with a pronoun) and then judging the result (e.g. checking if it is grammatical). Motivated by this idea, we design an unsupervised parser by specifying a set of transformations and using an unsupervised neural acceptability model to make grammaticality decisions. To produce a tree given a sentence, we score each span by aggregating its constituency test judgments, and we choose the binary tree with the highest total score. While this approach already achieves performance in the range of current methods, we further improve accuracy by fine-tuning the grammaticality model through a refinement procedure, where we alternate between improving the estimated trees and improving the grammaticality model. The refined model achieves 62.8 F1 on the Penn Treebank test set, an absolute improvement of 7.6 points over the previous best published result.","Unsupervised Parsing via Constituency Tests We propose a method for unsupervised parsing based on the linguistic notion of a constituency test. One type of constituency test involves modifying the sentence via some transformation (e.g. replacing the span with a pronoun) and then judging the result (e.g. checking if it is grammatical). Motivated by this idea, we design an unsupervised parser by specifying a set of transformations and using an unsupervised neural acceptability model to make grammaticality decisions. To produce a tree given a sentence, we score each span by aggregating its constituency test judgments, and we choose the binary tree with the highest total score. While this approach already achieves performance in the range of current methods, we further improve accuracy by fine-tuning the grammaticality model through a refinement procedure, where we alternate between improving the estimated trees and improving the grammaticality model. The refined model achieves 62.8 F1 on the Penn Treebank test set, an absolute improvement of 7.6 points over the previous best published result.","unsupervised parsing constituency test propose method unsupervised parsing base linguistic notion constituency test . type constituency test involve modify sentence transformation ( e.g. replace span pronoun ) judge result ( e.g. check grammatical ) . motivate idea , design unsupervised parser specify set transformation unsupervised neural acceptability model grammaticality decision . produce tree give sentence , score span aggregate constituency test judgment , choose binary tree high total score . approach achieve performance range current method , improve accuracy fine - tune grammaticality model refinement procedure , alternate improve estimate tree improve grammaticality model . refined model achieve 62.8 f1 penn treebank test set , absolute improvement 7.6 point previous good publish result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 11, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Parsing Gapping Constructions Based on Grammatical and Semantic Roles,A gapping construction consists of a coordinated structure where redundant elements are elided from all but one conjuncts. This paper proposes a method of parsing sentences with gapping to recover elided elements. The proposed method is based on constituent trees annotated with grammatical and semantic roles that are useful for identifying elided elements. Our method outperforms the previous method in terms of F-measure and recall.,Parsing Gapping Constructions Based on Grammatical and Semantic Roles A gapping construction consists of a coordinated structure where redundant elements are elided from all but one conjuncts. This paper proposes a method of parsing sentences with gapping to recover elided elements. The proposed method is based on constituent trees annotated with grammatical and semantic roles that are useful for identifying elided elements. Our method outperforms the previous method in terms of F-measure and recall.,parse gapping construction base grammatical semantic role gapping construction consist coordinate structure redundant element elide conjunct . paper propose method parse sentence gapping recover elide element . propose method base constituent tree annotate grammatical semantic role useful identify elide element . method outperform previous method term f - measure recall .,"{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
"Syntax: Tagging, Chunking and Parsing",On the Role of Supervision in Unsupervised Constituency Parsing,"We analyze several recent unsupervised constituency parsing models, which are tuned with respect to the parsing F 1 score on the Wall Street Journal (WSJ) development set (1,700 sentences). We introduce strong baselines for them, by training an existing supervised parsing model (Kitaev and Klein, 2018)  on the same labeled examples they access. When training on the 1,700 examples, or even when using only 50 examples for training and 5 for development, such a few-shot parsing approach can outperform all the unsupervised parsing methods by a significant margin. Fewshot parsing can be further improved by a simple data augmentation method and selftraining. This suggests that, in order to arrive at fair conclusions, we should carefully consider the amount of labeled data used for model development. We propose two protocols for future work on unsupervised parsing: (i) use fully unsupervised criteria for hyperparameter tuning and model selection; (ii) use as few labeled examples as possible for model development, and compare to few-shot parsing trained on the same labeled examples. 1","On the Role of Supervision in Unsupervised Constituency Parsing We analyze several recent unsupervised constituency parsing models, which are tuned with respect to the parsing F 1 score on the Wall Street Journal (WSJ) development set (1,700 sentences). We introduce strong baselines for them, by training an existing supervised parsing model (Kitaev and Klein, 2018)  on the same labeled examples they access. When training on the 1,700 examples, or even when using only 50 examples for training and 5 for development, such a few-shot parsing approach can outperform all the unsupervised parsing methods by a significant margin. Fewshot parsing can be further improved by a simple data augmentation method and selftraining. This suggests that, in order to arrive at fair conclusions, we should carefully consider the amount of labeled data used for model development. We propose two protocols for future work on unsupervised parsing: (i) use fully unsupervised criteria for hyperparameter tuning and model selection; (ii) use as few labeled examples as possible for model development, and compare to few-shot parsing trained on the same labeled examples. 1","role supervision unsupervised constituency parsing analyze recent unsupervised constituency parsing model , tune respect parsing f 1 score wall street journal ( wsj ) development set ( 1,700 sentence ) . introduce strong baseline , train exist supervise parsing model ( kitaev klein , 2018 )   label example access . train 1,700 example , 50 example training 5 development , - shot parsing approach outperform unsupervised parsing method significant margin . fewshot parsing improve simple data augmentation method selftraining . suggest , order arrive fair conclusion , carefully consider label datum model development . propose protocol future work unsupervised parsing : ( ) use fully unsupervised criterion hyperparameter tuning model selection ; ( ii ) use label example possible model development , compare - shot parsing train label example . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 9, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 14, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Adversarial Semantic Decoupling for Recognizing Open-Vocabulary Slots,"Open-vocabulary slots, such as file name, album name, or schedule title, significantly degrade the performance of neural-based slot filling models since these slots can take on values from a virtually unlimited set and have no semantic restriction nor a length limit. In this paper, we propose a robust adversarial model-agnostic slot filling method that explicitly decouples local semantics inherent in open-vocabulary slot words from the global context. We aim to depart entangled contextual semantics and focus more on the holistic context at the level of the whole sentence. Experiments on two public datasets show that our method consistently outperforms other methods with a statistically significant margin on all the open-vocabulary slots without deteriorating the performance of normal slots.","Adversarial Semantic Decoupling for Recognizing Open-Vocabulary Slots Open-vocabulary slots, such as file name, album name, or schedule title, significantly degrade the performance of neural-based slot filling models since these slots can take on values from a virtually unlimited set and have no semantic restriction nor a length limit. In this paper, we propose a robust adversarial model-agnostic slot filling method that explicitly decouples local semantics inherent in open-vocabulary slot words from the global context. We aim to depart entangled contextual semantics and focus more on the holistic context at the level of the whole sentence. Experiments on two public datasets show that our method consistently outperforms other methods with a statistically significant margin on all the open-vocabulary slots without deteriorating the performance of normal slots.","adversarial semantic decoupling recognize open - vocabulary slot open - vocabulary slot , file , album , schedule title , significantly degrade performance neural - base slot filling model slot value virtually unlimited set semantic restriction length limit . paper , propose robust adversarial model - agnostic slot filling method explicitly decouple local semantic inherent open - vocabulary slot word global context . aim depart entangle contextual semantic focus holistic context level sentence . experiment public dataset method consistently outperform method statistically significant margin open - vocabulary slot deteriorate performance normal slot .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
"Syntax: Tagging, Chunking and Parsing",Some Languages Seem Easier to Parse Because Their Treebanks Leak,"Cross-language differences in dependency parsing performance are mostly attributed to treebank size, average sentence length, average dependency length, morphological complexity, and domain differences. In this paper I point to a factor not previously discussed: If we abstract away from words and dependency labels, how many graphs in the test data were seen in the training data? I discuss how to compute graph isomorphisms, and show that, treebank size aside, overlap between training and test graphs explains more of the observed variation than standard explanations such as the above.","Some Languages Seem Easier to Parse Because Their Treebanks Leak Cross-language differences in dependency parsing performance are mostly attributed to treebank size, average sentence length, average dependency length, morphological complexity, and domain differences. In this paper I point to a factor not previously discussed: If we abstract away from words and dependency labels, how many graphs in the test data were seen in the training data? I discuss how to compute graph isomorphisms, and show that, treebank size aside, overlap between training and test graphs explains more of the observed variation than standard explanations such as the above.","language easy parse treebank leak cross - language difference dependency parsing performance attribute treebank size , average sentence length , average dependency length , morphological complexity , domain difference . paper point factor previously discuss : abstract away word dependency label , graph test datum see training datum ? discuss compute graph isomorphism , , treebank size aside , overlap training test graph explain observe variation standard explanation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 8, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Uncertainty-Aware Label Refinement for Sequence Labeling,"Conditional random fields (CRF) for label decoding has become ubiquitous in sequence labeling tasks. However, the local label dependencies and inefficient Viterbi decoding have always been a problem to be solved. In this work, we introduce a novel two-stage label decoding framework to model long-term label dependencies, while being much more computationally efficient. A base model first predicts draft labels, and then a novel twostream self-attention model makes refinements on these draft predictions based on longrange label dependencies, which can achieve parallel decoding for a faster prediction. In addition, in order to mitigate the side effects of incorrect draft labels, Bayesian neural networks are used to indicate the labels with a high probability of being wrong, which can greatly assist in preventing error propagation. The experimental results on three sequence labeling benchmarks demonstrated that the proposed method not only outperformed the CRF-based methods but also greatly accelerated the inference process.","Uncertainty-Aware Label Refinement for Sequence Labeling Conditional random fields (CRF) for label decoding has become ubiquitous in sequence labeling tasks. However, the local label dependencies and inefficient Viterbi decoding have always been a problem to be solved. In this work, we introduce a novel two-stage label decoding framework to model long-term label dependencies, while being much more computationally efficient. A base model first predicts draft labels, and then a novel twostream self-attention model makes refinements on these draft predictions based on longrange label dependencies, which can achieve parallel decoding for a faster prediction. In addition, in order to mitigate the side effects of incorrect draft labels, Bayesian neural networks are used to indicate the labels with a high probability of being wrong, which can greatly assist in preventing error propagation. The experimental results on three sequence labeling benchmarks demonstrated that the proposed method not only outperformed the CRF-based methods but also greatly accelerated the inference process.","uncertainty - aware label refinement sequence labeling conditional random field ( crf ) label decoding ubiquitous sequence labeling task . , local label dependency inefficient viterbi decoding problem solve . work , introduce novel - stage label decoding framework model long - term label dependency , computationally efficient . base model predict draft label , novel twostream self - attention model make refinement draft prediction base longrange label dependency , achieve parallel decoding fast prediction . addition , order mitigate effect incorrect draft label , bayesian neural network indicate label high probability wrong , greatly assist prevent error propagation . experimental result sequence labeling benchmark demonstrate propose method outperform crf - base method greatly accelerate inference process .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Syntax: Tagging, Chunking and Parsing",AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network,"The linear-chain Conditional Random Field (CRF) model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.","AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network The linear-chain Conditional Random Field (CRF) model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.","ain : fast accurate sequence labeling approximate inference network linear - chain conditional random field ( crf ) model widely - neural sequence labeling approach . exact probabilistic inference algorithm forward - backward viterbi algorithm typically apply training prediction stage crf model . , algorithm require sequential computation make parallelization impossible . paper , propose employ parallelizable approximate variational inference algorithm crf model . base algorithm , design approximate inference network connect encoder neural crf model form end - - end network , amenable parallelization fast training prediction . empirical result propose approach achieve 12.7 - fold improvement decode speed long sentence competitive accuracy compare traditional crf approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
"Syntax: Tagging, Chunking and Parsing",Position-Aware Tagging for Aspect Sentiment Triplet Extraction,"Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first end-to-end model with a novel positionaware tagging scheme that is capable of jointly extracting the triplets. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness 1 .","Position-Aware Tagging for Aspect Sentiment Triplet Extraction Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first end-to-end model with a novel positionaware tagging scheme that is capable of jointly extracting the triplets. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness 1 .","position - aware tagging aspect sentiment triplet extraction aspect sentiment triplet extraction ( aste ) task extract triplet target entity , associate sentiment , opinion span explain reason sentiment . exist research effort solve problem pipeline approach , break triplet extraction process stage . observation element triplet highly related , motivate build joint model extract triplet sequence tagging approach . , effectively design tagging approach extract triplet capture rich interaction element challenging research question . work , propose end - - end model novel positionaware tagging scheme capable jointly extract triplet . experimental result exist dataset jointly capture element triplet approach lead improve performance exist approach . conduct extensive experiment investigate model effectiveness robustness 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 10, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
"Syntax: Tagging, Chunking and Parsing",Keep it Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in Sanskrit,"Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020) , proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework's default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.","Keep it Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in Sanskrit Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020) , proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework's default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.","surprisingly simple : simple order graph base parsing model joint morphosyntactic parsing sanskrit morphologically rich language benefit joint processing morphology syntax , compare pipeline architecture . propose graph - base model joint morphological parsing dependency parsing sanskrit . , extend energy base model framework ( krishna et al . , 2020 ) , propose structured prediction task sanskrit , 2 simple significant way . , framework default input graph generation method modify generate multigraph , enable use exact search inference . second , prune input search space linguistically motivate approach , root traditional grammatical analysis sanskrit . experiment morphological parsing joint model outperform standalone morphological parser . report state art result morphological parsing , dependency parsing , standalone ( gold morphological tag ) joint morphosyntactic parsing setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 8, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 13, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 13, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
"Syntax: Tagging, Chunking and Parsing",Please Mind the Root: Decoding Arborescences for Dependency Parsing,"The connection between dependency trees and spanning trees is exploited by the NLP community to train and to decode graph-based dependency parsers. However, the NLP literature has missed an important difference between the two structures: only one edge may emanate from the root in a dependency tree. We analyzed the output of state-of-the-art parsers on many languages from the Universal Dependency Treebank: although these parsers are often able to learn that trees which violate the constraint should be assigned lower probabilities, their ability to do so unsurprisingly degrades as the size of the training set decreases. In fact, the worst constraint-violation rate we observe is 24%. Prior work has proposed an inefficient algorithm to enforce the constraint, which adds a factor of n to the decoding runtime. We adapt an algorithm due to Gabow and Tarjan (1984) to dependency parsing, which satisfies the constraint without compromising the original runtime. 1","Please Mind the Root: Decoding Arborescences for Dependency Parsing The connection between dependency trees and spanning trees is exploited by the NLP community to train and to decode graph-based dependency parsers. However, the NLP literature has missed an important difference between the two structures: only one edge may emanate from the root in a dependency tree. We analyzed the output of state-of-the-art parsers on many languages from the Universal Dependency Treebank: although these parsers are often able to learn that trees which violate the constraint should be assigned lower probabilities, their ability to do so unsurprisingly degrades as the size of the training set decreases. In fact, the worst constraint-violation rate we observe is 24%. Prior work has proposed an inefficient algorithm to enforce the constraint, which adds a factor of n to the decoding runtime. We adapt an algorithm due to Gabow and Tarjan (1984) to dependency parsing, which satisfies the constraint without compromising the original runtime. 1","mind root : decode arborescence dependency parsing connection dependency tree span tree exploit nlp community train decode graph - base dependency parser . , nlp literature miss important difference structure : edge emanate root dependency tree . analyze output state - - - art parser language universal dependency treebank : parser able learn tree violate constraint assign low probability , ability unsurprisingly degrade size training set decrease . fact , bad constraint - violation rate observe 24 % . prior work propose inefficient algorithm enforce constraint , add factor n decoding runtime . adapt algorithm gabow tarjan ( 1984 ) dependency parsing , satisfy constraint compromise original runtime . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 18, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
