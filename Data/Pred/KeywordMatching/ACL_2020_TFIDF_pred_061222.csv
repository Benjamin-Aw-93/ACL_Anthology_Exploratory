Labels,Paper Name,abstract,Text,Lemm Stemmed Text,Dictionary Output,Predicted Label,Label outcome
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Overestimation of Syntactic Representation in Neural Language Models,"With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.","Overestimation of Syntactic Representation in Neural Language Models With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.","overestimation syntactic representation neural language model advent powerful neural language model year , research attention increasingly focus aspect language represent successful . testing methodology develop probe model ' syntactic representation . popular method determine model ability induce syntactic structure train model string generate accord template test model ability distinguish string superficially similar one different syntax . illustrate fundamental problem approach reproduce positive result recent paper non - syntactic baseline language model : n - gram model lstm model train scrambled input .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",True
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals,"Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.","Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.","inflect majority : limitation encoder - decoder neural network cognitive model german plural artificial neural network learn represent inflectional morphology generalize new word human speaker ? kirov cotterell ( 2018 ) argue answer yes : modern encoder - decoder ( ed ) architecture learn human - like behavior inflect english verb , extend regular past tense form /-(e)d/ novel word . , work address criticism raise marcus et al . ( 1995 ) : neural model learn extend regular , frequent class -and fail task like german number inflection , infrequent suffix like /-s/ productively generalize . investigate question , collect new dataset german speaker ( production rating plural form novel noun ) design avoid source information unavailable ed model . speaker datum high variability , suffix evince ' regular ' behavior , appear phonologically atypical input . encoder - decoder model generalize frequently produce plural class , human - like variability ' regular ' extension plural marker . conclude modern neural model struggle minority - class generalization .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 2, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",A Systematic Assessment of Syntactic Generalization in Neural Language Models,"While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.","A Systematic Assessment of Syntactic Generalization in Neural Language Models While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.","systematic assessment syntactic generalization neural language model state - - - art neural network model continue achieve low perplexity score language modeling benchmark , remain unknown optimize broad - coverage predictive performance lead human - like syntactic knowledge . furthermore , exist work provide clear picture model property require produce proper syntactic generalization . present systematic evaluation syntactic knowledge neural language model , test 20 combination model type data size set 34 english - language syntactic test suite . find substantial difference syntactic generalization performance model architecture , sequential model underperform architecture . factorially manipulate model architecture training dataset size ( 1m-40 m word ) , find variability syntactic generalization performance substantially great architecture dataset size corpus test experiment . result reveal dissociation perplexity syntactic generalization performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 13, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",True
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts,"Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.","Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.","predict depression screening interview latent categorization interview prompt despite pervasiveness clinical depression modern society , professional help remain highly stigmatized , inaccessible , expensive . accurately diagnose depression difficult - require time - intensive interview , assessment , analysis . , automate method assess linguistic pattern interview help psychiatric professional fast , informed decision diagnosis . propose jlpc , method analyze interview transcript identify depression jointly categorize interview prompt latent category . latent categorization allow model identify high - level conversational context influence pattern language depressed individual . propose model outperform competitive baseline , latent prompt category provide psycholinguistic insight depression .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 11, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",True
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Probing Linguistic Systematicity,"Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.","Probing Linguistic Systematicity Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.","probe linguistic systematicity recently , interest question deep natural language understanding model exhibit systematicitygeneralizing unit like word consistent contribution meaning sentence appear . accumulate evidence neural model generalize non - systematically . examine notion systematicity linguistic perspective , define set probe set metric measure systematic behaviour . identify way network architecture generalize non - systematically , discuss form generalization unsatisfying . case study , perform series experiment setting natural language inference ( nli ) , demonstrate nlu system achieve high overall performance despite non - systematic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 8, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction,"Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only predictions (i.e. predicting the time to read a single word). We seek to extend these works by examining whether or not document level predictions are effective, given additional information such as subject matter, font characteristics, and readability metrics. We perform a novel experiment to examine how different features of text contribute to the time it takes to read, distributing and collecting data from over a thousand participants. We then employ a large number of machine learning methods to predict a user's reading time. We find that despite extensive research showing that word level reading time can be most effectively predicted by neural networks, larger scale text can be easily and most accurately predicted by one factor, the number of words.","You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only predictions (i.e. predicting the time to read a single word). We seek to extend these works by examining whether or not document level predictions are effective, given additional information such as subject matter, font characteristics, and readability metrics. We perform a novel experiment to examine how different features of text contribute to the time it takes to read, distributing and collecting data from over a thousand participants. We then employ a large number of machine learning methods to predict a user's reading time. We find that despite extensive research showing that word level reading time can be most effectively predicted by neural networks, larger scale text can be easily and most accurately predicted by one factor, the number of words.","time read : exploration document reading time prediction predict reading time subject previous work , focus different word affect human processing , measure reading time . , previous work deal limited number participant word level prediction ( i.e. predict time read single word ) . seek extend work examine document level prediction effective , give additional information subject matter , font characteristic , readability metric . perform novel experiment examine different feature text contribute time take read , distribute collect datum thousand participant . employ large number machine learning method predict user reading time . find despite extensive research show word level reading time effectively predict neural network , large scale text easily accurately predict factor , number word .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 5, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Learning to Understand Child-directed and Adult-directed Speech,"Speech directed to children differs from adultdirected speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.","Learning to Understand Child-directed and Adult-directed Speech Speech directed to children differs from adultdirected speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.","learn understand child - direct adult - direct speech speech direct child differ adultdirected speech linguistic aspect repetition , word choice , sentence length , aspect speech signal , prosodic phonemic variation . human language acquisition research indicate child - direct speech help language learner . study explore effect child - direct speech learn extract semantic information speech directly . compare task performance model train adult - direct speech ( ads ) child - direct speech ( cds ) . find indication cds help initial stage learning , eventually , model train ads reach comparable task performance , generalize well . result suggest partially linguistic acoustic property register , pattern look model train acoustically comparable synthetic speech .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 20, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 10, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",True
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Speakers enhance contextually confusable words,"Recent work has found evidence that natural languages are shaped by pressures for efficient communication -e.g. the more contextually predictable a word is, the fewer speech sounds or syllables it has (Piantadosi et al. 2011 ). Research on the degree to which speech and language are shaped by pressures for effective communication -robustness in the face of noise and uncertainty -has been more equivocal. We develop a measure of contextual confusability during word recognition based on psychoacoustic data. Applying this measure to naturalistic speech corpora, we find evidence suggesting that speakers alter their productions to make contextually more confusable words easier to understand.","Speakers enhance contextually confusable words Recent work has found evidence that natural languages are shaped by pressures for efficient communication -e.g. the more contextually predictable a word is, the fewer speech sounds or syllables it has (Piantadosi et al. 2011 ). Research on the degree to which speech and language are shaped by pressures for effective communication -robustness in the face of noise and uncertainty -has been more equivocal. We develop a measure of contextual confusability during word recognition based on psychoacoustic data. Applying this measure to naturalistic speech corpora, we find evidence suggesting that speakers alter their productions to make contextually more confusable words easier to understand.","speaker enhance contextually confusable word recent work find evidence natural language shape pressure efficient communication -e.g . contextually predictable word , few speech sound syllable ( piantadosi et al . 2011 ) . research degree speech language shape pressure effective communication -robustness face noise uncertainty -ha equivocal . develop measure contextual confusability word recognition base psychoacoustic datum . apply measure naturalistic speech corpora , find evidence suggest speaker alter production contextually confusable word easy understand .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment,"A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.","Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.","recurrent neural network language model learn english - like relative clause attachment standard approach evaluate language model analyze model assign probability valid versus invalid syntactic construction ( i.e. grammatical sentence probable ungrammatical sentence ) . work use ambiguous relative clause attachment extend evaluation case multiple simultaneous valid interpretation , stark grammaticality difference absent . compare model performance english spanish non - linguistic bias rnn lms advantageously overlap syntactic structure english spanish . , english model appear acquire human - like syntactic preference , model train spanish fail acquire comparable human - like preference . conclude relate result broad concern relationship comprehension ( i.e. typical language model use case ) production ( generate training datum language model ) , suggest necessary linguistic bias present training signal .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,False
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models,"We investigate the use of NLP as a measure of the cognitive processes involved in storytelling, contrasting imagination and recollection of events. To facilitate this, we collect and release HIPPOCORPUS, a dataset of 7,000 stories about imagined and recalled events. We introduce a measure of narrative flow and use this to examine the narratives for imagined and recalled events. Additionally, we measure the differential recruitment of knowledge attributed to semantic memory versus episodic memory (Tulving, 1972) for imagined and recalled storytelling by comparing the frequency of descriptions of general commonsense events with more specific realis events. Our analyses show that imagined stories have a substantially more linear narrative flow, compared to recalled stories in which adjacent sentences are more disconnected. In addition, while recalled stories rely more on autobiographical events based on episodic memory, imagined stories express more commonsense knowledge based on semantic memory. Finally, our measures reveal the effect of narrativization of memories in stories (e.g., stories about frequently recalled memories flow more linearly; Bartlett, 1932) . Our findings highlight the potential of using NLP tools to study the traces of human cognition in language.","Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models We investigate the use of NLP as a measure of the cognitive processes involved in storytelling, contrasting imagination and recollection of events. To facilitate this, we collect and release HIPPOCORPUS, a dataset of 7,000 stories about imagined and recalled events. We introduce a measure of narrative flow and use this to examine the narratives for imagined and recalled events. Additionally, we measure the differential recruitment of knowledge attributed to semantic memory versus episodic memory (Tulving, 1972) for imagined and recalled storytelling by comparing the frequency of descriptions of general commonsense events with more specific realis events. Our analyses show that imagined stories have a substantially more linear narrative flow, compared to recalled stories in which adjacent sentences are more disconnected. In addition, while recalled stories rely more on autobiographical events based on episodic memory, imagined stories express more commonsense knowledge based on semantic memory. Finally, our measures reveal the effect of narrativization of memories in stories (e.g., stories about frequently recalled memories flow more linearly; Bartlett, 1932) . Our findings highlight the potential of using NLP tools to study the traces of human cognition in language.","recollection versus imagination : explore human memory cognition neural language model investigate use nlp measure cognitive process involve storytelling , contrast imagination recollection event . facilitate , collect release hippocorpus , dataset 7,000 story imagine recall event . introduce measure narrative flow use examine narrative imagine recall event . additionally , measure differential recruitment knowledge attribute semantic memory versus episodic memory ( tulving , 1972 ) imagine recall storytelling compare frequency description general commonsense event specific realis event . analysis imagine story substantially linear narrative flow , compare recall story adjacent sentence disconnected . addition , recall story rely autobiographical event base episodic memory , imagine story express commonsense knowledge base semantic memory . finally , measure reveal effect narrativization memory story ( e.g. , story frequently recall memory flow linearly ; bartlett , 1932 ) . finding highlight potential nlp tool study trace human cognition language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 11, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",True
"Linguistic Theories, Cognitive Modeling and Psycholinguistics",What determines the order of adjectives in English? Comparing efficiency-based theories using dependency treebanks,"We take up the scientific question of what determines the preferred order of adjectives in English, in phrases such as big blue box where multiple adjectives modify a following noun. We implement and test four quantitative theories, all of which are theoretically motivated in terms of efficiency in human language production and comprehension. The four theories we test are subjectivity (Scontras et al., 2017) , information locality (Futrell, 2019), integration cost (Dyer, 2017), and information gain, which we introduce. We evaluate theories based on their ability to predict orders of unseen adjectives in hand-parsed and automatically-parsed dependency treebanks. We find that subjectivity, information locality, and information gain are all strong predictors, with some evidence for a two-factor account, where subjectivity and information gain reflect a factor involving semantics, and information locality reflects collocational preferences.","What determines the order of adjectives in English? Comparing efficiency-based theories using dependency treebanks We take up the scientific question of what determines the preferred order of adjectives in English, in phrases such as big blue box where multiple adjectives modify a following noun. We implement and test four quantitative theories, all of which are theoretically motivated in terms of efficiency in human language production and comprehension. The four theories we test are subjectivity (Scontras et al., 2017) , information locality (Futrell, 2019), integration cost (Dyer, 2017), and information gain, which we introduce. We evaluate theories based on their ability to predict orders of unseen adjectives in hand-parsed and automatically-parsed dependency treebanks. We find that subjectivity, information locality, and information gain are all strong predictors, with some evidence for a two-factor account, where subjectivity and information gain reflect a factor involving semantics, and information locality reflects collocational preferences.","determine order adjective english ? compare efficiency - base theory dependency treebanks scientific question determine prefer order adjective english , phrase big blue box multiple adjective modify follow noun . implement test quantitative theory , theoretically motivate term efficiency human language production comprehension . theory test subjectivity ( scontras et al . , 2017 ) , information locality ( futrell , 2019 ) , integration cost ( dyer , 2017 ) , information gain , introduce . evaluate theory base ability predict order unseen adjective hand - parse automatically - parse dependency treebank . find subjectivity , information locality , information gain strong predictor , evidence - factor account , subjectivity information gain reflect factor involve semantic , information locality reflect collocational preference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 2, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Phonology, Morphology and Word Segmentation",False
Computational Social Science and Social Media,"Code-Switching Patterns Can Be an Effective Route to Improve Performance of Downstream NLP Applications: A Case Study of Humour, Sarcasm and Hate Speech Detection","In this paper we demonstrate how codeswitching patterns can be utilised to improve various downstream NLP applications. In particular, we encode different switching features to improve humour, sarcasm and hate speech detection tasks. We believe that this simple linguistic observation can also be potentially helpful in improving other similar NLP applications.","Code-Switching Patterns Can Be an Effective Route to Improve Performance of Downstream NLP Applications: A Case Study of Humour, Sarcasm and Hate Speech Detection In this paper we demonstrate how codeswitching patterns can be utilised to improve various downstream NLP applications. In particular, we encode different switching features to improve humour, sarcasm and hate speech detection tasks. We believe that this simple linguistic observation can also be potentially helpful in improving other similar NLP applications.","code - switching pattern effective route improve performance downstream nlp application : case study humour , sarcasm hate speech detection paper demonstrate codeswitching pattern utilise improve downstream nlp application . particular , encode different switching feature improve humour , sarcasm hate speech detection task . believe simple linguistic observation potentially helpful improve similar nlp application .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Computational Social Science and Social Media,Analyzing Political Parody in Social Media,"Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts. In this paper, we present the first computational study of parody. We introduce a new publicly available data set of tweets from real politicians and their corresponding parody accounts. We run a battery of supervised machine learning models for automatically detecting parody tweets with an emphasis on robustness by testing on tweets from accounts unseen in training, across different genders and across countries. Our results show that political parody tweets can be predicted with an accuracy up to 90%. Finally, we identify the markers of parody through a linguistic analysis. Beyond research in linguistics and political communication, accurately and automatically detecting parody is important to improving fact checking for journalists and analytics such as sentiment analysis through filtering out parodical utterances. 1 * Equal contribution. â€  Work was done while at the University of Sheffield. 1 Data is available here: https://archive.org/de tails/parody data acl20 2 The 'Kapou Opa' column by K. Maniatis parodying Greek popular persons was a source of inspiration for this workhttps://www.oneman.gr/originals/to -imerologio-karantinas-tou-dimitri-kouts oumpa/","Analyzing Political Parody in Social Media Parody is a figurative device used to imitate an entity for comedic or critical purposes and represents a widespread phenomenon in social media through many popular parody accounts. In this paper, we present the first computational study of parody. We introduce a new publicly available data set of tweets from real politicians and their corresponding parody accounts. We run a battery of supervised machine learning models for automatically detecting parody tweets with an emphasis on robustness by testing on tweets from accounts unseen in training, across different genders and across countries. Our results show that political parody tweets can be predicted with an accuracy up to 90%. Finally, we identify the markers of parody through a linguistic analysis. Beyond research in linguistics and political communication, accurately and automatically detecting parody is important to improving fact checking for journalists and analytics such as sentiment analysis through filtering out parodical utterances. 1 * Equal contribution. â€  Work was done while at the University of Sheffield. 1 Data is available here: https://archive.org/de tails/parody data acl20 2 The 'Kapou Opa' column by K. Maniatis parodying Greek popular persons was a source of inspiration for this workhttps://www.oneman.gr/originals/to -imerologio-karantinas-tou-dimitri-kouts oumpa/","analyze political parody social media parody figurative device imitate entity comedic critical purpose represent widespread phenomenon social medium popular parody account . paper , present computational study parody . introduce new publicly available data set tweet real politician correspond parody account . run battery supervised machine learning model automatically detect parody tweet emphasis robustness test tweet account unseen training , different gender country . result political parody tweet predict accuracy 90 % . finally , identify marker parody linguistic analysis . research linguistic political communication , accurately automatically detect parody important improve fact checking journalist analytic sentiment analysis filter parodical utterance . 1 * equal contribution . â€  work university sheffield . 1 data available : https://archive.org/de tails / parody datum acl20 2 ' kapou opa ' column k. maniatis parody greek popular person source inspiration workhttps://www.oneman.gr/originals/to -imerologio - karantinas - tou - dimitri - kouts oumpa/","{'Computational Social Science and Social Media': 22, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Understanding the Language of Political Agreement and Disagreement in Legislative Texts,"While national politics often receive the spotlight, the overwhelming majority of legislation proposed, discussed, and enacted is done at the state level. Despite this fact, there is little awareness of the dynamics that lead to adopting these policies. In this paper, we take the first step towards a better understanding of these processes and the underlying dynamics that shape them, using data-driven methods. We build a new large-scale dataset, from multiple data sources, connecting state bills and legislator information, geographical information about their districts, and donations and donors' information. We suggest a novel task, predicting the legislative body's vote breakdown for a given bill, according to different criteria of interest, such as gender, rural-urban and ideological splits. Finally, we suggest a shared relational embedding model, representing the interactions between the text of the bill and the legislative context in which it is presented. Our experiments show that providing this context helps improve the prediction over strong text-based models.","Understanding the Language of Political Agreement and Disagreement in Legislative Texts While national politics often receive the spotlight, the overwhelming majority of legislation proposed, discussed, and enacted is done at the state level. Despite this fact, there is little awareness of the dynamics that lead to adopting these policies. In this paper, we take the first step towards a better understanding of these processes and the underlying dynamics that shape them, using data-driven methods. We build a new large-scale dataset, from multiple data sources, connecting state bills and legislator information, geographical information about their districts, and donations and donors' information. We suggest a novel task, predicting the legislative body's vote breakdown for a given bill, according to different criteria of interest, such as gender, rural-urban and ideological splits. Finally, we suggest a shared relational embedding model, representing the interactions between the text of the bill and the legislative context in which it is presented. Our experiments show that providing this context helps improve the prediction over strong text-based models.","understand language political agreement disagreement legislative text national politic receive spotlight , overwhelming majority legislation propose , discuss , enact state level . despite fact , little awareness dynamic lead adopt policy . paper , step well understanding process underlie dynamic shape , data - drive method . build new large - scale dataset , multiple data source , connect state bill legislator information , geographical information district , donation donor ' information . suggest novel task , predict legislative body vote breakdown give bill , accord different criterion interest , gender , rural - urban ideological split . finally , suggest share relational embedding model , represent interaction text bill legislative context present . experiment provide context help improve prediction strong text - base model .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 6, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Computational Social Science and Social Media,Integrating Semantic and Structural Information with Graph Convolutional Network for Controversy Detection,"Identifying controversial posts on social media is a fundamental task for mining public sentiment, assessing the influence of events, and alleviating the polarized views. However, existing methods fail to 1) effectively incorporate the semantic information from contentrelated posts; 2) preserve the structural information for reply relationship modeling; 3) properly handle posts from topics dissimilar to those in the training set. To overcome the first two limitations, we propose Topic-Post-Comment Graph Convolutional Network (TPC-GCN), which integrates the information from the graph structure and content of topics, posts, and comments for post-level controversy detection. As to the third limitation, we extend our model to Disentangled TPC-GCN (DTPC-GCN), to disentangle topic-related and topic-unrelated features and then fuse dynamically. Extensive experiments on two realworld datasets demonstrate that our models outperform existing methods. Analysis of the results and cases proves that our models can integrate both semantic and structural information with significant generalizability.","Integrating Semantic and Structural Information with Graph Convolutional Network for Controversy Detection Identifying controversial posts on social media is a fundamental task for mining public sentiment, assessing the influence of events, and alleviating the polarized views. However, existing methods fail to 1) effectively incorporate the semantic information from contentrelated posts; 2) preserve the structural information for reply relationship modeling; 3) properly handle posts from topics dissimilar to those in the training set. To overcome the first two limitations, we propose Topic-Post-Comment Graph Convolutional Network (TPC-GCN), which integrates the information from the graph structure and content of topics, posts, and comments for post-level controversy detection. As to the third limitation, we extend our model to Disentangled TPC-GCN (DTPC-GCN), to disentangle topic-related and topic-unrelated features and then fuse dynamically. Extensive experiments on two realworld datasets demonstrate that our models outperform existing methods. Analysis of the results and cases proves that our models can integrate both semantic and structural information with significant generalizability.","integrate semantic structural information graph convolutional network controversy detection identify controversial post social medium fundamental task mine public sentiment , assess influence event , alleviate polarized view . , exist method fail 1 ) effectively incorporate semantic information contentrelated post ; 2 ) preserve structural information reply relationship modeling ; 3 ) properly handle post topic dissimilar training set . overcome limitation , propose topic - post - comment graph convolutional network ( tpc - gcn ) , integrate information graph structure content topic , post , comment post - level controversy detection . limitation , extend model disentangled tpc - gcn ( dtpc - gcn ) , disentangle topic - relate topic - unrelated feature fuse dynamically . extensive experiment realworld dataset demonstrate model outperform exist method . analysis result case prove model integrate semantic structural information significant generalizability .","{'Computational Social Science and Social Media': 9, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Measuring Forecasting Skill from Text,"People vary in their ability to make accurate predictions about the future. Prior studies have shown that some individuals can predict the outcome of future events with consistently better accuracy. This leads to a natural question: what makes some forecasters better than others? In this paper we explore connections between the language people use to describe their predictions and their forecasting skill. Datasets from two different forecasting domains are explored: (1) geopolitical forecasts from Good Judgment Open, an online prediction forum and (2) a corpus of company earnings forecasts made by financial analysts. We present a number of linguistic metrics which are computed over text associated with people's predictions about the future including: uncertainty, readability, and emotion. By studying linguistic factors associated with predictions, we are able to shed some light on the approach taken by skilled forecasters. Furthermore, we demonstrate that it is possible to accurately predict forecasting skill using a model that is based solely on language. This could potentially be useful for identifying accurate predictions or potentially skilled forecasters earlier. 1","Measuring Forecasting Skill from Text People vary in their ability to make accurate predictions about the future. Prior studies have shown that some individuals can predict the outcome of future events with consistently better accuracy. This leads to a natural question: what makes some forecasters better than others? In this paper we explore connections between the language people use to describe their predictions and their forecasting skill. Datasets from two different forecasting domains are explored: (1) geopolitical forecasts from Good Judgment Open, an online prediction forum and (2) a corpus of company earnings forecasts made by financial analysts. We present a number of linguistic metrics which are computed over text associated with people's predictions about the future including: uncertainty, readability, and emotion. By studying linguistic factors associated with predictions, we are able to shed some light on the approach taken by skilled forecasters. Furthermore, we demonstrate that it is possible to accurately predict forecasting skill using a model that is based solely on language. This could potentially be useful for identifying accurate predictions or potentially skilled forecasters earlier. 1","measure forecasting skill text people vary ability accurate prediction future . prior study show individual predict outcome future event consistently well accuracy . lead natural question : make forecaster well ? paper explore connection language people use describe prediction forecasting skill . dataset different forecasting domain explore : ( 1 ) geopolitical forecast good judgment open , online prediction forum ( 2 ) corpus company earning forecast financial analyst . present number linguistic metric compute text associate people prediction future include : uncertainty , readability , emotion . study linguistic factor associate prediction , able shed light approach take skilled forecaster . furthermore , demonstrate possible accurately predict forecasting skill model base solely language . potentially useful identify accurate prediction potentially skilled forecaster early . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Computational Social Science and Social Media,"Stock Embeddings Acquired from News Articles and Price History, and an Application to Portfolio Optimization","Previous works that integrated news articles to better process stock prices used a variety of neural networks to predict price movements. The textual and price information were both encoded in the neural network, and it is therefore difficult to apply this approach in situations other than the original framework of the notoriously hard problem of price prediction. In contrast, this paper presents a method to encode the influence of news articles through a vector representation of stocks called a stock embedding. The stock embedding is acquired with a deep learning framework using both news articles and price history. Because the embedding takes the operational form of a vector, it is applicable to other financial problems besides price prediction. As one example application, we show the results of portfolio optimization using Reuters & Bloomberg headlines, producing a capital gain 2.8 times larger than that obtained with a baseline method using only stock price data. This suggests that the proposed stock embedding can leverage textual financial semantics to solve financial prediction problems.","Stock Embeddings Acquired from News Articles and Price History, and an Application to Portfolio Optimization Previous works that integrated news articles to better process stock prices used a variety of neural networks to predict price movements. The textual and price information were both encoded in the neural network, and it is therefore difficult to apply this approach in situations other than the original framework of the notoriously hard problem of price prediction. In contrast, this paper presents a method to encode the influence of news articles through a vector representation of stocks called a stock embedding. The stock embedding is acquired with a deep learning framework using both news articles and price history. Because the embedding takes the operational form of a vector, it is applicable to other financial problems besides price prediction. As one example application, we show the results of portfolio optimization using Reuters & Bloomberg headlines, producing a capital gain 2.8 times larger than that obtained with a baseline method using only stock price data. This suggests that the proposed stock embedding can leverage textual financial semantics to solve financial prediction problems.","stock embedding acquire news article price history , application portfolio optimization previous work integrate news article well process stock price variety neural network predict price movement . textual price information encode neural network , difficult apply approach situation original framework notoriously hard problem price prediction . contrast , paper present method encode influence news article vector representation stock call stock embedding . stock embedding acquire deep learning framework news article price history . embedding take operational form vector , applicable financial problem price prediction . example application , result portfolio optimization reuters & bloomberg headline , produce capital gain 2.8 time large obtain baseline method stock price datum . suggest propose stock embedding leverage textual financial semantic solve financial prediction problem .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 8, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Computational Social Science and Social Media,Neural Temporal Opinion Modelling for Opinion Prediction on Twitter,"Opinion prediction on Twitter is challenging due to the transient nature of tweet content and neighbourhood context. In this paper, we model users' tweet posting behaviour as a temporal point process to jointly predict the posting time and the stance label of the next tweet given a user's historical tweet sequence and tweets posted by their neighbours. We design a topic-driven attention mechanism to capture the dynamic topic shifts in the neighbourhood context. Experimental results show that the proposed model predicts both the posting time and the stance labels of future tweets more accurately compared to a number of competitive baselines.","Neural Temporal Opinion Modelling for Opinion Prediction on Twitter Opinion prediction on Twitter is challenging due to the transient nature of tweet content and neighbourhood context. In this paper, we model users' tweet posting behaviour as a temporal point process to jointly predict the posting time and the stance label of the next tweet given a user's historical tweet sequence and tweets posted by their neighbours. We design a topic-driven attention mechanism to capture the dynamic topic shifts in the neighbourhood context. Experimental results show that the proposed model predicts both the posting time and the stance labels of future tweets more accurately compared to a number of competitive baselines.","neural temporal opinion modelling opinion prediction twitter opinion prediction twitter challenging transient nature tweet content neighbourhood context . paper , model user ' tweet posting behaviour temporal point process jointly predict posting time stance label tweet give user historical tweet sequence tweet post neighbour . design topic - drive attention mechanism capture dynamic topic shift neighbourhood context . experimental result propose model predict posting time stance label future tweet accurately compare number competitive baseline .","{'Computational Social Science and Social Media': 10, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Masking Actor Information Leads to Fairer Political Claims Detection,"A central concern in Computational Social Sciences (CSS) is fairness: where the role of NLP is to scale up text analysis to large corpora, the quality of automatic analyses should be as independent as possible of textual properties. We analyze the performance of a state-of-theart neural model on the task of political claims detection (i.e., the identification of forwardlooking statements made by political actors) and identify a strong frequency bias: claims made by frequent actors are recognized better. We propose two simple debiasing methods which mask proper names and pronouns during training of the model, thus removing personal information bias. We find that (a) these methods significantly decrease frequency bias while keeping the overall performance stable; and (b) the resulting models improve when evaluated in an out-of-domain setting.","Masking Actor Information Leads to Fairer Political Claims Detection A central concern in Computational Social Sciences (CSS) is fairness: where the role of NLP is to scale up text analysis to large corpora, the quality of automatic analyses should be as independent as possible of textual properties. We analyze the performance of a state-of-theart neural model on the task of political claims detection (i.e., the identification of forwardlooking statements made by political actors) and identify a strong frequency bias: claims made by frequent actors are recognized better. We propose two simple debiasing methods which mask proper names and pronouns during training of the model, thus removing personal information bias. We find that (a) these methods significantly decrease frequency bias while keeping the overall performance stable; and (b) the resulting models improve when evaluated in an out-of-domain setting.","mask actor information lead fair political claim detection central concern computational social sciences ( css ) fairness : role nlp scale text analysis large corpora , quality automatic analysis independent possible textual property . analyze performance state - - theart neural model task political claim detection ( i.e. , identification forwardlooking statement political actor ) identify strong frequency bias : claim frequent actor recognize well . propose simple debiase method mask proper name pronoun training model , remove personal information bias . find ( ) method significantly decrease frequency bias keep overall performance stable ; ( b ) result model improve evaluate - - domain setting .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 6, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media,"This paper solves the fake news detection problem under a more realistic scenario on social media. Given the source short-text tweet and the corresponding sequence of retweet users without text comments, we aim at predicting whether the source tweet is fake or not, and generating explanation by highlighting the evidences on suspicious retweeters and the words they concern. We develop a novel neural network-based model, Graph-aware Co-Attention Networks (GCAN), to achieve the goal. Extensive experiments conducted on real tweet datasets exhibit that GCAN can significantly outperform state-of-the-art methods by 16% in accuracy on average. In addition, the case studies also show that GCAN can produce reasonable explanations.","GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media This paper solves the fake news detection problem under a more realistic scenario on social media. Given the source short-text tweet and the corresponding sequence of retweet users without text comments, we aim at predicting whether the source tweet is fake or not, and generating explanation by highlighting the evidences on suspicious retweeters and the words they concern. We develop a novel neural network-based model, Graph-aware Co-Attention Networks (GCAN), to achieve the goal. Extensive experiments conducted on real tweet datasets exhibit that GCAN can significantly outperform state-of-the-art methods by 16% in accuracy on average. In addition, the case studies also show that GCAN can produce reasonable explanations.","gcan : graph - aware co - attention networks explainable fake news detection social medium paper solve fake news detection problem realistic scenario social medium . give source short - text tweet corresponding sequence retweet user text comment , aim predict source tweet fake , generate explanation highlight evidence suspicious retweeter word concern . develop novel neural network - base model , graph - aware co - attention networks ( gcan ) , achieve goal . extensive experiment conduct real tweet dataset exhibit gcan significantly outperform state - - - art method 16 % accuracy average . addition , case study gcan produce reasonable explanation .","{'Computational Social Science and Social Media': 11, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,"It Takes Two to Lie: One to Lie, and One to Listen","Trust is implicit in many online text conversations-striking up new friendships, or asking for tech support. But trust can be betrayed through deception. We study the language and dynamics of deception in the negotiation-based game Diplomacy, where seven players compete for world domination by forging and breaking alliances with each other. Our study with players from the Diplomacy community gathers 17,289 messages annotated by the sender for their intended truthfulness and by the receiver for their perceived truthfulness. Unlike existing datasets, this captures deception in long-lasting relationships, where the interlocutors strategically combine truth with lies to advance objectives. A model that uses power dynamics and conversational contexts can predict when a lie occurs nearly as well as human players.","It Takes Two to Lie: One to Lie, and One to Listen Trust is implicit in many online text conversations-striking up new friendships, or asking for tech support. But trust can be betrayed through deception. We study the language and dynamics of deception in the negotiation-based game Diplomacy, where seven players compete for world domination by forging and breaking alliances with each other. Our study with players from the Diplomacy community gathers 17,289 messages annotated by the sender for their intended truthfulness and by the receiver for their perceived truthfulness. Unlike existing datasets, this captures deception in long-lasting relationships, where the interlocutors strategically combine truth with lies to advance objectives. A model that uses power dynamics and conversational contexts can predict when a lie occurs nearly as well as human players.","take lie : lie , listen trust implicit online text conversation - strike new friendship , ask tech support . trust betray deception . study language dynamic deception negotiation - base game diplomacy , seven player compete world domination forge break alliance . study player diplomacy community gather 17,289 message annotate sender intend truthfulness receiver perceive truthfulness . unlike exist dataset , capture deception long - last relationship , interlocutor strategically combine truth lie advance objective . model use power dynamic conversational context predict lie occur nearly human player .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Computational Social Science and Social Media,Predicting the Topical Stance and Political Leaning of Media using Tweets,"Discovering the stances of media outlets and influential people on current, debatable topics is important for social statisticians and policy makers. Many supervised solutions exist for determining viewpoints, but manually annotating training data is costly. In this paper, we propose a cascaded method that uses unsupervised learning to ascertain the stance of Twitter users with respect to a polarizing topic by leveraging their retweet behavior; then, it uses supervised learning based on user labels to characterize both the general political leaning of online media and of popular Twitter users, as well as their stance with respect to the target polarizing topic. We evaluate the model by comparing its predictions to gold labels from the Media Bias/Fact Check website, achieving 82.6% accuracy.","Predicting the Topical Stance and Political Leaning of Media using Tweets Discovering the stances of media outlets and influential people on current, debatable topics is important for social statisticians and policy makers. Many supervised solutions exist for determining viewpoints, but manually annotating training data is costly. In this paper, we propose a cascaded method that uses unsupervised learning to ascertain the stance of Twitter users with respect to a polarizing topic by leveraging their retweet behavior; then, it uses supervised learning based on user labels to characterize both the general political leaning of online media and of popular Twitter users, as well as their stance with respect to the target polarizing topic. We evaluate the model by comparing its predictions to gold labels from the Media Bias/Fact Check website, achieving 82.6% accuracy.","predict topical stance political leaning medium tweet discover stance medium outlet influential people current , debatable topic important social statistician policy maker . supervise solution exist determine viewpoint , manually annotate training datum costly . paper , propose cascade method use unsupervised learning ascertain stance twitter user respect polarize topic leverage retweet behavior ; , use supervised learning base user label characterize general political leaning online medium popular twitter user , stance respect target polarize topic . evaluate model compare prediction gold label media bias / fact check website , achieve 82.6 % accuracy .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim Verification,"Recently, many methods discover effective evidence from reliable sources by appropriate neural networks for explainable claim verification, which has been widely recognized. However, in these methods, the discovery process of evidence is nontransparent and unexplained. Simultaneously, the discovered evidence only roughly aims at the interpretability of the whole sequence of claims but insufficient to focus on the false parts of claims. In this paper, we propose a Decision Tree-based Co-Attention model (DTCA) to discover evidence for explainable claim verification. Specifically, we first construct Decision Tree-based Evidence model (DTE) to select comments with high credibility as evidence in a transparent and interpretable way. Then we design Co-attention Self-attention networks (CaSa) to make the selected evidence interact with claims, which is for 1) training DTE to determine the optimal decision thresholds and obtain more powerful evidence; and 2) utilizing the evidence to find the false parts in the claim. Experiments on two public datasets, RumourEval and PHEME, demonstrate that DTCA not only provides explanations for the results of claim verification but also achieves the state-of-the-art performance, boosting the F1-score by 3.11%, 2.41%, respectively. 24 Compute loss L(Î˜) using Eq. (9,10); 25 Compute gradient âˆ‡(Î˜); 26 Update model: Î˜ â† Î˜ âˆ’ âˆ‡(Î˜); 27 End For 28 Update parameters a1, a2, a3; 29 Until a1 = 0.8, a2 = 0.8, and a3 = 0.7.","DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim Verification Recently, many methods discover effective evidence from reliable sources by appropriate neural networks for explainable claim verification, which has been widely recognized. However, in these methods, the discovery process of evidence is nontransparent and unexplained. Simultaneously, the discovered evidence only roughly aims at the interpretability of the whole sequence of claims but insufficient to focus on the false parts of claims. In this paper, we propose a Decision Tree-based Co-Attention model (DTCA) to discover evidence for explainable claim verification. Specifically, we first construct Decision Tree-based Evidence model (DTE) to select comments with high credibility as evidence in a transparent and interpretable way. Then we design Co-attention Self-attention networks (CaSa) to make the selected evidence interact with claims, which is for 1) training DTE to determine the optimal decision thresholds and obtain more powerful evidence; and 2) utilizing the evidence to find the false parts in the claim. Experiments on two public datasets, RumourEval and PHEME, demonstrate that DTCA not only provides explanations for the results of claim verification but also achieves the state-of-the-art performance, boosting the F1-score by 3.11%, 2.41%, respectively. 24 Compute loss L(Î˜) using Eq. (9,10); 25 Compute gradient âˆ‡(Î˜); 26 Update model: Î˜ â† Î˜ âˆ’ âˆ‡(Î˜); 27 End For 28 Update parameters a1, a2, a3; 29 Until a1 = 0.8, a2 = 0.8, and a3 = 0.7.","dtca : decision tree - base co - attention network explainable claim verification recently , method discover effective evidence reliable source appropriate neural network explainable claim verification , widely recognize . , method , discovery process evidence nontransparent unexplained . simultaneously , discover evidence roughly aim interpretability sequence claim insufficient focus false part claim . paper , propose decision tree - base co - attention model ( dtca ) discover evidence explainable claim verification . specifically , construct decision tree - base evidence model ( dte ) select comment high credibility evidence transparent interpretable way . design co - attention self - attention network ( casa ) select evidence interact claim , 1 ) train dte determine optimal decision threshold obtain powerful evidence ; 2 ) utilize evidence find false part claim . experiment public dataset , rumoureval pheme , demonstrate dtca provide explanation result claim verification achieve state - - - art performance , boost f1 - score 3.11 % , 2.41 % , respectively . 24 compute loss l(Î¸ ) eq . ( 9,10 ) ; 25 compute gradient âˆ‡(Î¸ ) ; 26 update model : Î¸ â† Î¸ âˆ’ âˆ‡(Î¸ ) ; 27 end 28 update parameter a1 , a2 , a3 ; 29 a1 = 0.8 , a2 = 0.8 , a3 = 0.7 .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer,"In this paper, we study Multimodal Named Entity Recognition (MNER) for social media posts. Existing approaches for MNER mainly suffer from two drawbacks: (1) despite generating word-aware visual representations, their word representations are insensitive to the visual context; (2) most of them ignore the bias brought by the visual context. To tackle the first issue, we propose a multimodal interaction module to obtain both image-aware word representations and word-aware visual representations. To alleviate the visual bias, we further propose to leverage purely text-based entity span detection as an auxiliary module, and design a Unified Multimodal Transformer to guide the final predictions with the entity span predictions. Experiments show that our unified approach achieves the new state-of-the-art performance on two benchmark datasets.","Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer In this paper, we study Multimodal Named Entity Recognition (MNER) for social media posts. Existing approaches for MNER mainly suffer from two drawbacks: (1) despite generating word-aware visual representations, their word representations are insensitive to the visual context; (2) most of them ignore the bias brought by the visual context. To tackle the first issue, we propose a multimodal interaction module to obtain both image-aware word representations and word-aware visual representations. To alleviate the visual bias, we further propose to leverage purely text-based entity span detection as an auxiliary module, and design a Unified Multimodal Transformer to guide the final predictions with the entity span predictions. Experiments show that our unified approach achieves the new state-of-the-art performance on two benchmark datasets.","improve multimodal name entity recognition entity span detection unified multimodal transformer paper , study multimodal name entity recognition ( mner ) social medium post . exist approach mner mainly suffer drawback : ( 1 ) despite generate word - aware visual representation , word representation insensitive visual context ; ( 2 ) ignore bias bring visual context . tackle issue , propose multimodal interaction module obtain image - aware word representation word - aware visual representation . alleviate visual bias , propose leverage purely text - base entity span detection auxiliary module , design unified multimodal transformer guide final prediction entity span prediction . experiment unify approach achieve new state - - - art performance benchmark dataset .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 4, 'Information Extraction': 16, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Computational Social Science and Social Media,"Simple, Interpretable and Stable Method for Detecting Words with Usage Change across Corpora","The problem of comparing two bodies of text and searching for words that differ in their usage between them arises often in digital humanities and computational social science. This is commonly approached by training word embeddings on each corpus, aligning the vector spaces, and looking for words whose cosine distance in the aligned space is large. However, these methods often require extensive filtering of the vocabulary to perform well, and-as we show in this work-result in unstable, and hence less reliable, results. We propose an alternative approach that does not use vector space alignment, and instead considers the neighbors of each word. The method is simple, interpretable and stable. We demonstrate its effectiveness in 9 different setups, considering different corpus splitting criteria (age, gender and profession of tweet authors, time of tweet) and different languages (English, French and Hebrew).","Simple, Interpretable and Stable Method for Detecting Words with Usage Change across Corpora The problem of comparing two bodies of text and searching for words that differ in their usage between them arises often in digital humanities and computational social science. This is commonly approached by training word embeddings on each corpus, aligning the vector spaces, and looking for words whose cosine distance in the aligned space is large. However, these methods often require extensive filtering of the vocabulary to perform well, and-as we show in this work-result in unstable, and hence less reliable, results. We propose an alternative approach that does not use vector space alignment, and instead considers the neighbors of each word. The method is simple, interpretable and stable. We demonstrate its effectiveness in 9 different setups, considering different corpus splitting criteria (age, gender and profession of tweet authors, time of tweet) and different languages (English, French and Hebrew).","simple , interpretable stable method detect word usage change corpora problem compare body text search word differ usage arise digital humanity computational social science . commonly approach train word embedding corpus , align vector space , look word cosine distance align space large . , method require extensive filtering vocabulary perform , - work - result unstable , reliable , result . propose alternative approach use vector space alignment , instead consider neighbor word . method simple , interpretable stable . demonstrate effectiveness 9 different setup , consider different corpus splitting criterion ( age , gender profession tweet author , time tweet ) different language ( english , french hebrew ) .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Computational Social Science and Social Media,What Was Written vs. Who Read It: News Media Profiling Using Text Analysis and Social Media Context,"Predicting the political bias and the factuality of reporting of entire news outlets are critical elements of media profiling, which is an understudied but an increasingly important research direction. The present level of proliferation of fake, biased, and propagandistic content online, has made it impossible to fact-check every single suspicious claim, either manually or automatically. Alternatively, we can profile entire news outlets and look for those that are likely to publish fake or biased content. This approach makes it possible to detect likely ""fake news"" the moment they are published, by simply checking the reliability of their source. From a practical perspective, political bias and factuality of reporting have a linguistic aspect but also a social context. Here, we study the impact of both, namely (i) what was written (i.e., what was published by the target medium, and how it describes itself on Twitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium on Facebook, Twitter, and YouTube). We further study (iii)  what was written about the target medium on Wikipedia. The evaluation results show that what was written matters most, and that putting all information sources together yields huge improvements over the current state-of-the-art.","What Was Written vs. Who Read It: News Media Profiling Using Text Analysis and Social Media Context Predicting the political bias and the factuality of reporting of entire news outlets are critical elements of media profiling, which is an understudied but an increasingly important research direction. The present level of proliferation of fake, biased, and propagandistic content online, has made it impossible to fact-check every single suspicious claim, either manually or automatically. Alternatively, we can profile entire news outlets and look for those that are likely to publish fake or biased content. This approach makes it possible to detect likely ""fake news"" the moment they are published, by simply checking the reliability of their source. From a practical perspective, political bias and factuality of reporting have a linguistic aspect but also a social context. Here, we study the impact of both, namely (i) what was written (i.e., what was published by the target medium, and how it describes itself on Twitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium on Facebook, Twitter, and YouTube). We further study (iii)  what was written about the target medium on Wikipedia. The evaluation results show that what was written matters most, and that putting all information sources together yields huge improvements over the current state-of-the-art.","write vs. read : news medium profiling text analysis social medium context predict political bias factuality reporting entire news outlet critical element medium profiling , understudied increasingly important research direction . present level proliferation fake , biased , propagandistic content online , impossible fact - check single suspicious claim , manually automatically . alternatively , profile entire news outlet look likely publish fake biased content . approach make possible detect likely "" fake news "" moment publish , simply check reliability source . practical perspective , political bias factuality reporting linguistic aspect social context . , study impact , ( ) write ( i.e. , publish target medium , describe twitter ) vs. ( ii ) read ( i.e. , analyze reader target medium facebook , twitter , youtube ) . study ( iii )   write target medium wikipedia . evaluation result write matter , put information source yield huge improvement current state - - - art .","{'Computational Social Science and Social Media': 12, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 6, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Balancing Objectives in Counseling Conversations: Advancing Forwards or Looking Backwards,"Throughout a conversation, participants make choices that can orient the flow of the interaction. Such choices are particularly salient in the consequential domain of crisis counseling, where a difficulty for counselors is balancing between two key objectives: advancing the conversation towards a resolution, and empathetically addressing the crisis situation. In this work, we develop an unsupervised methodology to quantify how counselors manage this balance. Our main intuition is that if an utterance can only receive a narrow range of appropriate replies, then its likely aim is to advance the conversation forwards, towards a target within that range. Likewise, an utterance that can only appropriately follow a narrow range of possible utterances is likely aimed backwards at addressing a specific situation within that range. By applying this intuition, we can map each utterance to a continuous orientation axis that captures the degree to which it is intended to direct the flow of the conversation forwards or backwards. This unsupervised method allows us to characterize counselor behaviors in a large dataset of crisis counseling conversations, where we show that known counseling strategies intuitively align with this axis. We also illustrate how our measure can be indicative of a conversation's progress, as well as its effectiveness.","Balancing Objectives in Counseling Conversations: Advancing Forwards or Looking Backwards Throughout a conversation, participants make choices that can orient the flow of the interaction. Such choices are particularly salient in the consequential domain of crisis counseling, where a difficulty for counselors is balancing between two key objectives: advancing the conversation towards a resolution, and empathetically addressing the crisis situation. In this work, we develop an unsupervised methodology to quantify how counselors manage this balance. Our main intuition is that if an utterance can only receive a narrow range of appropriate replies, then its likely aim is to advance the conversation forwards, towards a target within that range. Likewise, an utterance that can only appropriately follow a narrow range of possible utterances is likely aimed backwards at addressing a specific situation within that range. By applying this intuition, we can map each utterance to a continuous orientation axis that captures the degree to which it is intended to direct the flow of the conversation forwards or backwards. This unsupervised method allows us to characterize counselor behaviors in a large dataset of crisis counseling conversations, where we show that known counseling strategies intuitively align with this axis. We also illustrate how our measure can be indicative of a conversation's progress, as well as its effectiveness.","balance objective counseling conversation : advance forwards look backwards conversation , participant choice orient flow interaction . choice particularly salient consequential domain crisis counseling , difficulty counselor balance key objective : advance conversation resolution , empathetically address crisis situation . work , develop unsupervised methodology quantify counselor manage balance . main intuition utterance receive narrow range appropriate reply , likely aim advance conversation forwards , target range . likewise , utterance appropriately follow narrow range possible utterance likely aim backwards address specific situation range . apply intuition , map utterance continuous orientation axis capture degree intend direct flow conversation forwards backwards . unsupervised method allow characterize counselor behavior large dataset crisis counseling conversation , know counseling strategy intuitively align axis . illustrate measure indicative conversation progress , effectiveness .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Computational Social Science and Social Media,Dynamic Online Conversation Recommendation,"Trending topics in social media content evolve over time, and it is therefore crucial to understand social media users and their interpersonal communications in a dynamic manner. In this research we study dynamic online conversation recommendation, to help users engage in conversations that satisfy their evolving interests. Different from works in conversation recommendation which assume static user interests, our model captures the temporal aspects of user interests. Moreover, our model can cater for cold start problem where conversations are new and unseen in training. We propose a neural architecture to analyze changes of user interactions and interests over time, whose result is used to predict which discussions the users are likely to enter. We conduct experiments on large-scale collections of Reddit conversations. Results on three subreddits show that our model significantly outperforms state-of-the-art models based on static assumption of user interests. We further evaluate performance in cold start, and observe consistently better performance by our model when considering various degrees of sparsity of user's chatting history and conversation contexts. Lastly, our analysis also confirms the change of user interests. This further justify the advantage and efficacy of our model.","Dynamic Online Conversation Recommendation Trending topics in social media content evolve over time, and it is therefore crucial to understand social media users and their interpersonal communications in a dynamic manner. In this research we study dynamic online conversation recommendation, to help users engage in conversations that satisfy their evolving interests. Different from works in conversation recommendation which assume static user interests, our model captures the temporal aspects of user interests. Moreover, our model can cater for cold start problem where conversations are new and unseen in training. We propose a neural architecture to analyze changes of user interactions and interests over time, whose result is used to predict which discussions the users are likely to enter. We conduct experiments on large-scale collections of Reddit conversations. Results on three subreddits show that our model significantly outperforms state-of-the-art models based on static assumption of user interests. We further evaluate performance in cold start, and observe consistently better performance by our model when considering various degrees of sparsity of user's chatting history and conversation contexts. Lastly, our analysis also confirms the change of user interests. This further justify the advantage and efficacy of our model.","dynamic online conversation recommendation trend topic social medium content evolve time , crucial understand social medium user interpersonal communication dynamic manner . research study dynamic online conversation recommendation , help user engage conversation satisfy evolve interest . different work conversation recommendation assume static user interest , model capture temporal aspect user interest . , model cater cold start problem conversation new unseen training . propose neural architecture analyze change user interaction interest time , result predict discussion user likely enter . conduct experiment large - scale collection reddit conversation . result subreddit model significantly outperform state - - - art model base static assumption user interest . evaluate performance cold start , observe consistently well performance model consider degree sparsity user chatting history conversation context . lastly , analysis confirm change user interest . justify advantage efficacy model .","{'Computational Social Science and Social Media': 13, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 12, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 10, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Text and Causal Inference: A Review of Using Text to Remove Confounding from Causal Estimates,"Many applications of computational social science aim to infer causal conclusions from nonexperimental data. Such observational data often contains confounders, variables that influence both potential causes and potential effects. Unmeasured or latent confounders can bias causal estimates, and this has motivated interest in measuring potential confounders from observed text. For example, an individual's entire history of social media posts or the content of a news article could provide a rich measurement of multiple confounders. Yet, methods and applications for this problem are scattered across different communities and evaluation practices are inconsistent. This review is the first to gather and categorize these examples and provide a guide to dataprocessing and evaluation decisions. Despite increased attention on adjusting for confounding using text, there are still many open problems, which we highlight in this paper.","Text and Causal Inference: A Review of Using Text to Remove Confounding from Causal Estimates Many applications of computational social science aim to infer causal conclusions from nonexperimental data. Such observational data often contains confounders, variables that influence both potential causes and potential effects. Unmeasured or latent confounders can bias causal estimates, and this has motivated interest in measuring potential confounders from observed text. For example, an individual's entire history of social media posts or the content of a news article could provide a rich measurement of multiple confounders. Yet, methods and applications for this problem are scattered across different communities and evaluation practices are inconsistent. This review is the first to gather and categorize these examples and provide a guide to dataprocessing and evaluation decisions. Despite increased attention on adjusting for confounding using text, there are still many open problems, which we highlight in this paper.","text causal inference : review text remove confound causal estimate application computational social science aim infer causal conclusion nonexperimental datum . observational data contain confounder , variable influence potential cause potential effect . unmeasured latent confounder bias causal estimate , motivate interest measure potential confounder observed text . example , individual entire history social medium post content news article provide rich measurement multiple confounder . , method application problem scatter different community evaluation practice inconsistent . review gather categorize example provide guide dataprocessing evaluation decision . despite increase attention adjust confound text , open problem , highlight paper .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Text-Based Ideal Points,"Ideal point models analyze lawmakers' votes to quantify their political positions, or ideal points. But votes are not the only way to express a political position. Lawmakers also give speeches, release press statements, and post tweets. In this paper, we introduce the text-based ideal point model ( ), an unsupervised probabilistic topic model that analyzes texts to quantify the political positions of its authors. We demonstrate the with two types of politicized text data: U.S. Senate speeches and senator tweets. Though the model does not analyze their votes or political affiliations, the separates lawmakers by party, learns interpretable politicized topics, and infers ideal points close to the classical vote-based ideal points. One benefit of analyzing texts, as opposed to votes, is that the can estimate ideal points of anyone who authors political texts, including non-voting actors. To this end, we use it to study tweets from the 2020 Democratic presidential candidates. Using only the texts of their tweets, it identifies them along an interpretable progressive-tomoderate spectrum.","Text-Based Ideal Points Ideal point models analyze lawmakers' votes to quantify their political positions, or ideal points. But votes are not the only way to express a political position. Lawmakers also give speeches, release press statements, and post tweets. In this paper, we introduce the text-based ideal point model ( ), an unsupervised probabilistic topic model that analyzes texts to quantify the political positions of its authors. We demonstrate the with two types of politicized text data: U.S. Senate speeches and senator tweets. Though the model does not analyze their votes or political affiliations, the separates lawmakers by party, learns interpretable politicized topics, and infers ideal points close to the classical vote-based ideal points. One benefit of analyzing texts, as opposed to votes, is that the can estimate ideal points of anyone who authors political texts, including non-voting actors. To this end, we use it to study tweets from the 2020 Democratic presidential candidates. Using only the texts of their tweets, it identifies them along an interpretable progressive-tomoderate spectrum.","text - base ideal point ideal point model analyze lawmaker ' vote quantify political position , ideal point . vote way express political position . lawmaker speech , release press statement , post tweet . paper , introduce text - base ideal point model ( ) , unsupervised probabilistic topic model analyze text quantify political position author . demonstrate type politicized text datum : u.s. senate speech senator tweet . model analyze vote political affiliation , separate lawmaker party , learn interpretable politicized topic , infer ideal point close classical vote - base ideal point . benefit analyze text , oppose vote , estimate ideal point author political text , include non - voting actor . end , use study tweet 2020 democratic presidential candidate . text tweet , identify interpretable progressive - tomoderate spectrum .","{'Computational Social Science and Social Media': 10, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 7, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,True
Computational Social Science and Social Media,Detecting Perceived Emotions in Hurricane Disasters,"Natural disasters (e.g., hurricanes) affect millions of people each year, causing widespread destruction in their wake. People have recently taken to social media websites (e.g., Twitter) to share their sentiments and feelings with the larger community. Consequently, these platforms have become instrumental in understanding and perceiving emotions at scale. In this paper, we introduce HURRICANEEMO, an emotion dataset of 15,000 English tweets spanning three hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of fine-grained emotions and propose classification tasks to discriminate between coarsegrained emotion groups. Our best BERT (Devlin et al., 2019) model, even after task-guided pre-training which leverages unlabeled Twitter data, achieves only 68% accuracy (averaged across all groups). HURRICANEEMO serves not only as a challenging benchmark for models but also as a valuable resource for analyzing emotions in disaster-centric domains.","Detecting Perceived Emotions in Hurricane Disasters Natural disasters (e.g., hurricanes) affect millions of people each year, causing widespread destruction in their wake. People have recently taken to social media websites (e.g., Twitter) to share their sentiments and feelings with the larger community. Consequently, these platforms have become instrumental in understanding and perceiving emotions at scale. In this paper, we introduce HURRICANEEMO, an emotion dataset of 15,000 English tweets spanning three hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of fine-grained emotions and propose classification tasks to discriminate between coarsegrained emotion groups. Our best BERT (Devlin et al., 2019) model, even after task-guided pre-training which leverages unlabeled Twitter data, achieves only 68% accuracy (averaged across all groups). HURRICANEEMO serves not only as a challenging benchmark for models but also as a valuable resource for analyzing emotions in disaster-centric domains.","detect perceive emotion hurricane disaster natural disaster ( e.g. , hurricane ) affect million people year , cause widespread destruction wake . people recently take social medium website ( e.g. , twitter ) share sentiment feeling large community . consequently , platform instrumental understand perceive emotion scale . paper , introduce hurricaneemo , emotion dataset 15,000 english tweet span hurricane : harvey , irma , maria . present comprehensive study fine - grained emotion propose classification task discriminate coarsegrained emotion group . good bert ( devlin et al . , 2019 ) model , task - guide pre - training leverage unlabeled twitter datum , achieve 68 % accuracy ( average group ) . hurricaneemo serve challenging benchmark model valuable resource analyze emotion disaster - centric domain .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Computational Social Science and Social Media,Hierarchical Modeling for User Personality Prediction: The Role of Message-Level Attention,"Not all documents are equally important. Language processing is increasingly finding use as a supplement for questionnaires to assess psychological attributes of consenting individuals, but most approaches neglect to consider whether all documents of an individual are equally informative. In this paper, we present a novel model that uses message-level attention to learn the relative weight of users' social media posts for assessing their five factor personality traits. We demonstrate that models with message-level attention outperform those with word-level attention, and ultimately yield stateof-the-art accuracies for all five traits by using both word and message attention in combination with past approaches (an average increase in Pearson r of 2.5%). In addition, examination of the high-signal posts identified by our model provides insight into the relationship between language and personality, helping to inform future work.","Hierarchical Modeling for User Personality Prediction: The Role of Message-Level Attention Not all documents are equally important. Language processing is increasingly finding use as a supplement for questionnaires to assess psychological attributes of consenting individuals, but most approaches neglect to consider whether all documents of an individual are equally informative. In this paper, we present a novel model that uses message-level attention to learn the relative weight of users' social media posts for assessing their five factor personality traits. We demonstrate that models with message-level attention outperform those with word-level attention, and ultimately yield stateof-the-art accuracies for all five traits by using both word and message attention in combination with past approaches (an average increase in Pearson r of 2.5%). In addition, examination of the high-signal posts identified by our model provides insight into the relationship between language and personality, helping to inform future work.","hierarchical modeling user personality prediction : role message - level attention document equally important . language processing increasingly find use supplement questionnaire assess psychological attribute consent individual , approach neglect consider document individual equally informative . paper , present novel model use message - level attention learn relative weight user ' social medium post assess factor personality trait . demonstrate model message - level attention outperform word - level attention , ultimately yield stateof - - art accuracy trait word message attention combination past approach ( average increase pearson r 2.5 % ) . addition , examination high - signal post identify model provide insight relationship language personality , help inform future work .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
Computational Social Science and Social Media,When do Word Embeddings Accurately Reflect Surveys on our Beliefs About People?,"Social biases are encoded in word embeddings. This presents a unique opportunity to study society historically and at scale, and a unique danger when embeddings are used in downstream applications. Here, we investigate the extent to which publicly-available word embeddings accurately reflect beliefs about certain kinds of people as measured via traditional survey methods. We find that biases found in word embeddings do, on average, closely mirror survey data across seventeen dimensions of social meaning. However, we also find that biases in embeddings are much more reflective of survey data for some dimensions of meaning (e.g. gender) than others (e.g. race), and that we can be highly confident that embedding-based measures reflect survey data only for the most salient biases.","When do Word Embeddings Accurately Reflect Surveys on our Beliefs About People? Social biases are encoded in word embeddings. This presents a unique opportunity to study society historically and at scale, and a unique danger when embeddings are used in downstream applications. Here, we investigate the extent to which publicly-available word embeddings accurately reflect beliefs about certain kinds of people as measured via traditional survey methods. We find that biases found in word embeddings do, on average, closely mirror survey data across seventeen dimensions of social meaning. However, we also find that biases in embeddings are much more reflective of survey data for some dimensions of meaning (e.g. gender) than others (e.g. race), and that we can be highly confident that embedding-based measures reflect survey data only for the most salient biases.","word embedding accurately reflect survey belief people ? social bias encode word embedding . present unique opportunity study society historically scale , unique danger embedding downstream application . , investigate extent publicly - available word embedding accurately reflect belief certain kind people measure traditional survey method . find bias find word embedding , average , closely mirror survey datum seventeen dimension social meaning . , find bias embedding reflective survey datum dimension meaning ( e.g. gender ) ( e.g. race ) , highly confident embedding - base measure reflect survey datum salient bias .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 8, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Computational Social Science and Social Media,Would you Rather? A New Benchmark for Learning Machine Alignment with Cultural Values and Social Preferences,"Understanding human preferences, along with cultural and social nuances, lives at the heart of natural language understanding. Concretely, we present a new task and corpus for learning alignments between machine and human preferences. Our newly introduced problem is concerned with predicting the preferable options from two sentences describing scenarios that may involve social and cultural situations. Our problem is framed as a natural language inference task with crowd-sourced preference votes by human players, obtained from a gamified voting platform. We benchmark several state-of-the-art neural models, along with BERT and friends on this task. Our experimental results show that current state-ofthe-art NLP models still leave much room for improvement.","Would you Rather? A New Benchmark for Learning Machine Alignment with Cultural Values and Social Preferences Understanding human preferences, along with cultural and social nuances, lives at the heart of natural language understanding. Concretely, we present a new task and corpus for learning alignments between machine and human preferences. Our newly introduced problem is concerned with predicting the preferable options from two sentences describing scenarios that may involve social and cultural situations. Our problem is framed as a natural language inference task with crowd-sourced preference votes by human players, obtained from a gamified voting platform. We benchmark several state-of-the-art neural models, along with BERT and friends on this task. Our experimental results show that current state-ofthe-art NLP models still leave much room for improvement.","? new benchmark learn machine alignment cultural value social preference understand human preference , cultural social nuance , live heart natural language understanding . concretely , present new task corpus learn alignment machine human preference . newly introduce problem concern predict preferable option sentence describe scenario involve social cultural situation . problem frame natural language inference task crowd - source preference vote human player , obtain gamified voting platform . benchmark state - - - art neural model , bert friend task . experimental result current state - ofthe - art nlp model leave room improvement .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Dialogue and Interactive Systems,Coach: A Coarse-to-Fine Approach for Cross-domain Slot Filling,"As an essential task in task-oriented dialog systems, slot filling requires extensive training data in a certain domain. However, such data are not always available. Hence, cross-domain slot filling has naturally arisen to cope with this data scarcity problem. In this paper, we propose a Coarse-to-fine approach (Coach) for cross-domain slot filling. Our model first learns the general pattern of slot entities by detecting whether the tokens are slot entities or not. It then predicts the specific types for the slot entities. In addition, we propose a template regularization approach to improve the adaptation robustness by regularizing the representation of utterances based on utterance templates. Experimental results show that our model significantly outperforms state-of-theart approaches in slot filling. Furthermore, our model can also be applied to the cross-domain named entity recognition task, and it achieves better adaptation performance than other existing baselines. The code is available at https: //github.com/zliucr/coach.","Coach: A Coarse-to-Fine Approach for Cross-domain Slot Filling As an essential task in task-oriented dialog systems, slot filling requires extensive training data in a certain domain. However, such data are not always available. Hence, cross-domain slot filling has naturally arisen to cope with this data scarcity problem. In this paper, we propose a Coarse-to-fine approach (Coach) for cross-domain slot filling. Our model first learns the general pattern of slot entities by detecting whether the tokens are slot entities or not. It then predicts the specific types for the slot entities. In addition, we propose a template regularization approach to improve the adaptation robustness by regularizing the representation of utterances based on utterance templates. Experimental results show that our model significantly outperforms state-of-theart approaches in slot filling. Furthermore, our model can also be applied to the cross-domain named entity recognition task, and it achieves better adaptation performance than other existing baselines. The code is available at https: //github.com/zliucr/coach.","coach : coarse - - fine approach cross - domain slot filling essential task task - orient dialog system , slot filling require extensive training datum certain domain . , datum available . , cross - domain slot filling naturally arise cope datum scarcity problem . paper , propose coarse - - fine approach ( coach ) cross - domain slot filling . model learn general pattern slot entity detect token slot entity . predict specific type slot entity . addition , propose template regularization approach improve adaptation robustness regularize representation utterance base utterance template . experimental result model significantly outperform state - - theart approach slot filling . furthermore , model apply cross - domain name entity recognition task , achieve well adaptation performance exist baseline . code available https : //github.com / zliucr / coach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Towards Conversational Recommendation over Multi-Type Dialogs,"We focus on the study of conversational recommendation in the context of multi-type dialogs, where the bots can proactively and naturally lead a conversation from a nonrecommendation dialog (e.g., QA) to a recommendation dialog, taking into account user's interests and feedback. To facilitate the study of this task, we create a human-to-human Chinese dialog dataset DuRecDial (about 10k dialogs, 156k utterances), which contains multiple sequential dialogs for every pair of a recommendation seeker (user) and a recommender (bot). In each dialog, the recommender proactively leads a multi-type dialog to approach recommendation targets and then makes multiple recommendations with rich interaction behavior. This dataset allows us to systematically investigate different parts of the overall problem, e.g., how to naturally lead a dialog, how to interact with users for recommendation. Finally we establish baseline results on DuRecDial for future studies. 1 * This work was done at Baidu.","Towards Conversational Recommendation over Multi-Type Dialogs We focus on the study of conversational recommendation in the context of multi-type dialogs, where the bots can proactively and naturally lead a conversation from a nonrecommendation dialog (e.g., QA) to a recommendation dialog, taking into account user's interests and feedback. To facilitate the study of this task, we create a human-to-human Chinese dialog dataset DuRecDial (about 10k dialogs, 156k utterances), which contains multiple sequential dialogs for every pair of a recommendation seeker (user) and a recommender (bot). In each dialog, the recommender proactively leads a multi-type dialog to approach recommendation targets and then makes multiple recommendations with rich interaction behavior. This dataset allows us to systematically investigate different parts of the overall problem, e.g., how to naturally lead a dialog, how to interact with users for recommendation. Finally we establish baseline results on DuRecDial for future studies. 1 * This work was done at Baidu.","conversational recommendation multi - type dialog focus study conversational recommendation context multi - type dialog , bot proactively naturally lead conversation nonrecommendation dialog ( e.g. , qa ) recommendation dialog , take account user interest feedback . facilitate study task , create human - - human chinese dialog dataset durecdial ( 10k dialog , 156k utterance ) , contain multiple sequential dialog pair recommendation seeker ( user ) recommender ( bot ) . dialog , recommender proactively lead multi - type dialog approach recommendation target make multiple recommendation rich interaction behavior . dataset allow systematically investigate different part overall problem , e.g. , naturally lead dialog , interact user recommendation . finally establish baseline result durecdial future study . 1 * work baidu .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 11, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 10, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Data Manipulation: Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight,"Current state-of-the-art neural dialogue models learn from human conversations following the data-driven paradigm. As such, a reliable training corpus is the crux of building a robust and well-behaved dialogue model. However, due to the open-ended nature of human conversations, the quality of user-generated training data varies greatly, and effective training samples are typically insufficient while noisy samples frequently appear. This impedes the learning of those data-driven neural dialogue models. Therefore, effective dialogue learning requires not only more reliable learning samples, but also fewer noisy samples. In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously. In particular, the data manipulation model selectively augments the training samples and assigns an importance weight to each instance to reform the training data. Note that, the proposed data manipulation framework is fully data-driven and learnable. It not only manipulates training samples to optimize the dialogue generation model, but also learns to increase its manipulation skills through gradient descent with validation samples. Extensive experiments show that our framework can improve the dialogue generation performance with respect to various automatic evaluation metrics and human judgments.","Data Manipulation: Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight Current state-of-the-art neural dialogue models learn from human conversations following the data-driven paradigm. As such, a reliable training corpus is the crux of building a robust and well-behaved dialogue model. However, due to the open-ended nature of human conversations, the quality of user-generated training data varies greatly, and effective training samples are typically insufficient while noisy samples frequently appear. This impedes the learning of those data-driven neural dialogue models. Therefore, effective dialogue learning requires not only more reliable learning samples, but also fewer noisy samples. In this paper, we propose a data manipulation framework to proactively reshape the data distribution towards reliable samples by augmenting and highlighting effective learning samples as well as reducing the effect of inefficient samples simultaneously. In particular, the data manipulation model selectively augments the training samples and assigns an importance weight to each instance to reform the training data. Note that, the proposed data manipulation framework is fully data-driven and learnable. It not only manipulates training samples to optimize the dialogue generation model, but also learns to increase its manipulation skills through gradient descent with validation samples. Extensive experiments show that our framework can improve the dialogue generation performance with respect to various automatic evaluation metrics and human judgments.","data manipulation : effective instance learning neural dialogue generation learn augment reweight current state - - - art neural dialogue model learn human conversation follow data - drive paradigm . , reliable training corpus crux build robust - behave dialogue model . , open - ended nature human conversation , quality user - generate training datum vary greatly , effective training sample typically insufficient noisy sample frequently appear . impede learning data - drive neural dialogue model . , effective dialogue learning require reliable learning sample , few noisy sample . paper , propose data manipulation framework proactively reshape datum distribution reliable sample augment highlight effective learning sample reduce effect inefficient sample simultaneously . particular , data manipulation model selectively augment training sample assign importance weight instance reform training datum . note , propose data manipulation framework fully data - drive learnable . manipulate training sample optimize dialogue generation model , learn increase manipulation skill gradient descent validation sample . extensive experiment framework improve dialogue generation performance respect automatic evaluation metric human judgment .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 16, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Learning Efficient Dialogue Policy from Demonstrations through Shaping,"Training a task-oriented dialogue agent with reinforcement learning is prohibitively expensive since it requires a large volume of interactions with users. Human demonstrations can be used to accelerate learning progress. However, how to effectively leverage demonstrations to learn dialogue policy remains less explored. In this paper, we present that efficiently learns dialogue policy from demonstrations through policy shaping and reward shaping. We use an imitation model to distill knowledge from demonstrations, based on which policy shaping estimates feedback on how the agent should act in policy space. Reward shaping is then incorporated to bonus state-actions similar to demonstrations explicitly in value space encouraging better exploration. The effectiveness of the proposed S 2 Agent is demonstrated in three dialogue domains and a challenging domain adaptation task with both user simulator evaluation and human evaluation.","Learning Efficient Dialogue Policy from Demonstrations through Shaping Training a task-oriented dialogue agent with reinforcement learning is prohibitively expensive since it requires a large volume of interactions with users. Human demonstrations can be used to accelerate learning progress. However, how to effectively leverage demonstrations to learn dialogue policy remains less explored. In this paper, we present that efficiently learns dialogue policy from demonstrations through policy shaping and reward shaping. We use an imitation model to distill knowledge from demonstrations, based on which policy shaping estimates feedback on how the agent should act in policy space. Reward shaping is then incorporated to bonus state-actions similar to demonstrations explicitly in value space encouraging better exploration. The effectiveness of the proposed S 2 Agent is demonstrated in three dialogue domains and a challenging domain adaptation task with both user simulator evaluation and human evaluation.","learn efficient dialogue policy demonstration shape training task - orient dialogue agent reinforcement learning prohibitively expensive require large volume interaction user . human demonstration accelerate learn progress . , effectively leverage demonstration learn dialogue policy remain explore . paper , present efficiently learn dialogue policy demonstration policy shaping reward shaping . use imitation model distill knowledge demonstration , base policy shaping estimate feedback agent act policy space . reward shaping incorporate bonus state - action similar demonstration explicitly value space encourage well exploration . effectiveness propose s 2 agent demonstrate dialogue domain challenging domain adaptation task user simulator evaluation human evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,CDL: Curriculum Dual Learning for Emotion-Controllable Response Generation,"Emotion-controllable response generation is an attractive and valuable task that aims to make open-domain conversations more empathetic and engaging. Existing methods mainly enhance the emotion expression by adding regularization terms to standard cross-entropy loss and thus influence the training process. However, due to the lack of further consideration of content consistency, the common problem of response generation tasks, safe response, is intensified. Besides, query emotions that can help model the relationship between query and response are simply ignored in previous models, which would further hurt the coherence. To alleviate these problems, we propose a novel framework named Curriculum Dual Learning (CDL) which extends the emotion-controllable response generation to a dual task to generate emotional responses and emotional queries alternatively. CDL utilizes two rewards focusing on emotion and content to improve the duality. Additionally, it applies curriculum learning to gradually generate high-quality responses based on the difficulties of expressing various emotions. Experimental results show that CDL significantly outperforms the baselines in terms of coherence, diversity, and relation to emotion factors.","CDL: Curriculum Dual Learning for Emotion-Controllable Response Generation Emotion-controllable response generation is an attractive and valuable task that aims to make open-domain conversations more empathetic and engaging. Existing methods mainly enhance the emotion expression by adding regularization terms to standard cross-entropy loss and thus influence the training process. However, due to the lack of further consideration of content consistency, the common problem of response generation tasks, safe response, is intensified. Besides, query emotions that can help model the relationship between query and response are simply ignored in previous models, which would further hurt the coherence. To alleviate these problems, we propose a novel framework named Curriculum Dual Learning (CDL) which extends the emotion-controllable response generation to a dual task to generate emotional responses and emotional queries alternatively. CDL utilizes two rewards focusing on emotion and content to improve the duality. Additionally, it applies curriculum learning to gradually generate high-quality responses based on the difficulties of expressing various emotions. Experimental results show that CDL significantly outperforms the baselines in terms of coherence, diversity, and relation to emotion factors.","cdl : curriculum dual learning emotion - controllable response generation emotion - controllable response generation attractive valuable task aim open - domain conversation empathetic engaging . exist method mainly enhance emotion expression add regularization term standard cross - entropy loss influence training process . , lack consideration content consistency , common problem response generation task , safe response , intensify . , query emotion help model relationship query response simply ignore previous model , hurt coherence . alleviate problem , propose novel framework name curriculum dual learning ( cdl ) extend emotion - controllable response generation dual task generate emotional response emotional query alternatively . cdl utilize reward focus emotion content improve duality . additionally , apply curriculum learning gradually generate high - quality response base difficulty express emotion . experimental result cdl significantly outperform baseline term coherence , diversity , relation emotion factor .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 10, 'Speech and Multimodality': 11, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Dialogue and Interactive Systems,"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot","This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast humanmachine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of largescale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.","The Design and Implementation of XiaoIce, an Empathetic Social Chatbot This article describes the development of Microsoft XiaoIce, the most popular social chatbot in the world. XiaoIce is uniquely designed as an artifical intelligence companion with an emotional connection to satisfy the human need for communication, affection, and social belonging. We take into account both intelligent quotient and emotional quotient in system design, cast humanmachine social chat as decision-making over Markov Decision Processes, and optimize XiaoIce for long-term user engagement, measured in expected Conversation-turns Per Session (CPS). We detail the system architecture and key components, including dialogue manager, core chat, skills, and an empathetic computing module. We show how XiaoIce dynamically recognizes human feelings and states, understands user intent, and responds to user needs throughout long conversations. Since the release in 2014, XiaoIce has communicated with over 660 million active users and succeeded in establishing long-term relationships with many of them. Analysis of largescale online logs shows that XiaoIce has achieved an average CPS of 23, which is significantly higher than that of other chatbots and even human conversations.","design implementation xiaoice , empathetic social chatbot article describe development microsoft xiaoice , popular social chatbot world . xiaoice uniquely design artifical intelligence companion emotional connection satisfy human need communication , affection , social belonging . account intelligent quotient emotional quotient system design , cast humanmachine social chat decision - making markov decision processes , optimize xiaoice long - term user engagement , measure expected conversation - turn session ( cps ) . detail system architecture key component , include dialogue manager , core chat , skill , empathetic computing module . xiaoice dynamically recognize human feeling state , understand user intent , respond user need long conversation . release 2014 , xiaoice communicate 660 million active user succeed establish long - term relationship . analysis largescale online log show xiaoice achieve average cps 23 , significantly high chatbot human conversation .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Dialogue and Interactive Systems,Learning Dialog Policies from Weak Demonstrations,"Deep reinforcement learning is a promising approach to training a dialog manager, but current methods struggle with the large state and action spaces of multi-domain dialog systems. Building upon Deep Q-learning from Demonstrations (DQfD), an algorithm that scores highly in difficult Atari games, we leverage dialog data to guide the agent to successfully respond to a user's requests. We make progressively fewer assumptions about the data needed, using labeled, reduced-labeled, and even unlabeled data to train expert demonstrators. We introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment. Experiments in a challenging multi-domain dialog system framework validate our approaches, and get high success rates even when trained on outof-domain data.","Learning Dialog Policies from Weak Demonstrations Deep reinforcement learning is a promising approach to training a dialog manager, but current methods struggle with the large state and action spaces of multi-domain dialog systems. Building upon Deep Q-learning from Demonstrations (DQfD), an algorithm that scores highly in difficult Atari games, we leverage dialog data to guide the agent to successfully respond to a user's requests. We make progressively fewer assumptions about the data needed, using labeled, reduced-labeled, and even unlabeled data to train expert demonstrators. We introduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to overcome the domain gap between the datasets and the environment. Experiments in a challenging multi-domain dialog system framework validate our approaches, and get high success rates even when trained on outof-domain data.","learn dialog policy weak demonstration deep reinforcement learning promising approach train dialog manager , current method struggle large state action space multi - domain dialog system . build deep q - learning demonstrations ( dqfd ) , algorithm score highly difficult atari game , leverage dialog datum guide agent successfully respond user request . progressively few assumption datum need , labeled , reduced - labeled , unlabeled datum train expert demonstrator . introduce reinforced fine - tune learning , extension dqfd , enable overcome domain gap dataset environment . experiment challenging multi - domain dialog system framework validate approach , high success rate train outof - domain datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 5, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Designing Precise and Robust Dialogue Response Evaluators,"Automatic dialogue response evaluator has been proposed as an alternative to automated metrics and human evaluation. However, existing automatic evaluators achieve only moderate correlation with human judgement and they are not robust. In this work, we propose to build a reference-free evaluator and exploit the power of semi-supervised training and pretrained (masked) language models. Experimental results demonstrate that the proposed evaluator achieves a strong correlation (> 0.6) with human judgement and generalizes robustly to diverse responses and corpora. We open-source the code and data in https://github.com/ ZHAOTING/dialog-processing.","Designing Precise and Robust Dialogue Response Evaluators Automatic dialogue response evaluator has been proposed as an alternative to automated metrics and human evaluation. However, existing automatic evaluators achieve only moderate correlation with human judgement and they are not robust. In this work, we propose to build a reference-free evaluator and exploit the power of semi-supervised training and pretrained (masked) language models. Experimental results demonstrate that the proposed evaluator achieves a strong correlation (> 0.6) with human judgement and generalizes robustly to diverse responses and corpora. We open-source the code and data in https://github.com/ ZHAOTING/dialog-processing.","design precise robust dialogue response evaluators automatic dialogue response evaluator propose alternative automate metric human evaluation . , exist automatic evaluator achieve moderate correlation human judgement robust . work , propose build reference - free evaluator exploit power semi - supervised training pretrained ( masked ) language model . experimental result demonstrate propose evaluator achieve strong correlation ( > 0.6 ) human judgement generalize robustly diverse response corpus . open - source code datum https://github.com/ zhaoting / dialog - processing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,A Generative Model for Joint Natural Language Understanding and Generation,"Natural language understanding (NLU) and natural language generation (NLG) are two fundamental and related tasks in building task-oriented dialogue systems with opposite objectives: NLU tackles the transformation from natural language to formal representations, whereas NLG does the reverse. A key to success in either task is parallel training data which is expensive to obtain at a large scale. In this work, we propose a generative model which couples NLU and NLG through a shared latent variable. This approach allows us to explore both spaces of natural language and formal representations, and facilitates information sharing through the latent space to eventually benefit NLU and NLG. Our model achieves state-of-the-art performance on two dialogue datasets with both flat and tree-structured formal representations. We also show that the model can be trained in a semi-supervised fashion by utilising unlabelled data to boost its performance.","A Generative Model for Joint Natural Language Understanding and Generation Natural language understanding (NLU) and natural language generation (NLG) are two fundamental and related tasks in building task-oriented dialogue systems with opposite objectives: NLU tackles the transformation from natural language to formal representations, whereas NLG does the reverse. A key to success in either task is parallel training data which is expensive to obtain at a large scale. In this work, we propose a generative model which couples NLU and NLG through a shared latent variable. This approach allows us to explore both spaces of natural language and formal representations, and facilitates information sharing through the latent space to eventually benefit NLU and NLG. Our model achieves state-of-the-art performance on two dialogue datasets with both flat and tree-structured formal representations. We also show that the model can be trained in a semi-supervised fashion by utilising unlabelled data to boost its performance.","generative model joint natural language understanding generation natural language understanding ( nlu ) natural language generation ( nlg ) fundamental related task build task - orient dialogue system opposite objective : nlu tackle transformation natural language formal representation , nlg reverse . key success task parallel training data expensive obtain large scale . work , propose generative model couple nlu nlg share latent variable . approach allow explore space natural language formal representation , facilitate information sharing latent space eventually benefit nlu nlg . model achieve state - - - art performance dialogue dataset flat tree - structured formal representation . model train semi - supervised fashion utilise unlabelled datum boost performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}",Machine Learning for NLP,False
Dialogue and Interactive Systems,Grounded Conversation Generation as Guided Traverses in Commonsense Knowledge Graphs,"Human conversations naturally evolve around related concepts and scatter to multi-hop concepts. This paper presents a new conversation generation model, ConceptFlow, which leverages commonsense knowledge graphs to explicitly model conversation flows. By grounding conversations to the concept space, Con-ceptFlow represents the potential conversation flow as traverses in the concept space along commonsense relations. The traverse is guided by graph attentions in the concept graph, moving towards more meaningful directions in the concept space, in order to generate more semantic and informative responses. Experiments on Reddit conversations demonstrate ConceptFlow's effectiveness over previous knowledge-aware conversation models and GPT-2 based models while using 70% fewer parameters, confirming the advantage of explicit modeling conversation structures. All source codes of this work are available at https://github.com/ thunlp/ConceptFlow.","Grounded Conversation Generation as Guided Traverses in Commonsense Knowledge Graphs Human conversations naturally evolve around related concepts and scatter to multi-hop concepts. This paper presents a new conversation generation model, ConceptFlow, which leverages commonsense knowledge graphs to explicitly model conversation flows. By grounding conversations to the concept space, Con-ceptFlow represents the potential conversation flow as traverses in the concept space along commonsense relations. The traverse is guided by graph attentions in the concept graph, moving towards more meaningful directions in the concept space, in order to generate more semantic and informative responses. Experiments on Reddit conversations demonstrate ConceptFlow's effectiveness over previous knowledge-aware conversation models and GPT-2 based models while using 70% fewer parameters, confirming the advantage of explicit modeling conversation structures. All source codes of this work are available at https://github.com/ thunlp/ConceptFlow.","ground conversation generation guide traverse commonsense knowledge graph human conversation naturally evolve related concept scatter multi - hop concept . paper present new conversation generation model , conceptflow , leverage commonsense knowledge graph explicitly model conversation flow . ground conversation concept space , con - ceptflow represent potential conversation flow traverse concept space commonsense relation . traverse guide graph attention concept graph , move meaningful direction concept space , order generate semantic informative response . experiment reddit conversation demonstrate conceptflow effectiveness previous knowledge - aware conversation model gpt-2 base model 70 % few parameter , confirm advantage explicit model conversation structure . source code work available https://github.com/ thunlp / conceptflow .","{'Computational Social Science and Social Media': 9, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 10, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Dialogue State Tracking with Explicit Slot Connection Modeling,"Recent proposed approaches have made promising progress in dialogue state tracking (DST). However, in multi-domain scenarios, ellipsis and reference are frequently adopted by users to express values that have been mentioned by slots from other domains. To handle these phenomena, we propose a Dialogue State Tracking with Slot Connections (DST-SC) model to explicitly consider slot correlations across different domains. Given a target slot, the slot connecting mechanism in DST-SC can infer its source slot and copy the source slot value directly, thus significantly reducing the difficulty of learning and reasoning. Experimental results verify the benefits of explicit slot connection modeling, and our model achieves state-of-the-art performance on Mul-tiWOZ 2.0 and MultiWOZ 2.1 datasets.","Dialogue State Tracking with Explicit Slot Connection Modeling Recent proposed approaches have made promising progress in dialogue state tracking (DST). However, in multi-domain scenarios, ellipsis and reference are frequently adopted by users to express values that have been mentioned by slots from other domains. To handle these phenomena, we propose a Dialogue State Tracking with Slot Connections (DST-SC) model to explicitly consider slot correlations across different domains. Given a target slot, the slot connecting mechanism in DST-SC can infer its source slot and copy the source slot value directly, thus significantly reducing the difficulty of learning and reasoning. Experimental results verify the benefits of explicit slot connection modeling, and our model achieves state-of-the-art performance on Mul-tiWOZ 2.0 and MultiWOZ 2.1 datasets.","dialogue state tracking explicit slot connection modeling recent propose approach promising progress dialogue state tracking ( dst ) . , multi - domain scenario , ellipsi reference frequently adopt user express value mention slot domain . handle phenomenon , propose dialogue state tracking slot connections ( dst - sc ) model explicitly consider slot correlation different domain . give target slot , slot connect mechanism dst - sc infer source slot copy source slot value directly , significantly reduce difficulty learning reasoning . experimental result verify benefit explicit slot connection modeling , model achieve state - - - art performance mul - tiwoz 2.0 multiwoz 2.1 dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 21, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,MuTual: A Dataset for Multi-Turn Dialogue Reasoning,"Non-task oriented dialogue systems have achieved great success in recent years due to largely accessible conversation data and the development of deep learning techniques. Given a context, current systems are able to yield a relevant and fluent response, but sometimes make logical mistakes because of weak reasoning capabilities. To facilitate the conversation reasoning research, we introduce Mu-Tual, a novel dataset for Multi-Turn dialogue Reasoning, consisting of 8,860 manually annotated dialogues based on Chinese student English listening comprehension exams. Compared to previous benchmarks for non-task oriented dialogue systems, MuTual is much more challenging since it requires a model that can handle various reasoning problems. Empirical results show that state-of-the-art methods only reach 71%, which is far behind the human performance of 94%, indicating that there is ample room for improving reasoning ability. MuTual is available at https://github. com/Nealcly/MuTual.","MuTual: A Dataset for Multi-Turn Dialogue Reasoning Non-task oriented dialogue systems have achieved great success in recent years due to largely accessible conversation data and the development of deep learning techniques. Given a context, current systems are able to yield a relevant and fluent response, but sometimes make logical mistakes because of weak reasoning capabilities. To facilitate the conversation reasoning research, we introduce Mu-Tual, a novel dataset for Multi-Turn dialogue Reasoning, consisting of 8,860 manually annotated dialogues based on Chinese student English listening comprehension exams. Compared to previous benchmarks for non-task oriented dialogue systems, MuTual is much more challenging since it requires a model that can handle various reasoning problems. Empirical results show that state-of-the-art methods only reach 71%, which is far behind the human performance of 94%, indicating that there is ample room for improving reasoning ability. MuTual is available at https://github. com/Nealcly/MuTual.","mutual : dataset multi - turn dialogue reasoning non - task oriented dialogue system achieve great success recent year largely accessible conversation datum development deep learning technique . give context , current system able yield relevant fluent response , logical mistake weak reasoning capability . facilitate conversation reasoning research , introduce mu - tual , novel dataset multi - turn dialogue reasoning , consist 8,860 manually annotate dialogue base chinese student english listening comprehension exam . compare previous benchmark non - task orient dialogue system , mutual challenging require model handle reasoning problem . empirical result state - - - art method reach 71 % , far human performance 94 % , indicate ample room improve reasoning ability . mutual available https://github . com / nealcly / mutual .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 19, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents,"We introduce dodecaDialogue: a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, ask questions, answer questions by utilizing knowledge resources, discuss topics and situations, and perceive and converse about images. By multi-tasking on such a broad large-scale set of data, we hope to both move towards and measure progress in producing a single unified agent that can perceive, reason and converse with humans in an open-domain setting. We show that such multi-tasking improves over a BERT pretrained baseline, largely due to multi-tasking with very large dialogue datasets in a similar domain, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the finetune and task transfer settings. We obtain stateof-the-art results on many of the tasks, providing a strong baseline for this challenge.","The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents We introduce dodecaDialogue: a set of 12 tasks that measures if a conversational agent can communicate engagingly with personality and empathy, ask questions, answer questions by utilizing knowledge resources, discuss topics and situations, and perceive and converse about images. By multi-tasking on such a broad large-scale set of data, we hope to both move towards and measure progress in producing a single unified agent that can perceive, reason and converse with humans in an open-domain setting. We show that such multi-tasking improves over a BERT pretrained baseline, largely due to multi-tasking with very large dialogue datasets in a similar domain, and that the multi-tasking in general provides gains to both text and image-based tasks using several metrics in both the finetune and task transfer settings. We obtain stateof-the-art results on many of the tasks, providing a strong baseline for this challenge.","dialogue dodecathlon : open - domain knowledge image ground conversational agent introduce dodecadialogue : set 12 task measure conversational agent communicate engagingly personality empathy , ask question , answer question utilize knowledge resource , discuss topic situation , perceive converse image . multi - task broad large - scale set datum , hope measure progress produce single unify agent perceive , reason converse human open - domain setting . multi - tasking improve bert pretraine baseline , largely multi - tasking large dialogue dataset similar domain , multi - tasking general provide gain text image - base task metric finetune task transfer setting . obtain stateof - - art result task , provide strong baseline challenge .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 3, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Response-Anticipated Memory for On-Demand Knowledge Integration in Response Generation,"Neural conversation models are known to generate appropriate but non-informative responses in general. A scenario where informativeness can be significantly enhanced is Conversing by Reading (CbR), where conversations take place with respect to a given external document. In previous work, the external document is utilized by (1) creating a contextaware document memory that integrates information from the document and the conversational context, and then (2) generating responses referring to the memory. In this paper, we propose to create the document memory with some anticipated responses in mind. This is achieved using a teacher-student framework. The teacher is given the external document, the context, and the ground-truth response, and learns how to build a response-aware document memory from three sources of information. The student learns to construct a response-anticipated document memory from the first two sources, and the teacher's insight on memory creation. Empirical results show that our model outperforms the previous stateof-the-art for the CbR task.","Response-Anticipated Memory for On-Demand Knowledge Integration in Response Generation Neural conversation models are known to generate appropriate but non-informative responses in general. A scenario where informativeness can be significantly enhanced is Conversing by Reading (CbR), where conversations take place with respect to a given external document. In previous work, the external document is utilized by (1) creating a contextaware document memory that integrates information from the document and the conversational context, and then (2) generating responses referring to the memory. In this paper, we propose to create the document memory with some anticipated responses in mind. This is achieved using a teacher-student framework. The teacher is given the external document, the context, and the ground-truth response, and learns how to build a response-aware document memory from three sources of information. The student learns to construct a response-anticipated document memory from the first two sources, and the teacher's insight on memory creation. Empirical results show that our model outperforms the previous stateof-the-art for the CbR task.","response - anticipate memory - demand knowledge integration response generation neural conversation model know generate appropriate non - informative response general . scenario informativeness significantly enhance converse reading ( cbr ) , conversation place respect give external document . previous work , external document utilize ( 1 ) create contextaware document memory integrate information document conversational context , ( 2 ) generate response refer memory . paper , propose create document memory anticipate response mind . achieve teacher - student framework . teacher give external document , context , ground - truth response , learn build response - aware document memory source information . student learn construct response - anticipate document memory source , teacher insight memory creation . empirical result model outperform previous stateof - - art cbr task .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations,"We introduce Span-ConveRT, a light-weight model for dialog slot-filling which frames the task as a turn-based span extraction task. This formulation allows for a simple integration of conversational knowledge coded in large pretrained conversational models such as Con-veRT (Henderson et al., 2019a). We show that leveraging such knowledge in Span-ConveRT is especially useful for few-shot learning scenarios: we report consistent gains over 1) a span extractor that trains representations from scratch in the target domain, and 2) a BERTbased span extractor. In order to inspire more work on span extraction for the slot-filling task, we also release RESTAURANTS-8K, a new challenging data set of 8,198 utterances, compiled from actual conversations in the restaurant booking domain.","Span-ConveRT: Few-shot Span Extraction for Dialog with Pretrained Conversational Representations We introduce Span-ConveRT, a light-weight model for dialog slot-filling which frames the task as a turn-based span extraction task. This formulation allows for a simple integration of conversational knowledge coded in large pretrained conversational models such as Con-veRT (Henderson et al., 2019a). We show that leveraging such knowledge in Span-ConveRT is especially useful for few-shot learning scenarios: we report consistent gains over 1) a span extractor that trains representations from scratch in the target domain, and 2) a BERTbased span extractor. In order to inspire more work on span extraction for the slot-filling task, we also release RESTAURANTS-8K, a new challenging data set of 8,198 utterances, compiled from actual conversations in the restaurant booking domain.","span - convert : - shot span extraction dialog pretrained conversational representation introduce span - convert , light - weight model dialog slot - filling frame task turn - base span extraction task . formulation allow simple integration conversational knowledge code large pretrained conversational model con - vert ( henderson et al . , 2019a ) . leverage knowledge span - convert especially useful - shot learning scenario : report consistent gain 1 ) span extractor train representation scratch target domain , 2 ) bertbased span extractor . order inspire work span extraction slot - fill task , release restaurants-8 k , new challenging data set 8,198 utterance , compile actual conversation restaurant booking domain .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Learning to Tag OOV Tokens by Integrating Contextual Representation and Background Knowledge,"Neural-based context-aware models for slot tagging have achieved state-of-the-art performance. However, the presence of OOV(outof-vocab) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-enhanced slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multilevel graph attention to explicitly model lexical relations. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets.","Learning to Tag OOV Tokens by Integrating Contextual Representation and Background Knowledge Neural-based context-aware models for slot tagging have achieved state-of-the-art performance. However, the presence of OOV(outof-vocab) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-enhanced slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multilevel graph attention to explicitly model lexical relations. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets.","learn tag oov token integrate contextual representation background knowledge neural - base context - aware model slot tagging achieve state - - - art performance . , presence oov(outof - vocab ) word significantly degrade performance neural - base model , especially - shot scenario . paper , propose novel knowledge - enhance slot tagging model integrate contextual representation input text large - scale lexical background knowledge . , use multilevel graph attention explicitly model lexical relation . experiment propose knowledge integration mechanism achieve consistent improvement setting different size training datum public benchmark dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Dialogue and Interactive Systems,USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation,"The lack of meaningful automatic evaluation metrics for dialog has impeded open-domain dialog research. Standard language generation metrics have been shown to be ineffective for evaluating dialog models. To this end, this paper presents USR, an UnSupervised and Reference-free evaluation metric for dialog. USR is a reference-free metric that trains unsupervised models to measure several desirable qualities of dialog. USR is shown to strongly correlate with human judgment on both Topical-Chat (turn-level: 0.42, systemlevel: 1.0) and PersonaChat (turn-level: 0.48 and system-level: 1.0). USR additionally produces interpretable measures for several desirable properties of dialog.","USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation The lack of meaningful automatic evaluation metrics for dialog has impeded open-domain dialog research. Standard language generation metrics have been shown to be ineffective for evaluating dialog models. To this end, this paper presents USR, an UnSupervised and Reference-free evaluation metric for dialog. USR is a reference-free metric that trains unsupervised models to measure several desirable qualities of dialog. USR is shown to strongly correlate with human judgment on both Topical-Chat (turn-level: 0.42, systemlevel: 1.0) and PersonaChat (turn-level: 0.48 and system-level: 1.0). USR additionally produces interpretable measures for several desirable properties of dialog.","usr : unsupervised reference free evaluation metric dialog generation lack meaningful automatic evaluation metric dialog impede open - domain dialog research . standard language generation metric show ineffective evaluate dialog model . end , paper present usr , unsupervised reference - free evaluation metric dialog . usr reference - free metric train unsupervised model measure desirable quality dialog . usr show strongly correlate human judgment topical - chat ( turn - level : 0.42 , systemlevel : 1.0 ) personachat ( turn - level : 0.48 system - level : 1.0 ) . usr additionally produce interpretable measure desirable property dialog .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 12, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Dialogue and Interactive Systems,Negative Training for Neural Dialogue Response Generation,"Although deep learning models have brought tremendous advancements to the field of opendomain dialogue response generation, recent research results have revealed that the trained models have undesirable generation behaviors, such as malicious responses and generic (boring) responses. In this work, we propose a framework named ""Negative Training"" to minimize such behaviors. Given a trained model, the framework will first find generated samples that exhibit the undesirable behavior, and then use them to feed negative training signals for fine-tuning the model. Our experiments show that negative training can significantly reduce the hit rate of malicious responses, or discourage frequent responses and improve response diversity.","Negative Training for Neural Dialogue Response Generation Although deep learning models have brought tremendous advancements to the field of opendomain dialogue response generation, recent research results have revealed that the trained models have undesirable generation behaviors, such as malicious responses and generic (boring) responses. In this work, we propose a framework named ""Negative Training"" to minimize such behaviors. Given a trained model, the framework will first find generated samples that exhibit the undesirable behavior, and then use them to feed negative training signals for fine-tuning the model. Our experiments show that negative training can significantly reduce the hit rate of malicious responses, or discourage frequent responses and improve response diversity.","negative training neural dialogue response generation deep learning model bring tremendous advancement field opendomain dialogue response generation , recent research result reveal train model undesirable generation behavior , malicious response generic ( boring ) response . work , propose framework name "" negative training "" minimize behavior . give train model , framework find generate sample exhibit undesirable behavior , use feed negative training signal fine - tune model . experiment negative training significantly reduce hit rate malicious response , discourage frequent response improve response diversity .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment,"Existing end-to-end dialog systems perform less effectively when data is scarce. To obtain an acceptable success in real-life online services with only a handful of training examples, both fast adaptability and reliable performance are highly desirable for dialog systems. In this paper, we propose the Meta-Dialog System (MDS), which combines the advantages of both meta-learning approaches and human-machine collaboration. We evaluate our methods on a new extended-bAbI dataset and a transformed MultiWOZ dataset for lowresource goal-oriented dialog learning. Experimental results show that MDS significantly outperforms non-meta-learning baselines and can achieve more than 90% per-turn accuracies with only 10 dialogs on the extended-bAbI dataset.","Learning Low-Resource End-To-End Goal-Oriented Dialog for Fast and Reliable System Deployment Existing end-to-end dialog systems perform less effectively when data is scarce. To obtain an acceptable success in real-life online services with only a handful of training examples, both fast adaptability and reliable performance are highly desirable for dialog systems. In this paper, we propose the Meta-Dialog System (MDS), which combines the advantages of both meta-learning approaches and human-machine collaboration. We evaluate our methods on a new extended-bAbI dataset and a transformed MultiWOZ dataset for lowresource goal-oriented dialog learning. Experimental results show that MDS significantly outperforms non-meta-learning baselines and can achieve more than 90% per-turn accuracies with only 10 dialogs on the extended-bAbI dataset.","learn low - resource end - - end goal - orient dialog fast reliable system deployment exist end - - end dialog system perform effectively data scarce . obtain acceptable success real - life online service handful training example , fast adaptability reliable performance highly desirable dialog system . paper , propose meta - dialog system ( mds ) , combine advantage meta - learn approach human - machine collaboration . evaluate method new extended - babi dataset transform multiwoz dataset lowresource goal - orient dialog learning . experimental result mds significantly outperform non - meta - learning baseline achieve 90 % - turn accuracy 10 dialog extended - babi dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,You Impress Me: Dialogue Generation via Mutual Persona Perception,"Despite the continuing efforts to improve the engagingness and consistency of chit-chat dialogue systems, the majority of current work simply focus on mimicking human-like responses, leaving understudied the aspects of modeling understanding between interlocutors. The research in cognitive science, instead, suggests that understanding is an essential signal for a high-quality chit-chat conversation. Motivated by this, we propose P 2 BOT, a transmitter-receiver based framework with the aim of explicitly modeling understanding. Specifically, P 2 BOT incorporates mutual persona perception to enhance the quality of personalized dialogue generation. Experiments on a large public dataset, PERSONA-CHAT, demonstrate the effectiveness of our approach, with a considerable boost over the state-of-theart baselines across both automatic metrics and human evaluations.","You Impress Me: Dialogue Generation via Mutual Persona Perception Despite the continuing efforts to improve the engagingness and consistency of chit-chat dialogue systems, the majority of current work simply focus on mimicking human-like responses, leaving understudied the aspects of modeling understanding between interlocutors. The research in cognitive science, instead, suggests that understanding is an essential signal for a high-quality chit-chat conversation. Motivated by this, we propose P 2 BOT, a transmitter-receiver based framework with the aim of explicitly modeling understanding. Specifically, P 2 BOT incorporates mutual persona perception to enhance the quality of personalized dialogue generation. Experiments on a large public dataset, PERSONA-CHAT, demonstrate the effectiveness of our approach, with a considerable boost over the state-of-theart baselines across both automatic metrics and human evaluations.","impress : dialogue generation mutual persona perception despite continue effort improve engagingness consistency chit - chat dialogue system , majority current work simply focus mimic human - like response , leave understudy aspect model understanding interlocutor . research cognitive science , instead , suggest understanding essential signal high - quality chit - chat conversation . motivate , propose p 2 bot , transmitter - receiver base framework aim explicitly model understanding . specifically , p 2 bot incorporate mutual persona perception enhance quality personalize dialogue generation . experiment large public dataset , persona - chat , demonstrate effectiveness approach , considerable boost state - - theart baseline automatic metric human evaluation .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Semi-Supervised Dialogue Policy Learning via Stochastic Reward Estimation,"Dialogue policy optimization often obtains feedback until task completion in taskoriented dialogue systems. This is insufficient for training intermediate dialogue turns since supervision signals (or rewards) are only provided at the end of dialogues. To address this issue, reward learning has been introduced to learn from state-action pairs of an optimal policy to provide turn-by-turn rewards. This approach requires complete state-action annotations of human-to-human dialogues (i.e., expert demonstrations), which is labor intensive. To overcome this limitation, we propose a novel reward learning approach for semisupervised policy learning. The proposed approach learns a dynamics model as the reward function which models dialogue progress (i.e., state-action sequences) based on expert demonstrations, either with or without annotations. The dynamics model computes rewards by predicting whether the dialogue progress is consistent with expert demonstrations. We further propose to learn action embeddings for a better generalization of the reward function. The proposed approach outperforms competitive policy learning baselines on MultiWOZ, a benchmark multi-domain dataset.","Semi-Supervised Dialogue Policy Learning via Stochastic Reward Estimation Dialogue policy optimization often obtains feedback until task completion in taskoriented dialogue systems. This is insufficient for training intermediate dialogue turns since supervision signals (or rewards) are only provided at the end of dialogues. To address this issue, reward learning has been introduced to learn from state-action pairs of an optimal policy to provide turn-by-turn rewards. This approach requires complete state-action annotations of human-to-human dialogues (i.e., expert demonstrations), which is labor intensive. To overcome this limitation, we propose a novel reward learning approach for semisupervised policy learning. The proposed approach learns a dynamics model as the reward function which models dialogue progress (i.e., state-action sequences) based on expert demonstrations, either with or without annotations. The dynamics model computes rewards by predicting whether the dialogue progress is consistent with expert demonstrations. We further propose to learn action embeddings for a better generalization of the reward function. The proposed approach outperforms competitive policy learning baselines on MultiWOZ, a benchmark multi-domain dataset.","semi - supervised dialogue policy learning stochastic reward estimation dialogue policy optimization obtain feedback task completion taskoriente dialogue system . insufficient train intermediate dialogue turn supervision signal ( reward ) provide end dialogue . address issue , reward learning introduce learn state - action pair optimal policy provide turn - - turn reward . approach require complete state - action annotation human - - human dialogue ( i.e. , expert demonstration ) , labor intensive . overcome limitation , propose novel reward learning approach semisupervised policy learning . propose approach learn dynamic model reward function model dialogue progress ( i.e. , state - action sequence ) base expert demonstration , annotation . dynamic model compute reward predict dialogue progress consistent expert demonstration . propose learn action embedding well generalization reward function . propose approach outperform competitive policy learning baseline multiwoz , benchmark multi - domain dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 21, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Generating Informative Conversational Response using Recurrent Knowledge-Interaction and Knowledge-Copy,"Knowledge-driven conversation approaches have achieved remarkable research attention recently. However, generating an informative response with multiple relevant knowledge without losing fluency and coherence is still one of the main challenges. To address this issue, this paper proposes a method that uses recurrent knowledge interaction among response decoding steps to incorporate appropriate knowledge. Furthermore, we introduce a knowledge copy mechanism using a knowledge-aware pointer network to copy words from external knowledge according to knowledge attention distribution. Our joint neural conversation model which integrates recurrent Knowledge-Interaction and knowledge Copy (KIC) performs well on generating informative responses. Experiments demonstrate that our model with fewer parameters yields significant improvements over competitive baselines on two datasets Wizardof-Wikipedia(average Bleu +87%; abs.:0.034) and DuConv(average Bleu +20%; abs.:0.047) with different knowledge formats (textual & structured) and different languages (English & Chinese).","Generating Informative Conversational Response using Recurrent Knowledge-Interaction and Knowledge-Copy Knowledge-driven conversation approaches have achieved remarkable research attention recently. However, generating an informative response with multiple relevant knowledge without losing fluency and coherence is still one of the main challenges. To address this issue, this paper proposes a method that uses recurrent knowledge interaction among response decoding steps to incorporate appropriate knowledge. Furthermore, we introduce a knowledge copy mechanism using a knowledge-aware pointer network to copy words from external knowledge according to knowledge attention distribution. Our joint neural conversation model which integrates recurrent Knowledge-Interaction and knowledge Copy (KIC) performs well on generating informative responses. Experiments demonstrate that our model with fewer parameters yields significant improvements over competitive baselines on two datasets Wizardof-Wikipedia(average Bleu +87%; abs.:0.034) and DuConv(average Bleu +20%; abs.:0.047) with different knowledge formats (textual & structured) and different languages (English & Chinese).","generate informative conversational response recurrent knowledge - interaction knowledge - copy knowledge - drive conversation approach achieve remarkable research attention recently . , generate informative response multiple relevant knowledge lose fluency coherence main challenge . address issue , paper propose method use recurrent knowledge interaction response decoding step incorporate appropriate knowledge . furthermore , introduce knowledge copy mechanism knowledge - aware pointer network copy word external knowledge accord knowledge attention distribution . joint neural conversation model integrate recurrent knowledge - interaction knowledge copy ( kic ) perform generate informative response . experiment demonstrate model few parameter yield significant improvement competitive baseline dataset wizardof - wikipedia(average bleu +87 % ; abs.:0.034 ) duconv(average bleu +20 % ; abs.:0.047 ) different knowledge format ( textual & structured ) different language ( english & chinese ) .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Video-Grounded Dialogues with Pretrained Generation Language Models,"Pre-trained language models have shown remarkable success in improving various downstream NLP tasks due to their ability to capture dependencies in textual data and generate natural responses. In this paper, we leverage the power of pre-trained language models for improving video-grounded dialogue, which is very challenging and involves complex features of different dynamics: (1) Video features which can extend across both spatial and temporal dimensions; and (2) Dialogue features which involve semantic dependencies over multiple dialogue turns. We propose a framework by extending GPT-2 models to tackle these challenges by formulating videogrounded dialogue tasks as a sequence-tosequence task, combining both visual and textual representation into a structured sequence, and fine-tuning a large pre-trained GPT-2 network. Our framework allows fine-tuning language models to capture dependencies across multiple modalities over different levels of information: spatio-temporal level in video and token-sentence level in dialogue context. We achieve promising improvement on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark from DSTC7, which supports a potential direction in this line of research.","Video-Grounded Dialogues with Pretrained Generation Language Models Pre-trained language models have shown remarkable success in improving various downstream NLP tasks due to their ability to capture dependencies in textual data and generate natural responses. In this paper, we leverage the power of pre-trained language models for improving video-grounded dialogue, which is very challenging and involves complex features of different dynamics: (1) Video features which can extend across both spatial and temporal dimensions; and (2) Dialogue features which involve semantic dependencies over multiple dialogue turns. We propose a framework by extending GPT-2 models to tackle these challenges by formulating videogrounded dialogue tasks as a sequence-tosequence task, combining both visual and textual representation into a structured sequence, and fine-tuning a large pre-trained GPT-2 network. Our framework allows fine-tuning language models to capture dependencies across multiple modalities over different levels of information: spatio-temporal level in video and token-sentence level in dialogue context. We achieve promising improvement on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark from DSTC7, which supports a potential direction in this line of research.","video - ground dialogue pretrained generation language model pre - trained language model show remarkable success improve downstream nlp task ability capture dependency textual datum generate natural response . paper , leverage power pre - trained language model improve video - ground dialogue , challenging involve complex feature different dynamic : ( 1 ) video feature extend spatial temporal dimension ; ( 2 ) dialogue feature involve semantic dependency multiple dialogue turn . propose framework extend gpt-2 model tackle challenge formulate videogrounded dialogue task sequence - tosequence task , combine visual textual representation structured sequence , fine - tune large pre - trained gpt-2 network . framework allow fine - tune language model capture dependency multiple modality different level information : spatio - temporal level video token - sentence level dialogue context . achieve promising improvement audio - visual scene - aware dialogues ( avsd ) benchmark dstc7 , support potential direction line research .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 17, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Large Scale Multi-Actor Generative Dialog Modeling,"Non-goal oriented dialog agents (i.e. chatbots) aim to produce varying and engaging conversations with a user; however, they typically exhibit either inconsistent personality across conversations or the average personality of all users. This paper addresses these issues by controlling an agent's persona upon generation via conditioning on prior conversations of a target actor. In doing so, we are able to utilize more abstract patterns within a person's speech and better emulate them in generated responses. This work introduces the GENERATIVE CONVERSATION CONTROL model, an augmented and fine-tuned GPT-2 language model that conditions on past reference conversations to probabilistically model multi-turn conversations in the actor's persona. We introduce an accompanying data collection procedure to obtain 10.3M conversations from 6 months worth of Reddit comments. We demonstrate that scaling model sizes from 117M to 8.3B parameters yields an improvement from 23.14 to 13.14 perplexity on 1.7M held out Reddit conversations. Increasing model scale yielded similar improvements in human evaluations that measure preference of model samples to the held out target distribution in terms of realism (31% increased to 37% preference), style matching (37% to 42%), grammar and content quality (29% to 42%), and conversation coherency (32% to 40%). We find that conditionally modeling past conversations improves perplexity by 0.47 in automatic evaluations. Through human trials we identify positive trends between conditional modeling and style matching and outline steps to further improve persona control. * First two authors have contributed equally. â€  Research conducted during an internship at NVIDIA.","Large Scale Multi-Actor Generative Dialog Modeling Non-goal oriented dialog agents (i.e. chatbots) aim to produce varying and engaging conversations with a user; however, they typically exhibit either inconsistent personality across conversations or the average personality of all users. This paper addresses these issues by controlling an agent's persona upon generation via conditioning on prior conversations of a target actor. In doing so, we are able to utilize more abstract patterns within a person's speech and better emulate them in generated responses. This work introduces the GENERATIVE CONVERSATION CONTROL model, an augmented and fine-tuned GPT-2 language model that conditions on past reference conversations to probabilistically model multi-turn conversations in the actor's persona. We introduce an accompanying data collection procedure to obtain 10.3M conversations from 6 months worth of Reddit comments. We demonstrate that scaling model sizes from 117M to 8.3B parameters yields an improvement from 23.14 to 13.14 perplexity on 1.7M held out Reddit conversations. Increasing model scale yielded similar improvements in human evaluations that measure preference of model samples to the held out target distribution in terms of realism (31% increased to 37% preference), style matching (37% to 42%), grammar and content quality (29% to 42%), and conversation coherency (32% to 40%). We find that conditionally modeling past conversations improves perplexity by 0.47 in automatic evaluations. Through human trials we identify positive trends between conditional modeling and style matching and outline steps to further improve persona control. * First two authors have contributed equally. â€  Research conducted during an internship at NVIDIA.","large scale multi - actor generative dialog modeling non - goal orient dialog agent ( i.e. chatbot ) aim produce varying engaging conversation user ; , typically exhibit inconsistent personality conversation average personality user . paper address issue control agent persona generation conditioning prior conversation target actor . , able utilize abstract pattern person speech well emulate generate response . work introduce generative conversation control model , augment fine - tune gpt-2 language model condition past reference conversation probabilistically model multi - turn conversation actor persona . introduce accompany data collection procedure obtain 10.3 m conversation 6 month worth reddit comment . demonstrate scale model size 117 m 8.3b parameter yield improvement 23.14 13.14 perplexity 1.7 m hold reddit conversation . increase model scale yield similar improvement human evaluation measure preference model sample hold target distribution term realism ( 31 % increase 37 % preference ) , style matching ( 37 % 42 % ) , grammar content quality ( 29 % 42 % ) , conversation coherency ( 32 % 40 % ) . find conditionally model past conversation improve perplexity 0.47 automatic evaluation . human trial identify positive trend conditional modeling style matching outline step improve persona control . * author contribute equally . â€  research conduct internship nvidia .","{'Computational Social Science and Social Media': 10, 'Dialogue and Interactive Systems': 15, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 9, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Conversational Word Embedding for Retrieval-Based Dialog System,"Human conversations contain many types of information, e.g., knowledge, common sense, and language habits. In this paper, we propose a conversational word embedding method named PR-Embedding, which utilizes the conversation pairs post, reply 1 to learn word embedding. Different from previous works, PR-Embedding uses the vectors from two different semantic spaces to represent the words in post and reply. To catch the information among the pair, we first introduce the word alignment model from statistical machine translation to generate the cross-sentence window, then train the embedding on word-level and sentence-level. We evaluate the method on single-turn and multi-turn response selection tasks for retrieval-based dialog systems. The experiment results show that PR-Embedding can improve the quality of the selected response. 2","Conversational Word Embedding for Retrieval-Based Dialog System Human conversations contain many types of information, e.g., knowledge, common sense, and language habits. In this paper, we propose a conversational word embedding method named PR-Embedding, which utilizes the conversation pairs post, reply 1 to learn word embedding. Different from previous works, PR-Embedding uses the vectors from two different semantic spaces to represent the words in post and reply. To catch the information among the pair, we first introduce the word alignment model from statistical machine translation to generate the cross-sentence window, then train the embedding on word-level and sentence-level. We evaluate the method on single-turn and multi-turn response selection tasks for retrieval-based dialog systems. The experiment results show that PR-Embedding can improve the quality of the selected response. 2","conversational word embedding retrieval - base dialog system human conversation contain type information , e.g. , knowledge , common sense , language habit . paper , propose conversational word embedding method name pr - embedding , utilize conversation pair post , reply 1 learn word embedding . different previous work , pr - embedding use vector different semantic space represent word post reply . catch information pair , introduce word alignment model statistical machine translation generate cross - sentence window , train embedding word - level sentence - level . evaluate method single - turn multi - turn response selection task retrieval - base dialog system . experiment result pr - embedding improve quality select response . 2","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 11, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Dialogue and Interactive Systems,Recursive Template-based Frame Generation for Task Oriented Dialog,"The Natural Language Understanding (NLU) component in task oriented dialog systems processes a user's request and converts it into structured information that can be consumed by downstream components such as the Dialog State Tracker (DST). This information is typically represented as a semantic frame that captures the intent and slot-labels provided by the user. We first show that such a shallow representation is insufficient for complex dialog scenarios, because it does not capture the recursive nature inherent in many domains. We propose a recursive, hierarchical frame-based representation and show how to learn it from data. We formulate the frame generation task as a template-based tree decoding task, where the decoder recursively generates a template and then fills slot values into the template. We extend local tree-based loss functions with terms that provide global supervision and show how to optimize them end-to-end. We achieve a small improvement on the widely used ATIS dataset and a much larger improvement on a more complex dataset we describe here.","Recursive Template-based Frame Generation for Task Oriented Dialog The Natural Language Understanding (NLU) component in task oriented dialog systems processes a user's request and converts it into structured information that can be consumed by downstream components such as the Dialog State Tracker (DST). This information is typically represented as a semantic frame that captures the intent and slot-labels provided by the user. We first show that such a shallow representation is insufficient for complex dialog scenarios, because it does not capture the recursive nature inherent in many domains. We propose a recursive, hierarchical frame-based representation and show how to learn it from data. We formulate the frame generation task as a template-based tree decoding task, where the decoder recursively generates a template and then fills slot values into the template. We extend local tree-based loss functions with terms that provide global supervision and show how to optimize them end-to-end. We achieve a small improvement on the widely used ATIS dataset and a much larger improvement on a more complex dataset we describe here.","recursive template - base frame generation task orient dialog natural language understanding ( nlu ) component task orient dialog system process user request convert structured information consume downstream component dialog state tracker ( dst ) . information typically represent semantic frame capture intent slot - label provide user . shallow representation insufficient complex dialog scenario , capture recursive nature inherent domain . propose recursive , hierarchical frame - base representation learn datum . formulate frame generation task template - base tree decoding task , decoder recursively generate template fill slot value template . extend local tree - base loss function term provide global supervision optimize end - - end . achieve small improvement widely atis dataset large improvement complex dataset describe .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Conversational Graph Grounded Policy Learning for Open-Domain Conversation Generation,"To address the challenge of policy learning in open-domain multi-turn conversation, we propose to represent prior information about dialog transitions as a graph and learn a graph grounded dialog policy, aimed at fostering a more coherent and controllable dialog. To this end, we first construct a conversational graph (CG) from dialog corpora, in which there are vertices to represent ""what to say"" and ""how to say"", and edges to represent natural transition between a message (the last utterance in a dialog context) and its response. We then present a novel CG grounded policy learning framework that conducts dialog flow planning by graph traversal, which learns to identify a what-vertex and a how-vertex from the CG at each turn to guide response generation. In this way, we effectively leverage the CG to facilitate policy learning as follows: (1) it enables more effective long-term reward design, (2) it provides high-quality candidate actions, and (3) it gives us more control over the policy. Results on two benchmark corpora demonstrate the effectiveness of this framework.","Conversational Graph Grounded Policy Learning for Open-Domain Conversation Generation To address the challenge of policy learning in open-domain multi-turn conversation, we propose to represent prior information about dialog transitions as a graph and learn a graph grounded dialog policy, aimed at fostering a more coherent and controllable dialog. To this end, we first construct a conversational graph (CG) from dialog corpora, in which there are vertices to represent ""what to say"" and ""how to say"", and edges to represent natural transition between a message (the last utterance in a dialog context) and its response. We then present a novel CG grounded policy learning framework that conducts dialog flow planning by graph traversal, which learns to identify a what-vertex and a how-vertex from the CG at each turn to guide response generation. In this way, we effectively leverage the CG to facilitate policy learning as follows: (1) it enables more effective long-term reward design, (2) it provides high-quality candidate actions, and (3) it gives us more control over the policy. Results on two benchmark corpora demonstrate the effectiveness of this framework.","conversational graph ground policy learning open - domain conversation generation address challenge policy learning open - domain multi - turn conversation , propose represent prior information dialog transition graph learn graph ground dialog policy , aim foster coherent controllable dialog . end , construct conversational graph ( cg ) dialog corpora , vertex represent "" "" "" "" , edge represent natural transition message ( utterance dialog context ) response . present novel cg ground policy learning framework conduct dialog flow planning graph traversal , learn identify - vertex - vertex cg turn guide response generation . way , effectively leverage cg facilitate policy learning follow : ( 1 ) enable effective long - term reward design , ( 2 ) provide high - quality candidate action , ( 3 ) give control policy . result benchmark corpus demonstrate effectiveness framework .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 14, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Towards Unsupervised Language Understanding and Generation by Joint Dual Learning,"In modular dialogue systems, natural language understanding (NLU) and natural language generation (NLG) are two critical components, where NLU extracts the semantics from the given texts and NLG is to construct corresponding natural language sentences based on the input semantic representations. However, the dual property between understanding and generation has been rarely explored. The prior work (Su et al., 2019) is the first attempt that utilized the duality between NLU and NLG to improve the performance via a dual supervised learning framework. However, the prior work still learned both components in a supervised manner; instead, this paper introduces a general learning framework to effectively exploit such duality, providing flexibility of incorporating both supervised and unsupervised learning algorithms to train language understanding and generation models in a joint fashion. The benchmark experiments demonstrate that the proposed approach is capable of boosting the performance of both NLU and NLG. 1","Towards Unsupervised Language Understanding and Generation by Joint Dual Learning In modular dialogue systems, natural language understanding (NLU) and natural language generation (NLG) are two critical components, where NLU extracts the semantics from the given texts and NLG is to construct corresponding natural language sentences based on the input semantic representations. However, the dual property between understanding and generation has been rarely explored. The prior work (Su et al., 2019) is the first attempt that utilized the duality between NLU and NLG to improve the performance via a dual supervised learning framework. However, the prior work still learned both components in a supervised manner; instead, this paper introduces a general learning framework to effectively exploit such duality, providing flexibility of incorporating both supervised and unsupervised learning algorithms to train language understanding and generation models in a joint fashion. The benchmark experiments demonstrate that the proposed approach is capable of boosting the performance of both NLU and NLG. 1","unsupervised language understanding generation joint dual learning modular dialogue system , natural language understanding ( nlu ) natural language generation ( nlg ) critical component , nlu extract semantic give text nlg construct corresponding natural language sentence base input semantic representation . , dual property understanding generation rarely explore . prior work ( su et al . , 2019 ) attempt utilize duality nlu nlg improve performance dual supervise learning framework . , prior work learn component supervised manner ; instead , paper introduce general learning framework effectively exploit duality , provide flexibility incorporate supervised unsupervised learning algorithm train language understanding generation model joint fashion . benchmark experiment demonstrate propose approach capable boost performance nlu nlg . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Dialogue and Interactive Systems,End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2,"The goal-oriented dialogue system needs to be optimized for tracking the dialogue flow and carrying out an effective conversation under various situations to meet the user goal. The traditional approach to building such a dialogue system is to take a pipelined modular architecture, where its modules are optimized individually. However, such an optimization scheme does not necessarily yield an overall performance improvement of the whole system. On the other hand, end-to-end dialogue systems with monolithic neural architecture are often trained only with input-output utterances, without taking into account the entire annotations available in the corpus. This scheme makes it difficult for goal-oriented dialogues where the system needs to be integrated with external systems or to provide interpretable information about why the system generated a particular response. In this paper, we present an end-to-end neural architecture for dialogue systems that addresses both challenges above. Our dialogue system achieved the success rate of 68.32%, the language understanding score of 4.149, and the response appropriateness score of 4.287 in human evaluations, which ranked the system at the top position in the end-to-end multi-domain dialogue system task in the 8th dialogue systems technology challenge (DSTC8).","End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2 The goal-oriented dialogue system needs to be optimized for tracking the dialogue flow and carrying out an effective conversation under various situations to meet the user goal. The traditional approach to building such a dialogue system is to take a pipelined modular architecture, where its modules are optimized individually. However, such an optimization scheme does not necessarily yield an overall performance improvement of the whole system. On the other hand, end-to-end dialogue systems with monolithic neural architecture are often trained only with input-output utterances, without taking into account the entire annotations available in the corpus. This scheme makes it difficult for goal-oriented dialogues where the system needs to be integrated with external systems or to provide interpretable information about why the system generated a particular response. In this paper, we present an end-to-end neural architecture for dialogue systems that addresses both challenges above. Our dialogue system achieved the success rate of 68.32%, the language understanding score of 4.149, and the response appropriateness score of 4.287 in human evaluations, which ranked the system at the top position in the end-to-end multi-domain dialogue system task in the 8th dialogue systems technology challenge (DSTC8).","end - - end neural pipeline goal - orient dialogue system gpt-2 goal - orient dialogue system need optimize track dialogue flow carry effective conversation situation meet user goal . traditional approach build dialogue system pipelined modular architecture , module optimize individually . , optimization scheme necessarily yield overall performance improvement system . hand , end - - end dialogue system monolithic neural architecture train input - output utterance , take account entire annotation available corpus . scheme make difficult goal - orient dialogue system need integrate external system provide interpretable information system generate particular response . paper , present end - - end neural architecture dialogue system address challenge . dialogue system achieve success rate 68.32 % , language understanding score 4.149 , response appropriateness score 4.287 human evaluation , rank system position end - - end multi - domain dialogue system task 8th dialogue system technology challenge ( dstc8 ) .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 36, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 8, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 14, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Paraphrase Augmented Task-Oriented Dialog Generation,"Neural generative models have achieved promising performance on dialog generation tasks if given a huge data set. However, the lack of high-quality dialog data and the expensive data annotation process greatly limit their application in real-world settings. We propose a paraphrase augmented response generation (PARG) framework that jointly trains a paraphrase model and a response generation model to improve the dialog generation performance. We also design a method to automatically construct paraphrase training data set based on dialog state and dialog act labels. PARG is applicable to various dialog generation models, such as TSCP (Lei et al., 2018) and DAMD (Zhang et al., 2019) . Experimental results show that the proposed framework improves these state-of-the-art dialog models further on CamRest676 and MultiWOZ. PARG also significantly outperforms other data augmentation methods in dialog generation tasks, especially under low resource settings. 1 2","Paraphrase Augmented Task-Oriented Dialog Generation Neural generative models have achieved promising performance on dialog generation tasks if given a huge data set. However, the lack of high-quality dialog data and the expensive data annotation process greatly limit their application in real-world settings. We propose a paraphrase augmented response generation (PARG) framework that jointly trains a paraphrase model and a response generation model to improve the dialog generation performance. We also design a method to automatically construct paraphrase training data set based on dialog state and dialog act labels. PARG is applicable to various dialog generation models, such as TSCP (Lei et al., 2018) and DAMD (Zhang et al., 2019) . Experimental results show that the proposed framework improves these state-of-the-art dialog models further on CamRest676 and MultiWOZ. PARG also significantly outperforms other data augmentation methods in dialog generation tasks, especially under low resource settings. 1 2","paraphrase augmented task - orient dialog generation neural generative model achieve promising performance dialog generation task give huge data set . , lack high - quality dialog datum expensive datum annotation process greatly limit application real - world setting . propose paraphrase augment response generation ( parg ) framework jointly train paraphrase model response generation model improve dialog generation performance . design method automatically construct paraphrase training datum set base dialog state dialog act label . parg applicable dialog generation model , tscp ( lei et al . , 2018 ) damd ( zhang et al . , 2019 ) . experimental result propose framework improve state - - - art dialog model camrest676 multiwoz . parg significantly outperform data augmentation method dialog generation task , especially low resource setting . 1 2","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 12, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog,"Recent studies have shown remarkable success in end-to-end task-oriented dialog system. However, most neural models rely on large training data, which are only available for a certain number of task domains, such as navigation and scheduling. This makes it difficult to scalable for a new domain with limited labeled data. However, there has been relatively little research on how to effectively use data from all domains to improve the performance of each domain and also unseen domains. To this end, we investigate methods that can make explicit use of domain knowledge and introduce a shared-private network to learn shared and specific knowledge. In addition, we propose a novel Dynamic Fusion Network (DF-Net) which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature. Besides, with little training data, we show its transferability by outperforming prior best model by 13.9% on average.","Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog Recent studies have shown remarkable success in end-to-end task-oriented dialog system. However, most neural models rely on large training data, which are only available for a certain number of task domains, such as navigation and scheduling. This makes it difficult to scalable for a new domain with limited labeled data. However, there has been relatively little research on how to effectively use data from all domains to improve the performance of each domain and also unseen domains. To this end, we investigate methods that can make explicit use of domain knowledge and introduce a shared-private network to learn shared and specific knowledge. In addition, we propose a novel Dynamic Fusion Network (DF-Net) which automatically exploit the relevance between the target domain and each domain. Results show that our model outperforms existing methods on multi-domain dialogue, giving the state-of-the-art in the literature. Besides, with little training data, we show its transferability by outperforming prior best model by 13.9% on average.","dynamic fusion network multi - domain end - - end task - orient dialog recent study show remarkable success end - - end task - orient dialog system . , neural model rely large training datum , available certain number task domain , navigation scheduling . make difficult scalable new domain limited label datum . , relatively little research effectively use datum domain improve performance domain unseen domain . end , investigate method explicit use domain knowledge introduce share - private network learn shared specific knowledge . addition , propose novel dynamic fusion network ( df - net ) automatically exploit relevance target domain domain . result model outperform exist method multi - domain dialogue , give state - - - art literature . , little training datum , transferability outperform prior good model 13.9 % average .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network,"Data-driven approaches using neural networks have achieved promising performances in natural language generation (NLG). However, neural generators are prone to make mistakes, e.g., neglecting an input slot value and generating a redundant slot value. Prior works refer this to hallucination phenomenon. In this paper, we study slot consistency for building reliable NLG systems with all slot values of input dialogue act (DA) properly generated in output sentences. We propose Iterative Rectification Network (IRN) for improving general NLG systems to produce both correct and fluent responses. It applies a bootstrapping algorithm to sample training candidates and uses reinforcement learning to incorporate discrete reward related to slot inconsistency into training. Comprehensive studies have been conducted on multiple benchmark datasets, showing that the proposed methods have significantly reduced the slot error rate (ERR) for all strong baselines. Human evaluations also have confirmed its effectiveness.","Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network Data-driven approaches using neural networks have achieved promising performances in natural language generation (NLG). However, neural generators are prone to make mistakes, e.g., neglecting an input slot value and generating a redundant slot value. Prior works refer this to hallucination phenomenon. In this paper, we study slot consistency for building reliable NLG systems with all slot values of input dialogue act (DA) properly generated in output sentences. We propose Iterative Rectification Network (IRN) for improving general NLG systems to produce both correct and fluent responses. It applies a bootstrapping algorithm to sample training candidates and uses reinforcement learning to incorporate discrete reward related to slot inconsistency into training. Comprehensive studies have been conducted on multiple benchmark datasets, showing that the proposed methods have significantly reduced the slot error rate (ERR) for all strong baselines. Human evaluations also have confirmed its effectiveness.","slot - consistent nlg task - orient dialogue system iterative rectification network data - drive approach neural network achieve promising performance natural language generation ( nlg ) . , neural generator prone mistake , e.g. , neglect input slot value generate redundant slot value . prior work refer hallucination phenomenon . paper , study slot consistency build reliable nlg system slot value input dialogue act ( da ) properly generate output sentence . propose iterative rectification network ( irn ) improve general nlg system produce correct fluent response . apply bootstrappe algorithm sample training candidate use reinforcement learning incorporate discrete reward relate slot inconsistency training . comprehensive study conduct multiple benchmark dataset , show propose method significantly reduce slot error rate ( err ) strong baseline . human evaluation confirm effectiveness .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 14, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback,"We study the task of semantic parse correction with natural language feedback. Given a natural language utterance, most semantic parsing systems pose the problem as one-shot translation where the utterance is mapped to a corresponding logical form. In this paper, we investigate a more interactive scenario where humans can further interact with the system by providing free-form natural language feedback to correct the system when it generates an inaccurate interpretation of an initial utterance. We focus on natural language to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL interpretations and the corresponding natural language feedback. We compare various reference models for the correction task and show that incorporating such a rich form of feedback can significantly improve the overall semantic parsing accuracy while retaining the flexibility of natural language interaction. While we estimated human correction accuracy is 81.5%, our best model achieves only 25.1%, which leaves a large gap for improvement in future research. SPLASH is publicly available at https:// aka.ms/Splash_dataset.","Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback We study the task of semantic parse correction with natural language feedback. Given a natural language utterance, most semantic parsing systems pose the problem as one-shot translation where the utterance is mapped to a corresponding logical form. In this paper, we investigate a more interactive scenario where humans can further interact with the system by providing free-form natural language feedback to correct the system when it generates an inaccurate interpretation of an initial utterance. We focus on natural language to SQL systems and construct, SPLASH, a dataset of utterances, incorrect SQL interpretations and the corresponding natural language feedback. We compare various reference models for the correction task and show that incorporating such a rich form of feedback can significantly improve the overall semantic parsing accuracy while retaining the flexibility of natural language interaction. While we estimated human correction accuracy is 81.5%, our best model achieves only 25.1%, which leaves a large gap for improvement in future research. SPLASH is publicly available at https:// aka.ms/Splash_dataset.","speak parser : interactive text - - sql natural language feedback study task semantic parse correction natural language feedback . give natural language utterance , semantic parsing system pose problem - shot translation utterance map corresponding logical form . paper , investigate interactive scenario human interact system provide free - form natural language feedback correct system generate inaccurate interpretation initial utterance . focus natural language sql system construct , splash , dataset utterance , incorrect sql interpretation corresponding natural language feedback . compare reference model correction task incorporate rich form feedback significantly improve overall semantic parsing accuracy retain flexibility natural language interaction . estimate human correction accuracy 81.5 % , good model achieve 25.1 % , leave large gap improvement future research . splash publicly available https:// aka.ms/splash_dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 7, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Dialogue and Interactive Systems,Unknown Intent Detection Using Gaussian Mixture Model with an Application to Zero-shot Intent Classification,"User intent classification plays a vital role in dialogue systems. Since user intent may frequently change over time in many realistic scenarios, unknown (new) intent detection has become an essential problem, where the study has just begun. This paper proposes a semantic-enhanced Gaussian mixture model (SEG) for unknown intent detection. In particular, we model utterance embeddings with a Gaussian mixture distribution and inject dynamic class semantic information into Gaussian means, which enables learning more classconcentrated embeddings that help to facilitate downstream outlier detection. Coupled with a density-based outlier detection algorithm, SEG achieves competitive results on three real task-oriented dialogue datasets in two languages for unknown intent detection. On top of that, we propose to integrate SEG as an unknown intent identifier into existing generalized zero-shot intent classification models to improve their performance. A case study on a state-of-the-art method, ReCapsNet, shows that SEG can push the classification performance to a significantly higher level.","Unknown Intent Detection Using Gaussian Mixture Model with an Application to Zero-shot Intent Classification User intent classification plays a vital role in dialogue systems. Since user intent may frequently change over time in many realistic scenarios, unknown (new) intent detection has become an essential problem, where the study has just begun. This paper proposes a semantic-enhanced Gaussian mixture model (SEG) for unknown intent detection. In particular, we model utterance embeddings with a Gaussian mixture distribution and inject dynamic class semantic information into Gaussian means, which enables learning more classconcentrated embeddings that help to facilitate downstream outlier detection. Coupled with a density-based outlier detection algorithm, SEG achieves competitive results on three real task-oriented dialogue datasets in two languages for unknown intent detection. On top of that, we propose to integrate SEG as an unknown intent identifier into existing generalized zero-shot intent classification models to improve their performance. A case study on a state-of-the-art method, ReCapsNet, shows that SEG can push the classification performance to a significantly higher level.","unknown intent detection gaussian mixture model application zero - shot intent classification user intent classification play vital role dialogue system . user intent frequently change time realistic scenario , unknown ( new ) intent detection essential problem , study begin . paper propose semantic - enhance gaussian mixture model ( seg ) unknown intent detection . particular , model utterance embedding gaussian mixture distribution inject dynamic class semantic information gaussian mean , enable learn classconcentrated embedding help facilitate downstream outlier detection . couple density - base outlier detection algorithm , seg achieve competitive result real task - orient dialogue dataset language unknown intent detection . , propose integrate seg unknown intent identifier exist generalized zero - shot intent classification model improve performance . case study state - - - art method , recapsnet , show seg push classification performance significantly high level .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Meta-Reinforced Multi-Domain State Generator for Dialogue Systems,"A Dialogue State Tracker (DST) is a core component of a modular task-oriented dialogue system. Tremendous progress has been made in recent years. However, the major challenges remain. The state-of-the-art accuracy for DST is below 50% for a multi-domain dialogue task. A learnable DST for any new domain requires a large amount of labeled indomain data and training from scratch. In this paper, we propose a Meta-Reinforced Multi-Domain State Generator (MERET). Our first contribution is to improve the DST accuracy. We enhance a neural model based DST generator with a reward manager, which is built on policy gradient reinforcement learning (R-L) to fine-tune the generator. With this change, we are able to improve the joint accuracy of DST from 48.79% to 50.91% on the Multi-WOZ corpus. Second, we explore to train a DST meta-learning model with a few domains as source domains and a new domain as target domain. We apply the model-agnostic metalearning (MAML) algorithm to DST and the obtained meta-learning model is used for new domain adaptation. Our experimental results show this solution is able to outperform the traditional training approach with extremely less training data in target domain.","Meta-Reinforced Multi-Domain State Generator for Dialogue Systems A Dialogue State Tracker (DST) is a core component of a modular task-oriented dialogue system. Tremendous progress has been made in recent years. However, the major challenges remain. The state-of-the-art accuracy for DST is below 50% for a multi-domain dialogue task. A learnable DST for any new domain requires a large amount of labeled indomain data and training from scratch. In this paper, we propose a Meta-Reinforced Multi-Domain State Generator (MERET). Our first contribution is to improve the DST accuracy. We enhance a neural model based DST generator with a reward manager, which is built on policy gradient reinforcement learning (R-L) to fine-tune the generator. With this change, we are able to improve the joint accuracy of DST from 48.79% to 50.91% on the Multi-WOZ corpus. Second, we explore to train a DST meta-learning model with a few domains as source domains and a new domain as target domain. We apply the model-agnostic metalearning (MAML) algorithm to DST and the obtained meta-learning model is used for new domain adaptation. Our experimental results show this solution is able to outperform the traditional training approach with extremely less training data in target domain.","meta - reinforced multi - domain state generator dialogue system dialogue state tracker ( dst ) core component modular task - orient dialogue system . tremendous progress recent year . , major challenge remain . state - - - art accuracy dst 50 % multi - domain dialogue task . learnable dst new domain require large label indomain datum training scratch . paper , propose meta - reinforced multi - domain state generator ( meret ) . contribution improve dst accuracy . enhance neural model base dst generator reward manager , build policy gradient reinforcement learning ( r - l ) fine - tune generator . change , able improve joint accuracy dst 48.79 % 50.91 % multi - woz corpus . second , explore train dst meta - learning model domain source domain new domain target domain . apply model - agnostic metalearning ( maml ) algorithm dst obtain meta - learning model new domain adaptation . experimental result solution able outperform traditional training approach extremely training datum target domain .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 20, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Image-Chat: Engaging Grounded Conversations,"To achieve the long-term goal of machines being able to engage humans in conversation, our models should captivate the interest of their speaking partners. Communication grounded in images, whereby a dialogue is conducted based on a given photo, is a setup naturally appealing to humans (Hu et al., 2014) . In this work we study large-scale architectures and datasets for this goal. We test a set of neural architectures using state-of-the-art image and text representations, considering various ways to fuse the components. To test such models, we collect a dataset of grounded human-human conversations, where speakers are asked to play roles given a provided emotional mood or style, as the use of such traits is also a key factor in engagingness (Guo et al., 2019) . Our dataset, Image-Chat, consists of 202k dialogues over 202k images using 215 possible style traits. Automatic metrics and human evaluations of engagingness show the efficacy of our approach; in particular, we obtain state-of-the-art performance on the existing IGC task, and our best performing model is almost on par with humans on the Image-Chat test set (preferred 47.7% of the time).","Image-Chat: Engaging Grounded Conversations To achieve the long-term goal of machines being able to engage humans in conversation, our models should captivate the interest of their speaking partners. Communication grounded in images, whereby a dialogue is conducted based on a given photo, is a setup naturally appealing to humans (Hu et al., 2014) . In this work we study large-scale architectures and datasets for this goal. We test a set of neural architectures using state-of-the-art image and text representations, considering various ways to fuse the components. To test such models, we collect a dataset of grounded human-human conversations, where speakers are asked to play roles given a provided emotional mood or style, as the use of such traits is also a key factor in engagingness (Guo et al., 2019) . Our dataset, Image-Chat, consists of 202k dialogues over 202k images using 215 possible style traits. Automatic metrics and human evaluations of engagingness show the efficacy of our approach; in particular, we obtain state-of-the-art performance on the existing IGC task, and our best performing model is almost on par with humans on the Image-Chat test set (preferred 47.7% of the time).","image - chat : engage ground conversation achieve long - term goal machine able engage human conversation , model captivate interest speak partner . communication ground image , dialogue conduct base give photo , setup naturally appeal human ( hu et al . , 2014 ) . work study large - scale architecture dataset goal . test set neural architecture state - - - art image text representation , consider way fuse component . test model , collect dataset ground human - human conversation , speaker ask play role give provide emotional mood style , use trait key factor engagingness ( guo et al . , 2019 ) . dataset , image - chat , consist 202k dialogue 202k image 215 possible style trait . automatic metric human evaluation engagingness efficacy approach ; particular , obtain state - - - art performance exist igc task , well perform model par human image - chat test set ( prefer 47.7 % time ) .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 7, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation,"The research of knowledge-driven conversational systems is largely limited due to the lack of dialog data which consists of multi-turn conversations on multiple topics and with knowledge annotations. In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs. Our corpus contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics. To facilitate the following research on this corpus, we provide several benchmark models. Comparative results show that the models can be enhanced by introducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available 1 .","KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation The research of knowledge-driven conversational systems is largely limited due to the lack of dialog data which consists of multi-turn conversations on multiple topics and with knowledge annotations. In this paper, we propose a Chinese multi-domain knowledge-driven conversation dataset, KdConv, which grounds the topics in multi-turn conversations to knowledge graphs. Our corpus contains 4.5K conversations from three domains (film, music, and travel), and 86K utterances with an average turn number of 19.0. These conversations contain in-depth discussions on related topics and natural transition between multiple topics. To facilitate the following research on this corpus, we provide several benchmark models. Comparative results show that the models can be enhanced by introducing background knowledge, yet there is still a large space for leveraging knowledge to model multi-turn conversations for further research. Results also show that there are obvious performance differences between different domains, indicating that it is worth further explore transfer learning and domain adaptation. The corpus and benchmark models are publicly available 1 .","kdconv : chinese multi - domain dialogue dataset multi - turn knowledge - drive conversation research knowledge - drive conversational system largely limited lack dialog data consist multi - turn conversation multiple topic knowledge annotation . paper , propose chinese multi - domain knowledge - drive conversation dataset , kdconv , ground topic multi - turn conversation knowledge graph . corpus contain 4.5 k conversation domain ( film , music , travel ) , 86 k utterance average turn number 19.0 . conversation contain - depth discussion related topic natural transition multiple topic . facilitate follow research corpus , provide benchmark model . comparative result model enhance introduce background knowledge , large space leverage knowledge model multi - turn conversation research . result obvious performance difference different domain , indicate worth explore transfer learning domain adaptation . corpus benchmark model publicly available 1 .","{'Computational Social Science and Social Media': 8, 'Dialogue and Interactive Systems': 16, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable,"Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.","PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable Pre-training models have been proved effective for a wide range of natural language processing tasks. Inspired by this, we propose a novel dialogue generation pre-training framework to support various kinds of conversations, including chit-chat, knowledge grounded dialogues, and conversational question answering. In this framework, we adopt flexible attention mechanisms to fully leverage the bi-directional context and the uni-directional characteristic of language generation. We also introduce discrete latent variables to tackle the inherent one-to-many mapping problem in response generation. Two reciprocal tasks of response generation and latent act recognition are designed and carried out simultaneously within a shared network. Comprehensive experiments on three publicly available datasets verify the effectiveness and superiority of the proposed framework.","plato : pre - trained dialogue generation model discrete latent variable pre - training model prove effective wide range natural language processing task . inspire , propose novel dialogue generation pre - training framework support kind conversation , include chit - chat , knowledge ground dialogue , conversational question answering . framework , adopt flexible attention mechanism fully leverage bi - directional context uni - directional characteristic language generation . introduce discrete latent variable tackle inherent - - mapping problem response generation . reciprocal task response generation latent act recognition design carry simultaneously share network . comprehensive experiment publicly available dataset verify effectiveness superiority propose framework .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,"Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation","Maintaining a consistent personality in conversations is quite natural for human beings, but is still a non-trivial task for machines. The persona-based dialogue generation task is thus introduced to tackle the personalityinconsistent problem by incorporating explicit persona text into dialogue generation models. Despite the success of existing personabased models on generating human-like responses, their one-stage decoding framework can hardly avoid the generation of inconsistent persona words. In this work, we introduce a three-stage framework that employs a generate-delete-rewrite mechanism to delete inconsistent words from a generated response prototype and further rewrite it to a personality-consistent one. We carry out evaluations by both human and automatic metrics. Experiments on the Persona-Chat dataset show that our approach achieves good performance.","Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation Maintaining a consistent personality in conversations is quite natural for human beings, but is still a non-trivial task for machines. The persona-based dialogue generation task is thus introduced to tackle the personalityinconsistent problem by incorporating explicit persona text into dialogue generation models. Despite the success of existing personabased models on generating human-like responses, their one-stage decoding framework can hardly avoid the generation of inconsistent persona words. In this work, we introduce a three-stage framework that employs a generate-delete-rewrite mechanism to delete inconsistent words from a generated response prototype and further rewrite it to a personality-consistent one. We carry out evaluations by both human and automatic metrics. Experiments on the Persona-Chat dataset show that our approach achieves good performance.","generate , delete rewrite : - stage framework improve persona consistency dialogue generation maintain consistent personality conversation natural human being , non - trivial task machine . persona - base dialogue generation task introduce tackle personalityinconsistent problem incorporate explicit persona text dialogue generation model . despite success exist personabase model generate human - like response , - stage decoding framework hardly avoid generation inconsistent persona word . work , introduce - stage framework employ generate - delete - rewrite mechanism delete inconsistent word generate response prototype rewrite personality - consistent . carry evaluation human automatic metric . experiment persona - chat dataset approach achieve good performance .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Gated Convolutional Bidirectional Attention-based Model for Off-topic Spoken Response Detection,"Off-topic spoken response detection, the task aiming at predicting whether a response is offtopic for the corresponding prompt, is important for an automated speaking assessment system. In many real-world educational applications, off-topic spoken response detectors are required to achieve high recall for off-topic responses not only on seen prompts but also on prompts that are unseen during training. In this paper, we propose a novel approach for offtopic spoken response detection with high offtopic recall on both seen and unseen prompts. We introduce a new model, Gated Convolutional Bidirectional Attention-based Model (GCBiA), which applies bi-attention mechanism and convolutions to extract topic words of prompts and key-phrases of responses, and introduces gated unit and residual connections between major layers to better represent the relevance of responses and prompts. Moreover, a new negative sampling method is proposed to augment training data. Experiment results demonstrate that our novel approach can achieve significant improvements in detecting off-topic responses with extremely high ontopic recall, for both seen and unseen prompts.","Gated Convolutional Bidirectional Attention-based Model for Off-topic Spoken Response Detection Off-topic spoken response detection, the task aiming at predicting whether a response is offtopic for the corresponding prompt, is important for an automated speaking assessment system. In many real-world educational applications, off-topic spoken response detectors are required to achieve high recall for off-topic responses not only on seen prompts but also on prompts that are unseen during training. In this paper, we propose a novel approach for offtopic spoken response detection with high offtopic recall on both seen and unseen prompts. We introduce a new model, Gated Convolutional Bidirectional Attention-based Model (GCBiA), which applies bi-attention mechanism and convolutions to extract topic words of prompts and key-phrases of responses, and introduces gated unit and residual connections between major layers to better represent the relevance of responses and prompts. Moreover, a new negative sampling method is proposed to augment training data. Experiment results demonstrate that our novel approach can achieve significant improvements in detecting off-topic responses with extremely high ontopic recall, for both seen and unseen prompts.","gated convolutional bidirectional attention - base model - topic spoken response detection - topic speak response detection , task aim predict response offtopic corresponding prompt , important automate speaking assessment system . real - world educational application , - topic speak response detector require achieve high recall - topic response see prompt prompt unseen training . paper , propose novel approach offtopic speak response detection high offtopic recall seen unseen prompt . introduce new model , gated convolutional bidirectional attention - base model ( gcbia ) , apply bi - attention mechanism convolution extract topic word prompt key - phrase response , introduce gate unit residual connection major layer well represent relevance response prompt . , new negative sampling method propose augment training datum . experiment result demonstrate novel approach achieve significant improvement detect - topic response extremely high ontopic recall , seen unseen prompt .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 10, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Dialogue and Interactive Systems,Guiding Variational Response Generator to Exploit Persona,"Leveraging persona information of users in Neural Response Generators (NRG) to perform personalized conversations has been considered as an attractive and important topic in the research of conversational agents over the past few years. Despite of the promising progress achieved by recent studies in this field, persona information tends to be incorporated into neural networks in the form of user embeddings, with the expectation that the persona can be involved via End-to-End learning. This paper proposes to adopt the personalityrelated characteristics of human conversations into variational response generators, by designing a specific conditional variational autoencoder based deep model with two new regularization terms employed to the loss function, so as to guide the optimization towards the direction of generating both persona-aware and relevant responses. Besides, to reasonably evaluate the performances of various persona modeling approaches, this paper further presents three direct persona-oriented metrics from different perspectives. The experimental results have shown that our proposed methodology can notably improve the performance of persona-aware response generation, and the metrics are reasonable to evaluate the results.","Guiding Variational Response Generator to Exploit Persona Leveraging persona information of users in Neural Response Generators (NRG) to perform personalized conversations has been considered as an attractive and important topic in the research of conversational agents over the past few years. Despite of the promising progress achieved by recent studies in this field, persona information tends to be incorporated into neural networks in the form of user embeddings, with the expectation that the persona can be involved via End-to-End learning. This paper proposes to adopt the personalityrelated characteristics of human conversations into variational response generators, by designing a specific conditional variational autoencoder based deep model with two new regularization terms employed to the loss function, so as to guide the optimization towards the direction of generating both persona-aware and relevant responses. Besides, to reasonably evaluate the performances of various persona modeling approaches, this paper further presents three direct persona-oriented metrics from different perspectives. The experimental results have shown that our proposed methodology can notably improve the performance of persona-aware response generation, and the metrics are reasonable to evaluate the results.","guide variational response generator exploit persona leverage persona information user neural response generators ( nrg ) perform personalized conversation consider attractive important topic research conversational agent past year . despite promising progress achieve recent study field , persona information tend incorporate neural network form user embedding , expectation persona involve end - - end learning . paper propose adopt personalityrelated characteristic human conversation variational response generator , design specific conditional variational autoencoder base deep model new regularization term employ loss function , guide optimization direction generate persona - aware relevant response . , reasonably evaluate performance persona modeling approach , paper present direct persona - orient metric different perspective . experimental result show propose methodology notably improve performance persona - aware response generation , metric reasonable evaluate result .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Neural Generation of Dialogue Response Timings,"The timings of spoken response offsets in human dialogue have been shown to vary based on contextual elements of the dialogue. We propose neural models that simulate the distributions of these response offsets, taking into account the response turn as well as the preceding turn. The models are designed to be integrated into the pipeline of an incremental spoken dialogue system (SDS). We evaluate our models using offline experiments as well as human listening tests. We show that human listeners consider certain response timings to be more natural based on the dialogue context. The introduction of these models into SDS pipelines could increase the perceived naturalness of interactions. 1","Neural Generation of Dialogue Response Timings The timings of spoken response offsets in human dialogue have been shown to vary based on contextual elements of the dialogue. We propose neural models that simulate the distributions of these response offsets, taking into account the response turn as well as the preceding turn. The models are designed to be integrated into the pipeline of an incremental spoken dialogue system (SDS). We evaluate our models using offline experiments as well as human listening tests. We show that human listeners consider certain response timings to be more natural based on the dialogue context. The introduction of these models into SDS pipelines could increase the perceived naturalness of interactions. 1","neural generation dialogue response timing timing speak response offset human dialogue show vary base contextual element dialogue . propose neural model simulate distribution response offset , take account response turn precede turn . model design integrate pipeline incremental speak dialogue system ( sds ) . evaluate model offline experiment human listening test . human listener consider certain response timing natural base dialogue context . introduction model sds pipeline increase perceive naturalness interaction . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 18, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for Automatic Dialog Evaluation,"Open Domain dialog system evaluation is one of the most important challenges in dialog research. Existing automatic evaluation metrics, such as BLEU are mostly referencebased. They calculate the difference between the generated response and a limited number of available references. Likert-score based self-reported user rating is widely adopted by social conversational systems, such as Amazon Alexa Prize chatbots. However, selfreported user rating suffers from bias and variance among different users. To alleviate this problem, we formulate dialog evaluation as a comparison task. We also propose an automatic evaluation model CMADE (Comparison Model for Automatic Dialog Evaluation) that automatically cleans self-reported user ratings as it trains on them. Specifically, we first use a self-supervised method to learn better dialog feature representation, and then use KNN and Shapley to remove confusing samples. Our experiments show that CMADE achieves 89.2% accuracy in the dialog comparison task. Our implementation is available at https://github.com/Weixin-Liang/ dialog_evaluation_CMADE.","Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for Automatic Dialog Evaluation Open Domain dialog system evaluation is one of the most important challenges in dialog research. Existing automatic evaluation metrics, such as BLEU are mostly referencebased. They calculate the difference between the generated response and a limited number of available references. Likert-score based self-reported user rating is widely adopted by social conversational systems, such as Amazon Alexa Prize chatbots. However, selfreported user rating suffers from bias and variance among different users. To alleviate this problem, we formulate dialog evaluation as a comparison task. We also propose an automatic evaluation model CMADE (Comparison Model for Automatic Dialog Evaluation) that automatically cleans self-reported user ratings as it trains on them. Specifically, we first use a self-supervised method to learn better dialog feature representation, and then use KNN and Shapley to remove confusing samples. Our experiments show that CMADE achieves 89.2% accuracy in the dialog comparison task. Our implementation is available at https://github.com/Weixin-Liang/ dialog_evaluation_CMADE.","user self - report likert scale rating : comparison model automatic dialog evaluation open domain dialog system evaluation important challenge dialog research . exist automatic evaluation metric , bleu referencebased . calculate difference generate response limited number available reference . likert - score base self - report user rating widely adopt social conversational system , amazon alexa prize chatbot . , selfreporte user rating suffer bias variance different user . alleviate problem , formulate dialog evaluation comparison task . propose automatic evaluation model cmade ( comparison model automatic dialog evaluation ) automatically clean self - report user rating train . specifically , use self - supervise method learn well dialog feature representation , use knn shapley remove confusing sample . experiment cmade achieve 89.2 % accuracy dialog comparison task . implementation available https://github.com/weixin-liang/ dialog_evaluation_cmade .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 14, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 8, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Dialogue and Interactive Systems,CraftAssist Instruction Parsing: Semantic Parsing for a Voxel-World Assistant,"We propose a semantic parsing dataset focused on instruction-driven communication with an agent in the game Minecraft 1 . The dataset consists of 7K human utterances and their corresponding parses. Given proper world state, the parses can be interpreted and executed in game. We report the performance of baseline models, and analyze their successes and failures.","CraftAssist Instruction Parsing: Semantic Parsing for a Voxel-World Assistant We propose a semantic parsing dataset focused on instruction-driven communication with an agent in the game Minecraft 1 . The dataset consists of 7K human utterances and their corresponding parses. Given proper world state, the parses can be interpreted and executed in game. We report the performance of baseline models, and analyze their successes and failures.","craftassist instruction parsing : semantic parsing voxel - world assistant propose semantic parsing dataset focus instruction - drive communication agent game minecraft 1 . dataset consist 7 k human utterance corresponding parse . give proper world state , parse interpret execute game . report performance baseline model , analyze success failure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Dialogue and Interactive Systems,Diversifying Dialogue Generation with Non-Conversational Text,"Neural network-based sequence-to-sequence (seq2seq) models strongly suffer from the lowdiversity problem when it comes to opendomain dialogue generation. As bland and generic utterances usually dominate the frequency distribution in our daily chitchat, avoiding them to generate more interesting responses requires complex data filtering, sampling techniques or modifying the training objective. In this paper, we propose a new perspective to diversify dialogue generation by leveraging non-conversational text. Compared with bilateral conversations, nonconversational text are easier to obtain, more diverse and cover a much broader range of topics. We collect a large-scale nonconversational corpus from multi sources including forum comments, idioms and book snippets. We further present a training paradigm to effectively incorporate these text via iterative back translation. The resulting model is tested on two conversational datasets and is shown to produce significantly more diverse responses without sacrificing the relevance with context.","Diversifying Dialogue Generation with Non-Conversational Text Neural network-based sequence-to-sequence (seq2seq) models strongly suffer from the lowdiversity problem when it comes to opendomain dialogue generation. As bland and generic utterances usually dominate the frequency distribution in our daily chitchat, avoiding them to generate more interesting responses requires complex data filtering, sampling techniques or modifying the training objective. In this paper, we propose a new perspective to diversify dialogue generation by leveraging non-conversational text. Compared with bilateral conversations, nonconversational text are easier to obtain, more diverse and cover a much broader range of topics. We collect a large-scale nonconversational corpus from multi sources including forum comments, idioms and book snippets. We further present a training paradigm to effectively incorporate these text via iterative back translation. The resulting model is tested on two conversational datasets and is shown to produce significantly more diverse responses without sacrificing the relevance with context.","diversify dialogue generation non - conversational text neural network - base sequence - - sequence ( seq2seq ) model strongly suffer lowdiversity problem come opendomain dialogue generation . bland generic utterance usually dominate frequency distribution daily chitchat , avoid generate interesting response require complex datum filtering , sampling technique modify training objective . paper , propose new perspective diversify dialogue generation leverage non - conversational text . compare bilateral conversation , nonconversational text easy obtain , diverse cover broad range topic . collect large - scale nonconversational corpus multi source include forum comment , idiom book snippet . present training paradigm effectively incorporate text iterative translation . result model test conversational dataset show produce significantly diverse response sacrifice relevance context .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 14, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition,"Many studies have applied reinforcement learning to train a dialog policy and show great promise these years. One common approach is to employ a user simulator to obtain a large number of simulated user experiences for reinforcement learning algorithms. However, modeling a realistic user simulator is challenging. A rule-based simulator requires heavy domain expertise for complex tasks, and a data-driven simulator requires considerable data and it is even unclear how to evaluate a simulator. To avoid explicitly building a user simulator beforehand, we propose Multi-Agent Dialog Policy Learning, which regards both the system and the user as the dialog agents. Two agents interact with each other and are jointly learned simultaneously. The method uses the actorcritic framework to facilitate pretraining and improve scalability. We also propose Hybrid Value Network for the role-aware reward decomposition to integrate role-specific domain knowledge of each agent in task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction.","Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition Many studies have applied reinforcement learning to train a dialog policy and show great promise these years. One common approach is to employ a user simulator to obtain a large number of simulated user experiences for reinforcement learning algorithms. However, modeling a realistic user simulator is challenging. A rule-based simulator requires heavy domain expertise for complex tasks, and a data-driven simulator requires considerable data and it is even unclear how to evaluate a simulator. To avoid explicitly building a user simulator beforehand, we propose Multi-Agent Dialog Policy Learning, which regards both the system and the user as the dialog agents. Two agents interact with each other and are jointly learned simultaneously. The method uses the actorcritic framework to facilitate pretraining and improve scalability. We also propose Hybrid Value Network for the role-aware reward decomposition to integrate role-specific domain knowledge of each agent in task-oriented dialog. Results show that our method can successfully build a system policy and a user policy simultaneously, and two agents can achieve a high task success rate through conversational interaction.","multi - agent task - orient dialog policy learning role - aware reward decomposition study apply reinforcement learning train dialog policy great promise year . common approach employ user simulator obtain large number simulate user experience reinforcement learning algorithm . , model realistic user simulator challenging . rule - base simulator require heavy domain expertise complex task , data - drive simulator require considerable datum unclear evaluate simulator . avoid explicitly build user simulator , propose multi - agent dialog policy learning , regard system user dialog agent . agent interact jointly learn simultaneously . method use actorcritic framework facilitate pretraining improve scalability . propose hybrid value network role - aware reward decomposition integrate role - specific domain knowledge agent task - orient dialog . result method successfully build system policy user policy simultaneously , agent achieve high task success rate conversational interaction .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 8, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness,"Generative dialogue systems tend to produce generic responses, which often leads to boring conversations. For alleviating this issue, Recent studies proposed to retrieve and introduce knowledge facts from knowledge graphs. While this paradigm works to a certain extent, it usually retrieves knowledge facts only based on the entity word itself, without considering the specific dialogue context. Thus, the introduction of the context-irrelevant knowledge facts can impact the quality of generations. To this end, this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI. We collect and build a large-scale Chinese dataset aligned with the commonsense knowledge for dialogue generation. Extensive evaluations over both an open-released English dataset and our Chinese dataset demonstrate that our approach ConKADI outperforms the state-of-the-art approach CCM, in most experiments.","Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness Generative dialogue systems tend to produce generic responses, which often leads to boring conversations. For alleviating this issue, Recent studies proposed to retrieve and introduce knowledge facts from knowledge graphs. While this paradigm works to a certain extent, it usually retrieves knowledge facts only based on the entity word itself, without considering the specific dialogue context. Thus, the introduction of the context-irrelevant knowledge facts can impact the quality of generations. To this end, this paper proposes a novel commonsense knowledge-aware dialogue generation model, ConKADI. We design a Felicitous Fact mechanism to help the model focus on the knowledge facts that are highly relevant to the context; furthermore, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion are proposed to facilitate the integration of the knowledge in the ConKADI. We collect and build a large-scale Chinese dataset aligned with the commonsense knowledge for dialogue generation. Extensive evaluations over both an open-released English dataset and our Chinese dataset demonstrate that our approach ConKADI outperforms the state-of-the-art approach CCM, in most experiments.","diverse informative dialogue generation context - specific commonsense knowledge awareness generative dialogue system tend produce generic response , lead boring conversation . alleviate issue , recent study propose retrieve introduce knowledge fact knowledge graph . paradigm work certain extent , usually retrieve knowledge fact base entity word , consider specific dialogue context . , introduction context - irrelevant knowledge fact impact quality generation . end , paper propose novel commonsense knowledge - aware dialogue generation model , conkadi . design felicitous fact mechanism help model focus knowledge fact highly relevant context ; furthermore , technique , context - knowledge fusion flexible mode fusion propose facilitate integration knowledge conkadi . collect build large - scale chinese dataset align commonsense knowledge dialogue generation . extensive evaluation open - release english dataset chinese dataset demonstrate approach conkadi outperform state - - - art approach ccm , experiment .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,SAS: Dialogue State Tracking via Slot Attention and Slot Information Sharing,"Dialogue state tracker is responsible for inferring user intentions through dialogue history. Previous methods have difficulties in handling dialogues with long interaction context, due to the excessive information. We propose a Dialogue State Tracker with Slot Attention and Slot Information Sharing (SAS) to reduce redundant information's interference and improve long dialogue context tracking. Specially, we first apply a Slot Attention to learn a set of slot-specific features from the original dialogue and then integrate them using a Slot Information Sharing. The sharing improve the models ability to deduce value from related slots. Our model yields a significantly improved performance compared to previous state-of-the-art models on the Multi-WOZ dataset.","SAS: Dialogue State Tracking via Slot Attention and Slot Information Sharing Dialogue state tracker is responsible for inferring user intentions through dialogue history. Previous methods have difficulties in handling dialogues with long interaction context, due to the excessive information. We propose a Dialogue State Tracker with Slot Attention and Slot Information Sharing (SAS) to reduce redundant information's interference and improve long dialogue context tracking. Specially, we first apply a Slot Attention to learn a set of slot-specific features from the original dialogue and then integrate them using a Slot Information Sharing. The sharing improve the models ability to deduce value from related slots. Our model yields a significantly improved performance compared to previous state-of-the-art models on the Multi-WOZ dataset.","sas : dialogue state tracking slot attention slot information sharing dialogue state tracker responsible infer user intention dialogue history . previous method difficulty handle dialogue long interaction context , excessive information . propose dialogue state tracker slot attention slot information sharing ( sas ) reduce redundant information interference improve long dialogue context tracking . specially , apply slot attention learn set slot - specific feature original dialogue integrate slot information sharing . sharing improve model ability deduce value related slot . model yield significantly improve performance compare previous state - - - art model multi - woz dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 25, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Modeling Long Context for Task-Oriented Dialogue State Generation,"Based on the recently proposed transferable dialogue state generator (TRADE) (Wu  et al., 2019)  that predicts dialogue states from utterance-concatenated dialogue context, we propose a multi-task learning model with a simple yet effective utterance tagging technique and a bidirectional language model as an auxiliary task for task-oriented dialogue state generation. By enabling the model to learn a better representation of the long dialogue context, our approaches attempt to solve the problem that the performance of the baseline significantly drops when the input dialogue context sequence is long. In our experiments, our proposed model achieves a 7.03% relative improvement over the baseline, establishing a new state-of-the-art joint goal accuracy of 52.04% on the MultiWOZ 2.0 dataset.","Modeling Long Context for Task-Oriented Dialogue State Generation Based on the recently proposed transferable dialogue state generator (TRADE) (Wu  et al., 2019)  that predicts dialogue states from utterance-concatenated dialogue context, we propose a multi-task learning model with a simple yet effective utterance tagging technique and a bidirectional language model as an auxiliary task for task-oriented dialogue state generation. By enabling the model to learn a better representation of the long dialogue context, our approaches attempt to solve the problem that the performance of the baseline significantly drops when the input dialogue context sequence is long. In our experiments, our proposed model achieves a 7.03% relative improvement over the baseline, establishing a new state-of-the-art joint goal accuracy of 52.04% on the MultiWOZ 2.0 dataset.","model long context task - orient dialogue state generation base recently propose transferable dialogue state generator ( trade ) ( wu   et al . , 2019 )   predict dialogue state utterance - concatenate dialogue context , propose multi - task learning model simple effective utterance tagging technique bidirectional language model auxiliary task task - orient dialogue state generation . enable model learn well representation long dialogue context , approach attempt solve problem performance baseline significantly drop input dialogue context sequence long . experiment , propose model achieve 7.03 % relative improvement baseline , establish new state - - - art joint goal accuracy 52.04 % multiwoz 2.0 dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 20, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Efficient Dialogue State Tracking by Selectively Overwriting Memory,"Recent works in dialogue state tracking (DST)   focus on an open vocabulary-based setting to resolve scalability and generalization issues of the predefined ontology-based approaches. However, they are inefficient in that they predict the dialogue state at every turn from scratch. Here, we consider dialogue state as an explicit fixed-sized memory and propose a selectively overwriting mechanism for more efficient DST. This mechanism consists of two steps: (1) predicting state operation on each of the memory slots, and (2) overwriting the memory with new values, of which only a few are generated according to the predicted state operations. Our method decomposes DST into two sub-tasks and guides the decoder to focus only on one of the tasks, thus reducing the burden of the decoder. This enhances the effectiveness of training and DST performance. Our SOM-DST (Selectively Overwriting Memory for Dialogue State Tracking) model achieves state-of-theart joint goal accuracy with 51.72% in Mul-tiWOZ 2.0 and 53.01% in MultiWOZ 2.1 in an open vocabulary-based DST setting. In addition, we analyze the accuracy gaps between the current and the ground truth-given situations and suggest that it is a promising direction to improve state operation prediction to boost the DST performance. 1","Efficient Dialogue State Tracking by Selectively Overwriting Memory Recent works in dialogue state tracking (DST)   focus on an open vocabulary-based setting to resolve scalability and generalization issues of the predefined ontology-based approaches. However, they are inefficient in that they predict the dialogue state at every turn from scratch. Here, we consider dialogue state as an explicit fixed-sized memory and propose a selectively overwriting mechanism for more efficient DST. This mechanism consists of two steps: (1) predicting state operation on each of the memory slots, and (2) overwriting the memory with new values, of which only a few are generated according to the predicted state operations. Our method decomposes DST into two sub-tasks and guides the decoder to focus only on one of the tasks, thus reducing the burden of the decoder. This enhances the effectiveness of training and DST performance. Our SOM-DST (Selectively Overwriting Memory for Dialogue State Tracking) model achieves state-of-theart joint goal accuracy with 51.72% in Mul-tiWOZ 2.0 and 53.01% in MultiWOZ 2.1 in an open vocabulary-based DST setting. In addition, we analyze the accuracy gaps between the current and the ground truth-given situations and suggest that it is a promising direction to improve state operation prediction to boost the DST performance. 1","efficient dialogue state tracking selectively overwrite memory recent work dialogue state tracking ( dst )    focus open vocabulary - base setting resolve scalability generalization issue predefine ontology - base approach . , inefficient predict dialogue state turn scratch . , consider dialogue state explicit fix - sized memory propose selectively overwrite mechanism efficient dst . mechanism consist step : ( 1 ) predict state operation memory slot , ( 2 ) overwrite memory new value , generate accord predict state operation . method decompose dst sub - task guide decoder focus task , reduce burden decoder . enhance effectiveness training dst performance . som - dst ( selectively overwrite memory dialogue state tracking ) model achieve state - - theart joint goal accuracy 51.72 % mul - tiwoz 2.0 53.01 % multiwoz 2.1 open vocabulary - base dst setting . addition , analyze accuracy gap current ground truth - give situation suggest promising direction improve state operation prediction boost dst performance . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 24, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking,"Recent studies in dialogue state tracking (DST) leverage historical information to determine states which are generally represented as slot-value pairs. However, most of them have limitations to efficiently exploit relevant context due to the lack of a powerful mechanism for modeling interactions between the slot and the dialogue history. Besides, existing methods usually ignore the slot imbalance problem and treat all slots indiscriminately, which limits the learning of hard slots and eventually hurts overall performance. In this paper, we propose to enhance the DST through employing a contextual hierarchical attention network to not only discern relevant information at both word level and turn level but also learn contextual representations. We further propose an adaptive objective to alleviate the slot imbalance problem by dynamically adjust weights of different slots during training. Experimental results show that our approach reaches 52.68% and 58.55% joint accuracy on MultiWOZ 2.0 and MultiWOZ 2.1 datasets respectively and achieves new stateof-the-art performance with considerable improvements (+1.24% and +5.98%). 1","A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking Recent studies in dialogue state tracking (DST) leverage historical information to determine states which are generally represented as slot-value pairs. However, most of them have limitations to efficiently exploit relevant context due to the lack of a powerful mechanism for modeling interactions between the slot and the dialogue history. Besides, existing methods usually ignore the slot imbalance problem and treat all slots indiscriminately, which limits the learning of hard slots and eventually hurts overall performance. In this paper, we propose to enhance the DST through employing a contextual hierarchical attention network to not only discern relevant information at both word level and turn level but also learn contextual representations. We further propose an adaptive objective to alleviate the slot imbalance problem by dynamically adjust weights of different slots during training. Experimental results show that our approach reaches 52.68% and 58.55% joint accuracy on MultiWOZ 2.0 and MultiWOZ 2.1 datasets respectively and achieves new stateof-the-art performance with considerable improvements (+1.24% and +5.98%). 1","contextual hierarchical attention network adaptive objective dialogue state tracking recent study dialogue state tracking ( dst ) leverage historical information determine state generally represent slot - value pair . , limitation efficiently exploit relevant context lack powerful mechanism model interaction slot dialogue history . , exist method usually ignore slot imbalance problem treat slot indiscriminately , limit learning hard slot eventually hurt overall performance . paper , propose enhance dst employ contextual hierarchical attention network discern relevant information word level turn level learn contextual representation . propose adaptive objective alleviate slot imbalance problem dynamically adjust weight different slot training . experimental result approach reach 52.68 % 58.55 % joint accuracy multiwoz 2.0 multiwoz 2.1 dataset respectively achieve new stateof - - art performance considerable improvement ( +1.24 % +5.98 % ) . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 18, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Speaker Sensitive Response Evaluation Model,"Automatic evaluation of open-domain dialogue response generation is very challenging because there are many appropriate responses for a given context. Existing evaluation models merely compare the generated response with the ground truth response and rate many of the appropriate responses as inappropriate if they deviate from the ground truth. One approach to resolve this problem is to consider the similarity of the generated response with the conversational context. In this paper, we propose an automatic evaluation model based on that idea and learn the model parameters from an unlabeled conversation corpus. Our approach considers the speakers in defining the different levels of similar context. We use a Twitter conversation corpus that contains many speakers and conversations to test our evaluation model. Experiments show that our model outperforms the other existing evaluation metrics in terms of high correlation with human annotation scores. We also show that our model trained on Twitter can be applied to movie dialogues without any additional training. We provide our code and the learned parameters so that they can be used for automatic evaluation of dialogue response generation models. Context A: What do you want to do tonight? B: Why don't we go see a movie? Ground truth response A: Yeah Let's go to the theater Utterance BLEU ROUGE EMB RUBER SSREM Human A1 That sounds good! Have you seen Thor? 0.00 (3) 0.00 (3) 0.95 (2) 0.59 (2) 0.64 (1) 5.00 (1) A2 Good, What movie? 0.00 (3) 0.00 (3) 0.92 (4) 0.55 (4) 0.62 (2) 5.00 (1) A3 Or hang out in city 0.00 (3) 0.00 (3) 0.89 (6) 0.48 (5) 0.49 (3) 3.80 (3) N1 The weather is no good for walking 0.32 (1) 0.15 (2) 0.94 (3) 0.47 (6) 0.44 (4) 2.60 (4) N2 The sight is extra beautiful here 0.32 (1) 0.17 (1) 0.97 (1) 0.64 (1) 0.38 (5) 1.00 (5) N3 Enjoy your concert 0.00 (3) 0.00 (3) 0.91 (5) 0.57 (3) 0.33 (6) 1.00 (5)","Speaker Sensitive Response Evaluation Model Automatic evaluation of open-domain dialogue response generation is very challenging because there are many appropriate responses for a given context. Existing evaluation models merely compare the generated response with the ground truth response and rate many of the appropriate responses as inappropriate if they deviate from the ground truth. One approach to resolve this problem is to consider the similarity of the generated response with the conversational context. In this paper, we propose an automatic evaluation model based on that idea and learn the model parameters from an unlabeled conversation corpus. Our approach considers the speakers in defining the different levels of similar context. We use a Twitter conversation corpus that contains many speakers and conversations to test our evaluation model. Experiments show that our model outperforms the other existing evaluation metrics in terms of high correlation with human annotation scores. We also show that our model trained on Twitter can be applied to movie dialogues without any additional training. We provide our code and the learned parameters so that they can be used for automatic evaluation of dialogue response generation models. Context A: What do you want to do tonight? B: Why don't we go see a movie? Ground truth response A: Yeah Let's go to the theater Utterance BLEU ROUGE EMB RUBER SSREM Human A1 That sounds good! Have you seen Thor? 0.00 (3) 0.00 (3) 0.95 (2) 0.59 (2) 0.64 (1) 5.00 (1) A2 Good, What movie? 0.00 (3) 0.00 (3) 0.92 (4) 0.55 (4) 0.62 (2) 5.00 (1) A3 Or hang out in city 0.00 (3) 0.00 (3) 0.89 (6) 0.48 (5) 0.49 (3) 3.80 (3) N1 The weather is no good for walking 0.32 (1) 0.15 (2) 0.94 (3) 0.47 (6) 0.44 (4) 2.60 (4) N2 The sight is extra beautiful here 0.32 (1) 0.17 (1) 0.97 (1) 0.64 (1) 0.38 (5) 1.00 (5) N3 Enjoy your concert 0.00 (3) 0.00 (3) 0.91 (5) 0.57 (3) 0.33 (6) 1.00 (5)","speaker sensitive response evaluation model automatic evaluation open - domain dialogue response generation challenging appropriate response give context . exist evaluation model merely compare generate response ground truth response rate appropriate response inappropriate deviate ground truth . approach resolve problem consider similarity generate response conversational context . paper , propose automatic evaluation model base idea learn model parameter unlabeled conversation corpus . approach consider speaker define different level similar context . use twitter conversation corpus contain speaker conversation test evaluation model . experiment model outperform exist evaluation metric term high correlation human annotation score . model train twitter apply movie dialogue additional training . provide code learn parameter automatic evaluation dialogue response generation model . context : want tonight ? b : movie ? ground truth response : yeah let theater utterance bleu rouge emb ruber ssrem human a1 sound good ! see thor ? 0.00 ( 3 ) 0.00 ( 3 ) 0.95 ( 2 ) 0.59 ( 2 ) 0.64 ( 1 ) 5.00 ( 1 ) a2 good , movie ? 0.00 ( 3 ) 0.00 ( 3 ) 0.92 ( 4 ) 0.55 ( 4 ) 0.62 ( 2 ) 5.00 ( 1 ) a3 hang city 0.00 ( 3 ) 0.00 ( 3 ) 0.89 ( 6 ) 0.48 ( 5 ) 0.49 ( 3 ) 3.80 ( 3 ) n1 weather good walking 0.32 ( 1 ) 0.15 ( 2 ) 0.94 ( 3 ) 0.47 ( 6 ) 0.44 ( 4 ) 2.60 ( 4 ) n2 sight extra beautiful 0.32 ( 1 ) 0.17 ( 1 ) 0.97 ( 1 ) 0.64 ( 1 ) 0.38 ( 5 ) 1.00 ( 5 ) n3 enjoy concert 0.00 ( 3 ) 0.00 ( 3 ) 0.91 ( 5 ) 0.57 ( 3 ) 0.33 ( 6 ) 1.00 ( 5 )","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 19, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network,"In this paper, we explore the slot tagging with only a few labeled support sentences (a.k.a. few-shot). Few-shot slot tagging faces a unique challenge compared to the other fewshot classification problems as it calls for modeling the dependencies between labels. But it is hard to apply previously learned label dependencies to an unseen domain, due to the discrepancy of label sets. To tackle this, we introduce a collapsed dependency transfer mechanism into the conditional random field (CRF) to transfer abstract label dependency patterns as transition scores. In the few-shot setting, the emission score of CRF can be calculated as a word's similarity to the representation of each label. To calculate such similarity, we propose a Label-enhanced Task-Adaptive Projection Network (L-TapNet) based on the stateof-the-art few-shot classification model -Tap-Net, by leveraging label name semantics in representing labels. Experimental results show that our model significantly outperforms the strongest few-shot learning baseline by 14.64","Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network In this paper, we explore the slot tagging with only a few labeled support sentences (a.k.a. few-shot). Few-shot slot tagging faces a unique challenge compared to the other fewshot classification problems as it calls for modeling the dependencies between labels. But it is hard to apply previously learned label dependencies to an unseen domain, due to the discrepancy of label sets. To tackle this, we introduce a collapsed dependency transfer mechanism into the conditional random field (CRF) to transfer abstract label dependency patterns as transition scores. In the few-shot setting, the emission score of CRF can be calculated as a word's similarity to the representation of each label. To calculate such similarity, we propose a Label-enhanced Task-Adaptive Projection Network (L-TapNet) based on the stateof-the-art few-shot classification model -Tap-Net, by leveraging label name semantics in representing labels. Experimental results show that our model significantly outperforms the strongest few-shot learning baseline by 14.64","- shot slot tagging collapse dependency transfer label - enhance task - adaptive projection network paper , explore slot tagging label support sentence ( a.k.a . - shot ) . - shot slot tagging face unique challenge compare fewshot classification problem call model dependency label . hard apply previously learn label dependency unseen domain , discrepancy label set . tackle , introduce collapse dependency transfer mechanism conditional random field ( crf ) transfer abstract label dependency pattern transition score . - shot setting , emission score crf calculate word similarity representation label . calculate similarity , propose label - enhance task - adaptive projection network ( l - tapnet ) base stateof - - art - shot classification model -tap - net , leverage label semantic represent label . experimental result model significantly outperform strong - shot learning baseline 14.64","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Dialogue and Interactive Systems,Multi-Domain Dialogue Acts and Response Co-Generation,"Generating fluent and informative responses is of critical importance for task-oriented dialogue systems. Existing pipeline approaches generally predict multiple dialogue acts first and use them to assist response generation. There are at least two shortcomings with such approaches. First, the inherent structures of multi-domain dialogue acts are neglected. Second, the semantic associations between acts and responses are not taken into account for response generation. To address these issues, we propose a neural co-generation model that generates dialogue acts and responses concurrently. Unlike those pipeline approaches, our act generation module preserves the semantic structures of multi-domain dialogue acts and our response generation module dynamically attends to different acts as needed. We train the two modules jointly using an uncertainty loss to adjust their task weights adaptively. Extensive experiments are conducted on the largescale MultiWOZ dataset and the results show that our model achieves very favorable improvement over several state-of-the-art models in both automatic and human evaluations.","Multi-Domain Dialogue Acts and Response Co-Generation Generating fluent and informative responses is of critical importance for task-oriented dialogue systems. Existing pipeline approaches generally predict multiple dialogue acts first and use them to assist response generation. There are at least two shortcomings with such approaches. First, the inherent structures of multi-domain dialogue acts are neglected. Second, the semantic associations between acts and responses are not taken into account for response generation. To address these issues, we propose a neural co-generation model that generates dialogue acts and responses concurrently. Unlike those pipeline approaches, our act generation module preserves the semantic structures of multi-domain dialogue acts and our response generation module dynamically attends to different acts as needed. We train the two modules jointly using an uncertainty loss to adjust their task weights adaptively. Extensive experiments are conducted on the largescale MultiWOZ dataset and the results show that our model achieves very favorable improvement over several state-of-the-art models in both automatic and human evaluations.","multi - domain dialogue acts response co - generation generate fluent informative response critical importance task - orient dialogue system . exist pipeline approach generally predict multiple dialogue act use assist response generation . shortcoming approach . , inherent structure multi - domain dialogue act neglect . second , semantic association act response take account response generation . address issue , propose neural co - generation model generate dialogue act response concurrently . unlike pipeline approach , act generation module preserve semantic structure multi - domain dialogue act response generation module dynamically attend different act need . train module jointly uncertainty loss adjust task weight adaptively . extensive experiment conduct largescale multiwoz dataset result model achieve favorable improvement state - - - art model automatic human evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 21, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking,Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of data acquisition. This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. We show that data augmentation through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the accuracy obtained with the full training dataset. We improve the zero-shot learning state of the art on average across domains by 21%.,Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of data acquisition. This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. We show that data augmentation through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the accuracy obtained with the full training dataset. We improve the zero-shot learning state of the art on average across domains by 21%.,zero - shot transfer learning synthesize datum multi - domain dialogue state tracking zero - shot transfer learning multi - domain dialogue state tracking allow handle new domain incur high cost datum acquisition . paper propose new zero - short transfer learning technique dialogue state tracking - domain training datum synthesize abstract dialogue model ontology domain . datum augmentation synthesize datum improve accuracy zero - shot learning trade model bert - base sumbt model multiwoz 2.1 dataset . training synthesize - domain datum sumbt model reach 2/3 accuracy obtain training dataset . improve zero - shot learning state art average domain 21 % .,"{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Can You Put it All Together: Evaluating Conversational Agents' Ability to Blend Skills,"Being engaging, knowledgeable, and empathetic are all desirable general qualities in a conversational agent. Previous work has introduced tasks and datasets that aim to help agents to learn those qualities in isolation and gauge how well they can express them. But rather than being specialized in one single quality, a good open-domain conversational agent should be able to seamlessly blend them all into one cohesive conversational flow. In this work, we investigate several ways to combine models trained towards isolated capabilities, ranging from simple model aggregation schemes that require minimal additional training, to various forms of multi-task training that encompass several skills at all training stages. We further propose a new dataset, Blended-SkillTalk, to analyze how these capabilities would mesh together in a natural conversation, and compare the performance of different architectures and training schemes. Our experiments show that multi-tasking over several tasks that focus on particular capabilities results in better blended conversation performance compared to models trained on a single skill, and that both unified or two-stage approaches perform well if they are constructed to avoid unwanted bias in skill selection or are fine-tuned on our new task.","Can You Put it All Together: Evaluating Conversational Agents' Ability to Blend Skills Being engaging, knowledgeable, and empathetic are all desirable general qualities in a conversational agent. Previous work has introduced tasks and datasets that aim to help agents to learn those qualities in isolation and gauge how well they can express them. But rather than being specialized in one single quality, a good open-domain conversational agent should be able to seamlessly blend them all into one cohesive conversational flow. In this work, we investigate several ways to combine models trained towards isolated capabilities, ranging from simple model aggregation schemes that require minimal additional training, to various forms of multi-task training that encompass several skills at all training stages. We further propose a new dataset, Blended-SkillTalk, to analyze how these capabilities would mesh together in a natural conversation, and compare the performance of different architectures and training schemes. Our experiments show that multi-tasking over several tasks that focus on particular capabilities results in better blended conversation performance compared to models trained on a single skill, and that both unified or two-stage approaches perform well if they are constructed to avoid unwanted bias in skill selection or are fine-tuned on our new task.",": evaluate conversational agent ' ability blend skill engage , knowledgeable , empathetic desirable general quality conversational agent . previous work introduce task dataset aim help agent learn quality isolation gauge express . specialize single quality , good open - domain conversational agent able seamlessly blend cohesive conversational flow . work , investigate way combine model train isolate capability , range simple model aggregation scheme require minimal additional training , form multi - task training encompass skill training stage . propose new dataset , blended - skilltalk , analyze capability mesh natural conversation , compare performance different architecture training scheme . experiment multi - task task focus particular capability result well blend conversation performance compare model train single skill , unified - stage approach perform construct avoid unwanted bias skill selection fine - tune new task .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Dialogue and Interactive Systems,Evaluating Dialogue Generation Systems via Response Selection,"Existing automatic evaluation metrics for open-domain dialogue response generation systems correlate poorly with human evaluation. We focus on evaluating response generation systems via response selection. To evaluate systems properly via response selection, we propose a method to construct response selection test sets with well-chosen false candidates. Specifically, we propose to construct test sets filtering out some types of false candidates: (i) those unrelated to the ground-truth response and (ii) those acceptable as appropriate responses. Through experiments, we demonstrate that evaluating systems via response selection with the test set developed by our method correlates more strongly with human evaluation, compared with widely used automatic evaluation metrics such as BLEU.","Evaluating Dialogue Generation Systems via Response Selection Existing automatic evaluation metrics for open-domain dialogue response generation systems correlate poorly with human evaluation. We focus on evaluating response generation systems via response selection. To evaluate systems properly via response selection, we propose a method to construct response selection test sets with well-chosen false candidates. Specifically, we propose to construct test sets filtering out some types of false candidates: (i) those unrelated to the ground-truth response and (ii) those acceptable as appropriate responses. Through experiments, we demonstrate that evaluating systems via response selection with the test set developed by our method correlates more strongly with human evaluation, compared with widely used automatic evaluation metrics such as BLEU.","evaluate dialogue generation system response selection exist automatic evaluation metric open - domain dialogue response generation system correlate poorly human evaluation . focus evaluate response generation system response selection . evaluate system properly response selection , propose method construct response selection test set - choose false candidate . specifically , propose construct test set filter type false candidate : ( ) unrelated ground - truth response ( ii ) acceptable appropriate response . experiment , demonstrate evaluate system response selection test set develop method correlate strongly human evaluation , compare widely automatic evaluation metric bleu .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Learning an Unreferenced Metric for Online Dialogue Evaluation,"Evaluating the quality of a dialogue interaction between two agents is a difficult task, especially in open-domain chit-chat style dialogue. There have been recent efforts to develop automatic dialogue evaluation metrics, but most of them do not generalize to unseen datasets and/or need a human-generated reference response during inference, making it infeasible for online evaluation. Here, we propose an unreferenced automated evaluation metric that uses large pre-trained language models to extract latent representations of utterances, and leverages the temporal transitions that exist between them. We show that our model achieves higher correlation with human annotations in an online setting, while not requiring true responses for comparison during inference.","Learning an Unreferenced Metric for Online Dialogue Evaluation Evaluating the quality of a dialogue interaction between two agents is a difficult task, especially in open-domain chit-chat style dialogue. There have been recent efforts to develop automatic dialogue evaluation metrics, but most of them do not generalize to unseen datasets and/or need a human-generated reference response during inference, making it infeasible for online evaluation. Here, we propose an unreferenced automated evaluation metric that uses large pre-trained language models to extract latent representations of utterances, and leverages the temporal transitions that exist between them. We show that our model achieves higher correlation with human annotations in an online setting, while not requiring true responses for comparison during inference.","learn unreferenced metric online dialogue evaluation evaluate quality dialogue interaction agent difficult task , especially open - domain chit - chat style dialogue . recent effort develop automatic dialogue evaluation metric , generalize unseen dataset and/or need human - generate reference response inference , make infeasible online evaluation . , propose unreferenced automate evaluation metric use large pre - trained language model extract latent representation utterance , leverage temporal transition exist . model achieve high correlation human annotation online setting , require true response comparison inference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 10, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Grounding Conversations with Improvised Dialogues,"Effective dialogue involves grounding, the process of establishing mutual knowledge that is essential for communication between people. Modern dialogue systems are not explicitly trained to build common ground, and therefore overlook this important aspect of communication. Improvisational theater (improv) intrinsically contains a high proportion of dialogue focused on building common ground, and makes use of the yes-and principle, a strong grounding speech act, to establish coherence and an actionable objective reality. We collect a corpus of more than 26,000 yes-and turns, transcribing them from improv dialogues and extracting them from larger, but more sparsely populated movie script dialogue corpora, via a bootstrapped classifier. We fine-tune chit-chat dialogue systems with our corpus to encourage more grounded, relevant conversation and confirm these findings with human evaluations.","Grounding Conversations with Improvised Dialogues Effective dialogue involves grounding, the process of establishing mutual knowledge that is essential for communication between people. Modern dialogue systems are not explicitly trained to build common ground, and therefore overlook this important aspect of communication. Improvisational theater (improv) intrinsically contains a high proportion of dialogue focused on building common ground, and makes use of the yes-and principle, a strong grounding speech act, to establish coherence and an actionable objective reality. We collect a corpus of more than 26,000 yes-and turns, transcribing them from improv dialogues and extracting them from larger, but more sparsely populated movie script dialogue corpora, via a bootstrapped classifier. We fine-tune chit-chat dialogue systems with our corpus to encourage more grounded, relevant conversation and confirm these findings with human evaluations.","grounding conversations improvised dialogue effective dialogue involve grounding , process establish mutual knowledge essential communication people . modern dialogue system explicitly train build common ground , overlook important aspect communication . improvisational theater ( improv ) intrinsically contain high proportion dialogue focus build common ground , make use yes - principle , strong ground speech act , establish coherence actionable objective reality . collect corpus 26,000 yes - turn , transcribe improv dialogue extract large , sparsely populated movie script dialogue corpora , bootstrappe classifier . fine - tune chit - chat dialogue system corpus encourage grounded , relevant conversation confirm finding human evaluation .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 19, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Dialogue and Interactive Systems,Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks,"Training the generative models with minimal corpus is one of the critical challenges for building open-domain dialogue systems. Existing methods tend to use the meta-learning framework which pre-trains the parameters on all non-target tasks then fine-tunes on the target task. However, fine-tuning distinguishes tasks from the parameter perspective but ignores the model-structure perspective, resulting in similar dialogue models for different tasks. In this paper, we propose an algorithm that can customize a unique dialogue model for each task in the few-shot setting. In our approach, each dialogue model consists of a shared module, a gating module, and a private module. The first two modules are shared among all the tasks, while the third one will differentiate into different network structures to better capture the characteristics of the corresponding task. The extensive experiments on two datasets show that our method outperforms all the baselines in terms of task consistency, response quality, and diversity.","Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks Training the generative models with minimal corpus is one of the critical challenges for building open-domain dialogue systems. Existing methods tend to use the meta-learning framework which pre-trains the parameters on all non-target tasks then fine-tunes on the target task. However, fine-tuning distinguishes tasks from the parameter perspective but ignores the model-structure perspective, resulting in similar dialogue models for different tasks. In this paper, we propose an algorithm that can customize a unique dialogue model for each task in the few-shot setting. In our approach, each dialogue model consists of a shared module, a gating module, and a private module. The first two modules are shared among all the tasks, while the third one will differentiate into different network structures to better capture the characteristics of the corresponding task. The extensive experiments on two datasets show that our method outperforms all the baselines in terms of task consistency, response quality, and diversity.","learn customize model structure - shot dialogue generation task train generative model minimal corpus critical challenge build open - domain dialogue system . exist method tend use meta - learning framework pre - train parameter non - target task fine - tune target task . , fine - tuning distinguish task parameter perspective ignore model - structure perspective , result similar dialogue model different task . paper , propose algorithm customize unique dialogue model task - shot setting . approach , dialogue model consist share module , gating module , private module . module share task , differentiate different network structure well capture characteristic correspond task . extensive experiment dataset method outperform baseline term task consistency , response quality , diversity .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 12, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,True
Discourse and Pragmatics,Implicit Discourse Relation Classification: We Need to Talk about Evaluation,"Implicit relation classification on Penn Discourse TreeBank (PDTB) 2.0 is a common benchmark task for evaluating the understanding of discourse relations. However, the lack of consistency in preprocessing and evaluation poses challenges to fair comparison of results in the literature. In this work, we highlight these inconsistencies and propose an improved evaluation protocol. Paired with this protocol, we report strong baseline results from pretrained sentence encoders, which set the new state-of-the-art for PDTB 2.0. Furthermore, this work is the first to explore fine-grained relation classification on PDTB 3.0. We expect our work to serve as a point of comparison for future work, and also as an initiative to discuss models of larger context and possible data augmentations for downstream transferability.","Implicit Discourse Relation Classification: We Need to Talk about Evaluation Implicit relation classification on Penn Discourse TreeBank (PDTB) 2.0 is a common benchmark task for evaluating the understanding of discourse relations. However, the lack of consistency in preprocessing and evaluation poses challenges to fair comparison of results in the literature. In this work, we highlight these inconsistencies and propose an improved evaluation protocol. Paired with this protocol, we report strong baseline results from pretrained sentence encoders, which set the new state-of-the-art for PDTB 2.0. Furthermore, this work is the first to explore fine-grained relation classification on PDTB 3.0. We expect our work to serve as a point of comparison for future work, and also as an initiative to discuss models of larger context and possible data augmentations for downstream transferability.","implicit discourse relation classification : need talk evaluation implicit relation classification penn discourse treebank ( pdtb ) 2.0 common benchmark task evaluate understanding discourse relation . , lack consistency preprocessing evaluation pose challenge fair comparison result literature . work , highlight inconsistency propose improve evaluation protocol . pair protocol , report strong baseline result pretrained sentence encoder , set new state - - - art pdtb 2.0 . furthermore , work explore fine - grained relation classification pdtb 3.0 . expect work serve point comparison future work , initiative discuss model large context possible data augmentation downstream transferability .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,Dialogue Coherence Assessment Without Explicit Dialogue Act Labels,"Recent dialogue coherence models use the coherence features designed for monologue texts, e.g. nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels. It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels. We address these issues by introducing a novel approach to dialogue coherence assessment. We use dialogue act prediction as an auxiliary task in a multi-task learning scenario to obtain informative utterance representations for coherence assessment. Our approach alleviates the need for explicit dialogue act labels during evaluation. The results of our experiments show that our model substantially (more than 20 accuracy points) outperforms its strong competitors on the Dai-lyDialogue corpus, and performs on par with them on the SwitchBoard corpus for ranking dialogues concerning their coherence. We release our source code 1 .","Dialogue Coherence Assessment Without Explicit Dialogue Act Labels Recent dialogue coherence models use the coherence features designed for monologue texts, e.g. nominal entities, to represent utterances and then explicitly augment them with dialogue-relevant features, e.g., dialogue act labels. It indicates two drawbacks, (a) semantics of utterances is limited to entity mentions, and (b) the performance of coherence models strongly relies on the quality of the input dialogue act labels. We address these issues by introducing a novel approach to dialogue coherence assessment. We use dialogue act prediction as an auxiliary task in a multi-task learning scenario to obtain informative utterance representations for coherence assessment. Our approach alleviates the need for explicit dialogue act labels during evaluation. The results of our experiments show that our model substantially (more than 20 accuracy points) outperforms its strong competitors on the Dai-lyDialogue corpus, and performs on par with them on the SwitchBoard corpus for ranking dialogues concerning their coherence. We release our source code 1 .","dialogue coherence assessment explicit dialogue act label recent dialogue coherence model use coherence feature design monologue text , e.g. nominal entity , represent utterance explicitly augment dialogue - relevant feature , e.g. , dialogue act label . indicate drawback , ( ) semantic utterance limit entity mention , ( b ) performance coherence model strongly rely quality input dialogue act label . address issue introduce novel approach dialogue coherence assessment . use dialogue act prediction auxiliary task multi - task learning scenario obtain informative utterance representation coherence assessment . approach alleviate need explicit dialogue act label evaluation . result experiment model substantially ( 20 accuracy point ) outperform strong competitor dai - lydialogue corpus , perform par switchboard corpus rank dialogue concern coherence . release source code 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 22, 'Discourse and Pragmatics': 7, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Discourse and Pragmatics,A Complete Shift-Reduce Chinese Discourse Parser with Robust Dynamic Oracle,"This work proposes a standalone, complete Chinese discourse parser for practical applications. We approach Chinese discourse parsing from a variety of aspects and improve the shift-reduce parser not only by integrating the pre-trained text encoder, but also by employing novel training strategies. We revise the dynamic-oracle procedure for training the shift-reduce parser, and apply unsupervised data augmentation to enhance rhetorical relation recognition. Experimental results show that our Chinese discourse parser achieves the state-of-the-art performance.","A Complete Shift-Reduce Chinese Discourse Parser with Robust Dynamic Oracle This work proposes a standalone, complete Chinese discourse parser for practical applications. We approach Chinese discourse parsing from a variety of aspects and improve the shift-reduce parser not only by integrating the pre-trained text encoder, but also by employing novel training strategies. We revise the dynamic-oracle procedure for training the shift-reduce parser, and apply unsupervised data augmentation to enhance rhetorical relation recognition. Experimental results show that our Chinese discourse parser achieves the state-of-the-art performance.","complete shift - reduce chinese discourse parser robust dynamic oracle work propose standalone , complete chinese discourse parser practical application . approach chinese discourse parsing variety aspect improve shift - reduce parser integrate pre - train text encoder , employ novel training strategy . revise dynamic - oracle procedure train shift - reduce parser , apply unsupervised datum augmentation enhance rhetorical relation recognition . experimental result chinese discourse parser achieve state - - - art performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 8, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,TransS-Driven Joint Learning Architecture for Implicit Discourse Relation Recognition,"Implicit discourse relation recognition is a challenging task due to the lack of connectives as strong linguistic clues. Previous methods primarily encode two arguments separately or extract the specific interaction patterns for the task, which have not fully exploited the annotated relation signal. Therefore, we propose a novel TransS-driven joint learning architecture to address the issues. Specifically, based on the multi-level encoder, we 1) translate discourse relations in low-dimensional embedding space (called TransS), which could mine the latent geometric structure information of argumentrelation instances; 2) further exploit the semantic features of arguments to assist discourse understanding; 3) jointly learn 1) and 2) to mutually reinforce each other to obtain the better argument representations, so as to improve the performance of the task. Extensive experimental results on the Penn Discourse TreeBank (PDTB) show that our model achieves competitive results against several state-of-the-art systems.","TransS-Driven Joint Learning Architecture for Implicit Discourse Relation Recognition Implicit discourse relation recognition is a challenging task due to the lack of connectives as strong linguistic clues. Previous methods primarily encode two arguments separately or extract the specific interaction patterns for the task, which have not fully exploited the annotated relation signal. Therefore, we propose a novel TransS-driven joint learning architecture to address the issues. Specifically, based on the multi-level encoder, we 1) translate discourse relations in low-dimensional embedding space (called TransS), which could mine the latent geometric structure information of argumentrelation instances; 2) further exploit the semantic features of arguments to assist discourse understanding; 3) jointly learn 1) and 2) to mutually reinforce each other to obtain the better argument representations, so as to improve the performance of the task. Extensive experimental results on the Penn Discourse TreeBank (PDTB) show that our model achieves competitive results against several state-of-the-art systems.","transs - drive joint learning architecture implicit discourse relation recognition implicit discourse relation recognition challenging task lack connective strong linguistic clue . previous method primarily encode argument separately extract specific interaction pattern task , fully exploit annotate relation signal . , propose novel transs - drive joint learning architecture address issue . specifically , base multi - level encoder , 1 ) translate discourse relation low - dimensional embedding space ( call transs ) , latent geometric structure information argumentrelation instance ; 2 ) exploit semantic feature argument assist discourse understanding ; 3 ) jointly learn 1 ) 2 ) mutually reinforce obtain well argument representation , improve performance task . extensive experimental result penn discourse treebank ( pdtb ) model achieve competitive result state - - - art system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 8, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,ZPR2: Joint Zero Pronoun Recovery and Resolution using Multi-Task Learning and BERT,"Zero pronoun recovery and resolution aim at recovering the dropped pronoun and pointing out its anaphoric mentions, respectively. We propose to better explore their interaction by solving both tasks together, while the previous work treats them separately. For zero pronoun resolution, we study this task in a more realistic setting, where no parsing trees or only automatic trees are available, while most previous work assumes gold trees. Experiments on two benchmarks show that joint modeling significantly outperforms our baseline that already beats the previous state of the arts. Our code is available at https://github.com/ freesunshine0316/lab-zp-joint.","ZPR2: Joint Zero Pronoun Recovery and Resolution using Multi-Task Learning and BERT Zero pronoun recovery and resolution aim at recovering the dropped pronoun and pointing out its anaphoric mentions, respectively. We propose to better explore their interaction by solving both tasks together, while the previous work treats them separately. For zero pronoun resolution, we study this task in a more realistic setting, where no parsing trees or only automatic trees are available, while most previous work assumes gold trees. Experiments on two benchmarks show that joint modeling significantly outperforms our baseline that already beats the previous state of the arts. Our code is available at https://github.com/ freesunshine0316/lab-zp-joint.","zpr2 : joint zero pronoun recovery resolution multi - task learning bert zero pronoun recovery resolution aim recover drop pronoun point anaphoric mention , respectively . propose well explore interaction solve task , previous work treat separately . zero pronoun resolution , study task realistic setting , parsing tree automatic tree available , previous work assume gold tree . experiment benchmark joint modeling significantly outperform baseline beat previous state art . code available https://github.com/ freesunshine0316 / lab - zp - joint .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,Bridging Anaphora Resolution as Question Answering,"Most previous studies on bridging anaphora resolution (Poesio et al., 2004; Hou et al., 2013b; Hou, 2018a) use the pairwise model to tackle the problem and assume that the gold mention information is given. In this paper, we cast bridging anaphora resolution as question answering based on context. This allows us to find the antecedent for a given anaphor without knowing any gold mention information (except the anaphor itself). We present a question answering framework (BARQA) for this task, which leverages the power of transfer learning. Furthermore, we propose a novel method to generate a large amount of ""quasi-bridging"" training data. We show that our model pre-trained on this dataset and fine-tuned on a small amount of in-domain dataset achieves new state-of-the-art results for bridging anaphora resolution on two bridging corpora (ISNotes (Markert et al., 2012)  and BASHI (RÃ¶siger, 2018) ).","Bridging Anaphora Resolution as Question Answering Most previous studies on bridging anaphora resolution (Poesio et al., 2004; Hou et al., 2013b; Hou, 2018a) use the pairwise model to tackle the problem and assume that the gold mention information is given. In this paper, we cast bridging anaphora resolution as question answering based on context. This allows us to find the antecedent for a given anaphor without knowing any gold mention information (except the anaphor itself). We present a question answering framework (BARQA) for this task, which leverages the power of transfer learning. Furthermore, we propose a novel method to generate a large amount of ""quasi-bridging"" training data. We show that our model pre-trained on this dataset and fine-tuned on a small amount of in-domain dataset achieves new state-of-the-art results for bridging anaphora resolution on two bridging corpora (ISNotes (Markert et al., 2012)  and BASHI (RÃ¶siger, 2018) ).","bridge anaphora resolution question answering previous study bridge anaphora resolution ( poesio et al . , 2004 ; hou et al . , 2013b ; hou , 2018a ) use pairwise model tackle problem assume gold mention information give . paper , cast bridge anaphora resolution question answering base context . allow find antecedent give anaphor know gold mention information ( anaphor ) . present question answering framework ( barqa ) task , leverage power transfer learning . furthermore , propose novel method generate large "" quasi - bridge "" training datum . model pre - train dataset fine - tune small - domain dataset achieve new state - - - art result bridge anaphora resolution bridge corpus ( isnotes ( markert et al . , 2012 )   bashi ( rÃ¶siger , 2018 ) ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 14, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 16, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Discourse and Pragmatics,Discourse as a Function of Event: Profiling Discourse Structure in News Articles around the Main Event,"Understanding discourse structures of news articles is vital to effectively contextualize the occurrence of a news event. To enable computational modeling of news structures, we apply an existing theory of functional discourse structure for news articles that revolves around the main event and create a human-annotated corpus of 802 documents spanning over four domains and three media sources. Next, we propose several documentlevel neural-network models to automatically construct news content structures. Finally, we demonstrate that incorporating system predicted news structures yields new state-of-theart performance for event coreference resolution. The news documents we annotated are openly available and the annotations are publicly released for future research 1 .","Discourse as a Function of Event: Profiling Discourse Structure in News Articles around the Main Event Understanding discourse structures of news articles is vital to effectively contextualize the occurrence of a news event. To enable computational modeling of news structures, we apply an existing theory of functional discourse structure for news articles that revolves around the main event and create a human-annotated corpus of 802 documents spanning over four domains and three media sources. Next, we propose several documentlevel neural-network models to automatically construct news content structures. Finally, we demonstrate that incorporating system predicted news structures yields new state-of-theart performance for event coreference resolution. The news documents we annotated are openly available and the annotations are publicly released for future research 1 .","discourse function event : profile discourse structure news article main event understand discourse structure news article vital effectively contextualize occurrence news event . enable computational modeling news structure , apply exist theory functional discourse structure news article revolve main event create human - annotate corpus 802 document span domain medium source . , propose documentlevel neural - network model automatically construct news content structure . finally , demonstrate incorporate system predict news structure yield new state - - theart performance event coreference resolution . news document annotate openly available annotation publicly release future research 1 .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 8, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Discourse and Pragmatics,Harnessing the linguistic signal to predict scalar inferences,"Pragmatic inferences often subtly depend on the presence or absence of linguistic features. For example, the presence of a partitive construction (of the) increases the strength of a so-called scalar inference: listeners perceive the inference that Chris did not eat all of the cookies to be stronger after hearing ""Chris ate some of the cookies"" than after hearing the same utterance without a partitive, ""Chris ate some cookies"". In this work, we explore to what extent neural network sentence encoders can learn to predict the strength of scalar inferences. We first show that an LSTM-based sentence encoder trained on an English dataset of human inference strength ratings is able to predict ratings with high accuracy (r = 0.78). We then probe the model's behavior using manually constructed minimal sentence pairs and corpus data. We find that the model inferred previously established associations between linguistic features and inference strength, suggesting that the model learns to use linguistic features to predict pragmatic inferences.","Harnessing the linguistic signal to predict scalar inferences Pragmatic inferences often subtly depend on the presence or absence of linguistic features. For example, the presence of a partitive construction (of the) increases the strength of a so-called scalar inference: listeners perceive the inference that Chris did not eat all of the cookies to be stronger after hearing ""Chris ate some of the cookies"" than after hearing the same utterance without a partitive, ""Chris ate some cookies"". In this work, we explore to what extent neural network sentence encoders can learn to predict the strength of scalar inferences. We first show that an LSTM-based sentence encoder trained on an English dataset of human inference strength ratings is able to predict ratings with high accuracy (r = 0.78). We then probe the model's behavior using manually constructed minimal sentence pairs and corpus data. We find that the model inferred previously established associations between linguistic features and inference strength, suggesting that the model learns to use linguistic features to predict pragmatic inferences.","harness linguistic signal predict scalar inference pragmatic inference subtly depend presence absence linguistic feature . example , presence partitive construction ( ) increase strength - call scalar inference : listener perceive inference chris eat cookie strong hear "" chris eat cookie "" hear utterance partitive , "" chris eat cookie "" . work , explore extent neural network sentence encoder learn predict strength scalar inference . lstm - base sentence encoder train english dataset human inference strength rating able predict rating high accuracy ( r = 0.78 ) . probe model behavior manually construct minimal sentence pair corpus datum . find model infer previously establish association linguistic feature inference strength , suggest model learn use linguistic feature predict pragmatic inference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Discourse and Pragmatics,A Top-down Neural Architecture towards Text-level Parsing of Discourse Rhetorical Structure,"Due to its great importance in deep natural language understanding and various down-stream applications, text-level parsing of discourse rhetorical structure (DRS) has been drawing more and more attention in recent years. However, all the previous studies on text-level discourse parsing adopt bottom-up approaches, which much limit the DRS determination on local information and fail to well benefit from global information of the overall discourse. In this paper, we justify from both computational and perceptive points-of-view that the top-down architecture is more suitable for textlevel DRS parsing. On the basis, we propose a top-down neural architecture toward text-level DRS parsing. In particular, we cast discourse parsing as a recursive split point ranking task, where a split point is classified to different levels according to its rank and the elementary discourse units (EDUs) associated with it are arranged accordingly. In this way, we can determine the complete DRS as a hierarchical tree structure via an encoder-decoder with an internal stack. Experimentation on both the English RST-DT corpus and the Chinese CDTB corpus shows the great effectiveness of our proposed top-down approach towards textlevel DRS parsing.","A Top-down Neural Architecture towards Text-level Parsing of Discourse Rhetorical Structure Due to its great importance in deep natural language understanding and various down-stream applications, text-level parsing of discourse rhetorical structure (DRS) has been drawing more and more attention in recent years. However, all the previous studies on text-level discourse parsing adopt bottom-up approaches, which much limit the DRS determination on local information and fail to well benefit from global information of the overall discourse. In this paper, we justify from both computational and perceptive points-of-view that the top-down architecture is more suitable for textlevel DRS parsing. On the basis, we propose a top-down neural architecture toward text-level DRS parsing. In particular, we cast discourse parsing as a recursive split point ranking task, where a split point is classified to different levels according to its rank and the elementary discourse units (EDUs) associated with it are arranged accordingly. In this way, we can determine the complete DRS as a hierarchical tree structure via an encoder-decoder with an internal stack. Experimentation on both the English RST-DT corpus and the Chinese CDTB corpus shows the great effectiveness of our proposed top-down approach towards textlevel DRS parsing.","- neural architecture text - level parsing discourse rhetorical structure great importance deep natural language understanding - stream application , text - level parsing discourse rhetorical structure ( drs ) draw attention recent year . , previous study text - level discourse parsing adopt - approach , limit drs determination local information fail benefit global information overall discourse . paper , justify computational perceptive point - - view - architecture suitable textlevel drs parsing . basis , propose - neural architecture text - level drs parsing . particular , cast discourse parsing recursive split point ranking task , split point classify different level accord rank elementary discourse unit ( edu ) associate arrange accordingly . way , determine complete drs hierarchical tree structure encoder - decoder internal stack . experimentation english rst - dt corpus chinese cdtb corpus show great effectiveness propose - approach textlevel drs parsing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 19, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 8, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,DRTS Parsing with Structure-Aware Encoding and Decoding,"Discourse representation tree structure (DRTS) parsing is a novel semantic parsing task which has been concerned most recently. State-of-the-art performance can be achieved by a neural sequence-to-sequence model, treating the tree construction as an incremental sequence generation problem. Structural information such as input syntax and the intermediate skeleton of the partial output has been ignored in the model, which could be potentially useful for the DRTS parsing. In this work, we propose a structural-aware model at both the encoder and decoder phase to integrate the structural information, where graph attention network (GAT) is exploited for effectively modeling. Experimental results on a benchmark dataset show that our proposed model is effective and can obtain the best performance in the literature.","DRTS Parsing with Structure-Aware Encoding and Decoding Discourse representation tree structure (DRTS) parsing is a novel semantic parsing task which has been concerned most recently. State-of-the-art performance can be achieved by a neural sequence-to-sequence model, treating the tree construction as an incremental sequence generation problem. Structural information such as input syntax and the intermediate skeleton of the partial output has been ignored in the model, which could be potentially useful for the DRTS parsing. In this work, we propose a structural-aware model at both the encoder and decoder phase to integrate the structural information, where graph attention network (GAT) is exploited for effectively modeling. Experimental results on a benchmark dataset show that our proposed model is effective and can obtain the best performance in the literature.","drts parsing structure - aware encoding decoding discourse representation tree structure ( drts ) parsing novel semantic parsing task concern recently . state - - - art performance achieve neural sequence - - sequence model , treat tree construction incremental sequence generation problem . structural information input syntax intermediate skeleton partial output ignore model , potentially useful drts parsing . work , propose structural - aware model encoder decoder phase integrate structural information , graph attention network ( gat ) exploit effectively model . experimental result benchmark dataset propose model effective obtain good performance literature .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Discourse and Pragmatics,PeTra: A Sparsely Supervised Memory Model for People Tracking,"We propose PeTra, a memory-augmented neural network designed to track entities in its memory slots. PeTra is trained using sparse annotation from the GAP pronoun resolution dataset and outperforms a prior memory model on the task while using a simpler architecture. We empirically compare key modeling choices, finding that we can simplify several aspects of the design of the memory module while retaining strong performance. To measure the people tracking capability of memory models, we (a) propose a new diagnostic evaluation based on counting the number of unique entities in text, and (b) conduct a small scale human evaluation to compare evidence of people tracking in the memory logs of PeTra relative to a previous approach. PeTra is highly effective in both evaluations, demonstrating its ability to track people in its memory despite being trained with limited annotation.","PeTra: A Sparsely Supervised Memory Model for People Tracking We propose PeTra, a memory-augmented neural network designed to track entities in its memory slots. PeTra is trained using sparse annotation from the GAP pronoun resolution dataset and outperforms a prior memory model on the task while using a simpler architecture. We empirically compare key modeling choices, finding that we can simplify several aspects of the design of the memory module while retaining strong performance. To measure the people tracking capability of memory models, we (a) propose a new diagnostic evaluation based on counting the number of unique entities in text, and (b) conduct a small scale human evaluation to compare evidence of people tracking in the memory logs of PeTra relative to a previous approach. PeTra is highly effective in both evaluations, demonstrating its ability to track people in its memory despite being trained with limited annotation.","petra : sparsely supervise memory model people tracking propose petra , memory - augment neural network design track entity memory slot . petra train sparse annotation gap pronoun resolution dataset outperform prior memory model task simple architecture . empirically compare key modeling choice , find simplify aspect design memory module retain strong performance . measure people track capability memory model , ( ) propose new diagnostic evaluation base count number unique entity text , ( b ) conduct small scale human evaluation compare evidence people track memory log petra relative previous approach . petra highly effective evaluation , demonstrate ability track people memory despite train limited annotation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 6, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,True
Discourse and Pragmatics,Unsupervised Discourse Constituency Parsing Using Viterbi EM,"In this paper, we introduce an unsupervised discourse constituency parsing algorithm. We use Viterbi EM with a margin-based criterion to train a span-based discourse parser in an unsupervised manner. We also propose initialization methods for Viterbi training of discourse constituents based on our prior knowledge of text structures. Experimental results demonstrate that our unsupervised parser achieves comparable or even superior performance to fully supervised parsers. We also investigate discourse constituents that are learned by our method.","Unsupervised Discourse Constituency Parsing Using Viterbi EM In this paper, we introduce an unsupervised discourse constituency parsing algorithm. We use Viterbi EM with a margin-based criterion to train a span-based discourse parser in an unsupervised manner. We also propose initialization methods for Viterbi training of discourse constituents based on our prior knowledge of text structures. Experimental results demonstrate that our unsupervised parser achieves comparable or even superior performance to fully supervised parsers. We also investigate discourse constituents that are learned by our method.","unsupervised discourse constituency parsing viterbi em paper , introduce unsupervised discourse constituency parsing algorithm . use viterbi em margin - base criterion train span - base discourse parser unsupervised manner . propose initialization method viterbi training discourse constituent base prior knowledge text structure . experimental result demonstrate unsupervised parser achieve comparable superior performance fully supervise parser . investigate discourse constituent learn method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 8, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 9, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
Ethics and NLP,Towards Debiasing Sentence Representations,"As natural language processing methods are increasingly deployed in real-world scenarios such as healthcare, legal systems, and social science, it becomes necessary to recognize the role they potentially play in shaping social biases and stereotypes. Previous work has revealed the presence of social biases in widely used word embeddings involving gender, race, religion, and other social constructs. While some methods were proposed to debias these word-level embeddings, there is a need to perform debiasing at the sentence-level given the recent shift towards new contextualized sentence representations such as ELMo and BERT. In this paper, we investigate the presence of social biases in sentence-level representations and propose a new method, SENT-DEBIAS, to reduce these biases. We show that SENT-DEBIAS is effective in removing biases, and at the same time, preserves performance on sentence-level downstream tasks such as sentiment analysis, linguistic acceptability, and natural language understanding. We hope that our work will inspire future research on characterizing and removing social biases from widely adopted sentence representations for fairer NLP.","Towards Debiasing Sentence Representations As natural language processing methods are increasingly deployed in real-world scenarios such as healthcare, legal systems, and social science, it becomes necessary to recognize the role they potentially play in shaping social biases and stereotypes. Previous work has revealed the presence of social biases in widely used word embeddings involving gender, race, religion, and other social constructs. While some methods were proposed to debias these word-level embeddings, there is a need to perform debiasing at the sentence-level given the recent shift towards new contextualized sentence representations such as ELMo and BERT. In this paper, we investigate the presence of social biases in sentence-level representations and propose a new method, SENT-DEBIAS, to reduce these biases. We show that SENT-DEBIAS is effective in removing biases, and at the same time, preserves performance on sentence-level downstream tasks such as sentiment analysis, linguistic acceptability, and natural language understanding. We hope that our work will inspire future research on characterizing and removing social biases from widely adopted sentence representations for fairer NLP.","debiase sentence representation natural language processing method increasingly deploy real - world scenario healthcare , legal system , social science , necessary recognize role potentially play shape social bias stereotype . previous work reveal presence social bias widely word embedding involve gender , race , religion , social construct . method propose debias word - level embedding , need perform debiasing sentence - level give recent shift new contextualize sentence representation elmo bert . paper , investigate presence social bias sentence - level representation propose new method , sent - debias , reduce bias . sent - debias effective remove bias , time , preserve performance sentence - level downstream task sentiment analysis , linguistic acceptability , natural language understanding . hope work inspire future research characterize remove social bias widely adopt sentence representation fair nlp .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 27, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,Demographics Should Not Be the Reason of Toxicity: Mitigating Discrimination in Text Classifications with Instance Weighting,"With the recent proliferation of the use of text classifications, researchers have found that there are certain unintended biases in text classification datasets. For example, texts containing some demographic identity-terms (e.g., ""gay"", ""black"") are more likely to be abusive in existing abusive language detection datasets. As a result, models trained with these datasets may consider sentences like ""She makes me happy to be gay"" as abusive simply because of the word ""gay."" In this paper, we formalize the unintended biases in text classification datasets as a kind of selection bias from the non-discrimination distribution to the discrimination distribution. Based on this formalization, we further propose a model-agnostic debiasing training framework by recovering the non-discrimination distribution using instance weighting, which does not require any extra resources or annotations apart from a pre-defined set of demographic identity-terms. Experiments demonstrate that our method can effectively alleviate the impacts of the unintended biases without significantly hurting models' generalization ability.","Demographics Should Not Be the Reason of Toxicity: Mitigating Discrimination in Text Classifications with Instance Weighting With the recent proliferation of the use of text classifications, researchers have found that there are certain unintended biases in text classification datasets. For example, texts containing some demographic identity-terms (e.g., ""gay"", ""black"") are more likely to be abusive in existing abusive language detection datasets. As a result, models trained with these datasets may consider sentences like ""She makes me happy to be gay"" as abusive simply because of the word ""gay."" In this paper, we formalize the unintended biases in text classification datasets as a kind of selection bias from the non-discrimination distribution to the discrimination distribution. Based on this formalization, we further propose a model-agnostic debiasing training framework by recovering the non-discrimination distribution using instance weighting, which does not require any extra resources or annotations apart from a pre-defined set of demographic identity-terms. Experiments demonstrate that our method can effectively alleviate the impacts of the unintended biases without significantly hurting models' generalization ability.","demographic reason toxicity : mitigate discrimination text classification instance weighting recent proliferation use text classification , researcher find certain unintended bias text classification dataset . example , text contain demographic identity - term ( e.g. , "" gay "" , "" black "" ) likely abusive exist abusive language detection dataset . result , model train dataset consider sentence like "" make happy gay "" abusive simply word "" gay . "" paper , formalize unintended bias text classification dataset kind selection bias non - discrimination distribution discrimination distribution . base formalization , propose model - agnostic debiase training framework recover non - discrimination distribution instance weighting , require extra resource annotation apart pre - defined set demographic identity - term . experiment demonstrate method effectively alleviate impact unintended bias significantly hurt model ' generalization ability .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 6, 'Generation': 8, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Generation,False
Ethics and NLP,Social Bias Frames: Reasoning about Social and Power Implications of Language,"Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people's judgments about others. For example, given a statement that ""we shouldn't lower our standards to hire more women,"" most listeners will infer the implicature intended by the speaker -that ""women (candidates) are less qualified."" Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce SOCIAL BIAS FRAMES, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover SOCIAL BIAS FRAMES from unstructured text. We find that while stateof-the-art neural models are effective at highlevel categorization of whether a given statement projects unwanted social bias (80% F 1 ), they are not effective at spelling out more detailed explanations in terms of SOCIAL BIAS FRAMES. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.","Social Bias Frames: Reasoning about Social and Power Implications of Language Warning: this paper contains content that may be offensive or upsetting. Language has the power to reinforce stereotypes and project social biases onto others. At the core of the challenge is that it is rarely what is stated explicitly, but rather the implied meanings, that frame people's judgments about others. For example, given a statement that ""we shouldn't lower our standards to hire more women,"" most listeners will infer the implicature intended by the speaker -that ""women (candidates) are less qualified."" Most semantic formalisms, to date, do not capture such pragmatic implications in which people express social biases and power differentials in language. We introduce SOCIAL BIAS FRAMES, a new conceptual formalism that aims to model the pragmatic frames in which people project social biases and stereotypes onto others. In addition, we introduce the Social Bias Inference Corpus to support large-scale modelling and evaluation with 150k structured annotations of social media posts, covering over 34k implications about a thousand demographic groups. We then establish baseline approaches that learn to recover SOCIAL BIAS FRAMES from unstructured text. We find that while stateof-the-art neural models are effective at highlevel categorization of whether a given statement projects unwanted social bias (80% F 1 ), they are not effective at spelling out more detailed explanations in terms of SOCIAL BIAS FRAMES. Our study motivates future work that combines structured pragmatic inference with commonsense reasoning on social implications.","social bias frame : reasoning social power implication language warning : paper contain content offensive upsetting . language power reinforce stereotype project social bias . core challenge rarely state explicitly , imply meaning , frame people judgment . example , give statement "" lower standard hire woman , "" listener infer implicature intend speaker -that "" woman ( candidate ) qualified . "" semantic formalism , date , capture pragmatic implication people express social bias power differential language . introduce social bias frames , new conceptual formalism aim model pragmatic frame people project social bias stereotype . addition , introduce social bias inference corpus support large - scale modelling evaluation 150k structure annotation social medium post , cover 34k implication thousand demographic group . establish baseline approach learn recover social bias frames unstructured text . find stateof - - art neural model effective highlevel categorization give statement project unwanted social bias ( 80 % f 1 ) , effective spell detailed explanation term social bia frame . study motivate future work combine structured pragmatic inference commonsense reasoning social implication .","{'Computational Social Science and Social Media': 15, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 28, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Ethics and NLP,True
Ethics and NLP,Contextualizing Hate Speech Classifiers with Post-hoc Explanation,"Hate speech classifiers trained on imbalanced datasets struggle to determine if group identifiers like ""gay"" or ""black"" are used in offensive or prejudiced ways. Such biases manifest in false positives when these identifiers are present, due to models' inability to learn the contexts which constitute a hateful usage of identifiers. We extract post-hoc explanations from fine-tuned BERT classifiers to detect bias towards identity terms. Then, we propose a novel regularization technique based on these explanations that encourages models to learn from the context of group identifiers in addition to the identifiers themselves. Our approach improved over baselines in limiting false positives on out-of-domain data while maintaining or improving in-domain performance. â€ ","Contextualizing Hate Speech Classifiers with Post-hoc Explanation Hate speech classifiers trained on imbalanced datasets struggle to determine if group identifiers like ""gay"" or ""black"" are used in offensive or prejudiced ways. Such biases manifest in false positives when these identifiers are present, due to models' inability to learn the contexts which constitute a hateful usage of identifiers. We extract post-hoc explanations from fine-tuned BERT classifiers to detect bias towards identity terms. Then, we propose a novel regularization technique based on these explanations that encourages models to learn from the context of group identifiers in addition to the identifiers themselves. Our approach improved over baselines in limiting false positives on out-of-domain data while maintaining or improving in-domain performance. â€ ","contextualize hate speech classifier post - hoc explanation hate speech classifier train imbalanced dataset struggle determine group identifier like "" gay "" "" black "" offensive prejudiced way . bias manifest false positive identifier present , model ' inability learn context constitute hateful usage identifier . extract post - hoc explanation fine - tune bert classifier detect bias identity term . , propose novel regularization technique base explanation encourage model learn context group identifier addition identifier . approach improve baseline limit false positive - - domain datum maintain improve - domain performance . â€ ","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 7, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,Is Your Classifier Actually Biased? Measuring Fairness under Uncertainty with Bernstein Bounds,"Most NLP datasets are not annotated with protected attributes such as gender, making it difficult to measure classification bias using standard measures of fairness (e.g., equal opportunity). However, manually annotating a large dataset with a protected attribute is slow and expensive. Instead of annotating all the examples, can we annotate a subset of them and use that sample to estimate the bias? While it is possible to do so, the smaller this annotated sample is, the less certain we are that the estimate is close to the true bias. In this work, we propose using Bernstein bounds to represent this uncertainty about the bias estimate as a confidence interval. We provide empirical evidence that a 95% confidence interval derived this way consistently bounds the true bias. In quantifying this uncertainty, our method, which we call Bernstein-bounded unfairness, helps prevent classifiers from being deemed biased or unbiased when there is insufficient evidence to make either claim. Our findings suggest that the datasets currently used to measure specific biases are too small to conclusively identify bias except in the most egregious cases. For example, consider a coreference resolution system that is 5% more accurate on gender-stereotypical sentences -to claim it is biased with 95% confidence, we need a bias-specific dataset that is 3.8 times larger than WinoBias, the largest available.","Is Your Classifier Actually Biased? Measuring Fairness under Uncertainty with Bernstein Bounds Most NLP datasets are not annotated with protected attributes such as gender, making it difficult to measure classification bias using standard measures of fairness (e.g., equal opportunity). However, manually annotating a large dataset with a protected attribute is slow and expensive. Instead of annotating all the examples, can we annotate a subset of them and use that sample to estimate the bias? While it is possible to do so, the smaller this annotated sample is, the less certain we are that the estimate is close to the true bias. In this work, we propose using Bernstein bounds to represent this uncertainty about the bias estimate as a confidence interval. We provide empirical evidence that a 95% confidence interval derived this way consistently bounds the true bias. In quantifying this uncertainty, our method, which we call Bernstein-bounded unfairness, helps prevent classifiers from being deemed biased or unbiased when there is insufficient evidence to make either claim. Our findings suggest that the datasets currently used to measure specific biases are too small to conclusively identify bias except in the most egregious cases. For example, consider a coreference resolution system that is 5% more accurate on gender-stereotypical sentences -to claim it is biased with 95% confidence, we need a bias-specific dataset that is 3.8 times larger than WinoBias, the largest available.","classifier actually bias ? measure fairness uncertainty bernstein bound nlp dataset annotate protect attribute gender , make difficult measure classification bias standard measure fairness ( e.g. , equal opportunity ) . , manually annotate large dataset protect attribute slow expensive . instead annotate example , annotate subset use sample estimate bias ? possible , small annotate sample , certain estimate close true bias . work , propose bernstein bound represent uncertainty bias estimate confidence interval . provide empirical evidence 95 % confidence interval derive way consistently bound true bias . quantify uncertainty , method , bernstein - bound unfairness , help prevent classifier deem biased unbiased insufficient evidence claim . finding suggest dataset currently measure specific bias small conclusively identify bias egregious case . example , consider coreference resolution system 5 % accurate gender - stereotypical sentence -to claim biased 95 % confidence , need bias - specific dataset 3.8 time large winobias , large available .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 15, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,Mitigating Gender Bias Amplification in Distribution by Posterior Regularization,"Advanced machine learning techniques have boosted the performance of natural language processing. Nevertheless, recent studies, e.g., Zhao et al. (2017) show that these techniques inadvertently capture the societal bias hidden in the corpus and further amplify it. However, their analysis is conducted only on models' top predictions. In this paper, we investigate the gender bias amplification issue from the distribution perspective and demonstrate that the bias is amplified in the view of predicted probability distribution over labels. We further propose a bias mitigation approach based on posterior regularization. With little performance loss, our method can almost remove the bias amplification in the distribution. Our study sheds the light on understanding the bias amplification.","Mitigating Gender Bias Amplification in Distribution by Posterior Regularization Advanced machine learning techniques have boosted the performance of natural language processing. Nevertheless, recent studies, e.g., Zhao et al. (2017) show that these techniques inadvertently capture the societal bias hidden in the corpus and further amplify it. However, their analysis is conducted only on models' top predictions. In this paper, we investigate the gender bias amplification issue from the distribution perspective and demonstrate that the bias is amplified in the view of predicted probability distribution over labels. We further propose a bias mitigation approach based on posterior regularization. With little performance loss, our method can almost remove the bias amplification in the distribution. Our study sheds the light on understanding the bias amplification.","mitigate gender bias amplification distribution posterior regularization advanced machine learning technique boost performance natural language processing . , recent study , e.g. , zhao et al . ( 2017 ) technique inadvertently capture societal bias hide corpus amplify . , analysis conduct model ' prediction . paper , investigate gender bias amplification issue distribution perspective demonstrate bias amplify view predict probability distribution label . propose bias mitigation approach base posterior regularization . little performance loss , method remove bias amplification distribution . study shed light understand bias amplification .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 13, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,Toward Gender-Inclusive Coreference Resolution,"Correctly resolving textual mentions of people fundamentally entails making inferences about those people. Such inferences raise the risk of systemic biases in coreference resolution systems, including biases that can harm binary and non-binary trans and cis stakeholders. To better understand such biases, we foreground nuanced conceptualizations of gender from sociology and sociolinguistics, and develop two new datasets for interrogating bias in crowd annotations and in existing coreference resolution systems. Through these studies, conducted on English text, we confirm that without acknowledging and building systems that recognize the complexity of gender, we build systems that lead to many potential harms.","Toward Gender-Inclusive Coreference Resolution Correctly resolving textual mentions of people fundamentally entails making inferences about those people. Such inferences raise the risk of systemic biases in coreference resolution systems, including biases that can harm binary and non-binary trans and cis stakeholders. To better understand such biases, we foreground nuanced conceptualizations of gender from sociology and sociolinguistics, and develop two new datasets for interrogating bias in crowd annotations and in existing coreference resolution systems. Through these studies, conducted on English text, we confirm that without acknowledging and building systems that recognize the complexity of gender, we build systems that lead to many potential harms.","gender - inclusive coreference resolution correctly resolve textual mention people fundamentally entail make inference people . inference raise risk systemic bias coreference resolution system , include bias harm binary non - binary trans cis stakeholder . well understand bias , foreground nuanced conceptualization gender sociology sociolinguistics , develop new dataset interrogate bias crowd annotation exist coreference resolution system . study , conduct english text , confirm acknowledge build system recognize complexity gender , build system lead potential harm .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 7, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,Social Biases in NLP Models as Barriers for Persons with Disabilities,"Building equitable and inclusive NLP technologies demands consideration of whether and how social attitudes are represented in ML models. In particular, representations encoded in models often inadvertently perpetuate undesirable social biases from the data on which they are trained. In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis. Next, we demonstrate that the neural embeddings that are the critical first step in most NLP pipelines similarly contain undesirable biases towards mentions of disability. We end by highlighting topical biases in the discourse about disability which may contribute to the observed model biases; for instance, gun violence, homelessness, and drug addiction are over-represented in texts discussing mental illness.","Social Biases in NLP Models as Barriers for Persons with Disabilities Building equitable and inclusive NLP technologies demands consideration of whether and how social attitudes are represented in ML models. In particular, representations encoded in models often inadvertently perpetuate undesirable social biases from the data on which they are trained. In this paper, we present evidence of such undesirable biases towards mentions of disability in two different English language models: toxicity prediction and sentiment analysis. Next, we demonstrate that the neural embeddings that are the critical first step in most NLP pipelines similarly contain undesirable biases towards mentions of disability. We end by highlighting topical biases in the discourse about disability which may contribute to the observed model biases; for instance, gun violence, homelessness, and drug addiction are over-represented in texts discussing mental illness.","social bias nlp model barrier person disability build equitable inclusive nlp technology demand consideration social attitude represent ml model . particular , representation encode model inadvertently perpetuate undesirable social bias datum train . paper , present evidence undesirable bias mention disability different english language model : toxicity prediction sentiment analysis . , demonstrate neural embedding critical step nlp pipeline similarly contain undesirable bias mention disability . end highlight topical bias discourse disability contribute observe model bias ; instance , gun violence , homelessness , drug addiction - represent text discuss mental illness .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 11, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,"Give Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?","As part of growing NLP capabilities, coupled with an awareness of the ethical dimensions of research, questions have been raised about whether particular datasets and tasks should be deemed off-limits for NLP research. We examine this question with respect to a paper on automatic legal sentencing from EMNLP 2019 which was a source of some debate, in asking whether the paper should have been allowed to be published, who should have been charged with making such a decision, and on what basis. We focus in particular on the role of data statements in ethically assessing research, but also discuss the topic of dual use, and examine the outcomes of similar debates in other scientific disciplines.","Give Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis? As part of growing NLP capabilities, coupled with an awareness of the ethical dimensions of research, questions have been raised about whether particular datasets and tasks should be deemed off-limits for NLP research. We examine this question with respect to a paper on automatic legal sentencing from EMNLP 2019 which was a source of some debate, in asking whether the paper should have been allowed to be published, who should have been charged with making such a decision, and on what basis. We focus in particular on the role of data statements in ethically assessing research, but also discuss the topic of dual use, and examine the outcomes of similar debates in other scientific disciplines.","convenience death : decide use nlp appropriate , basi ? grow nlp capability , couple awareness ethical dimension research , question raise particular dataset task deem - limit nlp research . examine question respect paper automatic legal sentencing emnlp 2019 source debate , ask paper allow publish , charge make decision , basis . focus particular role datum statement ethically assess research , discuss topic dual use , examine outcome similar debate scientific discipline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 2, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 7, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,False
Ethics and NLP,Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation,"Word embeddings derived from humangenerated corpora inherit strong gender bias which can be further amplified by downstream models. Some commonly adopted debiasing approaches, including the seminal Hard Debias algorithm (Bolukbasi et al., 2016) , apply post-processing procedures that project pre-trained word embeddings into a subspace orthogonal to an inferred gender subspace. We discover that semantic-agnostic corpus regularities such as word frequency captured by the word embeddings negatively impact the performance of these algorithms. We propose a simple but effective technique, Double-Hard Debias, which purifies the word embeddings against such corpus regularities prior to inferring and removing the gender subspace. Experiments on three bias mitigation benchmarks show that our approach preserves the distributional semantics of the pre-trained word embeddings while reducing gender bias to a significantly larger degree than prior approaches.","Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation Word embeddings derived from humangenerated corpora inherit strong gender bias which can be further amplified by downstream models. Some commonly adopted debiasing approaches, including the seminal Hard Debias algorithm (Bolukbasi et al., 2016) , apply post-processing procedures that project pre-trained word embeddings into a subspace orthogonal to an inferred gender subspace. We discover that semantic-agnostic corpus regularities such as word frequency captured by the word embeddings negatively impact the performance of these algorithms. We propose a simple but effective technique, Double-Hard Debias, which purifies the word embeddings against such corpus regularities prior to inferring and removing the gender subspace. Experiments on three bias mitigation benchmarks show that our approach preserves the distributional semantics of the pre-trained word embeddings while reducing gender bias to a significantly larger degree than prior approaches.","double - hard debia : tailor word embedding gender bias mitigation word embedding derive humangenerated corpora inherit strong gender bias amplify downstream model . commonly adopt debiase approach , include seminal hard debias algorithm ( bolukbasi et al . , 2016 ) , apply post - process procedure project pre - train word embedding subspace orthogonal infer gender subspace . discover semantic - agnostic corpus regularity word frequency capture word embedding negatively impact performance algorithm . propose simple effective technique , double - hard debias , purify word embedding corpus regularity prior infer remove gender subspace . experiment bias mitigation benchmark approach preserve distributional semantic pre - train word embedding reduce gender bias significantly large degree prior approach .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 22, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 14, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer,"Multilingual representations embed words from many languages into a single semantic space such that words with similar meanings are close to each other regardless of the language. These embeddings have been widely used in various settings, such as cross-lingual transfer, where a natural language processing (NLP) model trained on one language is deployed to another language. While the crosslingual transfer techniques are powerful, they carry gender bias from the source to target languages. In this paper, we study gender bias in multilingual embeddings and how it affects transfer learning for NLP applications. We create a multilingual dataset for bias analysis and propose several ways for quantifying bias in multilingual representations from both the intrinsic and extrinsic perspectives. Experimental results show that the magnitude of bias in the multilingual representations changes differently when we align the embeddings to different target spaces and that the alignment direction can also have an influence on the bias in transfer learning. We further provide recommendations for using the multilingual word representations for downstream tasks.","Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer Multilingual representations embed words from many languages into a single semantic space such that words with similar meanings are close to each other regardless of the language. These embeddings have been widely used in various settings, such as cross-lingual transfer, where a natural language processing (NLP) model trained on one language is deployed to another language. While the crosslingual transfer techniques are powerful, they carry gender bias from the source to target languages. In this paper, we study gender bias in multilingual embeddings and how it affects transfer learning for NLP applications. We create a multilingual dataset for bias analysis and propose several ways for quantifying bias in multilingual representations from both the intrinsic and extrinsic perspectives. Experimental results show that the magnitude of bias in the multilingual representations changes differently when we align the embeddings to different target spaces and that the alignment direction can also have an influence on the bias in transfer learning. We further provide recommendations for using the multilingual word representations for downstream tasks.","gender bias multilingual embedding cross - lingual transfer multilingual representation embed word language single semantic space word similar meaning close regardless language . embedding widely setting , cross - lingual transfer , natural language processing ( nlp ) model train language deploy language . crosslingual transfer technique powerful , carry gender bias source target language . paper , study gender bias multilingual embedding affect transfer learning nlp application . create multilingual dataset bias analysis propose way quantify bias multilingual representation intrinsic extrinsic perspective . experimental result magnitude bias multilingual representation change differently align embedding different target space alignment direction influence bias transfer learning . provide recommendation multilingual word representation downstream task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 13, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Ethics and NLP,Towards Understanding Gender Bias in Relation Extraction,"Recent developments in Neural Relation Extraction (NRE) have made significant strides towards automated knowledge base construction. While much attention has been dedicated towards improvements in accuracy, there have been no attempts in the literature to evaluate social biases exhibited in NRE systems. In this paper, we create WikiGenderBias, a distantly supervised dataset composed of over 45,000 sentences including a 10% human annotated test set for the purpose of analyzing gender bias in relation extraction systems. We find that when extracting spouse and hypernym (i.e., occupation) relations, an NRE system performs differently when the gender of the target entity is different. However, such disparity does not appear when extracting relations such as birth date or birth place. We also analyze two existing bias mitigation techniques, word embedding debiasing and data augmentation. Unfortunately, due to NRE models relying heavily on surface level cues, we find that existing bias mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in relation extraction.","Towards Understanding Gender Bias in Relation Extraction Recent developments in Neural Relation Extraction (NRE) have made significant strides towards automated knowledge base construction. While much attention has been dedicated towards improvements in accuracy, there have been no attempts in the literature to evaluate social biases exhibited in NRE systems. In this paper, we create WikiGenderBias, a distantly supervised dataset composed of over 45,000 sentences including a 10% human annotated test set for the purpose of analyzing gender bias in relation extraction systems. We find that when extracting spouse and hypernym (i.e., occupation) relations, an NRE system performs differently when the gender of the target entity is different. However, such disparity does not appear when extracting relations such as birth date or birth place. We also analyze two existing bias mitigation techniques, word embedding debiasing and data augmentation. Unfortunately, due to NRE models relying heavily on surface level cues, we find that existing bias mitigation approaches have a negative effect on NRE. Our analysis lays groundwork for future quantifying and mitigating bias in relation extraction.","understand gender bias relation extraction recent development neural relation extraction ( nre ) significant stride automate knowledge base construction . attention dedicate improvement accuracy , attempt literature evaluate social bias exhibit nre system . paper , create wikigenderbias , distantly supervised dataset compose 45,000 sentence include 10 % human annotate test set purpose analyze gender bias relation extraction system . find extract spouse hypernym ( i.e. , occupation ) relation , nre system perform differently gender target entity different . , disparity appear extract relation birth date birth place . analyze exist bias mitigation technique , word embedding debiasing data augmentation . unfortunately , nre model rely heavily surface level cue , find exist bias mitigation approach negative effect nre . analysis lay groundwork future quantify mitigate bias relation extraction .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 26, 'Generation': 0, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,True
Generation,A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation,"Story generation, namely, generating a reasonable story from a leading context, is an important but challenging task. In spite of the success in modeling fluency and local coherence, existing neural language generation models (e.g., GPT-2) still suffer from repetition, logic conflicts, and lack of long-range coherence in generated stories. We conjecture that this is because of the difficulty of associating relevant commonsense knowledge, understanding the causal relationships, and planning entities and events with proper temporal order. In this paper, we devise a knowledge-enhanced pretraining model for commonsense story generation. We propose to utilize commonsense knowledge from external knowledge bases to generate reasonable stories. To further capture the causal and temporal dependencies between the sentences in a reasonable story, we use multi-task learning, which combines a discriminative objective to distinguish true and fake stories during fine-tuning. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence.","A Knowledge-Enhanced Pretraining Model for Commonsense Story Generation Story generation, namely, generating a reasonable story from a leading context, is an important but challenging task. In spite of the success in modeling fluency and local coherence, existing neural language generation models (e.g., GPT-2) still suffer from repetition, logic conflicts, and lack of long-range coherence in generated stories. We conjecture that this is because of the difficulty of associating relevant commonsense knowledge, understanding the causal relationships, and planning entities and events with proper temporal order. In this paper, we devise a knowledge-enhanced pretraining model for commonsense story generation. We propose to utilize commonsense knowledge from external knowledge bases to generate reasonable stories. To further capture the causal and temporal dependencies between the sentences in a reasonable story, we use multi-task learning, which combines a discriminative objective to distinguish true and fake stories during fine-tuning. Automatic and manual evaluation shows that our model can generate more reasonable stories than state-of-the-art baselines, particularly in terms of logic and global coherence.","knowledge - enhance pretraine model commonsense story generation story generation , , generate reasonable story leading context , important challenging task . spite success model fluency local coherence , exist neural language generation model ( e.g. , gpt-2 ) suffer repetition , logic conflict , lack long - range coherence generate story . conjecture difficulty associate relevant commonsense knowledge , understand causal relationship , plan entity event proper temporal order . paper , devise knowledge - enhance pretraine model commonsense story generation . propose utilize commonsense knowledge external knowledge basis generate reasonable story . capture causal temporal dependency sentence reasonable story , use multi - task learning , combine discriminative objective distinguish true fake story fine - tuning . automatic manual evaluation show model generate reasonable story state - - - art baseline , particularly term logic global coherence .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 20, 'Information Extraction': 10, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,TAG : Type Auxiliary Guiding for Code Comment Generation,"Existing leading code comment generation approaches with the structure-to-sequence framework ignores the type information of the interpretation of the code, e.g., operator, string, etc. However, introducing the type information into the existing framework is non-trivial due to the hierarchical dependence among the type information. In order to address the issues above, we propose a Type Auxiliary Guiding encoder-decoder framework for the code comment generation task which considers the source code as an N-ary tree with type information associated with each node. Specifically, our framework is featured with a Typeassociated Encoder and a Type-restricted Decoder which enables adaptive summarization of the source code. We further propose a hierarchical reinforcement learning method to resolve the training difficulties of our proposed framework. Extensive evaluations demonstrate the state-of-the-art performance of our framework with both the auto-evaluated metrics and case studies.","TAG : Type Auxiliary Guiding for Code Comment Generation Existing leading code comment generation approaches with the structure-to-sequence framework ignores the type information of the interpretation of the code, e.g., operator, string, etc. However, introducing the type information into the existing framework is non-trivial due to the hierarchical dependence among the type information. In order to address the issues above, we propose a Type Auxiliary Guiding encoder-decoder framework for the code comment generation task which considers the source code as an N-ary tree with type information associated with each node. Specifically, our framework is featured with a Typeassociated Encoder and a Type-restricted Decoder which enables adaptive summarization of the source code. We further propose a hierarchical reinforcement learning method to resolve the training difficulties of our proposed framework. Extensive evaluations demonstrate the state-of-the-art performance of our framework with both the auto-evaluated metrics and case studies.","tag : type auxiliary guiding code comment generation exist lead code comment generation approach structure - - sequence framework ignore type information interpretation code , e.g. , operator , string , etc . , introduce type information exist framework non - trivial hierarchical dependence type information . order address issue , propose type auxiliary guiding encoder - decoder framework code comment generation task consider source code n - ary tree type information associate node . specifically , framework feature typeassociated encoder type - restricted decoder enable adaptive summarization source code . propose hierarchical reinforcement learning method resolve training difficulty propose framework . extensive evaluation demonstrate state - - - art performance framework auto - evaluate metric case study .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 10, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Generation,Toward Better Storylines with Sentence-Level Language Models,"We propose a sentence-level language model which selects the next sentence in a story from a finite set of fluent alternatives. Since it does not need to model fluency, the sentence-level language model can focus on longer range dependencies, which are crucial for multisentence coherence. Rather than dealing with individual words, our method treats the story so far as a list of pre-trained sentence embeddings and predicts an embedding for the next sentence, which is more efficient than predicting word embeddings. Notably this allows us to consider a large number of candidates for the next sentence during training. We demonstrate the effectiveness of our approach with state-of-the-art accuracy on the unsupervised Story Cloze task and with promising results on larger-scale next sentence prediction tasks.","Toward Better Storylines with Sentence-Level Language Models We propose a sentence-level language model which selects the next sentence in a story from a finite set of fluent alternatives. Since it does not need to model fluency, the sentence-level language model can focus on longer range dependencies, which are crucial for multisentence coherence. Rather than dealing with individual words, our method treats the story so far as a list of pre-trained sentence embeddings and predicts an embedding for the next sentence, which is more efficient than predicting word embeddings. Notably this allows us to consider a large number of candidates for the next sentence during training. We demonstrate the effectiveness of our approach with state-of-the-art accuracy on the unsupervised Story Cloze task and with promising results on larger-scale next sentence prediction tasks.","well storyline sentence - level language model propose sentence - level language model select sentence story finite set fluent alternative . need model fluency , sentence - level language model focus long range dependency , crucial multisentence coherence . deal individual word , method treat story far list pre - trained sentence embedding predict embedding sentence , efficient predict word embedding . notably allow consider large number candidate sentence training . demonstrate effectiveness approach state - - - art accuracy unsupervised story cloze task promising result large - scale sentence prediction task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Generation,Semantic Graphs for Generating Deep Questions,"This paper proposes the problem of Deep Question Generation (DQG), which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage. In order to capture the global structure of the document and facilitate reasoning, we propose a novel framework which first constructs a semantic-level graph for the input document and then encodes the semantic graph by introducing an attention-based GGNN (Att-GGNN). Afterwards, we fuse the document-level and graphlevel representations to perform joint training of content selection and question decoding. On the HotpotQA deep-question centric dataset, our model greatly improves performance over questions requiring reasoning over multiple facts, leading to state-of-theart performance. The code is publicly available at https://github.com/WING-NUS/ SG-Deep-Question-Generation.","Semantic Graphs for Generating Deep Questions This paper proposes the problem of Deep Question Generation (DQG), which aims to generate complex questions that require reasoning over multiple pieces of information of the input passage. In order to capture the global structure of the document and facilitate reasoning, we propose a novel framework which first constructs a semantic-level graph for the input document and then encodes the semantic graph by introducing an attention-based GGNN (Att-GGNN). Afterwards, we fuse the document-level and graphlevel representations to perform joint training of content selection and question decoding. On the HotpotQA deep-question centric dataset, our model greatly improves performance over questions requiring reasoning over multiple facts, leading to state-of-theart performance. The code is publicly available at https://github.com/WING-NUS/ SG-Deep-Question-Generation.","semantic graph generate deep question paper propose problem deep question generation ( dqg ) , aim generate complex question require reason multiple piece information input passage . order capture global structure document facilitate reasoning , propose novel framework construct semantic - level graph input document encode semantic graph introduce attention - base ggnn ( att - ggnn ) . , fuse document - level graphlevel representation perform joint training content selection question decoding . hotpotqa deep - question centric dataset , model greatly improve performance question require reasoning multiple fact , lead state - - theart performance . code publicly available https://github.com/wing-nus/ sg - deep - question - generation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 8, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation,"Generating sequential natural language descriptions from graph-structured data (e.g., knowledge graph) is challenging, partly because of the structural differences between the input graph and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the encoder and decoder, making faithful generation difficult. To narrow this gap, we propose DUA-LENC, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.","Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation Generating sequential natural language descriptions from graph-structured data (e.g., knowledge graph) is challenging, partly because of the structural differences between the input graph and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the encoder and decoder, making faithful generation difficult. To narrow this gap, we propose DUA-LENC, a dual encoding model that can not only incorporate the graph structure, but can also cater to the linear structure of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.","bridge structural gap encode decode data - - text generation generate sequential natural language description graph - structured datum ( e.g. , knowledge graph ) challenging , partly structural difference input graph output text . , popular sequence - - sequence model , require serialize input , natural fit task . graph neural network , hand , well encode input graph broaden structural gap encoder decoder , make faithful generation difficult . narrow gap , propose dua - lenc , dual encoding model incorporate graph structure , cater linear structure output text . empirical comparison strong single - encoder baseline demonstrate dual encoding significantly improve quality generate text .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Politeness Transfer: A Tag and Generate Approach,"This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 million instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https:// github.com/tag-and-generate/ Introduction Politeness plays a crucial role in social interaction, and is closely tied with power dynamics, social distance between the participants of a conversation, and gender (Brown et al., 1987; Danescu-Niculescu-Mizil et al., 2013) . It is also imperative to use the appropriate level of politeness for smooth communication in conversations (Coppock, 2005) , organizational settings like emails (Peterson et al., 2011) , memos, official documents, and many other settings. Notably, politeness has also been identified as an interpersonal style which can be decoupled from content (Kang and Hovy, 2019). Motivated by its central importance, in this paper we study the task of converting non-polite sentences to polite sentences while preserving the meaning.","Politeness Transfer: A Tag and Generate Approach This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 million instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https:// github.com/tag-and-generate/ Introduction Politeness plays a crucial role in social interaction, and is closely tied with power dynamics, social distance between the participants of a conversation, and gender (Brown et al., 1987; Danescu-Niculescu-Mizil et al., 2013) . It is also imperative to use the appropriate level of politeness for smooth communication in conversations (Coppock, 2005) , organizational settings like emails (Peterson et al., 2011) , memos, official documents, and many other settings. Notably, politeness has also been identified as an interpersonal style which can be decoupled from content (Kang and Hovy, 2019). Motivated by its central importance, in this paper we study the task of converting non-polite sentences to polite sentences while preserving the meaning.","politeness transfer : tag generate approach paper introduce new task politeness transfer involve convert non - polite sentence polite sentence preserve meaning . provide dataset 1.39 million instance automatically label politeness encourage benchmark evaluation new task . design tag generate pipeline identify stylistic attribute subsequently generate sentence target style preserve source content . politeness transfer task , model outperform state - - - art method automatic metric content preservation , comparable well performance style transfer accuracy . additionally , model surpass exist method human evaluation grammaticality , mean preservation transfer accuracy style transfer task . datum code locate https:// github.com/tag-and-generate/ introduction politeness play crucial role social interaction , closely tie power dynamic , social distance participant conversation , gender ( brown et al . , 1987 ; danescu - niculescu - mizil et al . , 2013 ) . imperative use appropriate level politeness smooth communication conversation ( coppock , 2005 ) , organizational setting like email ( peterson et al . , 2011 ) , memo , official document , setting . notably , politeness identify interpersonal style decouple content ( kang hovy , 2019 ) . motivate central importance , paper study task convert non - polite sentence polite sentence preserve meaning .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Generation,Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence,"The neural attention model has achieved great success in data-to-text generation tasks. Though usually excelling at producing fluent text, it suffers from the problem of information missing, repetition and ""hallucination"". Due to the black-box nature of the neural attention architecture, avoiding these problems in a systematic way is non-trivial. To address this concern, we propose to explicitly segment target text into fragment units and align them with their data correspondences. The segmentation and correspondence are jointly learned as latent variables without any human annotations. We further impose a soft statistical constraint to regularize the segmental granularity. The resulting architecture maintains the same expressive power as neural attention models, while being able to generate fully interpretable outputs with several times less computational cost. On both E2E and WebNLG benchmarks, we show the proposed model consistently outperforms its neural attention counterparts.","Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence The neural attention model has achieved great success in data-to-text generation tasks. Though usually excelling at producing fluent text, it suffers from the problem of information missing, repetition and ""hallucination"". Due to the black-box nature of the neural attention architecture, avoiding these problems in a systematic way is non-trivial. To address this concern, we propose to explicitly segment target text into fragment units and align them with their data correspondences. The segmentation and correspondence are jointly learned as latent variables without any human annotations. We further impose a soft statistical constraint to regularize the segmental granularity. The resulting architecture maintains the same expressive power as neural attention models, while being able to generate fully interpretable outputs with several times less computational cost. On both E2E and WebNLG benchmarks, we show the proposed model consistently outperforms its neural attention counterparts.","neural data - - text generation jointly learn segmentation correspondence neural attention model achieve great success data - - text generation task . usually excel produce fluent text , suffer problem information miss , repetition "" hallucination "" . black - box nature neural attention architecture , avoid problem systematic way non - trivial . address concern , propose explicitly segment target text fragment unit align data correspondence . segmentation correspondence jointly learn latent variable human annotation . impose soft statistical constraint regularize segmental granularity . result architecture maintain expressive power neural attention model , able generate fully interpretable output time computational cost . e2e webnlg benchmark , propose model consistently outperform neural attention counterpart .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Few-Shot NLG with Pre-Trained Language Model,"Neural-based end-to-end approaches to natural language generation (NLG) from structured data or knowledge are data-hungry, making their adoption for real-world applications difficult with limited data. In this work, we propose the new task of few-shot natural language generation. Motivated by how humans tend to summarize tabular data, we propose a simple yet effective approach and show that it not only demonstrates strong performance but also provides good generalization across domains. The design of the model architecture is based on two aspects: content selection from input data and language modeling to compose coherent sentences, which can be acquired from prior knowledge. With just 200 training examples, across multiple domains, we show that our approach achieves very reasonable performances and outperforms the strongest baseline by an average of over 8.0 BLEU points improvement.","Few-Shot NLG with Pre-Trained Language Model Neural-based end-to-end approaches to natural language generation (NLG) from structured data or knowledge are data-hungry, making their adoption for real-world applications difficult with limited data. In this work, we propose the new task of few-shot natural language generation. Motivated by how humans tend to summarize tabular data, we propose a simple yet effective approach and show that it not only demonstrates strong performance but also provides good generalization across domains. The design of the model architecture is based on two aspects: content selection from input data and language modeling to compose coherent sentences, which can be acquired from prior knowledge. With just 200 training examples, across multiple domains, we show that our approach achieves very reasonable performances and outperforms the strongest baseline by an average of over 8.0 BLEU points improvement.","- shot nlg pre - trained language model neural - base end - - end approach natural language generation ( nlg ) structure datum knowledge datum - hungry , make adoption real - world application difficult limited datum . work , propose new task - shot natural language generation . motivate human tend summarize tabular datum , propose simple effective approach demonstrate strong performance provide good generalization domain . design model architecture base aspect : content selection input datum language modeling compose coherent sentence , acquire prior knowledge . 200 training example , multiple domain , approach achieve reasonable performance outperform strong baseline average 8.0 bleu point improvement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 3, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Fluent Response Generation for Conversational Question Answering,"Question answering (QA) is an important aspect of open-domain conversational agents, garnering specific research focus in the conversational QA (ConvQA) subtask. One notable limitation of recent ConvQA efforts is the response being answer span extraction from the target corpus, thus ignoring the natural language generation (NLG) aspect of high-quality conversational agents. In this work, we propose a method for situating QA responses within a SEQ2SEQ NLG approach to generate fluent grammatical answer responses while maintaining correctness. From a technical perspective, we use data augmentation to generate training data for an end-to-end system. Specifically, we develop Syntactic Transformations (STs) to produce question-specific candidate answer responses and rank them using a BERT-based classifier (Devlin et al., 2019). Human evaluation on SQuAD 2.0 data (Rajpurkar et al., 2018) demonstrate that the proposed model outperforms baseline CoQA and QuAC models in generating conversational responses. We further show our model's scalability by conducting tests on the CoQA dataset. 1","Fluent Response Generation for Conversational Question Answering Question answering (QA) is an important aspect of open-domain conversational agents, garnering specific research focus in the conversational QA (ConvQA) subtask. One notable limitation of recent ConvQA efforts is the response being answer span extraction from the target corpus, thus ignoring the natural language generation (NLG) aspect of high-quality conversational agents. In this work, we propose a method for situating QA responses within a SEQ2SEQ NLG approach to generate fluent grammatical answer responses while maintaining correctness. From a technical perspective, we use data augmentation to generate training data for an end-to-end system. Specifically, we develop Syntactic Transformations (STs) to produce question-specific candidate answer responses and rank them using a BERT-based classifier (Devlin et al., 2019). Human evaluation on SQuAD 2.0 data (Rajpurkar et al., 2018) demonstrate that the proposed model outperforms baseline CoQA and QuAC models in generating conversational responses. We further show our model's scalability by conducting tests on the CoQA dataset. 1","fluent response generation conversational question answering question answering ( qa ) important aspect open - domain conversational agent , garner specific research focus conversational qa ( convqa ) subtask . notable limitation recent convqa effort response answer span extraction target corpus , ignore natural language generation ( nlg ) aspect high - quality conversational agent . work , propose method situate qa response seq2seq nlg approach generate fluent grammatical answer response maintain correctness . technical perspective , use data augmentation generate training datum end - - end system . specifically , develop syntactic transformations ( sts ) produce question - specific candidate answer response rank bert - base classifier ( devlin et al . , 2019 ) . human evaluation squad 2.0 datum ( rajpurkar et al . , 2018 ) demonstrate propose model outperform baseline coqa quac model generate conversational response . model scalability conduct test coqa dataset . 1","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 21, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Generation,Structural Information Preserving for Graph-to-Text Generation,"The task of graph-to-text generation aims at producing sentences that preserve the meaning of input graphs. As a crucial defect, the current state-of-the-art models may mess up or even drop the core structural information of input graphs when generating outputs. We propose to tackle this problem by leveraging richer training signals that can guide our model for preserving input information. In particular, we introduce two types of autoencoding losses, each individually focusing on different aspects (a.k.a. views) of input graphs. The losses are then back-propagated to better calibrate our model via multi-task training. Experiments on two benchmarks for graph-to-text generation show the effectiveness of our approach over a state-of-the-art baseline. Our code is available at http://github.com/ Soistesimmer/AMR-multiview.","Structural Information Preserving for Graph-to-Text Generation The task of graph-to-text generation aims at producing sentences that preserve the meaning of input graphs. As a crucial defect, the current state-of-the-art models may mess up or even drop the core structural information of input graphs when generating outputs. We propose to tackle this problem by leveraging richer training signals that can guide our model for preserving input information. In particular, we introduce two types of autoencoding losses, each individually focusing on different aspects (a.k.a. views) of input graphs. The losses are then back-propagated to better calibrate our model via multi-task training. Experiments on two benchmarks for graph-to-text generation show the effectiveness of our approach over a state-of-the-art baseline. Our code is available at http://github.com/ Soistesimmer/AMR-multiview.","structural information preserving graph - - text generation task graph - - text generation aim produce sentence preserve meaning input graph . crucial defect , current state - - - art model mess drop core structural information input graph generate output . propose tackle problem leverage rich training signal guide model preserve input information . particular , introduce type autoencoding loss , individually focus different aspect ( a.k.a . view ) input graph . loss - propagate well calibrate model multi - task training . experiment benchmark graph - - text generation effectiveness approach state - - - art baseline . code available http://github.com/ soistesimmer / amr - multiview .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation,"Question Generation (QG) is fundamentally a simple syntactic transformation; however, many aspects of semantics influence what questions are good to form. We implement this observation by developing Syn-QG, a set of transparent syntactic rules leveraging universal dependencies, shallow semantic parsing, lexical resources, and custom rules which transform declarative sentences into questionanswer pairs. We utilize PropBank argument descriptions and VerbNet state predicates to incorporate shallow semantic content, which helps generate questions of a descriptive nature and produce inferential and semantically richer questions than existing systems. In order to improve syntactic fluency and eliminate grammatically incorrect questions, we employ back-translation over the output of these syntactic rules. A set of crowd-sourced evaluations shows that our system can generate a larger number of highly grammatical and relevant questions than previous QG systems and that back-translation drastically improves grammaticality at a slight cost of generating irrelevant questions.","Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation Question Generation (QG) is fundamentally a simple syntactic transformation; however, many aspects of semantics influence what questions are good to form. We implement this observation by developing Syn-QG, a set of transparent syntactic rules leveraging universal dependencies, shallow semantic parsing, lexical resources, and custom rules which transform declarative sentences into questionanswer pairs. We utilize PropBank argument descriptions and VerbNet state predicates to incorporate shallow semantic content, which helps generate questions of a descriptive nature and produce inferential and semantically richer questions than existing systems. In order to improve syntactic fluency and eliminate grammatically incorrect questions, we employ back-translation over the output of these syntactic rules. A set of crowd-sourced evaluations shows that our system can generate a larger number of highly grammatical and relevant questions than previous QG systems and that back-translation drastically improves grammaticality at a slight cost of generating irrelevant questions.","syn - qg : syntactic shallow semantic rules question generation question generation ( qg ) fundamentally simple syntactic transformation ; , aspect semantic influence question good form . implement observation develop syn - qg , set transparent syntactic rule leverage universal dependency , shallow semantic parsing , lexical resource , custom rule transform declarative sentence questionanswer pair . utilize propbank argument description verbnet state predicate incorporate shallow semantic content , help generate question descriptive nature produce inferential semantically rich question exist system . order improve syntactic fluency eliminate grammatically incorrect question , employ - translation output syntactic rule . set crowd - source evaluation show system generate large number highly grammatical relevant question previous qg system - translation drastically improve grammaticality slight cost generate irrelevant question .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 10, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Generation,Rigid Formats Controlled Text Generation,"Neural text generation has made tremendous progress in various tasks. One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating. However, we may confront some special text paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these texts are in three folds: (1) They must comply fully with the rigid predefined formats. (2) They must obey some rhyming schemes. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, text generation based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant framework named SongNet to tackle this problem. The backbone of the framework is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on format, rhyme, and sentence integrity. We improve the attention mechanism to impel the model to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation. 1","Rigid Formats Controlled Text Generation Neural text generation has made tremendous progress in various tasks. One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating. However, we may confront some special text paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these texts are in three folds: (1) They must comply fully with the rigid predefined formats. (2) They must obey some rhyming schemes. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, text generation based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant framework named SongNet to tackle this problem. The backbone of the framework is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on format, rhyme, and sentence integrity. We improve the attention mechanism to impel the model to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation. 1","rigid format control text generation neural text generation tremendous progress task . common characteristic task text restrict rigid format generate . , confront special text paradigm lyric ( assume music score give ) , sonnet , songci ( classical chinese poetry song dynasty ) , etc . typical characteristic text fold : ( 1 ) comply fully rigid predefine format . ( 2 ) obey rhyming scheme . ( 3 ) restrict format , sentence integrity guarantee . good knowledge , text generation base predefine rigid format investigate . , propose simple elegant framework name songnet tackle problem . backbone framework transformer - base auto - regressive language model . set symbol tailor - design improve modeling performance especially format , rhyme , sentence integrity . improve attention mechanism impel model capture future information format . pre - training fine - tuning framework design improve generation quality . extensive experiment conduct collect corpus demonstrate propose framework generate significantly well result term automatic metric human evaluation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 14, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Neural Syntactic Preordering for Controlled Paraphrase Generation,"Paraphrasing natural language sentences is a multifaceted process: it might involve replacing individual words or short phrases, local rearrangement of content, or high-level restructuring like topicalization or passivization. Past approaches struggle to cover this space of paraphrase possibilities in an interpretable manner. Our work, inspired by pre-ordering literature in machine translation, uses syntactic transformations to softly ""reorder"" the source sentence and guide our neural paraphrasing model. First, given an input sentence, we derive a set of feasible syntactic rearrangements using an encoder-decoder model. This model operates over a partially lexical, partially syntactic view of the sentence and can reorder big chunks. Next, we use each proposed rearrangement to produce a sequence of position embeddings, which encourages our final encoder-decoder paraphrase model to attend to the source words in a particular order. Our evaluation, both automatic and human, shows that the proposed system retains the quality of the baseline approaches while giving a substantial increase in the diversity of the generated paraphrases. 1","Neural Syntactic Preordering for Controlled Paraphrase Generation Paraphrasing natural language sentences is a multifaceted process: it might involve replacing individual words or short phrases, local rearrangement of content, or high-level restructuring like topicalization or passivization. Past approaches struggle to cover this space of paraphrase possibilities in an interpretable manner. Our work, inspired by pre-ordering literature in machine translation, uses syntactic transformations to softly ""reorder"" the source sentence and guide our neural paraphrasing model. First, given an input sentence, we derive a set of feasible syntactic rearrangements using an encoder-decoder model. This model operates over a partially lexical, partially syntactic view of the sentence and can reorder big chunks. Next, we use each proposed rearrangement to produce a sequence of position embeddings, which encourages our final encoder-decoder paraphrase model to attend to the source words in a particular order. Our evaluation, both automatic and human, shows that the proposed system retains the quality of the baseline approaches while giving a substantial increase in the diversity of the generated paraphrases. 1","neural syntactic preordering control paraphrase generation paraphrase natural language sentence multifaceted process : involve replace individual word short phrase , local rearrangement content , high - level restructuring like topicalization passivization . past approach struggle cover space paraphrase possibility interpretable manner . work , inspire pre - order literature machine translation , use syntactic transformation softly "" reorder "" source sentence guide neural paraphrasing model . , give input sentence , derive set feasible syntactic rearrangement encoder - decoder model . model operate partially lexical , partially syntactic view sentence reorder big chunk . , use propose rearrangement produce sequence position embedding , encourage final encoder - decoder paraphrase model attend source word particular order . evaluation , automatic human , show propose system retain quality baseline approach give substantial increase diversity generate paraphrase . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Generation,Fact-based Text Editing,"We propose a novel text editing task, referred to as fact-based text editing, in which the goal is to revise a given document to better describe the facts in a knowledge base (e.g., several triples). The task is important in practice because reflecting the truth is a common requirement in text editing. First, we propose a method for automatically generating a dataset for research on fact-based text editing, where each instance consists of a draft text, a revised text, and several facts represented in triples. We apply the method into two public tableto-text datasets, obtaining two new datasets consisting of 233k and 37k instances, respectively. Next, we propose a new neural network architecture for fact-based text editing, called FACTEDITOR, which edits a draft text by referring to given facts using a buffer, a stream, and a memory. A straightforward approach to address the problem would be to employ an encoder-decoder model. Our experimental results on the two datasets show that FACTE-DITOR outperforms the encoder-decoder approach in terms of fidelity and fluency. The results also show that FACTEDITOR conducts inference faster than the encoder-decoder approach.","Fact-based Text Editing We propose a novel text editing task, referred to as fact-based text editing, in which the goal is to revise a given document to better describe the facts in a knowledge base (e.g., several triples). The task is important in practice because reflecting the truth is a common requirement in text editing. First, we propose a method for automatically generating a dataset for research on fact-based text editing, where each instance consists of a draft text, a revised text, and several facts represented in triples. We apply the method into two public tableto-text datasets, obtaining two new datasets consisting of 233k and 37k instances, respectively. Next, we propose a new neural network architecture for fact-based text editing, called FACTEDITOR, which edits a draft text by referring to given facts using a buffer, a stream, and a memory. A straightforward approach to address the problem would be to employ an encoder-decoder model. Our experimental results on the two datasets show that FACTE-DITOR outperforms the encoder-decoder approach in terms of fidelity and fluency. The results also show that FACTEDITOR conducts inference faster than the encoder-decoder approach.","fact - base text editing propose novel text editing task , refer fact - base text editing , goal revise give document well describe fact knowledge base ( e.g. , triple ) . task important practice reflect truth common requirement text editing . , propose method automatically generate dataset research fact - base text editing , instance consist draft text , revise text , fact represent triple . apply method public tableto - text dataset , obtain new dataset consist 233k 37k instance , respectively . , propose new neural network architecture fact - base text editing , call facteditor , edit draft text refer give fact buffer , stream , memory . straightforward approach address problem employ encoder - decoder model . experimental result dataset facte - ditor outperform encoder - decoder approach term fidelity fluency . result facteditor conduct inference fast encoder - decoder approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 21, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 12, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Fast and Accurate Non-Projective Dependency Tree Linearization,"We propose a graph-based method to tackle the dependency tree linearization task. We formulate the task as a Traveling Salesman Problem (TSP), and use a biaffine attention model to calculate the edge costs. We facilitate the decoding by solving the TSP for each subtree and combining the solution into a projective tree. We then design a transition system as post-processing, inspired by non-projective transition-based parsing, to obtain non-projective sentences. Our proposed method outperforms the state-of-the-art linearizer while being 10 times faster in training and decoding.","Fast and Accurate Non-Projective Dependency Tree Linearization We propose a graph-based method to tackle the dependency tree linearization task. We formulate the task as a Traveling Salesman Problem (TSP), and use a biaffine attention model to calculate the edge costs. We facilitate the decoding by solving the TSP for each subtree and combining the solution into a projective tree. We then design a transition system as post-processing, inspired by non-projective transition-based parsing, to obtain non-projective sentences. Our proposed method outperforms the state-of-the-art linearizer while being 10 times faster in training and decoding.","fast accurate non - projective dependency tree linearization propose graph - base method tackle dependency tree linearization task . formulate task traveling salesman problem ( tsp ) , use biaffine attention model calculate edge cost . facilitate decoding solve tsp subtree combine solution projective tree . design transition system post - processing , inspire non - projective transition - base parsing , obtain non - projective sentence . propose method outperform state - - - art linearizer 10 time fast training decoding .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 9, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
Generation,Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints,"Text generation from a knowledge base aims to translate knowledge triples to naturallanguage descriptions. Most existing methods ignore the faithfulness between a generated text description and the original table, leading to generated information that goes beyond the content of the table. In this paper, for the first time, we propose a novel Transformerbased generation framework to achieve the goal. The core techniques in our method to enforce faithfulness include a new table-text optimal-transport matching loss and a tabletext embedding similarity loss based on the Transformer model. Furthermore, to evaluate faithfulness, we propose a new automatic metric specialized to the table-to-text generation problem. We also provide detailed analysis on each component of our model in our experiments. Automatic and human evaluations show that our framework can significantly outperform state-of-the-art by a large margin.","Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints Text generation from a knowledge base aims to translate knowledge triples to naturallanguage descriptions. Most existing methods ignore the faithfulness between a generated text description and the original table, leading to generated information that goes beyond the content of the table. In this paper, for the first time, we propose a novel Transformerbased generation framework to achieve the goal. The core techniques in our method to enforce faithfulness include a new table-text optimal-transport matching loss and a tabletext embedding similarity loss based on the Transformer model. Furthermore, to evaluate faithfulness, we propose a new automatic metric specialized to the table-to-text generation problem. We also provide detailed analysis on each component of our model in our experiments. Automatic and human evaluations show that our framework can significantly outperform state-of-the-art by a large margin.","faithful neural table - - text generation content - matching constraint text generation knowledge base aim translate knowledge triple naturallanguage description . exist method ignore faithfulness generate text description original table , lead generate information go content table . paper , time , propose novel transformerbased generation framework achieve goal . core technique method enforce faithfulness include new table - text optimal - transport matching loss tabletext embedding similarity loss base transformer model . furthermore , evaluate faithfulness , propose new automatic metric specialize table - - text generation problem . provide detailed analysis component model experiment . automatic human evaluation framework significantly outperform state - - - art large margin .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Iterative Edit-Based Unsupervised Sentence Simplification,"We present a novel iterative, edit-based approach to unsupervised sentence simplification. Our model is guided by a scoring function involving fluency, simplicity, and meaning preservation. Then, we iteratively perform word and phrase-level edits on the complex sentence. Compared with previous approaches, our model does not require a parallel training set, but is more controllable and interpretable. Experiments on Newsela and WikiLarge datasets show that our approach is nearly as effective as state-of-the-art supervised approaches. 1","Iterative Edit-Based Unsupervised Sentence Simplification We present a novel iterative, edit-based approach to unsupervised sentence simplification. Our model is guided by a scoring function involving fluency, simplicity, and meaning preservation. Then, we iteratively perform word and phrase-level edits on the complex sentence. Compared with previous approaches, our model does not require a parallel training set, but is more controllable and interpretable. Experiments on Newsela and WikiLarge datasets show that our approach is nearly as effective as state-of-the-art supervised approaches. 1","iterative edit - base unsupervised sentence simplification present novel iterative , edit - base approach unsupervised sentence simplification . model guide scoring function involve fluency , simplicity , meaning preservation . , iteratively perform word phrase - level edit complex sentence . compare previous approach , model require parallel training set , controllable interpretable . experiment newsela wikilarge dataset approach nearly effective state - - - art supervise approach . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Neural CRF Model for Sentence Alignment in Text Simplification,"The success of a text simplification system heavily depends on the quality and quantity of complex-simple sentence pairs in the training corpus, which are extracted by aligning sentences between parallel articles. To evaluate and improve sentence alignment quality, we create two manually annotated sentence-aligned datasets from two commonly used text simplification corpora, Newsela and Wikipedia. We propose a novel neural CRF alignment model which not only leverages the sequential nature of sentences in parallel documents but also utilizes a neural sentence pair model to capture semantic similarity. Experiments demonstrate that our proposed approach outperforms all the previous work on monolingual sentence alignment task by more than 5 points in F1. We apply our CRF aligner to construct two new text simplification datasets, NEWSELA-AUTO and WIKI-AUTO, which are much larger and of better quality compared to the existing datasets. A Transformer-based seq2seq model trained on our datasets establishes a new state-of-the-art for text simplification in both automatic and human evaluation. 1","Neural CRF Model for Sentence Alignment in Text Simplification The success of a text simplification system heavily depends on the quality and quantity of complex-simple sentence pairs in the training corpus, which are extracted by aligning sentences between parallel articles. To evaluate and improve sentence alignment quality, we create two manually annotated sentence-aligned datasets from two commonly used text simplification corpora, Newsela and Wikipedia. We propose a novel neural CRF alignment model which not only leverages the sequential nature of sentences in parallel documents but also utilizes a neural sentence pair model to capture semantic similarity. Experiments demonstrate that our proposed approach outperforms all the previous work on monolingual sentence alignment task by more than 5 points in F1. We apply our CRF aligner to construct two new text simplification datasets, NEWSELA-AUTO and WIKI-AUTO, which are much larger and of better quality compared to the existing datasets. A Transformer-based seq2seq model trained on our datasets establishes a new state-of-the-art for text simplification in both automatic and human evaluation. 1","neural crf model sentence alignment text simplification success text simplification system heavily depend quality quantity complex - simple sentence pair training corpus , extract align sentence parallel article . evaluate improve sentence alignment quality , create manually annotate sentence - align dataset commonly text simplification corpus , newsela wikipedia . propose novel neural crf alignment model leverage sequential nature sentence parallel document utilize neural sentence pair model capture semantic similarity . experiment demonstrate propose approach outperform previous work monolingual sentence alignment task 5 point f1 . apply crf aligner construct new text simplification dataset , newsela - auto wiki - auto , large well quality compare exist dataset . transformer - base seq2seq model train dataset establish new state - - - art text simplification automatic human evaluation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 6, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,False
Generation,BLEURT: Learning Robust Metrics for Text Generation,"Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgments. We propose BLEURT, a learned evaluation metric based on BERT that can model human judgments with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-ofthe-art results on the last three years of the WMT Metrics shared task and the WebNLG Competition dataset. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution.","BLEURT: Learning Robust Metrics for Text Generation Text generation has made significant advances in the last few years. Yet, evaluation metrics have lagged behind, as the most popular choices (e.g., BLEU and ROUGE) may correlate poorly with human judgments. We propose BLEURT, a learned evaluation metric based on BERT that can model human judgments with a few thousand possibly biased training examples. A key aspect of our approach is a novel pre-training scheme that uses millions of synthetic examples to help the model generalize. BLEURT provides state-ofthe-art results on the last three years of the WMT Metrics shared task and the WebNLG Competition dataset. In contrast to a vanilla BERT-based approach, it yields superior results even when the training data is scarce and out-of-distribution.","bleurt : learn robust metric text generation text generation significant advance year . , evaluation metric lag , popular choice ( e.g. , bleu rouge ) correlate poorly human judgment . propose bleurt , learn evaluation metric base bert model human judgment thousand possibly biased training example . key aspect approach novel pre - training scheme use million synthetic example help model generalize . bleurt provide state - ofthe - art result year wmt metrics share task webnlg competition dataset . contrast vanilla bert - base approach , yield superior result training data scarce - - distribution .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Explicit Semantic Decomposition for Definition Generation,"Definition generation, which aims to automatically generate dictionary definitions for words, has recently been proposed to assist the construction of dictionaries and help people understand unfamiliar texts. However, previous works hardly consider explicitly modeling the ""components"" of definitions, leading to under-specific generation results. In this paper, we propose ESD, namely Explicit Semantic Decomposition for definition generation, which explicitly decomposes meaning of words into semantic components, and models them with discrete latent variables for definition generation. Experimental results show that ESD achieves substantial improvements on WordNet and Oxford benchmarks over strong previous baselines.","Explicit Semantic Decomposition for Definition Generation Definition generation, which aims to automatically generate dictionary definitions for words, has recently been proposed to assist the construction of dictionaries and help people understand unfamiliar texts. However, previous works hardly consider explicitly modeling the ""components"" of definitions, leading to under-specific generation results. In this paper, we propose ESD, namely Explicit Semantic Decomposition for definition generation, which explicitly decomposes meaning of words into semantic components, and models them with discrete latent variables for definition generation. Experimental results show that ESD achieves substantial improvements on WordNet and Oxford benchmarks over strong previous baselines.","explicit semantic decomposition definition generation definition generation , aim automatically generate dictionary definition word , recently propose assist construction dictionary help people understand unfamiliar text . , previous work hardly consider explicitly model "" component "" definition , lead - specific generation result . paper , propose esd , explicit semantic decomposition definition generation , explicitly decompose meaning word semantic component , model discrete latent variable definition generation . experimental result esd achieve substantial improvement wordnet oxford benchmark strong previous baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Distilling Knowledge Learned in BERT for Text Generation,"Large-scale pre-trained language model such as BERT has achieved great success in language understanding tasks. However, it remains an open question how to utilize BERT for language generation. In this paper, we present a novel approach, Conditional Masked Language Modeling (C-MLM), to enable the finetuning of BERT on target generation tasks. The finetuned BERT (teacher) is exploited as extra supervision to improve conventional Seq2Seq models (student) for better text generation performance. By leveraging BERT's idiosyncratic bidirectional nature, distilling knowledge learned in BERT can encourage auto-regressive Seq2Seq models to plan ahead, imposing global sequence-level supervision for coherent text generation. Experiments show that the proposed approach significantly outperforms strong Transformer baselines on multiple language generation tasks such as machine translation and text summarization. Our proposed model also achieves new state of the art on IWSLT German-English and English-Vietnamese MT datasets. 1","Distilling Knowledge Learned in BERT for Text Generation Large-scale pre-trained language model such as BERT has achieved great success in language understanding tasks. However, it remains an open question how to utilize BERT for language generation. In this paper, we present a novel approach, Conditional Masked Language Modeling (C-MLM), to enable the finetuning of BERT on target generation tasks. The finetuned BERT (teacher) is exploited as extra supervision to improve conventional Seq2Seq models (student) for better text generation performance. By leveraging BERT's idiosyncratic bidirectional nature, distilling knowledge learned in BERT can encourage auto-regressive Seq2Seq models to plan ahead, imposing global sequence-level supervision for coherent text generation. Experiments show that the proposed approach significantly outperforms strong Transformer baselines on multiple language generation tasks such as machine translation and text summarization. Our proposed model also achieves new state of the art on IWSLT German-English and English-Vietnamese MT datasets. 1","distil knowledge learn bert text generation large - scale pre - train language model bert achieve great success language understanding task . , remain open question utilize bert language generation . paper , present novel approach , conditional masked language modeling ( c - mlm ) , enable finetuning bert target generation task . finetune bert ( teacher ) exploit extra supervision improve conventional seq2seq model ( student ) well text generation performance . leverage bert idiosyncratic bidirectional nature , distil knowledge learn bert encourage auto - regressive seq2seq model plan ahead , impose global sequence - level supervision coherent text generation . experiment propose approach significantly outperform strong transformer baseline multiple language generation task machine translation text summarization . propose model achieve new state art iwslt german - english english - vietnamese mt dataset . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Expertise Style Transfer: A New Task Towards Better Communication between Experts and Laymen,"The curse of knowledge can impede communication between experts and laymen. We propose a new task of expertise style transfer and contribute a manually annotated dataset with the goal of alleviating such cognitive biases. Solving this task not only simplifies the professional language, but also improves the accuracy and expertise level of laymen descriptions using simple words. This is a challenging task, unaddressed in previous work, as it requires the models to have expert intelligence in order to modify text with a deep understanding of domain knowledge and structures. We establish the benchmark performance of five stateof-the-art models for style transfer and text simplification. The results demonstrate a significant gap between machine and human performance. We also discuss the challenges of automatic evaluation, to provide insights into future research directions. The dataset is publicly available at https://srhthu.github. io/expertise-style-transfer/. Many cause dyspnea, pleuritic chest pain, or both. The most common symptoms, regardless of the type of fluid in the pleural space or its cause, are shortness of breath and chest pain. About 1/1000 hypertensive patients has a pheochromocytoma. The incidence of Pheochromocytomas may be quite small. The lesion slowly enlarges, often ulcerates, and spread to other skin areas. Lesions heal slowly, with scarring. The sores slowly enlarge and spread to nearby tissue, causing further damage. Sores heal slowly and may result in permanent scarring. In patients with papilledema, vision is usually not affected initially, but seconds-long graying out of vision, flickering, or blurred or double vision may occur. At first, papilledema may be present without affecting vision. Fleeting vision changes (blurred vision, double vision, flickering, or complete loss of vision) typically lasting seconds are characteristic of papilledema.","Expertise Style Transfer: A New Task Towards Better Communication between Experts and Laymen The curse of knowledge can impede communication between experts and laymen. We propose a new task of expertise style transfer and contribute a manually annotated dataset with the goal of alleviating such cognitive biases. Solving this task not only simplifies the professional language, but also improves the accuracy and expertise level of laymen descriptions using simple words. This is a challenging task, unaddressed in previous work, as it requires the models to have expert intelligence in order to modify text with a deep understanding of domain knowledge and structures. We establish the benchmark performance of five stateof-the-art models for style transfer and text simplification. The results demonstrate a significant gap between machine and human performance. We also discuss the challenges of automatic evaluation, to provide insights into future research directions. The dataset is publicly available at https://srhthu.github. io/expertise-style-transfer/. Many cause dyspnea, pleuritic chest pain, or both. The most common symptoms, regardless of the type of fluid in the pleural space or its cause, are shortness of breath and chest pain. About 1/1000 hypertensive patients has a pheochromocytoma. The incidence of Pheochromocytomas may be quite small. The lesion slowly enlarges, often ulcerates, and spread to other skin areas. Lesions heal slowly, with scarring. The sores slowly enlarge and spread to nearby tissue, causing further damage. Sores heal slowly and may result in permanent scarring. In patients with papilledema, vision is usually not affected initially, but seconds-long graying out of vision, flickering, or blurred or double vision may occur. At first, papilledema may be present without affecting vision. Fleeting vision changes (blurred vision, double vision, flickering, or complete loss of vision) typically lasting seconds are characteristic of papilledema.","expertise style transfer : new task well communication expert layman curse knowledge impede communication expert layman . propose new task expertise style transfer contribute manually annotate dataset goal alleviate cognitive bias . solve task simplify professional language , improve accuracy expertise level layman description simple word . challenging task , unaddressed previous work , require model expert intelligence order modify text deep understanding domain knowledge structure . establish benchmark performance stateof - - art model style transfer text simplification . result demonstrate significant gap machine human performance . discuss challenge automatic evaluation , provide insight future research direction . dataset publicly available https://srhthu.github . io / expertise - style - transfer/. cause dyspnea , pleuritic chest pain , . common symptom , regardless type fluid pleural space cause , shortness breath chest pain . 1/1000 hypertensive patient pheochromocytoma . incidence pheochromocytoma small . lesion slowly enlarge , ulcerate , spread skin area . lesion heal slowly , scarring . sore slowly enlarge spread nearby tissue , cause damage . sore heal slowly result permanent scarring . patient papilledema , vision usually affect initially , second - long gray vision , flickering , blurred double vision occur . , papilledema present affect vision . fleet vision change ( blurred vision , double vision , flickering , complete loss vision ) typically last second characteristic papilledema .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Generation,Simple and Effective Retrieve-Edit-Rerank Text Generation,"Retrieve-and-edit seq2seq methods typically retrieve an output from the training set and learn a model to edit it to produce the final output. We propose to extend this framework with a simple and effective post-generation ranking approach. Our framework (i) retrieves several potentially relevant outputs for each input, (ii) edits each candidate independently, and (iii) re-ranks the edited candidates to select the final output. We use a standard editing model with simple task-specific reranking approaches, and we show empirically that this approach outperforms existing, significantly more complex methodologies. Experiments on two machine translation (MT) datasets show new state-of-art results. We also achieve near state-of-art performance on the Gigaword summarization dataset, where our analyses show that there is significant room for performance improvement with better candidate output selection in future work.","Simple and Effective Retrieve-Edit-Rerank Text Generation Retrieve-and-edit seq2seq methods typically retrieve an output from the training set and learn a model to edit it to produce the final output. We propose to extend this framework with a simple and effective post-generation ranking approach. Our framework (i) retrieves several potentially relevant outputs for each input, (ii) edits each candidate independently, and (iii) re-ranks the edited candidates to select the final output. We use a standard editing model with simple task-specific reranking approaches, and we show empirically that this approach outperforms existing, significantly more complex methodologies. Experiments on two machine translation (MT) datasets show new state-of-art results. We also achieve near state-of-art performance on the Gigaword summarization dataset, where our analyses show that there is significant room for performance improvement with better candidate output selection in future work.","simple effective retrieve - edit - rerank text generation retrieve - - edit seq2seq method typically retrieve output training set learn model edit produce final output . propose extend framework simple effective post - generation ranking approach . framework ( ) retrieve potentially relevant output input , ( ii ) edit candidate independently , ( iii ) - rank edit candidate select final output . use standard editing model simple task - specific reranking approach , empirically approach outperform exist , significantly complex methodology . experiment machine translation ( mt ) dataset new state - - art result . achieve near state - - art performance gigaword summarization dataset , analysis significant room performance improvement well candidate output selection future work .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Improving Image Captioning with Better Use of Caption,"Image captioning is a multimodal problem that has drawn extensive attention in both the natural language processing and computer vision community. In this paper, we present a novel image captioning architecture to better explore semantics available in captions and leverage that to enhance both image representation and caption generation. Our models first construct caption-guided visual relationship graphs that introduce beneficial inductive bias using weakly supervised multi-instance learning. The representation is then enhanced with neighbouring and contextual nodes with their textual and visual features. During generation, the model further incorporates visual relationships using multi-task learning for jointly predicting word and object/predicate tag sequences. We perform extensive experiments on the MSCOCO dataset, showing that the proposed framework significantly outperforms the baselines, resulting in the state-of-the-art performance under a wide range of evaluation metrics. The code of our paper has been made publicly available. 1","Improving Image Captioning with Better Use of Caption Image captioning is a multimodal problem that has drawn extensive attention in both the natural language processing and computer vision community. In this paper, we present a novel image captioning architecture to better explore semantics available in captions and leverage that to enhance both image representation and caption generation. Our models first construct caption-guided visual relationship graphs that introduce beneficial inductive bias using weakly supervised multi-instance learning. The representation is then enhanced with neighbouring and contextual nodes with their textual and visual features. During generation, the model further incorporates visual relationships using multi-task learning for jointly predicting word and object/predicate tag sequences. We perform extensive experiments on the MSCOCO dataset, showing that the proposed framework significantly outperforms the baselines, resulting in the state-of-the-art performance under a wide range of evaluation metrics. The code of our paper has been made publicly available. 1","improve image captioning well use caption image captioning multimodal problem draw extensive attention natural language processing computer vision community . paper , present novel image captioning architecture well explore semantic available caption leverage enhance image representation caption generation . model construct caption - guide visual relationship graph introduce beneficial inductive bias weakly supervise multi - instance learning . representation enhance neighbouring contextual node textual visual feature . generation , model incorporate visual relationship multi - task learning jointly predict word object / predicate tag sequence . perform extensive experiment mscoco dataset , show propose framework significantly outperform baseline , result state - - - art performance wide range evaluation metric . code paper publicly available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 5, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 15, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Generation,Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs,"One of the most crucial challenges in question answering (QA) is the scarcity of labeled data, since it is costly to obtain question-answer (QA) pairs for a target text domain with human annotation. An alternative approach to tackle the problem is to use automatically generated QA pairs from either the problem context or from large amount of unstructured texts (e.g. Wikipedia). In this work, we propose a hierarchical conditional variational autoencoder (HCVAE) for generating QA pairs given unstructured texts as contexts, while maximizing the mutual information between generated QA pairs to ensure their consistency. We validate our Information Maximizing Hierarchical Conditional Variational AutoEncoder (Info-HCVAE) on several benchmark datasets by evaluating the performance of the QA model (BERT-base) using only the generated QA pairs (QA-based evaluation) or by using both the generated and human-labeled pairs (semisupervised learning) for training, against stateof-the-art baseline models. The results show that our model obtains impressive performance gains over all baselines on both tasks, using only a fraction of data for training. 1 * Equal contribution 1 The generated QA pairs and the code can be found at https://github.com/seanie12/Info-HCVAE","Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs One of the most crucial challenges in question answering (QA) is the scarcity of labeled data, since it is costly to obtain question-answer (QA) pairs for a target text domain with human annotation. An alternative approach to tackle the problem is to use automatically generated QA pairs from either the problem context or from large amount of unstructured texts (e.g. Wikipedia). In this work, we propose a hierarchical conditional variational autoencoder (HCVAE) for generating QA pairs given unstructured texts as contexts, while maximizing the mutual information between generated QA pairs to ensure their consistency. We validate our Information Maximizing Hierarchical Conditional Variational AutoEncoder (Info-HCVAE) on several benchmark datasets by evaluating the performance of the QA model (BERT-base) using only the generated QA pairs (QA-based evaluation) or by using both the generated and human-labeled pairs (semisupervised learning) for training, against stateof-the-art baseline models. The results show that our model obtains impressive performance gains over all baselines on both tasks, using only a fraction of data for training. 1 * Equal contribution 1 The generated QA pairs and the code can be found at https://github.com/seanie12/Info-HCVAE","generate diverse consistent qa pair context information - maximize hierarchical conditional vae crucial challenge question answering ( qa ) scarcity label datum , costly obtain question - answer ( qa ) pair target text domain human annotation . alternative approach tackle problem use automatically generate qa pair problem context large unstructured text ( e.g. wikipedia ) . work , propose hierarchical conditional variational autoencoder ( hcvae ) generate qa pair give unstructured text context , maximize mutual information generate qa pair ensure consistency . validate information maximizing hierarchical conditional variational autoencoder ( info - hcvae ) benchmark dataset evaluate performance qa model ( bert - base ) generate qa pair ( qa - base evaluation ) generate human - label pair ( semisupervised learning ) training , stateof - - art baseline model . result model obtain impressive performance gain baseline task , fraction datum training . 1 * equal contribution 1 generate qa pair code find https://github.com/seanie12/info-hcva","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 13, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 17, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Generation,GPT-too: A Language-Model-First Approach for AMR-to-Text Generation,"Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequenceto-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these models outperform all previous techniques on the English LDC2017T10 dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.","GPT-too: A Language-Model-First Approach for AMR-to-Text Generation Meaning Representations (AMRs) are broad-coverage sentence-level semantic graphs. Existing approaches to generating text from AMR have focused on training sequenceto-sequence or graph-to-sequence models on AMR annotated data only. In this paper, we propose an alternative approach that combines a strong pre-trained language model with cycle consistency-based re-scoring. Despite the simplicity of the approach, our experimental results show these models outperform all previous techniques on the English LDC2017T10 dataset, including the recent use of transformer architectures. In addition to the standard evaluation metrics, we provide human evaluation experiments that further substantiate the strength of our approach.","gpt - : language - model - approach amr - - text generation meaning representation ( amrs ) broad - coverage sentence - level semantic graph . exist approach generate text amr focus train sequenceto - sequence graph - - sequence model amr annotate datum . paper , propose alternative approach combine strong pre - train language model cycle consistency - base - scoring . despite simplicity approach , experimental result model outperform previous technique english ldc2017t10 dataset , include recent use transformer architecture . addition standard evaluation metric , provide human evaluation experiment substantiate strength approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Unsupervised Paraphrasing by Simulated Annealing,"We propose UPSA, a novel approach that accomplishes Unsupervised Paraphrasing by Simulated Annealing. We model paraphrase generation as an optimization problem and propose a sophisticated objective function, involving semantic similarity, expression diversity, and language fluency of paraphrases. UPSA searches the sentence space towards this objective by performing a sequence of local edits. We evaluate our approach on various datasets, namely, Quora, Wikianswers, MSCOCO, and Twitter. Extensive results show that UPSA achieves the state-of-the-art performance compared with previous unsupervised methods in terms of both automatic and human evaluations. Further, our approach outperforms most existing domain-adapted supervised models, showing the generalizability of UPSA. 1","Unsupervised Paraphrasing by Simulated Annealing We propose UPSA, a novel approach that accomplishes Unsupervised Paraphrasing by Simulated Annealing. We model paraphrase generation as an optimization problem and propose a sophisticated objective function, involving semantic similarity, expression diversity, and language fluency of paraphrases. UPSA searches the sentence space towards this objective by performing a sequence of local edits. We evaluate our approach on various datasets, namely, Quora, Wikianswers, MSCOCO, and Twitter. Extensive results show that UPSA achieves the state-of-the-art performance compared with previous unsupervised methods in terms of both automatic and human evaluations. Further, our approach outperforms most existing domain-adapted supervised models, showing the generalizability of UPSA. 1","unsupervised paraphrasing simulated annealing propose upsa , novel approach accomplish unsupervised paraphrasing simulated annealing . model paraphrase generation optimization problem propose sophisticated objective function , involve semantic similarity , expression diversity , language fluency paraphrase . upsa search sentence space objective perform sequence local edit . evaluate approach dataset , , quora , wikianswers , mscoco , twitter . extensive result upsa achieve state - - - art performance compare previous unsupervised method term automatic human evaluation . , approach outperform exist domain - adapt supervise model , show generalizability upsa . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Heterogeneous Graph Transformer for Graph-to-Sequence Learning,"The graph-to-sequence (Graph2Seq) learning aims to transduce graph-structured representations to word sequences for text generation. Recent studies propose various models to encode graph structure. However, most previous works ignore the indirect relations between distance nodes, or treat indirect relations and direct relations in the same way. In this paper, we propose the Heterogeneous Graph Transformer to independently model the different relations in the individual subgraphs of the original graph, including direct relations, indirect relations and multiple possible relations between nodes. Experimental results show that our model strongly outperforms the state of the art on all four standard benchmarks of AMRto-text generation and syntax-based neural machine translation.","Heterogeneous Graph Transformer for Graph-to-Sequence Learning The graph-to-sequence (Graph2Seq) learning aims to transduce graph-structured representations to word sequences for text generation. Recent studies propose various models to encode graph structure. However, most previous works ignore the indirect relations between distance nodes, or treat indirect relations and direct relations in the same way. In this paper, we propose the Heterogeneous Graph Transformer to independently model the different relations in the individual subgraphs of the original graph, including direct relations, indirect relations and multiple possible relations between nodes. Experimental results show that our model strongly outperforms the state of the art on all four standard benchmarks of AMRto-text generation and syntax-based neural machine translation.","heterogeneous graph transformer graph - - sequence learning graph - - sequence ( graph2seq ) learning aim transduce graph - structure representation word sequence text generation . recent study propose model encode graph structure . , previous work ignore indirect relation distance node , treat indirect relation direct relation way . paper , propose heterogeneous graph transformer independently model different relation individual subgraph original graph , include direct relation , indirect relation multiple possible relation node . experimental result model strongly outperform state art standard benchmark amrto - text generation syntax - base neural machine translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Generation,True
Generation,One Size Does Not Fit All: Generating and Evaluating Variable Number of Keyphrases,"Different texts shall by nature correspond to different number of keyphrases. This desideratum is largely missing from existing neural keyphrase generation models. In this study, we address this problem from both modeling and evaluation perspectives. We first propose a recurrent generative model that generates multiple keyphrases as delimiter-separated sequences. Generation diversity is further enhanced with two novel techniques by manipulating decoder hidden states. In contrast to previous approaches, our model is capable of generating diverse keyphrases and controlling number of outputs. We further propose two evaluation metrics tailored towards the variable-number generation. We also introduce a new dataset (ST A C KEX) that expands beyond the only existing genre (i.e., academic writing) in keyphrase generation tasks. With both previous and new evaluation metrics, our model outperforms strong baselines on all datasets.","One Size Does Not Fit All: Generating and Evaluating Variable Number of Keyphrases Different texts shall by nature correspond to different number of keyphrases. This desideratum is largely missing from existing neural keyphrase generation models. In this study, we address this problem from both modeling and evaluation perspectives. We first propose a recurrent generative model that generates multiple keyphrases as delimiter-separated sequences. Generation diversity is further enhanced with two novel techniques by manipulating decoder hidden states. In contrast to previous approaches, our model is capable of generating diverse keyphrases and controlling number of outputs. We further propose two evaluation metrics tailored towards the variable-number generation. We also introduce a new dataset (ST A C KEX) that expands beyond the only existing genre (i.e., academic writing) in keyphrase generation tasks. With both previous and new evaluation metrics, our model outperforms strong baselines on all datasets.","size fit : generate evaluate variable number keyphrase different text shall nature correspond different number keyphrase . desideratum largely miss exist neural keyphrase generation model . study , address problem modeling evaluation perspective . propose recurrent generative model generate multiple keyphrase delimiter - separate sequence . generation diversity enhance novel technique manipulate decoder hide state . contrast previous approach , model capable generate diverse keyphrase control number output . propose evaluation metric tailor variable - number generation . introduce new dataset ( st c kex ) expand exist genre ( i.e. , academic writing ) keyphrase generation task . previous new evaluation metric , model outperform strong baseline dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 8, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Cross-modal Language Generation using Pivot Stabilization for Web-scale Language Coverage,"Cross-modal language generation tasks such as image captioning are directly hurt in their ability to support non-English languages by the trend of data-hungry models combined with the lack of non-English annotations. We investigate potential solutions for combining existing language-generation annotations in English with translation capabilities in order to create solutions at web-scale in both domain and language coverage. We describe an approach called Pivot-Language Generation Stabilization (PLuGS), which leverages directly at training time both existing English annotations (gold data) as well as their machinetranslated versions (silver data); at run-time, it generates first an English caption and then a corresponding target-language caption. We show that PLuGS models outperform other candidate solutions in evaluations performed over 5 different target languages, under a largedomain testset using images from the Open Images dataset. Furthermore, we find an interesting effect where the English captions generated by the PLuGS models are better than the captions generated by the original, monolingual English model.","Cross-modal Language Generation using Pivot Stabilization for Web-scale Language Coverage Cross-modal language generation tasks such as image captioning are directly hurt in their ability to support non-English languages by the trend of data-hungry models combined with the lack of non-English annotations. We investigate potential solutions for combining existing language-generation annotations in English with translation capabilities in order to create solutions at web-scale in both domain and language coverage. We describe an approach called Pivot-Language Generation Stabilization (PLuGS), which leverages directly at training time both existing English annotations (gold data) as well as their machinetranslated versions (silver data); at run-time, it generates first an English caption and then a corresponding target-language caption. We show that PLuGS models outperform other candidate solutions in evaluations performed over 5 different target languages, under a largedomain testset using images from the Open Images dataset. Furthermore, we find an interesting effect where the English captions generated by the PLuGS models are better than the captions generated by the original, monolingual English model.","cross - modal language generation pivot stabilization web - scale language coverage cross - modal language generation task image captioning directly hurt ability support non - english language trend data - hungry model combine lack non - english annotation . investigate potential solution combine exist language - generation annotation english translation capability order create solution web - scale domain language coverage . describe approach call pivot - language generation stabilization ( plugs ) , leverage directly training time existing english annotation ( gold datum ) machinetranslated version ( silver datum ) ; run - time , generate english caption corresponding target - language caption . plugs model outperform candidate solution evaluation perform 5 different target language , largedomain testset image open images dataset . furthermore , find interesting effect english caption generate plugs model well caption generate original , monolingual english model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 8, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Probabilistically Masked Language Model Capable of Autoregressive Generation in Arbitrary Word Order,"Masked language model and autoregressive language model are two types of language models. While pretrained masked language models such as BERT (Devlin et al., 2019)   overwhelm the line of natural language understanding (NLU) tasks, autoregressive language models such as GPT (Radford et al.,  2018)  are especially capable in natural language generation (NLG). In this paper, we propose a probabilistic masking scheme for the masked language model, which we call probabilistically masked language model (PMLM). We implement a specific PMLM with a uniform prior distribution on the masking ratio named u-PMLM. We prove that u-PMLM is equivalent to an autoregressive permutated language model. One main advantage of the model is that it supports text generation in arbitrary order with surprisingly good quality, which could potentially enable new applications over traditional unidirectional generation. Besides, the pretrained u-PMLM also outperforms BERT on a set of downstream NLU tasks.","Probabilistically Masked Language Model Capable of Autoregressive Generation in Arbitrary Word Order Masked language model and autoregressive language model are two types of language models. While pretrained masked language models such as BERT (Devlin et al., 2019)   overwhelm the line of natural language understanding (NLU) tasks, autoregressive language models such as GPT (Radford et al.,  2018)  are especially capable in natural language generation (NLG). In this paper, we propose a probabilistic masking scheme for the masked language model, which we call probabilistically masked language model (PMLM). We implement a specific PMLM with a uniform prior distribution on the masking ratio named u-PMLM. We prove that u-PMLM is equivalent to an autoregressive permutated language model. One main advantage of the model is that it supports text generation in arbitrary order with surprisingly good quality, which could potentially enable new applications over traditional unidirectional generation. Besides, the pretrained u-PMLM also outperforms BERT on a set of downstream NLU tasks.","probabilistically mask language model capable autoregressive generation arbitrary word order masked language model autoregressive language model type language model . pretrained mask language model bert ( devlin et al . , 2019 )    overwhelm line natural language understanding ( nlu ) task , autoregressive language model gpt ( radford et al . ,   2018 )   especially capable natural language generation ( nlg ) . paper , propose probabilistic masking scheme mask language model , probabilistically mask language model ( pmlm ) . implement specific pmlm uniform prior distribution masking ratio name u - pmlm . prove u - pmlm equivalent autoregressive permutated language model . main advantage model support text generation arbitrary order surprisingly good quality , potentially enable new application traditional unidirectional generation . , pretrained u - pmlm outperform bert set downstream nlu task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Generation,True
Generation,ESPRIT: Explaining Solutions to Physical Reasoning Tasks,"Neural networks lack the ability to reason about qualitative physics and so cannot generalize to scenarios and tasks unseen during training. We propose ESPRIT, a framework for commonsense reasoning about qualitative physics in natural language that generates interpretable descriptions of physical events. We use a two-step approach of first identifying the pivotal physical events in an environment and then generating natural language descriptions of those events using a data-to-text approach. Our framework learns to generate explanations of how the physical simulation will causally evolve so that an agent or a human can easily reason about a solution using those interpretable descriptions. Human evaluations indicate that ESPRIT produces crucial fine-grained details and has high coverage of physical concepts compared to even human annotations. Dataset, code and documentation are available at https://github.com/ salesforce/esprit.","ESPRIT: Explaining Solutions to Physical Reasoning Tasks Neural networks lack the ability to reason about qualitative physics and so cannot generalize to scenarios and tasks unseen during training. We propose ESPRIT, a framework for commonsense reasoning about qualitative physics in natural language that generates interpretable descriptions of physical events. We use a two-step approach of first identifying the pivotal physical events in an environment and then generating natural language descriptions of those events using a data-to-text approach. Our framework learns to generate explanations of how the physical simulation will causally evolve so that an agent or a human can easily reason about a solution using those interpretable descriptions. Human evaluations indicate that ESPRIT produces crucial fine-grained details and has high coverage of physical concepts compared to even human annotations. Dataset, code and documentation are available at https://github.com/ salesforce/esprit.","esprit : explain solution physical reasoning task neural network lack ability reason qualitative physics generalize scenario task unseen training . propose esprit , framework commonsense reasoning qualitative physic natural language generate interpretable description physical event . use - step approach identify pivotal physical event environment generate natural language description event data - - text approach . framework learn generate explanation physical simulation causally evolve agent human easily reason solution interpretable description . human evaluation indicate esprit produce crucial fine - grained detail high coverage physical concept compare human annotation . dataset , code documentation available https://github.com/ salesforce / esprit .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Generation,Learning Implicit Text Generation via Feature Matching,"Generative feature matching network (GFMN) is an approach for training implicit generative models for images by performing moment matching on features from pre-trained neural networks. In this paper, we present new GFMN formulations that are effective for sequential data. Our experimental results show the effectiveness of the proposed method, Se-qGFMN, for three distinct generation tasks in English: unconditional text generation, classconditional text generation, and unsupervised text style transfer. SeqGFMN is stable to train and outperforms various adversarial approaches for text generation and text style transfer.","Learning Implicit Text Generation via Feature Matching Generative feature matching network (GFMN) is an approach for training implicit generative models for images by performing moment matching on features from pre-trained neural networks. In this paper, we present new GFMN formulations that are effective for sequential data. Our experimental results show the effectiveness of the proposed method, Se-qGFMN, for three distinct generation tasks in English: unconditional text generation, classconditional text generation, and unsupervised text style transfer. SeqGFMN is stable to train and outperforms various adversarial approaches for text generation and text style transfer.","learn implicit text generation feature matching generative feature matching network ( gfmn ) approach train implicit generative model image perform moment matching feature pre - train neural network . paper , present new gfmn formulation effective sequential datum . experimental result effectiveness propose method , se - qgfmn , distinct generation task english : unconditional text generation , classconditional text generation , unsupervised text style transfer . seqgfmn stable train outperform adversarial approach text generation text style transfer .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 15, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,A Study of Non-autoregressive Model for Sequence Generation,Non-autoregressive (NAR) models generate * Equal contribution. â€  Corresponding author of a target token on source tokens and thus eases the training of NAR models.,A Study of Non-autoregressive Model for Sequence Generation Non-autoregressive (NAR) models generate * Equal contribution. â€  Corresponding author of a target token on source tokens and thus eases the training of NAR models.,study non - autoregressive model sequence generation non - autoregressive ( nar ) model generate * equal contribution . â€  correspond author target token source token ease training nar model .,"{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Improved Natural Language Generation via Loss Truncation,"Neural language models are usually trained to match the distributional properties of largescale corpora by minimizing the log loss. While straightforward to optimize, this approach forces the model to reproduce all variations in the dataset, including noisy and invalid references (e.g., misannotations and hallucinated facts). Even a small fraction of noisy data can degrade the performance of log loss. As an alternative, prior work has shown that minimizing the distinguishability of generated samples is a principled and robust loss that can handle invalid references. However, distinguishability has not been used in practice due to challenges in optimization and estimation. We propose loss truncation: a simple and scalable procedure which adaptively removes high log loss examples as a way to optimize for distinguishability. Empirically, we demonstrate that loss truncation outperforms existing baselines on distinguishability on a summarization task. Furthermore, we show that samples generated by the loss truncation model have factual accuracy ratings that exceed those of baselines and match human references.","Improved Natural Language Generation via Loss Truncation Neural language models are usually trained to match the distributional properties of largescale corpora by minimizing the log loss. While straightforward to optimize, this approach forces the model to reproduce all variations in the dataset, including noisy and invalid references (e.g., misannotations and hallucinated facts). Even a small fraction of noisy data can degrade the performance of log loss. As an alternative, prior work has shown that minimizing the distinguishability of generated samples is a principled and robust loss that can handle invalid references. However, distinguishability has not been used in practice due to challenges in optimization and estimation. We propose loss truncation: a simple and scalable procedure which adaptively removes high log loss examples as a way to optimize for distinguishability. Empirically, we demonstrate that loss truncation outperforms existing baselines on distinguishability on a summarization task. Furthermore, we show that samples generated by the loss truncation model have factual accuracy ratings that exceed those of baselines and match human references.","improved natural language generation loss truncation neural language model usually train match distributional property largescale corpora minimize log loss . straightforward optimize , approach force model reproduce variation dataset , include noisy invalid reference ( e.g. , misannotation hallucinate fact ) . small fraction noisy datum degrade performance log loss . alternative , prior work show minimize distinguishability generate sample principled robust loss handle invalid reference . , distinguishability practice challenge optimization estimation . propose loss truncation : simple scalable procedure adaptively remove high log loss example way optimize distinguishability . empirically , demonstrate loss truncation outperform exist baseline distinguishability summarization task . furthermore , sample generate loss truncation model factual accuracy rating exceed baseline match human reference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Automatic Poetry Generation from Prosaic Text,"In the last few years, a number of successful approaches have emerged that are able to adequately model various aspects of natural language. In particular, language models based on neural networks have improved the state of the art with regard to predictive language modeling, while topic models are successful at capturing clear-cut, semantic dimensions. In this paper, we explore how these approaches can be adapted and combined to model the linguistic and literary aspects needed for poetry generation. The system is exclusively trained on standard, non-poetic text, and its output is constrained in order to confer a poetic character to the generated verse. The framework is applied to the generation of poems in both English and French, and is equally evaluated for both languages. Even though it only uses standard, non-poetic text as input, the system yields state of the art results for poetry generation.","Automatic Poetry Generation from Prosaic Text In the last few years, a number of successful approaches have emerged that are able to adequately model various aspects of natural language. In particular, language models based on neural networks have improved the state of the art with regard to predictive language modeling, while topic models are successful at capturing clear-cut, semantic dimensions. In this paper, we explore how these approaches can be adapted and combined to model the linguistic and literary aspects needed for poetry generation. The system is exclusively trained on standard, non-poetic text, and its output is constrained in order to confer a poetic character to the generated verse. The framework is applied to the generation of poems in both English and French, and is equally evaluated for both languages. Even though it only uses standard, non-poetic text as input, the system yields state of the art results for poetry generation.","automatic poetry generation prosaic text year , number successful approach emerge able adequately model aspect natural language . particular , language model base neural network improve state art regard predictive language modeling , topic model successful capture clear - cut , semantic dimension . paper , explore approach adapt combine model linguistic literary aspect need poetry generation . system exclusively train standard , non - poetic text , output constrain order confer poetic character generate verse . framework apply generation poem english french , equally evaluate language . use standard , non - poetic text input , system yield state art result poetry generation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Learning to Update Natural Language Comments Based on Code Changes,"We formulate the novel task of automatically updating an existing natural language comment based on changes in the body of code it accompanies. We propose an approach that learns to correlate changes across two distinct language representations, to generate a sequence of edits that are applied to the existing comment to reflect the source code modifications. We train and evaluate our model using a dataset that we collected from commit histories of open-source software projects, with each example consisting of a concurrent update to a method and its corresponding comment. We compare our approach against multiple baselines using both automatic metrics and human evaluation. Results reflect the challenge of this task and that our model outperforms baselines with respect to making edits.","Learning to Update Natural Language Comments Based on Code Changes We formulate the novel task of automatically updating an existing natural language comment based on changes in the body of code it accompanies. We propose an approach that learns to correlate changes across two distinct language representations, to generate a sequence of edits that are applied to the existing comment to reflect the source code modifications. We train and evaluate our model using a dataset that we collected from commit histories of open-source software projects, with each example consisting of a concurrent update to a method and its corresponding comment. We compare our approach against multiple baselines using both automatic metrics and human evaluation. Results reflect the challenge of this task and that our model outperforms baselines with respect to making edits.","learn update natural language comment base code change formulate novel task automatically update exist natural language comment base change body code accompany . propose approach learn correlate change distinct language representation , generate sequence edit apply exist comment reflect source code modification . train evaluate model dataset collect commit history open - source software project , example consist concurrent update method corresponding comment . compare approach multiple baseline automatic metric human evaluation . result reflect challenge task model outperform baseline respect make edit .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,"Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data","A number of researchers have recently questioned the necessity of increasingly complex neural network (NN) architectures. In particular, several recent papers have shown that simpler, properly tuned models are at least competitive across several NLP tasks. In this work, we show that this is also the case for text generation from structured and unstructured data. We consider neural tableto-text generation and neural question generation (NQG) tasks for text generation from structured and unstructured data, respectively. Table - to-text generation aims to generate a description based on a given table, and NQG is the task of generating a question from a given passage where the generated question can be answered by a certain sub-span of the passage using NN models. Experimental results demonstrate that a basic attentionbased seq2seq model trained with the exponential moving average technique achieves the state of the art in both tasks. Code is available at https://github.com/h-shahidi/ 2birds-gen.","Two Birds, One Stone: A Simple, Unified Model for Text Generation from Structured and Unstructured Data A number of researchers have recently questioned the necessity of increasingly complex neural network (NN) architectures. In particular, several recent papers have shown that simpler, properly tuned models are at least competitive across several NLP tasks. In this work, we show that this is also the case for text generation from structured and unstructured data. We consider neural tableto-text generation and neural question generation (NQG) tasks for text generation from structured and unstructured data, respectively. Table - to-text generation aims to generate a description based on a given table, and NQG is the task of generating a question from a given passage where the generated question can be answered by a certain sub-span of the passage using NN models. Experimental results demonstrate that a basic attentionbased seq2seq model trained with the exponential moving average technique achieves the state of the art in both tasks. Code is available at https://github.com/h-shahidi/ 2birds-gen.","birds , stone : simple , unify model text generation structured unstructured datum number researcher recently question necessity increasingly complex neural network ( nn ) architecture . particular , recent paper show simple , properly tune model competitive nlp task . work , case text generation structured unstructured datum . consider neural tableto - text generation neural question generation ( nqg ) task text generation structured unstructured datum , respectively . table - - text generation aim generate description base give table , nqg task generate question give passage generate question answer certain sub - span passage nn model . experimental result demonstrate basic attentionbased seq2seq model train exponential move average technique achieve state art task . code available https://github.com/h-shahidi/ 2bird - gen .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 20, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 6, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,INSET: Sentence Infilling with INter-SEntential Transformer,"Missing sentence generation (or sentence infilling) fosters a wide range of applications in natural language generation, such as document auto-completion and meeting note expansion. This task asks the model to generate intermediate missing sentences that can syntactically and semantically bridge the surrounding context. Solving the sentence infilling task requires techniques in natural language processing ranging from understanding to discourselevel planning to generation. In this paper, we propose a framework to decouple the challenge and address these three aspects respectively, leveraging the power of existing largescale pre-trained models such as BERT and GPT-2. We empirically demonstrate the effectiveness of our model in learning a sentence representation for generation and further generating a missing sentence that fits the context.","INSET: Sentence Infilling with INter-SEntential Transformer Missing sentence generation (or sentence infilling) fosters a wide range of applications in natural language generation, such as document auto-completion and meeting note expansion. This task asks the model to generate intermediate missing sentences that can syntactically and semantically bridge the surrounding context. Solving the sentence infilling task requires techniques in natural language processing ranging from understanding to discourselevel planning to generation. In this paper, we propose a framework to decouple the challenge and address these three aspects respectively, leveraging the power of existing largescale pre-trained models such as BERT and GPT-2. We empirically demonstrate the effectiveness of our model in learning a sentence representation for generation and further generating a missing sentence that fits the context.","inset : sentence infilling inter - sentential transformer missing sentence generation ( sentence infilling ) foster wide range application natural language generation , document auto - completion meeting note expansion . task ask model generate intermediate miss sentence syntactically semantically bridge surround context . solve sentence infilling task require technique natural language processing range understanding discourselevel planning generation . paper , propose framework decouple challenge address aspect respectively , leverage power exist largescale pre - trained model bert gpt-2 . empirically demonstrate effectiveness model learn sentence representation generation generate miss sentence fit context .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Enabling Language Models to Fill in the Blanks,"We present a simple approach for text infilling, the task of predicting missing spans of text at any position in a document. While infilling could enable rich functionality especially for writing assistance tools, more attention has been devoted to language modeling-a special case of infilling where text is predicted at the end of a document. In this paper, we aim to extend the capabilities of language models (LMs) to the more general task of infilling. To this end, we train (or fine-tune) off-the-shelf LMs on sequences containing the concatenation of artificially-masked text and the text which was masked. We show that this approach, which we call infilling by language modeling, can enable LMs to infill entire sentences effectively on three different domains: short stories, scientific abstracts, and lyrics. Furthermore, we show that humans have difficulty identifying sentences infilled by our approach as machinegenerated in the domain of short stories.","Enabling Language Models to Fill in the Blanks We present a simple approach for text infilling, the task of predicting missing spans of text at any position in a document. While infilling could enable rich functionality especially for writing assistance tools, more attention has been devoted to language modeling-a special case of infilling where text is predicted at the end of a document. In this paper, we aim to extend the capabilities of language models (LMs) to the more general task of infilling. To this end, we train (or fine-tune) off-the-shelf LMs on sequences containing the concatenation of artificially-masked text and the text which was masked. We show that this approach, which we call infilling by language modeling, can enable LMs to infill entire sentences effectively on three different domains: short stories, scientific abstracts, and lyrics. Furthermore, we show that humans have difficulty identifying sentences infilled by our approach as machinegenerated in the domain of short stories.","enable language model fill blank present simple approach text infilling , task predict miss span text position document . infilling enable rich functionality especially write assistance tool , attention devote language modeling - special case infilling text predict end document . paper , aim extend capability language model ( lms ) general task infilling . end , train ( fine - tune ) - - shelf lm sequence contain concatenation artificially - mask text text mask . approach , infille language modeling , enable lm infill entire sentence effectively different domain : short story , scientific abstract , lyric . furthermore , human difficulty identify sentence infille approach machinegenerate domain short story .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Learning to Ask More: Semi-Autoregressive Sequential Question Generation under Dual-Graph Interaction,"Traditional Question Generation (TQG) aims to generate a question given an input passage and an answer. When there is a sequence of answers, we can perform Sequential Question Generation (SQG) to produce a series of interconnected questions. Since the frequently occurred information omission and coreference between questions, SQG is rather challenging. Prior works regarded SQG as a dialog generation task and recurrently produced each question. However, they suffered from problems caused by error cascades and could only capture limited context dependencies. To this end, we generate questions in a semi-autoregressive way. Our model divides questions into different groups and generates each group of them in parallel. During this process, it builds two graphs focusing on information from passages, answers respectively and performs dual-graph interaction to get information for generation. Besides, we design an answer-aware attention mechanism and the coarse-to-fine generation scenario. Experiments on our new dataset containing 81.9K questions show that our model substantially outperforms prior works.","Learning to Ask More: Semi-Autoregressive Sequential Question Generation under Dual-Graph Interaction Traditional Question Generation (TQG) aims to generate a question given an input passage and an answer. When there is a sequence of answers, we can perform Sequential Question Generation (SQG) to produce a series of interconnected questions. Since the frequently occurred information omission and coreference between questions, SQG is rather challenging. Prior works regarded SQG as a dialog generation task and recurrently produced each question. However, they suffered from problems caused by error cascades and could only capture limited context dependencies. To this end, we generate questions in a semi-autoregressive way. Our model divides questions into different groups and generates each group of them in parallel. During this process, it builds two graphs focusing on information from passages, answers respectively and performs dual-graph interaction to get information for generation. Besides, we design an answer-aware attention mechanism and the coarse-to-fine generation scenario. Experiments on our new dataset containing 81.9K questions show that our model substantially outperforms prior works.","learn ask : semi - autoregressive sequential question generation dual - graph interaction traditional question generation ( tqg ) aim generate question give input passage answer . sequence answer , perform sequential question generation ( sqg ) produce series interconnected question . frequently occur information omission coreference question , sqg challenging . prior work regard sqg dialog generation task recurrently produce question . , suffer problem cause error cascade capture limited context dependency . end , generate question semi - autoregressive way . model divide question different group generate group parallel . process , build graph focus information passage , answer respectively perform dual - graph interaction information generation . , design answer - aware attention mechanism coarse - - fine generation scenario . experiment new dataset contain 81.9 k question model substantially outperform prior work .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 14, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Line Graph Enhanced AMR-to-Text Generation with Mix-Order Graph Attention Networks,"Efficient structure encoding for graphs with labeled edges is an important yet challenging point in many graph-based models. This work focuses on AMR-to-text generation -A graph-to-sequence task aiming to recover natural language from Abstract Meaning Representations (AMR). Existing graph-to-sequence approaches generally utilize graph neural networks as their encoders, which have two limitations: 1) The message propagation process in AMR graphs is only guided by the firstorder adjacency information. 2) The relationships between labeled edges are not fully considered. In this work, we propose a novel graph encoding framework which can effectively explore the edge relations. We also adopt graph attention networks with higherorder neighborhood information to encode the rich structure in AMR graphs. Experiment results show that our approach obtains new state-of-the-art performance on English AMR benchmark datasets. The ablation analyses also demonstrate that both edge relations and higher-order information are beneficial to graph-to-sequence modeling.","Line Graph Enhanced AMR-to-Text Generation with Mix-Order Graph Attention Networks Efficient structure encoding for graphs with labeled edges is an important yet challenging point in many graph-based models. This work focuses on AMR-to-text generation -A graph-to-sequence task aiming to recover natural language from Abstract Meaning Representations (AMR). Existing graph-to-sequence approaches generally utilize graph neural networks as their encoders, which have two limitations: 1) The message propagation process in AMR graphs is only guided by the firstorder adjacency information. 2) The relationships between labeled edges are not fully considered. In this work, we propose a novel graph encoding framework which can effectively explore the edge relations. We also adopt graph attention networks with higherorder neighborhood information to encode the rich structure in AMR graphs. Experiment results show that our approach obtains new state-of-the-art performance on English AMR benchmark datasets. The ablation analyses also demonstrate that both edge relations and higher-order information are beneficial to graph-to-sequence modeling.","line graph enhance amr - - text generation mix - order graph attention networks efficient structure encoding graph label edge important challenging point graph - base model . work focus amr - - text generation -a graph - - sequence task aim recover natural language abstract meaning representations ( amr ) . exist graph - - sequence approach generally utilize graph neural network encoder , limitation : 1 ) message propagation process amr graph guide firstorder adjacency information . 2 ) relationship label edge fully consider . work , propose novel graph encoding framework effectively explore edge relation . adopt graph attention network higherorder neighborhood information encode rich structure amr graph . experiment result approach obtain new state - - - art performance english amr benchmark dataset . ablation analysis demonstrate edge relation high - order information beneficial graph - - sequence modeling .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 18, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 12, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Review-based Question Generation with Adaptive Instance Transfer and Augmentation,"While online reviews of products and services become an important information source, it remains inefficient for potential consumers to exploit verbose reviews for fulfilling their information need. We propose to explore question generation as a new way of review information exploitation, namely generating questions that can be answered by the corresponding review sentences. One major challenge of this generation task is the lack of training data, i.e. explicit mapping relation between the user-posed questions and review sentences. To obtain proper training instances for the generation model, we propose an iterative learning framework with adaptive instance transfer and augmentation. To generate to the point questions about the major aspects in reviews, related features extracted in an unsupervised manner are incorporated without the burden of aspect annotation. Experiments on data from various categories of a popular E-commerce site demonstrate the effectiveness of the framework, as well as the potentials of the proposed review-based question generation task.","Review-based Question Generation with Adaptive Instance Transfer and Augmentation While online reviews of products and services become an important information source, it remains inefficient for potential consumers to exploit verbose reviews for fulfilling their information need. We propose to explore question generation as a new way of review information exploitation, namely generating questions that can be answered by the corresponding review sentences. One major challenge of this generation task is the lack of training data, i.e. explicit mapping relation between the user-posed questions and review sentences. To obtain proper training instances for the generation model, we propose an iterative learning framework with adaptive instance transfer and augmentation. To generate to the point questions about the major aspects in reviews, related features extracted in an unsupervised manner are incorporated without the burden of aspect annotation. Experiments on data from various categories of a popular E-commerce site demonstrate the effectiveness of the framework, as well as the potentials of the proposed review-based question generation task.","review - base question generation adaptive instance transfer augmentation online review product service important information source , remain inefficient potential consumer exploit verbose review fulfil information need . propose explore question generation new way review information exploitation , generate question answer correspond review sentence . major challenge generation task lack training datum , i.e. explicit map relation user - pose question review sentence . obtain proper training instance generation model , propose iterative learning framework adaptive instance transfer augmentation . generate point question major aspect review , related feature extract unsupervised manner incorporate burden aspect annotation . experiment datum category popular e - commerce site demonstrate effectiveness framework , potential propose review - base question generation task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 8, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,"BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension","We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by ( 1 ) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance. 1","BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by ( 1 ) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance. 1","bart : denoise sequence - - sequence pre - training natural language generation , translation , comprehension present bart , denoise autoencoder pretraine sequence - - sequence model . bart train ( 1 ) corrupt text arbitrary noising function , ( 2 ) learn model reconstruct original text . use standard tranformer - base neural machine translation architecture , despite simplicity , see generalize bert ( bidirectional encoder ) , gpt ( left - - right decoder ) , recent pretraine scheme . evaluate number noising approach , find good performance randomly shuffle order sentence novel - filling scheme , span text replace single mask token . bart particularly effective fine tune text generation work comprehension task . match performance roberta glue squad , achieve new stateof - - art result range abstractive dialogue , question answering , summarization task , gain 3.5 rouge . bart provide 1.1 bleu increase - translation system machine translation , target language pretraining . replicate pretraine scheme bart framework , understand effect end - task performance . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Generation,Reverse Engineering Configurations of Neural Text Generation Models,"This paper seeks to develop a deeper understanding of the fundamental properties of neural text generations models. The study of artifacts that emerge in machine generated text as a result of modeling choices is a nascent research area. Previously, the extent and degree to which these artifacts surface in generated text has not been well studied. In the spirit of better understanding generative text models and their artifacts, we propose the new task of distinguishing which of several variants of a given model generated a piece of text, and we conduct an extensive suite of diagnostic tests to observe whether modeling choices (e.g., sampling methods, top-k probabilities, model architectures, etc.) leave detectable artifacts in the text they generate. Our key finding, which is backed by a rigorous set of experiments, is that such artifacts are present and that different modeling choices can be inferred by observing the generated text alone. This suggests that neural text generators may be more sensitive to various modeling choices than previously thought.","Reverse Engineering Configurations of Neural Text Generation Models This paper seeks to develop a deeper understanding of the fundamental properties of neural text generations models. The study of artifacts that emerge in machine generated text as a result of modeling choices is a nascent research area. Previously, the extent and degree to which these artifacts surface in generated text has not been well studied. In the spirit of better understanding generative text models and their artifacts, we propose the new task of distinguishing which of several variants of a given model generated a piece of text, and we conduct an extensive suite of diagnostic tests to observe whether modeling choices (e.g., sampling methods, top-k probabilities, model architectures, etc.) leave detectable artifacts in the text they generate. Our key finding, which is backed by a rigorous set of experiments, is that such artifacts are present and that different modeling choices can be inferred by observing the generated text alone. This suggests that neural text generators may be more sensitive to various modeling choices than previously thought.","reverse engineering configuration neural text generation model paper seek develop deep understanding fundamental property neural text generation model . study artifact emerge machine generate text result model choice nascent research area . previously , extent degree artifact surface generate text study . spirit well understand generative text model artifact , propose new task distinguish variant give model generate piece text , conduct extensive suite diagnostic test observe modeling choice ( e.g. , sampling method , - k probability , model architecture , etc . ) leave detectable artifact text generate . key finding , back rigorous set experiment , artifact present different modeling choice infer observe generate text . suggest neural text generator sensitive modeling choice previously think .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 18, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto-Encoders,"Conditional Text Generation has drawn much attention as a topic of Natural Language Generation (NLG) which provides the possibility for humans to control the properties of generated contents. Current conditional generation models cannot handle emerging conditions due to their joint end-to-end learning fashion. When a new condition added, these techniques require full retraining. In this paper, we present a new framework named Pre-train and Plug-in Variational Auto-Encoder (PPVAE) towards flexible conditional text generation. PPVAE decouples the text generation module from the condition representation module to allow ""one-to-many"" conditional generation. When a fresh condition emerges, only a lightweight network needs to be trained and works as a plug-in for PPVAE, which is efficient and desirable for real-world applications. Extensive experiments demonstrate the superiority of PPVAE against the existing alternatives with better conditionality and diversity but less training effort. 1","Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto-Encoders Conditional Text Generation has drawn much attention as a topic of Natural Language Generation (NLG) which provides the possibility for humans to control the properties of generated contents. Current conditional generation models cannot handle emerging conditions due to their joint end-to-end learning fashion. When a new condition added, these techniques require full retraining. In this paper, we present a new framework named Pre-train and Plug-in Variational Auto-Encoder (PPVAE) towards flexible conditional text generation. PPVAE decouples the text generation module from the condition representation module to allow ""one-to-many"" conditional generation. When a fresh condition emerges, only a lightweight network needs to be trained and works as a plug-in for PPVAE, which is efficient and desirable for real-world applications. Extensive experiments demonstrate the superiority of PPVAE against the existing alternatives with better conditionality and diversity but less training effort. 1","pre - train plug - : flexible conditional text generation variational auto - encoders conditional text generation draw attention topic natural language generation ( nlg ) provide possibility human control property generate content . current conditional generation model handle emerge condition joint end - - end learning fashion . new condition add , technique require retraining . paper , present new framework name pre - train plug - variational auto - encoder ( ppvae ) flexible conditional text generation . ppvae decouple text generation module condition representation module allow "" - - "" conditional generation . fresh condition emerge , lightweight network need train work plug - ppvae , efficient desirable real - world application . extensive experiment demonstrate superiority ppvae exist alternative well conditionality diversity training effort . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 17, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Logical Natural Language Generation from Open-Domain Tables,"Neural natural language generation (NLG) models have recently shown remarkable progress in fluency and coherence. However, existing studies on neural NLG are primarily focused on surface-level realizations with limited emphasis on logical inference, an important aspect of human thinking and language. In this paper, we suggest a new NLG task where a model is tasked with generating natural language statements that can be logically entailed by the facts in an open-domain semi-structured table . To facilitate the study of the proposed logical NLG problem, we use the existing Tab-Fact dataset (Chen et al., 2019) featured with a wide range of logical/symbolic inferences as our testbed, and propose new automatic metrics to evaluate the fidelity of generation models w.r.t. logical inference. The new task poses challenges to the existing monotonic generation frameworks due to the mismatch between sequence order and logical order. In our experiments, we comprehensively survey different generation architectures (LSTM, Transformer, Pre-Trained LM) trained with different algorithms (RL, Adversarial Training, Coarse-to-Fine) on the dataset and made following observations: 1) Pre-Trained LM can significantly boost both the fluency and logical fidelity metrics, 2) RL and Adversarial Training are trading fluency for fidelity, 3) Coarse-to-Fine generation can help partially alleviate the fidelity issue while maintaining high language fluency. The code and data are available at https: //github.com/wenhuchen/LogicNLG.","Logical Natural Language Generation from Open-Domain Tables Neural natural language generation (NLG) models have recently shown remarkable progress in fluency and coherence. However, existing studies on neural NLG are primarily focused on surface-level realizations with limited emphasis on logical inference, an important aspect of human thinking and language. In this paper, we suggest a new NLG task where a model is tasked with generating natural language statements that can be logically entailed by the facts in an open-domain semi-structured table . To facilitate the study of the proposed logical NLG problem, we use the existing Tab-Fact dataset (Chen et al., 2019) featured with a wide range of logical/symbolic inferences as our testbed, and propose new automatic metrics to evaluate the fidelity of generation models w.r.t. logical inference. The new task poses challenges to the existing monotonic generation frameworks due to the mismatch between sequence order and logical order. In our experiments, we comprehensively survey different generation architectures (LSTM, Transformer, Pre-Trained LM) trained with different algorithms (RL, Adversarial Training, Coarse-to-Fine) on the dataset and made following observations: 1) Pre-Trained LM can significantly boost both the fluency and logical fidelity metrics, 2) RL and Adversarial Training are trading fluency for fidelity, 3) Coarse-to-Fine generation can help partially alleviate the fidelity issue while maintaining high language fluency. The code and data are available at https: //github.com/wenhuchen/LogicNLG.","logical natural language generation open - domain table neural natural language generation ( nlg ) model recently show remarkable progress fluency coherence . , exist study neural nlg primarily focus surface - level realization limited emphasis logical inference , important aspect human thinking language . paper , suggest new nlg task model task generate natural language statement logically entail fact open - domain semi - structured table . facilitate study propose logical nlg problem , use exist tab - fact dataset ( chen et al . , 2019 ) feature wide range logical / symbolic inference testbed , propose new automatic metric evaluate fidelity generation model w.r.t . logical inference . new task pose challenge exist monotonic generation framework mismatch sequence order logical order . experiment , comprehensively survey different generation architecture ( lstm , transformer , pre - train lm ) train different algorithm ( rl , adversarial training , coarse - - fine ) dataset follow observation : 1 ) pre - train lm significantly boost fluency logical fidelity metric , 2 ) rl adversarial training trade fluency fidelity , 3 ) coarse - - fine generation help partially alleviate fidelity issue maintain high language fluency . code datum available https : //github.com / wenhuchen / logicnlg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 13, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Improving Adversarial Text Generation by Modeling the Distant Future,"Auto-regressive text generation models usually focus on local fluency, and may cause inconsistent semantic meaning in long text generation. Further, automatically generating words with similar semantics is challenging, and hand-crafted linguistic rules are difficult to apply. We consider a text planning scheme and present a model-based imitation-learning approach to alleviate the aforementioned issues. Specifically, we propose a novel guider network to focus on the generative process over a longer horizon, which can assist next-word prediction and provide intermediate rewards for generator optimization. Extensive experiments demonstrate that the proposed method leads to improved performance.","Improving Adversarial Text Generation by Modeling the Distant Future Auto-regressive text generation models usually focus on local fluency, and may cause inconsistent semantic meaning in long text generation. Further, automatically generating words with similar semantics is challenging, and hand-crafted linguistic rules are difficult to apply. We consider a text planning scheme and present a model-based imitation-learning approach to alleviate the aforementioned issues. Specifically, we propose a novel guider network to focus on the generative process over a longer horizon, which can assist next-word prediction and provide intermediate rewards for generator optimization. Extensive experiments demonstrate that the proposed method leads to improved performance.","improve adversarial text generation model distant future auto - regressive text generation model usually focus local fluency , cause inconsistent semantic meaning long text generation . , automatically generate word similar semantic challenging , hand - craft linguistic rule difficult apply . consider text planning scheme present model - base imitation - learning approach alleviate aforementioned issue . specifically , propose novel guider network focus generative process long horizon , assist - word prediction provide intermediate reward generator optimization . extensive experiment demonstrate propose method lead improve performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Automatic Detection of Generated Text is Easiest when Humans are Fooled,"Recent advancements in neural language modelling make it possible to rapidly generate vast amounts of human-sounding text. The capabilities of humans and automatic discriminators to detect machine-generated text have been a large source of research interest, but humans and machines rely on different cues to make their decisions. Here, we perform careful benchmarking and analysis of three popular sampling-based decoding strategies-topk, nucleus sampling, and untruncated random sampling-and show that improvements in decoding methods have primarily optimized for fooling humans. This comes at the expense of introducing statistical abnormalities that make detection easy for automatic systems. We also show that though both human and automatic detector performance improve with longer excerpt length, even multi-sentence excerpts can fool expert human raters over 30% of the time. Our findings reveal the importance of using both human and automatic detectors to assess the humanness of text generation systems.","Automatic Detection of Generated Text is Easiest when Humans are Fooled Recent advancements in neural language modelling make it possible to rapidly generate vast amounts of human-sounding text. The capabilities of humans and automatic discriminators to detect machine-generated text have been a large source of research interest, but humans and machines rely on different cues to make their decisions. Here, we perform careful benchmarking and analysis of three popular sampling-based decoding strategies-topk, nucleus sampling, and untruncated random sampling-and show that improvements in decoding methods have primarily optimized for fooling humans. This comes at the expense of introducing statistical abnormalities that make detection easy for automatic systems. We also show that though both human and automatic detector performance improve with longer excerpt length, even multi-sentence excerpts can fool expert human raters over 30% of the time. Our findings reveal the importance of using both human and automatic detectors to assess the humanness of text generation systems.","automatic detection generate text easy human fool recent advancement neural language modelling possible rapidly generate vast amount human - sound text . capability human automatic discriminator detect machine - generate text large source research interest , human machine rely different cue decision . , perform careful benchmarking analysis popular sampling - base decoding strategy - topk , nucleus sampling , untruncated random sampling - improvement decode method primarily optimize fool human . come expense introduce statistical abnormality detection easy automatic system . human automatic detector performance improve long excerpt length , multi - sentence excerpt fool expert human rater 30 % time . finding reveal importance human automatic detector assess humanness text generation system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,True
Generation,Shape of Synth to Come: Why We Should Use Synthetic Data for English Surface Realization,"The Surface Realization Shared Tasks of 2018 and 2019 were Natural Language Generation shared tasks with the goal of exploring approaches to surface realization from Universal-Dependency-like trees to surface strings for several languages. In the 2018 shared task there was very little difference in the absolute performance of systems trained with and without additional, synthetically created data, and a new rule prohibiting the use of synthetic data was introduced for the 2019 shared task. Contrary to the findings of the 2018 shared task, we show, in experiments on the English 2018 dataset, that the use of synthetic data can have a substantial positive effect -an improvement of almost 8 BLEU points for a previously state-of-the-art system. We analyse the effects of synthetic data, and we argue that its use should be encouraged rather than prohibited so that future research efforts continue to explore systems that can take advantage of such data.","Shape of Synth to Come: Why We Should Use Synthetic Data for English Surface Realization The Surface Realization Shared Tasks of 2018 and 2019 were Natural Language Generation shared tasks with the goal of exploring approaches to surface realization from Universal-Dependency-like trees to surface strings for several languages. In the 2018 shared task there was very little difference in the absolute performance of systems trained with and without additional, synthetically created data, and a new rule prohibiting the use of synthetic data was introduced for the 2019 shared task. Contrary to the findings of the 2018 shared task, we show, in experiments on the English 2018 dataset, that the use of synthetic data can have a substantial positive effect -an improvement of almost 8 BLEU points for a previously state-of-the-art system. We analyse the effects of synthetic data, and we argue that its use should be encouraged rather than prohibited so that future research efforts continue to explore systems that can take advantage of such data.","shape synth come : use synthetic datum english surface realization surface realization share task 2018 2019 natural language generation share task goal explore approach surface realization universal - dependency - like tree surface string language . 2018 share task little difference absolute performance system train additional , synthetically create datum , new rule prohibit use synthetic datum introduce 2019 share task . contrary finding 2018 share task , , experiment english 2018 dataset , use synthetic datum substantial positive effect -an improvement 8 bleu point previously state - - - art system . analyse effect synthetic datum , argue use encourage prohibit future research effort continue explore system advantage datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Information Extraction,Towards Open Domain Event Trigger Identification using Adversarial Domain Adaptation,"We tackle the task of building supervised event trigger identification models which can generalize better across domains. Our work leverages the adversarial domain adaptation (ADA) framework to introduce domain-invariance. ADA uses adversarial training to construct representations that are predictive for trigger identification, but not predictive of the example's domain. It requires no labeled data from the target domain, making it completely unsupervised. Experiments with two domains (English literature and news) show that ADA leads to an average F1 score improvement of 3.9 on outof-domain data. Our best performing model (BERT-A) reaches 44-49 F1 across both domains, using no labeled target data. Preliminary experiments reveal that finetuning on 1% labeled data, followed by self-training leads to substantial improvement, reaching 51.5 and 67.2 F1 on literature and news respectively. 1","Towards Open Domain Event Trigger Identification using Adversarial Domain Adaptation We tackle the task of building supervised event trigger identification models which can generalize better across domains. Our work leverages the adversarial domain adaptation (ADA) framework to introduce domain-invariance. ADA uses adversarial training to construct representations that are predictive for trigger identification, but not predictive of the example's domain. It requires no labeled data from the target domain, making it completely unsupervised. Experiments with two domains (English literature and news) show that ADA leads to an average F1 score improvement of 3.9 on outof-domain data. Our best performing model (BERT-A) reaches 44-49 F1 across both domains, using no labeled target data. Preliminary experiments reveal that finetuning on 1% labeled data, followed by self-training leads to substantial improvement, reaching 51.5 and 67.2 F1 on literature and news respectively. 1","open domain event trigger identification adversarial domain adaptation tackle task build supervise event trigger identification model generalize well domain . work leverage adversarial domain adaptation ( ada ) framework introduce domain - invariance . ada use adversarial training construct representation predictive trigger identification , predictive example domain . require label datum target domain , make completely unsupervised . experiment domain ( english literature news ) ada lead average f1 score improvement 3.9 outof - domain datum . well perform model ( bert - ) reach 44 - 49 f1 domain , label target datum . preliminary experiment reveal finetune 1 % label datum , follow self - training lead substantial improvement , reach 51.5 67.2 f1 literature news respectively . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,A Unified MRC Framework for Named Entity Recognition,"The task of named entity recognition (NER) is normally divided into nested NER and flat NER depending on whether named entities are nested or not. Models are usually separately developed for the two tasks, since sequence labeling models are only able to assign a single label to a particular token, which is unsuitable for nested NER where a token may be assigned several labels.","A Unified MRC Framework for Named Entity Recognition The task of named entity recognition (NER) is normally divided into nested NER and flat NER depending on whether named entities are nested or not. Models are usually separately developed for the two tasks, since sequence labeling models are only able to assign a single label to a particular token, which is unsuitable for nested NER where a token may be assigned several labels.","unified mrc framework name entity recognition task name entity recognition ( ner ) normally divide nested ner flat ner depend name entity nested . model usually separately develop task , sequence labeling model able assign single label particular token , unsuitable nest ner token assign label .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 18, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Bipartite Flat-Graph Network for Nested Named Entity Recognition,"In this paper, we propose a novel bipartite flatgraph network (BiFlaG) for nested named entity recognition (NER), which contains two subgraph modules: a flat NER module for outermost entities and a graph module for all the entities located in inner layers. Bidirectional LSTM (BiLSTM) and graph convolutional network (GCN) are adopted to jointly learn flat entities and their inner dependencies. Different from previous models, which only consider the unidirectional delivery of information from innermost layers to outer ones (or outside-toinside), our model effectively captures the bidirectional interaction between them. We first use the entities recognized by the flat NER module to construct an entity graph, which is fed to the next graph module. The richer representation learned from graph module carries the dependencies of inner entities and can be exploited to improve outermost entity predictions. Experimental results on three standard nested NER datasets demonstrate that our BiFlaG outperforms previous state-of-the-art models.","Bipartite Flat-Graph Network for Nested Named Entity Recognition In this paper, we propose a novel bipartite flatgraph network (BiFlaG) for nested named entity recognition (NER), which contains two subgraph modules: a flat NER module for outermost entities and a graph module for all the entities located in inner layers. Bidirectional LSTM (BiLSTM) and graph convolutional network (GCN) are adopted to jointly learn flat entities and their inner dependencies. Different from previous models, which only consider the unidirectional delivery of information from innermost layers to outer ones (or outside-toinside), our model effectively captures the bidirectional interaction between them. We first use the entities recognized by the flat NER module to construct an entity graph, which is fed to the next graph module. The richer representation learned from graph module carries the dependencies of inner entities and can be exploited to improve outermost entity predictions. Experimental results on three standard nested NER datasets demonstrate that our BiFlaG outperforms previous state-of-the-art models.","bipartite flat - graph network nest name entity recognition paper , propose novel bipartite flatgraph network ( biflag ) nested name entity recognition ( ner ) , contain subgraph module : flat ner module outermost entity graph module entity locate inner layer . bidirectional lstm ( bilstm ) graph convolutional network ( gcn ) adopt jointly learn flat entity inner dependency . different previous model , consider unidirectional delivery information innermost layer outer one ( outside - toinside ) , model effectively capture bidirectional interaction . use entity recognize flat ner module construct entity graph , feed graph module . rich representation learn graph module carry dependency inner entity exploit improve outermost entity prediction . experimental result standard nest ner dataset demonstrate biflag outperform previous state - - - art model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 30, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Pyramid: A Layered Model for Nested Named Entity Recognition,"This paper presents Pyramid, a novel layered model for Nested Named Entity Recognition (nested NER). In our approach, token or text region embeddings are recursively inputted into L flat NER layers, from bottom to top, stacked in a pyramid shape. Each time an embedding passes through a layer of the pyramid, its length is reduced by one. Its hidden state at layer l represents an l-gram in the input text, which is labeled only if its corresponding text region represents a complete entity mention. We also design an inverse pyramid to allow bidirectional interaction between layers. The proposed method achieves state-of-the-art F1 scores in nested","Pyramid: A Layered Model for Nested Named Entity Recognition This paper presents Pyramid, a novel layered model for Nested Named Entity Recognition (nested NER). In our approach, token or text region embeddings are recursively inputted into L flat NER layers, from bottom to top, stacked in a pyramid shape. Each time an embedding passes through a layer of the pyramid, its length is reduced by one. Its hidden state at layer l represents an l-gram in the input text, which is labeled only if its corresponding text region represents a complete entity mention. We also design an inverse pyramid to allow bidirectional interaction between layers. The proposed method achieves state-of-the-art F1 scores in nested","pyramid : layer model nested name entity recognition paper present pyramid , novel layered model nested named entity recognition ( nest ner ) . approach , token text region embedding recursively inputte l flat ner layer , , stack pyramid shape . time embedding pass layer pyramid , length reduce . hide state layer l represent l - gram input text , label correspond text region represent complete entity mention . design inverse pyramid allow bidirectional interaction layer . propose method achieve state - - - art f1 score nest","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 13, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Relabel the Noise: Joint Extraction of Entities and Relations via Cooperative Multiagents,"Distant supervision based methods for entity and relation extraction have received increasing popularity due to the fact that these methods require light human annotation efforts. In this paper, we consider the problem of shifted label distribution, which is caused by the inconsistency between the noisy-labeled training set subject to external knowledge graph and the human-annotated test set, and exacerbated by the pipelined entity-then-relation extraction manner with noise propagation. We propose a joint extraction approach to address this problem by re-labeling noisy instances with a group of cooperative multiagents. To handle noisy instances in a fine-grained manner, each agent in the cooperative group evaluates the instance by calculating a continuous confidence score from its own perspective; To leverage the correlations between these two extraction tasks, a confidence consensus module is designed to gather the wisdom of all agents and re-distribute the noisy training set with confidence-scored labels. Further, the confidences are used to adjust the training losses of extractors. Experimental results on two realworld datasets verify the benefits of re-labeling noisy instance, and show that the proposed model significantly outperforms the state-ofthe-art entity and relation extraction methods.","Relabel the Noise: Joint Extraction of Entities and Relations via Cooperative Multiagents Distant supervision based methods for entity and relation extraction have received increasing popularity due to the fact that these methods require light human annotation efforts. In this paper, we consider the problem of shifted label distribution, which is caused by the inconsistency between the noisy-labeled training set subject to external knowledge graph and the human-annotated test set, and exacerbated by the pipelined entity-then-relation extraction manner with noise propagation. We propose a joint extraction approach to address this problem by re-labeling noisy instances with a group of cooperative multiagents. To handle noisy instances in a fine-grained manner, each agent in the cooperative group evaluates the instance by calculating a continuous confidence score from its own perspective; To leverage the correlations between these two extraction tasks, a confidence consensus module is designed to gather the wisdom of all agents and re-distribute the noisy training set with confidence-scored labels. Further, the confidences are used to adjust the training losses of extractors. Experimental results on two realworld datasets verify the benefits of re-labeling noisy instance, and show that the proposed model significantly outperforms the state-ofthe-art entity and relation extraction methods.","relabel noise : joint extraction entity relation cooperative multiagent distant supervision base method entity relation extraction receive increase popularity fact method require light human annotation effort . paper , consider problem shift label distribution , cause inconsistency noisy - label training set subject external knowledge graph human - annotate test set , exacerbate pipelined entity - - relation extraction manner noise propagation . propose joint extraction approach address problem - label noisy instance group cooperative multiagent . handle noisy instance fine - grained manner , agent cooperative group evaluate instance calculate continuous confidence score perspective ; leverage correlation extraction task , confidence consensus module design gather wisdom agent - distribute noisy training set confidence - score label . , confidence adjust training loss extractor . experimental result realworld dataset verify benefit - label noisy instance , propose model significantly outperform state - ofthe - art entity relation extraction method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 17, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 11, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Instance-Based Learning of Span Representations: A Case Study through Named Entity Recognition,"Interpretable rationales for model predictions play a critical role in practical applications. In this study, we develop models possessing interpretable inference process for structured prediction. Specifically, we present a method of instance-based learning that learns similarities between spans. At inference time, each span is assigned a class label based on its similar spans in the training set, where it is easy to understand how much each training instance contributes to the predictions. Through empirical analysis on named entity recognition, we demonstrate that our method enables to build models that have high interpretability without sacrificing performance.","Instance-Based Learning of Span Representations: A Case Study through Named Entity Recognition Interpretable rationales for model predictions play a critical role in practical applications. In this study, we develop models possessing interpretable inference process for structured prediction. Specifically, we present a method of instance-based learning that learns similarities between spans. At inference time, each span is assigned a class label based on its similar spans in the training set, where it is easy to understand how much each training instance contributes to the predictions. Through empirical analysis on named entity recognition, we demonstrate that our method enables to build models that have high interpretability without sacrificing performance.","instance - base learning span representation : case study name entity recognition interpretable rationale model prediction play critical role practical application . study , develop model possess interpretable inference process structured prediction . specifically , present method instance - base learning learn similarity span . inference time , span assign class label base similar span training set , easy understand training instance contribute prediction . empirical analysis name entity recognition , demonstrate method enable build model high interpretability sacrifice performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 10, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Hierarchical Entity Typing via Multi-level Learning to Rank,"We propose a novel method for hierarchical entity classification that embraces ontological structure at both training and during prediction. At training, our novel multi-level learning-to-rank loss compares positive types against negative siblings according to the type tree. During prediction, we define a coarseto-fine decoder that restricts viable candidates at each level of the ontology based on already predicted parent type(s). We achieve stateof-the-art across multiple datasets, particularly with respect to strict accuracy. 1","Hierarchical Entity Typing via Multi-level Learning to Rank We propose a novel method for hierarchical entity classification that embraces ontological structure at both training and during prediction. At training, our novel multi-level learning-to-rank loss compares positive types against negative siblings according to the type tree. During prediction, we define a coarseto-fine decoder that restricts viable candidates at each level of the ontology based on already predicted parent type(s). We achieve stateof-the-art across multiple datasets, particularly with respect to strict accuracy. 1","hierarchical entity typing multi - level learning rank propose novel method hierarchical entity classification embrace ontological structure training prediction . training , novel multi - level learn - - rank loss compare positive type negative sibling accord type tree . prediction , define coarseto - fine decoder restrict viable candidate level ontology base predict parent type(s ) . achieve stateof - - art multiple dataset , particularly respect strict accuracy . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,Exploiting the Syntax-Model Consistency for Neural Relation Extraction,"This paper studies the task of Relation Extraction (RE) that aims to identify the semantic relations between two entity mentions in text. In the deep learning models for RE, it has been beneficial to incorporate the syntactic structures from the dependency trees of the input sentences. In such models, the dependency trees are often used to directly structure the network architectures or to obtain the dependency relations between the word pairs to inject the syntactic information into the models via multi-task learning. The major problems with these approaches are the lack of generalization beyond the syntactic structures in the training data or the failure to capture the syntactic importance of the words for RE. In order to overcome these issues, we propose a novel deep learning model for RE that uses the dependency trees to extract the syntax-based importance scores for the words, serving as a tree representation to introduce syntactic information into the models with greater generalization. In particular, we leverage Ordered-Neuron Long-Short Term Memory Networks (ON-LSTM) to infer the model-based importance scores for RE for every word in the sentences that are then regulated to be consistent with the syntax-based scores to enable syntactic information injection. We perform extensive experiments to demonstrate the effectiveness of the proposed method, leading to the state-of-the-art performance on three RE benchmark datasets.","Exploiting the Syntax-Model Consistency for Neural Relation Extraction This paper studies the task of Relation Extraction (RE) that aims to identify the semantic relations between two entity mentions in text. In the deep learning models for RE, it has been beneficial to incorporate the syntactic structures from the dependency trees of the input sentences. In such models, the dependency trees are often used to directly structure the network architectures or to obtain the dependency relations between the word pairs to inject the syntactic information into the models via multi-task learning. The major problems with these approaches are the lack of generalization beyond the syntactic structures in the training data or the failure to capture the syntactic importance of the words for RE. In order to overcome these issues, we propose a novel deep learning model for RE that uses the dependency trees to extract the syntax-based importance scores for the words, serving as a tree representation to introduce syntactic information into the models with greater generalization. In particular, we leverage Ordered-Neuron Long-Short Term Memory Networks (ON-LSTM) to infer the model-based importance scores for RE for every word in the sentences that are then regulated to be consistent with the syntax-based scores to enable syntactic information injection. We perform extensive experiments to demonstrate the effectiveness of the proposed method, leading to the state-of-the-art performance on three RE benchmark datasets.","exploit syntax - model consistency neural relation extraction paper study task relation extraction ( ) aim identify semantic relation entity mention text . deep learning model , beneficial incorporate syntactic structure dependency tree input sentence . model , dependency tree directly structure network architecture obtain dependency relation word pair inject syntactic information model multi - task learning . major problem approach lack generalization syntactic structure training datum failure capture syntactic importance word . order overcome issue , propose novel deep learning model use dependency tree extract syntax - base importance score word , serve tree representation introduce syntactic information model great generalization . particular , leverage ordered - neuron long - short term memory networks ( - lstm ) infer model - base importance score word sentence regulate consistent syntax - base score enable syntactic information injection . perform extensive experiment demonstrate effectiveness propose method , lead state - - - art performance benchmark dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 6, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 8, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}",Information Extraction,True
Information Extraction,Improving Low-Resource Named Entity Recognition using Joint Sentence and Token Labeling,"Exploiting sentence-level labels, which are easy to obtain, is one of the plausible methods to improve low-resource named entity recognition (NER), where token-level labels are costly to annotate. Current models for jointly learning sentence and token labeling are limited to binary classification. We present a joint model that supports multi-class classification and introduce a simple variant of self-attention that allows the model to learn scaling factors. Our model produces 3.78%, 4.20%, 2.08% improvements in F1 over the BiLSTM-CRF baseline on e-commerce product titles in three different low-resource languages: Vietnamese, Thai, and Indonesian, respectively.","Improving Low-Resource Named Entity Recognition using Joint Sentence and Token Labeling Exploiting sentence-level labels, which are easy to obtain, is one of the plausible methods to improve low-resource named entity recognition (NER), where token-level labels are costly to annotate. Current models for jointly learning sentence and token labeling are limited to binary classification. We present a joint model that supports multi-class classification and introduce a simple variant of self-attention that allows the model to learn scaling factors. Our model produces 3.78%, 4.20%, 2.08% improvements in F1 over the BiLSTM-CRF baseline on e-commerce product titles in three different low-resource languages: Vietnamese, Thai, and Indonesian, respectively.","improve low - resource name entity recognition joint sentence token labeling exploit sentence - level label , easy obtain , plausible method improve low - resource name entity recognition ( ner ) , token - level label costly annotate . current model jointly learn sentence token labeling limit binary classification . present joint model support multi - class classification introduce simple variant self - attention allow model learn scale factor . model produce 3.78 % , 4.20 % , 2.08 % improvement f1 bilstm - crf baseline e - commerce product title different low - resource language : vietnamese , thai , indonesian , respectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product Categories,"Extracting structured knowledge from product profiles is crucial for various applications in e-Commerce. State-of-the-art approaches for knowledge extraction were each designed for a single category of product, and thus do not apply to real-life e-Commerce scenarios, which often contain thousands of diverse categories. This paper proposes TXtract, a taxonomyaware knowledge extraction model that applies to thousands of product categories organized in a hierarchical taxonomy. Through category conditional self-attention and multi-task learning, our approach is both scalable, as it trains a single model for thousands of categories, and effective, as it extracts categoryspecific attribute values. Experiments on products from a taxonomy with 4,000 categories show that TXtract outperforms state-of-the-art approaches by up to 10% in F1 and 15% in coverage across all categories.","TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product Categories Extracting structured knowledge from product profiles is crucial for various applications in e-Commerce. State-of-the-art approaches for knowledge extraction were each designed for a single category of product, and thus do not apply to real-life e-Commerce scenarios, which often contain thousands of diverse categories. This paper proposes TXtract, a taxonomyaware knowledge extraction model that applies to thousands of product categories organized in a hierarchical taxonomy. Through category conditional self-attention and multi-task learning, our approach is both scalable, as it trains a single model for thousands of categories, and effective, as it extracts categoryspecific attribute values. Experiments on products from a taxonomy with 4,000 categories show that TXtract outperforms state-of-the-art approaches by up to 10% in F1 and 15% in coverage across all categories.","txtract : taxonomy - aware knowledge extraction thousand product category extract structure knowledge product profile crucial application e - commerce . state - - - art approach knowledge extraction design single category product , apply real - life e - commerce scenario , contain thousand diverse category . paper propose txtract , taxonomyaware knowledge extraction model apply thousand product category organize hierarchical taxonomy . category conditional self - attention multi - task learning , approach scalable , train single model thousand category , effective , extract categoryspecific attribute value . experiment product taxonomy 4,000 category txtract outperform state - - - art approach 10 % f1 15 % coverage category .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Improving Event Detection via Open-domain Trigger Knowledge,"Event Detection (ED) is a fundamental task in automatically structuring texts. Due to the small scale of training data, previous methods perform poorly on unseen/sparsely labeled trigger words and are prone to overfitting densely labeled trigger words. To address the issue, we propose a novel Enrichment Knowledge Distillation (EKD) model to leverage external open-domain trigger knowledge to reduce the in-built biases to frequent trigger words in annotations. Experiments on benchmark ACE2005 show that our model outperforms nine strong baselines, is especially effective for unseen/sparsely labeled trigger words. The source code is released on https://github.com/shuaiwa16/ekd.git.","Improving Event Detection via Open-domain Trigger Knowledge Event Detection (ED) is a fundamental task in automatically structuring texts. Due to the small scale of training data, previous methods perform poorly on unseen/sparsely labeled trigger words and are prone to overfitting densely labeled trigger words. To address the issue, we propose a novel Enrichment Knowledge Distillation (EKD) model to leverage external open-domain trigger knowledge to reduce the in-built biases to frequent trigger words in annotations. Experiments on benchmark ACE2005 show that our model outperforms nine strong baselines, is especially effective for unseen/sparsely labeled trigger words. The source code is released on https://github.com/shuaiwa16/ekd.git.","improve event detection open - domain trigger knowledge event detection ( ed ) fundamental task automatically structure text . small scale training datum , previous method perform poorly unseen / sparsely label trigger word prone overfitte densely label trigger word . address issue , propose novel enrichment knowledge distillation ( ekd ) model leverage external open - domain trigger knowledge reduce - build bias frequent trigger word annotation . experiment benchmark ace2005 model outperform strong baseline , especially effective unseen / sparsely label trigger word . source code release https://github.com/shuaiwa16/ekd.git .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Temporally-Informed Analysis of Named Entity Recognition,"Natural language processing models often have to make predictions on text data that evolves over time as a result of changes in language use or the information described in the text. However, evaluation results on existing data sets are seldom reported by taking the timestamp of the document into account. We analyze and propose methods that make better use of temporally-diverse training data, with a focus on the task of named entity recognition. To support these experiments, we introduce a novel data set of English tweets annotated with named entities. 1 We empirically demonstrate the effect of temporal drift on performance, and how the temporal information of documents can be used to obtain better models compared to those that disregard temporal information. Our analysis gives insights into why this information is useful, in the hope of informing potential avenues of improvement for named entity recognition as well as other NLP tasks under similar experimental setups.","Temporally-Informed Analysis of Named Entity Recognition Natural language processing models often have to make predictions on text data that evolves over time as a result of changes in language use or the information described in the text. However, evaluation results on existing data sets are seldom reported by taking the timestamp of the document into account. We analyze and propose methods that make better use of temporally-diverse training data, with a focus on the task of named entity recognition. To support these experiments, we introduce a novel data set of English tweets annotated with named entities. 1 We empirically demonstrate the effect of temporal drift on performance, and how the temporal information of documents can be used to obtain better models compared to those that disregard temporal information. Our analysis gives insights into why this information is useful, in the hope of informing potential avenues of improvement for named entity recognition as well as other NLP tasks under similar experimental setups.","temporally - inform analysis name entity recognition natural language processing model prediction text datum evolve time result change language use information describe text . , evaluation result exist data set seldom report take timestamp document account . analyze propose method well use temporally - diverse training datum , focus task name entity recognition . support experiment , introduce novel data set english tweet annotate name entity . 1 empirically demonstrate effect temporal drift performance , temporal information document obtain well model compare disregard temporal information . analysis give insight information useful , hope inform potential avenue improvement name entity recognition nlp task similar experimental setup .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 18, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Revisiting Unsupervised Relation Extraction,"Unsupervised relation extraction (URE) extracts relations between named entities from raw text without manually-labelled data and existing knowledge bases (KBs). URE methods can be categorised into generative and discriminative approaches, which rely either on hand-crafted features or surface form. However, we demonstrate that by using only named entities to induce relation types, we can outperform existing methods on two popular datasets. We conduct a comparison and evaluation of our findings with other URE techniques, to ascertain the important features in URE. We conclude that entity types provide a strong inductive bias for URE. 1","Revisiting Unsupervised Relation Extraction Unsupervised relation extraction (URE) extracts relations between named entities from raw text without manually-labelled data and existing knowledge bases (KBs). URE methods can be categorised into generative and discriminative approaches, which rely either on hand-crafted features or surface form. However, we demonstrate that by using only named entities to induce relation types, we can outperform existing methods on two popular datasets. We conduct a comparison and evaluation of our findings with other URE techniques, to ascertain the important features in URE. We conclude that entity types provide a strong inductive bias for URE. 1","revisit unsupervised relation extraction unsupervised relation extraction ( ure ) extract relation name entity raw text manually - label datum exist knowledge basis ( kb ) . ure method categorise generative discriminative approach , rely hand - craft feature surface form . , demonstrate name entity induce relation type , outperform exist method popular dataset . conduct comparison evaluation finding ure technique , ascertain important feature ure . conclude entity type provide strong inductive bias ure . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Representation Learning for Information Extraction from Form-like Documents,"We propose a novel approach using representation learning for tackling the problem of extracting structured information from form-like document images. We propose an extraction system that uses knowledge of the types of the target fields to generate extraction candidates, and a neural network architecture that learns a dense representation of each candidate based on neighboring words in the document. These learned representations are not only useful in solving the extraction task for unseen document templates from two different domains, but are also interpretable, as we show using loss cases.","Representation Learning for Information Extraction from Form-like Documents We propose a novel approach using representation learning for tackling the problem of extracting structured information from form-like document images. We propose an extraction system that uses knowledge of the types of the target fields to generate extraction candidates, and a neural network architecture that learns a dense representation of each candidate based on neighboring words in the document. These learned representations are not only useful in solving the extraction task for unseen document templates from two different domains, but are also interpretable, as we show using loss cases.","representation learning information extraction form - like document propose novel approach representation learning tackle problem extract structured information form - like document image . propose extraction system use knowledge type target field generate extraction candidate , neural network architecture learn dense representation candidate base neighbor word document . learn representation useful solve extraction task unseen document template different domain , interpretable , loss case .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,A Novel Cascade Binary Tagging Framework for Relational Triple Extraction,"Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction. However, few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities. In this work, we introduce a fresh perspective to revisit the relational triple extraction task and propose a novel cascade binary tagging framework (CASREL) derived from a principled problem formulation. Instead of treating relations as discrete labels as in previous works, our new framework models relations as functions that map subjects to objects in a sentence, which naturally handles the overlapping problem. Experiments show that the CAS-REL framework already outperforms state-ofthe-art methods even when its encoder module uses a randomly initialized BERT encoder, showing the power of the new tagging framework. It enjoys further performance boost when employing a pre-trained BERT encoder, outperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score on two public datasets NYT and WebNLG, respectively. In-depth analysis on different scenarios of overlapping triples shows that the method delivers consistent performance gain across all these scenarios. The source code and data are released online 1 .","A Novel Cascade Binary Tagging Framework for Relational Triple Extraction Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction. However, few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities. In this work, we introduce a fresh perspective to revisit the relational triple extraction task and propose a novel cascade binary tagging framework (CASREL) derived from a principled problem formulation. Instead of treating relations as discrete labels as in previous works, our new framework models relations as functions that map subjects to objects in a sentence, which naturally handles the overlapping problem. Experiments show that the CAS-REL framework already outperforms state-ofthe-art methods even when its encoder module uses a randomly initialized BERT encoder, showing the power of the new tagging framework. It enjoys further performance boost when employing a pre-trained BERT encoder, outperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score on two public datasets NYT and WebNLG, respectively. In-depth analysis on different scenarios of overlapping triples shows that the method delivers consistent performance gain across all these scenarios. The source code and data are released online 1 .","novel cascade binary tagging framework relational triple extraction extract relational triple unstructured text crucial large - scale knowledge graph construction . , exist work excel solve overlapping triple problem multiple relational triple sentence share entity . work , introduce fresh perspective revisit relational triple extraction task propose novel cascade binary tagging framework ( casrel ) derive principled problem formulation . instead treat relation discrete label previous work , new framework model relation function map subject object sentence , naturally handle overlap problem . experiment cas - rel framework outperform state - ofthe - art method encoder module use randomly initialize bert encoder , show power new tagging framework . enjoy performance boost employ pre - trained bert encoder , outperform strong baseline 17.5 30.2 absolute gain f1 - score public dataset nyt webnlg , respectively . - depth analysis different scenario overlap triple show method deliver consistent performance gain scenario . source code datum release online 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,From English to Code-Switching: Transfer Learning with Strong Morphological Clues,"Linguistic Code-switching (CS) is still an understudied phenomenon in natural language processing. The NLP community has mostly focused on monolingual and multi-lingual scenarios, but little attention has been given to CS in particular. This is partly because of the lack of resources and annotated data, despite its increasing occurrence in social media platforms. In this paper, we aim at adapting monolingual models to code-switched text in various tasks. Specifically, we transfer English knowledge from a pre-trained ELMo model to different code-switched language pairs (i.e., Nepali-English, Spanish-English, and Hindi-English) using the task of language identification. Our method, CS-ELMo, is an extension of ELMo with a simple yet effective position-aware attention mechanism inside its character convolutions. We show the effectiveness of this transfer learning step by outperforming multilingual BERT and homologous CS-unaware ELMo models and establishing a new state of the art in CS tasks, such as NER and POS tagging. Our technique can be expanded to more English-paired code-switched languages, providing more resources to the CS community.","From English to Code-Switching: Transfer Learning with Strong Morphological Clues Linguistic Code-switching (CS) is still an understudied phenomenon in natural language processing. The NLP community has mostly focused on monolingual and multi-lingual scenarios, but little attention has been given to CS in particular. This is partly because of the lack of resources and annotated data, despite its increasing occurrence in social media platforms. In this paper, we aim at adapting monolingual models to code-switched text in various tasks. Specifically, we transfer English knowledge from a pre-trained ELMo model to different code-switched language pairs (i.e., Nepali-English, Spanish-English, and Hindi-English) using the task of language identification. Our method, CS-ELMo, is an extension of ELMo with a simple yet effective position-aware attention mechanism inside its character convolutions. We show the effectiveness of this transfer learning step by outperforming multilingual BERT and homologous CS-unaware ELMo models and establishing a new state of the art in CS tasks, such as NER and POS tagging. Our technique can be expanded to more English-paired code-switched languages, providing more resources to the CS community.","english code - switching : transfer learning strong morphological clue linguistic code - switching ( cs ) understudied phenomenon natural language processing . nlp community focus monolingual multi - lingual scenario , little attention give cs particular . partly lack resource annotate datum , despite increase occurrence social media platform . paper , aim adapt monolingual model code - switch text task . specifically , transfer english knowledge pre - train elmo model different code - switch language pair ( i.e. , nepali - english , spanish - english , hindi - english ) task language identification . method , cs - elmo , extension elmo simple effective position - aware attention mechanism inside character convolution . effectiveness transfer learning step outperform multilingual bert homologous cs - unaware elmo model establish new state art cs task , ner pos tagging . technique expand english - paired code - switch language , provide resource cs community .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Information Extraction,Named Entity Recognition without Labelled Data: A Weak Supervision Approach,"Named Entity Recognition (NER) performance often degrades rapidly when applied to target domains that differ from the texts observed during training. When in-domain labelled data is available, transfer learning techniques can be used to adapt existing NER models to the target domain. But what should one do when there is no hand-labelled data for the target domain? This paper presents a simple but powerful approach to learn NER models in the absence of labelled data through weak supervision. The approach relies on a broad spectrum of labelling functions to automatically annotate texts from the target domain. These annotations are then merged together using a hidden Markov model which captures the varying accuracies and confusions of the labelling functions. A sequence labelling model can finally be trained on the basis of this unified annotation. We evaluate the approach on two English datasets (CoNLL 2003 and news articles from Reuters and Bloomberg) and demonstrate an improvement of about 7 percentage points in entity-level F 1 scores compared to an out-of-domain neural NER model.","Named Entity Recognition without Labelled Data: A Weak Supervision Approach Named Entity Recognition (NER) performance often degrades rapidly when applied to target domains that differ from the texts observed during training. When in-domain labelled data is available, transfer learning techniques can be used to adapt existing NER models to the target domain. But what should one do when there is no hand-labelled data for the target domain? This paper presents a simple but powerful approach to learn NER models in the absence of labelled data through weak supervision. The approach relies on a broad spectrum of labelling functions to automatically annotate texts from the target domain. These annotations are then merged together using a hidden Markov model which captures the varying accuracies and confusions of the labelling functions. A sequence labelling model can finally be trained on the basis of this unified annotation. We evaluate the approach on two English datasets (CoNLL 2003 and news articles from Reuters and Bloomberg) and demonstrate an improvement of about 7 percentage points in entity-level F 1 scores compared to an out-of-domain neural NER model.","name entity recognition label datum : weak supervision approach name entity recognition ( ner ) performance degrade rapidly apply target domain differ text observe training . - domain label datum available , transfer learning technique adapt exist ner model target domain . hand - label datum target domain ? paper present simple powerful approach learn ner model absence label datum weak supervision . approach rely broad spectrum labelling function automatically annotate text target domain . annotation merge hidden markov model capture vary accuracy confusion labelling function . sequence labelling model finally train basis unify annotation . evaluate approach english dataset ( conll 2003 news article reuters bloomberg ) demonstrate improvement 7 percentage point entity - level f 1 score compare - - domain neural ner model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 15, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language,"To better tackle the named entity recognition (NER) problem on languages with little/no labeled data, cross-lingual NER must effectively leverage knowledge learned from source languages with rich labeled data. Previous works on cross-lingual NER are mostly based on label projection with pairwise texts or direct model transfer. However, such methods either are not applicable if the labeled data in the source languages is unavailable, or do not leverage information contained in unlabeled data in the target language. In this paper, we propose a teacher-student learning method to address such limitations, where NER models in the source languages are used as teachers to train a student model on unlabeled data in the target language. The proposed method works for both single-source and multi-source crosslingual NER. For the latter, we further propose a similarity measuring method to better weight the supervision from different teacher models. Extensive experiments for 3 target languages on benchmark datasets well demonstrate that our method outperforms existing state-of-theart methods for both single-source and multisource cross-lingual NER.","Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language To better tackle the named entity recognition (NER) problem on languages with little/no labeled data, cross-lingual NER must effectively leverage knowledge learned from source languages with rich labeled data. Previous works on cross-lingual NER are mostly based on label projection with pairwise texts or direct model transfer. However, such methods either are not applicable if the labeled data in the source languages is unavailable, or do not leverage information contained in unlabeled data in the target language. In this paper, we propose a teacher-student learning method to address such limitations, where NER models in the source languages are used as teachers to train a student model on unlabeled data in the target language. The proposed method works for both single-source and multi-source crosslingual NER. For the latter, we further propose a similarity measuring method to better weight the supervision from different teacher models. Extensive experiments for 3 target languages on benchmark datasets well demonstrate that our method outperforms existing state-of-theart methods for both single-source and multisource cross-lingual NER.","single-/multi - source cross - lingual ner teacher - student learning unlabeled datum target language well tackle name entity recognition ( ner ) problem language little / label datum , cross - lingual ner effectively leverage knowledge learn source language rich label datum . previous work cross - lingual ner base label projection pairwise text direct model transfer . , method applicable label datum source language unavailable , leverage information contain unlabeled datum target language . paper , propose teacher - student learning method address limitation , ner model source language teacher train student model unlabeled datum target language . propose method work single - source multi - source crosslingual ner . , propose similarity measure method well weight supervision different teacher model . extensive experiment 3 target language benchmark dataset demonstrate method outperform exist state - - theart method single - source multisource cross - lingual ner .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Multi-Sentence Argument Linking,"We present a novel document-level model for finding argument spans that fill an event's roles, connecting related ideas in sentencelevel semantic role labeling and coreference resolution. Because existing datasets for cross-sentence linking are small, development of our neural model is supported through the creation of a new resource, Roles Across Multiple Sentences (RAMS), which contains 9,124 annotated events across 139 types. We demonstrate strong performance of our model on RAMS and other event-related datasets. 1 * Equal Contribution 1 Data and code at http://nlp.jhu.edu/rams/. 2 would indicate there is no explicit referent in the text. 3 LDC2019E04 (data); LDC2019E07 (annotations) 4 LDC2019E42 (data); LDC2019E77 (annotations)","Multi-Sentence Argument Linking We present a novel document-level model for finding argument spans that fill an event's roles, connecting related ideas in sentencelevel semantic role labeling and coreference resolution. Because existing datasets for cross-sentence linking are small, development of our neural model is supported through the creation of a new resource, Roles Across Multiple Sentences (RAMS), which contains 9,124 annotated events across 139 types. We demonstrate strong performance of our model on RAMS and other event-related datasets. 1 * Equal Contribution 1 Data and code at http://nlp.jhu.edu/rams/. 2 would indicate there is no explicit referent in the text. 3 LDC2019E04 (data); LDC2019E07 (annotations) 4 LDC2019E42 (data); LDC2019E77 (annotations)","multi - sentence argument linking present novel document - level model find argument span fill event role , connect related idea sentencelevel semantic role labeling coreference resolution . exist dataset cross - sentence linking small , development neural model support creation new resource , roles multiple sentences ( rams ) , contain 9,124 annotate event 139 type . demonstrate strong performance model rams event - relate dataset . 1 * equal contribution 1 datum code http://nlp.jhu.edu/rams/. 2 indicate explicit referent text . 3 ldc2019e04 ( datum ) ; ldc2019e07 ( annotation ) 4 ldc2019e42 ( datum ) ; ldc2019e77 ( annotation )","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Information Extraction,An Effective Transition-based Model for Discontinuous NER,"Unlike widely used Named Entity Recognition (NER) data sets in generic domains, biomedical NER data sets often contain mentions consisting of discontinuous spans. Conventional sequence tagging techniques encode Markov assumptions that are efficient but preclude recovery of these mentions. We propose a simple, effective transition-based model with generic neural encoding for discontinuous NER. Through extensive experiments on three biomedical data sets, we show that our model can effectively recognize discontinuous mentions without sacrificing the accuracy on continuous mentions.","An Effective Transition-based Model for Discontinuous NER Unlike widely used Named Entity Recognition (NER) data sets in generic domains, biomedical NER data sets often contain mentions consisting of discontinuous spans. Conventional sequence tagging techniques encode Markov assumptions that are efficient but preclude recovery of these mentions. We propose a simple, effective transition-based model with generic neural encoding for discontinuous NER. Through extensive experiments on three biomedical data sets, we show that our model can effectively recognize discontinuous mentions without sacrificing the accuracy on continuous mentions.","effective transition - base model discontinuous ner unlike widely name entity recognition ( ner ) data set generic domain , biomedical ner datum set contain mention consist discontinuous span . conventional sequence tagging technique encode markov assumption efficient preclude recovery mention . propose simple , effective transition - base model generic neural encoding discontinuous ner . extensive experiment biomedical data set , model effectively recognize discontinuous mention sacrifice accuracy continuous mention .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Multi-Cell Compositional LSTM for NER Domain Adaptation,"Cross-domain NER is a challenging yet practical problem. Entity mentions can be highly different across domains. However, the correlations between entity types can be relatively more stable across domains. We investigate a multi-cell compositional LSTM structure for multi-task learning, modeling each entity type using a separate cell state. With the help of entity typed units, cross-domain knowledge transfer can be made in an entity type level. Theoretically, the resulting distinct feature distributions for each entity type make it more powerful for cross-domain transfer. Empirically, experiments on four few-shot and zeroshot datasets show our method significantly outperforms a series of multi-task learning methods and achieves the best results.","Multi-Cell Compositional LSTM for NER Domain Adaptation Cross-domain NER is a challenging yet practical problem. Entity mentions can be highly different across domains. However, the correlations between entity types can be relatively more stable across domains. We investigate a multi-cell compositional LSTM structure for multi-task learning, modeling each entity type using a separate cell state. With the help of entity typed units, cross-domain knowledge transfer can be made in an entity type level. Theoretically, the resulting distinct feature distributions for each entity type make it more powerful for cross-domain transfer. Empirically, experiments on four few-shot and zeroshot datasets show our method significantly outperforms a series of multi-task learning methods and achieves the best results.","multi - cell compositional lstm ner domain adaptation cross - domain ner challenging practical problem . entity mention highly different domain . , correlation entity type relatively stable domain . investigate multi - cell compositional lstm structure multi - task learning , model entity type separate cell state . help entity type unit , cross - domain knowledge transfer entity type level . theoretically , result distinct feature distribution entity type powerful cross - domain transfer . empirically , experiment - shot zeroshot dataset method significantly outperform series multi - task learning method achieve good result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Extraction,True
Information Extraction,Handling Rare Entities for Neural Sequence Labeling,"One great challenge in neural sequence labeling is the data sparsity problem for rare entity words and phrases. Most of test set entities appear only few times and are even unseen in training corpus, yielding large number of out-of-vocabulary (OOV) and low-frequency (LF) entities during evaluation. In this work, we propose approaches to address this problem. For OOV entities, we introduce local context reconstruction to implicitly incorporate contextual information into their representations. For LF entities, we present delexicalized entity identification to explicitly extract their frequency-agnostic and entity-typespecific representations. Extensive experiments on multiple benchmark datasets show that our model has significantly outperformed all previous methods and achieved new startof-the-art results. Notably, our methods surpass the model fine-tuned on pre-trained language models without external resource.","Handling Rare Entities for Neural Sequence Labeling One great challenge in neural sequence labeling is the data sparsity problem for rare entity words and phrases. Most of test set entities appear only few times and are even unseen in training corpus, yielding large number of out-of-vocabulary (OOV) and low-frequency (LF) entities during evaluation. In this work, we propose approaches to address this problem. For OOV entities, we introduce local context reconstruction to implicitly incorporate contextual information into their representations. For LF entities, we present delexicalized entity identification to explicitly extract their frequency-agnostic and entity-typespecific representations. Extensive experiments on multiple benchmark datasets show that our model has significantly outperformed all previous methods and achieved new startof-the-art results. Notably, our methods surpass the model fine-tuned on pre-trained language models without external resource.","handle rare entity neural sequence labeling great challenge neural sequence labeling data sparsity problem rare entity word phrase . test set entity appear time unseen training corpus , yield large number - - vocabulary ( oov ) low - frequency ( lf ) entity evaluation . work , propose approach address problem . oov entity , introduce local context reconstruction implicitly incorporate contextual information representation . lf entity , present delexicalized entity identification explicitly extract frequency - agnostic entity - typespecific representation . extensive experiment multiple benchmark dataset model significantly outperform previous method achieve new startof - - art result . notably , method surpass model fine - tune pre - trained language model external resource .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,A Joint Neural Model for Information Extraction with Global Features,"Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a VICTIM of a DIE event is likely to be a VICTIM of an AT-TACK event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, ONEIE, that aims to extract the globally optimal IE result as a graph from an input sentence. ONEIE performs end-to-end IE in four stages: (1) Encoding a given sentence as contextualized word representations; (2) Identifying entity mentions and event triggers as nodes; (3) Computing label scores for all nodes and their pairwise links using local classifiers; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our model and achieves new state-of-the-art on all subtasks. As ONEIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner. Our code and models for English, Spanish and Chinese are publicly available for research purpose 1 . PER Erdogan PER Abdullah Gul End-Position resigned Elect won person person Example: Prime Minister Abdullah Gul resigned earlier Tuesday to make way for Erdogan, who won a parliamentary seat in by-elections Sunday.","A Joint Neural Model for Information Extraction with Global Features Most existing joint neural models for Information Extraction (IE) use local task-specific classifiers to predict labels for individual instances (e.g., trigger, relation) regardless of their interactions. For example, a VICTIM of a DIE event is likely to be a VICTIM of an AT-TACK event in the same sentence. In order to capture such cross-subtask and cross-instance inter-dependencies, we propose a joint neural framework, ONEIE, that aims to extract the globally optimal IE result as a graph from an input sentence. ONEIE performs end-to-end IE in four stages: (1) Encoding a given sentence as contextualized word representations; (2) Identifying entity mentions and event triggers as nodes; (3) Computing label scores for all nodes and their pairwise links using local classifiers; (4) Searching for the globally optimal graph with a beam decoder. At the decoding stage, we incorporate global features to capture the cross-subtask and cross-instance interactions. Experiments show that adding global features improves the performance of our model and achieves new state-of-the-art on all subtasks. As ONEIE does not use any language-specific feature, we prove it can be easily applied to new languages or trained in a multilingual manner. Our code and models for English, Spanish and Chinese are publicly available for research purpose 1 . PER Erdogan PER Abdullah Gul End-Position resigned Elect won person person Example: Prime Minister Abdullah Gul resigned earlier Tuesday to make way for Erdogan, who won a parliamentary seat in by-elections Sunday.","joint neural model information extraction global feature exist joint neural model information extraction ( ie ) use local task - specific classifier predict label individual instance ( e.g. , trigger , relation ) regardless interaction . example , victim die event likely victim - tack event sentence . order capture cross - subtask cross - instance inter - dependency , propose joint neural framework , oneie , aim extract globally optimal ie result graph input sentence . oneie perform end - - end ie stage : ( 1 ) encode give sentence contextualize word representation ; ( 2 ) identify entity mention event trigger node ; ( 3 ) compute label score node pairwise link local classifier ; ( 4 ) search globally optimal graph beam decoder . decoding stage , incorporate global feature capture cross - subtask cross - instance interaction . experiment add global feature improve performance model achieve new state - - - art subtask . oneie use language - specific feature , prove easily apply new language train multilingual manner . code model english , spanish chinese publicly available research purpose 1 . erdogan abdullah gul end - position resign elect win person person example : prime minister abdullah gul resign early tuesday way erdogan , win parliamentary seat - election sunday .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Sources of Transfer in Multilingual Named Entity Recognition,"Named-entities are inherently multilingual, and annotations in any given language may be limited. This motivates us to consider polyglot named-entity recognition (NER), where one model is trained using annotated data drawn from more than one language. However, a straightforward implementation of this simple idea does not always work in practice: naive training of NER models using annotated data drawn from multiple languages consistently underperforms models trained on monolingual data alone, despite having access to more training data. The starting point of this paper is a simple solution to this problem, in which polyglot models are fine-tuned on monolingual data to consistently and significantly outperform their monolingual counterparts. To explain this phenomena, we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that fine-tuning may utilize a large number of those parameters.","Sources of Transfer in Multilingual Named Entity Recognition Named-entities are inherently multilingual, and annotations in any given language may be limited. This motivates us to consider polyglot named-entity recognition (NER), where one model is trained using annotated data drawn from more than one language. However, a straightforward implementation of this simple idea does not always work in practice: naive training of NER models using annotated data drawn from multiple languages consistently underperforms models trained on monolingual data alone, despite having access to more training data. The starting point of this paper is a simple solution to this problem, in which polyglot models are fine-tuned on monolingual data to consistently and significantly outperform their monolingual counterparts. To explain this phenomena, we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that fine-tuning may utilize a large number of those parameters.","source transfer multilingual name entity recognition name - entity inherently multilingual , annotation give language limited . motivate consider polyglot name - entity recognition ( ner ) , model train annotate datum draw language . , straightforward implementation simple idea work practice : naive training ner model annotate datum draw multiple language consistently underperform model train monolingual datum , despite have access training datum . starting point paper simple solution problem , polyglot model fine - tune monolingual datum consistently significantly outperform monolingual counterpart . explain phenomenon , explore source multilingual transfer polyglot ner model examine weight structure polyglot model compare monolingual counterpart . find polyglot model efficiently share parameter language fine - tuning utilize large number parameter .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Improving Candidate Generation for Low-resource Cross-lingual Entity Linking,"Cross-lingual entity linking (XEL) is the task of finding referents in a target-language knowledge base (KB) for mentions extracted from source-language texts. The first step of (X)EL is candidate generation, which retrieves a list of plausible candidate entities from the target-language KB for each mention. Approaches based on resources from Wikipedia have proven successful in the realm of relatively high-resource languages, but these do not extend well to low-resource languages with few, if any, Wikipedia pages. Recently, transfer learning methods have been shown to reduce the demand for resources in the lowresource languages by utilizing resources in closely related languages, but the performance still lags far behind their high-resource counterparts. In this paper, we first assess the problems faced by current entity candidate generation methods for low-resource XEL, then propose three improvements that (1) reduce the disconnect between entity mentions and KB entries, and (2) improve the robustness of the model to low-resource scenarios. The methods are simple, but effective: We experiment with our approach on seven XEL datasets and find that they yield an average gain of 16.9% in TOP-30 gold candidate recall, compared with state-of-the-art baselines. Our improved model also yields an average gain of 7.9% in in-KB accuracy of end-to-end XEL. 1","Improving Candidate Generation for Low-resource Cross-lingual Entity Linking Cross-lingual entity linking (XEL) is the task of finding referents in a target-language knowledge base (KB) for mentions extracted from source-language texts. The first step of (X)EL is candidate generation, which retrieves a list of plausible candidate entities from the target-language KB for each mention. Approaches based on resources from Wikipedia have proven successful in the realm of relatively high-resource languages, but these do not extend well to low-resource languages with few, if any, Wikipedia pages. Recently, transfer learning methods have been shown to reduce the demand for resources in the lowresource languages by utilizing resources in closely related languages, but the performance still lags far behind their high-resource counterparts. In this paper, we first assess the problems faced by current entity candidate generation methods for low-resource XEL, then propose three improvements that (1) reduce the disconnect between entity mentions and KB entries, and (2) improve the robustness of the model to low-resource scenarios. The methods are simple, but effective: We experiment with our approach on seven XEL datasets and find that they yield an average gain of 16.9% in TOP-30 gold candidate recall, compared with state-of-the-art baselines. Our improved model also yields an average gain of 7.9% in in-KB accuracy of end-to-end XEL. 1","improve candidate generation low - resource cross - lingual entity linking cross - lingual entity linking ( xel ) task find referent target - language knowledge base ( kb ) mention extract source - language text . step ( x)el candidate generation , retrieve list plausible candidate entity target - language kb mention . approach base resource wikipedia prove successful realm relatively high - resource language , extend low - resource language , , wikipedia page . recently , transfer learning method show reduce demand resource lowresource language utilize resource closely relate language , performance lag far high - resource counterpart . paper , assess problem face current entity candidate generation method low - resource xel , propose improvement ( 1 ) reduce disconnect entity mention kb entry , ( 2 ) improve robustness model low - resource scenario . method simple , effective : experiment approach seven xel dataset find yield average gain 16.9 % top-30 gold candidate recall , compare state - - - art baseline . improved model yield average gain 7.9 % - kb accuracy end - - end xel . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,MIE: A Medical Information Extractor towards Medical Dialogues,"Electronic Medical Records (EMRs) have become key components of modern medical care systems. Despite the merits of EMRs, many doctors suffer from writing them, which is time-consuming and tedious. We believe that automatically converting medical dialogues to EMRs can greatly reduce the burdens of doctors, and extracting information from medical dialogues is an essential step. To this end, we annotate online medical consultation dialogues in a window-sliding style, which is much easier than the sequential labeling annotation. We then propose a Medical Information Extractor (MIE) towards medical dialogues. MIE is able to extract mentioned symptoms, surgeries, tests, other information and their corresponding status. To tackle the particular challenges of the task, MIE uses a deep matching architecture, taking dialogue turn-interaction into account. The experimental results demonstrate MIE is a promising solution to extract medical information from doctor-patient dialogues. 1","MIE: A Medical Information Extractor towards Medical Dialogues Electronic Medical Records (EMRs) have become key components of modern medical care systems. Despite the merits of EMRs, many doctors suffer from writing them, which is time-consuming and tedious. We believe that automatically converting medical dialogues to EMRs can greatly reduce the burdens of doctors, and extracting information from medical dialogues is an essential step. To this end, we annotate online medical consultation dialogues in a window-sliding style, which is much easier than the sequential labeling annotation. We then propose a Medical Information Extractor (MIE) towards medical dialogues. MIE is able to extract mentioned symptoms, surgeries, tests, other information and their corresponding status. To tackle the particular challenges of the task, MIE uses a deep matching architecture, taking dialogue turn-interaction into account. The experimental results demonstrate MIE is a promising solution to extract medical information from doctor-patient dialogues. 1","mie : medical information extractor medical dialogue electronic medical record ( emrs ) key component modern medical care system . despite merit emr , doctor suffer write , time - consume tedious . believe automatically convert medical dialogue emr greatly reduce burden doctor , extract information medical dialogue essential step . end , annotate online medical consultation dialogue window - sliding style , easy sequential labeling annotation . propose medical information extractor ( mie ) medical dialogue . mie able extract mention symptom , surgery , test , information correspond status . tackle particular challenge task , mie use deep match architecture , take dialogue turn - interaction account . experimental result demonstrate mie promising solution extract medical information doctor - patient dialogue . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 15, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Information Extraction,Document-Level Event Role Filler Extraction using Multi-Granularity Contextualized Encoding,"Few works in the literature of event extraction have gone beyond individual sentences to make extraction decisions. This is problematic when the information needed to recognize an event argument is spread across multiple sentences. We argue that document-level event extraction is a difficult task since it requires a view of a larger context to determine which spans of text correspond to event role fillers. We first investigate how end-toend neural sequence models (with pre-trained language model representations) perform on document-level role filler extraction, as well as how the length of context captured affects the models' performance. To dynamically aggregate information captured by neural representations learned at different levels of granularity (e.g., the sentence-and paragraph-level), we propose a novel multi-granularity reader. We evaluate our models on the MUC-4 event extraction dataset, and show that our best system performs substantially better than prior work. We also report findings on the relationship between context length and neural model performance on the task.","Document-Level Event Role Filler Extraction using Multi-Granularity Contextualized Encoding Few works in the literature of event extraction have gone beyond individual sentences to make extraction decisions. This is problematic when the information needed to recognize an event argument is spread across multiple sentences. We argue that document-level event extraction is a difficult task since it requires a view of a larger context to determine which spans of text correspond to event role fillers. We first investigate how end-toend neural sequence models (with pre-trained language model representations) perform on document-level role filler extraction, as well as how the length of context captured affects the models' performance. To dynamically aggregate information captured by neural representations learned at different levels of granularity (e.g., the sentence-and paragraph-level), we propose a novel multi-granularity reader. We evaluate our models on the MUC-4 event extraction dataset, and show that our best system performs substantially better than prior work. We also report findings on the relationship between context length and neural model performance on the task.","document - level event role filler extraction multi - granularity contextualize encoding work literature event extraction go individual sentence extraction decision . problematic information need recognize event argument spread multiple sentence . argue document - level event extraction difficult task require view large context determine span text correspond event role filler . investigate end - toend neural sequence model ( pre - train language model representation ) perform document - level role filler extraction , length context capture affect model ' performance . dynamically aggregate information capture neural representation learn different level granularity ( e.g. , sentence - paragraph - level ) , propose novel multi - granularity reader . evaluate model muc-4 event extraction dataset , good system perform substantially well prior work . report finding relationship context length neural model performance task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 7, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,FLAT: Chinese NER Using Flat-Lattice Transformer,"Recently, the character-word lattice structure has been proved to be effective for Chinese named entity recognition (NER) by incorporating the word information. However, since the lattice structure is complex and dynamic, most existing lattice-based models are hard to fully utilize the parallel computation of GPUs and usually have a low inference-speed. In this paper, we propose FLAT: Flat-LAttice Transformer for Chinese NER, which converts the lattice structure into a flat structure consisting of spans. Each span corresponds to a character or latent word and its position in the original lattice. With the power of Transformer and well-designed position encoding, FLAT can fully leverage the lattice information and has an excellent parallelization ability. Experiments on four datasets show FLAT outperforms other lexicon-based models in performance and efficiency.","FLAT: Chinese NER Using Flat-Lattice Transformer Recently, the character-word lattice structure has been proved to be effective for Chinese named entity recognition (NER) by incorporating the word information. However, since the lattice structure is complex and dynamic, most existing lattice-based models are hard to fully utilize the parallel computation of GPUs and usually have a low inference-speed. In this paper, we propose FLAT: Flat-LAttice Transformer for Chinese NER, which converts the lattice structure into a flat structure consisting of spans. Each span corresponds to a character or latent word and its position in the original lattice. With the power of Transformer and well-designed position encoding, FLAT can fully leverage the lattice information and has an excellent parallelization ability. Experiments on four datasets show FLAT outperforms other lexicon-based models in performance and efficiency.","flat : chinese ner flat - lattice transformer recently , character - word lattice structure prove effective chinese name entity recognition ( ner ) incorporate word information . , lattice structure complex dynamic , exist lattice - base model hard fully utilize parallel computation gpu usually low inference - speed . paper , propose flat : flat - lattice transformer chinese ner , convert lattice structure flat structure consist span . span correspond character latent word position original lattice . power transformer - design position encoding , flat fully leverage lattice information excellent parallelization ability . experiment dataset flat outperform lexicon - base model performance efficiency .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 15, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 12, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,TriggerNER: Learning with Entity Triggers as Explanations for Named Entity Recognition,"Training neural models for named entity recognition (NER) in a new domain often requires additional human annotations that are usually expensive and time-consuming to collect. Thus, a crucial research question is how to obtain supervision in a cost-effective way. In this paper, we introduce ""entity triggers,"" an effective proxy of human explanations for facilitating label-efficient learning of NER models. An entity trigger is defined as a group of words in a sentence that helps to explain why humans would recognize an entity in the sentence. We crowd-sourced 14k entity triggers for two well-studied NER datasets 1 . Our proposed model, Trigger Matching Network, jointly learns trigger representations and soft matching module with self-attention such that can generalize to unseen sentences easily for tagging. The framework is significantly more cost-effective than the traditional frameworks.","TriggerNER: Learning with Entity Triggers as Explanations for Named Entity Recognition Training neural models for named entity recognition (NER) in a new domain often requires additional human annotations that are usually expensive and time-consuming to collect. Thus, a crucial research question is how to obtain supervision in a cost-effective way. In this paper, we introduce ""entity triggers,"" an effective proxy of human explanations for facilitating label-efficient learning of NER models. An entity trigger is defined as a group of words in a sentence that helps to explain why humans would recognize an entity in the sentence. We crowd-sourced 14k entity triggers for two well-studied NER datasets 1 . Our proposed model, Trigger Matching Network, jointly learns trigger representations and soft matching module with self-attention such that can generalize to unseen sentences easily for tagging. The framework is significantly more cost-effective than the traditional frameworks.","triggerner : learn entity trigger explanation name entity recognition training neural model name entity recognition ( ner ) new domain require additional human annotation usually expensive time - consume collect . , crucial research question obtain supervision cost - effective way . paper , introduce "" entity trigger , "" effective proxy human explanation facilitate label - efficient learning ner model . entity trigger define group word sentence help explain human recognize entity sentence . crowd - source 14k entity trigger - study ner dataset 1 . propose model , trigger matching network , jointly learn trigger representation soft matching module self - attention generalize unseen sentence easily tagging . framework significantly cost - effective traditional framework .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 27, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,SciREX: A Challenge Dataset for Document-Level Information Extraction,"Extracting information from full documents is an important problem in many domains, but most previous work focus on identifying relationships within a sentence or a paragraph. It is challenging to create a large-scale information extraction (IE) dataset at the document level since it requires an understanding of the whole document to annotate entities and their document-level relationships that usually span beyond sentences or even sections. In this paper, we introduce SCIREX, a document level IE dataset that encompasses multiple IE tasks, including salient entity identification and document level N -ary relation identification from scientific articles. We annotate our dataset by integrating automatic and human annotations, leveraging existing scientific knowledge resources. We develop a neural model as a strong baseline that extends previous state-of-the-art IE models to documentlevel IE. Analyzing the model performance shows a significant gap between human performance and current baselines, inviting the community to use our dataset as a challenge to develop document-level IE models. Our data and code are publicly available at https: //github.com/allenai/SciREX","SciREX: A Challenge Dataset for Document-Level Information Extraction Extracting information from full documents is an important problem in many domains, but most previous work focus on identifying relationships within a sentence or a paragraph. It is challenging to create a large-scale information extraction (IE) dataset at the document level since it requires an understanding of the whole document to annotate entities and their document-level relationships that usually span beyond sentences or even sections. In this paper, we introduce SCIREX, a document level IE dataset that encompasses multiple IE tasks, including salient entity identification and document level N -ary relation identification from scientific articles. We annotate our dataset by integrating automatic and human annotations, leveraging existing scientific knowledge resources. We develop a neural model as a strong baseline that extends previous state-of-the-art IE models to documentlevel IE. Analyzing the model performance shows a significant gap between human performance and current baselines, inviting the community to use our dataset as a challenge to develop document-level IE models. Our data and code are publicly available at https: //github.com/allenai/SciREX","scirex : challenge dataset document - level information extraction extract information document important problem domain , previous work focus identify relationship sentence paragraph . challenging create large - scale information extraction ( ie ) dataset document level require understanding document annotate entity document - level relationship usually span sentence section . paper , introduce scirex , document level ie dataset encompass multiple ie task , include salient entity identification document level n -ary relation identification scientific article . annotate dataset integrate automatic human annotation , leverage exist scientific knowledge resource . develop neural model strong baseline extend previous state - - - art ie model documentlevel ie . analyze model performance show significant gap human performance current baseline , invite community use dataset challenge develop document - level ie model . datum code publicly available https : //github.com / allenai / scirex","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 9, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Information Extraction,Named Entity Recognition as Dependency Parsing,"Named Entity Recognition (NER) is a fundamental task in Natural Language Processing, concerned with identifying spans of text expressing references to entities. NER research is often focused on flat entities only (flat NER), ignoring the fact that entity references can be nested, as in [Bank of [China]] (Finkel and Manning, 2009) . In this paper, we use ideas from graph-based dependency parsing to provide our model a global view on the input via a biaffine model (Dozat and Manning, 2017). The biaffine model scores pairs of start and end tokens in a sentence which we use to explore all spans, so that the model is able to predict named entities accurately. We show that the model works well for both nested and flat NER through evaluation on 8 corpora and achieving SoTA performance on all of them, with accuracy gains of up to 2.2 percentage points.","Named Entity Recognition as Dependency Parsing Named Entity Recognition (NER) is a fundamental task in Natural Language Processing, concerned with identifying spans of text expressing references to entities. NER research is often focused on flat entities only (flat NER), ignoring the fact that entity references can be nested, as in [Bank of [China]] (Finkel and Manning, 2009) . In this paper, we use ideas from graph-based dependency parsing to provide our model a global view on the input via a biaffine model (Dozat and Manning, 2017). The biaffine model scores pairs of start and end tokens in a sentence which we use to explore all spans, so that the model is able to predict named entities accurately. We show that the model works well for both nested and flat NER through evaluation on 8 corpora and achieving SoTA performance on all of them, with accuracy gains of up to 2.2 percentage points.","name entity recognition dependency parsing name entity recognition ( ner ) fundamental task natural language processing , concern identify span text express reference entity . ner research focus flat entity ( flat ner ) , ignore fact entity reference nest , [ bank [ china ] ] ( finkel manning , 2009 ) . paper , use idea graph - base dependency parsing provide model global view input biaffine model ( dozat manning , 2017 ) . biaffine model score pair start end token sentence use explore span , model able predict name entity accurately . model work nested flat ner evaluation 8 corpus achieve sota performance , accuracy gain 2.2 percentage point .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 23, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Soft Gazetteers for Low-Resource Named Entity Recognition,"Traditional named entity recognition models use gazetteers (lists of entities) as features to improve performance. Although modern neural network models do not require such handcrafted features for strong performance, recent work (Wu et al., 2018) has demonstrated their utility for named entity recognition on English data. However, designing such features for low-resource languages is challenging, because exhaustive entity gazetteers do not exist in these languages. To address this problem, we propose a method of ""soft gazetteers"" that incorporates ubiquitously available information from English knowledge bases, such as Wikipedia, into neural named entity recognition models through cross-lingual entity linking. Our experiments on four low-resource languages show an average improvement of 4 points in F1 score. 1","Soft Gazetteers for Low-Resource Named Entity Recognition Traditional named entity recognition models use gazetteers (lists of entities) as features to improve performance. Although modern neural network models do not require such handcrafted features for strong performance, recent work (Wu et al., 2018) has demonstrated their utility for named entity recognition on English data. However, designing such features for low-resource languages is challenging, because exhaustive entity gazetteers do not exist in these languages. To address this problem, we propose a method of ""soft gazetteers"" that incorporates ubiquitously available information from English knowledge bases, such as Wikipedia, into neural named entity recognition models through cross-lingual entity linking. Our experiments on four low-resource languages show an average improvement of 4 points in F1 score. 1","soft gazetteer low - resource name entity recognition traditional name entity recognition model use gazetteer ( list entity ) feature improve performance . modern neural network model require handcraft feature strong performance , recent work ( wu et al . , 2018 ) demonstrate utility name entity recognition english datum . , design feature low - resource language challenging , exhaustive entity gazetteer exist language . address problem , propose method "" soft gazetteer "" incorporate ubiquitously available information english knowledge basis , wikipedia , neural name entity recognition model cross - lingual entity linking . experiment low - resource language average improvement 4 point f1 score . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 23, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Relation Extraction with Explanation,"Recent neural models for relation extraction with distant supervision alleviate the impact of irrelevant sentences in a bag by learning importance weights for the sentences. Efforts thus far have focused on improving extraction accuracy but little is known about their explainability. In this work we annotate a test set with ground-truth sentence-level explanations to evaluate the quality of explanations afforded by the relation extraction models. We demonstrate that replacing the entity mentions in the sentences with their fine-grained entity types not only enhances extraction accuracy but also improves explanation. We also propose to automatically generate ""distractor"" sentences to augment the bags and train the model to ignore the distractors. Evaluations on the widely used FB-NYT dataset show that our methods achieve new state-of-the-art accuracy while improving model explainability.","Relation Extraction with Explanation Recent neural models for relation extraction with distant supervision alleviate the impact of irrelevant sentences in a bag by learning importance weights for the sentences. Efforts thus far have focused on improving extraction accuracy but little is known about their explainability. In this work we annotate a test set with ground-truth sentence-level explanations to evaluate the quality of explanations afforded by the relation extraction models. We demonstrate that replacing the entity mentions in the sentences with their fine-grained entity types not only enhances extraction accuracy but also improves explanation. We also propose to automatically generate ""distractor"" sentences to augment the bags and train the model to ignore the distractors. Evaluations on the widely used FB-NYT dataset show that our methods achieve new state-of-the-art accuracy while improving model explainability.","relation extraction explanation recent neural model relation extraction distant supervision alleviate impact irrelevant sentence bag learn importance weight sentence . effort far focus improve extraction accuracy little know explainability . work annotate test set ground - truth sentence - level explanation evaluate quality explanation afford relation extraction model . demonstrate replace entity mention sentence fine - grained entity type enhance extraction accuracy improve explanation . propose automatically generate "" distractor "" sentence augment bag train model ignore distractor . evaluation widely fb - nyt dataset method achieve new state - - - art accuracy improve model explainability .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,ZeroShotCeres: Zero-Shot Relation Extraction from Semi-Structured Webpages,"In many documents, such as semi-structured webpages, textual semantics are augmented with additional information conveyed using visual elements including layout, font size, and color. Prior work on information extraction from semi-structured websites has required learning an extraction model specific to a given template via either manually labeled or distantly supervised data from that template. In this work, we propose a solution for ""zero-shot"" open-domain relation extraction from webpages with a previously unseen template, including from websites with little overlap with existing sources of knowledge for distant supervision and websites in entirely new subject verticals. Our model uses a graph neural network-based approach to build a rich representation of text fields on a webpage and the relationships between them, enabling generalization to new templates. Experiments show this approach provides a 31% F1 gain over a baseline for zero-shot extraction in a new subject vertical.","ZeroShotCeres: Zero-Shot Relation Extraction from Semi-Structured Webpages In many documents, such as semi-structured webpages, textual semantics are augmented with additional information conveyed using visual elements including layout, font size, and color. Prior work on information extraction from semi-structured websites has required learning an extraction model specific to a given template via either manually labeled or distantly supervised data from that template. In this work, we propose a solution for ""zero-shot"" open-domain relation extraction from webpages with a previously unseen template, including from websites with little overlap with existing sources of knowledge for distant supervision and websites in entirely new subject verticals. Our model uses a graph neural network-based approach to build a rich representation of text fields on a webpage and the relationships between them, enabling generalization to new templates. Experiments show this approach provides a 31% F1 gain over a baseline for zero-shot extraction in a new subject vertical.","zeroshotceres : zero - shot relation extraction semi - structured webpage document , semi - structured webpage , textual semantic augment additional information convey visual element include layout , font size , color . prior work information extraction semi - structured website require learn extraction model specific give template manually label distantly supervise datum template . work , propose solution "" zero - shot "" open - domain relation extraction webpage previously unseen template , include website little overlap exist source knowledge distant supervision website entirely new subject vertical . model use graph neural network - base approach build rich representation text field webpage relationship , enable generalization new template . experiment approach provide 31 % f1 gain baseline zero - shot extraction new subject vertical .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Neighborhood Matching Network for Entity Alignment,"Structural heterogeneity between knowledge graphs is an outstanding challenge for entity alignment. This paper presents Neighborhood Matching Network (NMN), a novel entity alignment framework for tackling the structural heterogeneity challenge. NMN estimates the similarities between entities to capture both the topological structure and the neighborhood difference. It provides two innovative components for better learning representations for entity alignment. It first uses a novel graph sampling method to distill a discriminative neighborhood for each entity. It then adopts a cross-graph neighborhood matching module to jointly encode the neighborhood difference for a given entity pair. Such strategies allow NMN to effectively construct matchingoriented entity representations while ignoring noisy neighbors that have a negative impact on the alignment task. Extensive experiments performed on three entity alignment datasets show that NMN can well estimate the neighborhood similarity in more tough cases and significantly outperforms 12 previous state-ofthe-art methods.","Neighborhood Matching Network for Entity Alignment Structural heterogeneity between knowledge graphs is an outstanding challenge for entity alignment. This paper presents Neighborhood Matching Network (NMN), a novel entity alignment framework for tackling the structural heterogeneity challenge. NMN estimates the similarities between entities to capture both the topological structure and the neighborhood difference. It provides two innovative components for better learning representations for entity alignment. It first uses a novel graph sampling method to distill a discriminative neighborhood for each entity. It then adopts a cross-graph neighborhood matching module to jointly encode the neighborhood difference for a given entity pair. Such strategies allow NMN to effectively construct matchingoriented entity representations while ignoring noisy neighbors that have a negative impact on the alignment task. Extensive experiments performed on three entity alignment datasets show that NMN can well estimate the neighborhood similarity in more tough cases and significantly outperforms 12 previous state-ofthe-art methods.","neighborhood matching network entity alignment structural heterogeneity knowledge graph outstanding challenge entity alignment . paper present neighborhood matching network ( nmn ) , novel entity alignment framework tackle structural heterogeneity challenge . nmn estimate similarity entity capture topological structure neighborhood difference . provide innovative component well learn representation entity alignment . use novel graph sampling method distill discriminative neighborhood entity . adopt cross - graph neighborhood matching module jointly encode neighborhood difference give entity pair . strategy allow nmn effectively construct matchingoriente entity representation ignore noisy neighbor negative impact alignment task . extensive experiment perform entity alignment dataset nmn estimate neighborhood similarity tough case significantly outperform 12 previous state - ofthe - art method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,IMoJIE: Iterative Memory-Based Joint Open Information Extraction,"While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et al., 2018) . Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMOJIE, an extension to Copy-Attention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMOJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMOJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.","IMoJIE: Iterative Memory-Based Joint Open Information Extraction While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et al., 2018) . Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMOJIE, an extension to Copy-Attention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMOJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMOJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.","imojie : iterative memory - base joint open information extraction traditional system open information extraction statistical rule - base , recently neural model introduce task . work build copyattention , sequence generation openie model ( cui et al . , 2018 ) . analysis reveal copyattention produce constant number extraction sentence , extract tuple express redundant information . present imojie , extension copy - attention , produce extraction condition previously extract tuple . approach overcome shortcoming copyattention , result variable number diverse extraction sentence . train imojie training datum bootstrappe extraction non - neural system , automatically filter reduce redundancy noise . imojie outperform copyattention 18 f1 pt , bert - base strong baseline 2 f1 pt , establish new state art task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,"Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts","Concept graphs are created as universal taxonomies for text understanding in the open domain knowledge. The nodes in concept graphs include both entities and concepts. The edges are from entities to concepts, showing that an entity is an instance of a concept. In this paper, we propose the task of learning interpretable relationships from open domain facts to enrich and refine concept graphs. The Bayesian network structures are learned from open domain facts as the interpretable relationships between relations of facts and concepts of entities. We conduct extensive experiments on public English and Chinese datasets. Compared to the state-of-the-art methods, the learned network structures help improving the identification of concepts for entities based on the relations of entities on both English and Chinese datasets.","Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts Concept graphs are created as universal taxonomies for text understanding in the open domain knowledge. The nodes in concept graphs include both entities and concepts. The edges are from entities to concepts, showing that an entity is an instance of a concept. In this paper, we propose the task of learning interpretable relationships from open domain facts to enrich and refine concept graphs. The Bayesian network structures are learned from open domain facts as the interpretable relationships between relations of facts and concepts of entities. We conduct extensive experiments on public English and Chinese datasets. Compared to the state-of-the-art methods, the learned network structures help improving the identification of concepts for entities based on the relations of entities on both English and Chinese datasets.","learn interpretable relationship entity , relation concept bayesian structure learn open domain fact concept graph create universal taxonomy text understanding open domain knowledge . node concept graph include entity concept . edge entity concept , show entity instance concept . paper , propose task learn interpretable relationship open domain fact enrich refine concept graph . bayesian network structure learn open domain fact interpretable relationship relation fact concept entity . conduct extensive experiment public english chinese dataset . compare state - - - art method , learn network structure help improve identification concept entity base relation entity english chinese dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 13, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 9, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Synchronous Double-channel Recurrent Network for Aspect-Opinion Pair Extraction,"Opinion entity extraction is a fundamental task in fine-grained opinion mining. Related studies generally extract aspects and/or opinion expressions without recognizing the relations between them. However, the relations are crucial for downstream tasks, including sentiment classification, opinion summarization, etc. In this paper, we explore Aspect-Opinion Pair Extraction (AOPE) task, which aims at extracting aspects and opinion expressions in pairs. To deal with this task, we propose Synchronous Double-channel Recurrent Network (SDRN) mainly consisting of an opinion entity extraction unit, a relation detection unit, and a synchronization unit. The opinion entity extraction unit and the relation detection unit are developed as two channels to extract opinion entities and relations simultaneously. Furthermore, within the synchronization unit, we design Entity Synchronization Mechanism (ESM) and Relation Synchronization Mechanism (RSM) to enhance the mutual benefit on the above two channels. To verify the performance of SDRN, we manually build three datasets based on SemEval 2014 and 2015 benchmarks. Extensive experiments demonstrate that SDRN achieves state-of-the-art performances.","Synchronous Double-channel Recurrent Network for Aspect-Opinion Pair Extraction Opinion entity extraction is a fundamental task in fine-grained opinion mining. Related studies generally extract aspects and/or opinion expressions without recognizing the relations between them. However, the relations are crucial for downstream tasks, including sentiment classification, opinion summarization, etc. In this paper, we explore Aspect-Opinion Pair Extraction (AOPE) task, which aims at extracting aspects and opinion expressions in pairs. To deal with this task, we propose Synchronous Double-channel Recurrent Network (SDRN) mainly consisting of an opinion entity extraction unit, a relation detection unit, and a synchronization unit. The opinion entity extraction unit and the relation detection unit are developed as two channels to extract opinion entities and relations simultaneously. Furthermore, within the synchronization unit, we design Entity Synchronization Mechanism (ESM) and Relation Synchronization Mechanism (RSM) to enhance the mutual benefit on the above two channels. To verify the performance of SDRN, we manually build three datasets based on SemEval 2014 and 2015 benchmarks. Extensive experiments demonstrate that SDRN achieves state-of-the-art performances.","synchronous double - channel recurrent network aspect - opinion pair extraction opinion entity extraction fundamental task fine - grained opinion mining . related study generally extract aspect and/or opinion expression recognize relation . , relation crucial downstream task , include sentiment classification , opinion summarization , etc . paper , explore aspect - opinion pair extraction ( aope ) task , aim extract aspect opinion expression pair . deal task , propose synchronous double - channel recurrent network ( sdrn ) mainly consist opinion entity extraction unit , relation detection unit , synchronization unit . opinion entity extraction unit relation detection unit develop channel extract opinion entity relation simultaneously . furthermore , synchronization unit , design entity synchronization mechanism ( esm ) relation synchronization mechanism ( rsm ) enhance mutual benefit channel . verify performance sdrn , manually build dataset base semeval 2014 2015 benchmark . extensive experiment demonstrate sdrn achieve state - - - art performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 17, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 20, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Information Extraction,Continual Relation Learning via Episodic Memory Activation and Reconsolidation,"Continual relation learning aims to continually train a model on new data to learn incessantly emerging novel relations while avoiding catastrophically forgetting old relations. Some pioneering work has proved that storing a handful of historical relation examples in episodic memory and replaying them in subsequent training is an effective solution for such a challenging problem. However, these memorybased methods usually suffer from overfitting the few memorized examples of old relations, which may gradually cause inevitable confusion among existing relations. Inspired by the mechanism in human long-term memory formation, we introduce episodic memory activation and reconsolidation (EMAR) to continual relation learning. Every time neural models are activated to learn both new and memorized data, EMAR utilizes relation prototypes for memory reconsolidation exercise to keep a stable understanding of old relations. The experimental results show that EMAR could get rid of catastrophically forgetting old relations and outperform the state-of-the-art continual learning models. The code and datasets are released on https://github.com/thunlp/ ContinualRE.","Continual Relation Learning via Episodic Memory Activation and Reconsolidation Continual relation learning aims to continually train a model on new data to learn incessantly emerging novel relations while avoiding catastrophically forgetting old relations. Some pioneering work has proved that storing a handful of historical relation examples in episodic memory and replaying them in subsequent training is an effective solution for such a challenging problem. However, these memorybased methods usually suffer from overfitting the few memorized examples of old relations, which may gradually cause inevitable confusion among existing relations. Inspired by the mechanism in human long-term memory formation, we introduce episodic memory activation and reconsolidation (EMAR) to continual relation learning. Every time neural models are activated to learn both new and memorized data, EMAR utilizes relation prototypes for memory reconsolidation exercise to keep a stable understanding of old relations. The experimental results show that EMAR could get rid of catastrophically forgetting old relations and outperform the state-of-the-art continual learning models. The code and datasets are released on https://github.com/thunlp/ ContinualRE.","continual relation learning episodic memory activation reconsolidation continual relation learning aim continually train model new datum learn incessantly emerge novel relation avoid catastrophically forget old relation . pioneering work prove store handful historical relation example episodic memory replay subsequent training effective solution challenge problem . , memorybased method usually suffer overfitte memorize example old relation , gradually cause inevitable confusion exist relation . inspire mechanism human long - term memory formation , introduce episodic memory activation reconsolidation ( emar ) continual relation learning . time neural model activate learn new memorize datum , emar utilize relation prototype memory reconsolidation exercise stable understanding old relation . experimental result emar rid catastrophically forget old relation outperform state - - - art continual learning model . code dataset release https://github.com/thunlp/ continualre .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,"Amalgamation of protein sequence, structure and textual information for improving protein-protein interaction identification","An in-depth exploration of protein-protein interactions (PPI) is essential to understand the metabolism in addition to the regulations of biological entities like proteins, carbohydrates, and many more. Most of the recent PPI tasks in BioNLP domain have been carried out solely using textual data. In this paper, we argue that incorporation of multimodal cues can improve the automatic identification of PPI. As a first step towards enabling the development of multimodal approaches for PPI identification, we have developed two multimodal datasets which are extensions and multimodal versions of two popular benchmark PPI corpora (BioInfer and HRPD50). Besides, existing textual modalities, two new modalities, 3D protein structure and underlying genomic sequence, are also added to each instance. Further, a novel deep multi-modal architecture is also implemented to efficiently predict the protein interactions from the developed datasets. A detailed experimental analysis reveals the superiority of the multi-modal approach in comparison to the strong baselines including uni-modal approaches and state-of the-art methods over both the generated multimodal datasets. The developed multi-modal datasets are available for use at https:// github.com/sduttap16/MM_PPI_NLP.","Amalgamation of protein sequence, structure and textual information for improving protein-protein interaction identification An in-depth exploration of protein-protein interactions (PPI) is essential to understand the metabolism in addition to the regulations of biological entities like proteins, carbohydrates, and many more. Most of the recent PPI tasks in BioNLP domain have been carried out solely using textual data. In this paper, we argue that incorporation of multimodal cues can improve the automatic identification of PPI. As a first step towards enabling the development of multimodal approaches for PPI identification, we have developed two multimodal datasets which are extensions and multimodal versions of two popular benchmark PPI corpora (BioInfer and HRPD50). Besides, existing textual modalities, two new modalities, 3D protein structure and underlying genomic sequence, are also added to each instance. Further, a novel deep multi-modal architecture is also implemented to efficiently predict the protein interactions from the developed datasets. A detailed experimental analysis reveals the superiority of the multi-modal approach in comparison to the strong baselines including uni-modal approaches and state-of the-art methods over both the generated multimodal datasets. The developed multi-modal datasets are available for use at https:// github.com/sduttap16/MM_PPI_NLP.","amalgamation protein sequence , structure textual information improve protein - protein interaction identification - depth exploration protein - protein interaction ( ppi ) essential understand metabolism addition regulation biological entity like protein , carbohydrate , . recent ppi task bionlp domain carry solely textual datum . paper , argue incorporation multimodal cue improve automatic identification ppi . step enable development multimodal approach ppi identification , develop multimodal dataset extension multimodal version popular benchmark ppi corpus ( bioinfer hrpd50 ) . , existing textual modality , new modality , 3d protein structure underlie genomic sequence , add instance . , novel deep multi - modal architecture implement efficiently predict protein interaction develop dataset . detailed experimental analysis reveal superiority multi - modal approach comparison strong baseline include uni - modal approach state - - art method generate multimodal dataset . develop multi - modal dataset available use https:// github.com/sduttap16/mm_ppi_nlp .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 7, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Information Extraction,TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task,"TACRED (Zhang et al., 2017)  is one of the largest, most widely used crowdsourced datasets in Relation Extraction (RE). But, even with recent advances in unsupervised pretraining and knowledge enhanced neural RE, models still show a high error rate. In this paper, we investigate the questions: Have we reached a performance ceiling or is there still room for improvement? And how do crowd annotations, dataset, and models contribute to this error rate? To answer these questions, we first validate the most challenging 5K examples in the development and test sets using trained annotators. We find that label errors account for 8% absolute F1 test error, and that more than 50% of the examples need to be relabeled. On the relabeled test set the average F1 score of a large baseline model set improves from 62.1 to 70.1. After validation, we analyze misclassifications on the challenging instances, categorize them into linguistically motivated error groups, and verify the resulting error hypotheses on three state-of-the-art RE models. We show that two groups of ambiguous relations are responsible for most of the remaining errors and that models may adopt shallow heuristics on the dataset when entities are not masked.","TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task TACRED (Zhang et al., 2017)  is one of the largest, most widely used crowdsourced datasets in Relation Extraction (RE). But, even with recent advances in unsupervised pretraining and knowledge enhanced neural RE, models still show a high error rate. In this paper, we investigate the questions: Have we reached a performance ceiling or is there still room for improvement? And how do crowd annotations, dataset, and models contribute to this error rate? To answer these questions, we first validate the most challenging 5K examples in the development and test sets using trained annotators. We find that label errors account for 8% absolute F1 test error, and that more than 50% of the examples need to be relabeled. On the relabeled test set the average F1 score of a large baseline model set improves from 62.1 to 70.1. After validation, we analyze misclassifications on the challenging instances, categorize them into linguistically motivated error groups, and verify the resulting error hypotheses on three state-of-the-art RE models. We show that two groups of ambiguous relations are responsible for most of the remaining errors and that models may adopt shallow heuristics on the dataset when entities are not masked.","tacred revisit : thorough evaluation tacred relation extraction task tacred ( zhang et al . , 2017 )   large , widely crowdsource dataset relation extraction ( ) . , recent advance unsupervised pretraining knowledge enhance neural , model high error rate . paper , investigate question : reach performance ceiling room improvement ? crowd annotation , dataset , model contribute error rate ? answer question , validate challenging 5 k example development test set train annotator . find label error account 8 % absolute f1 test error , 50 % example need relabele . relabele test set average f1 score large baseline model set improve 62.1 70.1 . validation , analyze misclassification challenge instance , categorize linguistically motivated error group , verify result error hypothesis state - - - art model . group ambiguous relation responsible remain error model adopt shallow heuristic dataset entity mask .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 3, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Improving Entity Linking through Semantic Reinforced Entity Embeddings,"Entity embeddings, which represent different aspects of each entity with a single vector like word embeddings, are a key component of neural entity linking models. Existing entity embeddings are learned from canonical Wikipedia articles and local contexts surrounding target entities. Such entity embeddings are effective, but too distinctive for linking models to learn contextual commonality. We propose a simple yet effective method, FGS2EE, to inject fine-grained semantic information into entity embeddings to reduce the distinctiveness and facilitate the learning of contextual commonality. FGS2EE first uses the embeddings of semantic type words to generate semantic embeddings, and then combines them with existing entity embeddings through linear aggregation. Extensive experiments show the effectiveness of such embeddings. Based on our entity embeddings, we achieved new state-ofthe-art performance on entity linking.","Improving Entity Linking through Semantic Reinforced Entity Embeddings Entity embeddings, which represent different aspects of each entity with a single vector like word embeddings, are a key component of neural entity linking models. Existing entity embeddings are learned from canonical Wikipedia articles and local contexts surrounding target entities. Such entity embeddings are effective, but too distinctive for linking models to learn contextual commonality. We propose a simple yet effective method, FGS2EE, to inject fine-grained semantic information into entity embeddings to reduce the distinctiveness and facilitate the learning of contextual commonality. FGS2EE first uses the embeddings of semantic type words to generate semantic embeddings, and then combines them with existing entity embeddings through linear aggregation. Extensive experiments show the effectiveness of such embeddings. Based on our entity embeddings, we achieved new state-ofthe-art performance on entity linking.","improve entity linking semantic reinforce entity embedding entity embedding , represent different aspect entity single vector like word embedding , key component neural entity link model . exist entity embedding learn canonical wikipedia article local context surround target entity . entity embedding effective , distinctive link model learn contextual commonality . propose simple effective method , fgs2ee , inject fine - grained semantic information entity embedding reduce distinctiveness facilitate learning contextual commonality . fgs2ee use embedding semantic type word generate semantic embedding , combine exist entity embedding linear aggregation . extensive experiment effectiveness embedding . base entity embedding , achieve new state - ofthe - art performance entity linking .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 13, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,ReInceptionE: Relation-Aware Inception Network with Joint Local-Global Structural Information for Knowledge Graph Embedding,"The goal of Knowledge graph embedding (KGE) is to learn how to represent the lowdimensional vectors for entities and relations based on the observed triples. The conventional shallow models are limited to their expressiveness. ConvE (Dettmers et al., 2018)   takes advantage of CNN and improves the expressive power with parameter efficient operators by increasing the interactions between head and relation embeddings. However, there is no structural information in the embedding space of ConvE, and the performance is still limited by the number of interactions. The recent KBGAT (Nathani et al.,  2019)  provides another way to learn embeddings by adaptively utilizing structural information. In this paper, we take the benefits of ConvE and KBGAT together and propose a Relation-aware Inception network with joint local-global structural information for knowledge graph Embedding (ReInceptionE). Specifically, we first explore the Inception network to learn query embedding, which aims to further increase the interactions between head and relation embeddings. Then, we propose to use a relation-aware attention mechanism to enrich the query embedding with the local neighborhood and global entity information. Experimental results on both WN18RR and FB15k-237 datasets demonstrate that ReIncep-tionE achieves competitive performance compared with state-of-the-art methods.","ReInceptionE: Relation-Aware Inception Network with Joint Local-Global Structural Information for Knowledge Graph Embedding The goal of Knowledge graph embedding (KGE) is to learn how to represent the lowdimensional vectors for entities and relations based on the observed triples. The conventional shallow models are limited to their expressiveness. ConvE (Dettmers et al., 2018)   takes advantage of CNN and improves the expressive power with parameter efficient operators by increasing the interactions between head and relation embeddings. However, there is no structural information in the embedding space of ConvE, and the performance is still limited by the number of interactions. The recent KBGAT (Nathani et al.,  2019)  provides another way to learn embeddings by adaptively utilizing structural information. In this paper, we take the benefits of ConvE and KBGAT together and propose a Relation-aware Inception network with joint local-global structural information for knowledge graph Embedding (ReInceptionE). Specifically, we first explore the Inception network to learn query embedding, which aims to further increase the interactions between head and relation embeddings. Then, we propose to use a relation-aware attention mechanism to enrich the query embedding with the local neighborhood and global entity information. Experimental results on both WN18RR and FB15k-237 datasets demonstrate that ReIncep-tionE achieves competitive performance compared with state-of-the-art methods.","reinceptione : relation - aware inception network joint local - global structural information knowledge graph embedding goal knowledge graph embedding ( kge ) learn represent lowdimensional vector entity relation base observed triple . conventional shallow model limit expressiveness . conve ( dettmers et al . , 2018 )    take advantage cnn improve expressive power parameter efficient operator increase interaction head relation embedding . , structural information embedding space conve , performance limit number interaction . recent kbgat ( nathani et al . ,   2019 )   provide way learn embedding adaptively utilize structural information . paper , benefit conve kbgat propose relation - aware inception network joint local - global structural information knowledge graph embedding ( reinceptione ) . specifically , explore inception network learn query embedding , aim increase interaction head relation embedding . , propose use relation - aware attention mechanism enrich query embedding local neighborhood global entity information . experimental result wn18rr fb15k-237 dataset demonstrate reincep - tione achieve competitive performance compare state - - - art method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,Multi-Domain Named Entity Recognition with Genre-Aware and Agnostic Inference,"Named entity recognition is a key component of many text processing pipelines and it is thus essential for this component to be robust to different types of input. However, domain transfer of NER models with data from multiple genres has not been widely studied. To this end, we conduct NER experiments in three predictive setups on data from: a) multiple domains; b) multiple domains where the genre label is unknown at inference time; c) domains not encountered in training. We introduce a new architecture tailored to this task by using shared and private domain parameters and multi-task learning. This consistently outperforms all other baseline and competitive methods on all three experimental setups, with differences ranging between +1.95 to +3.11 average F1 across multiple genres when compared to standard approaches. These results illustrate the challenges that need to be taken into account when building real-world NLP applications that are robust to various types of text and the methods that can help, at least partially, alleviate these issues.","Multi-Domain Named Entity Recognition with Genre-Aware and Agnostic Inference Named entity recognition is a key component of many text processing pipelines and it is thus essential for this component to be robust to different types of input. However, domain transfer of NER models with data from multiple genres has not been widely studied. To this end, we conduct NER experiments in three predictive setups on data from: a) multiple domains; b) multiple domains where the genre label is unknown at inference time; c) domains not encountered in training. We introduce a new architecture tailored to this task by using shared and private domain parameters and multi-task learning. This consistently outperforms all other baseline and competitive methods on all three experimental setups, with differences ranging between +1.95 to +3.11 average F1 across multiple genres when compared to standard approaches. These results illustrate the challenges that need to be taken into account when building real-world NLP applications that are robust to various types of text and the methods that can help, at least partially, alleviate these issues.","multi - domain name entity recognition genre - aware agnostic inference name entity recognition key component text processing pipeline essential component robust different type input . , domain transfer ner model datum multiple genre widely study . end , conduct ner experiment predictive setup datum : ) multiple domain ; b ) multiple domain genre label unknown inference time ; c ) domain encounter training . introduce new architecture tailor task shared private domain parameter multi - task learning . consistently outperform baseline competitive method experimental setup , difference range +1.95 +3.11 average f1 multiple genre compare standard approach . result illustrate challenge need take account build real - world nlp application robust type text method help , partially , alleviate issue .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 2, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,NAT: Noise-Aware Training for Robust Neural Sequence Labeling,"Sequence labeling systems should perform reliably not only under ideal conditions but also with corrupted inputs-as these systems often process user-generated text or follow an errorprone upstream component. To this end, we formulate the noisy sequence labeling problem, where the input may undergo an unknown noising process and propose two Noise-Aware Training (NAT) objectives that improve robustness of sequence labeling performed on perturbed input: Our data augmentation method trains a neural model using a mixture of clean and noisy samples, whereas our stability training algorithm encourages the model to create a noise-invariant latent representation. We employ a vanilla noise model at training time. For evaluation, we use both the original data and its variants perturbed with real OCR errors and misspellings. Extensive experiments on English and German named entity recognition benchmarks confirmed that NAT consistently improved robustness of popular sequence labeling models, preserving accuracy on the original input. We make our code and data publicly available for the research community.","NAT: Noise-Aware Training for Robust Neural Sequence Labeling Sequence labeling systems should perform reliably not only under ideal conditions but also with corrupted inputs-as these systems often process user-generated text or follow an errorprone upstream component. To this end, we formulate the noisy sequence labeling problem, where the input may undergo an unknown noising process and propose two Noise-Aware Training (NAT) objectives that improve robustness of sequence labeling performed on perturbed input: Our data augmentation method trains a neural model using a mixture of clean and noisy samples, whereas our stability training algorithm encourages the model to create a noise-invariant latent representation. We employ a vanilla noise model at training time. For evaluation, we use both the original data and its variants perturbed with real OCR errors and misspellings. Extensive experiments on English and German named entity recognition benchmarks confirmed that NAT consistently improved robustness of popular sequence labeling models, preserving accuracy on the original input. We make our code and data publicly available for the research community.","nat : noise - aware training robust neural sequence labeling sequence labeling system perform reliably ideal condition corrupted input - system process user - generate text follow errorprone upstream component . end , formulate noisy sequence labeling problem , input undergo unknown noising process propose noise - aware training ( nat ) objective improve robustness sequence labeling perform perturbed input : data augmentation method train neural model mixture clean noisy sample , stability training algorithm encourage model create noise - invariant latent representation . employ vanilla noise model training time . evaluation , use original datum variant perturb real ocr error misspelling . extensive experiment english german name entity recognition benchmark confirm nat consistently improve robustness popular sequence labeling model , preserve accuracy original input . code datum publicly available research community .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,A Two-Stage Masked LM Method for Term Set Expansion,"We tackle the task of Term Set Expansion (TSE): given a small seed set of example terms from a semantic class, finding more members of that class. The task is of great practical utility, and also of theoretical utility as it requires generalization from few examples. Previous approaches to the TSE task can be characterized as either distributional or pattern-based. We harness the power of neural masked language models (MLM) and propose a novel TSE algorithm, which combines the pattern-based and distributional approaches. Due to the small size of the seed set, fine-tuning methods are not effective, calling for more creative use of the MLM. The gist of the idea is to use the MLM to first mine for informative patterns with respect to the seed set, and then to obtain more members of the seed class by generalizing these patterns. Our method outperforms stateof-the-art TSE algorithms. Implementation","A Two-Stage Masked LM Method for Term Set Expansion We tackle the task of Term Set Expansion (TSE): given a small seed set of example terms from a semantic class, finding more members of that class. The task is of great practical utility, and also of theoretical utility as it requires generalization from few examples. Previous approaches to the TSE task can be characterized as either distributional or pattern-based. We harness the power of neural masked language models (MLM) and propose a novel TSE algorithm, which combines the pattern-based and distributional approaches. Due to the small size of the seed set, fine-tuning methods are not effective, calling for more creative use of the MLM. The gist of the idea is to use the MLM to first mine for informative patterns with respect to the seed set, and then to obtain more members of the seed class by generalizing these patterns. Our method outperforms stateof-the-art TSE algorithms. Implementation","- stage mask lm method term set expansion tackle task term set expansion ( tse ): give small seed set example term semantic class , find member class . task great practical utility , theoretical utility require generalization example . previous approach tse task characterize distributional pattern - base . harness power neural mask language model ( mlm ) propose novel tse algorithm , combine pattern - base distributional approach . small size seed set , fine - tune method effective , call creative use mlm . gist idea use mlm informative pattern respect seed set , obtain member seed class generalize pattern . method outperform stateof - - art tse algorithm . implement","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Phonology, Morphology and Word Segmentation",False
Information Extraction,Machine Reading of Historical Events,"Machine reading is an ambitious goal in NLP that subsumes a wide range of text understanding capabilities. Within this broad framework, we address the task of machine reading the time of historical events, compile datasets for the task, and develop a model for tackling it. Given a brief textual description of an event, we show that good performance can be achieved by extracting relevant sentences from Wikipedia, and applying a combination of taskspecific and general-purpose feature embeddings for the classification. Furthermore, we establish a link between the historical event ordering task and the event focus time task from the information retrieval literature, showing they also provide a challenging test case for machine reading algorithms. 1","Machine Reading of Historical Events Machine reading is an ambitious goal in NLP that subsumes a wide range of text understanding capabilities. Within this broad framework, we address the task of machine reading the time of historical events, compile datasets for the task, and develop a model for tackling it. Given a brief textual description of an event, we show that good performance can be achieved by extracting relevant sentences from Wikipedia, and applying a combination of taskspecific and general-purpose feature embeddings for the classification. Furthermore, we establish a link between the historical event ordering task and the event focus time task from the information retrieval literature, showing they also provide a challenging test case for machine reading algorithms. 1","machine reading historical event machine reading ambitious goal nlp subsume wide range text understanding capability . broad framework , address task machine read time historical event , compile dataset task , develop model tackle . give brief textual description event , good performance achieve extract relevant sentence wikipedia , apply combination taskspecific general - purpose feature embedding classification . furthermore , establish link historical event ordering task event focus time task information retrieval literature , show provide challenging test case machine reading algorithm . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 6, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Information Extraction,Connecting Embeddings for Knowledge Graph Entity Typing,"Knowledge graph (KG) entity typing aims at inferring possible missing entity type instances in KG, which is a very significant but still under-explored subtask of knowledge graph completion. In this paper, we propose a novel approach for KG entity typing which is trained by jointly utilizing local typing knowledge from existing entity type assertions and global triple knowledge from KGs. Specifically, we present two distinct knowledge-driven effective mechanisms of entity type inference. Accordingly, we build two novel embedding models to realize the mechanisms. Afterward, a joint model with them is used to infer missing entity type instances, which favors inferences that agree with both entity type instances and triple knowledge in KGs. Experimental results on two real-world datasets (Freebase and YAGO) demonstrate the effectiveness of our proposed mechanisms and models for improving KG entity typing.","Connecting Embeddings for Knowledge Graph Entity Typing Knowledge graph (KG) entity typing aims at inferring possible missing entity type instances in KG, which is a very significant but still under-explored subtask of knowledge graph completion. In this paper, we propose a novel approach for KG entity typing which is trained by jointly utilizing local typing knowledge from existing entity type assertions and global triple knowledge from KGs. Specifically, we present two distinct knowledge-driven effective mechanisms of entity type inference. Accordingly, we build two novel embedding models to realize the mechanisms. Afterward, a joint model with them is used to infer missing entity type instances, which favors inferences that agree with both entity type instances and triple knowledge in KGs. Experimental results on two real-world datasets (Freebase and YAGO) demonstrate the effectiveness of our proposed mechanisms and models for improving KG entity typing.","connect embedding knowledge graph entity typing knowledge graph ( kg ) entity typing aim infer possible miss entity type instance kg , significant - explore subtask knowledge graph completion . paper , propose novel approach kg entity typing train jointly utilize local type knowledge exist entity type assertion global triple knowledge kgs . specifically , present distinct knowledge - drive effective mechanism entity type inference . accordingly , build novel embedding model realize mechanism . afterward , joint model infer miss entity type instance , favor inference agree entity type instance triple knowledge kgs . experimental result real - world dataset ( freebase yago ) demonstrate effectiveness propose mechanism model improve kg entity typing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Reasoning with Latent Structure Refinement for Document-Level Relation Extraction,"Document-level relation extraction requires integrating information within and across multiple sentences of a document and capturing complex interactions between inter-sentence entities. However, effective aggregation of relevant information in the document remains a challenging research question. Existing approaches construct static document-level graphs based on syntactic trees, co-references or heuristics from the unstructured text to model the dependencies. Unlike previous methods that may not be able to capture rich non-local interactions for inference, we propose a novel model that empowers the relational reasoning across sentences by automatically inducing the latent document-level graph. We further develop a refinement strategy, which enables the model to incrementally aggregate relevant information for multi-hop reasoning. Specifically, our model achieves an F 1 score of 59.05 on a large-scale documentlevel dataset (DocRED), significantly improving over the previous results, and also yields new state-of-the-art results on the CDR and GDA dataset. Furthermore, extensive analyses show that the model is able to discover more accurate inter-sentence relations.","Reasoning with Latent Structure Refinement for Document-Level Relation Extraction Document-level relation extraction requires integrating information within and across multiple sentences of a document and capturing complex interactions between inter-sentence entities. However, effective aggregation of relevant information in the document remains a challenging research question. Existing approaches construct static document-level graphs based on syntactic trees, co-references or heuristics from the unstructured text to model the dependencies. Unlike previous methods that may not be able to capture rich non-local interactions for inference, we propose a novel model that empowers the relational reasoning across sentences by automatically inducing the latent document-level graph. We further develop a refinement strategy, which enables the model to incrementally aggregate relevant information for multi-hop reasoning. Specifically, our model achieves an F 1 score of 59.05 on a large-scale documentlevel dataset (DocRED), significantly improving over the previous results, and also yields new state-of-the-art results on the CDR and GDA dataset. Furthermore, extensive analyses show that the model is able to discover more accurate inter-sentence relations.","reason latent structure refinement document - level relation extraction document - level relation extraction require integrate information multiple sentence document capture complex interaction inter - sentence entity . , effective aggregation relevant information document remain challenge research question . exist approach construct static document - level graph base syntactic tree , co - reference heuristic unstructured text model dependency . unlike previous method able capture rich non - local interaction inference , propose novel model empower relational reasoning sentence automatically induce latent document - level graph . develop refinement strategy , enable model incrementally aggregate relevant information multi - hop reasoning . specifically , model achieve f 1 score 59.05 large - scale documentlevel dataset ( docred ) , significantly improve previous result , yield new state - - - art result cdr gda dataset . furthermore , extensive analysis model able discover accurate inter - sentence relation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,A Generate-and-Rank Framework with Semantic Type Regularization for Biomedical Concept Normalization,"Concept normalization, the task of linking textual mentions of concepts to concepts in an ontology, is challenging because ontologies are large. In most cases, annotated datasets cover only a small sample of the concepts, yet concept normalizers are expected to predict all concepts in the ontology. In this paper, we propose an architecture consisting of a candidate generator and a list-wise ranker based on BERT. The ranker considers pairings of concept mentions and candidate concepts, allowing it to make predictions for any concept, not just those seen during training. We further enhance this list-wise approach with a semantic type regularizer that allows the model to incorporate semantic type information from the ontology during training. Our proposed concept normalization framework achieves stateof-the-art performance on multiple datasets.","A Generate-and-Rank Framework with Semantic Type Regularization for Biomedical Concept Normalization Concept normalization, the task of linking textual mentions of concepts to concepts in an ontology, is challenging because ontologies are large. In most cases, annotated datasets cover only a small sample of the concepts, yet concept normalizers are expected to predict all concepts in the ontology. In this paper, we propose an architecture consisting of a candidate generator and a list-wise ranker based on BERT. The ranker considers pairings of concept mentions and candidate concepts, allowing it to make predictions for any concept, not just those seen during training. We further enhance this list-wise approach with a semantic type regularizer that allows the model to incorporate semantic type information from the ontology during training. Our proposed concept normalization framework achieves stateof-the-art performance on multiple datasets.","generate - - rank framework semantic type regularization biomedical concept normalization concept normalization , task link textual mention concept concept ontology , challenging ontology large . case , annotate dataset cover small sample concept , concept normalizer expect predict concept ontology . paper , propose architecture consist candidate generator list - wise ranker base bert . ranker consider pairing concept mention candidate concept , allow prediction concept , see training . enhance list - wise approach semantic type regularizer allow model incorporate semantic type information ontology training . propose concept normalization framework achieve stateof - - art performance multiple dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 11, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Information Extraction,Simplify the Usage of Lexicon in Chinese NER,"Recently, many works have tried to augment the performance of Chinese named entity recognition (NER) using word lexicons. As a representative, Lattice-LSTM (Zhang and Yang, 2018) has achieved new benchmark results on several public Chinese NER datasets. However, Lattice-LSTM has a complex model architecture. This limits its application in many industrial areas where real-time NER responses are needed. In this work, we propose a simple but effective method for incorporating the word lexicon into the character representations. This method avoids designing a complicated sequence modeling architecture, and for any neural NER model, it requires only subtle adjustment of the character representation layer to introduce the lexicon information. Experimental studies on four benchmark Chinese NER datasets show that our method achieves an inference speed up to 6.15 times faster than those of state-ofthe-art methods, along with a better performance. The experimental results also show that the proposed method can be easily incorporated with pre-trained models like BERT. 1","Simplify the Usage of Lexicon in Chinese NER Recently, many works have tried to augment the performance of Chinese named entity recognition (NER) using word lexicons. As a representative, Lattice-LSTM (Zhang and Yang, 2018) has achieved new benchmark results on several public Chinese NER datasets. However, Lattice-LSTM has a complex model architecture. This limits its application in many industrial areas where real-time NER responses are needed. In this work, we propose a simple but effective method for incorporating the word lexicon into the character representations. This method avoids designing a complicated sequence modeling architecture, and for any neural NER model, it requires only subtle adjustment of the character representation layer to introduce the lexicon information. Experimental studies on four benchmark Chinese NER datasets show that our method achieves an inference speed up to 6.15 times faster than those of state-ofthe-art methods, along with a better performance. The experimental results also show that the proposed method can be easily incorporated with pre-trained models like BERT. 1","simplify usage lexicon chinese ner recently , work try augment performance chinese name entity recognition ( ner ) word lexicon . representative , lattice - lstm ( zhang yang , 2018 ) achieve new benchmark result public chinese ner dataset . , lattice - lstm complex model architecture . limit application industrial area real - time ner response need . work , propose simple effective method incorporate word lexicon character representation . method avoid design complicated sequence modeling architecture , neural ner model , require subtle adjustment character representation layer introduce lexicon information . experimental study benchmark chinese ner dataset method achieve inference speed 6.15 time fast state - ofthe - art method , well performance . experimental result propose method easily incorporate pre - trained model like bert . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 11, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,True
Information Extraction,Rationalizing Medical Relation Prediction from Corpus-level Statistics,"Nowadays, the interpretability of machine learning models is becoming increasingly important, especially in the medical domain. Aiming to shed some light on how to rationalize medical relation prediction, we present a new interpretable framework inspired by existing theories on how human memory works, e.g., theories of recall and recognition. Given the corpus-level statistics, i.e., a global cooccurrence graph of a clinical text corpus, to predict the relations between two entities, we first recall rich contexts associated with the target entities, and then recognize relational interactions between these contexts to form model rationales, which will contribute to the final prediction. We conduct experiments on a real-world public clinical dataset and show that our framework can not only achieve competitive predictive performance against a comprehensive list of neural baseline models, but also present rationales to justify its prediction. We further collaborate with medical experts deeply to verify the usefulness of our model rationales for clinical decision making 1 .","Rationalizing Medical Relation Prediction from Corpus-level Statistics Nowadays, the interpretability of machine learning models is becoming increasingly important, especially in the medical domain. Aiming to shed some light on how to rationalize medical relation prediction, we present a new interpretable framework inspired by existing theories on how human memory works, e.g., theories of recall and recognition. Given the corpus-level statistics, i.e., a global cooccurrence graph of a clinical text corpus, to predict the relations between two entities, we first recall rich contexts associated with the target entities, and then recognize relational interactions between these contexts to form model rationales, which will contribute to the final prediction. We conduct experiments on a real-world public clinical dataset and show that our framework can not only achieve competitive predictive performance against a comprehensive list of neural baseline models, but also present rationales to justify its prediction. We further collaborate with medical experts deeply to verify the usefulness of our model rationales for clinical decision making 1 .","rationalize medical relation prediction corpus - level statistic nowadays , interpretability machine learning model increasingly important , especially medical domain . aim shed light rationalize medical relation prediction , present new interpretable framework inspire exist theory human memory work , e.g. , theory recall recognition . give corpus - level statistic , i.e. , global cooccurrence graph clinical text corpus , predict relation entity , recall rich context associate target entity , recognize relational interaction context form model rationale , contribute final prediction . conduct experiment real - world public clinical dataset framework achieve competitive predictive performance comprehensive list neural baseline model , present rationale justify prediction . collaborate medical expert deeply verify usefulness model rationale clinical decision making 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Extraction,A Two-Step Approach for Implicit Event Argument Detection,"In this work, we explore the implicit event argument detection task, which studies event arguments beyond sentence boundaries. The addition of cross-sentence argument candidates imposes great challenges for modeling. To reduce the number of candidates, we adopt a two-step approach, decomposing the problem into two sub-problems: argument head-word detection and head-to-span expansion. Evaluated on the recent RAMS dataset (Ebner et al., 2020), our model achieves overall better performance than a strong sequence labeling baseline. We further provide detailed error analysis, presenting where the model mainly makes errors and indicating directions for future improvements. It remains a challenge to detect implicit arguments, calling for more future work of document-level modeling for this task.","A Two-Step Approach for Implicit Event Argument Detection In this work, we explore the implicit event argument detection task, which studies event arguments beyond sentence boundaries. The addition of cross-sentence argument candidates imposes great challenges for modeling. To reduce the number of candidates, we adopt a two-step approach, decomposing the problem into two sub-problems: argument head-word detection and head-to-span expansion. Evaluated on the recent RAMS dataset (Ebner et al., 2020), our model achieves overall better performance than a strong sequence labeling baseline. We further provide detailed error analysis, presenting where the model mainly makes errors and indicating directions for future improvements. It remains a challenge to detect implicit arguments, calling for more future work of document-level modeling for this task.","- step approach implicit event argument detection work , explore implicit event argument detection task , study event argument sentence boundary . addition cross - sentence argument candidate impose great challenge modeling . reduce number candidate , adopt - step approach , decompose problem sub - problem : argument head - word detection head - - span expansion . evaluate recent rams dataset ( ebner et al . , 2020 ) , model achieve overall well performance strong sequence labeling baseline . provide detailed error analysis , present model mainly make error indicate direction future improvement . remain challenge detect implicit argument , call future work document - level modeling task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Information Retrieval and Text Mining,A Joint Model for Document Segmentation and Segment Labeling,"Text segmentation aims to uncover latent structure by dividing text from a document into coherent sections. Where previous work on text segmentation considers the tasks of document segmentation and segment labeling separately, we show that the tasks contain complementary information and are best addressed jointly. We introduce the Segment Pooling LSTM (S-LSTM) model, which is capable of jointly segmenting a document and labeling segments. In support of joint training, we develop a method for teaching the model to recover from errors by aligning the predicted and ground truth segments. We show that S-LSTM reduces segmentation error by 30% on average, while also improving segment labeling.","A Joint Model for Document Segmentation and Segment Labeling Text segmentation aims to uncover latent structure by dividing text from a document into coherent sections. Where previous work on text segmentation considers the tasks of document segmentation and segment labeling separately, we show that the tasks contain complementary information and are best addressed jointly. We introduce the Segment Pooling LSTM (S-LSTM) model, which is capable of jointly segmenting a document and labeling segments. In support of joint training, we develop a method for teaching the model to recover from errors by aligning the predicted and ground truth segments. We show that S-LSTM reduces segmentation error by 30% on average, while also improving segment labeling.","joint model document segmentation segment labeling text segmentation aim uncover latent structure divide text document coherent section . previous work text segmentation consider task document segmentation segment labeling separately , task contain complementary information well address jointly . introduce segment pooling lstm ( s - lstm ) model , capable jointly segment document label segment . support joint training , develop method teach model recover error align predict ground truth segment . s - lstm reduce segmentation error 30 % average , improve segment labeling .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Contextualized Weak Supervision for Text Classification,"Weakly supervised text classification based on a few user-provided seed words has recently attracted much attention from researchers. Existing methods mainly generate pseudo-labels in a context-free manner (e.g., string matching), therefore, the ambiguous, context-dependent nature of human language has been long overlooked. In this paper, we propose a novel framework ConWea, providing contextualized weak supervision for text classification. Specifically, we leverage contextualized representations of word occurrences and seed word information to automatically differentiate multiple interpretations of the same word, and thus create a contextualized corpus. This contextualized corpus is further utilized to train the classifier and expand seed words in an iterative manner. This process not only adds new contextualized, highly label-indicative keywords but also disambiguates initial seed words, making our weak supervision fully contextualized. Extensive experiments and case studies on real-world datasets demonstrate the necessity and significant advantages of using contextualized weak supervision, especially when the class labels are fine-grained.","Contextualized Weak Supervision for Text Classification Weakly supervised text classification based on a few user-provided seed words has recently attracted much attention from researchers. Existing methods mainly generate pseudo-labels in a context-free manner (e.g., string matching), therefore, the ambiguous, context-dependent nature of human language has been long overlooked. In this paper, we propose a novel framework ConWea, providing contextualized weak supervision for text classification. Specifically, we leverage contextualized representations of word occurrences and seed word information to automatically differentiate multiple interpretations of the same word, and thus create a contextualized corpus. This contextualized corpus is further utilized to train the classifier and expand seed words in an iterative manner. This process not only adds new contextualized, highly label-indicative keywords but also disambiguates initial seed words, making our weak supervision fully contextualized. Extensive experiments and case studies on real-world datasets demonstrate the necessity and significant advantages of using contextualized weak supervision, especially when the class labels are fine-grained.","contextualized weak supervision text classification weakly supervise text classification base user - provide seed word recently attract attention researcher . exist method mainly generate pseudo - label context - free manner ( e.g. , string matching ) , , ambiguous , context - dependent nature human language long overlook . paper , propose novel framework conwea , provide contextualize weak supervision text classification . specifically , leverage contextualized representation word occurrence seed word information automatically differentiate multiple interpretation word , create contextualized corpus . contextualize corpus utilize train classifier expand seed word iterative manner . process add new contextualize , highly label - indicative keyword disambiguate initial seed word , make weak supervision fully contextualize . extensive experiment case study real - world dataset demonstrate necessity significant advantage contextualize weak supervision , especially class label fine - grained .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 14, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Retrieval and Text Mining,Keyphrase Generation for Scientific Document Retrieval,"Sequence-to-sequence models have lead to significant progress in keyphrase generation, but it remains unknown whether they are reliable enough to be beneficial for document retrieval. This study provides empirical evidence that such models can significantly improve retrieval performance, and introduces a new extrinsic evaluation framework that allows for a better understanding of the limitations of keyphrase generation models. Using this framework, we point out and discuss the difficulties encountered with supplementing documents with -not present in textkeyphrases, and generalizing models across domains. Our code is available at https:// github.com/boudinfl/ir-using-kg.","Keyphrase Generation for Scientific Document Retrieval Sequence-to-sequence models have lead to significant progress in keyphrase generation, but it remains unknown whether they are reliable enough to be beneficial for document retrieval. This study provides empirical evidence that such models can significantly improve retrieval performance, and introduces a new extrinsic evaluation framework that allows for a better understanding of the limitations of keyphrase generation models. Using this framework, we point out and discuss the difficulties encountered with supplementing documents with -not present in textkeyphrases, and generalizing models across domains. Our code is available at https:// github.com/boudinfl/ir-using-kg.","keyphrase generation scientific document retrieval sequence - - sequence model lead significant progress keyphrase generation , remain unknown reliable beneficial document retrieval . study provide empirical evidence model significantly improve retrieval performance , introduce new extrinsic evaluation framework allow well understanding limitation keyphrase generation model . framework , point discuss difficulty encounter supplement document -not present textkeyphrase , generalize model domain . code available https:// github.com/boudinfl/ir-using-kg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 10, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Hierarchy-Aware Global Model for Hierarchical Text Classification,"Hierarchical text classification is an essential yet challenging subtask of multi-label text classification with a taxonomic hierarchy. Existing methods have difficulties in modeling the hierarchical label structure in a global view. Furthermore, they cannot make full use of the mutual interactions between the text feature space and the label space. In this paper, we formulate the hierarchy as a directed graph and introduce hierarchy-aware structure encoders for modeling label dependencies. Based on the hierarchy encoder, we propose a novel end-to-end hierarchy-aware global model (Hi-AGM) with two variants. A multi-label attention variant (HiAGM-LA) learns hierarchyaware label embeddings through the hierarchy encoder and conducts inductive fusion of labelaware text features. A text feature propagation model (HiAGM-TP) is proposed as the deductive variant that directly feeds text features into hierarchy encoders. Compared with previous works, both HiAGM-LA and HiAGM-TP achieve significant and consistent improvements on three benchmark datasets.","Hierarchy-Aware Global Model for Hierarchical Text Classification Hierarchical text classification is an essential yet challenging subtask of multi-label text classification with a taxonomic hierarchy. Existing methods have difficulties in modeling the hierarchical label structure in a global view. Furthermore, they cannot make full use of the mutual interactions between the text feature space and the label space. In this paper, we formulate the hierarchy as a directed graph and introduce hierarchy-aware structure encoders for modeling label dependencies. Based on the hierarchy encoder, we propose a novel end-to-end hierarchy-aware global model (Hi-AGM) with two variants. A multi-label attention variant (HiAGM-LA) learns hierarchyaware label embeddings through the hierarchy encoder and conducts inductive fusion of labelaware text features. A text feature propagation model (HiAGM-TP) is proposed as the deductive variant that directly feeds text features into hierarchy encoders. Compared with previous works, both HiAGM-LA and HiAGM-TP achieve significant and consistent improvements on three benchmark datasets.","hierarchy - aware global model hierarchical text classification hierarchical text classification essential challenging subtask multi - label text classification taxonomic hierarchy . exist method difficulty model hierarchical label structure global view . furthermore , use mutual interaction text feature space label space . paper , formulate hierarchy direct graph introduce hierarchy - aware structure encoder model label dependency . base hierarchy encoder , propose novel end - - end hierarchy - aware global model ( hi - agm ) variant . multi - label attention variant ( hiagm - la ) learn hierarchyaware label embedding hierarchy encoder conduct inductive fusion labelaware text feature . text feature propagation model ( hiagm - tp ) propose deductive variant directly feed text feature hierarchy encoder . compare previous work , hiagm - la hiagm - tp achieve significant consistent improvement benchmark dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 18, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 9}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Empower Entity Set Expansion via Language Model Probing,"Entity set expansion, aiming at expanding a small seed entity set with new entities belonging to the same semantic class, is a critical task that benefits many downstream NLP and IR applications, such as question answering, query understanding, and taxonomy construction. Existing set expansion methods bootstrap the seed entity set by adaptively selecting context features and extracting new entities. A key challenge for entity set expansion is to avoid selecting ambiguous context features which will shift the class semantics and lead to accumulative errors in later iterations. In this study, we propose a novel iterative set expansion framework that leverages automatically generated class names to address the semantic drift issue. In each iteration, we select one positive and several negative class names by probing a pre-trained language model, and further score each candidate entity based on selected class names. Experiments on two datasets show that our framework generates high-quality class names and outperforms previous state-of-the-art methods significantly.","Empower Entity Set Expansion via Language Model Probing Entity set expansion, aiming at expanding a small seed entity set with new entities belonging to the same semantic class, is a critical task that benefits many downstream NLP and IR applications, such as question answering, query understanding, and taxonomy construction. Existing set expansion methods bootstrap the seed entity set by adaptively selecting context features and extracting new entities. A key challenge for entity set expansion is to avoid selecting ambiguous context features which will shift the class semantics and lead to accumulative errors in later iterations. In this study, we propose a novel iterative set expansion framework that leverages automatically generated class names to address the semantic drift issue. In each iteration, we select one positive and several negative class names by probing a pre-trained language model, and further score each candidate entity based on selected class names. Experiments on two datasets show that our framework generates high-quality class names and outperforms previous state-of-the-art methods significantly.","empower entity set expansion language model probe entity set expansion , aim expand small seed entity set new entity belong semantic class , critical task benefit downstream nlp ir application , question answering , query understanding , taxonomy construction . exist set expansion method bootstrap seed entity set adaptively select context feature extract new entity . key challenge entity set expansion avoid select ambiguous context feature shift class semantic lead accumulative error later iteration . study , propose novel iterative set expansion framework leverage automatically generate class name address semantic drift issue . iteration , select positive negative class name probe pre - trained language model , score candidate entity base select class name . experiment dataset framework generate high - quality class name outperform previous state - - - art method significantly .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 14, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Information Retrieval and Text Mining,Text Classification with Negative Supervision,"Advanced pre-trained models for text representation have achieved state-of-the-art performance on various text classification tasks. However, the discrepancy between the semantic similarity of texts and labelling standards affects classifiers, i.e. leading to lower performance in cases where classifiers should assign different labels to semantically similar texts. To address this problem, we propose a simple multitask learning model that uses negative supervision. Specifically, our model encourages texts with different labels to have distinct representations. Comprehensive experiments show that our model outperforms the stateof-the-art pre-trained model on both singleand multi-label classifications, sentence and document classifications, and classifications in three different languages.","Text Classification with Negative Supervision Advanced pre-trained models for text representation have achieved state-of-the-art performance on various text classification tasks. However, the discrepancy between the semantic similarity of texts and labelling standards affects classifiers, i.e. leading to lower performance in cases where classifiers should assign different labels to semantically similar texts. To address this problem, we propose a simple multitask learning model that uses negative supervision. Specifically, our model encourages texts with different labels to have distinct representations. Comprehensive experiments show that our model outperforms the stateof-the-art pre-trained model on both singleand multi-label classifications, sentence and document classifications, and classifications in three different languages.","text classification negative supervision advanced pre - trained model text representation achieve state - - - art performance text classification task . , discrepancy semantic similarity text labelling standard affect classifier , i.e. lead low performance case classifier assign different label semantically similar text . address problem , propose simple multitask learning model use negative supervision . specifically , model encourage text different label distinct representation . comprehensive experiment model outperform stateof - - art pre - trained model singleand multi - label classification , sentence document classification , classification different language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Information Retrieval and Text Mining,Learning Robust Models for e-Commerce Product Search,"Showing items that do not match search query intent degrades customer experience in ecommerce. These mismatches result from counterfactual biases of the ranking algorithms toward noisy behavioral signals such as clicks and purchases in the search logs. Mitigating the problem requires a large labeled dataset, which is expensive and time-consuming to obtain. In this paper, we develop a deep, endto-end model that learns to effectively classify mismatches and to generate hard mismatched examples to improve the classifier. We train the model end-to-end by introducing a latent variable into the cross-entropy loss that alternates between using the real and generated samples. This not only makes the classifier more robust but also boosts the overall ranking performance. Our model achieves a relative gain compared to baselines by over 26% in F-score, and over 17% in Area Under PR curve. On live search traffic, our model gains significant improvement in multiple countries.","Learning Robust Models for e-Commerce Product Search Showing items that do not match search query intent degrades customer experience in ecommerce. These mismatches result from counterfactual biases of the ranking algorithms toward noisy behavioral signals such as clicks and purchases in the search logs. Mitigating the problem requires a large labeled dataset, which is expensive and time-consuming to obtain. In this paper, we develop a deep, endto-end model that learns to effectively classify mismatches and to generate hard mismatched examples to improve the classifier. We train the model end-to-end by introducing a latent variable into the cross-entropy loss that alternates between using the real and generated samples. This not only makes the classifier more robust but also boosts the overall ranking performance. Our model achieves a relative gain compared to baselines by over 26% in F-score, and over 17% in Area Under PR curve. On live search traffic, our model gains significant improvement in multiple countries.","learn robust model e - commerce product search show item match search query intent degrade customer experience ecommerce . mismatch result counterfactual bias rank algorithm noisy behavioral signal click purchase search log . mitigate problem require large label dataset , expensive time - consume obtain . paper , develop deep , endto - end model learn effectively classify mismatch generate hard mismatched example improve classifier . train model end - - end introduce latent variable cross - entropy loss alternate real generate sample . make classifier robust boost overall ranking performance . model achieve relative gain compare baseline 26 % f - score , 17 % area pr curve . live search traffic , model gain significant improvement multiple country .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Information Retrieval and Text Mining,Tree-Structured Neural Topic Model,"This paper presents a tree-structured neural topic model, which has a topic distribution over a tree with an infinite number of branches. Our model parameterizes an unbounded ancestral and fraternal topic distribution by applying doubly-recurrent neural networks. With the help of autoencoding variational Bayes, our model improves data scalability and achieves competitive performance when inducing latent topics and tree structures, as compared to a prior tree-structured topic model (Blei et al., 2010) . This work extends the tree-structured topic model such that it can be incorporated with neural models for downstream tasks.","Tree-Structured Neural Topic Model This paper presents a tree-structured neural topic model, which has a topic distribution over a tree with an infinite number of branches. Our model parameterizes an unbounded ancestral and fraternal topic distribution by applying doubly-recurrent neural networks. With the help of autoencoding variational Bayes, our model improves data scalability and achieves competitive performance when inducing latent topics and tree structures, as compared to a prior tree-structured topic model (Blei et al., 2010) . This work extends the tree-structured topic model such that it can be incorporated with neural models for downstream tasks.","tree - structured neural topic model paper present tree - structured neural topic model , topic distribution tree infinite number branch . model parameterize unbounded ancestral fraternal topic distribution apply doubly - recurrent neural network . help autoencode variational baye , model improve data scalability achieve competitive performance induce latent topic tree structure , compare prior tree - structured topic model ( blei et al . , 2010 ) . work extend tree - structured topic model incorporate neural model downstream task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 11, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Generative Semantic Hashing Enhanced via Boltzmann Machines,"Generative semantic hashing is a promising technique for large-scale information retrieval thanks to its fast retrieval speed and small memory footprint. For the tractability of training, existing generative-hashing methods mostly assume a factorized form for the posterior distribution, enforcing independence among the bits of hash codes. From the perspectives of both model representation and code space size, independence is always not the best assumption. In this paper, to introduce correlations among the bits of hash codes, we propose to employ the distribution of Boltzmann machine as the variational posterior. To address the intractability issue of training, we first develop an approximate method to reparameterize the distribution of a Boltzmann machine by augmenting it as a hierarchical concatenation of a Gaussian-like distribution and a Bernoulli distribution. Based on that, an asymptotically-exact lower bound is further derived for the evidence lower bound (ELBO). With these novel techniques, the entire model can be optimized efficiently. Extensive experimental results demonstrate that by effectively modeling correlations among different bits within a hash code, our model can achieve significant performance gains.","Generative Semantic Hashing Enhanced via Boltzmann Machines Generative semantic hashing is a promising technique for large-scale information retrieval thanks to its fast retrieval speed and small memory footprint. For the tractability of training, existing generative-hashing methods mostly assume a factorized form for the posterior distribution, enforcing independence among the bits of hash codes. From the perspectives of both model representation and code space size, independence is always not the best assumption. In this paper, to introduce correlations among the bits of hash codes, we propose to employ the distribution of Boltzmann machine as the variational posterior. To address the intractability issue of training, we first develop an approximate method to reparameterize the distribution of a Boltzmann machine by augmenting it as a hierarchical concatenation of a Gaussian-like distribution and a Bernoulli distribution. Based on that, an asymptotically-exact lower bound is further derived for the evidence lower bound (ELBO). With these novel techniques, the entire model can be optimized efficiently. Extensive experimental results demonstrate that by effectively modeling correlations among different bits within a hash code, our model can achieve significant performance gains.","generative semantic hashing enhance boltzmann machines generative semantic hashing promising technique large - scale information retrieval thank fast retrieval speed small memory footprint . tractability training , exist generative - hashing method assume factorize form posterior distribution , enforce independence bit hash code . perspective model representation code space size , independence good assumption . paper , introduce correlation bit hash code , propose employ distribution boltzmann machine variational posterior . address intractability issue training , develop approximate method reparameterize distribution boltzmann machine augment hierarchical concatenation gaussian - like distribution bernoulli distribution . base , asymptotically - exact low bound derive evidence low bound ( elbo ) . novel technique , entire model optimize efficiently . extensive experimental result demonstrate effectively model correlation different bit hash code , model achieve significant performance gain .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Information Retrieval and Text Mining,Interactive Construction of User-Centric Dictionary for Text Analytics,"We propose a methodology to construct a term dictionary for text analytics through an interactive process between a human and a machine. The interactive approach helps the creation of flexible dictionaries with precise granularity required in text analysis. This paper introduces the first formulation of interactive dictionary construction to address this issue. To optimize the interaction, we propose a new algorithm that effectively captures an analyst's intention starting from only a small number of sample terms. Along with the algorithm, we also design an automatic evaluation framework that provides a systematic assessment of any interactive method for the dictionary creation task. Experiments using real scenario based corpora and dictionaries show that our algorithm outperforms baseline methods, and works even with a small number of interactions. Also, we provide our dataset for future studies 1 .","Interactive Construction of User-Centric Dictionary for Text Analytics We propose a methodology to construct a term dictionary for text analytics through an interactive process between a human and a machine. The interactive approach helps the creation of flexible dictionaries with precise granularity required in text analysis. This paper introduces the first formulation of interactive dictionary construction to address this issue. To optimize the interaction, we propose a new algorithm that effectively captures an analyst's intention starting from only a small number of sample terms. Along with the algorithm, we also design an automatic evaluation framework that provides a systematic assessment of any interactive method for the dictionary creation task. Experiments using real scenario based corpora and dictionaries show that our algorithm outperforms baseline methods, and works even with a small number of interactions. Also, we provide our dataset for future studies 1 .","interactive construction user - centric dictionary text analytic propose methodology construct term dictionary text analytic interactive process human machine . interactive approach help creation flexible dictionary precise granularity require text analysis . paper introduce formulation interactive dictionary construction address issue . optimize interaction , propose new algorithm effectively capture analyst intention start small number sample term . algorithm , design automatic evaluation framework provide systematic assessment interactive method dictionary creation task . experiment real scenario base corpus dictionary algorithm outperform baseline method , work small number interaction . , provide dataset future study 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 7, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Information Retrieval and Text Mining,Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks,"Text classification is fundamental in natural language processing (NLP), and Graph Neural Networks (GNN) are recently applied in this task. However, the existing graph-based works can neither capture the contextual word relationships within each document nor fulfil the inductive learning of new words. In this work, to overcome such problems, we propose TextING 1 for inductive text classification via GNN. We first build individual graphs for each document and then use GNN to learn the finegrained word representations based on their local structures, which can also effectively produce embeddings for unseen words in the new document. Finally, the word nodes are incorporated as the document embedding. Extensive experiments on four benchmark datasets show that our method outperforms state-of-theart text classification methods.","Every Document Owns Its Structure: Inductive Text Classification via Graph Neural Networks Text classification is fundamental in natural language processing (NLP), and Graph Neural Networks (GNN) are recently applied in this task. However, the existing graph-based works can neither capture the contextual word relationships within each document nor fulfil the inductive learning of new words. In this work, to overcome such problems, we propose TextING 1 for inductive text classification via GNN. We first build individual graphs for each document and then use GNN to learn the finegrained word representations based on their local structures, which can also effectively produce embeddings for unseen words in the new document. Finally, the word nodes are incorporated as the document embedding. Extensive experiments on four benchmark datasets show that our method outperforms state-of-theart text classification methods.","document own structure : inductive text classification graph neural networks text classification fundamental natural language processing ( nlp ) , graph neural networks ( gnn ) recently apply task . , exist graph - base work capture contextual word relationship document fulfil inductive learning new word . work , overcome problem , propose texting 1 inductive text classification gnn . build individual graph document use gnn learn finegrained word representation base local structure , effectively produce embedding unseen word new document . finally , word node incorporate document embedding . extensive experiment benchmark dataset method outperform state - - theart text classification method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 13, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Dynamic Memory Induction Networks for Few-Shot Text Classification,"This paper proposes Dynamic Memory Induction Networks (DMIN) for few-shot text classification. The model utilizes dynamic routing to provide more flexibility to memory-based few-shot learning in order to better adapt the support sets, which is a critical capacity of fewshot classification models. Based on that, we further develop induction models with query information, aiming to enhance the generalization ability of meta-learning. The proposed model achieves new state-of-the-art results on the miniRCV1 and ODIC dataset, improving the best performance (accuracy) by 2âˆ¼4%. Detailed analysis is further performed to show the effectiveness of each component.","Dynamic Memory Induction Networks for Few-Shot Text Classification This paper proposes Dynamic Memory Induction Networks (DMIN) for few-shot text classification. The model utilizes dynamic routing to provide more flexibility to memory-based few-shot learning in order to better adapt the support sets, which is a critical capacity of fewshot classification models. Based on that, we further develop induction models with query information, aiming to enhance the generalization ability of meta-learning. The proposed model achieves new state-of-the-art results on the miniRCV1 and ODIC dataset, improving the best performance (accuracy) by 2âˆ¼4%. Detailed analysis is further performed to show the effectiveness of each component.","dynamic memory induction networks - shot text classification paper propose dynamic memory induction networks ( dmin ) - shot text classification . model utilize dynamic routing provide flexibility memory - base - shot learning order well adapt support set , critical capacity fewshot classification model . base , develop induction model query information , aim enhance generalization ability meta - learning . propose model achieve new state - - - art result minircv1 odic dataset , improve good performance ( accuracy ) 2âˆ¼4 % . detailed analysis perform effectiveness component .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Feature Projection for Improved Text Classification,"In classification, there are usually some good features that are indicative of class labels. For example, in sentiment classification, words like good and nice are indicative of the positive sentiment and words like bad and terrible are indicative of the negative sentiment. However, there are also many common features (e.g., words) that are not indicative of any specific class (e.g., voice and screen, which are common to both sentiment classes and are not discriminative for classification). Although deep learning has made significant progresses in generating discriminative features through its powerful representation learning, we believe there is still room for improvement. In this paper, we propose a novel angle to further improve this representation learning, i.e., feature projection. This method projects existing features into the orthogonal space of the common features. The resulting projection is thus perpendicular to the common features and more discriminative for classification. We apply this new method to improve CNN, RNN, Transformer, and Bert based text classification and obtain markedly better results.","Feature Projection for Improved Text Classification In classification, there are usually some good features that are indicative of class labels. For example, in sentiment classification, words like good and nice are indicative of the positive sentiment and words like bad and terrible are indicative of the negative sentiment. However, there are also many common features (e.g., words) that are not indicative of any specific class (e.g., voice and screen, which are common to both sentiment classes and are not discriminative for classification). Although deep learning has made significant progresses in generating discriminative features through its powerful representation learning, we believe there is still room for improvement. In this paper, we propose a novel angle to further improve this representation learning, i.e., feature projection. This method projects existing features into the orthogonal space of the common features. The resulting projection is thus perpendicular to the common features and more discriminative for classification. We apply this new method to improve CNN, RNN, Transformer, and Bert based text classification and obtain markedly better results.","feature projection improve text classification classification , usually good feature indicative class label . example , sentiment classification , word like good nice indicative positive sentiment word like bad terrible indicative negative sentiment . , common feature ( e.g. , word ) indicative specific class ( e.g. , voice screen , common sentiment class discriminative classification ) . deep learning significant progress generate discriminative feature powerful representation learning , believe room improvement . paper , propose novel angle improve representation learning , i.e. , feature projection . method project exist feature orthogonal space common feature . result projection perpendicular common feature discriminative classification . apply new method improve cnn , rnn , transformer , bert base text classification obtain markedly well result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,False
Information Retrieval and Text Mining,Exclusive Hierarchical Decoding for Deep Keyphrase Generation,"Keyphrase generation (KG) aims to summarize the main ideas of a document into a set of keyphrases. A new setting is recently introduced into this problem, in which, given a document, the model needs to predict a set of keyphrases and simultaneously determine the appropriate number of keyphrases to produce. Previous work in this setting employs a sequential decoding process to generate keyphrases. However, such a decoding method ignores the intrinsic hierarchical compositionality existing in the keyphrase set of a document. Moreover, previous work tends to generate duplicated keyphrases, which wastes time and computing resources. To overcome these limitations, we propose an exclusive hierarchical decoding framework that includes a hierarchical decoding process and either a soft or a hard exclusion mechanism. The hierarchical decoding process is to explicitly model the hierarchical compositionality of a keyphrase set. Both the soft and the hard exclusion mechanisms keep track of previouslypredicted keyphrases within a window size to enhance the diversity of the generated keyphrases. Extensive experiments on multiple KG benchmark datasets demonstrate the effectiveness of our method to generate less duplicated and more accurate keyphrases 1 .","Exclusive Hierarchical Decoding for Deep Keyphrase Generation Keyphrase generation (KG) aims to summarize the main ideas of a document into a set of keyphrases. A new setting is recently introduced into this problem, in which, given a document, the model needs to predict a set of keyphrases and simultaneously determine the appropriate number of keyphrases to produce. Previous work in this setting employs a sequential decoding process to generate keyphrases. However, such a decoding method ignores the intrinsic hierarchical compositionality existing in the keyphrase set of a document. Moreover, previous work tends to generate duplicated keyphrases, which wastes time and computing resources. To overcome these limitations, we propose an exclusive hierarchical decoding framework that includes a hierarchical decoding process and either a soft or a hard exclusion mechanism. The hierarchical decoding process is to explicitly model the hierarchical compositionality of a keyphrase set. Both the soft and the hard exclusion mechanisms keep track of previouslypredicted keyphrases within a window size to enhance the diversity of the generated keyphrases. Extensive experiments on multiple KG benchmark datasets demonstrate the effectiveness of our method to generate less duplicated and more accurate keyphrases 1 .","exclusive hierarchical decoding deep keyphrase generation keyphrase generation ( kg ) aim summarize main idea document set keyphrase . new setting recently introduce problem , , give document , model need predict set keyphrase simultaneously determine appropriate number keyphrase produce . previous work setting employ sequential decoding process generate keyphrase . , decoding method ignore intrinsic hierarchical compositionality exist keyphrase set document . , previous work tend generate duplicated keyphrase , waste time computing resource . overcome limitation , propose exclusive hierarchical decoding framework include hierarchical decoding process soft hard exclusion mechanism . hierarchical decoding process explicitly model hierarchical compositionality keyphrase set . soft hard exclusion mechanism track previouslypredicte keyphrase window size enhance diversity generate keyphrase . extensive experiment multiple kg benchmark dataset demonstrate effectiveness method generate duplicated accurate keyphrase 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 21, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,An Online Semantic-enhanced Dirichlet Model for Short Text Stream Clustering,"Clustering short text streams is a challenging task due to its unique properties: infinite length, sparse data representation and cluster evolution. Existing approaches often exploit short text streams in a batch way. However, determine the optimal batch size is usually a difficult task since we have no prior knowledge when the topics evolve. In addition, traditional independent word representation in the graphical model tends to cause ""term ambiguity"" problem in short text clustering. Therefore, in this paper, we propose an Online Semantic-enhanced Dirichlet Model for short text stream clustering, called OSDM, which integrates the word-occurrence semantic information (i.e., context) into a new graphical model and clusters for each arriving short text automatically in an online way. Extensive results have demonstrated that OSDM gives better performance compared to many state-ofthe-art algorithms on both synthetic and realworld data sets.","An Online Semantic-enhanced Dirichlet Model for Short Text Stream Clustering Clustering short text streams is a challenging task due to its unique properties: infinite length, sparse data representation and cluster evolution. Existing approaches often exploit short text streams in a batch way. However, determine the optimal batch size is usually a difficult task since we have no prior knowledge when the topics evolve. In addition, traditional independent word representation in the graphical model tends to cause ""term ambiguity"" problem in short text clustering. Therefore, in this paper, we propose an Online Semantic-enhanced Dirichlet Model for short text stream clustering, called OSDM, which integrates the word-occurrence semantic information (i.e., context) into a new graphical model and clusters for each arriving short text automatically in an online way. Extensive results have demonstrated that OSDM gives better performance compared to many state-ofthe-art algorithms on both synthetic and realworld data sets.","online semantic - enhance dirichlet model short text stream clustering cluster short text stream challenging task unique property : infinite length , sparse datum representation cluster evolution . exist approach exploit short text stream batch way . , determine optimal batch size usually difficult task prior knowledge topic evolve . addition , traditional independent word representation graphical model tend cause "" term ambiguity "" problem short text clustering . , paper , propose online semantic - enhance dirichlet model short text stream clustering , call osdm , integrate word - occurrence semantic information ( i.e. , context ) new graphical model cluster arrive short text automatically online way . extensive result demonstrate osdm give well performance compare state - ofthe - art algorithm synthetic realworld data set .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Information Retrieval and Text Mining,A Prioritization Model for Suicidality Risk Assessment,"We reframe suicide risk assessment from social media as a ranking problem whose goal is maximizing detection of severely at-risk individuals given the time available. Building on measures developed for resource-bounded document retrieval, we introduce a well founded evaluation paradigm, and demonstrate using an expert-annotated test collection that meaningful improvements over plausible cascade model baselines can be achieved using an approach that jointly ranks individuals and their social media posts.","A Prioritization Model for Suicidality Risk Assessment We reframe suicide risk assessment from social media as a ranking problem whose goal is maximizing detection of severely at-risk individuals given the time available. Building on measures developed for resource-bounded document retrieval, we introduce a well founded evaluation paradigm, and demonstrate using an expert-annotated test collection that meaningful improvements over plausible cascade model baselines can be achieved using an approach that jointly ranks individuals and their social media posts.","prioritization model suicidality risk assessment reframe suicide risk assessment social medium rank problem goal maximize detection severely - risk individual give time available . build measure develop resource - bound document retrieval , introduce found evaluation paradigm , demonstrate expert - annotate test collection meaningful improvement plausible cascade model baseline achieve approach jointly rank individual social media post .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Information Retrieval and Text Mining,Document Translation vs. Query Translation for Cross-Lingual Information Retrieval in the Medical Domain,"We present a thorough comparison of two principal approaches to Cross-Lingual Information Retrieval: document translation (DT) and query translation (QT). Our experiments are conducted using the cross-lingual test collection produced within the CLEF eHealth information retrieval tasks in 2013-2015 containing English documents and queries in several European languages. We exploit the Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) paradigms and train several domain-specific and task-specific machine translation systems to translate the non-English queries into English (for the QT approach) and the English documents to all the query languages (for the DT approach). The results show that the quality of QT by SMT is sufficient enough to outperform the retrieval results of the DT approach for all the languages. NMT then further boosts translation quality and retrieval quality for both QT and DT for most languages, but still, QT provides generally better retrieval results than DT.","Document Translation vs. Query Translation for Cross-Lingual Information Retrieval in the Medical Domain We present a thorough comparison of two principal approaches to Cross-Lingual Information Retrieval: document translation (DT) and query translation (QT). Our experiments are conducted using the cross-lingual test collection produced within the CLEF eHealth information retrieval tasks in 2013-2015 containing English documents and queries in several European languages. We exploit the Statistical Machine Translation (SMT) and Neural Machine Translation (NMT) paradigms and train several domain-specific and task-specific machine translation systems to translate the non-English queries into English (for the QT approach) and the English documents to all the query languages (for the DT approach). The results show that the quality of QT by SMT is sufficient enough to outperform the retrieval results of the DT approach for all the languages. NMT then further boosts translation quality and retrieval quality for both QT and DT for most languages, but still, QT provides generally better retrieval results than DT.","document translation vs. query translation cross - lingual information retrieval medical domain present thorough comparison principal approach cross - lingual information retrieval : document translation ( dt ) query translation ( qt ) . experiment conduct cross - lingual test collection produce clef ehealth information retrieval task 2013 - 2015 contain english document query european language . exploit statistical machine translation ( smt ) neural machine translation ( nmt ) paradigm train domain - specific task - specific machine translation system translate non - english query english ( qt approach ) english document query language ( dt approach ) . result quality qt smt sufficient outperform retrieval result dt approach language . nmt boost translation quality retrieval quality qt dt language , , qt provide generally well retrieval result dt .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 10, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 18, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Information Retrieval and Text Mining,Neural Topic Modeling with Bidirectional Adversarial Training,"Recent years have witnessed a surge of interests of using neural topic models for automatic topic extraction from text, since they avoid the complicated mathematical derivations for model inference as in traditional topic models such as Latent Dirichlet Allocation (LDA). However, these models either typically assume improper prior (e.g. Gaussian or Logistic Normal) over latent topic space or could not infer topic distribution for a given document. To address these limitations, we propose a neural topic modeling approach, called Bidirectional Adversarial Topic (BAT) model, which represents the first attempt of applying bidirectional adversarial training for neural topic modeling. The proposed BAT builds a twoway projection between the document-topic distribution and the document-word distribution. It uses a generator to capture the semantic patterns from texts and an encoder for topic inference. Furthermore, to incorporate word relatedness information, the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To verify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are used in our experiments. The experimental results show that BAT and Gaussian-BAT obtain more coherent topics, outperforming several competitive baselines. Moreover, when performing text clustering based on the extracted topics, our models outperform all the baselines, with more significant improvements achieved by Gaussian-BAT where an increase of near 6% is observed in accuracy.","Neural Topic Modeling with Bidirectional Adversarial Training Recent years have witnessed a surge of interests of using neural topic models for automatic topic extraction from text, since they avoid the complicated mathematical derivations for model inference as in traditional topic models such as Latent Dirichlet Allocation (LDA). However, these models either typically assume improper prior (e.g. Gaussian or Logistic Normal) over latent topic space or could not infer topic distribution for a given document. To address these limitations, we propose a neural topic modeling approach, called Bidirectional Adversarial Topic (BAT) model, which represents the first attempt of applying bidirectional adversarial training for neural topic modeling. The proposed BAT builds a twoway projection between the document-topic distribution and the document-word distribution. It uses a generator to capture the semantic patterns from texts and an encoder for topic inference. Furthermore, to incorporate word relatedness information, the Bidirectional Adversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To verify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are used in our experiments. The experimental results show that BAT and Gaussian-BAT obtain more coherent topics, outperforming several competitive baselines. Moreover, when performing text clustering based on the extracted topics, our models outperform all the baselines, with more significant improvements achieved by Gaussian-BAT where an increase of near 6% is observed in accuracy.","neural topic modeling bidirectional adversarial training recent year witness surge interest neural topic model automatic topic extraction text , avoid complicated mathematical derivation model inference traditional topic model latent dirichlet allocation ( lda ) . , model typically assume improper prior ( e.g. gaussian logistic normal ) latent topic space infer topic distribution give document . address limitation , propose neural topic modeling approach , call bidirectional adversarial topic ( bat ) model , represent attempt apply bidirectional adversarial training neural topic modeling . propose bat build twoway projection document - topic distribution document - word distribution . use generator capture semantic pattern text encoder topic inference . furthermore , incorporate word relatedness information , bidirectional adversarial topic model gaussian ( gaussian - bat ) extend bat . verify effectiveness bat gaussian - bat , benchmark corpus experiment . experimental result bat gaussian - bat obtain coherent topic , outperform competitive baseline . , perform text clustering base extract topic , model outperform baseline , significant improvement achieve gaussian - bat increase near 6 % observe accuracy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 32, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,True
Information Retrieval and Text Mining,Unsupervised FAQ Retrieval with Question Generation and BERT,"We focus on the task of Frequently Asked Questions (FAQ) retrieval. A given user query can be matched against the questions and/or the answers in the FAQ. We present a fully unsupervised method that exploits the FAQ pairs to train two BERT models. The two models match user queries to FAQ answers and questions, respectively. We alleviate the missing labeled data of the latter by automatically generating high-quality question paraphrases. We show that our model is on par and even outperforms supervised models on existing datasets.","Unsupervised FAQ Retrieval with Question Generation and BERT We focus on the task of Frequently Asked Questions (FAQ) retrieval. A given user query can be matched against the questions and/or the answers in the FAQ. We present a fully unsupervised method that exploits the FAQ pairs to train two BERT models. The two models match user queries to FAQ answers and questions, respectively. We alleviate the missing labeled data of the latter by automatically generating high-quality question paraphrases. We show that our model is on par and even outperforms supervised models on existing datasets.","unsupervised faq retrieval question generation bert focus task frequently ask question ( faq ) retrieval . give user query match question and/or answer faq . present fully unsupervised method exploit faq pair train bert model . model match user query faq answer question , respectively . alleviate miss label datum automatically generate high - quality question paraphrase . model par outperform supervised model exist dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Information Retrieval and Text Mining,CluHTM - Semantic Hierarchical Topic Modeling based on CluWords,"Hierarchical Topic modeling (HTM) exploits latent topics and relationships among them as a powerful tool for data analysis and exploration. Despite advantages over traditional topic modeling, HTM poses its own challenges, such as (1) topic incoherence, (2) unreasonable (hierarchical) structure, and (3) issues related to the definition of the ""ideal"" number of topics and depth of the hierarchy. In this paper, we advance the stateof-the-art on HTM by means of the design and evaluation of CluHTM, a novel nonprobabilistic hierarchical matrix factorization aimed at solving the specific issues of HTM. CluHTM's novel contributions include: (i) the exploration of richer text representation that encapsulates both, global (dataset level) and local semantic information -when combined, these pieces of information help to solve the topic incoherence problem as well as issues related to the unreasonable structure; (ii) the exploitation of a stability analysis metric for defining the number of topics and the ""shape"" the hierarchical structure. In our evaluation, considering twelve datasets and seven stateof-the-art baselines, CluHTM outperformed the baselines in the vast majority of the cases, with gains of around 500% over the strongest state-of-the-art baselines. We also provide qualitative and quantitative statistical analyses of why our solution works so well.","CluHTM - Semantic Hierarchical Topic Modeling based on CluWords Hierarchical Topic modeling (HTM) exploits latent topics and relationships among them as a powerful tool for data analysis and exploration. Despite advantages over traditional topic modeling, HTM poses its own challenges, such as (1) topic incoherence, (2) unreasonable (hierarchical) structure, and (3) issues related to the definition of the ""ideal"" number of topics and depth of the hierarchy. In this paper, we advance the stateof-the-art on HTM by means of the design and evaluation of CluHTM, a novel nonprobabilistic hierarchical matrix factorization aimed at solving the specific issues of HTM. CluHTM's novel contributions include: (i) the exploration of richer text representation that encapsulates both, global (dataset level) and local semantic information -when combined, these pieces of information help to solve the topic incoherence problem as well as issues related to the unreasonable structure; (ii) the exploitation of a stability analysis metric for defining the number of topics and the ""shape"" the hierarchical structure. In our evaluation, considering twelve datasets and seven stateof-the-art baselines, CluHTM outperformed the baselines in the vast majority of the cases, with gains of around 500% over the strongest state-of-the-art baselines. We also provide qualitative and quantitative statistical analyses of why our solution works so well.","cluhtm - semantic hierarchical topic modeling base cluwords hierarchical topic modeling ( htm ) exploit latent topic relationship powerful tool datum analysis exploration . despite advantage traditional topic modeling , htm pose challenge , ( 1 ) topic incoherence , ( 2 ) unreasonable ( hierarchical ) structure , ( 3 ) issue relate definition "" ideal "" number topic depth hierarchy . paper , advance stateof - - art htm mean design evaluation cluhtm , novel nonprobabilistic hierarchical matrix factorization aim solve specific issue htm . cluhtm novel contribution include : ( ) exploration rich text representation encapsulate , global ( dataset level ) local semantic information -when combine , piece information help solve topic incoherence problem issue relate unreasonable structure ; ( ii ) exploitation stability analysis metric define number topic "" shape "" hierarchical structure . evaluation , consider dataset seven stateof - - art baseline , cluhtm outperform baseline vast majority case , gain 500 % strong state - - - art baseline . provide qualitative quantitative statistical analysis solution work .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 17, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Retrieval and Text Mining,True
Interpretability and Analysis of Models for NLP,A Re-evaluation of Knowledge Graph Completion Methods,"Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report performance of several existing methods using our protocol. The reproducible code has been made publicly available.","A Re-evaluation of Knowledge Graph Completion Methods Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report performance of several existing methods using our protocol. The reproducible code has been made publicly available.","- evaluation knowledge graph completion methods knowledge graph completion ( kgc ) aim automatically predict miss link large - scale knowledge graph . vast number state - - - art kgc technique get publish conference research field , include data mining , machine learning , natural language processing . , notice recent paper report high performance , largely outperform previous state - - - art method . paper , find attribute inappropriate evaluation protocol propose simple evaluation protocol address problem . propose protocol robust handle bias model , substantially affect final result . conduct extensive experiment report performance exist method protocol . reproducible code publicly available .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Interpretability and Analysis of Models for NLP,Cross-Linguistic Syntactic Evaluation of Word Prediction Models,"A range of studies have concluded that neural word prediction models can distinguish grammatical from ungrammatical sentences with high accuracy. However, these studies are based primarily on monolingual evidence from English. To investigate how these models' ability to learn syntax varies by language, we introduce CLAMS (Cross-Linguistic Assessment of Models on Syntax), a syntactic evaluation suite for monolingual and multilingual models. CLAMS includes subject-verb agreement challenge sets for English, French, German, Hebrew and Russian, generated from grammars we develop. We use CLAMS to evaluate LSTM language models as well as monolingual and multilingual BERT. Across languages, monolingual LSTMs achieved high accuracy on dependencies without attractors, and generally poor accuracy on agreement across object relative clauses. On other constructions, agreement accuracy was generally higher in languages with richer morphology. Multilingual models generally underperformed monolingual models. Multilingual BERT showed high syntactic accuracy on English, but noticeable deficiencies in other languages.","Cross-Linguistic Syntactic Evaluation of Word Prediction Models A range of studies have concluded that neural word prediction models can distinguish grammatical from ungrammatical sentences with high accuracy. However, these studies are based primarily on monolingual evidence from English. To investigate how these models' ability to learn syntax varies by language, we introduce CLAMS (Cross-Linguistic Assessment of Models on Syntax), a syntactic evaluation suite for monolingual and multilingual models. CLAMS includes subject-verb agreement challenge sets for English, French, German, Hebrew and Russian, generated from grammars we develop. We use CLAMS to evaluate LSTM language models as well as monolingual and multilingual BERT. Across languages, monolingual LSTMs achieved high accuracy on dependencies without attractors, and generally poor accuracy on agreement across object relative clauses. On other constructions, agreement accuracy was generally higher in languages with richer morphology. Multilingual models generally underperformed monolingual models. Multilingual BERT showed high syntactic accuracy on English, but noticeable deficiencies in other languages.","cross - linguistic syntactic evaluation word prediction model range study conclude neural word prediction model distinguish grammatical ungrammatical sentence high accuracy . , study base primarily monolingual evidence english . investigate model ' ability learn syntax vary language , introduce clams ( cross - linguistic assessment models syntax ) , syntactic evaluation suite monolingual multilingual model . clams include subject - verb agreement challenge set english , french , german , hebrew russian , generate grammar develop . use clams evaluate lstm language model monolingual multilingual bert . language , monolingual lstm achieve high accuracy dependency attractor , generally poor accuracy agreement object relative clause . construction , agreement accuracy generally high language rich morphology . multilingual model generally underperform monolingual model . multilingual bert show high syntactic accuracy english , noticeable deficiency language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 7, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Membership Inference Attacks on Sequence-to-Sequence Models: Is My Data In Your Machine Translation System?,"Data privacy is an important issue for ''machine learning as a service'' providers. We focus on the problem of membership inference attacks: Given a data sample and black-box access to a model's API, determine whether the sample existed in the model's training data. Our contribution is an investigation of this problem in the context of sequence-tosequence models, which are important in applications such as machine translation and video captioning. We define the membership inference problem for sequence generation, provide an open dataset based on state-of-the-art machine translation models, and report initial results on whether these models leak private information against several kinds of membership inference attacks.","Membership Inference Attacks on Sequence-to-Sequence Models: Is My Data In Your Machine Translation System? Data privacy is an important issue for ''machine learning as a service'' providers. We focus on the problem of membership inference attacks: Given a data sample and black-box access to a model's API, determine whether the sample existed in the model's training data. Our contribution is an investigation of this problem in the context of sequence-tosequence models, which are important in applications such as machine translation and video captioning. We define the membership inference problem for sequence generation, provide an open dataset based on state-of-the-art machine translation models, and report initial results on whether these models leak private information against several kinds of membership inference attacks.","membership inference attack sequence - - sequence model : data machine translation system ? datum privacy important issue '' machine learning service '' provider . focus problem membership inference attack : give datum sample black - box access model api , determine sample exist model training datum . contribution investigation problem context sequence - tosequence model , important application machine translation video captioning . define membership inference problem sequence generation , provide open dataset base state - - - art machine translation model , report initial result model leak private information kind membership inference attack .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Interpretability and Analysis of Models for NLP,Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?,"Algorithmic approaches to interpreting machine learning models have proliferated in recent years. We carry out human subject tests that are the first of their kind to isolate the effect of algorithmic explanations on a key aspect of model interpretability, simulatability, while avoiding important confounding experimental factors. A model is simulatable when a person can predict its behavior on new inputs. Through two kinds of simulation tests involving text and tabular data, we evaluate five explanations methods: (1) LIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a Composite approach that combines explanations from each method. Clear evidence of method effectiveness is found in very few cases: LIME improves simulatability in tabular classification, and our Prototype method is effective in counterfactual simulation tests. We also collect subjective ratings of explanations, but we do not find that ratings are predictive of how helpful explanations are. Our results provide the first reliable and comprehensive estimates of how explanations influence simulatability across a variety of explanation methods and data domains. We show that (1) we need to be careful about the metrics we use to evaluate explanation methods, and (2) there is significant room for improvement in current methods. 1","Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior? Algorithmic approaches to interpreting machine learning models have proliferated in recent years. We carry out human subject tests that are the first of their kind to isolate the effect of algorithmic explanations on a key aspect of model interpretability, simulatability, while avoiding important confounding experimental factors. A model is simulatable when a person can predict its behavior on new inputs. Through two kinds of simulation tests involving text and tabular data, we evaluate five explanations methods: (1) LIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a Composite approach that combines explanations from each method. Clear evidence of method effectiveness is found in very few cases: LIME improves simulatability in tabular classification, and our Prototype method is effective in counterfactual simulation tests. We also collect subjective ratings of explanations, but we do not find that ratings are predictive of how helpful explanations are. Our results provide the first reliable and comprehensive estimates of how explanations influence simulatability across a variety of explanation methods and data domains. We show that (1) we need to be careful about the metrics we use to evaluate explanation methods, and (2) there is significant room for improvement in current methods. 1","evaluate explainable ai : algorithmic explanation help user predict model behavior ? algorithmic approach interpret machine learning model proliferate recent year . carry human subject test kind isolate effect algorithmic explanation key aspect model interpretability , simulatability , avoid important confound experimental factor . model simulatable person predict behavior new input . kind simulation test involve text tabular datum , evaluate explanation method : ( 1 ) lime , ( 2 ) anchor , ( 3 ) decision boundary , ( 4 ) prototype model , ( 5 ) composite approach combine explanation method . clear evidence method effectiveness find case : lime improve simulatability tabular classification , prototype method effective counterfactual simulation test . collect subjective rating explanation , find rating predictive helpful explanation . result provide reliable comprehensive estimate explanation influence simulatability variety explanation method data domain . ( 1 ) need careful metric use evaluate explanation method , ( 2 ) significant room improvement current method . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 10, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,How does BERT's attention change when you fine-tune? An analysis methodology and a case study in negation scope,"Large pretrained language models like BERT, after fine-tuning to a downstream task, have achieved high performance on a variety of NLP problems. Yet explaining their decisions is difficult despite recent work probing their internal representations. We propose a procedure and analysis methods that take a hypothesis of how a transformer-based model might encode a linguistic phenomenon, and test the validity of that hypothesis based on a comparison between knowledge-related downstream tasks with downstream control tasks, and measurement of cross-dataset consistency. We apply this methodology to test BERT and RoBERTa on a hypothesis that some attention heads will consistently attend from a word in negation scope to the negation cue. We find that after fine-tuning BERT and RoBERTa on a negation scope task, the average attention head improves its sensitivity to negation and its attention consistency across negation datasets compared to the pre-trained models. However, only the base models (not the large models) improve compared to a control task, indicating there is evidence for a shallow encoding of negation only in the base models.","How does BERT's attention change when you fine-tune? An analysis methodology and a case study in negation scope Large pretrained language models like BERT, after fine-tuning to a downstream task, have achieved high performance on a variety of NLP problems. Yet explaining their decisions is difficult despite recent work probing their internal representations. We propose a procedure and analysis methods that take a hypothesis of how a transformer-based model might encode a linguistic phenomenon, and test the validity of that hypothesis based on a comparison between knowledge-related downstream tasks with downstream control tasks, and measurement of cross-dataset consistency. We apply this methodology to test BERT and RoBERTa on a hypothesis that some attention heads will consistently attend from a word in negation scope to the negation cue. We find that after fine-tuning BERT and RoBERTa on a negation scope task, the average attention head improves its sensitivity to negation and its attention consistency across negation datasets compared to the pre-trained models. However, only the base models (not the large models) improve compared to a control task, indicating there is evidence for a shallow encoding of negation only in the base models.","bert attention change fine - tune ? analysis methodology case study negation scope large pretrained language model like bert , fine - tuning downstream task , achieve high performance variety nlp problem . explain decision difficult despite recent work probe internal representation . propose procedure analysis method hypothesis transformer - base model encode linguistic phenomenon , test validity hypothesis base comparison knowledge - relate downstream task downstream control task , measurement cross - dataset consistency . apply methodology test bert roberta hypothesis attention head consistently attend word negation scope negation cue . find fine - tune bert roberta negation scope task , average attention head improve sensitivity negation attention consistency negation dataset compare pre - trained model . , base model ( large model ) improve compare control task , indicate evidence shallow encoding negation base model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,An Analysis of the Utility of Explicit Negative Examples to Improve the Syntactic Abilities of Neural Language Models,"We explore the utilities of explicit negative examples in training neural language models. Negative examples here are incorrect words in a sentence, such as barks in *The dogs barks. Neural language models are commonly trained only on positive examples, a set of sentences in the training data, but recent studies suggest that the models trained in this way are not capable of robustly handling complex syntactic constructions, such as long-distance agreement. In this paper, we first demonstrate that appropriately using negative examples about particular constructions (e.g., subject-verb agreement) will boost the model's robustness on them in English, with a negligible loss of perplexity. The key to our success is an additional margin loss between the log-likelihoods of a correct word and an incorrect word. We then provide a detailed analysis of the trained models. One of our findings is the difficulty of object-relative clauses for RNNs. We find that even with our direct learning signals the models still suffer from resolving agreement across an object-relative clause. Augmentation of training sentences involving the constructions somewhat helps, but the accuracy still does not reach the level of subjectrelative clauses. Although not directly cognitively appealing, our method can be a tool to analyze the true architectural limitation of neural models on challenging linguistic constructions.","An Analysis of the Utility of Explicit Negative Examples to Improve the Syntactic Abilities of Neural Language Models We explore the utilities of explicit negative examples in training neural language models. Negative examples here are incorrect words in a sentence, such as barks in *The dogs barks. Neural language models are commonly trained only on positive examples, a set of sentences in the training data, but recent studies suggest that the models trained in this way are not capable of robustly handling complex syntactic constructions, such as long-distance agreement. In this paper, we first demonstrate that appropriately using negative examples about particular constructions (e.g., subject-verb agreement) will boost the model's robustness on them in English, with a negligible loss of perplexity. The key to our success is an additional margin loss between the log-likelihoods of a correct word and an incorrect word. We then provide a detailed analysis of the trained models. One of our findings is the difficulty of object-relative clauses for RNNs. We find that even with our direct learning signals the models still suffer from resolving agreement across an object-relative clause. Augmentation of training sentences involving the constructions somewhat helps, but the accuracy still does not reach the level of subjectrelative clauses. Although not directly cognitively appealing, our method can be a tool to analyze the true architectural limitation of neural models on challenging linguistic constructions.","analysis utility explicit negative example improve syntactic ability neural language model explore utility explicit negative example train neural language model . negative example incorrect word sentence , bark * dog bark . neural language model commonly train positive example , set sentence training datum , recent study suggest model train way capable robustly handle complex syntactic construction , long - distance agreement . paper , demonstrate appropriately negative example particular construction ( e.g. , subject - verb agreement ) boost model robustness english , negligible loss perplexity . key success additional margin loss log - likelihood correct word incorrect word . provide detailed analysis train model . finding difficulty object - relative clause rnn . find direct learning signal model suffer resolve agreement object - relative clause . augmentation training sentence involve construction somewhat help , accuracy reach level subjectrelative clause . directly cognitively appeal , method tool analyze true architectural limitation neural model challenge linguistic construction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness?,"With the growing popularity of deep-learning based NLP models, comes a need for interpretable systems. But what is interpretability, and what constitutes a high-quality interpretation? In this opinion piece we reflect on the current state of interpretability evaluation research. We call for more clearly differentiating between different desired criteria an interpretation should satisfy, and focus on the faithfulness criteria. We survey the literature with respect to faithfulness evaluation, and arrange the current approaches around three assumptions, providing an explicit form to how faithfulness is ""defined"" by the community. We provide concrete guidelines on how evaluation of interpretation methods should and should not be conducted. Finally, we claim that the current binary definition for faithfulness sets a potentially unrealistic bar for being considered faithful. We call for discarding the binary notion of faithfulness in favor of a more graded one, which we believe will be of greater practical utility.","Towards Faithfully Interpretable NLP Systems: How Should We Define and Evaluate Faithfulness? With the growing popularity of deep-learning based NLP models, comes a need for interpretable systems. But what is interpretability, and what constitutes a high-quality interpretation? In this opinion piece we reflect on the current state of interpretability evaluation research. We call for more clearly differentiating between different desired criteria an interpretation should satisfy, and focus on the faithfulness criteria. We survey the literature with respect to faithfulness evaluation, and arrange the current approaches around three assumptions, providing an explicit form to how faithfulness is ""defined"" by the community. We provide concrete guidelines on how evaluation of interpretation methods should and should not be conducted. Finally, we claim that the current binary definition for faithfulness sets a potentially unrealistic bar for being considered faithful. We call for discarding the binary notion of faithfulness in favor of a more graded one, which we believe will be of greater practical utility.","faithfully interpretable nlp system : define evaluate faithfulness ? grow popularity deep - learning base nlp model , come need interpretable system . interpretability , constitute high - quality interpretation ? opinion piece reflect current state interpretability evaluation research . clearly differentiate different desire criterion interpretation satisfy , focus faithfulness criterion . survey literature respect faithfulness evaluation , arrange current approach assumption , provide explicit form faithfulness "" define "" community . provide concrete guideline evaluation interpretation method conduct . finally , claim current binary definition faithfulness set potentially unrealistic bar consider faithful . discard binary notion faithfulness favor graded , believe great practical utility .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 8, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,ERASER: A Benchmark to Evaluate Rationalized NLP Models,"State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the 'reasoning' behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of ""rationales"" (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/","ERASER: A Benchmark to Evaluate Rationalized NLP Models State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the 'reasoning' behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the Evaluating Rationales And Simple English Reasoning (ERASER ) benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of ""rationales"" (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/","eraser : benchmark evaluate rationalize nlp models state - - - art model nlp predominantly base deep neural network opaque term come prediction . limitation increase interest design interpretable deep model nlp reveal ' reasoning ' model output . work direction conduct different dataset task correspondingly unique aim metric ; make difficult track progress . propose evaluating rationales simple english reasoning ( eraser ) benchmark advance research interpretable model nlp . benchmark comprise multiple dataset task human annotation "" rationale "" ( support evidence ) collect . propose metric aim capture rationale provide model align human rationale , faithful rationale ( i.e. , degree provide rationale influence correspond prediction ) . hope release benchmark facilitate progress design interpretable nlp system . benchmark , code , documentation available https://www.eraserbenchmark.com/","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Roles and Utilization of Attention Heads in Transformer-based Neural Language Models,"Sentence encoders based on the transformer architecture have shown promising results on various natural language tasks. The main impetus lies in the pre-trained neural language models that capture long-range dependencies among words, owing to multi-head attention that is unique in the architecture. However, little is known for how linguistic properties are processed, represented, and utilized for downstream tasks among hundreds of attention heads inside the pre-trained transformerbased model. For the initial goal of examining the roles of attention heads in handling a set of linguistic features, we conducted a set of experiments with ten probing tasks and three downstream tasks on four pre-trained transformer families (GPT, GPT2, BERT, and ELECTRA). Meaningful insights are shown through the lens of heat map visualization and utilized to propose a relatively simple sentence representation method that takes advantage of most influential attention heads, resulting in additional performance improvements on the downstream tasks.","Roles and Utilization of Attention Heads in Transformer-based Neural Language Models Sentence encoders based on the transformer architecture have shown promising results on various natural language tasks. The main impetus lies in the pre-trained neural language models that capture long-range dependencies among words, owing to multi-head attention that is unique in the architecture. However, little is known for how linguistic properties are processed, represented, and utilized for downstream tasks among hundreds of attention heads inside the pre-trained transformerbased model. For the initial goal of examining the roles of attention heads in handling a set of linguistic features, we conducted a set of experiments with ten probing tasks and three downstream tasks on four pre-trained transformer families (GPT, GPT2, BERT, and ELECTRA). Meaningful insights are shown through the lens of heat map visualization and utilized to propose a relatively simple sentence representation method that takes advantage of most influential attention heads, resulting in additional performance improvements on the downstream tasks.","role utilization attention head transformer - base neural language model sentence encoder base transformer architecture show promising result natural language task . main impetus lie pre - trained neural language model capture long - range dependency word , owe multi - head attention unique architecture . , little know linguistic property process , represent , utilize downstream task hundred attention head inside pre - trained transformerbased model . initial goal examine role attention head handle set linguistic feature , conduct set experiment probe task downstream task pre - trained transformer family ( gpt , gpt2 , bert , electra ) . meaningful insight show lens heat map visualization utilize propose relatively simple sentence representation method take advantage influential attention head , result additional performance improvement downstream task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Compositionality and Generalization In Emergent Languages,"Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results. First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.","Compositionality and Generalization In Emergent Languages Natural language allows us to refer to novel composite concepts by combining expressions denoting their parts according to systematic rules, a property known as compositionality. In this paper, we study whether the language emerging in deep multi-agent simulations possesses a similar ability to refer to novel primitive combinations, and whether it accomplishes this feat by strategies akin to human-language compositionality. Equipped with new ways to measure compositionality in emergent languages inspired by disentanglement in representation learning, we establish three main results. First, given sufficiently large input spaces, the emergent language will naturally develop the ability to refer to novel composite concepts. Second, there is no correlation between the degree of compositionality of an emergent language and its ability to generalize. Third, while compositionality is not necessary for generalization, it provides an advantage in terms of language transmission: The more compositional a language is, the more easily it will be picked up by new learners, even when the latter differ in architecture from the original agents. We conclude that compositionality does not arise from simple generalization pressure, but if an emergent language does chance upon it, it will be more likely to survive and thrive.","compositionality generalization emergent language natural language allow refer novel composite concept combine expression denote part accord systematic rule , property know compositionality . paper , study language emerge deep multi - agent simulation possess similar ability refer novel primitive combination , accomplish feat strategy akin human - language compositionality . equip new way measure compositionality emergent language inspire disentanglement representation learning , establish main result . , give sufficiently large input space , emergent language naturally develop ability refer novel composite concept . second , correlation degree compositionality emergent language ability generalize . , compositionality necessary generalization , provide advantage term language transmission : compositional language , easily pick new learner , differ architecture original agent . conclude compositionality arise simple generalization pressure , emergent language chance , likely survive thrive .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Interpretability and Analysis of Models for NLP,Similarity Analysis of Contextual Word Representation Models,"This paper investigates contextual word representation models from the lens of similarity analysis. Given a collection of trained models, we measure the similarity of their internal representations and attention. Critically, these models come from vastly different architectures. We use existing and novel similarity measures that aim to gauge the level of localization of information in the deep models, and facilitate the investigation of which design factors affect model similarity, without requiring any external linguistic annotation. The analysis reveals that models within the same family are more similar to one another, as may be expected. Surprisingly, different architectures have rather similar representations, but different individual neurons. We also observed differences in information localization in lower and higher layers and found that higher layers are more affected by fine-tuning on downstream tasks. 1 * Equal contribution 1 The code is available at https://github.com/ johnmwu/contextual-corr-analysis.","Similarity Analysis of Contextual Word Representation Models This paper investigates contextual word representation models from the lens of similarity analysis. Given a collection of trained models, we measure the similarity of their internal representations and attention. Critically, these models come from vastly different architectures. We use existing and novel similarity measures that aim to gauge the level of localization of information in the deep models, and facilitate the investigation of which design factors affect model similarity, without requiring any external linguistic annotation. The analysis reveals that models within the same family are more similar to one another, as may be expected. Surprisingly, different architectures have rather similar representations, but different individual neurons. We also observed differences in information localization in lower and higher layers and found that higher layers are more affected by fine-tuning on downstream tasks. 1 * Equal contribution 1 The code is available at https://github.com/ johnmwu/contextual-corr-analysis.","similarity analysis contextual word representation model paper investigate contextual word representation model lens similarity analysis . give collection train model , measure similarity internal representation attention . critically , model come vastly different architecture . use exist novel similarity measure aim gauge level localization information deep model , facilitate investigation design factor affect model similarity , require external linguistic annotation . analysis reveal model family similar , expect . surprisingly , different architecture similar representation , different individual neuron . observe difference information localization low high layer find high layer affect fine - tuning downstream task . 1 * equal contribution 1 code available https://github.com/ johnmwu / contextual - corr - analysis .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection,"Generating explanations for neural networks has become crucial for their applications in real-world with respect to reliability and trustworthiness. In natural language processing, existing methods usually provide important features which are words or phrases selected from an input text as an explanation, but ignore the interactions between them. It poses challenges for humans to interpret an explanation and connect it to model prediction. In this work, we build hierarchical explanations by detecting feature interactions. Such explanations visualize how words and phrases are combined at different levels of the hierarchy, which can help users understand the decision-making of blackbox models. The proposed method is evaluated with three neural text classifiers (LSTM, CNN, and BERT) on two benchmark datasets, via both automatic and human evaluations. Experiments show the effectiveness of the proposed method in providing explanations that are both faithful to models and interpretable to humans.","Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection Generating explanations for neural networks has become crucial for their applications in real-world with respect to reliability and trustworthiness. In natural language processing, existing methods usually provide important features which are words or phrases selected from an input text as an explanation, but ignore the interactions between them. It poses challenges for humans to interpret an explanation and connect it to model prediction. In this work, we build hierarchical explanations by detecting feature interactions. Such explanations visualize how words and phrases are combined at different levels of the hierarchy, which can help users understand the decision-making of blackbox models. The proposed method is evaluated with three neural text classifiers (LSTM, CNN, and BERT) on two benchmark datasets, via both automatic and human evaluations. Experiments show the effectiveness of the proposed method in providing explanations that are both faithful to models and interpretable to humans.","generate hierarchical explanation text classification feature interaction detection generate explanation neural network crucial application real - world respect reliability trustworthiness . natural language processing , exist method usually provide important feature word phrase select input text explanation , ignore interaction . pose challenge human interpret explanation connect model prediction . work , build hierarchical explanation detect feature interaction . explanation visualize word phrase combine different level hierarchy , help user understand decision - making blackbox model . propose method evaluate neural text classifier ( lstm , cnn , bert ) benchmark dataset , automatic human evaluation . experiment effectiveness propose method provide explanation faithful model interpretable human .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 11, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Analyzing analytical methods: The case of phonology in neural models of spoken language,"Given the fast development of analysis techniques for NLP and speech processing systems, few systematic studies have been conducted to compare the strengths and weaknesses of each method. As a step in this direction we study the case of representations of phonology in neural network models of spoken language. We use two commonly applied analytical techniques, diagnostic classifiers and representational similarity analysis, to quantify to what extent neural activation patterns encode phonemes and phoneme sequences. We manipulate two factors that can affect the outcome of analysis. First, we investigate the role of learning by comparing neural activations extracted from trained versus randomly-initialized models. Second, we examine the temporal scope of the activations by probing both local activations corresponding to a few milliseconds of the speech signal, and global activations pooled over the whole utterance. We conclude that reporting analysis results with randomly initialized models is crucial, and that global-scope methods tend to yield more consistent results and we recommend their use as a complement to local-scope diagnostic methods.","Analyzing analytical methods: The case of phonology in neural models of spoken language Given the fast development of analysis techniques for NLP and speech processing systems, few systematic studies have been conducted to compare the strengths and weaknesses of each method. As a step in this direction we study the case of representations of phonology in neural network models of spoken language. We use two commonly applied analytical techniques, diagnostic classifiers and representational similarity analysis, to quantify to what extent neural activation patterns encode phonemes and phoneme sequences. We manipulate two factors that can affect the outcome of analysis. First, we investigate the role of learning by comparing neural activations extracted from trained versus randomly-initialized models. Second, we examine the temporal scope of the activations by probing both local activations corresponding to a few milliseconds of the speech signal, and global activations pooled over the whole utterance. We conclude that reporting analysis results with randomly initialized models is crucial, and that global-scope methods tend to yield more consistent results and we recommend their use as a complement to local-scope diagnostic methods.","analyze analytical method : case phonology neural model speak language give fast development analysis technique nlp speech processing system , systematic study conduct compare strength weakness method . step direction study case representation phonology neural network model speak language . use commonly apply analytical technique , diagnostic classifier representational similarity analysis , quantify extent neural activation pattern encode phoneme phoneme sequence . manipulate factor affect outcome analysis . , investigate role learning compare neural activation extract train versus randomly - initialize model . second , examine temporal scope activation probe local activation correspond millisecond speech signal , global activation pool utterance . conclude report analysis result randomly initialize model crucial , global - scope method tend yield consistent result recommend use complement local - scope diagnostic method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Interpretability and Analysis of Models for NLP,Towards Transparent and Explainable Attention Models,"Recent studies on interpretability of attention distributions have led to notions of faithful and plausible explanations for a model's predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model's prediction. They can be considered a plausible explanation if they provide a humanunderstandable justification for the model's predictions. In this work, we first explain why current attention mechanisms in LSTM based encoders can neither provide a faithful nor a plausible explanation of the model's predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model's predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the model's predictions to unimportant words such as punctuation and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model's predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the attention distributions learned by our model offer a plausible explanation of the model's predictions. Our code has been made publicly available at https://github.com/","Towards Transparent and Explainable Attention Models Recent studies on interpretability of attention distributions have led to notions of faithful and plausible explanations for a model's predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model's prediction. They can be considered a plausible explanation if they provide a humanunderstandable justification for the model's predictions. In this work, we first explain why current attention mechanisms in LSTM based encoders can neither provide a faithful nor a plausible explanation of the model's predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model's predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the model's predictions to unimportant words such as punctuation and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model's predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the attention distributions learned by our model offer a plausible explanation of the model's predictions. Our code has been made publicly available at https://github.com/","transparent explainable attention model recent study interpretability attention distribution lead notion faithful plausible explanation model prediction . attention distribution consider faithful explanation high attention weight imply great impact model prediction . consider plausible explanation provide humanunderstandable justification model prediction . work , explain current attention mechanism lstm base encoder provide faithful plausible explanation model prediction . observe lstm base encoder hide representation different time - step similar ( high conicity ) attention weight situation carry meaning random permutation attention weight affect model prediction . base experiment wide variety task dataset , observe attention distribution attribute model prediction unimportant word punctuation fail offer plausible explanation prediction . attention mechanism faithful plausible , propose modify lstm cell diversity - drive training objective ensure hide representation learn different time step diverse . result attention distribution offer transparency ( ) provide precise importance ranking hide state ( ii ) well indicative word important model prediction ( iii ) correlate well gradient - base attribution method . human evaluation indicate attention distribution learn model offer plausible explanation model prediction . code publicly available https://github.com/","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 44, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations,"To increase trust in artificial intelligence systems, a promising research direction consists of designing neural models capable of generating natural language explanations for their predictions. In this work, we show that such models are nonetheless prone to generating mutually inconsistent explanations, such as ""Because there is a dog in the image."" and ""Because there is no dog in the [same] image."", exposing flaws in either the decision-making process of the model or in the generation of the explanations. We introduce a simple yet effective adversarial framework for sanity checking models against the generation of inconsistent natural language explanations. Moreover, as part of the framework, we address the problem of adversarial attacks with full target sequences, a scenario that was not previously addressed in sequence-to-sequence attacks. Finally, we apply our framework on a state-of-the-art neural natural language inference model that provides natural language explanations for its predictions. Our framework shows that this model is capable of generating a significant number of inconsistent explanations. PREMISE: A guy in a red jacket is snowboarding in midair. ORIGINAL HYPOTHESIS: A guy is outside in the snow. PREDICTED LABEL: entailment ORIGINAL EXPLANATION: Snowboarding is done outside. REVERSE HYPOTHESIS: The guy is outside. PREDICTED LABEL: contradiction REVERSE EXPLANATION: Snowboarding is not done outside. PREMISE: A man talks to two guards as he holds a drink. ORIGINAL HYPOTHESIS: The prisoner is talking to two guards in the prison cafeteria. PREDICTED LABEL: neutral ORIGINAL EXPLANATION: The man is not necessarily a prisoner. REVERSE HYPOTHESIS: A prisoner talks to two guards. PREDICTED LABEL: entailment REVERSE EXPLANATION: A man is a prisoner. PREMISE: Two women and a man are sitting down eating and drinking various items. ORIGINAL HYPOTHESIS: Three women are shopping at the mall. PREDICTED LABEL: contradiction ORIGINAL EXPLANATION: There are either two women and a man or three women. REVERSE HYPOTHESIS: Three women are sitting down eating. PREDICTED LABEL: neutral REVERSE EXPLANATION: Two women and a man are three women. PREMISE: Biker riding through the forest. ORIGINAL HYPOTHESIS: Man riding motorcycle on highway. PREDICTED LABEL: contradiction ORIGINAL EXPLANATION: Biker and man are different. REVERSE HYPOTHESIS: A man rides his bike through the forest.","Make Up Your Mind! Adversarial Generation of Inconsistent Natural Language Explanations To increase trust in artificial intelligence systems, a promising research direction consists of designing neural models capable of generating natural language explanations for their predictions. In this work, we show that such models are nonetheless prone to generating mutually inconsistent explanations, such as ""Because there is a dog in the image."" and ""Because there is no dog in the [same] image."", exposing flaws in either the decision-making process of the model or in the generation of the explanations. We introduce a simple yet effective adversarial framework for sanity checking models against the generation of inconsistent natural language explanations. Moreover, as part of the framework, we address the problem of adversarial attacks with full target sequences, a scenario that was not previously addressed in sequence-to-sequence attacks. Finally, we apply our framework on a state-of-the-art neural natural language inference model that provides natural language explanations for its predictions. Our framework shows that this model is capable of generating a significant number of inconsistent explanations. PREMISE: A guy in a red jacket is snowboarding in midair. ORIGINAL HYPOTHESIS: A guy is outside in the snow. PREDICTED LABEL: entailment ORIGINAL EXPLANATION: Snowboarding is done outside. REVERSE HYPOTHESIS: The guy is outside. PREDICTED LABEL: contradiction REVERSE EXPLANATION: Snowboarding is not done outside. PREMISE: A man talks to two guards as he holds a drink. ORIGINAL HYPOTHESIS: The prisoner is talking to two guards in the prison cafeteria. PREDICTED LABEL: neutral ORIGINAL EXPLANATION: The man is not necessarily a prisoner. REVERSE HYPOTHESIS: A prisoner talks to two guards. PREDICTED LABEL: entailment REVERSE EXPLANATION: A man is a prisoner. PREMISE: Two women and a man are sitting down eating and drinking various items. ORIGINAL HYPOTHESIS: Three women are shopping at the mall. PREDICTED LABEL: contradiction ORIGINAL EXPLANATION: There are either two women and a man or three women. REVERSE HYPOTHESIS: Three women are sitting down eating. PREDICTED LABEL: neutral REVERSE EXPLANATION: Two women and a man are three women. PREMISE: Biker riding through the forest. ORIGINAL HYPOTHESIS: Man riding motorcycle on highway. PREDICTED LABEL: contradiction ORIGINAL EXPLANATION: Biker and man are different. REVERSE HYPOTHESIS: A man rides his bike through the forest.","mind ! adversarial generation inconsistent natural language explanation increase trust artificial intelligence system , promising research direction consist design neural model capable generate natural language explanation prediction . work , model nonetheless prone generate mutually inconsistent explanation , "" dog image . "" "" dog [ ] image . "" , expose flaw decision - making process model generation explanation . introduce simple effective adversarial framework sanity check model generation inconsistent natural language explanation . , framework , address problem adversarial attack target sequence , scenario previously address sequence - - sequence attack . finally , apply framework state - - - art neural natural language inference model provide natural language explanation prediction . framework show model capable generate significant number inconsistent explanation . premise : guy red jacket snowboard midair . original hypothesi : guy outside snow . predict label : entailment original explanation : snowboarding outside . reverse hypothesis : guy outside . predict label : contradiction reverse explanation : snowboarding outside . premise : man talk guard hold drink . original hypothesis : prisoner talk guard prison cafeteria . predict label : neutral original explanation : man necessarily prisoner . reverse hypothesis : prisoner talk guard . predict label : entailment reverse explanation : man prisoner . premise : woman man sit eat drink item . original hypothesis : woman shop mall . predict label : contradiction original explanation : woman man woman . reverse hypothesis : woman sit eat . predict label : neutral reverse explanation : woman man woman . premise : biker ride forest . original hypothesis : man ride motorcycle highway . predict label : contradiction original explanation : biker man different . reverse hypothesis : man ride bike forest .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 10, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 16, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 14, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT,"By introducing a small set of additional parameters, a probe learns to solve specific linguistic tasks (e.g., dependency parsing) in a supervised manner using feature representations (e.g., contextualized embeddings). The effectiveness of such probing tasks is taken as evidence that the pre-trained model encodes linguistic knowledge. However, this approach of evaluating a language model is undermined by the uncertainty of the amount of knowledge that is learned by the probe itself. Complementary to those works, we propose a parameter-free probing technique for analyzing pre-trained language models (e.g., BERT). Our method does not require direct supervision from the probing tasks, nor do we introduce additional parameters to the probing process. Our experiments on BERT show that syntactic trees recovered from BERT using our method are significantly better than linguistically-uninformed baselines. We further feed the empirically induced dependency structures into a downstream sentiment classification task and find its improvement compatible with or even superior to a human-designed dependency schema.","Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT By introducing a small set of additional parameters, a probe learns to solve specific linguistic tasks (e.g., dependency parsing) in a supervised manner using feature representations (e.g., contextualized embeddings). The effectiveness of such probing tasks is taken as evidence that the pre-trained model encodes linguistic knowledge. However, this approach of evaluating a language model is undermined by the uncertainty of the amount of knowledge that is learned by the probe itself. Complementary to those works, we propose a parameter-free probing technique for analyzing pre-trained language models (e.g., BERT). Our method does not require direct supervision from the probing tasks, nor do we introduce additional parameters to the probing process. Our experiments on BERT show that syntactic trees recovered from BERT using our method are significantly better than linguistically-uninformed baselines. We further feed the empirically induced dependency structures into a downstream sentiment classification task and find its improvement compatible with or even superior to a human-designed dependency schema.","perturbed masking : parameter - free probing analyze interpret bert introduce small set additional parameter , probe learn solve specific linguistic task ( e.g. , dependency parsing ) supervise manner feature representation ( e.g. , contextualize embedding ) . effectiveness probe task take evidence pre - trained model encode linguistic knowledge . , approach evaluate language model undermine uncertainty knowledge learn probe . complementary work , propose parameter - free probe technique analyze pre - trained language model ( e.g. , bert ) . method require direct supervision probe task , introduce additional parameter probe process . experiment bert syntactic tree recover bert method significantly well linguistically - uninformed baseline . feed empirically induce dependency structure downstream sentiment classification task find improvement compatible superior human - design dependency schema .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 0, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Rationalizing Text Matching: Learning Sparse Alignments via Optimal Transport,"Selecting input features of top relevance has become a popular method for building selfexplaining models. In this work, we extend this selective rationalization approach to text matching, where the goal is to jointly select and align text pieces, such as tokens or sentences, as a justification for the downstream prediction. Our approach employs optimal transport (OT) to find a minimal cost alignment between the inputs. However, directly applying OT often produces dense and therefore uninterpretable alignments. To overcome this limitation, we introduce novel constrained variants of the OT problem that result in highly sparse alignments with controllable sparsity. Our model is end-to-end differentiable using the Sinkhorn algorithm for OT and can be trained without any alignment annotations. We evaluate our model on the Stack-Exchange, MultiNews, e-SNLI, and MultiRC datasets. Our model achieves very sparse rationale selections with high fidelity while preserving prediction accuracy compared to strong attention baseline models. â€  * Denotes equal contribution.","Rationalizing Text Matching: Learning Sparse Alignments via Optimal Transport Selecting input features of top relevance has become a popular method for building selfexplaining models. In this work, we extend this selective rationalization approach to text matching, where the goal is to jointly select and align text pieces, such as tokens or sentences, as a justification for the downstream prediction. Our approach employs optimal transport (OT) to find a minimal cost alignment between the inputs. However, directly applying OT often produces dense and therefore uninterpretable alignments. To overcome this limitation, we introduce novel constrained variants of the OT problem that result in highly sparse alignments with controllable sparsity. Our model is end-to-end differentiable using the Sinkhorn algorithm for OT and can be trained without any alignment annotations. We evaluate our model on the Stack-Exchange, MultiNews, e-SNLI, and MultiRC datasets. Our model achieves very sparse rationale selections with high fidelity while preserving prediction accuracy compared to strong attention baseline models. â€  * Denotes equal contribution.","rationalize text matching : learn sparse alignment optimal transport select input feature relevance popular method build selfexplaine model . work , extend selective rationalization approach text matching , goal jointly select align text piece , token sentence , justification downstream prediction . approach employ optimal transport ( ot ) find minimal cost alignment input . , directly apply ot produce dense uninterpretable alignment . overcome limitation , introduce novel constrain variant ot problem result highly sparse alignment controllable sparsity . model end - - end differentiable sinkhorn algorithm ot train alignment annotation . evaluate model stack - exchange , multinews , e - snli , multirc dataset . model achieve sparse rationale selection high fidelity preserve prediction accuracy compare strong attention baseline model . â€  * denote equal contribution .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,On the Robustness of Language Encoders against Grammatical Errors,"We conduct a thorough study to diagnose the behaviors of pre-trained language encoders (ELMo, BERT, and RoBERTa) when confronted with natural grammatical errors. Specifically, we collect real grammatical errors from non-native speakers and conduct adversarial attacks to simulate these errors on clean text data. We use this approach to facilitate debugging models on downstream applications. Results confirm that the performance of all tested models is affected but the degree of impact varies. To interpret model behaviors, we further design a linguistic acceptability task to reveal their abilities in identifying ungrammatical sentences and the position of errors. We find that fixed contextual encoders with a simple classifier trained on the prediction of sentence correctness are able to locate error positions. We also design a cloze test for BERT and discover that BERT captures the interaction between errors and specific tokens in context. Our results shed light on understanding the robustness and behaviors of language encoders against grammatical errors.","On the Robustness of Language Encoders against Grammatical Errors We conduct a thorough study to diagnose the behaviors of pre-trained language encoders (ELMo, BERT, and RoBERTa) when confronted with natural grammatical errors. Specifically, we collect real grammatical errors from non-native speakers and conduct adversarial attacks to simulate these errors on clean text data. We use this approach to facilitate debugging models on downstream applications. Results confirm that the performance of all tested models is affected but the degree of impact varies. To interpret model behaviors, we further design a linguistic acceptability task to reveal their abilities in identifying ungrammatical sentences and the position of errors. We find that fixed contextual encoders with a simple classifier trained on the prediction of sentence correctness are able to locate error positions. We also design a cloze test for BERT and discover that BERT captures the interaction between errors and specific tokens in context. Our results shed light on understanding the robustness and behaviors of language encoders against grammatical errors.","robustness language encoder grammatical error conduct thorough study diagnose behavior pre - train language encoder ( elmo , bert , roberta ) confront natural grammatical error . specifically , collect real grammatical error non - native speaker conduct adversarial attack simulate error clean text datum . use approach facilitate debug model downstream application . result confirm performance test model affect degree impact vary . interpret model behavior , design linguistic acceptability task reveal ability identify ungrammatical sentence position error . find fix contextual encoder simple classifier train prediction sentence correctness able locate error position . design cloze test bert discover bert capture interaction error specific token context . result shed light understand robustness behavior language encoder grammatical error .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Learning to Deceive with Attention-Based Explanations,"Attention mechanisms are ubiquitous components in neural architectures applied to natural language processing. In addition to yielding gains in predictive accuracy, attention weights are often claimed to confer interpretability, purportedly useful both for providing insights to practitioners and for explaining why a model makes its decisions to stakeholders. We call the latter use of attention mechanisms into question by demonstrating a simple method for training models to produce deceptive attention masks. Our method diminishes the total weight assigned to designated impermissible tokens, even when the models can be shown to nevertheless rely on these features to drive predictions. Across multiple models and tasks, our approach manipulates attention weights while paying surprisingly little cost in accuracy. Through a human study, we show that our manipulated attention-based explanations deceive people into thinking that predictions from a model biased against gender minorities do not rely on the gender. Consequently, our results cast doubt on attention's reliability as a tool for auditing algorithms in the context of fairness and accountability. 1","Learning to Deceive with Attention-Based Explanations Attention mechanisms are ubiquitous components in neural architectures applied to natural language processing. In addition to yielding gains in predictive accuracy, attention weights are often claimed to confer interpretability, purportedly useful both for providing insights to practitioners and for explaining why a model makes its decisions to stakeholders. We call the latter use of attention mechanisms into question by demonstrating a simple method for training models to produce deceptive attention masks. Our method diminishes the total weight assigned to designated impermissible tokens, even when the models can be shown to nevertheless rely on these features to drive predictions. Across multiple models and tasks, our approach manipulates attention weights while paying surprisingly little cost in accuracy. Through a human study, we show that our manipulated attention-based explanations deceive people into thinking that predictions from a model biased against gender minorities do not rely on the gender. Consequently, our results cast doubt on attention's reliability as a tool for auditing algorithms in the context of fairness and accountability. 1","learn deceive attention - base explanation attention mechanism ubiquitous component neural architecture apply natural language processing . addition yield gain predictive accuracy , attention weight claim confer interpretability , purportedly useful provide insight practitioner explain model make decision stakeholder . use attention mechanism question demonstrate simple method train model produce deceptive attention mask . method diminish total weight assign designate impermissible token , model show rely feature drive prediction . multiple model task , approach manipulate attention weight pay surprisingly little cost accuracy . human study , manipulate attention - base explanation deceive people think prediction model bias gender minority rely gender . consequently , result cast doubt attention reliability tool audit algorithm context fairness accountability . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 14, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,On the Cross-lingual Transferability of Monolingual Representations,"State-of-the-art unsupervised multilingual models (e.g., multilingual BERT) have been shown to generalize in a zero-shot crosslingual setting. This generalization ability has been attributed to the use of a shared subword vocabulary and joint training across multiple languages giving rise to deep multilingual abstractions. We evaluate this hypothesis by designing an alternative approach that transfers a monolingual model to new languages at the lexical level. More concretely, we first train a transformer-based masked language model on one language, and transfer it to a new language by learning a new embedding matrix with the same masked language modeling objective-freezing parameters of all other layers. This approach does not rely on a shared vocabulary or joint training. However, we show that it is competitive with multilingual BERT on standard cross-lingual classification benchmarks and on a new Cross-lingual Question Answering Dataset (XQuAD). Our results contradict common beliefs of the basis of the generalization ability of multilingual models and suggest that deep monolingual models learn some abstractions that generalize across languages. We also release XQuAD as a more comprehensive cross-lingual benchmark, which comprises 240 paragraphs and 1190 question-answer pairs from SQuAD v1.1 translated into ten languages by professional translators.","On the Cross-lingual Transferability of Monolingual Representations State-of-the-art unsupervised multilingual models (e.g., multilingual BERT) have been shown to generalize in a zero-shot crosslingual setting. This generalization ability has been attributed to the use of a shared subword vocabulary and joint training across multiple languages giving rise to deep multilingual abstractions. We evaluate this hypothesis by designing an alternative approach that transfers a monolingual model to new languages at the lexical level. More concretely, we first train a transformer-based masked language model on one language, and transfer it to a new language by learning a new embedding matrix with the same masked language modeling objective-freezing parameters of all other layers. This approach does not rely on a shared vocabulary or joint training. However, we show that it is competitive with multilingual BERT on standard cross-lingual classification benchmarks and on a new Cross-lingual Question Answering Dataset (XQuAD). Our results contradict common beliefs of the basis of the generalization ability of multilingual models and suggest that deep monolingual models learn some abstractions that generalize across languages. We also release XQuAD as a more comprehensive cross-lingual benchmark, which comprises 240 paragraphs and 1190 question-answer pairs from SQuAD v1.1 translated into ten languages by professional translators.","cross - lingual transferability monolingual representation state - - - art unsupervised multilingual model ( e.g. , multilingual bert ) show generalize zero - shot crosslingual setting . generalization ability attribute use share subword vocabulary joint training multiple language give rise deep multilingual abstraction . evaluate hypothesis design alternative approach transfer monolingual model new language lexical level . concretely , train transformer - base mask language model language , transfer new language learn new embedding matrix mask language modeling objective - freeze parameter layer . approach rely share vocabulary joint training . , competitive multilingual bert standard cross - lingual classification benchmark new cross - lingual question answering dataset ( xquad ) . result contradict common belief basis generalization ability multilingual model suggest deep monolingual model learn abstraction generalize language . release xquad comprehensive cross - lingual benchmark , comprise 240 paragraph 1190 question - answer pair squad v1.1 translate language professional translator .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Interpretability and Analysis of Models for NLP,Interpreting Pretrained Contextualized Representations via Reductions to Static Embeddings,"Contextualized representations (e.g. ELMo, BERT) have become the default pretrained representations for downstream NLP applications. In some settings, this transition has rendered their static embedding predecessors (e.g. Word2Vec, GloVe) obsolete. As a side-effect, we observe that older interpretability methods for static embeddings -while more mature than those available for their dynamic counterparts -are underutilized in studying newer contextualized representations. Consequently, we introduce simple and fully general methods for converting from contextualized representations to static lookup-table embeddings which we apply to 5 popular pretrained models and 9 sets of pretrained weights. Our analysis of the resulting static embeddings notably reveals that pooling over many contexts significantly improves representational quality under intrinsic evaluation. Complementary to analyzing representational quality, we consider social biases encoded in pretrained representations with respect to gender, race/ethnicity, and religion and find that bias is encoded disparately across pretrained models and internal layers even for models that share the same training data. Concerningly, we find dramatic inconsistencies between social bias estimators for word embeddings. 2 A humanist's outlook on the (in)accessibility of BERT: https://tedunderwood.com/2019/07/15/ do-humanists-need-bert/ The first is subword pooling: the application of a pooling mechanism over the k subword representations generated for w in context c in order to compute a single representation for w in c, i.e. {w 1 c , . . . , w k c } â†’ w c . Beyond this, we define context combination to be the mapping from representations w c 1 , . . . , w cn of w in different contexts c 1 , . . . , c n to a single static embedding w that is agnostic of context. Subword Pooling. The tokenization procedure for BERT can be decomposed into two steps: performing a simple word-level tokenization and then potentially deconstructing a word into multiple subwords, yielding w 1 , . . . , w k such that cat(w 1 , . . . , w k ) = w where cat(â€¢) indicates concatenation. Then, every layer of the model computes vectors w 1 c , . . . , w k c . Given these vectors, we consider four pooling mechanisms to compute w c : mean, last} min(â€¢), max(â€¢) are element-wise min/max pooling, mean(â€¢) is the arithmetic mean and last(â€¢) indicates selecting the last vector, w k c . Context Combination. Next, we describe two approaches for specifying contexts c 1 , . . . , c n and combining the associated representations w c 1 , . . . , w cn .","Interpreting Pretrained Contextualized Representations via Reductions to Static Embeddings Contextualized representations (e.g. ELMo, BERT) have become the default pretrained representations for downstream NLP applications. In some settings, this transition has rendered their static embedding predecessors (e.g. Word2Vec, GloVe) obsolete. As a side-effect, we observe that older interpretability methods for static embeddings -while more mature than those available for their dynamic counterparts -are underutilized in studying newer contextualized representations. Consequently, we introduce simple and fully general methods for converting from contextualized representations to static lookup-table embeddings which we apply to 5 popular pretrained models and 9 sets of pretrained weights. Our analysis of the resulting static embeddings notably reveals that pooling over many contexts significantly improves representational quality under intrinsic evaluation. Complementary to analyzing representational quality, we consider social biases encoded in pretrained representations with respect to gender, race/ethnicity, and religion and find that bias is encoded disparately across pretrained models and internal layers even for models that share the same training data. Concerningly, we find dramatic inconsistencies between social bias estimators for word embeddings. 2 A humanist's outlook on the (in)accessibility of BERT: https://tedunderwood.com/2019/07/15/ do-humanists-need-bert/ The first is subword pooling: the application of a pooling mechanism over the k subword representations generated for w in context c in order to compute a single representation for w in c, i.e. {w 1 c , . . . , w k c } â†’ w c . Beyond this, we define context combination to be the mapping from representations w c 1 , . . . , w cn of w in different contexts c 1 , . . . , c n to a single static embedding w that is agnostic of context. Subword Pooling. The tokenization procedure for BERT can be decomposed into two steps: performing a simple word-level tokenization and then potentially deconstructing a word into multiple subwords, yielding w 1 , . . . , w k such that cat(w 1 , . . . , w k ) = w where cat(â€¢) indicates concatenation. Then, every layer of the model computes vectors w 1 c , . . . , w k c . Given these vectors, we consider four pooling mechanisms to compute w c : mean, last} min(â€¢), max(â€¢) are element-wise min/max pooling, mean(â€¢) is the arithmetic mean and last(â€¢) indicates selecting the last vector, w k c . Context Combination. Next, we describe two approaches for specifying contexts c 1 , . . . , c n and combining the associated representations w c 1 , . . . , w cn .","interpret pretrained contextualize representation reduction static embedding contextualize representation ( e.g. elmo , bert ) default pretrained representation downstream nlp application . setting , transition render static embedding predecessor ( e.g. word2vec , glove ) obsolete . - effect , observe old interpretability method static embedding -while mature available dynamic counterpart -are underutilize study new contextualize representation . consequently , introduce simple fully general method convert contextualize representation static lookup - table embedding apply 5 popular pretrained model 9 set pretrained weight . analysis result static embedding notably reveal pool context significantly improve representational quality intrinsic evaluation . complementary analyze representational quality , consider social bias encode pretrained representation respect gender , race / ethnicity , religion find bias encode disparately pretrained model internal layer model share training datum . concerningly , find dramatic inconsistency social bias estimator word embedding . 2 humanist outlook ( in)accessibility bert : https://tedunderwood.com/2019/07/15/ - humanist - need - bert/ subword pooling : application pool mechanism k subword representation generate w context c order compute single representation w c , i.e. { w 1 c , . . . , w k c } â†’ w c . , define context combination mapping representation w c 1 , . . . , w cn w different context c 1 , . . . , c n single static embedding w agnostic context . subword pooling . tokenization procedure bert decompose step : perform simple word - level tokenization potentially deconstruct word multiple subword , yield w 1 , . . . , w k cat(w 1 , . . . , w k ) = w cat(â€¢ ) indicate concatenation . , layer model compute vector w 1 c , . . . , w k c . give vector , consider pooling mechanism compute w c : mean , } min(â€¢ ) , max(â€¢ ) element - wise min / max pooling , mean(â€¢ ) arithmetic mean last(â€¢ ) indicate select vector , w k c . context combination . , describe approach specify context c 1 , . . . , c n combine associate representation w c 1 , . . . , w cn .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 8, 'Generation': 12, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 32, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 12, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Learning to Faithfully Rationalize by Construction,"In many settings it is important for one to be able to understand why a model made a particular prediction. In NLP this often entails extracting snippets of an input text 'responsible for' corresponding model output; when such a snippet comprises tokens that indeed informed the model's prediction, it is a faithful explanation. In some settings, faithfulness may be critical to ensure transparency. Lei et al. (2016) proposed a model to produce faithful rationales for neural text classification by defining independent snippet extraction and prediction modules. However, the discrete selection over input tokens performed by this method complicates training, leading to high variance and requiring careful hyperparameter tuning. We propose a simpler variant of this approach that provides faithful explanations by construction. In our scheme, named FRESH, arbitrary feature importance scores (e.g., gradients from a trained model) are used to induce binary labels over token inputs, which an extractor can be trained to predict. An independent classifier module is then trained exclusively on snippets provided by the extractor; these snippets thus constitute faithful explanations, even if the classifier is arbitrarily complex. In both automatic and manual evaluations we find that variants of this simple framework yield predictive performance superior to 'end-to-end' approaches, while being more general and easier to train. 1","Learning to Faithfully Rationalize by Construction In many settings it is important for one to be able to understand why a model made a particular prediction. In NLP this often entails extracting snippets of an input text 'responsible for' corresponding model output; when such a snippet comprises tokens that indeed informed the model's prediction, it is a faithful explanation. In some settings, faithfulness may be critical to ensure transparency. Lei et al. (2016) proposed a model to produce faithful rationales for neural text classification by defining independent snippet extraction and prediction modules. However, the discrete selection over input tokens performed by this method complicates training, leading to high variance and requiring careful hyperparameter tuning. We propose a simpler variant of this approach that provides faithful explanations by construction. In our scheme, named FRESH, arbitrary feature importance scores (e.g., gradients from a trained model) are used to induce binary labels over token inputs, which an extractor can be trained to predict. An independent classifier module is then trained exclusively on snippets provided by the extractor; these snippets thus constitute faithful explanations, even if the classifier is arbitrarily complex. In both automatic and manual evaluations we find that variants of this simple framework yield predictive performance superior to 'end-to-end' approaches, while being more general and easier to train. 1","learn faithfully rationalize construction setting important able understand model particular prediction . nlp entail extract snippet input text ' responsible ' correspond model output ; snippet comprise token inform model prediction , faithful explanation . setting , faithfulness critical ensure transparency . lei et al . ( 2016 ) propose model produce faithful rationale neural text classification define independent snippet extraction prediction module . , discrete selection input token perform method complicate training , lead high variance require careful hyperparameter tuning . propose simple variant approach provide faithful explanation construction . scheme , name fresh , arbitrary feature importance score ( e.g. , gradient train model ) induce binary label token input , extractor train predict . independent classifier module train exclusively snippet provide extractor ; snippet constitute faithful explanation , classifier arbitrarily complex . automatic manual evaluation find variant simple framework yield predictive performance superior ' end - - end ' approach , general easy train . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 13, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Finding Universal Grammatical Relations in Multilingual BERT,"Recent work has found evidence that Multilingual BERT (mBERT), a transformer-based multilingual masked language model, is capable of zero-shot cross-lingual transfer, suggesting that some aspects of its representations are shared cross-lingually. To better understand this overlap, we extend recent work on finding syntactic trees in neural networks' internal representations to the multilingual setting. We show that subspaces of mBERT representations recover syntactic tree distances in languages other than English, and that these subspaces are approximately shared across languages. Motivated by these results, we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy. This evidence suggests that even without explicit supervision, multilingual masked language models learn certain linguistic universals.","Finding Universal Grammatical Relations in Multilingual BERT Recent work has found evidence that Multilingual BERT (mBERT), a transformer-based multilingual masked language model, is capable of zero-shot cross-lingual transfer, suggesting that some aspects of its representations are shared cross-lingually. To better understand this overlap, we extend recent work on finding syntactic trees in neural networks' internal representations to the multilingual setting. We show that subspaces of mBERT representations recover syntactic tree distances in languages other than English, and that these subspaces are approximately shared across languages. Motivated by these results, we present an unsupervised analysis method that provides evidence mBERT learns representations of syntactic dependency labels, in the form of clusters which largely agree with the Universal Dependencies taxonomy. This evidence suggests that even without explicit supervision, multilingual masked language models learn certain linguistic universals.","find universal grammatical relation multilingual bert recent work find evidence multilingual bert ( mbert ) , transformer - base multilingual mask language model , capable zero - shot cross - lingual transfer , suggest aspect representation share cross - lingually . well understand overlap , extend recent work find syntactic tree neural network ' internal representation multilingual setting . subspace mbert representation recover syntactic tree distance language english , subspace approximately share language . motivate result , present unsupervised analysis method provide evidence mbert learn representation syntactic dependency label , form cluster largely agree universal dependencies taxonomy . evidence suggest explicit supervision , multilingual mask language model learn certain linguistic universal .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Information-Theoretic Probing for Linguistic Structure,"The success of neural networks on a diverse set of NLP tasks has led researchers to question how much these networks actually ""know"" about natural language. Probes are a natural way of assessing this. When probing, a researcher chooses a linguistic task and trains a supervised model to predict annotations in that linguistic task from the network's learned representations. If the probe does well, the researcher may conclude that the representations encode knowledge related to the task. A commonly held belief is that using simpler models as probes is better; the logic is that simpler models will identify linguistic structure, but not learn the task itself. We propose an information-theoretic operationalization of probing as estimating mutual information that contradicts this received wisdom: one should always select the highest performing probe one can, even if it is more complex, since it will result in a tighter estimate, and thus reveal more of the linguistic information inherent in the representation. The experimental portion of our paper focuses on empirically estimating the mutual information between a linguistic property and BERT, comparing these estimates to several baselines. We evaluate on a set of ten typologically diverse languages often underrepresented in NLP research-plus Englishtotalling eleven languages. Our implementation is available in https://github.com/ rycolab/info-theoretic-probing.","Information-Theoretic Probing for Linguistic Structure The success of neural networks on a diverse set of NLP tasks has led researchers to question how much these networks actually ""know"" about natural language. Probes are a natural way of assessing this. When probing, a researcher chooses a linguistic task and trains a supervised model to predict annotations in that linguistic task from the network's learned representations. If the probe does well, the researcher may conclude that the representations encode knowledge related to the task. A commonly held belief is that using simpler models as probes is better; the logic is that simpler models will identify linguistic structure, but not learn the task itself. We propose an information-theoretic operationalization of probing as estimating mutual information that contradicts this received wisdom: one should always select the highest performing probe one can, even if it is more complex, since it will result in a tighter estimate, and thus reveal more of the linguistic information inherent in the representation. The experimental portion of our paper focuses on empirically estimating the mutual information between a linguistic property and BERT, comparing these estimates to several baselines. We evaluate on a set of ten typologically diverse languages often underrepresented in NLP research-plus Englishtotalling eleven languages. Our implementation is available in https://github.com/ rycolab/info-theoretic-probing.","information - theoretic probing linguistic structure success neural network diverse set nlp task lead researcher question network actually "" know "" natural language . probe natural way assess . probe , researcher choose linguistic task train supervise model predict annotation linguistic task network learn representation . probe , researcher conclude representation encode knowledge relate task . commonly hold belief simple model probe well ; logic simple model identify linguistic structure , learn task . propose information - theoretic operationalization probing estimate mutual information contradict receive wisdom : select high perform probe , complex , result tight estimate , reveal linguistic information inherent representation . experimental portion paper focus empirically estimate mutual information linguistic property bert , compare estimate baseline . evaluate set typologically diverse language underrepresente nlp research - plus englishtotalle language . implementation available https://github.com/ rycolab / info - theoretic - probing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 1, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 8, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,False
Interpretability and Analysis of Models for NLP,Spying on Your Neighbors: Fine-grained Probing of Contextual Embeddings for Information about Surrounding Words,"Although models using contextual word embeddings have achieved state-of-the-art results on a host of NLP tasks, little is known about exactly what information these embeddings encode about the context words that they are understood to reflect. To address this question, we introduce a suite of probing tasks that enable fine-grained testing of contextual embeddings for encoding of information about surrounding words. We apply these tasks to examine the popular BERT, ELMo and GPT contextual encoders, and find that each of our tested information types is indeed encoded as contextual information across tokens, often with nearperfect recoverability-but the encoders vary in which features they distribute to which tokens, how nuanced their distributions are, and how robust the encoding of each feature is to distance. We discuss implications of these results for how different types of models break down and prioritize word-level context information when constructing token embeddings.","Spying on Your Neighbors: Fine-grained Probing of Contextual Embeddings for Information about Surrounding Words Although models using contextual word embeddings have achieved state-of-the-art results on a host of NLP tasks, little is known about exactly what information these embeddings encode about the context words that they are understood to reflect. To address this question, we introduce a suite of probing tasks that enable fine-grained testing of contextual embeddings for encoding of information about surrounding words. We apply these tasks to examine the popular BERT, ELMo and GPT contextual encoders, and find that each of our tested information types is indeed encoded as contextual information across tokens, often with nearperfect recoverability-but the encoders vary in which features they distribute to which tokens, how nuanced their distributions are, and how robust the encoding of each feature is to distance. We discuss implications of these results for how different types of models break down and prioritize word-level context information when constructing token embeddings.","spy neighbor : fine - grained probing contextual embedding information surround word model contextual word embedding achieve state - - - art result host nlp task , little know exactly information embedding encode context word understand reflect . address question , introduce suite probe task enable fine - grained testing contextual embedding encoding information surround word . apply task examine popular bert , elmo gpt contextual encoder , find test information type encode contextual information token , nearperfect recoverability - encoder vary feature distribute token , nuanced distribution , robust encoding feature distance . discuss implication result different type model break prioritize word - level context information construct token embedding .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Interpretability and Analysis of Models for NLP,Does Syntax Need to Grow on Trees? Sources of Hierarchical Inductive Bias in Sequence-to-Sequence Networks,"Learners that are exposed to the same training data might generalize differently due to differing inductive biases. In neural network models, inductive biases could in theory arise from any aspect of the model architecture. We investigate which architectural factors affect the generalization behavior of neural sequence-to-sequence models trained on two syntactic tasks, English question formation and English tense reinflection. For both tasks, the training set is consistent with a generalization based on hierarchical structure and a generalization based on linear order. All architectural factors that we investigated qualitatively affected how models generalized, including factors with no clear connection to hierarchical structure. For example, LSTMs and GRUs displayed qualitatively different inductive biases. However, the only factor that consistently contributed a hierarchical bias across tasks was the use of a treestructured model rather than a model with sequential recurrence, suggesting that humanlike syntactic generalization requires architectural syntactic structure.","Does Syntax Need to Grow on Trees? Sources of Hierarchical Inductive Bias in Sequence-to-Sequence Networks Learners that are exposed to the same training data might generalize differently due to differing inductive biases. In neural network models, inductive biases could in theory arise from any aspect of the model architecture. We investigate which architectural factors affect the generalization behavior of neural sequence-to-sequence models trained on two syntactic tasks, English question formation and English tense reinflection. For both tasks, the training set is consistent with a generalization based on hierarchical structure and a generalization based on linear order. All architectural factors that we investigated qualitatively affected how models generalized, including factors with no clear connection to hierarchical structure. For example, LSTMs and GRUs displayed qualitatively different inductive biases. However, the only factor that consistently contributed a hierarchical bias across tasks was the use of a treestructured model rather than a model with sequential recurrence, suggesting that humanlike syntactic generalization requires architectural syntactic structure.","syntax need grow tree ? source hierarchical inductive bias sequence - - sequence network learner expose training datum generalize differently differ inductive bias . neural network model , inductive bias theory arise aspect model architecture . investigate architectural factor affect generalization behavior neural sequence - - sequence model train syntactic task , english question formation english tense reinflection . task , training set consistent generalization base hierarchical structure generalization base linear order . architectural factor investigate qualitatively affect model generalize , include factor clear connection hierarchical structure . example , lstm gru display qualitatively different inductive bias . , factor consistently contribute hierarchical bias task use treestructured model model sequential recurrence , suggest humanlike syntactic generalization require architectural syntactic structure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 5, 'Generation': 0, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Extraction,False
Interpretability and Analysis of Models for NLP,Obtaining Faithful Interpretations from Compositional Neural Networks,"Neural module networks (NMNs) are a popular approach for modeling compositionality: they achieve high accuracy when applied to problems in language and vision, while reflecting the compositional structure of the problem in the network architecture. However, prior work implicitly assumed that the structure of the network modules, describing the abstract reasoning process, provides a faithful explanation of the model's reasoning; that is, that all modules perform their intended behaviour. In this work, we propose and conduct a systematic evaluation of the intermediate outputs of NMNs on NLVR2 and DROP, two datasets which require composing multiple reasoning steps. We find that the intermediate outputs differ from the expected output, illustrating that the network structure does not provide a faithful explanation of model behaviour. To remedy that, we train the model with auxiliary supervision and propose particular choices for module architecture that yield much better faithfulness, at a minimal cost to accuracy.","Obtaining Faithful Interpretations from Compositional Neural Networks Neural module networks (NMNs) are a popular approach for modeling compositionality: they achieve high accuracy when applied to problems in language and vision, while reflecting the compositional structure of the problem in the network architecture. However, prior work implicitly assumed that the structure of the network modules, describing the abstract reasoning process, provides a faithful explanation of the model's reasoning; that is, that all modules perform their intended behaviour. In this work, we propose and conduct a systematic evaluation of the intermediate outputs of NMNs on NLVR2 and DROP, two datasets which require composing multiple reasoning steps. We find that the intermediate outputs differ from the expected output, illustrating that the network structure does not provide a faithful explanation of model behaviour. To remedy that, we train the model with auxiliary supervision and propose particular choices for module architecture that yield much better faithfulness, at a minimal cost to accuracy.","obtain faithful interpretation compositional neural networks neural module network ( nmns ) popular approach model compositionality : achieve high accuracy apply problem language vision , reflect compositional structure problem network architecture . , prior work implicitly assume structure network module , describe abstract reasoning process , provide faithful explanation model reasoning ; , module perform intended behaviour . work , propose conduct systematic evaluation intermediate output nmns nlvr2 drop , dataset require compose multiple reasoning step . find intermediate output differ expect output , illustrate network structure provide faithful explanation model behaviour . remedy , train model auxiliary supervision propose particular choice module architecture yield well faithfulness , minimal cost accuracy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Influence Paths for Characterizing Subject-Verb Number Agreement in LSTM Language Models,"LSTM-based recurrent neural networks are the state-of-the-art for many natural language processing (NLP) tasks. Despite their performance, it is unclear whether, or how, LSTMs learn structural features of natural languages such as subject-verb number agreement in English. Lacking this understanding, the generality of LSTMs on this task and their suitability for related tasks remains uncertain. Further, errors cannot be properly attributed to a lack of structural capability, training data omissions, or other exceptional faults. We introduce influence paths, a causal account of structural properties as carried by paths across gates and neurons of a recurrent neural network. The approach refines the notion of influence (the subject's grammatical number has influence on the grammatical number of the subsequent verb) into a set of gate-level or neuron-level paths. The set localizes and segments the concept (e.g., subject-verb agreement), its constituent elements (e.g., the subject), and related or interfering elements (e.g., attractors). We exemplify the methodology on a widely-studied multi-layer LSTM language model, demonstrating its accounting for subject-verb number agreement. The results offer both a finer and a more complete view of an LSTM's handling of this structural aspect of the English language than prior results based on diagnostic classifiers and ablation.","Influence Paths for Characterizing Subject-Verb Number Agreement in LSTM Language Models LSTM-based recurrent neural networks are the state-of-the-art for many natural language processing (NLP) tasks. Despite their performance, it is unclear whether, or how, LSTMs learn structural features of natural languages such as subject-verb number agreement in English. Lacking this understanding, the generality of LSTMs on this task and their suitability for related tasks remains uncertain. Further, errors cannot be properly attributed to a lack of structural capability, training data omissions, or other exceptional faults. We introduce influence paths, a causal account of structural properties as carried by paths across gates and neurons of a recurrent neural network. The approach refines the notion of influence (the subject's grammatical number has influence on the grammatical number of the subsequent verb) into a set of gate-level or neuron-level paths. The set localizes and segments the concept (e.g., subject-verb agreement), its constituent elements (e.g., the subject), and related or interfering elements (e.g., attractors). We exemplify the methodology on a widely-studied multi-layer LSTM language model, demonstrating its accounting for subject-verb number agreement. The results offer both a finer and a more complete view of an LSTM's handling of this structural aspect of the English language than prior results based on diagnostic classifiers and ablation.","influence path characterize subject - verb number agreement lstm language models lstm - base recurrent neural network state - - - art natural language processing ( nlp ) task . despite performance , unclear , , lstms learn structural feature natural language subject - verb number agreement english . lack understanding , generality lstms task suitability related task remain uncertain . , error properly attribute lack structural capability , training datum omission , exceptional fault . introduce influence path , causal account structural property carry path gate neuron recurrent neural network . approach refine notion influence ( subject grammatical number influence grammatical number subsequent verb ) set gate - level neuron - level path . set localize segment concept ( e.g. , subject - verb agreement ) , constituent element ( e.g. , subject ) , related interfere element ( e.g. , attractor ) . exemplify methodology widely - study multi - layer lstm language model , demonstrate accounting subject - verb number agreement . result offer fine complete view lstm handling structural aspect english language prior result base diagnostic classifier ablation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 14, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models,"Pre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event predictionand, in particular, it shows clear insensitivity to the contextual impacts of negation.","What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models Pre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event predictionand, in particular, it shows clear insensitivity to the contextual impacts of negation.","bert : lesson new suite psycholinguistic diagnostic language model pre - training language modeling popular successful approach nlp task , understand exactly linguistic capacity pre - training process confer model . paper introduce suite diagnostic draw human language experiment , allow ask target question information language model generate prediction context . case study , apply diagnostic popular bert model , find generally distinguish good bad completion involve share category role reversal , albeit sensitivity human , robustly retrieve noun hypernym , struggle challenge inference role - base event predictionand , particular , show clear insensitivity contextual impact negation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,On the Spontaneous Emergence of Discrete and Compositional Signals,"We propose a general framework to study language emergence through signaling games with neural agents. Using a continuous latent space, we are able to (i) train using backpropagation, (ii) show that discrete messages nonetheless naturally emerge. We explore whether categorical perception effects follow and show that the messages are not compositional.","On the Spontaneous Emergence of Discrete and Compositional Signals We propose a general framework to study language emergence through signaling games with neural agents. Using a continuous latent space, we are able to (i) train using backpropagation, (ii) show that discrete messages nonetheless naturally emerge. We explore whether categorical perception effects follow and show that the messages are not compositional.","spontaneous emergence discrete compositional signal propose general framework study language emergence signaling game neural agent . continuous latent space , able ( ) train backpropagation , ( ii ) discrete message nonetheless naturally emerge . explore categorical perception effect follow message compositional .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Interpretability and Analysis of Models for NLP,Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions,"Modern deep learning models for NLP are notoriously opaque. This has motivated the development of methods for interpreting such models, e.g., via gradient-based saliency maps or the visualization of attention weights. Such approaches aim to provide explanations for a particular model prediction by highlighting important words in the corresponding input text. While this might be useful for tasks where decisions are explicitly influenced by individual tokens in the input, we suspect that such highlighting is not always suitable for tasks where model decisions should be driven by more complex reasoning. In this work, we investigate the use of influence functions for NLP, providing an alternative approach to interpreting neural text classifiers. Influence functions explain the decisions of a model by identifying influential training examples. Despite the promise of this approach, influence functions have not yet been extensively evaluated in the context of NLP, a gap addressed by this work. We conduct a comparison between influence functions and common word-saliency methods on representative tasks. As suspected, we find that influence functions are particularly useful for natural language inference, a task in which 'saliency maps' may not provide clear interpretation. Furthermore, we develop a new quantitative measure based on influence functions that can reveal artifacts in training data. 1","Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions Modern deep learning models for NLP are notoriously opaque. This has motivated the development of methods for interpreting such models, e.g., via gradient-based saliency maps or the visualization of attention weights. Such approaches aim to provide explanations for a particular model prediction by highlighting important words in the corresponding input text. While this might be useful for tasks where decisions are explicitly influenced by individual tokens in the input, we suspect that such highlighting is not always suitable for tasks where model decisions should be driven by more complex reasoning. In this work, we investigate the use of influence functions for NLP, providing an alternative approach to interpreting neural text classifiers. Influence functions explain the decisions of a model by identifying influential training examples. Despite the promise of this approach, influence functions have not yet been extensively evaluated in the context of NLP, a gap addressed by this work. We conduct a comparison between influence functions and common word-saliency methods on representative tasks. As suspected, we find that influence functions are particularly useful for natural language inference, a task in which 'saliency maps' may not provide clear interpretation. Furthermore, we develop a new quantitative measure based on influence functions that can reveal artifacts in training data. 1","explain black box prediction unveil data artifact influence function modern deep learning model nlp notoriously opaque . motivate development method interpret model , e.g. , gradient - base saliency map visualization attention weight . approach aim provide explanation particular model prediction highlight important word corresponding input text . useful task decision explicitly influence individual token input , suspect highlighting suitable task model decision drive complex reasoning . work , investigate use influence function nlp , provide alternative approach interpret neural text classifier . influence function explain decision model identify influential training example . despite promise approach , influence function extensively evaluate context nlp , gap address work . conduct comparison influence function common word - saliency method representative task . suspect , find influence function particularly useful natural language inference , task ' saliency map ' provide clear interpretation . furthermore , develop new quantitative measure base influence function reveal artifact training datum . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 14, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Quantifying Attention Flow in Transformers,"In the Transformer model, ""self-attention"" combines information from attended embeddings into the representation of the focal embedding in the next layer. Thus, across layers of the Transformer, information originating from different tokens gets increasingly mixed. This makes attention weights unreliable as explanations probes. In this paper, we consider the problem of quantifying this flow of information through self-attention. We propose two methods for approximating the attention to input tokens given attention weights, attention rollout and attention flow, as post hoc methods when we use attention weights as the relative relevance of the input tokens. We show that these methods give complementary views on the flow of information, and compared to raw attention, both yield higher correlations with importance scores of input tokens obtained using an ablation method and input gradients.","Quantifying Attention Flow in Transformers In the Transformer model, ""self-attention"" combines information from attended embeddings into the representation of the focal embedding in the next layer. Thus, across layers of the Transformer, information originating from different tokens gets increasingly mixed. This makes attention weights unreliable as explanations probes. In this paper, we consider the problem of quantifying this flow of information through self-attention. We propose two methods for approximating the attention to input tokens given attention weights, attention rollout and attention flow, as post hoc methods when we use attention weights as the relative relevance of the input tokens. We show that these methods give complementary views on the flow of information, and compared to raw attention, both yield higher correlations with importance scores of input tokens obtained using an ablation method and input gradients.","quantify attention flow transformer transformer model , "" self - attention "" combine information attend embedding representation focal embedding layer . , layer transformer , information originate different token get increasingly mix . make attention weight unreliable explanation probe . paper , consider problem quantify flow information self - attention . propose method approximate attention input token give attention weight , attention rollout attention flow , post hoc method use attention weight relative relevance input token . method complementary view flow information , compare raw attention , yield high correlation importance score input token obtain ablation method input gradient .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 15, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Human Attention Maps for Text Classification: Do Humans and Neural Networks Focus on the Same Words?,"Motivated by human attention, computational attention mechanisms have been designed to help neural networks adjust their focus on specific parts of the input data. While attention mechanisms are claimed to achieve interpretability, little is known about the actual relationships between machine and human attention. In this work, we conduct the first quantitative assessment of human versus computational attention mechanisms for the text classification task. To achieve this, we design and conduct a large-scale crowd-sourcing study to collect human attention maps that encode the parts of a text that humans focus on when conducting text classification. Based on this new resource of human attention dataset for text classification, YELP-HAT, collected on the publicly available YELP dataset, we perform a quantitative comparative analysis of machine attention maps created by deep learning models and human attention maps. Our analysis offers insights into the relationships between human versus machine attention maps along three dimensions: overlap in word selections, distribution over lexical categories, and context-dependency of sentiment polarity. Our findings open promising future research opportunities ranging from supervised attention to the design of human-centric attentionbased explanations.","Human Attention Maps for Text Classification: Do Humans and Neural Networks Focus on the Same Words? Motivated by human attention, computational attention mechanisms have been designed to help neural networks adjust their focus on specific parts of the input data. While attention mechanisms are claimed to achieve interpretability, little is known about the actual relationships between machine and human attention. In this work, we conduct the first quantitative assessment of human versus computational attention mechanisms for the text classification task. To achieve this, we design and conduct a large-scale crowd-sourcing study to collect human attention maps that encode the parts of a text that humans focus on when conducting text classification. Based on this new resource of human attention dataset for text classification, YELP-HAT, collected on the publicly available YELP dataset, we perform a quantitative comparative analysis of machine attention maps created by deep learning models and human attention maps. Our analysis offers insights into the relationships between human versus machine attention maps along three dimensions: overlap in word selections, distribution over lexical categories, and context-dependency of sentiment polarity. Our findings open promising future research opportunities ranging from supervised attention to the design of human-centric attentionbased explanations.","human attention map text classification : human neural network focus word ? motivate human attention , computational attention mechanism design help neural network adjust focus specific part input datum . attention mechanism claim achieve interpretability , little know actual relationship machine human attention . work , conduct quantitative assessment human versus computational attention mechanism text classification task . achieve , design conduct large - scale crowd - sourcing study collect human attention map encode part text human focus conduct text classification . base new resource human attention dataset text classification , yelp - hat , collect publicly available yelp dataset , perform quantitative comparative analysis machine attention map create deep learning model human attention map . analysis offer insight relationship human versus machine attention map dimension : overlap word selection , distribution lexical category , context - dependency sentiment polarity . finding open promising future research opportunity range supervise attention design human - centric attentionbased explanation .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 14, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
Interpretability and Analysis of Models for NLP,Probing for Referential Information in Language Models,"Language models keep track of complex linguistic information about the preceding context -including, e.g., syntactic relations in a sentence. We investigate whether they also capture information beneficial for resolving pronominal anaphora in English. We analyze two state of the art models with LSTM and Transformer architectures, respectively, using probe tasks on a coreference annotated corpus. Our hypothesis is that language models will capture grammatical properties of anaphora (such as agreement between a pronoun and its antecedent), but not semantico-referential information (the fact that pronoun and antecedent refer to the same entity). Instead, we find evidence that models capture referential aspects to some extent -though they are still much better at grammar. The Transformer outperforms the LSTM in all analyses, and exhibits in particular better semantico-referential abilities.","Probing for Referential Information in Language Models Language models keep track of complex linguistic information about the preceding context -including, e.g., syntactic relations in a sentence. We investigate whether they also capture information beneficial for resolving pronominal anaphora in English. We analyze two state of the art models with LSTM and Transformer architectures, respectively, using probe tasks on a coreference annotated corpus. Our hypothesis is that language models will capture grammatical properties of anaphora (such as agreement between a pronoun and its antecedent), but not semantico-referential information (the fact that pronoun and antecedent refer to the same entity). Instead, we find evidence that models capture referential aspects to some extent -though they are still much better at grammar. The Transformer outperforms the LSTM in all analyses, and exhibits in particular better semantico-referential abilities.","probe referential information language model language model track complex linguistic information preceding context -include , e.g. , syntactic relation sentence . investigate capture information beneficial resolve pronominal anaphora english . analyze state art model lstm transformer architecture , respectively , probe task coreference annotate corpus . hypothesis language model capture grammatical property anaphora ( agreement pronoun antecedent ) , semantico - referential information ( fact pronoun antecedent refer entity ) . instead , find evidence model capture referential aspect extent -though well grammar . transformer outperform lstm analysis , exhibit particular well semantico - referential ability .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Interpretability and Analysis of Models for NLP,Understanding Attention for Text Classification,"Attention has been proven successful in many natural language processing (NLP) tasks. Recently, many researchers started to investigate the interpretability of attention on NLP tasks. Many existing approaches focused on examining whether the local attention weights could reflect the importance of input representations. In this work, we present a study on understanding the internal mechanism of attention by looking into the gradient update process, checking its behavior when approaching a local minimum during training. We propose to analyze for each word token the following two quantities: its polarity score and its attention score, where the latter is a global assessment on the token's significance. We discuss conditions under which the attention mechanism may become more (or less) interpretable, and show how the interplay between the two quantities may impact the model performance. 1","Understanding Attention for Text Classification Attention has been proven successful in many natural language processing (NLP) tasks. Recently, many researchers started to investigate the interpretability of attention on NLP tasks. Many existing approaches focused on examining whether the local attention weights could reflect the importance of input representations. In this work, we present a study on understanding the internal mechanism of attention by looking into the gradient update process, checking its behavior when approaching a local minimum during training. We propose to analyze for each word token the following two quantities: its polarity score and its attention score, where the latter is a global assessment on the token's significance. We discuss conditions under which the attention mechanism may become more (or less) interpretable, and show how the interplay between the two quantities may impact the model performance. 1","understand attention text classification attention prove successful natural language processing ( nlp ) task . recently , researcher start investigate interpretability attention nlp task . exist approach focus examine local attention weight reflect importance input representation . work , present study understand internal mechanism attention look gradient update process , check behavior approach local minimum training . propose analyze word token follow quantity : polarity score attention score , global assessment token significance . discuss condition attention mechanism ( ) interpretable , interplay quantity impact model performance . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 8, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,True
"Language Grounding to Vision, Robotics and Beyond",Mapping Natural Language Instructions to Mobile UI Action Sequences,"We present a new problem: grounding natural language instructions to mobile user interface actions, and create three new datasets for it. For full task evaluation, we create PIX-ELHELP, a corpus that pairs English instructions with actions performed by people on a mobile UI emulator. To scale training, we decouple the language and action data by (a) annotating action phrase spans in HowTo instructions and (b) synthesizing grounded descriptions of actions for mobile user interfaces. We use a Transformer to extract action phrase tuples from long-range natural language instructions. A grounding Transformer then contextually represents UI objects using both their content and screen position and connects them to object descriptions. Given a starting screen and instruction, our model achieves 70.59% accuracy on predicting complete ground-truth action sequences in PIXELHELP.","Mapping Natural Language Instructions to Mobile UI Action Sequences We present a new problem: grounding natural language instructions to mobile user interface actions, and create three new datasets for it. For full task evaluation, we create PIX-ELHELP, a corpus that pairs English instructions with actions performed by people on a mobile UI emulator. To scale training, we decouple the language and action data by (a) annotating action phrase spans in HowTo instructions and (b) synthesizing grounded descriptions of actions for mobile user interfaces. We use a Transformer to extract action phrase tuples from long-range natural language instructions. A grounding Transformer then contextually represents UI objects using both their content and screen position and connects them to object descriptions. Given a starting screen and instruction, our model achieves 70.59% accuracy on predicting complete ground-truth action sequences in PIXELHELP.","map natural language instruction mobile ui action sequence present new problem : ground natural language instruction mobile user interface action , create new dataset . task evaluation , create pix - elhelp , corpus pair english instruction action perform people mobile ui emulator . scale training , decouple language action datum ( ) annotate action phrase span howto instruction ( b ) synthesize ground description action mobile user interface . use transformer extract action phrase tuple long - range natural language instruction . ground transformer contextually represent ui object content screen position connect object description . give start screen instruction , model achieve 70.59 % accuracy predict complete ground - truth action sequence pixelhelp .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 16, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 9, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Cross-Modality Relevance for Reasoning on Language and Vision,"This work deals with the challenge of learning and reasoning over language and vision data for the related downstream tasks such as visual question answering (VQA) and natural language for visual reasoning (NLVR). We design a novel cross-modality relevance module that is used in an end-to-end framework to learn the relevance representation between components of various input modalities under the supervision of a target task, which is more generalizable to unobserved data compared to merely reshaping the original representation space. In addition to modeling the relevance between the textual entities and visual entities, we model the higher-order relevance between entity relations in the text and object relations in the image. Our proposed approach shows competitive performance on two different language and vision tasks using public benchmarks and improves the state-of-the-art published results. The learned alignments of input spaces and their relevance representations by NLVR task boost the training efficiency of VQA task.","Cross-Modality Relevance for Reasoning on Language and Vision This work deals with the challenge of learning and reasoning over language and vision data for the related downstream tasks such as visual question answering (VQA) and natural language for visual reasoning (NLVR). We design a novel cross-modality relevance module that is used in an end-to-end framework to learn the relevance representation between components of various input modalities under the supervision of a target task, which is more generalizable to unobserved data compared to merely reshaping the original representation space. In addition to modeling the relevance between the textual entities and visual entities, we model the higher-order relevance between entity relations in the text and object relations in the image. Our proposed approach shows competitive performance on two different language and vision tasks using public benchmarks and improves the state-of-the-art published results. The learned alignments of input spaces and their relevance representations by NLVR task boost the training efficiency of VQA task.","cross - modality relevance reasoning language vision work deal challenge learn reason language vision datum related downstream task visual question answering ( vqa ) natural language visual reasoning ( nlvr ) . design novel cross - modality relevance module end - - end framework learn relevance representation component input modality supervision target task , generalizable unobserved datum compare merely reshape original representation space . addition model relevance textual entity visual entity , model high - order relevance entity relation text object relation image . propose approach show competitive performance different language vision task public benchmark improve state - - - art publish result . learn alignment input space relevance representation nlvr task boost training efficiency vqa task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 13, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",TVQA+: Spatio-Temporal Grounding for Video Question Answering,"We present the task of Spatio-Temporal Video Question Answering, which requires intelligent systems to simultaneously retrieve relevant moments and detect referenced visual concepts (people and objects) to answer natural language questions about videos. We first augment the TVQA dataset with 310.8K bounding boxes, linking depicted objects to visual concepts in questions and answers. We name this augmented version as TVQA+. We then propose Spatio-Temporal Answerer with Grounded Evidence (STAGE), a unified framework that grounds evidence in both spatial and temporal domains to answer questions about videos. Comprehensive experiments and analyses demonstrate the effectiveness of our framework and how the rich annotations in our TVQA+ dataset can contribute to the question answering task. Moreover, by performing this joint task, our model is able to produce insightful and interpretable spatio-temporal attention visualizations. 1","TVQA+: Spatio-Temporal Grounding for Video Question Answering We present the task of Spatio-Temporal Video Question Answering, which requires intelligent systems to simultaneously retrieve relevant moments and detect referenced visual concepts (people and objects) to answer natural language questions about videos. We first augment the TVQA dataset with 310.8K bounding boxes, linking depicted objects to visual concepts in questions and answers. We name this augmented version as TVQA+. We then propose Spatio-Temporal Answerer with Grounded Evidence (STAGE), a unified framework that grounds evidence in both spatial and temporal domains to answer questions about videos. Comprehensive experiments and analyses demonstrate the effectiveness of our framework and how the rich annotations in our TVQA+ dataset can contribute to the question answering task. Moreover, by performing this joint task, our model is able to produce insightful and interpretable spatio-temporal attention visualizations. 1","tvqa+ : spatio - temporal grounding video question answering present task spatio - temporal video question answering , require intelligent system simultaneously retrieve relevant moment detect reference visual concept ( people object ) answer natural language question video . augment tvqa dataset 310.8 k bounding box , link depict object visual concept question answer . augment version tvqa+ . propose spatio - temporal answerer grounded evidence ( stage ) , unified framework ground evidence spatial temporal domain answer question video . comprehensive experiment analysis demonstrate effectiveness framework rich annotation tvqa+ dataset contribute question answer task . , perform joint task , model able produce insightful interpretable spatio - temporal attention visualization . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 13, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 25, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning,"We present a method for combining multiagent communication and traditional datadriven approaches to natural language learning, with an end goal of teaching agents to communicate with humans in natural language. Our starting point is a language model that has been trained on generic, not task-specific language data. We then place this model in a multi-agent self-play environment that generates task-specific rewards used to adapt or modulate the model, turning it into a taskconditional language model. We introduce a new way for combining the two types of learning based on the idea of reranking language model samples, and show that this method outperforms others in communicating with humans in a visual referential communication task. Finally, we present a taxonomy of different types of language drift that can occur alongside a set of measures to detect them.","Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning We present a method for combining multiagent communication and traditional datadriven approaches to natural language learning, with an end goal of teaching agents to communicate with humans in natural language. Our starting point is a language model that has been trained on generic, not task-specific language data. We then place this model in a multi-agent self-play environment that generates task-specific rewards used to adapt or modulate the model, turning it into a taskconditional language model. We introduce a new way for combining the two types of learning based on the idea of reranking language model samples, and show that this method outperforms others in communicating with humans in a visual referential communication task. Finally, we present a taxonomy of different types of language drift that can occur alongside a set of measures to detect them.","multi - agent communication meet natural language : synergies functional structural language learning present method combine multiagent communication traditional datadriven approach natural language learning , end goal teach agent communicate human natural language . starting point language model train generic , task - specific language datum . place model multi - agent self - play environment generate task - specific reward adapt modulate model , turn taskconditional language model . introduce new way combine type learning base idea reranke language model sample , method outperform communicate human visual referential communication task . finally , present taxonomy different type language drift occur alongside set measure detect .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Language Grounding to Vision, Robotics and Beyond",Cross-media Structured Common Space for Multimedia Event Extraction,"We introduce a new task, MultiMedia Event Extraction (M 2 E 2 ), which aims to extract events and their arguments from multimedia documents. We develop the first benchmark and collect a dataset of 245 multimedia news articles with extensively annotated events and arguments. 1 We propose a novel method, Weakly Aligned Structured Embedding (WASE), that encodes structured representations of semantic information from textual and visual data into a common embedding space. The structures are aligned across modalities by employing a weakly supervised training strategy, which enables exploiting available resources without explicit cross-media annotation. Compared to unimodal state-of-the-art methods, our approach achieves 4.0% and 9.8% absolute F-score gains on text event argument role labeling and visual event extraction. Compared to stateof-the-art multimedia unstructured representations, we achieve 8.3% and 5.0% absolute Fscore gains on multimedia event extraction and argument role labeling, respectively. By utilizing images, we extract 21.4% more event mentions than traditional text-only methods.","Cross-media Structured Common Space for Multimedia Event Extraction We introduce a new task, MultiMedia Event Extraction (M 2 E 2 ), which aims to extract events and their arguments from multimedia documents. We develop the first benchmark and collect a dataset of 245 multimedia news articles with extensively annotated events and arguments. 1 We propose a novel method, Weakly Aligned Structured Embedding (WASE), that encodes structured representations of semantic information from textual and visual data into a common embedding space. The structures are aligned across modalities by employing a weakly supervised training strategy, which enables exploiting available resources without explicit cross-media annotation. Compared to unimodal state-of-the-art methods, our approach achieves 4.0% and 9.8% absolute F-score gains on text event argument role labeling and visual event extraction. Compared to stateof-the-art multimedia unstructured representations, we achieve 8.3% and 5.0% absolute Fscore gains on multimedia event extraction and argument role labeling, respectively. By utilizing images, we extract 21.4% more event mentions than traditional text-only methods.","cross - media structured common space multimedia event extraction introduce new task , multimedia event extraction ( m 2 e 2 ) , aim extract event argument multimedia document . develop benchmark collect dataset 245 multimedia news article extensively annotate event argument . 1 propose novel method , weakly align structured embedding ( wase ) , encode structure representation semantic information textual visual datum common embedding space . structure align modality employ weakly supervise training strategy , enable exploit available resource explicit cross - media annotation . compare unimodal state - - - art method , approach achieve 4.0 % 9.8 % absolute f - score gain text event argument role labeling visual event extraction . compare stateof - - art multimedia unstructured representation , achieve 8.3 % 5.0 % absolute fscore gain multimedia event extraction argument role labeling , respectively . utilize image , extract 21.4 % event mention traditional text - method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
"Language Grounding to Vision, Robotics and Beyond",Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context,"We explore learning web-based tasks from a human teacher through natural language explanations and a single demonstration. Our approach investigates a new direction for semantic parsing that models explaining a demonstration in a context, rather than mapping explanations to demonstrations. By leveraging the idea of inverse semantics from program synthesis to reason backwards from observed demonstrations, we ensure that all considered interpretations are consistent with executable actions in any context, thus simplifying the problem of search over logical forms. We present a dataset of explanations paired with demonstrations for web-based tasks. Our methods show better task completion rates than a supervised semantic parsing baseline (40% relative improvement on average), and are competitive with simple exploration-anddemonstration based methods, while requiring no exploration of the environment. In learning to align explanations with demonstrations, basic properties of natural language syntax emerge as learned behavior. This is an interesting example of pragmatic language acquisition without any linguistic annotation. * *Work done while the first author was at Microsoft Research. Task: Forward an email Click on the segment that mentions Maureen Click on the button name ""Forward"" at the bottom of the page Type in the word 'Amata' in front of the row tagged 'to' Click on the arrow button at the top of the page Task: Select a radio button Focus on the word sequence after Select Click on the radio button to the left of the word sequence Press submit","Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context We explore learning web-based tasks from a human teacher through natural language explanations and a single demonstration. Our approach investigates a new direction for semantic parsing that models explaining a demonstration in a context, rather than mapping explanations to demonstrations. By leveraging the idea of inverse semantics from program synthesis to reason backwards from observed demonstrations, we ensure that all considered interpretations are consistent with executable actions in any context, thus simplifying the problem of search over logical forms. We present a dataset of explanations paired with demonstrations for web-based tasks. Our methods show better task completion rates than a supervised semantic parsing baseline (40% relative improvement on average), and are competitive with simple exploration-anddemonstration based methods, while requiring no exploration of the environment. In learning to align explanations with demonstrations, basic properties of natural language syntax emerge as learned behavior. This is an interesting example of pragmatic language acquisition without any linguistic annotation. * *Work done while the first author was at Microsoft Research. Task: Forward an email Click on the segment that mentions Maureen Click on the button name ""Forward"" at the bottom of the page Type in the word 'Amata' in front of the row tagged 'to' Click on the arrow button at the top of the page Task: Select a radio button Focus on the word sequence after Select Click on the radio button to the left of the word sequence Press submit","learn web - base procedure reason explanation demonstration context explore learn web - base task human teacher natural language explanation single demonstration . approach investigate new direction semantic parsing model explain demonstration context , map explanation demonstration . leverage idea inverse semantic program synthesis reason backwards observe demonstration , ensure consider interpretation consistent executable action context , simplify problem search logical form . present dataset explanation pair demonstration web - base task . method well task completion rate supervise semantic parsing baseline ( 40 % relative improvement average ) , competitive simple exploration - anddemonstration base method , require exploration environment . learn align explanation demonstration , basic property natural language syntax emerge learn behavior . interesting example pragmatic language acquisition linguistic annotation . * * work author microsoft research . task : forward email click segment mention maureen click button "" forward "" page type word ' amata ' row tag ' ' click arrow button page task : select radio button focus word sequence select click radio button left word sequence press submit","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
"Language Grounding to Vision, Robotics and Beyond",Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting,"Unsupervised machine translation (MT) has recently achieved impressive results with monolingual corpora only. However, it is still challenging to associate source-target sentences in the latent space. As people speak different languages biologically share similar visual systems, the potential of achieving better alignment through visual content is promising yet under-explored in unsupervised multimodal MT (MMT). In this paper, we investigate how to utilize visual content for disambiguation and promoting latent space alignment in unsupervised MMT. Our model employs multimodal back-translation and features pseudo visual pivoting in which we learn a shared multilingual visual-semantic embedding space and incorporate visuallypivoted captioning as additional weak supervision. The experimental results on the widely used Multi30K dataset show that the proposed model significantly improves over the state-ofthe-art methods and generalizes well when images are not available at the testing time.","Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting Unsupervised machine translation (MT) has recently achieved impressive results with monolingual corpora only. However, it is still challenging to associate source-target sentences in the latent space. As people speak different languages biologically share similar visual systems, the potential of achieving better alignment through visual content is promising yet under-explored in unsupervised multimodal MT (MMT). In this paper, we investigate how to utilize visual content for disambiguation and promoting latent space alignment in unsupervised MMT. Our model employs multimodal back-translation and features pseudo visual pivoting in which we learn a shared multilingual visual-semantic embedding space and incorporate visuallypivoted captioning as additional weak supervision. The experimental results on the widely used Multi30K dataset show that the proposed model significantly improves over the state-ofthe-art methods and generalizes well when images are not available at the testing time.","unsupervised multimodal neural machine translation pseudo visual pivoting unsupervised machine translation ( mt ) recently achieve impressive result monolingual corpora . , challenging associate source - target sentence latent space . people speak different language biologically share similar visual system , potential achieve well alignment visual content promising - explore unsupervised multimodal mt ( mmt ) . paper , investigate utilize visual content disambiguation promote latent space alignment unsupervised mmt . model employ multimodal - translation feature pseudo visual pivoting learn share multilingual visual - semantic embedding space incorporate visuallypivoted captioning additional weak supervision . experimental result widely multi30 k dataset propose model significantly improve state - ofthe - art method generalize image available testing time .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 9, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",A negative case analysis of visual grounding methods for VQA,"Existing Visual Question Answering (VQA) methods tend to exploit dataset biases and spurious statistical correlations, instead of producing right answers for the right reasons. To address this issue, recent bias mitigation methods for VQA propose to incorporate visual cues (e.g., human attention maps) to better ground the VQA models, showcasing impressive gains. However, we show that the performance improvements are not a result of improved visual grounding, but a regularization effect which prevents over-fitting to linguistic priors. For instance, we find that it is not actually necessary to provide proper, humanbased cues; random, insensible cues also result in similar improvements. Based on this observation, we propose a simpler regularization scheme that does not require any external annotations and yet achieves near state-of-theart performance on VQA-CPv2 1 .","A negative case analysis of visual grounding methods for VQA Existing Visual Question Answering (VQA) methods tend to exploit dataset biases and spurious statistical correlations, instead of producing right answers for the right reasons. To address this issue, recent bias mitigation methods for VQA propose to incorporate visual cues (e.g., human attention maps) to better ground the VQA models, showcasing impressive gains. However, we show that the performance improvements are not a result of improved visual grounding, but a regularization effect which prevents over-fitting to linguistic priors. For instance, we find that it is not actually necessary to provide proper, humanbased cues; random, insensible cues also result in similar improvements. Based on this observation, we propose a simpler regularization scheme that does not require any external annotations and yet achieves near state-of-theart performance on VQA-CPv2 1 .","negative case analysis visual grounding method vqa exist visual question answering ( vqa ) method tend exploit dataset bias spurious statistical correlation , instead produce right answer right reason . address issue , recent bias mitigation method vqa propose incorporate visual cue ( e.g. , human attention map ) well ground vqa model , showcase impressive gain . , performance improvement result improve visual grounding , regularization effect prevent - fit linguistic prior . instance , find actually necessary provide proper , humanbased cue ; random , insensible cue result similar improvement . base observation , propose simple regularization scheme require external annotation achieve near state - - theart performance vqa - cpv2 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 9, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",Shaping Visual Representations with Language for Few-Shot Classification,"By describing the features and abstractions of our world, language is a crucial tool for human learning and a promising source of supervision for machine learning models. We use language to improve few-shot visual classification in the underexplored scenario where natural language task descriptions are available during training, but unavailable for novel tasks at test time. Existing models for this setting sample new descriptions at test time and use those to classify images. Instead, we propose language-shaped learning (LSL), an end-toend model that regularizes visual representations to predict language. LSL is conceptually simpler, more data efficient, and outperforms baselines in two challenging few-shot domains. c Meta (Snell et al., 2017) Support c Query f Î¸ True LSTM-Dec g Ï• L3 (Andreas et al.","Shaping Visual Representations with Language for Few-Shot Classification By describing the features and abstractions of our world, language is a crucial tool for human learning and a promising source of supervision for machine learning models. We use language to improve few-shot visual classification in the underexplored scenario where natural language task descriptions are available during training, but unavailable for novel tasks at test time. Existing models for this setting sample new descriptions at test time and use those to classify images. Instead, we propose language-shaped learning (LSL), an end-toend model that regularizes visual representations to predict language. LSL is conceptually simpler, more data efficient, and outperforms baselines in two challenging few-shot domains. c Meta (Snell et al., 2017) Support c Query f Î¸ True LSTM-Dec g Ï• L3 (Andreas et al.","shape visual representation language - shot classification describe feature abstraction world , language crucial tool human learning promising source supervision machine learning model . use language improve - shot visual classification underexplored scenario natural language task description available training , unavailable novel task test time . exist model setting sample new description test time use classify image . instead , propose language - shape learning ( lsl ) , end - toend model regularize visual representation predict language . lsl conceptually simple , data efficient , outperform baseline challenging - shot domain . c meta ( snell et al . , 2017 ) support c query f Î¸ true lstm - dec g Ï• l3 ( andreas et al .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning,"Approaches to Grounded Language Learning typically focus on a single task-based final performance measure that may not depend on desirable properties of the learned hidden representations, such as their ability to predict salient attributes or to generalise to unseen situations. To remedy this, we present GROLLA, an evaluation framework for Grounded Language Learning with Attributes with three subtasks: 1) Goal-oriented evaluation; 2) Object attribute prediction evaluation; and 3) Zeroshot evaluation. We also propose a new dataset CompGuessWhat?! as an instance of this framework for evaluating the quality of learned neural representations, in particular concerning attribute grounding. To this end, we extend the original GuessWhat?! dataset by including a semantic layer on top of the perceptual one. Specifically, we enrich the Vi-sualGenome scene graphs associated with the GuessWhat?! images with abstract and situated attributes. By using diagnostic classifiers, we show that current models learn representations that are not expressive enough to encode object attributes (average F1 of 44.27). In addition, they do not learn strategies nor representations that are robust enough to perform well when novel scenes or objects are involved in gameplay (zero-shot best accuracy 50.06%).","CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning Approaches to Grounded Language Learning typically focus on a single task-based final performance measure that may not depend on desirable properties of the learned hidden representations, such as their ability to predict salient attributes or to generalise to unseen situations. To remedy this, we present GROLLA, an evaluation framework for Grounded Language Learning with Attributes with three subtasks: 1) Goal-oriented evaluation; 2) Object attribute prediction evaluation; and 3) Zeroshot evaluation. We also propose a new dataset CompGuessWhat?! as an instance of this framework for evaluating the quality of learned neural representations, in particular concerning attribute grounding. To this end, we extend the original GuessWhat?! dataset by including a semantic layer on top of the perceptual one. Specifically, we enrich the Vi-sualGenome scene graphs associated with the GuessWhat?! images with abstract and situated attributes. By using diagnostic classifiers, we show that current models learn representations that are not expressive enough to encode object attributes (average F1 of 44.27). In addition, they do not learn strategies nor representations that are robust enough to perform well when novel scenes or objects are involved in gameplay (zero-shot best accuracy 50.06%).","compguesswhat ? ! : multi - task evaluation framework grounded language learning approach grounded language learning typically focus single task - base final performance measure depend desirable property learn hide representation , ability predict salient attribute generalise unseen situation . remedy , present grolla , evaluation framework grounded language learning attribute subtask : 1 ) goal - orient evaluation ; 2 ) object attribute prediction evaluation ; 3 ) zeroshot evaluation . propose new dataset compguesswhat ? ! instance framework evaluate quality learn neural representation , particular concern attribute grounding . end , extend original guesswhat ? ! dataset include semantic layer perceptual . specifically , enrich vi - sualgenome scene graph associate guesswhat ? ! image abstract situated attribute . diagnostic classifier , current model learn representation expressive encode object attribute ( average f1 44.27 ) . addition , learn strategy representation robust perform novel scene object involve gameplay ( zero - shot good accuracy 50.06 % ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Language Grounding to Vision, Robotics and Beyond",Multimodal Neural Graph Memory Networks for Visual Question Answering,"We introduce a new neural network architecture, Multimodal Neural Graph Memory Networks (MN-GMN), for visual question answering. The MN-GMN uses graph structure with different region features as node attributes and applies a recently proposed powerful graph neural network model, Graph Network (GN), to reason about objects and their interactions in an image. The input module of the MN-GMN generates a set of visual features plus a set of encoded region-grounded captions (RGCs) for the image. The RGCs capture object attributes and their relationships. Two GNs are constructed from the input module using the visual features and encoded RGCs. Each node of the GNs iteratively computes a questionguided contextualized representation of the visual/textual information assigned to it. Then, to combine the information from both GNs, the nodes write the updated representations to an external spatial memory. The final states of the memory cells are fed into an answer module to predict an answer. Experiments show MN-GMN rivals the state-of-the-art models on Visual7W, VQA-v2.0, and CLEVR datasets.","Multimodal Neural Graph Memory Networks for Visual Question Answering We introduce a new neural network architecture, Multimodal Neural Graph Memory Networks (MN-GMN), for visual question answering. The MN-GMN uses graph structure with different region features as node attributes and applies a recently proposed powerful graph neural network model, Graph Network (GN), to reason about objects and their interactions in an image. The input module of the MN-GMN generates a set of visual features plus a set of encoded region-grounded captions (RGCs) for the image. The RGCs capture object attributes and their relationships. Two GNs are constructed from the input module using the visual features and encoded RGCs. Each node of the GNs iteratively computes a questionguided contextualized representation of the visual/textual information assigned to it. Then, to combine the information from both GNs, the nodes write the updated representations to an external spatial memory. The final states of the memory cells are fed into an answer module to predict an answer. Experiments show MN-GMN rivals the state-of-the-art models on Visual7W, VQA-v2.0, and CLEVR datasets.","multimodal neural graph memory networks visual question answering introduce new neural network architecture , multimodal neural graph memory networks ( mn - gmn ) , visual question answering . mn - gmn use graph structure different region feature node attribute apply recently propose powerful graph neural network model , graph network ( gn ) , reason object interaction image . input module mn - gmn generate set visual feature plus set encode region - ground caption ( rgcs ) image . rgc capture object attribute relationship . gn construct input module visual feature encode rgc . node gn iteratively compute questionguided contextualize representation visual / textual information assign . , combine information gn , node write update representation external spatial memory . final state memory cell feed answer module predict answer . experiment mn - gmn rival state - - - art model visual7w , vqa - v2.0 , clevr dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 13, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 14, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning,"Generating multi-sentence descriptions for videos is one of the most challenging captioning tasks due to its high requirements for not only visual relevance but also discoursebased coherence across the sentences in the paragraph. Towards this goal, we propose a new approach called Memory-Augmented Recurrent Transformer (MART), which uses a memory module to augment the transformer architecture. The memory module generates a highly summarized memory state from the video segments and the sentence history so as to help better prediction of the next sentence (w.r.t. coreference and repetition aspects), thus encouraging coherent paragraph generation. Extensive experiments, human evaluations, and qualitative analyses on two popular datasets ActivityNet Captions and YouCookII show that MART generates more coherent and less repetitive paragraph captions than baseline methods, while maintaining relevance to the input video events. 1 * Work done while Jie Lei was an intern and Yelong Shen was an employee at Tencent AI Lab.","MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning Generating multi-sentence descriptions for videos is one of the most challenging captioning tasks due to its high requirements for not only visual relevance but also discoursebased coherence across the sentences in the paragraph. Towards this goal, we propose a new approach called Memory-Augmented Recurrent Transformer (MART), which uses a memory module to augment the transformer architecture. The memory module generates a highly summarized memory state from the video segments and the sentence history so as to help better prediction of the next sentence (w.r.t. coreference and repetition aspects), thus encouraging coherent paragraph generation. Extensive experiments, human evaluations, and qualitative analyses on two popular datasets ActivityNet Captions and YouCookII show that MART generates more coherent and less repetitive paragraph captions than baseline methods, while maintaining relevance to the input video events. 1 * Work done while Jie Lei was an intern and Yelong Shen was an employee at Tencent AI Lab.","mart : memory - augment recurrent transformer coherent video paragraph captioning generate multi - sentence description video challenging captioning task high requirement visual relevance discoursebase coherence sentence paragraph . goal , propose new approach call memory - augmented recurrent transformer ( mart ) , use memory module augment transformer architecture . memory module generate highly summarize memory state video segment sentence history help well prediction sentence ( w.r.t . coreference repetition aspect ) , encourage coherent paragraph generation . extensive experiment , human evaluation , qualitative analysis popular dataset activitynet captions youcookii mart generate coherent repetitive paragraph caption baseline method , maintain relevance input video event . 1 * work jie lei intern yelong shen employee tencent ai lab .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 11, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",BabyWalk: Going Farther in Vision-and-Language Navigation by Taking Baby Steps,"Learning to follow instructions is of fundamental importance to autonomous agents for vision-and-language navigation (VLN). In this paper, we study how an agent can navigate long paths when learning from a corpus that consists of shorter ones. We show that existing state-of-the-art agents do not generalize well. To this end, we propose BabyWalk, a new VLN agent that is learned to navigate by decomposing long instructions into shorter ones (BabySteps) and completing them sequentially. A special design memory buffer is used by the agent to turn its past experiences into contexts for future steps. The learning process is composed of two phases. In the first phase, the agent uses imitation learning from demonstration to accomplish BabySteps. In the second phase, the agent uses curriculum-based reinforcement learning to maximize rewards on navigation tasks with increasingly longer instructions. We create two new benchmark datasets (of long navigation tasks) and use them in conjunction with existing ones to examine BabyWalk's generalization ability. Empirical results show that BabyWalk achieves state-of-the-art results on several metrics, in particular, is able to follow long instructions better. The codes and the datasets are released on our project page https://github.com/ Sha-Lab/babywalk.","BabyWalk: Going Farther in Vision-and-Language Navigation by Taking Baby Steps Learning to follow instructions is of fundamental importance to autonomous agents for vision-and-language navigation (VLN). In this paper, we study how an agent can navigate long paths when learning from a corpus that consists of shorter ones. We show that existing state-of-the-art agents do not generalize well. To this end, we propose BabyWalk, a new VLN agent that is learned to navigate by decomposing long instructions into shorter ones (BabySteps) and completing them sequentially. A special design memory buffer is used by the agent to turn its past experiences into contexts for future steps. The learning process is composed of two phases. In the first phase, the agent uses imitation learning from demonstration to accomplish BabySteps. In the second phase, the agent uses curriculum-based reinforcement learning to maximize rewards on navigation tasks with increasingly longer instructions. We create two new benchmark datasets (of long navigation tasks) and use them in conjunction with existing ones to examine BabyWalk's generalization ability. Empirical results show that BabyWalk achieves state-of-the-art results on several metrics, in particular, is able to follow long instructions better. The codes and the datasets are released on our project page https://github.com/ Sha-Lab/babywalk.","babywalk : go far vision - - language navigation take baby step learn follow instruction fundamental importance autonomous agent vision - - language navigation ( vln ) . paper , study agent navigate long path learn corpus consist short one . exist state - - - art agent generalize . end , propose babywalk , new vln agent learn navigate decompose long instruction short one ( babystep ) complete sequentially . special design memory buffer agent turn past experience context future step . learning process compose phase . phase , agent use imitation learning demonstration accomplish babysteps . second phase , agent use curriculum - base reinforcement learning maximize reward navigation task increasingly long instruction . create new benchmark dataset ( long navigation task ) use conjunction exist one examine babywalk generalization ability . empirical result babywalk achieve state - - - art result metric , particular , able follow long instruction well . code dataset release project page https://github.com/ sha - lab / babywalk .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
"Language Grounding to Vision, Robotics and Beyond",Learning to execute instructions in a Minecraft dialogue,"The Minecraft Collaborative Building Task is a two-player game in which an Architect A instructs a Builder B to construct a target structure out of 3D blocks. We consider the task of predicting B's action sequences (block placements and removals) in a given game context, and show that capturing B's past actions as well as B's perspective leads to a significant improvement in performance on this challenging language understanding problem.","Learning to execute instructions in a Minecraft dialogue The Minecraft Collaborative Building Task is a two-player game in which an Architect A instructs a Builder B to construct a target structure out of 3D blocks. We consider the task of predicting B's action sequences (block placements and removals) in a given game context, and show that capturing B's past actions as well as B's perspective leads to a significant improvement in performance on this challenging language understanding problem.","learn execute instruction minecraft dialogue minecraft collaborative building task - player game architect instruct builder b construct target structure 3d block . consider task predict b action sequence ( block placement removal ) give game context , capture b past action b perspective lead significant improvement performance challenge language understanding problem .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Learning to Segment Actions from Observation and Narration,"We apply a generative segmental model of task structure, guided by narration, to action segmentation in video. We focus on unsupervised and weakly-supervised settings where no action labels are known during training. Despite its simplicity, our model performs competitively with previous work on a dataset of naturalistic instructional videos. Our model allows us to vary the sources of supervision used in training, and we find that both task structure and narrative language provide large benefits in segmentation quality.","Learning to Segment Actions from Observation and Narration We apply a generative segmental model of task structure, guided by narration, to action segmentation in video. We focus on unsupervised and weakly-supervised settings where no action labels are known during training. Despite its simplicity, our model performs competitively with previous work on a dataset of naturalistic instructional videos. Our model allows us to vary the sources of supervision used in training, and we find that both task structure and narrative language provide large benefits in segmentation quality.","learn segment action observation narration apply generative segmental model task structure , guide narration , action segmentation video . focus unsupervised weakly - supervise setting action label know training . despite simplicity , model perform competitively previous work dataset naturalistic instructional video . model allow vary source supervision training , find task structure narrative language provide large benefit segmentation quality .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Knowledge Supports Visual Language Grounding: A Case Study on Colour Terms,"In human cognition, world knowledge supports the perception of object colours: knowing that trees are typically green helps to perceive their colour in certain contexts. We go beyond previous studies on colour terms using isolated colour swatches and study visual grounding of colour terms in realistic objects. Our models integrate processing of visual information and object-specific knowledge via hard-coded (late) or learned (early) fusion. We find that both models consistently outperform a bottom-up baseline that predicts colour terms solely from visual inputs, but show interesting differences when predicting atypical colours of so-called colour diagnostic objects. Our models also achieve promising results when tested on new object categories not seen during training.","Knowledge Supports Visual Language Grounding: A Case Study on Colour Terms In human cognition, world knowledge supports the perception of object colours: knowing that trees are typically green helps to perceive their colour in certain contexts. We go beyond previous studies on colour terms using isolated colour swatches and study visual grounding of colour terms in realistic objects. Our models integrate processing of visual information and object-specific knowledge via hard-coded (late) or learned (early) fusion. We find that both models consistently outperform a bottom-up baseline that predicts colour terms solely from visual inputs, but show interesting differences when predicting atypical colours of so-called colour diagnostic objects. Our models also achieve promising results when tested on new object categories not seen during training.","knowledge support visual language grounding : case study colour term human cognition , world knowledge support perception object colour : know tree typically green help perceive colour certain context . previous study colour term isolate colour swatch study visual grounding colour term realistic object . model integrate processing visual information object - specific knowledge hard - code ( late ) learn ( early ) fusion . find model consistently outperform - baseline predict colour term solely visual input , interesting difference predict atypical colour - call colour diagnostic object . model achieve promising result test new object category see training .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 18, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Aligned Dual Channel Graph Convolutional Network for Visual Question Answering,"Visual question answering aims to answer the natural language question about a given image. Existing graph-based methods only focus on the relations between objects in an image and neglect the importance of the syntactic dependency relations between words in a question. To simultaneously capture the relations between objects in an image and the syntactic dependency relations between words in a question, we propose a novel dual channel graph convolutional network (DC-GCN) for better combining visual and textual advantages. The DC-GCN model consists of three parts: an I-GCN module to capture the relations between objects in an image, a Q-GCN module to capture the syntactic dependency relations between words in a question, and an attention alignment module to align image representations and question representations. Experimental results show that our model achieves comparable performance with the state-of-theart approaches.","Aligned Dual Channel Graph Convolutional Network for Visual Question Answering Visual question answering aims to answer the natural language question about a given image. Existing graph-based methods only focus on the relations between objects in an image and neglect the importance of the syntactic dependency relations between words in a question. To simultaneously capture the relations between objects in an image and the syntactic dependency relations between words in a question, we propose a novel dual channel graph convolutional network (DC-GCN) for better combining visual and textual advantages. The DC-GCN model consists of three parts: an I-GCN module to capture the relations between objects in an image, a Q-GCN module to capture the syntactic dependency relations between words in a question, and an attention alignment module to align image representations and question representations. Experimental results show that our model achieves comparable performance with the state-of-theart approaches.","align dual channel graph convolutional network visual question answer visual question answering aim answer natural language question give image . exist graph - base method focus relation object image neglect importance syntactic dependency relation word question . simultaneously capture relation object image syntactic dependency relation word question , propose novel dual channel graph convolutional network ( dc - gcn ) well combine visual textual advantage . dc - gcn model consist part : - gcn module capture relation object image , q - gcn module capture syntactic dependency relation word question , attention alignment module align image representation question representation . experimental result model achieve comparable performance state - - theart approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 11, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 14, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",History for Visual Dialog: Do we really need it?,"Visual Dialog involves ""understanding"" the dialog history (what has been discussed previously) and the current question (what is asked), in addition to grounding information in the image, to generate the correct response. In this paper, we show that co-attention models which explicitly encode dialog history outperform models that don't, achieving state-ofthe-art performance (72 % NDCG on val set). However, we also expose shortcomings of the crowd-sourcing dataset collection procedure by showing that history is indeed only required for a small amount of the data and that the current evaluation metric encourages generic replies. To that end, we propose a challenging subset (VisDialConv) of the VisDial val set and provide a benchmark of 63% NDCG.","History for Visual Dialog: Do we really need it? Visual Dialog involves ""understanding"" the dialog history (what has been discussed previously) and the current question (what is asked), in addition to grounding information in the image, to generate the correct response. In this paper, we show that co-attention models which explicitly encode dialog history outperform models that don't, achieving state-ofthe-art performance (72 % NDCG on val set). However, we also expose shortcomings of the crowd-sourcing dataset collection procedure by showing that history is indeed only required for a small amount of the data and that the current evaluation metric encourages generic replies. To that end, we propose a challenging subset (VisDialConv) of the VisDial val set and provide a benchmark of 63% NDCG.","history visual dialog : need ? visual dialog involve "" understand "" dialog history ( discuss previously ) current question ( ask ) , addition ground information image , generate correct response . paper , co - attention model explicitly encode dialog history outperform model , achieve state - ofthe - art performance ( 72 % ndcg val set ) . , expose shortcoming crowd - sourcing dataset collection procedure show history require small datum current evaluation metric encourage generic reply . end , propose challenge subset ( visdialconv ) visdial val set provide benchmark 63 % ndcg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 5, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
"Language Grounding to Vision, Robotics and Beyond",Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA,"Videos convey rich information. Dynamic spatio-temporal relationships between people/objects, and diverse multimodal events are present in a video clip. Hence, it is important to develop automated models that can accurately extract such information from videos. Answering questions on videos is one of the tasks which can evaluate such AI abilities. In this paper, we propose a video question answering model which effectively integrates multi-modal input sources and finds the temporally relevant information to answer questions. Specifically, we first employ dense image captions to help identify objects and their detailed salient regions and actions, and hence give the model useful extra information (in explicit textual format to allow easier matching) for answering questions. Moreover, our model is also comprised of duallevel attention (word/object and frame level), multi-head self/cross-integration for different sources (video and dense captions), and gates which pass more relevant information to the classifier. Finally, we also cast the frame selection problem as a multi-label classification task and introduce two loss functions, In-and-Out Frame Score Margin (IOFSM) and Balanced Binary Cross-Entropy (BBCE), to better supervise the model with human importance annotations. We evaluate our model on the challenging TVQA dataset, where each of our model components provides significant gains, and our overall model outperforms the stateof-the-art by a large margin (74.09% versus 70.52%). We also present several word, object, and frame level visualization studies. 1","Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA Videos convey rich information. Dynamic spatio-temporal relationships between people/objects, and diverse multimodal events are present in a video clip. Hence, it is important to develop automated models that can accurately extract such information from videos. Answering questions on videos is one of the tasks which can evaluate such AI abilities. In this paper, we propose a video question answering model which effectively integrates multi-modal input sources and finds the temporally relevant information to answer questions. Specifically, we first employ dense image captions to help identify objects and their detailed salient regions and actions, and hence give the model useful extra information (in explicit textual format to allow easier matching) for answering questions. Moreover, our model is also comprised of duallevel attention (word/object and frame level), multi-head self/cross-integration for different sources (video and dense captions), and gates which pass more relevant information to the classifier. Finally, we also cast the frame selection problem as a multi-label classification task and introduce two loss functions, In-and-Out Frame Score Margin (IOFSM) and Balanced Binary Cross-Entropy (BBCE), to better supervise the model with human importance annotations. We evaluate our model on the challenging TVQA dataset, where each of our model components provides significant gains, and our overall model outperforms the stateof-the-art by a large margin (74.09% versus 70.52%). We also present several word, object, and frame level visualization studies. 1","dense - caption matching frame - selection gating temporal localization videoqa video convey rich information . dynamic spatio - temporal relationship people / object , diverse multimodal event present video clip . , important develop automate model accurately extract information video . answer question video task evaluate ai ability . paper , propose video question answer model effectively integrate multi - modal input source find temporally relevant information answer question . specifically , employ dense image caption help identify object detailed salient region action , model useful extra information ( explicit textual format allow easy matching ) answer question . , model comprise duallevel attention ( word / object frame level ) , multi - head self / cross - integration different source ( video dense caption ) , gate pass relevant information classifier . finally , cast frame selection problem multi - label classification task introduce loss function , - - frame score margin ( iofsm ) balanced binary cross - entropy ( bbce ) , well supervise model human importance annotation . evaluate model challenging tvqa dataset , model component provide significant gain , overall model outperform stateof - - art large margin ( 74.09 % versus 70.52 % ) . present word , object , frame level visualization study . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 18, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond","Words Aren't Enough, Their Order Matters: On the Robustness of Grounding Visual Referring Expressions","Drew A Hudson and Christopher D Manning. 2019. Gqa: A new dataset for real-world visual reasoning and compositional question answering. In IEEE Conference on Computer Vision and Pattern Recognition, pages 6700-6709. Divyansh Kaushik, Eduard Hovy, and Zachary Lipton. 2020. Learning the difference that makes a difference with counterfactually-augmented data. In International Conference on Learning Representations.","Words Aren't Enough, Their Order Matters: On the Robustness of Grounding Visual Referring Expressions Drew A Hudson and Christopher D Manning. 2019. Gqa: A new dataset for real-world visual reasoning and compositional question answering. In IEEE Conference on Computer Vision and Pattern Recognition, pages 6700-6709. Divyansh Kaushik, Eduard Hovy, and Zachary Lipton. 2020. Learning the difference that makes a difference with counterfactually-augmented data. In International Conference on Learning Representations.","word , order matter : robustness ground visual referring expression drew hudson christopher d manning . 2019 . gqa : new dataset real - world visual reasoning compositional question answering . ieee conference computer vision pattern recognition , page 6700 - 6709 . divyansh kaushik , eduard hovy , zachary lipton . 2020 . learn difference make difference counterfactually - augment datum . international conference learning representation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 6, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Language Grounding to Vision, Robotics and Beyond",What is Learned in Visually Grounded Neural Syntax Acquisition,"Visual features are a promising signal for learning bootstrap textual models. However, blackbox learning models make it difficult to isolate the specific contribution of visual components. In this analysis, we consider the case study of the Visually Grounded Neural Syntax Learner (Shi et al., 2019) , a recent approach for learning syntax from a visual training signal. By constructing simplified versions of the model, we isolate the core factors that yield the model's strong performance. Contrary to what the model might be capable of learning, we find significantly less expressive versions produce similar predictions and perform just as well, or even better. We also find that a simple lexical signal of noun concreteness plays the main role in the model's predictions as opposed to more complex syntactic reasoning.","What is Learned in Visually Grounded Neural Syntax Acquisition Visual features are a promising signal for learning bootstrap textual models. However, blackbox learning models make it difficult to isolate the specific contribution of visual components. In this analysis, we consider the case study of the Visually Grounded Neural Syntax Learner (Shi et al., 2019) , a recent approach for learning syntax from a visual training signal. By constructing simplified versions of the model, we isolate the core factors that yield the model's strong performance. Contrary to what the model might be capable of learning, we find significantly less expressive versions produce similar predictions and perform just as well, or even better. We also find that a simple lexical signal of noun concreteness plays the main role in the model's predictions as opposed to more complex syntactic reasoning.","learn visually grounded neural syntax acquisition visual feature promising signal learn bootstrap textual model . , blackbox learning model difficult isolate specific contribution visual component . analysis , consider case study visually grounded neural syntax learner ( shi et al . , 2019 ) , recent approach learn syntax visual training signal . construct simplified version model , isolate core factor yield model strong performance . contrary model capable learn , find significantly expressive version produce similar prediction perform , well . find simple lexical signal noun concreteness play main role model prediction oppose complex syntactic reasoning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Cross-modal Coherence Modeling for Caption Generation,"We use coherence relations inspired by computational models of discourse to study the information needs and goals of image captioning. Using an annotation protocol specifically devised for capturing image-caption coherence relations, we annotate 10,000 instances from publicly-available image-caption pairs. We introduce a new task for learning inferences in imagery and text, coherence relation prediction, and show that these coherence annotations can be exploited to learn relation classifiers as an intermediary step, and also train coherence-aware, controllable image captioning models. The results show a dramatic improvement in the consistency and quality of the generated captions with respect to information needs specified via coherence relations.","Cross-modal Coherence Modeling for Caption Generation We use coherence relations inspired by computational models of discourse to study the information needs and goals of image captioning. Using an annotation protocol specifically devised for capturing image-caption coherence relations, we annotate 10,000 instances from publicly-available image-caption pairs. We introduce a new task for learning inferences in imagery and text, coherence relation prediction, and show that these coherence annotations can be exploited to learn relation classifiers as an intermediary step, and also train coherence-aware, controllable image captioning models. The results show a dramatic improvement in the consistency and quality of the generated captions with respect to information needs specified via coherence relations.","cross - modal coherence modeling caption generation use coherence relation inspire computational model discourse study information need goal image captioning . annotation protocol specifically devise capture image - caption coherence relation , annotate 10,000 instance publicly - available image - caption pair . introduce new task learn inference imagery text , coherence relation prediction , coherence annotation exploit learn relation classifier intermediary step , train coherence - aware , controllable image captioning model . result dramatic improvement consistency quality generate caption respect information need specify coherence relation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 8, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 11, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
"Language Grounding to Vision, Robotics and Beyond",Span-based Localizing Network for Natural Language Video Localization,"Given an untrimmed video and a text query, natural language video localization (NLVL) is to locate a matching span from the video that semantically corresponds to the query. Existing solutions formulate NLVL either as a ranking task and apply multimodal matching architecture, or as a regression task to directly regress the target video span. In this work, we address NLVL task with a span-based QA approach by treating the input video as text passage. We propose a video span localizing network (VSLNet), on top of the standard span-based QA framework, to address NLVL. The proposed VSLNet tackles the differences between NLVL and span-based QA through a simple and yet effective query-guided highlighting (QGH) strategy. The QGH guides VSLNet to search for matching video span within a highlighted region. Through extensive experiments on three benchmark datasets, we show that the proposed VSLNet outperforms the state-of-the-art methods; and adopting span-based QA framework is a promising direction to solve NLVL. 1","Span-based Localizing Network for Natural Language Video Localization Given an untrimmed video and a text query, natural language video localization (NLVL) is to locate a matching span from the video that semantically corresponds to the query. Existing solutions formulate NLVL either as a ranking task and apply multimodal matching architecture, or as a regression task to directly regress the target video span. In this work, we address NLVL task with a span-based QA approach by treating the input video as text passage. We propose a video span localizing network (VSLNet), on top of the standard span-based QA framework, to address NLVL. The proposed VSLNet tackles the differences between NLVL and span-based QA through a simple and yet effective query-guided highlighting (QGH) strategy. The QGH guides VSLNet to search for matching video span within a highlighted region. Through extensive experiments on three benchmark datasets, we show that the proposed VSLNet outperforms the state-of-the-art methods; and adopting span-based QA framework is a promising direction to solve NLVL. 1","span - base localizing network natural language video localization give untrimmed video text query , natural language video localization ( nlvl ) locate match span video semantically correspond query . exist solution formulate nlvl ranking task apply multimodal matching architecture , regression task directly regress target video span . work , address nlvl task span - base qa approach treat input video text passage . propose video span localize network ( vslnet ) , standard span - base qa framework , address nlvl . propose vslnet tackle difference nlvl span - base qa simple effective query - guide highlighting ( qgh ) strategy . qgh guide vslnet search match video span highlight region . extensive experiment benchmark dataset , propose vslnet outperform state - - - art method ; adopt span - base qa framework promising direction solve nlvl . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 8, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 4, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",True
Machine Learning for NLP,schuBERT: Optimizing Elements of BERT,"Transformers (Vaswani et al., 2017) have gradually become a key component for many state-of-the-art natural language representation models. A recent Transformer based model-BERT (Devlin et al., 2018) achieved state-of-the-art results on various natural language processing tasks, including GLUE, SQuAD v1.1, and SQuAD v2.0. This model however is computationally prohibitive and has a huge number of parameters. In this work we revisit the architecture choices of BERT in efforts to obtain a lighter model. We focus on reducing the number of parameters yet our methods can be applied towards other objectives such FLOPs or latency. We show that much efficient light BERT models can be obtained by reducing algorithmically chosen correct architecture design dimensions rather than reducing the number of Transformer encoder layers. In particular, our schuBERT gives 6.6% higher average accuracy on GLUE and SQuAD datasets as compared to BERT with three encoder layers while having the same number of parameters.","schuBERT: Optimizing Elements of BERT Transformers (Vaswani et al., 2017) have gradually become a key component for many state-of-the-art natural language representation models. A recent Transformer based model-BERT (Devlin et al., 2018) achieved state-of-the-art results on various natural language processing tasks, including GLUE, SQuAD v1.1, and SQuAD v2.0. This model however is computationally prohibitive and has a huge number of parameters. In this work we revisit the architecture choices of BERT in efforts to obtain a lighter model. We focus on reducing the number of parameters yet our methods can be applied towards other objectives such FLOPs or latency. We show that much efficient light BERT models can be obtained by reducing algorithmically chosen correct architecture design dimensions rather than reducing the number of Transformer encoder layers. In particular, our schuBERT gives 6.6% higher average accuracy on GLUE and SQuAD datasets as compared to BERT with three encoder layers while having the same number of parameters.","schubert : optimize elements bert transformers ( vaswani et al . , 2017 ) gradually key component state - - - art natural language representation model . recent transformer base model - bert ( devlin et al . , 2018 ) achieve state - - - art result natural language processing task , include glue , squad v1.1 , squad v2.0 . model computationally prohibitive huge number parameter . work revisit architecture choice bert effort obtain light model . focus reduce number parameter method apply objective flop latency . efficient light bert model obtain reduce algorithmically choose correct architecture design dimension reduce number transformer encoder layer . particular , schubert give 6.6 % high average accuracy glue squad dataset compare bert encoder layer have number parameter .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning,"Fine-tuning of pre-trained transformer models has become the standard approach for solving common NLP tasks (Devlin et al., 2019) . Most of the existing approaches rely on a randomly initialized classifier on top of such networks. We argue that this fine-tuning procedure is sub-optimal as the pre-trained model has no prior on the specific classifier labels, while it might have already learned an intrinsic textual representation of the task. In this paper, we introduce a new scoring method that casts a plausibility ranking task in a full-text format and leverages the masked language modeling head tuned during the pre-training phase. We study commonsense reasoning tasks where the model must rank a set of hypotheses given a premise, focusing on the COPA (Gordon et al., 2012) , Swag (Zellers et al., 2018), HellaSwag  (Zellers et al., 2019)  and CommonsenseQA  (Talmor et al., 2019)  datasets. By exploiting our scoring method without fine-tuning, we are able to produce strong baselines (e.g. 80% test accuracy on COPA) that are comparable to supervised approaches. Moreover, when fine-tuning directly on the proposed scoring function, we show that our method provides a much more stable training phase across random restarts (e.g Ã—10 standard deviation reduction on COPA test accuracy) and requires less annotated data than the standard classifier approach to reach equivalent performances.","Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning Fine-tuning of pre-trained transformer models has become the standard approach for solving common NLP tasks (Devlin et al., 2019) . Most of the existing approaches rely on a randomly initialized classifier on top of such networks. We argue that this fine-tuning procedure is sub-optimal as the pre-trained model has no prior on the specific classifier labels, while it might have already learned an intrinsic textual representation of the task. In this paper, we introduce a new scoring method that casts a plausibility ranking task in a full-text format and leverages the masked language modeling head tuned during the pre-training phase. We study commonsense reasoning tasks where the model must rank a set of hypotheses given a premise, focusing on the COPA (Gordon et al., 2012) , Swag (Zellers et al., 2018), HellaSwag  (Zellers et al., 2019)  and CommonsenseQA  (Talmor et al., 2019)  datasets. By exploiting our scoring method without fine-tuning, we are able to produce strong baselines (e.g. 80% test accuracy on COPA) that are comparable to supervised approaches. Moreover, when fine-tuning directly on the proposed scoring function, we show that our method provides a much more stable training phase across random restarts (e.g Ã—10 standard deviation reduction on COPA test accuracy) and requires less annotated data than the standard classifier approach to reach equivalent performances.","pre - training ( ) need : application commonsense reasoning fine - tuning pre - trained transformer model standard approach solve common nlp task ( devlin et al . , 2019 ) . exist approach rely randomly initialize classifier network . argue fine - tuning procedure sub - optimal pre - train model prior specific classifier label , learn intrinsic textual representation task . paper , introduce new scoring method cast plausibility ranking task - text format leverage mask language modeling head tune pre - training phase . study commonsense reasoning task model rank set hypothesis give premise , focus copa ( gordon et al . , 2012 ) , swag ( zellers et al . , 2018 ) , hellaswag   ( zellers et al . , 2019 )   commonsenseqa   ( talmor et al . , 2019 )   dataset . exploit scoring method fine - tuning , able produce strong baseline ( e.g. 80 % test accuracy copa ) comparable supervise approach . , fine - tune directly propose scoring function , method provide stable training phase random restart ( e.g Ã—10 standard deviation reduction copa test accuracy ) require annotate datum standard classifier approach reach equivalent performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Learning Architectures from an Extended Search Space for Language Modeling,"Neural architecture search (NAS) has advanced significantly in recent years but most NAS systems restrict search to learning architectures of a recurrent or convolutional cell. In this paper, we extend the search space of NAS. In particular, we present a general approach to learn both intra-cell and inter-cell architectures (call it ESS). For a better search result, we design a joint learning method to perform intra-cell and inter-cell NAS simultaneously. We implement our model in a differentiable architecture search system. For recurrent neural language modeling, it outperforms a strong baseline significantly on the PTB and Wiki-Text data, with a new state-of-the-art on PTB. Moreover, the learned architectures show good transferability to other systems. E.g., they improve state-of-the-art systems on the CoNLL and WNUT named entity recognition (NER) tasks and CoNLL chunking task, indicating a promising line of research on large-scale prelearned architectures.","Learning Architectures from an Extended Search Space for Language Modeling Neural architecture search (NAS) has advanced significantly in recent years but most NAS systems restrict search to learning architectures of a recurrent or convolutional cell. In this paper, we extend the search space of NAS. In particular, we present a general approach to learn both intra-cell and inter-cell architectures (call it ESS). For a better search result, we design a joint learning method to perform intra-cell and inter-cell NAS simultaneously. We implement our model in a differentiable architecture search system. For recurrent neural language modeling, it outperforms a strong baseline significantly on the PTB and Wiki-Text data, with a new state-of-the-art on PTB. Moreover, the learned architectures show good transferability to other systems. E.g., they improve state-of-the-art systems on the CoNLL and WNUT named entity recognition (NER) tasks and CoNLL chunking task, indicating a promising line of research on large-scale prelearned architectures.","learn architecture extend search space language modeling neural architecture search ( nas ) advance significantly recent year nas system restrict search learn architecture recurrent convolutional cell . paper , extend search space nas . particular , present general approach learn intra - cell inter - cell architecture ( ess ) . well search result , design joint learning method perform intra - cell inter - cell nas simultaneously . implement model differentiable architecture search system . recurrent neural language modeling , outperform strong baseline significantly ptb wiki - text datum , new state - - - art ptb . , learn architecture good transferability system . e.g. , improve state - - - art system conll wnut name entity recognition ( ner ) task conll chunking task , indicate promising line research large - scale prelearned architecture .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 11, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Machine Learning for NLP,A Mixture of h - 1 Heads is Better than h Heads,"Multi-head attentive neural architectures have achieved state-of-the-art results on a variety of natural language processing tasks. Evidence has shown that they are overparameterized; attention heads can be pruned without significant performance loss. In this work, we instead ""reallocate"" them-the model learns to activate different heads on different inputs. Drawing connections between multi-head attention and mixture of experts, we propose the mixture of attentive experts model (MAE). MAE is trained using a block coordinate descent algorithm that alternates between updating (1) the responsibilities of the experts and (2) their parameters. Experiments on machine translation and language modeling show that MAE outperforms strong baselines on both tasks. Particularly, on the WMT14 English to German translation dataset, MAE improves over ""transformer-base"" by 0.8 BLEU, with a comparable number of parameters. Our analysis shows that our model learns to specialize different experts to different inputs. 1","A Mixture of h - 1 Heads is Better than h Heads Multi-head attentive neural architectures have achieved state-of-the-art results on a variety of natural language processing tasks. Evidence has shown that they are overparameterized; attention heads can be pruned without significant performance loss. In this work, we instead ""reallocate"" them-the model learns to activate different heads on different inputs. Drawing connections between multi-head attention and mixture of experts, we propose the mixture of attentive experts model (MAE). MAE is trained using a block coordinate descent algorithm that alternates between updating (1) the responsibilities of the experts and (2) their parameters. Experiments on machine translation and language modeling show that MAE outperforms strong baselines on both tasks. Particularly, on the WMT14 English to German translation dataset, MAE improves over ""transformer-base"" by 0.8 BLEU, with a comparable number of parameters. Our analysis shows that our model learns to specialize different experts to different inputs. 1","mixture h - 1 head well h head multi - head attentive neural architecture achieve state - - - art result variety natural language processing task . evidence show overparameterize ; attention head prune significant performance loss . work , instead "" reallocate "" - model learn activate different head different input . draw connection multi - head attention mixture expert , propose mixture attentive expert model ( mae ) . mae train block coordinate descent algorithm alternate update ( 1 ) responsibility expert ( 2 ) parameter . experiment machine translation language modeling mae outperform strong baseline task . particularly , wmt14 english german translation dataset , mae improve "" transformer - base "" 0.8 bleu , comparable number parameter . analysis show model learn specialize different expert different input . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Machine Learning for NLP,Orthogonal Relation Transforms with Graph Context Modeling for Knowledge Graph Embedding,"Distance-based knowledge graph embeddings have shown substantial improvement on the knowledge graph link prediction task, from TransE to the latest state-of-the-art RotatE. However, complex relations such as N-to-1, 1-to-N and N-to-N still remain challenging to predict. In this work, we propose a novel distance-based approach for knowledge graph link prediction. First we extend the RotatE from 2D complex domain to high dimensional space with orthogonal transforms to model relations. The orthogonal transform embedding for relations keeps the capability for modeling symmetric/anti-symmetric, inverse and compositional relations while achieves better modeling capacity. Second, the graph context is integrated into distance scoring functions directly. Specifically, graph context is explicitly modeled via two directed context representations. Each node embedding in knowledge graph is augmented with two context representations, which are computed from the neighboring outgoing and incoming nodes/edges respectively. The proposed approach improves prediction accuracy on the difficult N-to-1, 1-to-N and N-to-N cases. Our experimental results show that it achieves state-of-the-art results on two common benchmarks FB15k-237 and WNRR-18, especially on FB15k-237 which has many high in-degree nodes. Code available at https://github.","Orthogonal Relation Transforms with Graph Context Modeling for Knowledge Graph Embedding Distance-based knowledge graph embeddings have shown substantial improvement on the knowledge graph link prediction task, from TransE to the latest state-of-the-art RotatE. However, complex relations such as N-to-1, 1-to-N and N-to-N still remain challenging to predict. In this work, we propose a novel distance-based approach for knowledge graph link prediction. First we extend the RotatE from 2D complex domain to high dimensional space with orthogonal transforms to model relations. The orthogonal transform embedding for relations keeps the capability for modeling symmetric/anti-symmetric, inverse and compositional relations while achieves better modeling capacity. Second, the graph context is integrated into distance scoring functions directly. Specifically, graph context is explicitly modeled via two directed context representations. Each node embedding in knowledge graph is augmented with two context representations, which are computed from the neighboring outgoing and incoming nodes/edges respectively. The proposed approach improves prediction accuracy on the difficult N-to-1, 1-to-N and N-to-N cases. Our experimental results show that it achieves state-of-the-art results on two common benchmarks FB15k-237 and WNRR-18, especially on FB15k-237 which has many high in-degree nodes. Code available at https://github.","orthogonal relation transform graph context modeling knowledge graph embedding distance - base knowledge graph embedding show substantial improvement knowledge graph link prediction task , transe late state - - - art rotate. , complex relation n - to-1 , 1 - - n n - - n remain challenging predict . work , propose novel distance - base approach knowledge graph link prediction . extend rotate 2d complex domain high dimensional space orthogonal transform model relation . orthogonal transform embedding relation keep capability model symmetric / anti - symmetric , inverse compositional relation achieve well modeling capacity . second , graph context integrate distance score function directly . specifically , graph context explicitly model direct context representation . node embed knowledge graph augment context representation , compute neighbor outgoing incoming node / edge respectively . propose approach improve prediction accuracy difficult n - to-1 , 1 - - n n - - n case . experimental result achieve state - - - art result common benchmark fb15k-237 wnrr-18 , especially fb15k-237 high - degree node . code available https://github .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 13, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Effective Estimation of Deep Generative Language Models,"Advances in variational inference enable parameterisation of probabilistic models by deep neural networks. This combines the statistical transparency of the probabilistic modelling framework with the representational power of deep learning. Yet, due to a problem known as posterior collapse, it is difficult to estimate such models in the context of language modelling effectively. We concentrate on one such model, the variational auto-encoder, which we argue is an important building block in hierarchical probabilistic models of language. This paper contributes a sober view of the problem, a survey of techniques to address it, novel techniques, and extensions to the model. To establish a ranking of techniques, we perform a systematic comparison using Bayesian optimisation and find that many techniques perform reasonably similar, given enough resources. Still, a favourite can be named based on convenience. We also make several empirical observations and recommendations of best practices that should help researchers interested in this exciting field.","Effective Estimation of Deep Generative Language Models Advances in variational inference enable parameterisation of probabilistic models by deep neural networks. This combines the statistical transparency of the probabilistic modelling framework with the representational power of deep learning. Yet, due to a problem known as posterior collapse, it is difficult to estimate such models in the context of language modelling effectively. We concentrate on one such model, the variational auto-encoder, which we argue is an important building block in hierarchical probabilistic models of language. This paper contributes a sober view of the problem, a survey of techniques to address it, novel techniques, and extensions to the model. To establish a ranking of techniques, we perform a systematic comparison using Bayesian optimisation and find that many techniques perform reasonably similar, given enough resources. Still, a favourite can be named based on convenience. We also make several empirical observations and recommendations of best practices that should help researchers interested in this exciting field.","effective estimation deep generative language model advance variational inference enable parameterisation probabilistic model deep neural network . combine statistical transparency probabilistic modelling framework representational power deep learning . , problem know posterior collapse , difficult estimate model context language modelling effectively . concentrate model , variational auto - encoder , argue important building block hierarchical probabilistic model language . paper contribute sober view problem , survey technique address , novel technique , extension model . establish ranking technique , perform systematic comparison bayesian optimisation find technique perform reasonably similar , give resource . , favourite name base convenience . empirical observation recommendation good practice help researcher interested exciting field .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Topological Sort for Sentence Ordering,"Sentence ordering is the task of arranging the sentences of a given text in the correct order. Recent work using deep neural networks for this task has framed it as a sequence prediction problem. In this paper, we propose a new framing of this task as a constraint solving problem and introduce a new technique to solve it. Additionally, we propose a human evaluation for this task. The results on both automatic and human metrics across four different datasets show that this new technique is better at capturing coherence in documents.","Topological Sort for Sentence Ordering Sentence ordering is the task of arranging the sentences of a given text in the correct order. Recent work using deep neural networks for this task has framed it as a sequence prediction problem. In this paper, we propose a new framing of this task as a constraint solving problem and introduce a new technique to solve it. Additionally, we propose a human evaluation for this task. The results on both automatic and human metrics across four different datasets show that this new technique is better at capturing coherence in documents.","topological sort sentence ordering sentence ordering task arrange sentence give text correct order . recent work deep neural network task frame sequence prediction problem . paper , propose new framing task constraint solve problem introduce new technique solve . additionally , propose human evaluation task . result automatic human metric different dataset new technique well capture coherence document .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Learning for NLP,Tchebycheff Procedure for Multi-task Text Classification,"Multi-task Learning methods have achieved significant progress in text classification. However, existing methods assume that multi-task text classification problems are convex multiobjective optimization problems, which is unrealistic in real-world applications. To address this issue, this paper presents a novel Tchebycheff procedure to optimize the multitask classification problems without any convex assumption. The extensive experiments back up our theoretical analysis and validate the superiority of our proposals.","Tchebycheff Procedure for Multi-task Text Classification Multi-task Learning methods have achieved significant progress in text classification. However, existing methods assume that multi-task text classification problems are convex multiobjective optimization problems, which is unrealistic in real-world applications. To address this issue, this paper presents a novel Tchebycheff procedure to optimize the multitask classification problems without any convex assumption. The extensive experiments back up our theoretical analysis and validate the superiority of our proposals.","tchebycheff procedure multi - task text classification multi - task learning method achieve significant progress text classification . , exist method assume multi - task text classification problem convex multiobjective optimization problem , unrealistic real - world application . address issue , paper present novel tchebycheff procedure optimize multitask classification problem convex assumption . extensive experiment theoretical analysis validate superiority proposal .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Retrieval and Text Mining,False
Machine Learning for NLP,Generalizing Natural Language Analysis through Span-relation Representations,"Natural language processing covers a wide variety of tasks predicting syntax, semantics, and information content, and usually each type of output is generated with specially designed architectures. In this paper, we provide the simple insight that a great variety of tasks can be represented in a single unified format consisting of labeling spans and relations between spans, thus a single task-independent model can be used across different tasks. We perform extensive experiments to test this insight on 10 disparate tasks spanning dependency parsing (syntax), semantic role labeling (semantics), relation extraction (information content), aspect based sentiment analysis (sentiment), and many others, achieving performance comparable to state-of-the-art specialized models. We further demonstrate benefits of multi-task learning, and also show that the proposed method makes it easy to analyze differences and similarities in how the model handles different tasks. Finally, we convert these datasets into a unified format to build a benchmark, which provides a holistic testbed for evaluating future models for generalized natural language analysis.","Generalizing Natural Language Analysis through Span-relation Representations Natural language processing covers a wide variety of tasks predicting syntax, semantics, and information content, and usually each type of output is generated with specially designed architectures. In this paper, we provide the simple insight that a great variety of tasks can be represented in a single unified format consisting of labeling spans and relations between spans, thus a single task-independent model can be used across different tasks. We perform extensive experiments to test this insight on 10 disparate tasks spanning dependency parsing (syntax), semantic role labeling (semantics), relation extraction (information content), aspect based sentiment analysis (sentiment), and many others, achieving performance comparable to state-of-the-art specialized models. We further demonstrate benefits of multi-task learning, and also show that the proposed method makes it easy to analyze differences and similarities in how the model handles different tasks. Finally, we convert these datasets into a unified format to build a benchmark, which provides a holistic testbed for evaluating future models for generalized natural language analysis.","generalize natural language analysis span - relation representation natural language processing cover wide variety task predict syntax , semantic , information content , usually type output generate specially design architecture . paper , provide simple insight great variety task represent single unify format consist labeling span relation span , single task - independent model different task . perform extensive experiment test insight 10 disparate task span dependency parsing ( syntax ) , semantic role labeling ( semantic ) , relation extraction ( information content ) , aspect base sentiment analysis ( sentiment ) , , achieve performance comparable state - - - art specialized model . demonstrate benefit multi - task learning , propose method make easy analyze difference similarity model handle different task . finally , convert dataset unified format build benchmark , provide holistic testbed evaluate future model generalize natural language analysis .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Information Extraction,False
Machine Learning for NLP,Why Overfitting Isn't Always Bad: Retrofitting Cross-Lingual Word Embeddings to Dictionaries,"Cross-lingual word embeddings (CLWE) are often evaluated on bilingual lexicon induction (BLI). Recent CLWE methods use linear projections, which underfit the training dictionary, to generalize on BLI. However, underfitting can hinder generalization to other downstream tasks that rely on words from the training dictionary. We address this limitation by retrofitting CLWE to the training dictionary, which pulls training translation pairs closer in the embedding space and overfits the training dictionary. This simple post-processing step often improves accuracy on two downstream tasks, despite lowering BLI test accuracy. We also retrofit to both the training dictionary and a synthetic dictionary induced from CLWE, which sometimes generalizes even better on downstream tasks. Our results confirm the importance of fully exploiting the training dictionary in downstream tasks and explains why BLI is a flawed CLWE evaluation.","Why Overfitting Isn't Always Bad: Retrofitting Cross-Lingual Word Embeddings to Dictionaries Cross-lingual word embeddings (CLWE) are often evaluated on bilingual lexicon induction (BLI). Recent CLWE methods use linear projections, which underfit the training dictionary, to generalize on BLI. However, underfitting can hinder generalization to other downstream tasks that rely on words from the training dictionary. We address this limitation by retrofitting CLWE to the training dictionary, which pulls training translation pairs closer in the embedding space and overfits the training dictionary. This simple post-processing step often improves accuracy on two downstream tasks, despite lowering BLI test accuracy. We also retrofit to both the training dictionary and a synthetic dictionary induced from CLWE, which sometimes generalizes even better on downstream tasks. Our results confirm the importance of fully exploiting the training dictionary in downstream tasks and explains why BLI is a flawed CLWE evaluation.","overfitting bad : retrofit cross - lingual word embedding dictionary cross - lingual word embedding ( clwe ) evaluate bilingual lexicon induction ( bli ) . recent clwe method use linear projection , underfit training dictionary , generalize bli . , underfitting hinder generalization downstream task rely word training dictionary . address limitation retrofit clwe training dictionary , pull training translation pair close embedding space overfit training dictionary . simple post - process step improve accuracy downstream task , despite lower bli test accuracy . retrofit training dictionary synthetic dictionary induce clwe , generalize well downstream task . result confirm importance fully exploit training dictionary downstream task explain bli flawed clwe evaluation .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Learning for NLP,Posterior Control of Blackbox Generation,"Text generation often requires high-precision output that obeys task-specific rules. This fine-grained control is difficult to enforce with off-the-shelf deep learning models. In this work, we consider augmenting neural generation models with discrete control states learned through a structured latent-variable approach. Under this formulation, task-specific knowledge can be encoded through a range of rich, posterior constraints that are effectively trained into the model. This approach allows users to ground internal model decisions based on prior knowledge, without sacrificing the representational power of neural generative models. Experiments consider applications of this approach for text generation. We find that this method improves over standard benchmarks, while also providing fine-grained control.","Posterior Control of Blackbox Generation Text generation often requires high-precision output that obeys task-specific rules. This fine-grained control is difficult to enforce with off-the-shelf deep learning models. In this work, we consider augmenting neural generation models with discrete control states learned through a structured latent-variable approach. Under this formulation, task-specific knowledge can be encoded through a range of rich, posterior constraints that are effectively trained into the model. This approach allows users to ground internal model decisions based on prior knowledge, without sacrificing the representational power of neural generative models. Experiments consider applications of this approach for text generation. We find that this method improves over standard benchmarks, while also providing fine-grained control.","posterior control blackbox generation text generation require high - precision output obey task - specific rule . fine - grained control difficult enforce - - shelf deep learning model . work , consider augment neural generation model discrete control state learn structure latent - variable approach . formulation , task - specific knowledge encode range rich , posterior constraint effectively train model . approach allow user ground internal model decision base prior knowledge , sacrifice representational power neural generative model . experiment consider application approach text generation . find method improve standard benchmark , provide fine - grained control .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling,"Sequence labeling is a fundamental task for a range of natural language processing problems. When used in practice, its performance is largely influenced by the annotation quality and quantity, and meanwhile, obtaining ground truth labels is often costly. In many cases, ground truth labels do not exist, but noisy annotations or annotations from different domains are accessible. In this paper, we propose a novel framework Consensus Network (CONNET) that can be trained on annotations from multiple sources (e.g., crowd annotation, cross-domain data). It learns individual representation for every source and dynamically aggregates source-specific knowledge by a context-aware attention module. Finally, it leads to a model reflecting the agreement (consensus) among multiple sources. We evaluate the proposed framework in two practical settings of multi-source learning: learning with crowd annotations and unsupervised crossdomain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings. We also demonstrate that the method can apply to various tasks and cope with different encoders. 1","Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling Sequence labeling is a fundamental task for a range of natural language processing problems. When used in practice, its performance is largely influenced by the annotation quality and quantity, and meanwhile, obtaining ground truth labels is often costly. In many cases, ground truth labels do not exist, but noisy annotations or annotations from different domains are accessible. In this paper, we propose a novel framework Consensus Network (CONNET) that can be trained on annotations from multiple sources (e.g., crowd annotation, cross-domain data). It learns individual representation for every source and dynamically aggregates source-specific knowledge by a context-aware attention module. Finally, it leads to a model reflecting the agreement (consensus) among multiple sources. We evaluate the proposed framework in two practical settings of multi-source learning: learning with crowd annotations and unsupervised crossdomain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings. We also demonstrate that the method can apply to various tasks and cope with different encoders. 1","learn contextually aggregate multi - source supervision sequence labeling sequence labeling fundamental task range natural language processing problem . practice , performance largely influence annotation quality quantity , , obtain ground truth label costly . case , ground truth label exist , noisy annotation annotation different domain accessible . paper , propose novel framework consensus network ( connet ) train annotation multiple source ( e.g. , crowd annotation , cross - domain datum ) . learn individual representation source dynamically aggregate source - specific knowledge context - aware attention module . finally , lead model reflect agreement ( consensus ) multiple source . evaluate propose framework practical setting multi - source learning : learn crowd annotation unsupervised crossdomain model adaptation . extensive experimental result model achieve significant improvement exist method setting . demonstrate method apply task cope different encoder . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
Machine Learning for NLP,Contrastive Self-Supervised Learning for Commonsense Reasoning,"We propose a self-supervised method to solve Pronoun Disambiguation and Winograd Schema Challenge problems. Our approach exploits the characteristic structure of training corpora related to so-called ""trigger"" words, which are responsible for flipping the answer in pronoun disambiguation. We achieve such commonsense reasoning by constructing pairwise contrastive auxiliary predictions. To this end, we leverage a mutual exclusive loss regularized by a contrastive margin. Our architecture is based on the recently introduced transformer networks, BERT, that exhibits strong performance on many NLP benchmarks. Empirical results show that our method alleviates the limitation of current supervised approaches for commonsense reasoning. This study opens up avenues for exploiting inexpensive self-supervision to achieve performance gain in commonsense reasoning tasks. 1","Contrastive Self-Supervised Learning for Commonsense Reasoning We propose a self-supervised method to solve Pronoun Disambiguation and Winograd Schema Challenge problems. Our approach exploits the characteristic structure of training corpora related to so-called ""trigger"" words, which are responsible for flipping the answer in pronoun disambiguation. We achieve such commonsense reasoning by constructing pairwise contrastive auxiliary predictions. To this end, we leverage a mutual exclusive loss regularized by a contrastive margin. Our architecture is based on the recently introduced transformer networks, BERT, that exhibits strong performance on many NLP benchmarks. Empirical results show that our method alleviates the limitation of current supervised approaches for commonsense reasoning. This study opens up avenues for exploiting inexpensive self-supervision to achieve performance gain in commonsense reasoning tasks. 1","contrastive self - supervised learning commonsense reasoning propose self - supervise method solve pronoun disambiguation winograd schema challenge problem . approach exploit characteristic structure training corpus relate - call "" trigger "" word , responsible flip answer pronoun disambiguation . achieve commonsense reasoning construct pairwise contrastive auxiliary prediction . end , leverage mutual exclusive loss regularize contrastive margin . architecture base recently introduce transformer network , bert , exhibit strong performance nlp benchmark . empirical result method alleviate limitation current supervise approach commonsense reasoning . study open avenue exploit inexpensive self - supervision achieve performance gain commonsense reasoning task . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Learning for NLP,Differentiable Window for Dynamic Local Attention,"We propose Differentiable Window, a new neural module and general purpose component for dynamic window selection. While universally applicable, we demonstrate a compelling use case of utilizing Differentiable Window to improve standard attention modules by enabling more focused attentions over the input regions. We propose two variants of Differentiable Window, and integrate them within the Transformer architecture in two novel ways. We evaluate our proposed approach on a myriad of NLP tasks, including machine translation, sentiment analysis, subject-verb agreement and language modeling. Our experimental results demonstrate consistent and sizable improvements across all tasks.","Differentiable Window for Dynamic Local Attention We propose Differentiable Window, a new neural module and general purpose component for dynamic window selection. While universally applicable, we demonstrate a compelling use case of utilizing Differentiable Window to improve standard attention modules by enabling more focused attentions over the input regions. We propose two variants of Differentiable Window, and integrate them within the Transformer architecture in two novel ways. We evaluate our proposed approach on a myriad of NLP tasks, including machine translation, sentiment analysis, subject-verb agreement and language modeling. Our experimental results demonstrate consistent and sizable improvements across all tasks.","differentiable window dynamic local attention propose differentiable window , new neural module general purpose component dynamic window selection . universally applicable , demonstrate compelling use case utilize differentiable window improve standard attention module enable focused attention input region . propose variant differentiable window , integrate transformer architecture novel way . evaluate propose approach myriad nlp task , include machine translation , sentiment analysis , subject - verb agreement language modeling . experimental result demonstrate consistent sizable improvement task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
Machine Learning for NLP,Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models,"Recent models for unsupervised representation learning of text have employed a number of techniques to improve contextual word representations but have put little focus on discourse-level representations. We propose CONPONO 1 , an inter-sentence objective for pretraining language models that models discourse coherence and the distance between sentences. Given an anchor sentence, our model is trained to predict the text k sentences away using a sampled-softmax objective where the candidates consist of neighboring sentences and sentences randomly sampled from the corpus. On the discourse representation benchmark DiscoEval, our model improves over the previous state-of-the-art by up to 13% and on average 4% absolute across 7 tasks. Our model is the same size as BERT-Base, but outperforms the much larger BERT-Large model and other more recent approaches that incorporate discourse. We also show that CONPONO yields gains of 2%-6% absolute even for tasks that do not explicitly evaluate discourse: textual entailment (RTE), common sense reasoning (COPA) and reading comprehension (ReCoRD).","Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models Recent models for unsupervised representation learning of text have employed a number of techniques to improve contextual word representations but have put little focus on discourse-level representations. We propose CONPONO 1 , an inter-sentence objective for pretraining language models that models discourse coherence and the distance between sentences. Given an anchor sentence, our model is trained to predict the text k sentences away using a sampled-softmax objective where the candidates consist of neighboring sentences and sentences randomly sampled from the corpus. On the discourse representation benchmark DiscoEval, our model improves over the previous state-of-the-art by up to 13% and on average 4% absolute across 7 tasks. Our model is the same size as BERT-Base, but outperforms the much larger BERT-Large model and other more recent approaches that incorporate discourse. We also show that CONPONO yields gains of 2%-6% absolute even for tasks that do not explicitly evaluate discourse: textual entailment (RTE), common sense reasoning (COPA) and reading comprehension (ReCoRD).","pretraine contrastive sentence objective improve discourse performance language model recent model unsupervised representation learning text employ number technique improve contextual word representation little focus discourse - level representation . propose conpono 1 , inter - sentence objective pretraine language model model discourse coherence distance sentence . give anchor sentence , model train predict text k sentence away sample - softmax objective candidate consist neighbor sentence sentence randomly sample corpus . discourse representation benchmark discoeval , model improve previous state - - - art 13 % average 4 % absolute 7 task . model size bert - base , outperform large bert - large model recent approach incorporate discourse . conpono yield gain 2%-6 % absolute task explicitly evaluate discourse : textual entailment ( rte ) , common sense reasoning ( copa ) reading comprehension ( record ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 7, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 3, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Low Resource Sequence Tagging using Sentence Reconstruction,"This work revisits the task of training sequence tagging models with limited resources using transfer learning. We investigate several proposed approaches introduced in recent works and suggest a new loss that relies on sentence reconstruction from normalized embeddings. Specifically, our method demonstrates how by adding a decoding layer for sentence reconstruction, we can improve the performance of various baselines. We show improved results on the CoNLL02 NER and UD 1.2 POS datasets","Low Resource Sequence Tagging using Sentence Reconstruction This work revisits the task of training sequence tagging models with limited resources using transfer learning. We investigate several proposed approaches introduced in recent works and suggest a new loss that relies on sentence reconstruction from normalized embeddings. Specifically, our method demonstrates how by adding a decoding layer for sentence reconstruction, we can improve the performance of various baselines. We show improved results on the CoNLL02 NER and UD 1.2 POS datasets","low resource sequence tagging sentence reconstruction work revisit task train sequence tagging model limited resource transfer learning . investigate propose approach introduce recent work suggest new loss rely sentence reconstruction normalize embedding . specifically , method demonstrate add decoding layer sentence reconstruction , improve performance baseline . improved result conll02 ner ud 1.2 pos dataset","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,A Probabilistic Generative Model for Typographical Analysis of Early Modern Printing,"We propose a deep and interpretable probabilistic generative model to analyze glyph shapes in printed Early Modern documents. We focus on clustering extracted glyph images into underlying templates in the presence of multiple confounding sources of variance. Our approach introduces a neural editor model that first generates well-understood printing phenomena like spatial perturbations from template parameters via interpertable latent variables, and then modifies the result by generating a non-interpretable latent vector responsible for inking variations, jitter, noise from the archiving process, and other unforeseen phenomena associated with Early Modern printing. Critically, by introducing an inference network whose input is restricted to the visual residual between the observation and the interpretably-modified template, we are able to control and isolate what the vector-valued latent variable captures. We show that our approach outperforms rigid interpretable clustering baselines (Ocular) and overly-flexible deep generative models (VAE) alike on the task of completely unsupervised discovery of typefaces in mixed-font documents.","A Probabilistic Generative Model for Typographical Analysis of Early Modern Printing We propose a deep and interpretable probabilistic generative model to analyze glyph shapes in printed Early Modern documents. We focus on clustering extracted glyph images into underlying templates in the presence of multiple confounding sources of variance. Our approach introduces a neural editor model that first generates well-understood printing phenomena like spatial perturbations from template parameters via interpertable latent variables, and then modifies the result by generating a non-interpretable latent vector responsible for inking variations, jitter, noise from the archiving process, and other unforeseen phenomena associated with Early Modern printing. Critically, by introducing an inference network whose input is restricted to the visual residual between the observation and the interpretably-modified template, we are able to control and isolate what the vector-valued latent variable captures. We show that our approach outperforms rigid interpretable clustering baselines (Ocular) and overly-flexible deep generative models (VAE) alike on the task of completely unsupervised discovery of typefaces in mixed-font documents.","probabilistic generative model typographical analysis early modern printing propose deep interpretable probabilistic generative model analyze glyph shape print early modern document . focus cluster extract glyph image underlie template presence multiple confound source variance . approach introduce neural editor model generate - understand printing phenomenon like spatial perturbation template parameter interpertable latent variable , modify result generate non - interpretable latent vector responsible inking variation , jitter , noise archiving process , unforeseen phenomenon associate early modern printing . critically , introduce inference network input restrict visual residual observation interpretably - modify template , able control isolate vector - value latent variable capture . approach outperform rigid interpretable clustering baseline ( ocular ) overly - flexible deep generative model ( vae ) alike task completely unsupervised discovery typeface mixed - font document .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing,"Prior work has explored directly regularizing the output distributions of probabilistic models to alleviate peaky (i.e. over-confident) predictions, a common sign of overfitting. This class of techniques, of which label smoothing is one, has a connection to entropy regularization. Despite the consistent success of label smoothing across architectures and datasets in language generation tasks, two problems remain open: (1) there is little understanding of the underlying effects entropy regularizers have on models, and (2) the full space of entropy regularization techniques is largely unexplored. We introduce a parametric family of entropy regularizers, which includes label smoothing as a special case, and use it to gain a better understanding of the relationship between the entropy of a trained model and its performance on language generation tasks. We also find that variance in model performance can be explained largely by the resulting entropy of the model. Lastly, we find that label smoothing provably does not allow for sparse distributions, an undesirable property for language generation models, and therefore advise the use of other entropy regularization methods in its place. Our code is available online at https://github.com/ rycolab/entropyRegularization.","Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing Prior work has explored directly regularizing the output distributions of probabilistic models to alleviate peaky (i.e. over-confident) predictions, a common sign of overfitting. This class of techniques, of which label smoothing is one, has a connection to entropy regularization. Despite the consistent success of label smoothing across architectures and datasets in language generation tasks, two problems remain open: (1) there is little understanding of the underlying effects entropy regularizers have on models, and (2) the full space of entropy regularization techniques is largely unexplored. We introduce a parametric family of entropy regularizers, which includes label smoothing as a special case, and use it to gain a better understanding of the relationship between the entropy of a trained model and its performance on language generation tasks. We also find that variance in model performance can be explained largely by the resulting entropy of the model. Lastly, we find that label smoothing provably does not allow for sparse distributions, an undesirable property for language generation models, and therefore advise the use of other entropy regularization methods in its place. Our code is available online at https://github.com/ rycolab/entropyRegularization.","generalized entropy regularization : special label smoothing prior work explore directly regularize output distribution probabilistic model alleviate peaky ( i.e. - confident ) prediction , common sign overfitting . class technique , label smoothing , connection entropy regularization . despite consistent success label smoothing architecture dataset language generation task , problem remain open : ( 1 ) little understanding underlie effect entropy regularizer model , ( 2 ) space entropy regularization technique largely unexplored . introduce parametric family entropy regularizer , include label smoothing special case , use gain well understanding relationship entropy train model performance language generation task . find variance model performance explain largely result entropy model . lastly , find label smoothing provably allow sparse distribution , undesirable property language generation model , advise use entropy regularization method place . code available online https://github.com/ rycolab / entropyregularization .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Active Imitation Learning with Noisy Guidance,"Imitation learning algorithms provide state-ofthe-art results on many structured prediction tasks by learning near-optimal search policies. Such algorithms assume training-time access to an expert that can provide the optimal action at any queried state; unfortunately, the number of such queries is often prohibitive, frequently rendering these approaches impractical. To combat this query complexity, we consider an active learning setting in which the learning algorithm has additional access to a much cheaper noisy heuristic that provides noisy guidance. Our algorithm, LEAQI, learns a difference classifier that predicts when the expert is likely to disagree with the heuristic, and queries the expert only when necessary. We apply LEAQI to three sequence labeling tasks, demonstrating significantly fewer queries to the expert and comparable (or better) accuracies over a passive approach.","Active Imitation Learning with Noisy Guidance Imitation learning algorithms provide state-ofthe-art results on many structured prediction tasks by learning near-optimal search policies. Such algorithms assume training-time access to an expert that can provide the optimal action at any queried state; unfortunately, the number of such queries is often prohibitive, frequently rendering these approaches impractical. To combat this query complexity, we consider an active learning setting in which the learning algorithm has additional access to a much cheaper noisy heuristic that provides noisy guidance. Our algorithm, LEAQI, learns a difference classifier that predicts when the expert is likely to disagree with the heuristic, and queries the expert only when necessary. We apply LEAQI to three sequence labeling tasks, demonstrating significantly fewer queries to the expert and comparable (or better) accuracies over a passive approach.","active imitation learning noisy guidance imitation learning algorithm provide state - ofthe - art result structure prediction task learn near - optimal search policy . algorithm assume training - time access expert provide optimal action query state ; unfortunately , number query prohibitive , frequently render approach impractical . combat query complexity , consider active learning setting learn algorithm additional access cheap noisy heuristic provide noisy guidance . algorithm , leaqi , learn difference classifier predict expert likely disagree heuristic , query expert necessary . apply leaqi sequence labeling task , demonstrate significantly few query expert comparable ( well ) accuracy passive approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Do Transformers Need Deep Long-Range Memory?,"Deep attention models have advanced the modelling of sequential data across many domains. For language modelling in particular, the Transformer-XL -a Transformer augmented with a long-range memory of past activations -has been shown to be state-ofthe-art across a variety of well-studied benchmarks. The Transformer-XL incorporates a long-range memory at every layer of the network, which renders its state to be thousands of times larger than RNN predecessors. However it is unclear whether this is necessary. We perform a set of interventions to show that comparable performance can be obtained with 6X fewer long range memories and better performance can be obtained by limiting the range of attention in lower layers of the network.","Do Transformers Need Deep Long-Range Memory? Deep attention models have advanced the modelling of sequential data across many domains. For language modelling in particular, the Transformer-XL -a Transformer augmented with a long-range memory of past activations -has been shown to be state-ofthe-art across a variety of well-studied benchmarks. The Transformer-XL incorporates a long-range memory at every layer of the network, which renders its state to be thousands of times larger than RNN predecessors. However it is unclear whether this is necessary. We perform a set of interventions to show that comparable performance can be obtained with 6X fewer long range memories and better performance can be obtained by limiting the range of attention in lower layers of the network.","transformer need deep long - range memory ? deep attention model advance modelling sequential datum domain . language modelling particular , transformer - xl -a transformer augment long - range memory past activation -ha show state - ofthe - art variety - study benchmark . transformer - xl incorporate long - range memory layer network , render state thousand time large rnn predecessor . unclear necessary . perform set intervention comparable performance obtain 6x few long range memory well performance obtain limit range attention low layer network .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Phonology, Morphology and Word Segmentation",False
Machine Learning for NLP,Low-Dimensional Hyperbolic Knowledge Graph Embeddings,"Knowledge graph (KG) embeddings learn lowdimensional representations of entities and relations to predict missing facts. KGs often exhibit hierarchical and logical patterns which must be preserved in the embedding space. For hierarchical data, hyperbolic embedding methods have shown promise for high-fidelity and parsimonious representations. However, existing hyperbolic embedding methods do not account for the rich logical patterns in KGs. In this work, we introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns. Our approach combines hyperbolic reflections and rotations with attention to model complex relational patterns. Experimental results on standard KG benchmarks show that our method improves over previous Euclidean-and hyperbolic-based efforts by up to 6.1% in mean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that different geometric transformations capture different types of relations while attentionbased transformations generalize to multiple relations. In high dimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR and 57.7% on YAGO3-10. * Work partially done during an internship at Google.","Low-Dimensional Hyperbolic Knowledge Graph Embeddings Knowledge graph (KG) embeddings learn lowdimensional representations of entities and relations to predict missing facts. KGs often exhibit hierarchical and logical patterns which must be preserved in the embedding space. For hierarchical data, hyperbolic embedding methods have shown promise for high-fidelity and parsimonious representations. However, existing hyperbolic embedding methods do not account for the rich logical patterns in KGs. In this work, we introduce a class of hyperbolic KG embedding models that simultaneously capture hierarchical and logical patterns. Our approach combines hyperbolic reflections and rotations with attention to model complex relational patterns. Experimental results on standard KG benchmarks show that our method improves over previous Euclidean-and hyperbolic-based efforts by up to 6.1% in mean reciprocal rank (MRR) in low dimensions. Furthermore, we observe that different geometric transformations capture different types of relations while attentionbased transformations generalize to multiple relations. In high dimensions, our approach yields new state-of-the-art MRRs of 49.6% on WN18RR and 57.7% on YAGO3-10. * Work partially done during an internship at Google.","low - dimensional hyperbolic knowledge graph embedding knowledge graph ( kg ) embedding learn lowdimensional representation entity relation predict miss fact . kgs exhibit hierarchical logical pattern preserve embedding space . hierarchical datum , hyperbolic embedding method show promise high - fidelity parsimonious representation . , exist hyperbolic embedding method account rich logical pattern kgs . work , introduce class hyperbolic kg embedding model simultaneously capture hierarchical logical pattern . approach combine hyperbolic reflection rotation attention model complex relational pattern . experimental result standard kg benchmark method improve previous euclidean - hyperbolic - base effort 6.1 % mean reciprocal rank ( mrr ) low dimension . furthermore , observe different geometric transformation capture different type relation attentionbased transformation generalize multiple relation . high dimension , approach yield new state - - - art mrr 49.6 % wn18rr 57.7 % yago3 - 10 . * work partially internship google .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices,"Natural Language Processing (NLP) has recently achieved great success by using huge pre-trained models with hundreds of millions of parameters. However, these models suffer from heavy model sizes and high latency such that they cannot be deployed to resourcelimited mobile devices. In this paper, we propose MobileBERT for compressing and accelerating the popular BERT model. Like the original BERT, MobileBERT is task-agnostic, that is, it can be generically applied to various downstream NLP tasks via simple fine-tuning. Basically, MobileBERT is a thin version of BERT LARGE , while equipped with bottleneck structures and a carefully designed balance between self-attentions and feed-forward networks. To train MobileBERT, we first train a specially designed teacher model, an invertedbottleneck incorporated BERT LARGE model. Then, we conduct knowledge transfer from this teacher to MobileBERT. Empirical studies show that MobileBERT is 4.3Ã— smaller and 5.5Ã— faster than BERT BASE while achieving competitive results on well-known benchmarks. On the natural language inference tasks of GLUE, MobileBERT achieves a GLUE score of 77.7 (0.6 lower than BERT BASE ), and 62 ms latency on a Pixel 4 phone. On the SQuAD v1.1/v2.0 question answering task, MobileBERT achieves a dev F1 score of 90.0/79.2 (1.5/2.1 higher than BERT BASE ).","MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices Natural Language Processing (NLP) has recently achieved great success by using huge pre-trained models with hundreds of millions of parameters. However, these models suffer from heavy model sizes and high latency such that they cannot be deployed to resourcelimited mobile devices. In this paper, we propose MobileBERT for compressing and accelerating the popular BERT model. Like the original BERT, MobileBERT is task-agnostic, that is, it can be generically applied to various downstream NLP tasks via simple fine-tuning. Basically, MobileBERT is a thin version of BERT LARGE , while equipped with bottleneck structures and a carefully designed balance between self-attentions and feed-forward networks. To train MobileBERT, we first train a specially designed teacher model, an invertedbottleneck incorporated BERT LARGE model. Then, we conduct knowledge transfer from this teacher to MobileBERT. Empirical studies show that MobileBERT is 4.3Ã— smaller and 5.5Ã— faster than BERT BASE while achieving competitive results on well-known benchmarks. On the natural language inference tasks of GLUE, MobileBERT achieves a GLUE score of 77.7 (0.6 lower than BERT BASE ), and 62 ms latency on a Pixel 4 phone. On the SQuAD v1.1/v2.0 question answering task, MobileBERT achieves a dev F1 score of 90.0/79.2 (1.5/2.1 higher than BERT BASE ).","mobilebert : compact task - agnostic bert resource - limited devices natural language processing ( nlp ) recently achieve great success huge pre - trained model hundred million parameter . , model suffer heavy model size high latency deploy resourcelimited mobile device . paper , propose mobilebert compress accelerate popular bert model . like original bert , mobilebert task - agnostic , , generically apply downstream nlp task simple fine - tuning . basically , mobilebert thin version bert large , equip bottleneck structure carefully design balance self - attention feed - forward network . train mobilebert , train specially design teacher model , invertedbottleneck incorporate bert large model . , conduct knowledge transfer teacher mobilebert . empirical study mobilebert 4.3Ã— small 5.5Ã— fast bert base achieve competitive result - know benchmark . natural language inference task glue , mobilebert achieve glue score 77.7 ( 0.6 low bert base ) , 62 m latency pixel 4 phone . squad v1.1 / v2.0 question answering task , mobilebert achieve dev f1 score 90.0/79.2 ( 1.5/2.1 high bert base ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 19, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 5, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,XtremeDistil: Multi-stage Distillation for Massive Multilingual Models,"Deep and large pre-trained language models are the state-of-the-art for various natural language processing tasks. However, the huge size of these models could be a deterrent to using them in practice. Some recent works use knowledge distillation to compress these huge models into shallow ones. In this work we study knowledge distillation with a focus on multilingual Named Entity Recognition (NER). In particular, we study several distillation strategies and propose a stage-wise optimization scheme leveraging teacher internal representations, that is agnostic of teacher architecture, and show that it outperforms strategies employed in prior works. Additionally, we investigate the role of several factors like the amount of unlabeled data, annotation resources, model architecture and inference latency to name a few. We show that our approach leads to massive compression of teacher models like mBERT by upto 35x in terms of parameters and 51x in terms of latency for batch inference while retaining 95% of its F 1 -score for NER over 41 languages.","XtremeDistil: Multi-stage Distillation for Massive Multilingual Models Deep and large pre-trained language models are the state-of-the-art for various natural language processing tasks. However, the huge size of these models could be a deterrent to using them in practice. Some recent works use knowledge distillation to compress these huge models into shallow ones. In this work we study knowledge distillation with a focus on multilingual Named Entity Recognition (NER). In particular, we study several distillation strategies and propose a stage-wise optimization scheme leveraging teacher internal representations, that is agnostic of teacher architecture, and show that it outperforms strategies employed in prior works. Additionally, we investigate the role of several factors like the amount of unlabeled data, annotation resources, model architecture and inference latency to name a few. We show that our approach leads to massive compression of teacher models like mBERT by upto 35x in terms of parameters and 51x in terms of latency for batch inference while retaining 95% of its F 1 -score for NER over 41 languages.","xtremedistil : multi - stage distillation massive multilingual model deep large pre - trained language model state - - - art natural language processing task . , huge size model deterrent practice . recent work use knowledge distillation compress huge model shallow one . work study knowledge distillation focus multilingual named entity recognition ( ner ) . particular , study distillation strategy propose stage - wise optimization scheme leverage teacher internal representation , agnostic teacher architecture , outperform strategy employ prior work . additionally , investigate role factor like unlabeled datum , annotation resource , model architecture inference latency . approach lead massive compression teacher model like mbert upto 35x term parameter 51x term latency batch inference retain 95 % f 1 -score ner 41 language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Contextual Embeddings: When Are They Worth It?,"We study the settings for which deep contextual embeddings (e.g., BERT) give large improvements in performance relative to classic pretrained embeddings (e.g., GloVe), and an even simpler baseline-random word embeddings-focusing on the impact of the training set size and the linguistic properties of the task. Surprisingly, we find that both of these simpler baselines can match contextual embeddings on industry-scale data, and often perform within 5 to 10% accuracy (absolute) on benchmark tasks. Furthermore, we identify properties of data for which contextual embeddings give particularly large gains: language containing complex structure, ambiguous word usage, and words unseen in training.","Contextual Embeddings: When Are They Worth It? We study the settings for which deep contextual embeddings (e.g., BERT) give large improvements in performance relative to classic pretrained embeddings (e.g., GloVe), and an even simpler baseline-random word embeddings-focusing on the impact of the training set size and the linguistic properties of the task. Surprisingly, we find that both of these simpler baselines can match contextual embeddings on industry-scale data, and often perform within 5 to 10% accuracy (absolute) on benchmark tasks. Furthermore, we identify properties of data for which contextual embeddings give particularly large gains: language containing complex structure, ambiguous word usage, and words unseen in training.","contextual embedding : worth ? study setting deep contextual embedding ( e.g. , bert ) large improvement performance relative classic pretrained embedding ( e.g. , glove ) , simple baseline - random word embedding - focus impact training set size linguistic property task . surprisingly , find simple baseline match contextual embedding industry - scale datum , perform 5 10 % accuracy ( absolute ) benchmark task . furthermore , identify property datum contextual embedding particularly large gain : language contain complex structure , ambiguous word usage , word unseen training .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Masked Language Model Scoring,"Pretrained masked language models (MLMs) require finetuning for most NLP tasks. Instead, we evaluate MLMs out of the box via their pseudo-log-likelihood scores (PLLs), which are computed by masking tokens one by one. We show that PLLs outperform scores from autoregressive language models like GPT-2 in a variety of tasks. By rescoring ASR and NMT hypotheses, RoBERTa reduces an endto-end LibriSpeech model's WER by 30% relative and adds up to +1.7 BLEU on state-of-theart baselines for low-resource translation pairs, with further gains from domain adaptation. We attribute this success to PLL's unsupervised expression of linguistic acceptability without a left-to-right bias, greatly improving on scores from GPT-2 (+10 points on island effects, NPI licensing in BLiMP). One can finetune MLMs to give scores without masking, enabling computation in a single inference pass. In all, PLLs and their associated pseudo-perplexities (PP-PLs) enable plug-and-play use of the growing number of pretrained MLMs; e.g., we use a single cross-lingual model to rescore translations in multiple languages. We release our library for language model scoring at https: //github.com/awslabs/mlm-scoring.","Masked Language Model Scoring Pretrained masked language models (MLMs) require finetuning for most NLP tasks. Instead, we evaluate MLMs out of the box via their pseudo-log-likelihood scores (PLLs), which are computed by masking tokens one by one. We show that PLLs outperform scores from autoregressive language models like GPT-2 in a variety of tasks. By rescoring ASR and NMT hypotheses, RoBERTa reduces an endto-end LibriSpeech model's WER by 30% relative and adds up to +1.7 BLEU on state-of-theart baselines for low-resource translation pairs, with further gains from domain adaptation. We attribute this success to PLL's unsupervised expression of linguistic acceptability without a left-to-right bias, greatly improving on scores from GPT-2 (+10 points on island effects, NPI licensing in BLiMP). One can finetune MLMs to give scores without masking, enabling computation in a single inference pass. In all, PLLs and their associated pseudo-perplexities (PP-PLs) enable plug-and-play use of the growing number of pretrained MLMs; e.g., we use a single cross-lingual model to rescore translations in multiple languages. We release our library for language model scoring at https: //github.com/awslabs/mlm-scoring.","masked language model scoring pretrained mask language model ( mlms ) require finetuning nlp task . instead , evaluate mlms box pseudo - log - likelihood score ( plls ) , compute mask token . pll outperform score autoregressive language model like gpt-2 variety task . rescore asr nmt hypothesis , roberta reduce endto - end librispeech model wer 30 % relative add +1.7 bleu state - - theart baseline low - resource translation pair , gain domain adaptation . attribute success pll unsupervised expression linguistic acceptability left - - right bias , greatly improve score gpt-2 ( +10 point island effect , npi licensing blimp ) . finetune mlm score mask , enable computation single inference pass . , plls associated pseudo - perplexity ( pp - pl ) enable plug - - play use grow number pretrained mlm ; e.g. , use single cross - lingual model rescore translation multiple language . release library language model scoring https : //github.com / awslabs / mlm - scoring .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization,"Transfer learning has fundamentally changed the landscape of natural language processing (NLP). Many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. However, due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models, aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. To address such an issue in a principled manner, we propose a new learning framework for robust and efficient fine-tuning for pre-trained models to attain better generalization performance. The proposed framework contains two important ingredients: 1. Smoothness-inducing regularization, which effectively manages the complexity of the model; 2. Bregman proximal point optimization, which is an instance of trustregion methods and can prevent aggressive updating. Our experiments show that the proposed framework achieves new state-of-the-art performance on a number of NLP tasks including GLUE, SNLI, SciTail and ANLI. Moreover, it also outperforms the state-of-the-art T5 model, which is the largest pre-trained model containing 11 billion parameters, on GLUE. 1 * Work was done during an internship at Microsoft Dynamics 365 AI.","SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization Transfer learning has fundamentally changed the landscape of natural language processing (NLP). Many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. However, due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models, aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. To address such an issue in a principled manner, we propose a new learning framework for robust and efficient fine-tuning for pre-trained models to attain better generalization performance. The proposed framework contains two important ingredients: 1. Smoothness-inducing regularization, which effectively manages the complexity of the model; 2. Bregman proximal point optimization, which is an instance of trustregion methods and can prevent aggressive updating. Our experiments show that the proposed framework achieves new state-of-the-art performance on a number of NLP tasks including GLUE, SNLI, SciTail and ANLI. Moreover, it also outperforms the state-of-the-art T5 model, which is the largest pre-trained model containing 11 billion parameters, on GLUE. 1 * Work was done during an internship at Microsoft Dynamics 365 AI.","smart : robust efficient fine - tuning pre - train natural language model principled regularized optimization transfer learning fundamentally change landscape natural language processing ( nlp ) . state - - - art model pre - train large text corpus fine - tune downstream task . , limited data resource downstream task extremely high complexity pre - train model , aggressive fine - tuning cause fine - tune model overfit training datum downstream task fail generalize unseen datum . address issue principled manner , propose new learning framework robust efficient fine - tuning pre - train model attain well generalization performance . propose framework contain important ingredient : 1 . smoothness - induce regularization , effectively manage complexity model ; 2 . bregman proximal point optimization , instance trustregion method prevent aggressive updating . experiment propose framework achieve new state - - - art performance number nlp task include glue , snli , scitail anli . , outperform state - - - art t5 model , large pre - trained model contain 11 billion parameter , glue . 1 * work internship microsoft dynamics 365 ai .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Single Model Ensemble using Pseudo-Tags and Distinct Vectors,"Model ensemble techniques often increase task performance in neural networks; however, they require increased time, memory, and management effort. In this study, we propose a novel method that replicates the effects of a model ensemble with a single model. Our approach creates K-virtual models within a single parameter space using K-distinct pseudotags and K-distinct vectors. Experiments on text classification and sequence labeling tasks on several datasets demonstrate that our method emulates or outperforms a traditional model ensemble with 1/K-times fewer parameters.","Single Model Ensemble using Pseudo-Tags and Distinct Vectors Model ensemble techniques often increase task performance in neural networks; however, they require increased time, memory, and management effort. In this study, we propose a novel method that replicates the effects of a model ensemble with a single model. Our approach creates K-virtual models within a single parameter space using K-distinct pseudotags and K-distinct vectors. Experiments on text classification and sequence labeling tasks on several datasets demonstrate that our method emulates or outperforms a traditional model ensemble with 1/K-times fewer parameters.","single model ensemble pseudo - tag distinct vector model ensemble technique increase task performance neural network ; , require increase time , memory , management effort . study , propose novel method replicate effect model ensemble single model . approach create k - virtual model single parameter space k - distinct pseudotag k - distinct vector . experiment text classification sequence labeling task dataset demonstrate method emulate outperform traditional model ensemble 1 / k - time few parameter .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Learning for NLP,Posterior Calibrated Training on Sentence Classification Tasks,"Most classification models work by first predicting a posterior probability distribution over all classes and then selecting that class with the largest estimated probability. In many settings however, the quality of posterior probability itself (e.g., 65% chance having diabetes), gives more reliable information than the final predicted class alone. When these methods are shown to be poorly calibrated, most fixes to date have relied on posterior calibration, which rescales the predicted probabilities but often has little impact on final classifications. Here we propose an end-to-end training procedure called posterior calibrated (PosCal) training that directly optimizes the objective while minimizing the difference between the predicted and empirical posterior probabilities. We show that PosCal not only helps reduce the calibration error but also improve task performance by penalizing drops in performance of both objectives. Our PosCal achieves about 2.5% of task performance gain and 16.1% of calibration error reduction on GLUE (Wang et al., 2018) compared to the baseline. We achieved the comparable task performance with 13.2% calibration error reduction on xSLUE (Kang and Hovy, 2019), but not outperforming the two-stage calibration baseline. PosCal training can be easily extendable to any types of classification tasks as a form of regularization term. Also, PosCal has the advantage that it incrementally tracks needed statistics for the calibration objective during the training process, making efficient use of large training sets 1 .","Posterior Calibrated Training on Sentence Classification Tasks Most classification models work by first predicting a posterior probability distribution over all classes and then selecting that class with the largest estimated probability. In many settings however, the quality of posterior probability itself (e.g., 65% chance having diabetes), gives more reliable information than the final predicted class alone. When these methods are shown to be poorly calibrated, most fixes to date have relied on posterior calibration, which rescales the predicted probabilities but often has little impact on final classifications. Here we propose an end-to-end training procedure called posterior calibrated (PosCal) training that directly optimizes the objective while minimizing the difference between the predicted and empirical posterior probabilities. We show that PosCal not only helps reduce the calibration error but also improve task performance by penalizing drops in performance of both objectives. Our PosCal achieves about 2.5% of task performance gain and 16.1% of calibration error reduction on GLUE (Wang et al., 2018) compared to the baseline. We achieved the comparable task performance with 13.2% calibration error reduction on xSLUE (Kang and Hovy, 2019), but not outperforming the two-stage calibration baseline. PosCal training can be easily extendable to any types of classification tasks as a form of regularization term. Also, PosCal has the advantage that it incrementally tracks needed statistics for the calibration objective during the training process, making efficient use of large training sets 1 .","posterior calibrate training sentence classification task classification model work predict posterior probability distribution class select class large estimate probability . setting , quality posterior probability ( e.g. , 65 % chance have diabete ) , give reliable information final predict class . method show poorly calibrate , fix date rely posterior calibration , rescale predict probability little impact final classification . propose end - - end training procedure call posterior calibrate ( poscal ) training directly optimize objective minimize difference predict empirical posterior probability . poscal help reduce calibration error improve task performance penalize drop performance objective . poscal achieve 2.5 % task performance gain 16.1 % calibration error reduction glue ( wang et al . , 2018 ) compare baseline . achieve comparable task performance 13.2 % calibration error reduction xslue ( kang hovy , 2019 ) , outperform - stage calibration baseline . poscal training easily extendable type classification task form regularization term . , poscal advantage incrementally track need statistic calibration objective training process , make efficient use large training set 1 .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 20, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Interactive Classification by Asking Informative Questions,"We study the potential for interaction in natural language classification. We add a limited form of interaction for intent classification, where users provide an initial query using natural language, and the system asks for additional information using binary or multichoice questions. At each turn, our system decides between asking the most informative question or making the final classification prediction.The simplicity of the model allows for bootstrapping of the system without interaction data, instead relying on simple crowdsourcing tasks. We evaluate our approach on two domains, showing the benefit of interaction and the advantage of learning to balance between asking additional questions and making the final prediction.","Interactive Classification by Asking Informative Questions We study the potential for interaction in natural language classification. We add a limited form of interaction for intent classification, where users provide an initial query using natural language, and the system asks for additional information using binary or multichoice questions. At each turn, our system decides between asking the most informative question or making the final classification prediction.The simplicity of the model allows for bootstrapping of the system without interaction data, instead relying on simple crowdsourcing tasks. We evaluate our approach on two domains, showing the benefit of interaction and the advantage of learning to balance between asking additional questions and making the final prediction.","interactive classification ask informative question study potential interaction natural language classification . add limited form interaction intent classification , user provide initial query natural language , system ask additional information binary multichoice question . turn , system decide ask informative question make final classification prediction . simplicity model allow bootstrapping system interaction datum , instead rely simple crowdsourcing task . evaluate approach domain , show benefit interaction advantage learn balance ask additional question make final prediction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 4, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Highway Transformer: Self-Gating Enhanced Self-Attentive Networks,"Self-attention mechanisms have made striking state-of-the-art (SOTA) progress in various sequence learning tasks, standing on the multiheaded dot product attention by attending to all the global contexts at different locations. Through a pseudo information highway, we introduce a gated component self-dependency units (SDU) that incorporates LSTM-styled gating units to replenish internal semantic importance within the multi-dimensional latent space of individual representations. The subsidiary content-based SDU gates allow for the information flow of modulated latent embeddings through skipped connections, leading to a clear margin of convergence speed with gradient descent algorithms. We may unveil the role of gating mechanism to aid in the contextbased Transformer modules, with hypothesizing that SDU gates, especially on shallow layers, could push it faster to step towards suboptimal points during the optimization process.","Highway Transformer: Self-Gating Enhanced Self-Attentive Networks Self-attention mechanisms have made striking state-of-the-art (SOTA) progress in various sequence learning tasks, standing on the multiheaded dot product attention by attending to all the global contexts at different locations. Through a pseudo information highway, we introduce a gated component self-dependency units (SDU) that incorporates LSTM-styled gating units to replenish internal semantic importance within the multi-dimensional latent space of individual representations. The subsidiary content-based SDU gates allow for the information flow of modulated latent embeddings through skipped connections, leading to a clear margin of convergence speed with gradient descent algorithms. We may unveil the role of gating mechanism to aid in the contextbased Transformer modules, with hypothesizing that SDU gates, especially on shallow layers, could push it faster to step towards suboptimal points during the optimization process.","highway transformer : self - gate enhance self - attentive networks self - attention mechanism striking state - - - art ( sota ) progress sequence learning task , stand multiheaded dot product attention attend global context different location . pseudo information highway , introduce gate component self - dependency unit ( sdu ) incorporate lstm - style gating unit replenish internal semantic importance multi - dimensional latent space individual representation . subsidiary content - base sdu gate allow information flow modulate latent embedding skip connection , lead clear margin convergence speed gradient descent algorithm . unveil role gating mechanism aid contextbased transformer module , hypothesize sdu gate , especially shallow layer , push fast step suboptimal point optimization process .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Enhancing Pre-trained Chinese Character Representation with Word-aligned Attention,"Most Chinese pre-trained models take character as the basic unit and learn representation according to character's external contexts, ignoring the semantics expressed in the word, which is the smallest meaningful utterance in Chinese. Hence, we propose a novel wordaligned attention to exploit explicit word information, which is complementary to various character-based Chinese pre-trained language models. Specifically, we devise a pooling mechanism to align the character-level attention to the word level and propose to alleviate the potential issue of segmentation error propagation by multi-source information fusion. As a result, word and character information are explicitly integrated at the fine-tuning procedure. Experimental results on five Chinese NLP benchmark tasks demonstrate that our method achieves significant improvements against BERT, ERNIE and BERT-wwm.","Enhancing Pre-trained Chinese Character Representation with Word-aligned Attention Most Chinese pre-trained models take character as the basic unit and learn representation according to character's external contexts, ignoring the semantics expressed in the word, which is the smallest meaningful utterance in Chinese. Hence, we propose a novel wordaligned attention to exploit explicit word information, which is complementary to various character-based Chinese pre-trained language models. Specifically, we devise a pooling mechanism to align the character-level attention to the word level and propose to alleviate the potential issue of segmentation error propagation by multi-source information fusion. As a result, word and character information are explicitly integrated at the fine-tuning procedure. Experimental results on five Chinese NLP benchmark tasks demonstrate that our method achieves significant improvements against BERT, ERNIE and BERT-wwm.","enhance pre - trained chinese character representation word - align attention chinese pre - trained model character basic unit learn representation accord character external context , ignore semantic express word , small meaningful utterance chinese . , propose novel wordaligned attention exploit explicit word information , complementary character - base chinese pre - trained language model . specifically , devise pool mechanism align character - level attention word level propose alleviate potential issue segmentation error propagation multi - source information fusion . result , word character information explicitly integrate fine - tuning procedure . experimental result chinese nlp benchmark task demonstrate method achieve significant improvement bert , ernie bert - wwm .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 14, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Learning for NLP,Bayesian Hierarchical Words Representation Learning,"This paper presents the Bayesian Hierarchical Words Representation (BHWR) learning algorithm. BHWR facilitates Variational Bayes word representation learning combined with semantic taxonomy modeling via hierarchical priors. By propagating relevant information between related words, BHWR utilizes the taxonomy to improve the quality of such representations. Evaluation of several linguistic datasets demonstrates the advantages of BHWR over suitable alternatives that facilitate Bayesian modeling with or without semantic priors. Finally, we further show that BHWR produces better representations for rare words.","Bayesian Hierarchical Words Representation Learning This paper presents the Bayesian Hierarchical Words Representation (BHWR) learning algorithm. BHWR facilitates Variational Bayes word representation learning combined with semantic taxonomy modeling via hierarchical priors. By propagating relevant information between related words, BHWR utilizes the taxonomy to improve the quality of such representations. Evaluation of several linguistic datasets demonstrates the advantages of BHWR over suitable alternatives that facilitate Bayesian modeling with or without semantic priors. Finally, we further show that BHWR produces better representations for rare words.","bayesian hierarchical words representation learning paper present bayesian hierarchical words representation ( bhwr ) learning algorithm . bhwr facilitate variational bayes word representation learning combine semantic taxonomy modeling hierarchical prior . propagate relevant information related word , bhwr utilize taxonomy improve quality representation . evaluation linguistic dataset demonstrate advantage bhwr suitable alternative facilitate bayesian modeling semantic prior . finally , bhwr produce well representation rare word .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Attentive Pooling with Learnable Norms for Text Representation,"Pooling is an important technique for learning text representations in many neural NLP models. In conventional pooling methods such as average, max and attentive pooling, text representations are weighted summations of the L 1 or L âˆž norm of input features. However, their pooling norms are always fixed and may not be optimal for learning accurate text representations in different tasks. In addition, in many popular pooling methods such as max and attentive pooling some features may be over-emphasized, while other useful ones are not fully exploited. In this paper, we propose an Attentive Pooling with Learnable Norms (APLN) approach for text representation. Different from existing pooling methods that use a fixed pooling norm, we propose to learn the norm in an end-to-end manner to automatically find the optimal ones for text representation in different tasks. In addition, we propose two methods to ensure the numerical stability of the model training. The first one is scale limiting, which re-scales the input to ensure non-negativity and alleviate the risk of exponential explosion. The second one is re-formulation, which decomposes the exponent operation to avoid computing the realvalued powers of the input and further accelerate the pooling operation. Experimental results on four benchmark datasets show that our approach can effectively improve the performance of attentive pooling.","Attentive Pooling with Learnable Norms for Text Representation Pooling is an important technique for learning text representations in many neural NLP models. In conventional pooling methods such as average, max and attentive pooling, text representations are weighted summations of the L 1 or L âˆž norm of input features. However, their pooling norms are always fixed and may not be optimal for learning accurate text representations in different tasks. In addition, in many popular pooling methods such as max and attentive pooling some features may be over-emphasized, while other useful ones are not fully exploited. In this paper, we propose an Attentive Pooling with Learnable Norms (APLN) approach for text representation. Different from existing pooling methods that use a fixed pooling norm, we propose to learn the norm in an end-to-end manner to automatically find the optimal ones for text representation in different tasks. In addition, we propose two methods to ensure the numerical stability of the model training. The first one is scale limiting, which re-scales the input to ensure non-negativity and alleviate the risk of exponential explosion. The second one is re-formulation, which decomposes the exponent operation to avoid computing the realvalued powers of the input and further accelerate the pooling operation. Experimental results on four benchmark datasets show that our approach can effectively improve the performance of attentive pooling.","attentive pooling learnable norm text representation pooling important technique learn text representation neural nlp model . conventional pooling method average , max attentive pooling , text representation weight summation l 1 l âˆž norm input feature . , pooling norm fix optimal learn accurate text representation different task . addition , popular pooling method max attentive pooling feature - emphasize , useful one fully exploit . paper , propose attentive pooling learnable norms ( apln ) approach text representation . different exist pooling method use fix pooling norm , propose learn norm end - - end manner automatically find optimal one text representation different task . addition , propose method ensure numerical stability model training . scale limit , - scale input ensure non - negativity alleviate risk exponential explosion . second - formulation , decompose exponent operation avoid compute realvalued power input accelerate pooling operation . experimental result benchmark dataset approach effectively improve performance attentive pooling .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Robust Encodings: A Framework for Combating Adversarial Typos,"Despite excellent performance on many tasks, NLP systems are easily fooled by small adversarial perturbations of inputs. Existing procedures to defend against such perturbations are either (i) heuristic in nature and susceptible to stronger attacks or (ii) provide guaranteed robustness to worst-case attacks, but are incompatible with state-of-the-art models like BERT. In this work, we introduce robust encodings (RobEn): a simple framework that confers guaranteed robustness, without making compromises on model architecture. The core component of RobEn is an encoding function, which maps sentences to a smaller, discrete space of encodings. Systems using these encodings as a bottleneck confer guaranteed robustness with standard training, and the same encodings can be used across multiple tasks. We identify two desiderata to construct robust encoding functions: perturbations of a sentence should map to a small set of encodings (stability), and models using encodings should still perform well (fidelity). We instantiate RobEn to defend against a large family of adversarial typos. Across six tasks from GLUE, our instantiation of RobEn paired with BERT achieves an average robust accuracy of 71.3% against all adversarial typos in the family considered, while previous work using a typo-corrector achieves only 35.3% accuracy against a simple greedy attack.","Robust Encodings: A Framework for Combating Adversarial Typos Despite excellent performance on many tasks, NLP systems are easily fooled by small adversarial perturbations of inputs. Existing procedures to defend against such perturbations are either (i) heuristic in nature and susceptible to stronger attacks or (ii) provide guaranteed robustness to worst-case attacks, but are incompatible with state-of-the-art models like BERT. In this work, we introduce robust encodings (RobEn): a simple framework that confers guaranteed robustness, without making compromises on model architecture. The core component of RobEn is an encoding function, which maps sentences to a smaller, discrete space of encodings. Systems using these encodings as a bottleneck confer guaranteed robustness with standard training, and the same encodings can be used across multiple tasks. We identify two desiderata to construct robust encoding functions: perturbations of a sentence should map to a small set of encodings (stability), and models using encodings should still perform well (fidelity). We instantiate RobEn to defend against a large family of adversarial typos. Across six tasks from GLUE, our instantiation of RobEn paired with BERT achieves an average robust accuracy of 71.3% against all adversarial typos in the family considered, while previous work using a typo-corrector achieves only 35.3% accuracy against a simple greedy attack.","robust encodings : framework combat adversarial typo despite excellent performance task , nlp system easily fool small adversarial perturbation input . exist procedure defend perturbation ( ) heuristic nature susceptible strong attack ( ii ) provide guarantee robustness bad - case attack , incompatible state - - - art model like bert . work , introduce robust encoding ( roben ): simple framework confer guarantee robustness , make compromise model architecture . core component roben encoding function , map sentence small , discrete space encoding . system encoding bottleneck confer guarantee robustness standard training , encoding multiple task . identify desideratum construct robust encoding function : perturbation sentence map small set encoding ( stability ) , model encoding perform ( fidelity ) . instantiate roben defend large family adversarial typo . task glue , instantiation roben pair bert achieve average robust accuracy 71.3 % adversarial typo family consider , previous work typo - corrector achieve 35.3 % accuracy simple greedy attack .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Learning Constraints for Structured Prediction Using Rectifier Networks,"Various natural language processing tasks are structured prediction problems where outputs are constructed with multiple interdependent decisions. Past work has shown that domain knowledge, framed as constraints over the output space, can help improve predictive accuracy. However, designing good constraints often relies on domain expertise. In this paper, we study the problem of learning such constraints. We frame the problem as that of training a two-layer rectifier network to identify valid structures or substructures, and show a construction for converting a trained network into a system of linear constraints over the inference variables. Our experiments on several NLP tasks show that the learned constraints can improve the prediction accuracy, especially when the number of training examples is small.","Learning Constraints for Structured Prediction Using Rectifier Networks Various natural language processing tasks are structured prediction problems where outputs are constructed with multiple interdependent decisions. Past work has shown that domain knowledge, framed as constraints over the output space, can help improve predictive accuracy. However, designing good constraints often relies on domain expertise. In this paper, we study the problem of learning such constraints. We frame the problem as that of training a two-layer rectifier network to identify valid structures or substructures, and show a construction for converting a trained network into a system of linear constraints over the inference variables. Our experiments on several NLP tasks show that the learned constraints can improve the prediction accuracy, especially when the number of training examples is small.","learn constraint structured prediction rectifier network natural language processing task structure prediction problem output construct multiple interdependent decision . past work show domain knowledge , frame constraint output space , help improve predictive accuracy . , design good constraint rely domain expertise . paper , study problem learn constraint . frame problem train - layer rectifier network identify valid structure substructure , construction convert train network system linear constraint inference variable . experiment nlp task learn constraint improve prediction accuracy , especially number training example small .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Stolen Probability: A Structural Weakness of Neural Language Models,"Neural Network Language Models (NNLMs) generate probability distributions by applying a softmax function to a distance metric formed by taking the dot product of a prediction vector with all word vectors in a high-dimensional embedding space. The dot-product distance metric forms part of the inductive bias of NNLMs. Although NNLMs optimize well with this inductive bias, we show that this results in a sub-optimal ordering of the embedding space that structurally impoverishes some words at the expense of others when assigning probability. We present numerical, theoretical and empirical analyses showing that words on the interior of the convex hull in the embedding space have their probability bounded by the probabilities of the words on the hull.","Stolen Probability: A Structural Weakness of Neural Language Models Neural Network Language Models (NNLMs) generate probability distributions by applying a softmax function to a distance metric formed by taking the dot product of a prediction vector with all word vectors in a high-dimensional embedding space. The dot-product distance metric forms part of the inductive bias of NNLMs. Although NNLMs optimize well with this inductive bias, we show that this results in a sub-optimal ordering of the embedding space that structurally impoverishes some words at the expense of others when assigning probability. We present numerical, theoretical and empirical analyses showing that words on the interior of the convex hull in the embedding space have their probability bounded by the probabilities of the words on the hull.","stolen probability : structural weakness neural language models neural network language models ( nnlms ) generate probability distribution apply softmax function distance metric form take dot product prediction vector word vector high - dimensional embedding space . dot - product distance metric form inductive bias nnlms . nnlms optimize inductive bias , result sub - optimal ordering embedding space structurally impoverish word expense assign probability . present numerical , theoretical empirical analysis show word interior convex hull embed space probability bound probability word hull .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,True
Machine Learning for NLP,GAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples,"Recent Transformer-based architectures, e.g., BERT, provide impressive results in many Natural Language Processing tasks. However, most of the adopted benchmarks are made of (sometimes hundreds of) thousands of examples. In many real scenarios, obtaining highquality annotated data is expensive and timeconsuming; in contrast, unlabeled examples characterizing the target task can be, in general, easily collected. One promising method to enable semi-supervised learning has been proposed in image processing, based on Semi-Supervised Generative Adversarial Networks. In this paper, we propose GAN-BERT that extends the fine-tuning of BERT-like architectures with unlabeled data in a generative adversarial setting. Experimental results show that the requirement for annotated examples can be drastically reduced (up to only 50-100 annotated examples), still obtaining good performances in several sentence classification tasks.","GAN-BERT: Generative Adversarial Learning for Robust Text Classification with a Bunch of Labeled Examples Recent Transformer-based architectures, e.g., BERT, provide impressive results in many Natural Language Processing tasks. However, most of the adopted benchmarks are made of (sometimes hundreds of) thousands of examples. In many real scenarios, obtaining highquality annotated data is expensive and timeconsuming; in contrast, unlabeled examples characterizing the target task can be, in general, easily collected. One promising method to enable semi-supervised learning has been proposed in image processing, based on Semi-Supervised Generative Adversarial Networks. In this paper, we propose GAN-BERT that extends the fine-tuning of BERT-like architectures with unlabeled data in a generative adversarial setting. Experimental results show that the requirement for annotated examples can be drastically reduced (up to only 50-100 annotated examples), still obtaining good performances in several sentence classification tasks.","gan - bert : generative adversarial learning robust text classification bunch label example recent transformer - base architecture , e.g. , bert , provide impressive result natural language processing task . , adopt benchmark ( hundred ) thousand example . real scenario , obtain highquality annotate datum expensive timeconsuming ; contrast , unlabeled example characterize target task , general , easily collect . promising method enable semi - supervised learning propose image processing , base semi - supervised generative adversarial networks . paper , propose gan - bert extend fine - tuning bert - like architecture unlabeled datum generative adversarial setting . experimental result requirement annotate example drastically reduce ( 50 - 100 annotate example ) , obtain good performance sentence classification task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,SpanBERT: Improving Pre-training by Representing and Predicting Spans,"We present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms BERT and our better-tuned baselines, with substantial gains on span selection tasks such as question answering and coreference resolution. In particular, with the same training data and model size as BERT large , our single model obtains 94.6% and 88.7% F1 on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6% F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE. 1 * Equal contribution. 1 Our code and pre-trained models are available at https:// github.com/facebookresearch/SpanBERT.","SpanBERT: Improving Pre-training by Representing and Predicting Spans We present SpanBERT, a pre-training method that is designed to better represent and predict spans of text. Our approach extends BERT by (1) masking contiguous random spans, rather than random tokens, and (2) training the span boundary representations to predict the entire content of the masked span, without relying on the individual token representations within it. SpanBERT consistently outperforms BERT and our better-tuned baselines, with substantial gains on span selection tasks such as question answering and coreference resolution. In particular, with the same training data and model size as BERT large , our single model obtains 94.6% and 88.7% F1 on SQuAD 1.1 and 2.0 respectively. We also achieve a new state of the art on the OntoNotes coreference resolution task (79.6% F1), strong performance on the TACRED relation extraction benchmark, and even gains on GLUE. 1 * Equal contribution. 1 Our code and pre-trained models are available at https:// github.com/facebookresearch/SpanBERT.","spanbert : improve pre - training represent predict span present spanbert , pre - training method design well represent predict span text . approach extend bert ( 1 ) mask contiguous random span , random token , ( 2 ) train span boundary representation predict entire content mask span , rely individual token representation . spanbert consistently outperform bert well - tune baseline , substantial gain span selection task question answering coreference resolution . particular , training datum model size bert large , single model obtain 94.6 % 88.7 % f1 squad 1.1 2.0 respectively . achieve new state art ontonotes coreference resolution task ( 79.6 % f1 ) , strong performance tacred relation extraction benchmark , gain glue . 1 * equal contribution . 1 code pre - trained model available https:// github.com/facebookresearch/spanbert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 18, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 5, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Showing Your Work Doesn't Always Work,"In natural language processing, a recently popular line of work explores how to best report the experimental results of neural networks. One exemplar publication, titled ""Show Your Work: Improved Reporting of Experimental Results"" (Dodge et al., 2019), advocates for reporting the expected validation effectiveness of the best-tuned model, with respect to the computational budget. In the present work, we critically examine this paper. As far as statistical generalizability is concerned, we find unspoken pitfalls and caveats with this approach. We analytically show that their estimator is biased and uses error-prone assumptions. We find that the estimator favors negative errors and yields poor bootstrapped confidence intervals. We derive an unbiased alternative and bolster our claims with empirical evidence from statistical simulation. Our codebase is at https://github.com/ castorini/meanmax.","Showing Your Work Doesn't Always Work In natural language processing, a recently popular line of work explores how to best report the experimental results of neural networks. One exemplar publication, titled ""Show Your Work: Improved Reporting of Experimental Results"" (Dodge et al., 2019), advocates for reporting the expected validation effectiveness of the best-tuned model, with respect to the computational budget. In the present work, we critically examine this paper. As far as statistical generalizability is concerned, we find unspoken pitfalls and caveats with this approach. We analytically show that their estimator is biased and uses error-prone assumptions. We find that the estimator favors negative errors and yields poor bootstrapped confidence intervals. We derive an unbiased alternative and bolster our claims with empirical evidence from statistical simulation. Our codebase is at https://github.com/ castorini/meanmax.","show work work natural language processing , recently popular line work explore well report experimental result neural network . exemplar publication , title "" work : improved reporting experimental results "" ( dodge et al . , 2019 ) , advocate report expect validation effectiveness well - tune model , respect computational budget . present work , critically examine paper . far statistical generalizability concern , find unspoken pitfall caveat approach . analytically estimator bias use error - prone assumption . find estimator favor negative error yield poor bootstrappe confidence interval . derive unbiased alternative bolster claim empirical evidence statistical simulation . codebase https://github.com/ castorini / meanmax .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Machine Learning for NLP,SEEK: Segmented Embedding of Knowledge Graphs,"In recent years, knowledge graph embedding becomes a pretty hot research topic of artificial intelligence and plays increasingly vital roles in various downstream applications, such as recommendation and question answering. However, existing methods for knowledge graph embedding can not make a proper trade-off between the model complexity and the model expressiveness, which makes them still far from satisfactory. To mitigate this problem, we propose a lightweight modeling framework that can achieve highly competitive relational expressiveness without increasing the model complexity. Our framework focuses on the design of scoring functions and highlights two critical characteristics: 1) facilitating sufficient feature interactions; 2) preserving both symmetry and antisymmetry properties of relations. It is noteworthy that owing to the general and elegant design of scoring functions, our framework can incorporate many famous existing methods as special cases. Moreover, extensive experiments on public benchmarks demonstrate the efficiency and effectiveness of our framework. Source codes and data can be found at https://github.com/ Wentao-Xu/SEEK.","SEEK: Segmented Embedding of Knowledge Graphs In recent years, knowledge graph embedding becomes a pretty hot research topic of artificial intelligence and plays increasingly vital roles in various downstream applications, such as recommendation and question answering. However, existing methods for knowledge graph embedding can not make a proper trade-off between the model complexity and the model expressiveness, which makes them still far from satisfactory. To mitigate this problem, we propose a lightweight modeling framework that can achieve highly competitive relational expressiveness without increasing the model complexity. Our framework focuses on the design of scoring functions and highlights two critical characteristics: 1) facilitating sufficient feature interactions; 2) preserving both symmetry and antisymmetry properties of relations. It is noteworthy that owing to the general and elegant design of scoring functions, our framework can incorporate many famous existing methods as special cases. Moreover, extensive experiments on public benchmarks demonstrate the efficiency and effectiveness of our framework. Source codes and data can be found at https://github.com/ Wentao-Xu/SEEK.","seek : segment embedding knowledge graph recent year , knowledge graph embedding pretty hot research topic artificial intelligence play increasingly vital role downstream application , recommendation question answering . , exist method knowledge graph embedding proper trade - model complexity model expressiveness , make far satisfactory . mitigate problem , propose lightweight modeling framework achieve highly competitive relational expressiveness increase model complexity . framework focus design scoring function highlight critical characteristic : 1 ) facilitate sufficient feature interaction ; 2 ) preserve symmetry antisymmetry property relation . noteworthy owe general elegant design scoring function , framework incorporate famous exist method special case . , extensive experiment public benchmark demonstrate efficiency effectiveness framework . source code datum find https://github.com/ wentao - xu / seek .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions,"State-of-the-art NLP models can often be fooled by human-unaware transformations such as synonymous word substitution. For security reasons, it is of critical importance to develop models with certified robustness that can provably guarantee that the prediction is can not be altered by any possible synonymous word substitution. In this work, we propose a certified robust method based on a new randomized smoothing technique, which constructs a stochastic ensemble by applying random word substitutions on the input sentences, and leverage the statistical properties of the ensemble to provably certify the robustness. Our method is simple and structure-free in that it only requires the black-box queries of the model outputs, and hence can be applied to any pre-trained models (such as BERT) and any types of models (world-level or subwordlevel). Our method significantly outperforms recent state-of-the-art methods for certified robustness on both IMDB and Amazon text classification tasks. To the best of our knowledge, we are the first work to achieve certified robustness on large systems such as BERT with practically meaningful certified accuracy.","SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions State-of-the-art NLP models can often be fooled by human-unaware transformations such as synonymous word substitution. For security reasons, it is of critical importance to develop models with certified robustness that can provably guarantee that the prediction is can not be altered by any possible synonymous word substitution. In this work, we propose a certified robust method based on a new randomized smoothing technique, which constructs a stochastic ensemble by applying random word substitutions on the input sentences, and leverage the statistical properties of the ensemble to provably certify the robustness. Our method is simple and structure-free in that it only requires the black-box queries of the model outputs, and hence can be applied to any pre-trained models (such as BERT) and any types of models (world-level or subwordlevel). Our method significantly outperforms recent state-of-the-art methods for certified robustness on both IMDB and Amazon text classification tasks. To the best of our knowledge, we are the first work to achieve certified robustness on large systems such as BERT with practically meaningful certified accuracy.","safer : structure - free approach certify robustness adversarial word substitution state - - - art nlp model fool human - unaware transformation synonymous word substitution . security reason , critical importance develop model certify robustness provably guarantee prediction alter possible synonymous word substitution . work , propose certify robust method base new randomize smoothing technique , construct stochastic ensemble apply random word substitution input sentence , leverage statistical property ensemble provably certify robustness . method simple structure - free require black - box query model output , apply pre - trained model ( bert ) type model ( world - level subwordlevel ) . method significantly outperform recent state - - - art method certify robustness imdb amazon text classification task . good knowledge , work achieve certify robustness large system bert practically meaningful certify accuracy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection,"The ability to control for the kinds of information encoded in neural representation has a variety of use cases, especially in light of the challenge of interpreting these models. We present Iterative Null-space Projection (INLP), a novel method for removing information from neural representations. Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the representations on their null-space. By doing so, the classifiers become oblivious to that target property, making it hard to linearly separate the data according to it. While applicable for multiple uses, we evaluate our method on bias and fairness use-cases, and show that our method is able to mitigate bias in word embeddings, as well as to increase fairness in a setting of multi-class classification.","Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection The ability to control for the kinds of information encoded in neural representation has a variety of use cases, especially in light of the challenge of interpreting these models. We present Iterative Null-space Projection (INLP), a novel method for removing information from neural representations. Our method is based on repeated training of linear classifiers that predict a certain property we aim to remove, followed by projection of the representations on their null-space. By doing so, the classifiers become oblivious to that target property, making it hard to linearly separate the data according to it. While applicable for multiple uses, we evaluate our method on bias and fairness use-cases, and show that our method is able to mitigate bias in word embeddings, as well as to increase fairness in a setting of multi-class classification.","null : guard protect attribute iterative nullspace projection ability control kind information encode neural representation variety use case , especially light challenge interpret model . present iterative null - space projection ( inlp ) , novel method remove information neural representation . method base repeat training linear classifier predict certain property aim remove , follow projection representation null - space . , classifier oblivious target property , make hard linearly separate datum accord . applicable multiple use , evaluate method bias fairness use - case , method able mitigate bias word embedding , increase fairness setting multi - class classification .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Span Selection Pre-training for Question Answering,"BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pretrained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension to better align the pre-training from memorization to understanding. Span Selection Pre-Training (SSPT) poses cloze-like training instances, but rather than draw the answer from the model's parameters, it is selected from a relevant passage. We find significant and consistent improvements over both BERT BASE and BERT LARGE on multiple Machine Reading Comprehension (MRC) datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT LARGE by 3 F1 points on short answer prediction. We also show significant impact in HotpotQA, improving answer prediction F1 by 4 points and supporting fact prediction F1 by 1 point and outperforming the previous best system. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.","Span Selection Pre-training for Question Answering BERT (Bidirectional Encoder Representations from Transformers) and related pre-trained Transformers have provided large gains across many language understanding tasks, achieving a new state-of-the-art (SOTA). BERT is pretrained on two auxiliary tasks: Masked Language Model and Next Sentence Prediction. In this paper we introduce a new pre-training task inspired by reading comprehension to better align the pre-training from memorization to understanding. Span Selection Pre-Training (SSPT) poses cloze-like training instances, but rather than draw the answer from the model's parameters, it is selected from a relevant passage. We find significant and consistent improvements over both BERT BASE and BERT LARGE on multiple Machine Reading Comprehension (MRC) datasets. Specifically, our proposed model has strong empirical evidence as it obtains SOTA results on Natural Questions, a new benchmark MRC dataset, outperforming BERT LARGE by 3 F1 points on short answer prediction. We also show significant impact in HotpotQA, improving answer prediction F1 by 4 points and supporting fact prediction F1 by 1 point and outperforming the previous best system. Moreover, we show that our pre-training approach is particularly effective when training data is limited, improving the learning curve by a large amount.","span selection pre - training question answering bert ( bidirectional encoder representations transformers ) relate pre - train transformers provide large gain language understanding task , achieve new state - - - art ( sota ) . bert pretraine auxiliary task : masked language model sentence prediction . paper introduce new pre - training task inspire reading comprehension well align pre - training memorization understanding . span selection pre - training ( sspt ) pose cloze - like training instance , draw answer model parameter , select relevant passage . find significant consistent improvement bert base bert large multiple machine reading comprehension ( mrc ) dataset . specifically , propose model strong empirical evidence obtain sota result natural questions , new benchmark mrc dataset , outperform bert large 3 f1 point short answer prediction . significant impact hotpotqa , improve answer prediction f1 4 point support fact prediction f1 1 point outperform previous good system . , pre - training approach particularly effective training data limit , improve learning curve large .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 20, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 17, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Improving Disentangled Text Representation Learning with Information-Theoretic Guidance,"Learning disentangled representations of natural language is essential for many NLP tasks, e.g., conditional text generation, style transfer, personalized dialogue systems, etc. Similar problems have been studied extensively for other forms of data, such as images and videos. However, the discrete nature of natural language makes the disentangling of textual representations more challenging (e.g., the manipulation over the data space cannot be easily achieved). Inspired by information theory, we propose a novel method that effectively manifests disentangled representations of text, without any supervision on semantics. A new mutual information upper bound is derived and leveraged to measure dependence between style and content. By minimizing this upper bound, the proposed method induces style and content embeddings into two independent low-dimensional spaces. Experiments on both conditional text generation and text-style transfer demonstrate the high quality of our disentangled representation in terms of content and style preservation.","Improving Disentangled Text Representation Learning with Information-Theoretic Guidance Learning disentangled representations of natural language is essential for many NLP tasks, e.g., conditional text generation, style transfer, personalized dialogue systems, etc. Similar problems have been studied extensively for other forms of data, such as images and videos. However, the discrete nature of natural language makes the disentangling of textual representations more challenging (e.g., the manipulation over the data space cannot be easily achieved). Inspired by information theory, we propose a novel method that effectively manifests disentangled representations of text, without any supervision on semantics. A new mutual information upper bound is derived and leveraged to measure dependence between style and content. By minimizing this upper bound, the proposed method induces style and content embeddings into two independent low-dimensional spaces. Experiments on both conditional text generation and text-style transfer demonstrate the high quality of our disentangled representation in terms of content and style preservation.","improve disentangle text representation learning information - theoretic guidance learn disentangle representation natural language essential nlp task , e.g. , conditional text generation , style transfer , personalize dialogue system , etc . similar problem study extensively form datum , image video . , discrete nature natural language make disentangling textual representation challenging ( e.g. , manipulation datum space easily achieve ) . inspire information theory , propose novel method effectively manifest disentangled representation text , supervision semantic . new mutual information upper bound derive leverage measure dependence style content . minimize upper bound , propose method induce style content embedding independent low - dimensional space . experiment conditional text generation text - style transfer demonstrate high quality disentangled representation term content style preservation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Taxonomy Construction of Unseen Domains via Graph-based Cross-Domain Knowledge Transfer,"Extracting lexico-semantic relations as graphstructured taxonomies, also known as taxonomy construction, has been beneficial in a variety of NLP applications. Recently Graph Neural Network (GNN) has shown to be powerful in successfully tackling many tasks. However, there has been no attempt to exploit GNN to create taxonomies. In this paper, we propose Graph2Taxo, a GNN-based cross-domain transfer framework for the taxonomy construction task. Our main contribution is to learn the latent features of taxonomy construction from existing domains to guide the structure learning of an unseen domain. We also propose a novel method of directed acyclic graph (DAG) generation for taxonomy construction. Specifically, our proposed Graph2Taxo uses a noisy graph constructed from automatically extracted noisy hyponym-hypernym candidate pairs, and a set of taxonomies for some known domains for training. The learned model is then used to generate taxonomy for a new unknown domain given a set of terms for that domain. Experiments on benchmark datasets from science and environment domains show that our approach attains significant improvements correspondingly over the state of the art.","Taxonomy Construction of Unseen Domains via Graph-based Cross-Domain Knowledge Transfer Extracting lexico-semantic relations as graphstructured taxonomies, also known as taxonomy construction, has been beneficial in a variety of NLP applications. Recently Graph Neural Network (GNN) has shown to be powerful in successfully tackling many tasks. However, there has been no attempt to exploit GNN to create taxonomies. In this paper, we propose Graph2Taxo, a GNN-based cross-domain transfer framework for the taxonomy construction task. Our main contribution is to learn the latent features of taxonomy construction from existing domains to guide the structure learning of an unseen domain. We also propose a novel method of directed acyclic graph (DAG) generation for taxonomy construction. Specifically, our proposed Graph2Taxo uses a noisy graph constructed from automatically extracted noisy hyponym-hypernym candidate pairs, and a set of taxonomies for some known domains for training. The learned model is then used to generate taxonomy for a new unknown domain given a set of terms for that domain. Experiments on benchmark datasets from science and environment domains show that our approach attains significant improvements correspondingly over the state of the art.","taxonomy construction unseen domain graph - base cross - domain knowledge transfer extract lexico - semantic relation graphstructured taxonomy , know taxonomy construction , beneficial variety nlp application . recently graph neural network ( gnn ) show powerful successfully tackle task . , attempt exploit gnn create taxonomy . paper , propose graph2taxo , gnn - base cross - domain transfer framework taxonomy construction task . main contribution learn latent feature taxonomy construction exist domain guide structure learning unseen domain . propose novel method direct acyclic graph ( dag ) generation taxonomy construction . specifically , propose graph2taxo use noisy graph construct automatically extract noisy hyponym - hypernym candidate pair , set taxonomy know domain train . learn model generate taxonomy new unknown domain give set term domain . experiment benchmark dataset science environment domain approach attain significant improvement correspondingly state art .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,How Does Selective Mechanism Improve Self-Attention Networks?,"Self-attention networks (SANs) with selective mechanism has produced substantial improvements in various NLP tasks by concentrating on a subset of input words. However, the underlying reasons for their strong performance have not been well explained. In this paper, we bridge the gap by assessing the strengths of selective SANs (SSANs), which are implemented with a flexible and universal Gumbel-Softmax. Experimental results on several representative NLP tasks, including natural language inference, semantic role labelling, and machine translation, show that SSANs consistently outperform the standard SANs. Through well-designed probing experiments, we empirically validate that the improvement of SSANs can be attributed in part to mitigating two commonly-cited weaknesses of SANs: word order encoding and structure modeling. Specifically, the selective mechanism improves SANs by paying more attention to content words that contribute to the meaning of the sentence. The code and data are released at https://github.com/xwgeng/SSAN.","How Does Selective Mechanism Improve Self-Attention Networks? Self-attention networks (SANs) with selective mechanism has produced substantial improvements in various NLP tasks by concentrating on a subset of input words. However, the underlying reasons for their strong performance have not been well explained. In this paper, we bridge the gap by assessing the strengths of selective SANs (SSANs), which are implemented with a flexible and universal Gumbel-Softmax. Experimental results on several representative NLP tasks, including natural language inference, semantic role labelling, and machine translation, show that SSANs consistently outperform the standard SANs. Through well-designed probing experiments, we empirically validate that the improvement of SSANs can be attributed in part to mitigating two commonly-cited weaknesses of SANs: word order encoding and structure modeling. Specifically, the selective mechanism improves SANs by paying more attention to content words that contribute to the meaning of the sentence. The code and data are released at https://github.com/xwgeng/SSAN.","selective mechanism improve self - attention network ? self - attention network ( sans ) selective mechanism produce substantial improvement nlp task concentrate subset input word . , underlie reason strong performance explain . paper , bridge gap assess strength selective san ( ssans ) , implement flexible universal gumbel - softmax . experimental result representative nlp task , include natural language inference , semantic role labelling , machine translation , ssans consistently outperform standard sans . - design probe experiment , empirically validate improvement ssans attribute mitigate commonly - cite weakness sans : word order encoding structure modeling . specifically , selective mechanism improve sans pay attention content word contribute meaning sentence . code datum release https://github.com/xwgeng/ssan .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Theme,False
Machine Learning for NLP,Calibrating Structured Output Predictors for Natural Language Processing,"We address the problem of calibrating prediction confidence for output entities of interest in natural language processing (NLP) applications. It is important that NLP applications such as named entity recognition and question answering produce calibrated confidence scores for their predictions, especially if the applications are to be deployed in a safetycritical domain such as healthcare. However, the output space of such structured prediction models is often too large to adapt binary or multi-class calibration methods directly. In this study, we propose a general calibration scheme for output entities of interest in neural network based structured prediction models. Our proposed method can be used with any binary class calibration scheme and a neural network model. Additionally, we show that our calibration method can also be used as an uncertainty-aware, entity-specific decoding step to improve the performance of the underlying model at no additional training cost or data requirements. We show that our method outperforms current calibration techniques for named-entity-recognition, part-ofspeech and question answering. We also improve our model's performance from our decoding step across several tasks and benchmark datasets. Our method improves the calibration and model performance on out-ofdomain test scenarios as well.","Calibrating Structured Output Predictors for Natural Language Processing We address the problem of calibrating prediction confidence for output entities of interest in natural language processing (NLP) applications. It is important that NLP applications such as named entity recognition and question answering produce calibrated confidence scores for their predictions, especially if the applications are to be deployed in a safetycritical domain such as healthcare. However, the output space of such structured prediction models is often too large to adapt binary or multi-class calibration methods directly. In this study, we propose a general calibration scheme for output entities of interest in neural network based structured prediction models. Our proposed method can be used with any binary class calibration scheme and a neural network model. Additionally, we show that our calibration method can also be used as an uncertainty-aware, entity-specific decoding step to improve the performance of the underlying model at no additional training cost or data requirements. We show that our method outperforms current calibration techniques for named-entity-recognition, part-ofspeech and question answering. We also improve our model's performance from our decoding step across several tasks and benchmark datasets. Our method improves the calibration and model performance on out-ofdomain test scenarios as well.","calibrate structured output predictor natural language processing address problem calibrate prediction confidence output entity interest natural language processing ( nlp ) application . important nlp application name entity recognition question answering produce calibrate confidence score prediction , especially application deploy safetycritical domain healthcare . , output space structure prediction model large adapt binary multi - class calibration method directly . study , propose general calibration scheme output entity interest neural network base structured prediction model . propose method binary class calibration scheme neural network model . additionally , calibration method uncertainty - aware , entity - specific decoding step improve performance underlie model additional training cost data requirement . method outperform current calibration technique name - entity - recognition , - ofspeech question answering . improve model performance decoding step task benchmark dataset . method improve calibration model performance - ofdomain test scenario .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 10, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Exploiting Syntactic Structure for Better Language Modeling: A Syntactic Distance Approach,"It is commonly believed that knowledge of syntactic structure should improve language modeling. However, effectively and computationally efficiently incorporating syntactic structure into neural language models has been a challenging topic. In this paper, we make use of a multi-task objective, i.e., the models simultaneously predict words as well as ground truth parse trees in a form called ""syntactic distances"", where information between these two separate objectives shares the same intermediate representation. Experimental results on the Penn Treebank and Chinese Treebank datasets show that when ground truth parse trees are provided as additional training signals, the model is able to achieve lower perplexity and induce trees with better quality.","Exploiting Syntactic Structure for Better Language Modeling: A Syntactic Distance Approach It is commonly believed that knowledge of syntactic structure should improve language modeling. However, effectively and computationally efficiently incorporating syntactic structure into neural language models has been a challenging topic. In this paper, we make use of a multi-task objective, i.e., the models simultaneously predict words as well as ground truth parse trees in a form called ""syntactic distances"", where information between these two separate objectives shares the same intermediate representation. Experimental results on the Penn Treebank and Chinese Treebank datasets show that when ground truth parse trees are provided as additional training signals, the model is able to achieve lower perplexity and induce trees with better quality.","exploit syntactic structure well language modeling : syntactic distance approach commonly believe knowledge syntactic structure improve language modeling . , effectively computationally efficiently incorporate syntactic structure neural language model challenge topic . paper , use multi - task objective , i.e. , model simultaneously predict word ground truth parse tree form call "" syntactic distance "" , information separate objective share intermediate representation . experimental result penn treebank chinese treebank dataset ground truth parse tree provide additional training signal , model able achieve low perplexity induce tree well quality .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",False
Machine Learning for NLP,A Relational Memory-based Embedding Model for Triple Classification and Search Personalization,"Knowledge graph embedding methods often suffer from a limitation of memorizing valid triples to predict new ones for triple classification and search personalization problems. To this end, we introduce a novel embedding model, named R-MeN, that explores a relational memory network to encode potential dependencies in relationship triples. R-MeN considers each triple as a sequence of 3 input vectors that recurrently interact with a memory using a transformer self-attention mechanism. Thus R-MeN encodes new information from interactions between the memory and each input vector to return a corresponding vector. Consequently, R-MeN feeds these 3 returned vectors to a convolutional neural network-based decoder to produce a scalar score for the triple. Experimental results show that our proposed R-MeN obtains state-of-theart results on SEARCH17 for the search personalization task, and on WN11 and FB13 for the triple classification task.","A Relational Memory-based Embedding Model for Triple Classification and Search Personalization Knowledge graph embedding methods often suffer from a limitation of memorizing valid triples to predict new ones for triple classification and search personalization problems. To this end, we introduce a novel embedding model, named R-MeN, that explores a relational memory network to encode potential dependencies in relationship triples. R-MeN considers each triple as a sequence of 3 input vectors that recurrently interact with a memory using a transformer self-attention mechanism. Thus R-MeN encodes new information from interactions between the memory and each input vector to return a corresponding vector. Consequently, R-MeN feeds these 3 returned vectors to a convolutional neural network-based decoder to produce a scalar score for the triple. Experimental results show that our proposed R-MeN obtains state-of-theart results on SEARCH17 for the search personalization task, and on WN11 and FB13 for the triple classification task.","relational memory - base embedding model triple classification search personalization knowledge graph embedding method suffer limitation memorize valid triple predict new one triple classification search personalization problem . end , introduce novel embedding model , name r - men , explore relational memory network encode potential dependency relationship triple . r - men consider triple sequence 3 input vector recurrently interact memory transformer self - attention mechanism . r - men encode new information interaction memory input vector return correspond vector . consequently , r - men feed 3 return vector convolutional neural network - base decoder produce scalar score triple . experimental result propose r - men obtain state - - theart result search17 search personalization task , wn11 fb13 triple classification task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,CamemBERT: a Tasty French Language Model,"Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models-in all languages except English-very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks.","CamemBERT: a Tasty French Language Model Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models-in all languages except English-very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks.","camembert : tasty french language model pretrained language model ubiquitous natural language processing . despite success , available model train english datum concatenation datum multiple language . make practical use model - language english - limited . paper , investigate feasibility train monolingual transformer - base language model language , take french example evaluate language model - - speech tagging , dependency parsing , name entity recognition natural language inference task . use web crawl datum preferable use wikipedia datum . surprisingly , relatively small web crawl dataset ( 4 gb ) lead result good obtain large dataset ( 130+gb ) . well perform model camembert reach improve state art downstream task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Machine Learning for NLP,Estimating the influence of auxiliary tasks for multi-task learning of sequence tagging tasks,"Multi-task learning (MTL) and transfer learning (TL) are techniques to overcome the issue of data scarcity when training state-of-theart neural networks. However, finding beneficial auxiliary datasets for MTL or TL is a time-and resource-consuming trial-and-error approach. We propose new methods to automatically assess the similarity of sequence tagging datasets to identify beneficial auxiliary data for MTL or TL setups. Our methods can compute the similarity between any two sequence tagging datasets, i.e. they do not need to be annotated with the same tagset or multiple labels in parallel. Additionally, our methods take tokens and their labels into account, which is more robust than only using either of them as an information source, as conducted in prior work. We empirically show that our similarity measures correlate with the change in test score of neural networks that use the auxiliary dataset for MTL to increase the main task performance. We provide an efficient, opensource implementation. 1","Estimating the influence of auxiliary tasks for multi-task learning of sequence tagging tasks Multi-task learning (MTL) and transfer learning (TL) are techniques to overcome the issue of data scarcity when training state-of-theart neural networks. However, finding beneficial auxiliary datasets for MTL or TL is a time-and resource-consuming trial-and-error approach. We propose new methods to automatically assess the similarity of sequence tagging datasets to identify beneficial auxiliary data for MTL or TL setups. Our methods can compute the similarity between any two sequence tagging datasets, i.e. they do not need to be annotated with the same tagset or multiple labels in parallel. Additionally, our methods take tokens and their labels into account, which is more robust than only using either of them as an information source, as conducted in prior work. We empirically show that our similarity measures correlate with the change in test score of neural networks that use the auxiliary dataset for MTL to increase the main task performance. We provide an efficient, opensource implementation. 1","estimate influence auxiliary task multi - task learning sequence tagging task multi - task learning ( mtl ) transfer learning ( tl ) technique overcome issue datum scarcity train state - - theart neural network . , find beneficial auxiliary dataset mtl tl time - resource - consume trial - - error approach . propose new method automatically assess similarity sequence tagging dataset identify beneficial auxiliary datum mtl tl setup . method compute similarity sequence tagging dataset , i.e. need annotate tagset multiple label parallel . additionally , method token label account , robust information source , conduct prior work . empirically similarity measure correlate change test score neural network use auxiliary dataset mtl increase main task performance . provide efficient , opensource implementation . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Learning for NLP,Zero-shot Text Classification via Reinforced Self-training,"Zero-shot learning has been a tough problem since no labeled data is available for unseen classes during training, especially for classes with low similarity. In this situation, transferring from seen classes to unseen classes is extremely hard. To tackle this problem, in this paper we propose a self-training based method to efficiently leverage unlabeled data. Traditional self-training methods use fixed heuristics to select instances from unlabeled data, whose performance varies among different datasets. We propose a reinforcement learning framework to learn data selection strategy automatically and provide more reliable selection. Experimental results on both benchmarks and a real-world e-commerce dataset show that our approach significantly outperforms previous methods in zero-shot text classification.","Zero-shot Text Classification via Reinforced Self-training Zero-shot learning has been a tough problem since no labeled data is available for unseen classes during training, especially for classes with low similarity. In this situation, transferring from seen classes to unseen classes is extremely hard. To tackle this problem, in this paper we propose a self-training based method to efficiently leverage unlabeled data. Traditional self-training methods use fixed heuristics to select instances from unlabeled data, whose performance varies among different datasets. We propose a reinforcement learning framework to learn data selection strategy automatically and provide more reliable selection. Experimental results on both benchmarks and a real-world e-commerce dataset show that our approach significantly outperforms previous methods in zero-shot text classification.","zero - shot text classification reinforced self - training zero - shot learning tough problem label data available unseen class training , especially class low similarity . situation , transfer see class unseen class extremely hard . tackle problem , paper propose self - training base method efficiently leverage unlabeled datum . traditional self - train method use fix heuristic select instance unlabeled datum , performance vary different dataset . propose reinforcement learning framework learn datum selection strategy automatically provide reliable selection . experimental result benchmark real - world e - commerce dataset approach significantly outperform previous method zero - shot text classification .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Learning for NLP,To Pretrain or Not to Pretrain: Examining the Benefits of Pretrainng on Resource Rich Tasks,"Pretraining NLP models with variants of Masked Language Model (MLM) objectives has recently led to a significant improvements on many tasks. This paper examines the benefits of pretrained models as a function of the number of training samples used in the downstream task. On several text classification tasks, we show that as the number of training examples grow into the millions, the accuracy gap between finetuning BERT-based model and training vanilla LSTM from scratch narrows to within 1%. Our findings indicate that MLM-based models might reach a diminishing return point as the supervised data size increases significantly.","To Pretrain or Not to Pretrain: Examining the Benefits of Pretrainng on Resource Rich Tasks Pretraining NLP models with variants of Masked Language Model (MLM) objectives has recently led to a significant improvements on many tasks. This paper examines the benefits of pretrained models as a function of the number of training samples used in the downstream task. On several text classification tasks, we show that as the number of training examples grow into the millions, the accuracy gap between finetuning BERT-based model and training vanilla LSTM from scratch narrows to within 1%. Our findings indicate that MLM-based models might reach a diminishing return point as the supervised data size increases significantly.","pretrain pretrain : examine benefit pretrainng resource rich task pretraine nlp model variant masked language model ( mlm ) objective recently lead significant improvement task . paper examine benefit pretraine model function number training sample downstream task . text classification task , number training example grow million , accuracy gap finetune bert - base model train vanilla lstm scratch narrow 1 % . finding indicate mlm - base model reach diminish return point supervise data size increase significantly .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Evaluating and Enhancing the Robustness of Neural Network-based Dependency Parsing Models with Adversarial Examples,"Despite achieving prominent performance on many important tasks, it has been reported that neural networks are vulnerable to adversarial examples. Previously studies along this line mainly focused on semantic tasks such as sentiment analysis, question answering and reading comprehension. In this study, we show that adversarial examples also exist in dependency parsing: we propose two approaches to study where and how parsers make mistakes by searching over perturbations to existing texts at sentence and phrase levels, and design algorithms to construct such examples in both of the black-box and white-box settings. Our experiments with one of state-of-the-art parsers on the English Penn Treebank (PTB) show that up to 77% of input examples admit adversarial perturbations, and we also show that the robustness of parsing models can be improved by crafting high-quality adversaries and including them in the training stage, while suffering little to no performance drop on the clean input data.","Evaluating and Enhancing the Robustness of Neural Network-based Dependency Parsing Models with Adversarial Examples Despite achieving prominent performance on many important tasks, it has been reported that neural networks are vulnerable to adversarial examples. Previously studies along this line mainly focused on semantic tasks such as sentiment analysis, question answering and reading comprehension. In this study, we show that adversarial examples also exist in dependency parsing: we propose two approaches to study where and how parsers make mistakes by searching over perturbations to existing texts at sentence and phrase levels, and design algorithms to construct such examples in both of the black-box and white-box settings. Our experiments with one of state-of-the-art parsers on the English Penn Treebank (PTB) show that up to 77% of input examples admit adversarial perturbations, and we also show that the robustness of parsing models can be improved by crafting high-quality adversaries and including them in the training stage, while suffering little to no performance drop on the clean input data.","evaluate enhance robustness neural network - base dependency parsing model adversarial example despite achieve prominent performance important task , report neural network vulnerable adversarial example . previously study line mainly focus semantic task sentiment analysis , question answering reading comprehension . study , adversarial example exist dependency parsing : propose approach study parser mistake search perturbation exist text sentence phrase level , design algorithm construct example black - box white - box setting . experiment state - - - art parser english penn treebank ( ptb ) 77 % input example admit adversarial perturbation , robustness parse model improve craft high - quality adversary include training stage , suffer little performance drop clean input datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 8, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 9, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
Machine Learning for NLP,SenseBERT: Driving Some Sense into BERT,"The ability to learn from large unlabeled corpora has allowed neural language models to advance the frontier in natural language understanding. However, existing self-supervision techniques operate at the word form level, which serves as a surrogate for the underlying semantic content. This paper proposes a method to employ weak-supervision directly at the word sense level. Our model, named SenseBERT, is pre-trained to predict not only the masked words but also their WordNet supersenses. Accordingly, we attain a lexicalsemantic level language model, without the use of human annotation. SenseBERT achieves significantly improved lexical understanding, as we demonstrate by experimenting on SemEval Word Sense Disambiguation, and by attaining a state of the art result on the 'Word in Context' task.","SenseBERT: Driving Some Sense into BERT The ability to learn from large unlabeled corpora has allowed neural language models to advance the frontier in natural language understanding. However, existing self-supervision techniques operate at the word form level, which serves as a surrogate for the underlying semantic content. This paper proposes a method to employ weak-supervision directly at the word sense level. Our model, named SenseBERT, is pre-trained to predict not only the masked words but also their WordNet supersenses. Accordingly, we attain a lexicalsemantic level language model, without the use of human annotation. SenseBERT achieves significantly improved lexical understanding, as we demonstrate by experimenting on SemEval Word Sense Disambiguation, and by attaining a state of the art result on the 'Word in Context' task.","sensebert : drive sense bert ability learn large unlabeled corpora allow neural language model advance frontier natural language understanding . , exist self - supervision technique operate word form level , serve surrogate underlie semantic content . paper propose method employ weak - supervision directly word sense level . model , name sensebert , pre - train predict mask word wordnet supersense . accordingly , attain lexicalsemantic level language model , use human annotation . sensebert achieve significantly improve lexical understanding , demonstrate experiment semeval word sense disambiguation , attain state art result ' word context ' task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 15, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Learning for NLP,On Importance Sampling-Based Evaluation of Latent Language Models,"Language models that use additional latent structures (e.g., syntax trees, coreference chains, and knowledge graph links) provide several advantages over traditional language models. However, likelihood-based evaluation of these models is often intractable as it requires marginalizing over the latent space. Existing methods avoid this issue by using importance sampling. Although this approach has asymptotic guarantees, analysis is rarely conducted on the effect of decisions such as sample size, granularity of sample aggregation, and the proposal distribution on the reported estimates. In this paper, we measure the effect these factors have on perplexity estimates for three different latent language models. In addition, we elucidate subtle differences in how importance sampling is applied, which can have substantial effects on the final estimates, as well as provide theoretical results that reinforce the validity of importance sampling for evaluating latent language models.","On Importance Sampling-Based Evaluation of Latent Language Models Language models that use additional latent structures (e.g., syntax trees, coreference chains, and knowledge graph links) provide several advantages over traditional language models. However, likelihood-based evaluation of these models is often intractable as it requires marginalizing over the latent space. Existing methods avoid this issue by using importance sampling. Although this approach has asymptotic guarantees, analysis is rarely conducted on the effect of decisions such as sample size, granularity of sample aggregation, and the proposal distribution on the reported estimates. In this paper, we measure the effect these factors have on perplexity estimates for three different latent language models. In addition, we elucidate subtle differences in how importance sampling is applied, which can have substantial effects on the final estimates, as well as provide theoretical results that reinforce the validity of importance sampling for evaluating latent language models.","importance sampling - base evaluation latent language model language model use additional latent structure ( e.g. , syntax tree , coreference chain , knowledge graph link ) provide advantage traditional language model . , likelihood - base evaluation model intractable require marginalize latent space . exist method avoid issue importance sampling . approach asymptotic guarantee , analysis rarely conduct effect decision sample size , granularity sample aggregation , proposal distribution report estimate . paper , measure effect factor perplexity estimate different latent language model . addition , elucidate subtle difference importance sampling apply , substantial effect final estimate , provide theoretical result reinforce validity importance sampling evaluate latent language model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Machine Learning for NLP,True
Machine Learning for NLP,The Right Tool for the Job: Matching Model and Instance Complexities,"As NLP models become larger, executing a trained model requires significant computational resources incurring monetary and environmental costs. To better respect a given inference budget, we propose a modification to contextual representation fine-tuning which, during inference, allows for an early (and fast) ""exit"" from neural network calculations for simple instances, and late (and accurate) exit for hard instances. To achieve this, we add classifiers to different layers of BERT and use their calibrated confidence scores to make early exit decisions. We test our proposed modification on five different datasets in two tasks: three text classification datasets and two natural language inference benchmarks. Our method presents a favorable speed/accuracy tradeoff in almost all cases, producing models which are up to five times faster than the state of the art, while preserving their accuracy. Our method also requires almost no additional training resources (in either time or parameters) compared to the baseline BERT model. Finally, our method alleviates the need for costly retraining of multiple models at different levels of efficiency; we allow users to control the inference speed/accuracy tradeoff using a single trained model, by setting a single variable at inference time. We publicly release our code. 1 * Research completed during an internship at AI2.","The Right Tool for the Job: Matching Model and Instance Complexities As NLP models become larger, executing a trained model requires significant computational resources incurring monetary and environmental costs. To better respect a given inference budget, we propose a modification to contextual representation fine-tuning which, during inference, allows for an early (and fast) ""exit"" from neural network calculations for simple instances, and late (and accurate) exit for hard instances. To achieve this, we add classifiers to different layers of BERT and use their calibrated confidence scores to make early exit decisions. We test our proposed modification on five different datasets in two tasks: three text classification datasets and two natural language inference benchmarks. Our method presents a favorable speed/accuracy tradeoff in almost all cases, producing models which are up to five times faster than the state of the art, while preserving their accuracy. Our method also requires almost no additional training resources (in either time or parameters) compared to the baseline BERT model. Finally, our method alleviates the need for costly retraining of multiple models at different levels of efficiency; we allow users to control the inference speed/accuracy tradeoff using a single trained model, by setting a single variable at inference time. We publicly release our code. 1 * Research completed during an internship at AI2.","right tool job : match model instance complexity nlp model large , execute train model require significant computational resource incur monetary environmental cost . well respect give inference budget , propose modification contextual representation fine - tuning , inference , allow early ( fast ) "" exit "" neural network calculation simple instance , late ( accurate ) exit hard instance . achieve , add classifier different layer bert use calibrate confidence score early exit decision . test propose modification different dataset task : text classification dataset natural language inference benchmark . method present favorable speed / accuracy tradeoff case , produce model time fast state art , preserve accuracy . method require additional training resource ( time parameter ) compare baseline bert model . finally , method alleviate need costly retraining multiple model different level efficiency ; allow user control inference speed / accuracy tradeoff single train model , set single variable inference time . publicly release code . 1 * research complete internship ai2 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Dependency Graph Enhanced Dual-transformer Structure for Aspect-based Sentiment Classification,"Aspect-based sentiment classification is a popular task aimed at identifying the corresponding emotion of a specific aspect. One sentence may contain various sentiments for different aspects. Many sophisticated methods such as attention mechanism and Convolutional Neural Networks (CNN) have been widely employed for handling this challenge. Recently, semantic dependency tree implemented by Graph Convolutional Networks (GCN) is introduced to describe the inner connection between aspects and the associated emotion words. But the improvement is limited due to the noise and instability of dependency trees. To this end, we propose a dependency graph enhanced dual-transformer network (named DGEDT) by jointly considering the flat representations learnt from Transformer and graphbased representations learnt from the corresponding dependency graph in an iterative interaction manner. Specifically, a dualtransformer structure is devised in DGEDT to support mutual reinforcement between the flat representation learning and graph-based representation learning. The idea is to allow the dependency graph to guide the representation learning of the transformer encoder and vice versa. The results on five datasets demonstrate that the proposed DGEDT outperforms all state-of-the-art alternatives with a large margin.","Dependency Graph Enhanced Dual-transformer Structure for Aspect-based Sentiment Classification Aspect-based sentiment classification is a popular task aimed at identifying the corresponding emotion of a specific aspect. One sentence may contain various sentiments for different aspects. Many sophisticated methods such as attention mechanism and Convolutional Neural Networks (CNN) have been widely employed for handling this challenge. Recently, semantic dependency tree implemented by Graph Convolutional Networks (GCN) is introduced to describe the inner connection between aspects and the associated emotion words. But the improvement is limited due to the noise and instability of dependency trees. To this end, we propose a dependency graph enhanced dual-transformer network (named DGEDT) by jointly considering the flat representations learnt from Transformer and graphbased representations learnt from the corresponding dependency graph in an iterative interaction manner. Specifically, a dualtransformer structure is devised in DGEDT to support mutual reinforcement between the flat representation learning and graph-based representation learning. The idea is to allow the dependency graph to guide the representation learning of the transformer encoder and vice versa. The results on five datasets demonstrate that the proposed DGEDT outperforms all state-of-the-art alternatives with a large margin.","dependency graph enhance dual - transformer structure aspect - base sentiment classification aspect - base sentiment classification popular task aim identify correspond emotion specific aspect . sentence contain sentiment different aspect . sophisticated method attention mechanism convolutional neural networks ( cnn ) widely employ handle challenge . recently , semantic dependency tree implement graph convolutional networks ( gcn ) introduce describe inner connection aspect associate emotion word . improvement limit noise instability dependency tree . end , propose dependency graph enhance dual - transformer network ( name dgedt ) jointly consider flat representation learn transformer graphbase representation learn corresponding dependency graph iterative interaction manner . specifically , dualtransformer structure devise dgedt support mutual reinforcement flat representation learning graph - base representation learning . idea allow dependency graph guide representation learning transformer encoder vice versa . result dataset demonstrate propose dgedt outperform state - - - art alternative large margin .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 10, 'Speech and Multimodality': 9, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 8, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Machine Learning for NLP,A Batch Normalized Inference Network Keeps the KL Vanishing Away,"Variational Autoencoder (VAE) is widely used as a generative model to approximate a model's posterior on latent variables by combining the amortized variational inference and deep neural networks. However, when paired with strong autoregressive decoders, VAE often converges to a degenerated local optimum known as ""posterior collapse"". Previous approaches consider the Kullback-Leibler divergence (KL) individual for each datapoint. We propose to let the KL follow a distribution across the whole dataset, and analyze that it is sufficient to prevent posterior collapse by keeping the expectation of the KL's distribution positive. Then we propose Batch Normalized-VAE (BN-VAE), a simple but effective approach to set a lower bound of the expectation by regularizing the distribution of the approximate posterior's parameters. Without introducing any new model component or modifying the objective, our approach can avoid the posterior collapse effectively and efficiently. We further show that the proposed BN-VAE can be extended to conditional VAE (CVAE). Empirically, our approach surpasses strong autoregressive baselines on language modeling, text classification and dialogue generation, and rivals more complex approaches while keeping almost the same training time as VAE.","A Batch Normalized Inference Network Keeps the KL Vanishing Away Variational Autoencoder (VAE) is widely used as a generative model to approximate a model's posterior on latent variables by combining the amortized variational inference and deep neural networks. However, when paired with strong autoregressive decoders, VAE often converges to a degenerated local optimum known as ""posterior collapse"". Previous approaches consider the Kullback-Leibler divergence (KL) individual for each datapoint. We propose to let the KL follow a distribution across the whole dataset, and analyze that it is sufficient to prevent posterior collapse by keeping the expectation of the KL's distribution positive. Then we propose Batch Normalized-VAE (BN-VAE), a simple but effective approach to set a lower bound of the expectation by regularizing the distribution of the approximate posterior's parameters. Without introducing any new model component or modifying the objective, our approach can avoid the posterior collapse effectively and efficiently. We further show that the proposed BN-VAE can be extended to conditional VAE (CVAE). Empirically, our approach surpasses strong autoregressive baselines on language modeling, text classification and dialogue generation, and rivals more complex approaches while keeping almost the same training time as VAE.","batch normalize inference network keep kl vanish away variational autoencoder ( vae ) widely generative model approximate model posterior latent variable combine amortized variational inference deep neural network . , pair strong autoregressive decoder , vae converge degenerate local optimum know "" posterior collapse "" . previous approach consider kullback - leibler divergence ( kl ) individual datapoint . propose let kl follow distribution dataset , analyze sufficient prevent posterior collapse keep expectation kl distribution positive . propose batch normalized - vae ( bn - vae ) , simple effective approach set low bound expectation regularize distribution approximate posterior parameter . introduce new model component modify objective , approach avoid posterior collapse effectively efficiently . propose bn - vae extend conditional vae ( cvae ) . empirically , approach surpass strong autoregressive baseline language modeling , text classification dialogue generation , rival complex approach keep training time vae .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 17, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification,"This paper presents MixText, a semisupervised learning method for text classification, which uses our newly designed data augmentation method called TMix. TMix creates a large amount of augmented training samples by interpolating text in hidden space. Moreover, we leverage recent advances in data augmentation to guess low-entropy labels for unlabeled data, hence making them as easy to use as labeled data. By mixing labeled, unlabeled and augmented data, MixText significantly outperformed current pre-trained and fined-tuned models and other state-ofthe-art semi-supervised learning methods on several text classification benchmarks. The improvement is especially prominent when supervision is extremely limited. We have publicly released our code at https: //github.com/GT-SALT/MixText.","MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification This paper presents MixText, a semisupervised learning method for text classification, which uses our newly designed data augmentation method called TMix. TMix creates a large amount of augmented training samples by interpolating text in hidden space. Moreover, we leverage recent advances in data augmentation to guess low-entropy labels for unlabeled data, hence making them as easy to use as labeled data. By mixing labeled, unlabeled and augmented data, MixText significantly outperformed current pre-trained and fined-tuned models and other state-ofthe-art semi-supervised learning methods on several text classification benchmarks. The improvement is especially prominent when supervision is extremely limited. We have publicly released our code at https: //github.com/GT-SALT/MixText.","mixtext : linguistically - inform interpolation hide space semi - supervised text classification paper present mixtext , semisupervised learning method text classification , use newly design data augmentation method call tmix . tmix create large augment training sample interpolate text hide space . , leverage recent advance datum augmentation guess low - entropy label unlabeled datum , make easy use label datum . mix label , unlabeled augment datum , mixtext significantly outperform current pre - trained fine - tune model state - ofthe - art semi - supervised learning method text classification benchmark . improvement especially prominent supervision extremely limited . publicly release code https : //github.com / gt - salt / mixtext .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Pretrained Transformers Improve Out-of-Distribution Robustness,"Although pretrained Transformers such as BERT achieve high accuracy on indistribution examples, do they generalize to new distributions? We systematically measure out-of-distribution (OOD) generalization for seven NLP datasets by constructing a new robustness benchmark with realistic distribution shifts. We measure the generalization of previous models including bag-of-words models, ConvNets, and LSTMs, and we show that pretrained Transformers' performance declines are substantially smaller. Pretrained transformers are also more effective at detecting anomalous or OOD examples, while many previous models are frequently worse than chance. We examine which factors affect robustness, finding that larger models are not necessarily more robust, distillation can be harmful, and more diverse pretraining data can enhance robustness. Finally, we show where future work can improve OOD robustness.","Pretrained Transformers Improve Out-of-Distribution Robustness Although pretrained Transformers such as BERT achieve high accuracy on indistribution examples, do they generalize to new distributions? We systematically measure out-of-distribution (OOD) generalization for seven NLP datasets by constructing a new robustness benchmark with realistic distribution shifts. We measure the generalization of previous models including bag-of-words models, ConvNets, and LSTMs, and we show that pretrained Transformers' performance declines are substantially smaller. Pretrained transformers are also more effective at detecting anomalous or OOD examples, while many previous models are frequently worse than chance. We examine which factors affect robustness, finding that larger models are not necessarily more robust, distillation can be harmful, and more diverse pretraining data can enhance robustness. Finally, we show where future work can improve OOD robustness.","pretrained transformer improve - - distribution robustness pretrained transformers bert achieve high accuracy indistribution example , generalize new distribution ? systematically measure - - distribution ( ood ) generalization seven nlp dataset construct new robustness benchmark realistic distribution shift . measure generalization previous model include bag - - word model , convnets , lstms , pretrained transformers ' performance decline substantially small . pretrained transformer effective detect anomalous ood example , previous model frequently bad chance . examine factor affect robustness , find large model necessarily robust , distillation harmful , diverse pretraine datum enhance robustness . finally , future work improve ood robustness .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,On the Encoder-Decoder Incompatibility in Variational Text Modeling and Beyond,"Variational autoencoders (VAEs) combine latent variables with amortized variational inference, whose optimization usually converges into a trivial local optimum termed posterior collapse, especially in text modeling. By tracking the optimization dynamics, we observe the encoder-decoder incompatibility that leads to poor parameterizations of the data manifold. We argue that the trivial local optimum may be avoided by improving the encoder and decoder parameterizations since the posterior network is part of a transition map between them. To this end, we propose Coupled-VAE, which couples a VAE model with a deterministic autoencoder with the same structure and improves the encoder and decoder parameterizations via encoder weight sharing and decoder signal matching. We apply the proposed Coupled-VAE approach to various VAE models with different regularization, posterior family, decoder structure, and optimization strategy. Experiments on benchmark datasets (i.e., PTB, Yelp, and Yahoo) show consistently improved results in terms of probability estimation and richness of the latent space. We also generalize our method to conditional language modeling and propose Coupled-CVAE, which largely improves the diversity of dialogue generation on the Switchboard dataset. 1","On the Encoder-Decoder Incompatibility in Variational Text Modeling and Beyond Variational autoencoders (VAEs) combine latent variables with amortized variational inference, whose optimization usually converges into a trivial local optimum termed posterior collapse, especially in text modeling. By tracking the optimization dynamics, we observe the encoder-decoder incompatibility that leads to poor parameterizations of the data manifold. We argue that the trivial local optimum may be avoided by improving the encoder and decoder parameterizations since the posterior network is part of a transition map between them. To this end, we propose Coupled-VAE, which couples a VAE model with a deterministic autoencoder with the same structure and improves the encoder and decoder parameterizations via encoder weight sharing and decoder signal matching. We apply the proposed Coupled-VAE approach to various VAE models with different regularization, posterior family, decoder structure, and optimization strategy. Experiments on benchmark datasets (i.e., PTB, Yelp, and Yahoo) show consistently improved results in terms of probability estimation and richness of the latent space. We also generalize our method to conditional language modeling and propose Coupled-CVAE, which largely improves the diversity of dialogue generation on the Switchboard dataset. 1","encoder - decoder incompatibility variational text modeling variational autoencoder ( vaes ) combine latent variable amortized variational inference , optimization usually converge trivial local optimum term posterior collapse , especially text modeling . track optimization dynamic , observe encoder - decoder incompatibility lead poor parameterization datum manifold . argue trivial local optimum avoid improve encoder decoder parameterization posterior network transition map . end , propose coupled - vae , couple vae model deterministic autoencoder structure improve encoder decoder parameterization encoder weight sharing decoder signal matching . apply propose coupled - vae approach vae model different regularization , posterior family , decoder structure , optimization strategy . experiment benchmark dataset ( i.e. , ptb , yelp , yahoo ) consistently improved result term probability estimation richness latent space . generalize method conditional language modeling propose coupled - cvae , largely improve diversity dialogue generation switchboard dataset . 1","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 13, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Machine Learning for NLP,ExpBERT: Representation Engineering with Natural Language Explanations,"Suppose we want to specify the inductive bias that married couples typically go on honeymoons for the task of extracting pairs of spouses from text. In this paper, we allow model developers to specify these types of inductive biases as natural language explanations. We use BERT fine-tuned on MultiNLI to ""interpret"" these explanations with respect to the input sentence, producing explanationguided representations of the input. Across three relation extraction tasks, our method, ExpBERT, matches a BERT baseline but with 3-20Ã— less labeled data and improves on the baseline by 3-10 F1 points with the same amount of labeled data.","ExpBERT: Representation Engineering with Natural Language Explanations Suppose we want to specify the inductive bias that married couples typically go on honeymoons for the task of extracting pairs of spouses from text. In this paper, we allow model developers to specify these types of inductive biases as natural language explanations. We use BERT fine-tuned on MultiNLI to ""interpret"" these explanations with respect to the input sentence, producing explanationguided representations of the input. Across three relation extraction tasks, our method, ExpBERT, matches a BERT baseline but with 3-20Ã— less labeled data and improves on the baseline by 3-10 F1 points with the same amount of labeled data.","expbert : representation engineering natural language explanation suppose want specify inductive bias married couple typically honeymoon task extract pair spouse text . paper , allow model developer specify type inductive bias natural language explanation . use bert fine - tune multinli "" interpret "" explanation respect input sentence , produce explanationguided representation input . relation extraction task , method , expbert , match bert baseline 3 - 20Ã— label datum improve baseline 3 - 10 f1 point label datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Knowledge Graph Embedding Compression,"Knowledge graph (KG) representation learning techniques that learn continuous embeddings of entities and relations in the KG have become popular in many AI applications. With a large KG, the embeddings consume a large amount of storage and memory. This is problematic and prohibits the deployment of these techniques in many real world settings. Thus, we propose an approach that compresses the KG embedding layer by representing each entity in the KG as a vector of discrete codes and then composes the embeddings from these codes. The approach can be trained end-toend with simple modifications to any existing KG embedding technique. We evaluate the approach on various standard KG embedding evaluations and show that it achieves 50-1000x compression of embeddings with a minor loss in performance. The compressed embeddings also retain the ability to perform various reasoning tasks such as KG inference.","Knowledge Graph Embedding Compression Knowledge graph (KG) representation learning techniques that learn continuous embeddings of entities and relations in the KG have become popular in many AI applications. With a large KG, the embeddings consume a large amount of storage and memory. This is problematic and prohibits the deployment of these techniques in many real world settings. Thus, we propose an approach that compresses the KG embedding layer by representing each entity in the KG as a vector of discrete codes and then composes the embeddings from these codes. The approach can be trained end-toend with simple modifications to any existing KG embedding technique. We evaluate the approach on various standard KG embedding evaluations and show that it achieves 50-1000x compression of embeddings with a minor loss in performance. The compressed embeddings also retain the ability to perform various reasoning tasks such as KG inference.","knowledge graph embedding compression knowledge graph ( kg ) representation learning technique learn continuous embedding entity relation kg popular ai application . large kg , embedding consume large storage memory . problematic prohibit deployment technique real world setting . , propose approach compress kg embedding layer represent entity kg vector discrete code compose embedding code . approach train end - toend simple modification exist kg embedding technique . evaluate approach standard kg embedding evaluation achieve 50 - 1000x compression embedding minor loss performance . compressed embedding retain ability perform reasoning task kg inference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 15, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Do you have the right scissors? Tailoring Pre-trained Language Models via Monte-Carlo Methods,"It has been a common approach to pre-train a language model on a large corpus and finetune it on task-specific data. In practice, we observe that fine-tuning a pre-trained model on a small dataset may lead to over-and/or under-estimation problem. In this paper, we propose MC-Tailor, a novel method to alleviate the above issue in text generation tasks by truncating and transferring the probability mass from over-estimated regions to underestimated ones. Experiments on a variety of text generation datasets show that MC-Tailor consistently and significantly outperforms the fine-tuning approach. Our code is available at https://github.com/NingMiao/ MC-tailor.","Do you have the right scissors? Tailoring Pre-trained Language Models via Monte-Carlo Methods It has been a common approach to pre-train a language model on a large corpus and finetune it on task-specific data. In practice, we observe that fine-tuning a pre-trained model on a small dataset may lead to over-and/or under-estimation problem. In this paper, we propose MC-Tailor, a novel method to alleviate the above issue in text generation tasks by truncating and transferring the probability mass from over-estimated regions to underestimated ones. Experiments on a variety of text generation datasets show that MC-Tailor consistently and significantly outperforms the fine-tuning approach. Our code is available at https://github.com/NingMiao/ MC-tailor.","right scissor ? tailor pre - trained language model monte - carlo method common approach pre - train language model large corpus finetune task - specific datum . practice , observe fine - tune pre - train model small dataset lead - and/or - estimation problem . paper , propose mc - tailor , novel method alleviate issue text generation task truncate transfer probability mass - estimate region underestimate one . experiment variety text generation dataset mc - tailor consistently significantly outperform fine - tuning approach . code available https://github.com/ningmiao/ mc - tailor .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Machine Learning for NLP,Discrete Latent Variable Representations for Low-Resource Text Classification,"While much work on deep latent variable models of text uses continuous latent variables, discrete latent variables are interesting because they are more interpretable and typically more space efficient. We consider several approaches to learning discrete latent variable models for text in the case where exact marginalization over these variables is intractable. We compare the performance of the learned representations as features for lowresource document and sentence classification. Our best models outperform the previous best reported results with continuous representations in these low-resource settings, while learning significantly more compressed representations. Interestingly, we find that an amortized variant of Hard EM performs particularly well in the lowest-resource regimes. 1 * Work done as an intern at Toyota Technological Institute at Chicago.","Discrete Latent Variable Representations for Low-Resource Text Classification While much work on deep latent variable models of text uses continuous latent variables, discrete latent variables are interesting because they are more interpretable and typically more space efficient. We consider several approaches to learning discrete latent variable models for text in the case where exact marginalization over these variables is intractable. We compare the performance of the learned representations as features for lowresource document and sentence classification. Our best models outperform the previous best reported results with continuous representations in these low-resource settings, while learning significantly more compressed representations. Interestingly, we find that an amortized variant of Hard EM performs particularly well in the lowest-resource regimes. 1 * Work done as an intern at Toyota Technological Institute at Chicago.","discrete latent variable representation low - resource text classification work deep latent variable model text use continuous latent variable , discrete latent variable interesting interpretable typically space efficient . consider approach learn discrete latent variable model text case exact marginalization variable intractable . compare performance learn representation feature lowresource document sentence classification . good model outperform previous good report result continuous representation low - resource setting , learn significantly compressed representation . interestingly , find amortize variant hard em perform particularly low - resource regime . 1 * work intern toyota technological institute chicago .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 15, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Weight Poisoning Attacks on Pretrained Models,"Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then fine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct ""weight poisoning"" attacks where pre-trained weights are injected with vulnerabilities that expose ""backdoors"" after fine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method, which we call RIPPLe, and an initialization procedure, which we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and finetuning procedure. Our experiments on sentiment classification, toxicity detection, and spam detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks. Code to reproduce our experiments is available at https://github.com/ neulab/RIPPLe.","Weight Poisoning Attacks on Pretrained Models Recently, NLP has seen a surge in the usage of large pre-trained models. Users download weights of models pre-trained on large datasets, then fine-tune the weights on a task of their choice. This raises the question of whether downloading untrusted pre-trained weights can pose a security threat. In this paper, we show that it is possible to construct ""weight poisoning"" attacks where pre-trained weights are injected with vulnerabilities that expose ""backdoors"" after fine-tuning, enabling the attacker to manipulate the model prediction simply by injecting an arbitrary keyword. We show that by applying a regularization method, which we call RIPPLe, and an initialization procedure, which we call Embedding Surgery, such attacks are possible even with limited knowledge of the dataset and finetuning procedure. Our experiments on sentiment classification, toxicity detection, and spam detection show that this attack is widely applicable and poses a serious threat. Finally, we outline practical defenses against such attacks. Code to reproduce our experiments is available at https://github.com/ neulab/RIPPLe.","weight poisoning attack pretrained model recently , nlp see surge usage large pre - train model . user download weight model pre - train large dataset , fine - tune weight task choice . raise question download untrusted pre - train weight pose security threat . paper , possible construct "" weight poisoning "" attack pre - trained weight inject vulnerability expose "" backdoor "" fine - tuning , enable attacker manipulate model prediction simply inject arbitrary keyword . apply regularization method , ripple , initialization procedure , embedding surgery , attack possible limited knowledge dataset finetuning procedure . experiment sentiment classification , toxicity detection , spam detection attack widely applicable pose threat . finally , outline practical defense attack . code reproduce experiment available https://github.com/ neulab / ripple .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,True
Machine Learning for NLP,Improving Transformer Models by Reordering their Sublayers,"Multilayer transformer networks consist of interleaved self-attention and feedforward sublayers. Could ordering the sublayers in a different pattern lead to better performance? We generate randomly ordered transformers and train them with the language modeling objective. We observe that some of these models are able to achieve better performance than the interleaved baseline, and that those successful variants tend to have more self-attention at the bottom and more feedforward sublayers at the top. We propose a new transformer pattern that adheres to this property, the sandwich transformer, and show that it improves perplexity on multiple word-level and character-level language modeling benchmarks, at no cost in parameters, memory, or training time. However, the sandwich reordering pattern does not guarantee performance gains across every task, as we demonstrate on machine translation models. Instead, we suggest that further exploration of task-specific sublayer reorderings is needed in order to unlock additional gains. 1","Improving Transformer Models by Reordering their Sublayers Multilayer transformer networks consist of interleaved self-attention and feedforward sublayers. Could ordering the sublayers in a different pattern lead to better performance? We generate randomly ordered transformers and train them with the language modeling objective. We observe that some of these models are able to achieve better performance than the interleaved baseline, and that those successful variants tend to have more self-attention at the bottom and more feedforward sublayers at the top. We propose a new transformer pattern that adheres to this property, the sandwich transformer, and show that it improves perplexity on multiple word-level and character-level language modeling benchmarks, at no cost in parameters, memory, or training time. However, the sandwich reordering pattern does not guarantee performance gains across every task, as we demonstrate on machine translation models. Instead, we suggest that further exploration of task-specific sublayer reorderings is needed in order to unlock additional gains. 1","improve transformer model reorder sublayer multilayer transformer network consist interleaved self - attention feedforward sublayer . order sublayer different pattern lead well performance ? generate randomly order transformer train language modeling objective . observe model able achieve well performance interleaved baseline , successful variant tend self - attention feedforward sublayer . propose new transformer pattern adhere property , sandwich transformer , improve perplexity multiple word - level character - level language modeling benchmark , cost parameter , memory , training time . , sandwich reordering pattern guarantee performance gain task , demonstrate machine translation model . instead , suggest exploration task - specific sublayer reordering need order unlock additional gain . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation,"This paper introduces Dynamic Programming Encoding (DPE), a new segmentation algorithm for tokenizing sentences into subword units. We view the subword segmentation of output sentences as a latent variable that should be marginalized out for learning and inference. A mixed character-subword transformer is proposed, which enables exact log marginal likelihood estimation and exact MAP inference to find target segmentations with maximum posterior probability. DPE uses a lightweight mixed character-subword transformer as a means of pre-processing parallel data to segment output sentences using dynamic programming. Empirical results on machine translation suggest that DPE is effective for segmenting output sentences and can be combined with BPE dropout for stochastic segmentation of source sentences. DPE achieves an average improvement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average improvement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several WMT datasets including English â†” (German, Romanian, Estonian, Finnish, Hungarian).","Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation This paper introduces Dynamic Programming Encoding (DPE), a new segmentation algorithm for tokenizing sentences into subword units. We view the subword segmentation of output sentences as a latent variable that should be marginalized out for learning and inference. A mixed character-subword transformer is proposed, which enables exact log marginal likelihood estimation and exact MAP inference to find target segmentations with maximum posterior probability. DPE uses a lightweight mixed character-subword transformer as a means of pre-processing parallel data to segment output sentences using dynamic programming. Empirical results on machine translation suggest that DPE is effective for segmenting output sentences and can be combined with BPE dropout for stochastic segmentation of source sentences. DPE achieves an average improvement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average improvement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several WMT datasets including English â†” (German, Romanian, Estonian, Finnish, Hungarian).","dynamic programming encoding subword segmentation neural machine translation paper introduce dynamic programming encoding ( dpe ) , new segmentation algorithm tokenize sentence subword unit . view subword segmentation output sentence latent variable marginalize learning inference . mix character - subword transformer propose , enable exact log marginal likelihood estimation exact map inference find target segmentation maximum posterior probability . dpe use lightweight mix character - subword transformer means pre - process parallel datum segment output sentence dynamic programming . empirical result machine translation suggest dpe effective segment output sentence combine bpe dropout stochastic segmentation source sentence . dpe achieve average improvement 0.9 bleu bpe ( sennrich et al . , 2016 ) average improvement 0.55 bleu bpe dropout ( provilkov et al . , 2019 ) wmt dataset include english â†” ( german , romanian , estonian , finnish , hungarian ) .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Lexically Constrained Neural Machine Translation with Levenshtein Transformer,"This paper proposes a simple and effective algorithm for incorporating lexical constraints in neural machine translation. Previous work either required re-training existing models with the lexical constraints or incorporating them during beam search decoding with significantly higher computational overheads. Leveraging the flexibility and speed of a recently proposed Levenshtein Transformer model (Gu et al., 2019) , our method injects terminology constraints at inference time without any impact on decoding speed. Our method does not require any modification to the training procedure and can be easily applied at runtime with custom dictionaries. Experiments on English-German WMT datasets show that our approach improves an unconstrained baseline and previous approaches.","Lexically Constrained Neural Machine Translation with Levenshtein Transformer This paper proposes a simple and effective algorithm for incorporating lexical constraints in neural machine translation. Previous work either required re-training existing models with the lexical constraints or incorporating them during beam search decoding with significantly higher computational overheads. Leveraging the flexibility and speed of a recently proposed Levenshtein Transformer model (Gu et al., 2019) , our method injects terminology constraints at inference time without any impact on decoding speed. Our method does not require any modification to the training procedure and can be easily applied at runtime with custom dictionaries. Experiments on English-German WMT datasets show that our approach improves an unconstrained baseline and previous approaches.","lexically constrain neural machine translation levenshtein transformer paper propose simple effective algorithm incorporate lexical constraint neural machine translation . previous work require - train exist model lexical constraint incorporate beam search decoding significantly high computational overhead . leverage flexibility speed recently propose levenshtein transformer model ( gu et al . , 2019 ) , method inject terminology constraint inference time impact decoding speed . method require modification training procedure easily apply runtime custom dictionary . experiment english - german wmt dataset approach improve unconstrained baseline previous approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Graph-based Coarse-to-fine Method for Unsupervised Bilingual Lexicon Induction,"Unsupervised bilingual lexicon induction is the task of inducing word translations from monolingual corpora of two languages. Recent methods are mostly based on unsupervised cross-lingual word embeddings, the key to which is to find initial solutions of word translations, followed by the learning and refinement of mappings between the embedding spaces of two languages. However, previous methods find initial solutions just based on word-level information, which may be (1) limited and inaccurate, and (2) prone to contain some noise introduced by the insufficiently pre-trained embeddings of some words. To deal with those issues, in this paper, we propose a novel graph-based paradigm to induce bilingual lexicons in a coarse-to-fine way. We first build a graph for each language with its vertices representing different words. Then we extract word cliques from the graphs and map the cliques of two languages. Based on that, we induce the initial word translation solution with the central words of the aligned cliques. This coarse-to-fine approach not only leverages clique-level information, which is richer and more accurate, but also effectively reduces the bad effect of the noise in the pre-trained embeddings. Finally, we take the initial solution as the seed to learn cross-lingual embeddings, from which we induce bilingual lexicons. Experiments show that our approach improves the performance of bilingual lexicon induction compared with previous methods.","A Graph-based Coarse-to-fine Method for Unsupervised Bilingual Lexicon Induction Unsupervised bilingual lexicon induction is the task of inducing word translations from monolingual corpora of two languages. Recent methods are mostly based on unsupervised cross-lingual word embeddings, the key to which is to find initial solutions of word translations, followed by the learning and refinement of mappings between the embedding spaces of two languages. However, previous methods find initial solutions just based on word-level information, which may be (1) limited and inaccurate, and (2) prone to contain some noise introduced by the insufficiently pre-trained embeddings of some words. To deal with those issues, in this paper, we propose a novel graph-based paradigm to induce bilingual lexicons in a coarse-to-fine way. We first build a graph for each language with its vertices representing different words. Then we extract word cliques from the graphs and map the cliques of two languages. Based on that, we induce the initial word translation solution with the central words of the aligned cliques. This coarse-to-fine approach not only leverages clique-level information, which is richer and more accurate, but also effectively reduces the bad effect of the noise in the pre-trained embeddings. Finally, we take the initial solution as the seed to learn cross-lingual embeddings, from which we induce bilingual lexicons. Experiments show that our approach improves the performance of bilingual lexicon induction compared with previous methods.","graph - base coarse - - fine method unsupervised bilingual lexicon induction unsupervised bilingual lexicon induction task induce word translation monolingual corpus language . recent method base unsupervised cross - lingual word embedding , key find initial solution word translation , follow learning refinement mapping embedding space language . , previous method find initial solution base word - level information , ( 1 ) limited inaccurate , ( 2 ) prone contain noise introduce insufficiently pre - train embedding word . deal issue , paper , propose novel graph - base paradigm induce bilingual lexicon coarse - - fine way . build graph language vertex represent different word . extract word clique graph map clique language . base , induce initial word translation solution central word align clique . coarse - - fine approach leverage clique - level information , rich accurate , effectively reduce bad effect noise pre - trained embedding . finally , initial solution seed learn cross - lingual embedding , induce bilingual lexicon . experiment approach improve performance bilingual lexicon induction compare previous method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 10, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Unsupervised Domain Clusters in Pretrained Language Models,"The notion of ""in-domain data"" in NLP is often over-simplistic and vague, as textual data varies in many nuanced linguistic aspects such as topic, style or level of formality. In addition, domain labels are many times unavailable, making it challenging to build domainspecific systems. We show that massive pretrained language models implicitly learn sentence representations that cluster by domains without supervision -suggesting a simple datadriven definition of domains in textual data. We harness this property and propose domain data selection methods based on such models, which require only a small set of in-domain monolingual data. We evaluate our data selection methods for neural machine translation across five diverse domains, where they outperform an established approach as measured by both BLEU and by precision and recall of sentence selection with respect to an oracle.","Unsupervised Domain Clusters in Pretrained Language Models The notion of ""in-domain data"" in NLP is often over-simplistic and vague, as textual data varies in many nuanced linguistic aspects such as topic, style or level of formality. In addition, domain labels are many times unavailable, making it challenging to build domainspecific systems. We show that massive pretrained language models implicitly learn sentence representations that cluster by domains without supervision -suggesting a simple datadriven definition of domains in textual data. We harness this property and propose domain data selection methods based on such models, which require only a small set of in-domain monolingual data. We evaluate our data selection methods for neural machine translation across five diverse domains, where they outperform an established approach as measured by both BLEU and by precision and recall of sentence selection with respect to an oracle.","unsupervised domain cluster pretrained language model notion "" - domain datum "" nlp - simplistic vague , textual data vary nuanced linguistic aspect topic , style level formality . addition , domain label time unavailable , make challenging build domainspecific system . massive pretrained language model implicitly learn sentence representation cluster domain supervision -suggeste simple datadriven definition domain textual datum . harness property propose domain datum selection method base model , require small set - domain monolingual datum . evaluate data selection method neural machine translation diverse domain , outperform establish approach measure bleu precision recall sentence selection respect oracle .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Norm-Based Curriculum Learning for Neural Machine Translation,"A neural machine translation (NMT) system is expensive to train, especially with highresource settings. As the NMT architectures become deeper and wider, this issue gets worse and worse. In this paper, we aim to improve the efficiency of training an NMT by introducing a novel norm-based curriculum learning method. We use the norm (aka length or module) of a word embedding as a measure of 1) the difficulty of the sentence, 2) the competence of the model, and 3) the weight of the sentence. The normbased sentence difficulty takes the advantages of both linguistically motivated and modelbased sentence difficulties. It is easy to determine and contains learning-dependent features. The norm-based model competence makes NMT learn the curriculum in a fully automated way, while the norm-based sentence weight further enhances the learning of the vector representation of the NMT. Experimental results for the WMT'14 English-German and WMT'17 Chinese-English translation tasks demonstrate that the proposed method outperforms strong baselines in terms of BLEU score (+1.17/+1.56) and training speedup (2.22x/3.33x).","Norm-Based Curriculum Learning for Neural Machine Translation A neural machine translation (NMT) system is expensive to train, especially with highresource settings. As the NMT architectures become deeper and wider, this issue gets worse and worse. In this paper, we aim to improve the efficiency of training an NMT by introducing a novel norm-based curriculum learning method. We use the norm (aka length or module) of a word embedding as a measure of 1) the difficulty of the sentence, 2) the competence of the model, and 3) the weight of the sentence. The normbased sentence difficulty takes the advantages of both linguistically motivated and modelbased sentence difficulties. It is easy to determine and contains learning-dependent features. The norm-based model competence makes NMT learn the curriculum in a fully automated way, while the norm-based sentence weight further enhances the learning of the vector representation of the NMT. Experimental results for the WMT'14 English-German and WMT'17 Chinese-English translation tasks demonstrate that the proposed method outperforms strong baselines in terms of BLEU score (+1.17/+1.56) and training speedup (2.22x/3.33x).","norm - base curriculum learning neural machine translation neural machine translation ( nmt ) system expensive train , especially highresource setting . nmt architecture deep wide , issue get bad bad . paper , aim improve efficiency train nmt introduce novel norm - base curriculum learning method . use norm ( aka length module ) word embedding measure 1 ) difficulty sentence , 2 ) competence model , 3 ) weight sentence . normbased sentence difficulty take advantage linguistically motivated modelbase sentence difficulty . easy determine contain learning - dependent feature . norm - base model competence make nmt learn curriculum fully automate way , norm - base sentence weight enhance learning vector representation nmt . experimental result wmt'14 english - german wmt'17 chinese - english translation task demonstrate propose method outperform strong baseline term bleu score ( +1.17/+1.56 ) training speedup ( 2.22x/3.33x ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 15, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Learning a Multi-Domain Curriculum for Neural Machine Translation,"Most data selection research in machine translation focuses on improving a single domain. We perform data selection for multiple domains at once. This is achieved by carefully introducing instance-level domain-relevance features and automatically constructing a training curriculum to gradually concentrate on multi-domain relevant and noise-reduced data batches. Both the choice of features and the use of curriculum are crucial for balancing and improving all domains, including out-ofdomain. In large-scale experiments, the multidomain curriculum simultaneously reaches or outperforms the individual performance and brings solid gains over no-curriculum training.","Learning a Multi-Domain Curriculum for Neural Machine Translation Most data selection research in machine translation focuses on improving a single domain. We perform data selection for multiple domains at once. This is achieved by carefully introducing instance-level domain-relevance features and automatically constructing a training curriculum to gradually concentrate on multi-domain relevant and noise-reduced data batches. Both the choice of features and the use of curriculum are crucial for balancing and improving all domains, including out-ofdomain. In large-scale experiments, the multidomain curriculum simultaneously reaches or outperforms the individual performance and brings solid gains over no-curriculum training.","learn multi - domain curriculum neural machine translation datum selection research machine translation focus improve single domain . perform data selection multiple domain . achieve carefully introduce instance - level domain - relevance feature automatically construct training curriculum gradually concentrate multi - domain relevant noise - reduce data batch . choice feature use curriculum crucial balance improve domain , include - ofdomain . large - scale experiment , multidomain curriculum simultaneously reach outperform individual performance bring solid gain - curriculum training .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,"On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation","The standard training algorithm in neural machine translation (NMT) suffers from exposure bias, and alternative algorithms have been proposed to mitigate this. However, the practical impact of exposure bias is under debate. In this paper, we link exposure bias to another well-known problem in NMT, namely the tendency to generate hallucinations under domain shift. In experiments on three datasets with multiple test domains, we show that exposure bias is partially to blame for hallucinations, and that training with Minimum Risk Training, which avoids exposure bias, can mitigate this. Our analysis explains why exposure bias is more problematic under domain shift, and also links exposure bias to the beam search problem, i.e. performance deterioration with increasing beam size. Our results provide a new justification for methods that reduce exposure bias: even if they do not increase performance on in-domain test sets, they can increase model robustness to domain shift.","On Exposure Bias, Hallucination and Domain Shift in Neural Machine Translation The standard training algorithm in neural machine translation (NMT) suffers from exposure bias, and alternative algorithms have been proposed to mitigate this. However, the practical impact of exposure bias is under debate. In this paper, we link exposure bias to another well-known problem in NMT, namely the tendency to generate hallucinations under domain shift. In experiments on three datasets with multiple test domains, we show that exposure bias is partially to blame for hallucinations, and that training with Minimum Risk Training, which avoids exposure bias, can mitigate this. Our analysis explains why exposure bias is more problematic under domain shift, and also links exposure bias to the beam search problem, i.e. performance deterioration with increasing beam size. Our results provide a new justification for methods that reduce exposure bias: even if they do not increase performance on in-domain test sets, they can increase model robustness to domain shift.","exposure bias , hallucination domain shift neural machine translation standard training algorithm neural machine translation ( nmt ) suffer exposure bias , alternative algorithm propose mitigate . , practical impact exposure bias debate . paper , link exposure bias - know problem nmt , tendency generate hallucination domain shift . experiment dataset multiple test domain , exposure bias partially blame hallucination , training minimum risk training , avoid exposure bias , mitigate . analysis explain exposure bias problematic domain shift , link exposure bias beam search problem , i.e. performance deterioration increase beam size . result provide new justification method reduce exposure bias : increase performance - domain test set , increase model robustness domain shift .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 9, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation,"In encoder-decoder neural models, multiple encoders are in general used to represent the contextual information in addition to the individual sentence. In this paper, we investigate multi-encoder approaches in document-level neural machine translation (NMT). Surprisingly, we find that the context encoder does not only encode the surrounding sentences but also behaves as a noise generator. This makes us rethink the real benefits of multi-encoder in context-aware translation -some of the improvements come from robust training. We compare several methods that introduce noise and/or well-tuned dropout setup into the training of these encoders. Experimental results show that noisy training plays an important role in multi-encoder-based NMT, especially when the training data is small. Also, we establish a new state-of-the-art on IWSLT Fr-En task by careful use of noise generation and dropout methods.","Does Multi-Encoder Help? A Case Study on Context-Aware Neural Machine Translation In encoder-decoder neural models, multiple encoders are in general used to represent the contextual information in addition to the individual sentence. In this paper, we investigate multi-encoder approaches in document-level neural machine translation (NMT). Surprisingly, we find that the context encoder does not only encode the surrounding sentences but also behaves as a noise generator. This makes us rethink the real benefits of multi-encoder in context-aware translation -some of the improvements come from robust training. We compare several methods that introduce noise and/or well-tuned dropout setup into the training of these encoders. Experimental results show that noisy training plays an important role in multi-encoder-based NMT, especially when the training data is small. Also, we establish a new state-of-the-art on IWSLT Fr-En task by careful use of noise generation and dropout methods.","multi - encoder help ? case study context - aware neural machine translation encoder - decoder neural model , multiple encoder general represent contextual information addition individual sentence . paper , investigate multi - encoder approach document - level neural machine translation ( nmt ) . surprisingly , find context encoder encode surround sentence behave noise generator . make rethink real benefit multi - encoder context - aware translation -some improvement come robust training . compare method introduce noise and/or - tune dropout setup training encoder . experimental result noisy training play important role multi - encoder - base nmt , especially training data small . , establish new state - - - art iwslt fr - en task careful use noise generation dropout method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 19, 'NLP Applications': 10, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Parallel Corpus Filtering via Pre-trained Language Models,"Web-crawled data provides a good source of parallel corpora for training machine translation models. It is automatically obtained, but extremely noisy, and recent work shows that neural machine translation systems are more sensitive to noise than traditional statistical machine translation methods. In this paper, we propose a novel approach to filter out noisy sentence pairs from web-crawled corpora via pre-trained language models. We measure sentence parallelism by leveraging the multilingual capability of BERT and use the Generative Pre-training (GPT) language model as a domain filter to balance data domains. We evaluate the proposed method on the WMT 2018 Parallel Corpus Filtering shared task, and on our own web-crawled Japanese-Chinese parallel corpus. Our method significantly outperforms baselines and achieves a new stateof-the-art. In an unsupervised setting, our method achieves comparable performance to the top-1 supervised method. We also evaluate on a web-crawled Japanese-Chinese parallel corpus that we make publicly available.","Parallel Corpus Filtering via Pre-trained Language Models Web-crawled data provides a good source of parallel corpora for training machine translation models. It is automatically obtained, but extremely noisy, and recent work shows that neural machine translation systems are more sensitive to noise than traditional statistical machine translation methods. In this paper, we propose a novel approach to filter out noisy sentence pairs from web-crawled corpora via pre-trained language models. We measure sentence parallelism by leveraging the multilingual capability of BERT and use the Generative Pre-training (GPT) language model as a domain filter to balance data domains. We evaluate the proposed method on the WMT 2018 Parallel Corpus Filtering shared task, and on our own web-crawled Japanese-Chinese parallel corpus. Our method significantly outperforms baselines and achieves a new stateof-the-art. In an unsupervised setting, our method achieves comparable performance to the top-1 supervised method. We also evaluate on a web-crawled Japanese-Chinese parallel corpus that we make publicly available.","parallel corpus filtering pre - trained language models web - crawl data provide good source parallel corpora train machine translation model . automatically obtain , extremely noisy , recent work show neural machine translation system sensitive noise traditional statistical machine translation method . paper , propose novel approach filter noisy sentence pair web - crawl corpora pre - trained language model . measure sentence parallelism leverage multilingual capability bert use generative pre - training ( gpt ) language model domain filter balance data domain . evaluate propose method wmt 2018 parallel corpus filtering share task , web - crawl japanese - chinese parallel corpus . method significantly outperform baseline achieve new stateof - - art . unsupervised setting , method achieve comparable performance top-1 supervise method . evaluate web - crawl japanese - chinese parallel corpus publicly available .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 12, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,False
Machine Translation and Multilinguality,``You Sound Just Like Your Father'' Commercial Machine Translation Systems Include Stylistic Biases,"The main goal of machine translation has been to convey the correct content. Stylistic considerations have been at best secondary. We show that as a consequence, the output of three commercial machine translation systems (Bing, DeepL, Google) make demographically diverse samples from five languages ""sound"" older and more male than the original. Our findings suggest that translation models reflect demographic bias in the training data. These results open up interesting new research avenues in machine translation to take stylistic considerations into account.","``You Sound Just Like Your Father'' Commercial Machine Translation Systems Include Stylistic Biases The main goal of machine translation has been to convey the correct content. Stylistic considerations have been at best secondary. We show that as a consequence, the output of three commercial machine translation systems (Bing, DeepL, Google) make demographically diverse samples from five languages ""sound"" older and more male than the original. Our findings suggest that translation models reflect demographic bias in the training data. These results open up interesting new research avenues in machine translation to take stylistic considerations into account.","` ` sound like father '' commercial machine translation system include stylistic bias main goal machine translation convey correct content . stylistic consideration well secondary . consequence , output commercial machine translation system ( bing , deepl , google ) demographically diverse sample language "" sound "" old male original . finding suggest translation model reflect demographic bias training datum . result open interesting new research avenue machine translation stylistic consideration account .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Self-Attention with Cross-Lingual Position Representation,"Position encoding (PE), an essential part of self-attention networks (SANs), is used to preserve the word order information for natural language processing tasks, generating fixed position indices for input sequences. However, in cross-lingual scenarios, e.g., machine translation, the PEs of source and target sentences are modeled independently. Due to word order divergences in different languages, modeling the cross-lingual positional relationships might help SANs tackle this problem. In this paper, we augment SANs with crosslingual position representations to model the bilingually aware latent structure for the input sentence. Specifically, we utilize bracketing transduction grammar (BTG)-based reordering information to encourage SANs to learn bilingual diagonal alignments. Experimental results on WMT'14 Englishâ‡’German, WAT'17 Japaneseâ‡’English, and WMT'17 Chineseâ‡”English translation tasks demonstrate that our approach significantly and consistently improves translation quality over strong baselines. Extensive analyses confirm that the performance gains come from the cross-lingual information.","Self-Attention with Cross-Lingual Position Representation Position encoding (PE), an essential part of self-attention networks (SANs), is used to preserve the word order information for natural language processing tasks, generating fixed position indices for input sequences. However, in cross-lingual scenarios, e.g., machine translation, the PEs of source and target sentences are modeled independently. Due to word order divergences in different languages, modeling the cross-lingual positional relationships might help SANs tackle this problem. In this paper, we augment SANs with crosslingual position representations to model the bilingually aware latent structure for the input sentence. Specifically, we utilize bracketing transduction grammar (BTG)-based reordering information to encourage SANs to learn bilingual diagonal alignments. Experimental results on WMT'14 Englishâ‡’German, WAT'17 Japaneseâ‡’English, and WMT'17 Chineseâ‡”English translation tasks demonstrate that our approach significantly and consistently improves translation quality over strong baselines. Extensive analyses confirm that the performance gains come from the cross-lingual information.","self - attention cross - lingual position representation position encoding ( pe ) , essential self - attention network ( sans ) , preserve word order information natural language processing task , generate fix position index input sequence . , cross - lingual scenario , e.g. , machine translation , pe source target sentence model independently . word order divergence different language , model cross - lingual positional relationship help sans tackle problem . paper , augment san crosslingual position representation model bilingually aware latent structure input sentence . specifically , utilize bracketing transduction grammar ( btg)-based reordering information encourage san learn bilingual diagonal alignment . experimental result wmt'14 englishâ‡’german , wat'17 japaneseâ‡’english , wmt'17 chineseâ‡”english translation task demonstrate approach significantly consistently improve translation quality strong baseline . extensive analysis confirm performance gain come cross - lingual information .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Systematic Study of Inner-Attention-Based Sentence Representations in Multilingual Neural Machine Translation,"Neural machine translation has considerably improved the quality of automatic translations by learning good representations of input sentences. In this article, we explore a multilingual translation model capable of producing fixed-size sentence representations by incorporating an intermediate crosslingual shared layer, which we refer to as attention bridge. This layer exploits the semantics from each language and develops into a language-agnostic meaning representation that can be efficiently used for transfer learning. We systematically study the impact of the size of the attention bridge and the effect of including additional languages in the model. In contrast to related previous work, we demonstrate that there is no conflict between translation performance and the use of sentence representations in downstream tasks. In particular, we show that larger intermediate layers not only improve translation quality, especially for long sentences, but also push the accuracy of trainable classification tasks. Nevertheless, shorter representations lead to increased compression that is beneficial in non-trainable similarity tasks. Similarly, we show that trainable downstream tasks benefit from multilingual models, whereas additional language signals do not improve performance in non-trainable benchmarks. This is an important insight Submission","A Systematic Study of Inner-Attention-Based Sentence Representations in Multilingual Neural Machine Translation Neural machine translation has considerably improved the quality of automatic translations by learning good representations of input sentences. In this article, we explore a multilingual translation model capable of producing fixed-size sentence representations by incorporating an intermediate crosslingual shared layer, which we refer to as attention bridge. This layer exploits the semantics from each language and develops into a language-agnostic meaning representation that can be efficiently used for transfer learning. We systematically study the impact of the size of the attention bridge and the effect of including additional languages in the model. In contrast to related previous work, we demonstrate that there is no conflict between translation performance and the use of sentence representations in downstream tasks. In particular, we show that larger intermediate layers not only improve translation quality, especially for long sentences, but also push the accuracy of trainable classification tasks. Nevertheless, shorter representations lead to increased compression that is beneficial in non-trainable similarity tasks. Similarly, we show that trainable downstream tasks benefit from multilingual models, whereas additional language signals do not improve performance in non-trainable benchmarks. This is an important insight Submission","systematic study inner - attention - base sentence representation multilingual neural machine translation neural machine translation considerably improve quality automatic translation learn good representation input sentence . article , explore multilingual translation model capable produce fix - size sentence representation incorporate intermediate crosslingual share layer , refer attention bridge . layer exploit semantic language develop language - agnostic meaning representation efficiently transfer learning . systematically study impact size attention bridge effect include additional language model . contrast related previous work , demonstrate conflict translation performance use sentence representation downstream task . particular , large intermediate layer improve translation quality , especially long sentence , push accuracy trainable classification task . , short representation lead increase compression beneficial non - trainable similarity task . similarly , trainable downstream task benefit multilingual model , additional language signal improve performance non - trainable benchmark . important insight submiss","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Improving Neural Machine Translation with Soft Template Prediction,"Although neural machine translation (NMT) has achieved significant progress in recent years, most previous NMT models only depend on the source text to generate translation. Inspired by the success of template-based and syntax-based approaches in other fields, we propose to use extracted templates from tree structures as soft target templates to guide the translation procedure. In order to learn the syntactic structure of the target sentences, we adopt the constituency-based parse tree to generate candidate templates. We incorporate the template information into the encoder-decoder framework to jointly utilize the templates and source text. Experiments show that our model significantly outperforms the baseline models on four benchmarks and demonstrate the effectiveness of soft target templates.","Improving Neural Machine Translation with Soft Template Prediction Although neural machine translation (NMT) has achieved significant progress in recent years, most previous NMT models only depend on the source text to generate translation. Inspired by the success of template-based and syntax-based approaches in other fields, we propose to use extracted templates from tree structures as soft target templates to guide the translation procedure. In order to learn the syntactic structure of the target sentences, we adopt the constituency-based parse tree to generate candidate templates. We incorporate the template information into the encoder-decoder framework to jointly utilize the templates and source text. Experiments show that our model significantly outperforms the baseline models on four benchmarks and demonstrate the effectiveness of soft target templates.","improve neural machine translation soft template prediction neural machine translation ( nmt ) achieve significant progress recent year , previous nmt model depend source text generate translation . inspire success template - base syntax - base approach field , propose use extract template tree structure soft target template guide translation procedure . order learn syntactic structure target sentence , adopt constituency - base parse tree generate candidate template . incorporate template information encoder - decoder framework jointly utilize template source text . experiment model significantly outperform baseline model benchmark demonstrate effectiveness soft target template .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation,"The masked language model has received remarkable attention due to its effectiveness on various natural language processing tasks. However, few works have adopted this technique in the sequence-to-sequence models. In this work, we introduce a jointly masked sequence-to-sequence model and explore its application on non-autoregressive neural machine translation (NAT). Specifically, we first empirically study the functionalities of the encoder and the decoder in NAT models, and find that the encoder takes a more important role than the decoder regarding the translation quality. Therefore, we propose to train the encoder more rigorously by masking the encoder input while training. As for the decoder, we propose to train it based on the consecutive masking of the decoder input with an ngram loss function to alleviate the problem of translating duplicate words. The two types of masks are applied to the model jointly at the training stage. We conduct experiments on five benchmark machine translation tasks, and our model can achieve 27.69/32.24 BLEU scores on WMT14 English-German/German-English tasks with 5+ times speed up compared with an autoregressive model.","Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation The masked language model has received remarkable attention due to its effectiveness on various natural language processing tasks. However, few works have adopted this technique in the sequence-to-sequence models. In this work, we introduce a jointly masked sequence-to-sequence model and explore its application on non-autoregressive neural machine translation (NAT). Specifically, we first empirically study the functionalities of the encoder and the decoder in NAT models, and find that the encoder takes a more important role than the decoder regarding the translation quality. Therefore, we propose to train the encoder more rigorously by masking the encoder input while training. As for the decoder, we propose to train it based on the consecutive masking of the decoder input with an ngram loss function to alleviate the problem of translating duplicate words. The two types of masks are applied to the model jointly at the training stage. We conduct experiments on five benchmark machine translation tasks, and our model can achieve 27.69/32.24 BLEU scores on WMT14 English-German/German-English tasks with 5+ times speed up compared with an autoregressive model.","jointly mask sequence - - sequence model non - autoregressive neural machine translation mask language model receive remarkable attention effectiveness natural language processing task . , work adopt technique sequence - - sequence model . work , introduce jointly mask sequence - - sequence model explore application non - autoregressive neural machine translation ( nat ) . specifically , empirically study functionality encoder decoder nat model , find encoder take important role decoder translation quality . , propose train encoder rigorously mask encoder input train . decoder , propose train base consecutive masking decoder input ngram loss function alleviate problem translate duplicate word . type mask apply model jointly training stage . conduct experiment benchmark machine translation task , model achieve 27.69/32.24 bleu score wmt14 english - german / german - english task 5 + time speed compare autoregressive model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 18, 'NLP Applications': 9, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Opportunistic Decoding with Timely Correction for Simultaneous Translation,"Simultaneous translation has many important application scenarios and attracts much attention from both academia and industry recently. Most existing frameworks, however, have difficulties in balancing between the translation quality and latency, i.e., the decoding policy is usually either too aggressive or too conservative. We propose an opportunistic decoding technique with timely correction ability, which always (over-)generates a certain mount of extra words at each step to keep the audience on track with the latest information. At the same time, it also corrects, in a timely fashion, the mistakes in the former overgenerated words when observing more source context to ensure high translation quality. Experiments show our technique achieves substantial reduction in latency and up to +3.1 increase in BLEU, with revision rate under 8% in Chinese-to-English and English-to-Chinese translation.","Opportunistic Decoding with Timely Correction for Simultaneous Translation Simultaneous translation has many important application scenarios and attracts much attention from both academia and industry recently. Most existing frameworks, however, have difficulties in balancing between the translation quality and latency, i.e., the decoding policy is usually either too aggressive or too conservative. We propose an opportunistic decoding technique with timely correction ability, which always (over-)generates a certain mount of extra words at each step to keep the audience on track with the latest information. At the same time, it also corrects, in a timely fashion, the mistakes in the former overgenerated words when observing more source context to ensure high translation quality. Experiments show our technique achieves substantial reduction in latency and up to +3.1 increase in BLEU, with revision rate under 8% in Chinese-to-English and English-to-Chinese translation.","opportunistic decoding timely correction simultaneous translation simultaneous translation important application scenario attract attention academia industry recently . exist framework , , difficulty balance translation quality latency , i.e. , decoding policy usually aggressive conservative . propose opportunistic decoding technique timely correction ability , ( over-)generate certain mount extra word step audience track late information . time , correct , timely fashion , mistake overgenerate word observe source context ensure high translation quality . experiment technique achieve substantial reduction latency +3.1 increase bleu , revision rate 8 % chinese - - english english - - chinese translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Using Context in Neural Machine Translation Training Objectives,"We present Neural Machine Translation (NMT) training using document-level metrics with batch-level documents. Previous sequence-objective approaches to NMT training focus exclusively on sentence-level metrics like sentence BLEU which do not correspond to the desired evaluation metric, typically document BLEU. Meanwhile research into document-level NMT training focuses on data or model architecture rather than training procedure. We find that each of these lines of research has a clear space in it for the other, and propose merging them with a scheme that allows a document-level evaluation metric to be used in the NMT training objective. We first sample pseudo-documents from sentence samples. We then approximate the expected document BLEU gradient with Monte Carlo sampling for use as a cost function in Minimum Risk Training (MRT). This twolevel sampling procedure gives NMT performance gains over sequence MRT and maximum-likelihood training. We demonstrate that training is more robust for document-level metrics than with sequence metrics. We further demonstrate improvements on NMT with TER and Grammatical Error Correction (GEC) using GLEU, both metrics used at the document level for evaluations.","Using Context in Neural Machine Translation Training Objectives We present Neural Machine Translation (NMT) training using document-level metrics with batch-level documents. Previous sequence-objective approaches to NMT training focus exclusively on sentence-level metrics like sentence BLEU which do not correspond to the desired evaluation metric, typically document BLEU. Meanwhile research into document-level NMT training focuses on data or model architecture rather than training procedure. We find that each of these lines of research has a clear space in it for the other, and propose merging them with a scheme that allows a document-level evaluation metric to be used in the NMT training objective. We first sample pseudo-documents from sentence samples. We then approximate the expected document BLEU gradient with Monte Carlo sampling for use as a cost function in Minimum Risk Training (MRT). This twolevel sampling procedure gives NMT performance gains over sequence MRT and maximum-likelihood training. We demonstrate that training is more robust for document-level metrics than with sequence metrics. We further demonstrate improvements on NMT with TER and Grammatical Error Correction (GEC) using GLEU, both metrics used at the document level for evaluations.","context neural machine translation training objective present neural machine translation ( nmt ) train document - level metric batch - level document . previous sequence - objective approach nmt training focus exclusively sentence - level metric like sentence bleu correspond desire evaluation metric , typically document bleu . research document - level nmt training focus datum model architecture training procedure . find line research clear space , propose merge scheme allow document - level evaluation metric nmt training objective . sample pseudo - document sentence sample . approximate expected document bleu gradient monte carlo sampling use cost function minimum risk training ( mrt ) . twolevel sampling procedure give nmt performance gain sequence mrt maximum - likelihood training . demonstrate training robust document - level metric sequence metric . demonstrate improvement nmt ter grammatical error correction ( gec ) gleu , metric document level evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 10, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 12, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Parallel Sentence Mining by Constrained Decoding,"We present a novel method to extract parallel sentences from two monolingual corpora, using neural machine translation. Our method relies on translating sentences in one corpus, but constraining the decoding by a prefix tree built on the other corpus. We argue that a neural machine translation system by itself can be a sentence similarity scorer and it efficiently approximates pairwise comparison with a modified beam search. When benchmarked on the BUCC shared task, our method achieves results comparable to other submissions.","Parallel Sentence Mining by Constrained Decoding We present a novel method to extract parallel sentences from two monolingual corpora, using neural machine translation. Our method relies on translating sentences in one corpus, but constraining the decoding by a prefix tree built on the other corpus. We argue that a neural machine translation system by itself can be a sentence similarity scorer and it efficiently approximates pairwise comparison with a modified beam search. When benchmarked on the BUCC shared task, our method achieves results comparable to other submissions.","parallel sentence mining constrain decoding present novel method extract parallel sentence monolingual corpus , neural machine translation . method rely translate sentence corpus , constrain decoding prefix tree build corpus . argue neural machine translation system sentence similarity scorer efficiently approximate pairwise comparison modify beam search . benchmarke bucc share task , method achieve result comparable submission .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 6, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Regularized Context Gates on Transformer for Machine Translation,"Context gates are effective to control the contributions from the source and target contexts in the recurrent neural network (RNN) based neural machine translation (NMT). However, it is challenging to extend them into the advanced Transformer architecture, which is more complicated than RNN. This paper first provides a method to identify source and target contexts and then introduce a gate mechanism to control the source and target contributions in Transformer. In addition, to further reduce the bias problem in the gate mechanism, this paper proposes a regularization method to guide the learning of the gates with supervision automatically generated using pointwise mutual information. Extensive experiments on 4 translation datasets demonstrate that the proposed model obtains an averaged gain of 1.0 BLEU score over a strong Transformer baseline.","Regularized Context Gates on Transformer for Machine Translation Context gates are effective to control the contributions from the source and target contexts in the recurrent neural network (RNN) based neural machine translation (NMT). However, it is challenging to extend them into the advanced Transformer architecture, which is more complicated than RNN. This paper first provides a method to identify source and target contexts and then introduce a gate mechanism to control the source and target contributions in Transformer. In addition, to further reduce the bias problem in the gate mechanism, this paper proposes a regularization method to guide the learning of the gates with supervision automatically generated using pointwise mutual information. Extensive experiments on 4 translation datasets demonstrate that the proposed model obtains an averaged gain of 1.0 BLEU score over a strong Transformer baseline.","regularize context gate transformer machine translation context gate effective control contribution source target context recurrent neural network ( rnn ) base neural machine translation ( nmt ) . , challenging extend advanced transformer architecture , complicated rnn . paper provide method identify source target context introduce gate mechanism control source target contribution transformer . addition , reduce bias problem gate mechanism , paper propose regularization method guide learning gate supervision automatically generate pointwise mutual information . extensive experiment 4 translation dataset demonstrate propose model obtain average gain 1.0 bleu score strong transformer baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Multi-Domain Neural Machine Translation with Word-Level Adaptive Layer-wise Domain Mixing,"Many multi-domain neural machine translation (NMT) models achieve knowledge transfer by enforcing one encoder to learn shared embedding across domains. However, this design lacks adaptation to individual domains. To overcome this limitation, we propose a novel multi-domain NMT model using individual modules for each domain, on which we apply word-level, adaptive and layer-wise domain mixing. We first observe that words in a sentence are often related to multiple domains. Hence, we assume each word has a domain proportion, which indicates its domain preference. Then word representations are obtained by mixing their embedding in individual domains based on their domain proportions. We show this can be achieved by carefully designing multi-head dot-product attention modules for different domains, and eventually taking weighted averages of their parameters by word-level layer-wise domain proportions. Through this, we can achieve effective domain knowledge sharing, and capture fine-grained domain-specific knowledge as well. Our experiments show that our proposed model outperforms existing ones in several NMT tasks.","Multi-Domain Neural Machine Translation with Word-Level Adaptive Layer-wise Domain Mixing Many multi-domain neural machine translation (NMT) models achieve knowledge transfer by enforcing one encoder to learn shared embedding across domains. However, this design lacks adaptation to individual domains. To overcome this limitation, we propose a novel multi-domain NMT model using individual modules for each domain, on which we apply word-level, adaptive and layer-wise domain mixing. We first observe that words in a sentence are often related to multiple domains. Hence, we assume each word has a domain proportion, which indicates its domain preference. Then word representations are obtained by mixing their embedding in individual domains based on their domain proportions. We show this can be achieved by carefully designing multi-head dot-product attention modules for different domains, and eventually taking weighted averages of their parameters by word-level layer-wise domain proportions. Through this, we can achieve effective domain knowledge sharing, and capture fine-grained domain-specific knowledge as well. Our experiments show that our proposed model outperforms existing ones in several NMT tasks.","multi - domain neural machine translation word - level adaptive layer - wise domain mixing multi - domain neural machine translation ( nmt ) model achieve knowledge transfer enforce encoder learn share embedding domain . , design lack adaptation individual domain . overcome limitation , propose novel multi - domain nmt model individual module domain , apply word - level , adaptive layer - wise domain mixing . observe word sentence relate multiple domain . , assume word domain proportion , indicate domain preference . word representation obtain mix embedding individual domain base domain proportion . achieve carefully design multi - head dot - product attention module different domain , eventually take weight average parameter word - level layer - wise domain proportion . , achieve effective domain knowledge sharing , capture fine - grained domain - specific knowledge . experiment propose model outperform exist one nmt task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation,"We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call ENGINE (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models. 1","ENGINE: Energy-Based Inference Networks for Non-Autoregressive Machine Translation We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call ENGINE (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models. 1","engine : energy - base inference networks non - autoregressive machine translation propose train non - autoregressive machine translation model minimize energy define pretraine autoregressive model . particular , view non - autoregressive translation system inference network ( tu gimpel , 2018 ) train minimize autoregressive teacher energy . contrast popular approach train non - autoregressive model distil corpus consist beam - search output teacher model . approach , engine ( energy - base inference networks ) , achieve state - - - art non - autoregressive result iwslt 2014 de - en wmt 2016 ro - en dataset , approach performance autoregressive model . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Lipschitz Constrained Parameter Initialization for Deep Transformers,"The Transformer translation model employs residual connection and layer normalization to ease the optimization difficulties caused by its multi-layer encoder/decoder structure. Previous research shows that even with residual connection and layer normalization, deep Transformers still have difficulty in training, and particularly Transformer models with more than 12 encoder/decoder layers fail to converge. In this paper, we first empirically demonstrate that a simple modification made in the official implementation, which changes the computation order of residual connection and layer normalization, can significantly ease the optimization of deep Transformers. We then compare the subtle differences in computation order in considerable detail, and present a parameter initialization method that leverages the Lipschitz constraint on the initialization of Transformer parameters that effectively ensures training convergence. In contrast to findings in previous research we further demonstrate that with Lipschitz parameter initialization, deep Transformers with the original computation order can converge, and obtain significant BLEU improvements with up to 24 layers. In contrast to previous research which focuses on deep encoders, our approach additionally enables Transformers to also benefit from deep decoders.","Lipschitz Constrained Parameter Initialization for Deep Transformers The Transformer translation model employs residual connection and layer normalization to ease the optimization difficulties caused by its multi-layer encoder/decoder structure. Previous research shows that even with residual connection and layer normalization, deep Transformers still have difficulty in training, and particularly Transformer models with more than 12 encoder/decoder layers fail to converge. In this paper, we first empirically demonstrate that a simple modification made in the official implementation, which changes the computation order of residual connection and layer normalization, can significantly ease the optimization of deep Transformers. We then compare the subtle differences in computation order in considerable detail, and present a parameter initialization method that leverages the Lipschitz constraint on the initialization of Transformer parameters that effectively ensures training convergence. In contrast to findings in previous research we further demonstrate that with Lipschitz parameter initialization, deep Transformers with the original computation order can converge, and obtain significant BLEU improvements with up to 24 layers. In contrast to previous research which focuses on deep encoders, our approach additionally enables Transformers to also benefit from deep decoders.","lipschitz constrained parameter initialization deep transformers transformer translation model employ residual connection layer normalization ease optimization difficulty cause multi - layer encoder / decoder structure . previous research show residual connection layer normalization , deep transformers difficulty training , particularly transformer model 12 encoder / decoder layer fail converge . paper , empirically demonstrate simple modification official implementation , change computation order residual connection layer normalization , significantly ease optimization deep transformers . compare subtle difference computation order considerable detail , present parameter initialization method leverage lipschitz constraint initialization transformer parameter effectively ensure training convergence . contrast finding previous research demonstrate lipschitz parameter initialization , deep transformers original computation order converge , obtain significant bleu improvement 24 layer . contrast previous research focus deep encoder , approach additionally enable transformers benefit deep decoder .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,Knowledge Distillation for Multilingual Unsupervised Neural Machine Translation,"Unsupervised neural machine translation (UNMT) has recently achieved remarkable results for several language pairs. However, it can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time. That is, research on multilingual UNMT has been limited. In this paper, we empirically introduce a simple method to translate between thirteen languages using a single encoder and a single decoder, making use of multilingual data to improve UNMT for all language pairs. On the basis of the empirical findings, we propose two knowledge distillation methods to further enhance multilingual UNMT performance. Our experiments on a dataset with English translated to and from twelve other languages (including three language families and six language branches) show remarkable results, surpassing strong unsupervised individual baselines while achieving promising performance between non-English language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs.","Knowledge Distillation for Multilingual Unsupervised Neural Machine Translation Unsupervised neural machine translation (UNMT) has recently achieved remarkable results for several language pairs. However, it can only translate between a single language pair and cannot produce translation results for multiple language pairs at the same time. That is, research on multilingual UNMT has been limited. In this paper, we empirically introduce a simple method to translate between thirteen languages using a single encoder and a single decoder, making use of multilingual data to improve UNMT for all language pairs. On the basis of the empirical findings, we propose two knowledge distillation methods to further enhance multilingual UNMT performance. Our experiments on a dataset with English translated to and from twelve other languages (including three language families and six language branches) show remarkable results, surpassing strong unsupervised individual baselines while achieving promising performance between non-English language pairs in zero-shot translation scenarios and alleviating poor performance in low-resource language pairs.","knowledge distillation multilingual unsupervised neural machine translation unsupervised neural machine translation ( unmt ) recently achieve remarkable result language pair . , translate single language pair produce translation result multiple language pair time . , research multilingual unmt limit . paper , empirically introduce simple method translate thirteen language single encoder single decoder , make use multilingual datum improve unmt language pair . basis empirical finding , propose knowledge distillation method enhance multilingual unmt performance . experiment dataset english translate language ( include language family language branch ) remarkable result , surpass strong unsupervised individual baseline achieve promising performance non - english language pair zero - shot translation scenario alleviate poor performance low - resource language pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 15, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Language-aware Interlingua for Multilingual Neural Machine Translation,"Multilingual neural machine translation (NMT) has led to impressive accuracy improvements in low-resource scenarios by sharing common linguistic information across languages. However, the traditional multilingual model fails to capture the diversity and specificity of different languages, resulting in inferior performance compared with individual models that are sufficiently trained. In this paper, we incorporate a language-aware interlingua into the Encoder-Decoder architecture. The interlingual network enables the model to learn a language-independent representation from the semantic spaces of different languages, while still allowing for language-specific specialization of a particular language-pair. Experiments show that our proposed method achieves remarkable improvements over state-of-the-art multilingual NMT baselines and produces comparable performance with strong individual models.","Language-aware Interlingua for Multilingual Neural Machine Translation Multilingual neural machine translation (NMT) has led to impressive accuracy improvements in low-resource scenarios by sharing common linguistic information across languages. However, the traditional multilingual model fails to capture the diversity and specificity of different languages, resulting in inferior performance compared with individual models that are sufficiently trained. In this paper, we incorporate a language-aware interlingua into the Encoder-Decoder architecture. The interlingual network enables the model to learn a language-independent representation from the semantic spaces of different languages, while still allowing for language-specific specialization of a particular language-pair. Experiments show that our proposed method achieves remarkable improvements over state-of-the-art multilingual NMT baselines and produces comparable performance with strong individual models.","language - aware interlingua multilingual neural machine translation multilingual neural machine translation ( nmt ) lead impressive accuracy improvement low - resource scenario share common linguistic information language . , traditional multilingual model fail capture diversity specificity different language , result inferior performance compare individual model sufficiently train . paper , incorporate language - aware interlingua encoder - decoder architecture . interlingual network enable model learn language - independent representation semantic space different language , allow language - specific specialization particular language - pair . experiment propose method achieve remarkable improvement state - - - art multilingual nmt baseline produce comparable performance strong individual model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Evaluating Explanation Methods for Neural Machine Translation,"Recently many efforts have been devoted to interpreting the black-box NMT models, but little progress has been made on metrics to evaluate explanation methods. Word Alignment Error Rate can be used as such a metric that matches human understanding, however, it can not measure explanation methods on those target words that are not aligned to any source word. This paper thereby makes an initial attempt to evaluate explanation methods from an alternative viewpoint. To this end, it proposes a principled metric based on fidelity in regard to the predictive behavior of the NMT model. As the exact computation for this metric is intractable, we employ an efficient approach as its approximation. On six standard translation tasks, we quantitatively evaluate several explanation methods in terms of the proposed metric and we reveal some valuable findings for these explanation methods in our experiments.","Evaluating Explanation Methods for Neural Machine Translation Recently many efforts have been devoted to interpreting the black-box NMT models, but little progress has been made on metrics to evaluate explanation methods. Word Alignment Error Rate can be used as such a metric that matches human understanding, however, it can not measure explanation methods on those target words that are not aligned to any source word. This paper thereby makes an initial attempt to evaluate explanation methods from an alternative viewpoint. To this end, it proposes a principled metric based on fidelity in regard to the predictive behavior of the NMT model. As the exact computation for this metric is intractable, we employ an efficient approach as its approximation. On six standard translation tasks, we quantitatively evaluate several explanation methods in terms of the proposed metric and we reveal some valuable findings for these explanation methods in our experiments.","evaluate explanation method neural machine translation recently effort devote interpret black - box nmt model , little progress metric evaluate explanation method . word alignment error rate metric match human understanding , , measure explanation method target word align source word . paper make initial attempt evaluate explanation method alternative viewpoint . end , propose principled metric base fidelity regard predictive behavior nmt model . exact computation metric intractable , employ efficient approach approximation . standard translation task , quantitatively evaluate explanation method term propose metric reveal valuable finding explanation method experiment .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Leveraging Monolingual Data with Self-Supervision for Multilingual Neural Machine Translation,"Over the last few years two promising research directions in low-resource neural machine translation (NMT) have emerged. The first focuses on utilizing high-resource languages to improve the quality of low-resource languages via multilingual NMT. The second direction employs monolingual data with selfsupervision to pre-train translation models, followed by fine-tuning on small amounts of supervised data. In this work, we join these two lines of research and demonstrate the efficacy of monolingual data with self-supervision in multilingual NMT. We offer three major results: (i) Using monolingual data significantly boosts the translation quality of lowresource languages in multilingual models. (ii) Self-supervision improves zero-shot translation quality in multilingual models. (iii) Leveraging monolingual data with self-supervision provides a viable path towards adding new languages to multilingual models, getting up to 33 BLEU on WMT ro-en translation without any parallel data or back-translation.","Leveraging Monolingual Data with Self-Supervision for Multilingual Neural Machine Translation Over the last few years two promising research directions in low-resource neural machine translation (NMT) have emerged. The first focuses on utilizing high-resource languages to improve the quality of low-resource languages via multilingual NMT. The second direction employs monolingual data with selfsupervision to pre-train translation models, followed by fine-tuning on small amounts of supervised data. In this work, we join these two lines of research and demonstrate the efficacy of monolingual data with self-supervision in multilingual NMT. We offer three major results: (i) Using monolingual data significantly boosts the translation quality of lowresource languages in multilingual models. (ii) Self-supervision improves zero-shot translation quality in multilingual models. (iii) Leveraging monolingual data with self-supervision provides a viable path towards adding new languages to multilingual models, getting up to 33 BLEU on WMT ro-en translation without any parallel data or back-translation.","leverage monolingual datum self - supervision multilingual neural machine translation year promising research direction low - resource neural machine translation ( nmt ) emerge . focus utilize high - resource language improve quality low - resource language multilingual nmt . second direction employ monolingual datum selfsupervision pre - train translation model , follow fine - tuning small amount supervise datum . work , join line research demonstrate efficacy monolingual datum self - supervision multilingual nmt . offer major result : ( ) monolingual datum significantly boost translation quality lowresource language multilingual model . ( ii ) self - supervision improve zero - shot translation quality multilingual model . ( iii ) leverage monolingual datum self - supervision provide viable path add new language multilingual model , get 33 bleu wmt ro - en translation parallel datum - translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 19, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 7, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,On the Linguistic Representational Power of Neural Machine Translation Models,"Despite the recent success of deep neural networks in natural language processing and other spheres of artificial intelligence, their interpretability remains a challenge. We analyze the representations learned by neural machine translation (NMT) models at various levels of granularity and evaluate their quality through relevant extrinsic properties. In particular, we seek answers to the following questions: (i) How accurately is word structure captured within the learned representations, which is an important aspect in translating morphologically rich languages? (ii) Do the representations capture long-range dependencies, and effectively handle syntactically divergent languages? (iii) Do the representations capture lexical semantics? We conduct a thorough investigation along several parameters: (i) Which layers in the architecture capture each of these linguistic phenomena; (ii) How does the choice of translation unit (word, character, or subword unit) impact the linguistic properties captured by the underlying representations? (iii) Do the encoder and decoder learn differently and independently? (iv) Do the representations learned by multilingual NMT models capture the same amount of linguistic information as their bilingual counterparts? Our data-driven, quantitative evaluation illuminates important aspects in NMT models and their ability to capture various linguistic phenomena. We show that deep NMT models trained in an end-to-end fashion, without being provided any direct supervision during the training process, learn a non-trivial amount of linguistic information. Notable findings include the following observations: (i) Word morphology and part-of-speech information are captured at the lower layers of the model; (ii) In contrast, lexical semantics or non-local syntactic and semantic dependencies are better represented at the higher layers of the model; (iii) Representations learned using characters are more informed about word-morphology compared to those learned using subword units; and (iv) Representations learned by multilingual models are richer compared to bilingual models.","On the Linguistic Representational Power of Neural Machine Translation Models Despite the recent success of deep neural networks in natural language processing and other spheres of artificial intelligence, their interpretability remains a challenge. We analyze the representations learned by neural machine translation (NMT) models at various levels of granularity and evaluate their quality through relevant extrinsic properties. In particular, we seek answers to the following questions: (i) How accurately is word structure captured within the learned representations, which is an important aspect in translating morphologically rich languages? (ii) Do the representations capture long-range dependencies, and effectively handle syntactically divergent languages? (iii) Do the representations capture lexical semantics? We conduct a thorough investigation along several parameters: (i) Which layers in the architecture capture each of these linguistic phenomena; (ii) How does the choice of translation unit (word, character, or subword unit) impact the linguistic properties captured by the underlying representations? (iii) Do the encoder and decoder learn differently and independently? (iv) Do the representations learned by multilingual NMT models capture the same amount of linguistic information as their bilingual counterparts? Our data-driven, quantitative evaluation illuminates important aspects in NMT models and their ability to capture various linguistic phenomena. We show that deep NMT models trained in an end-to-end fashion, without being provided any direct supervision during the training process, learn a non-trivial amount of linguistic information. Notable findings include the following observations: (i) Word morphology and part-of-speech information are captured at the lower layers of the model; (ii) In contrast, lexical semantics or non-local syntactic and semantic dependencies are better represented at the higher layers of the model; (iii) Representations learned using characters are more informed about word-morphology compared to those learned using subword units; and (iv) Representations learned by multilingual models are richer compared to bilingual models.","linguistic representational power neural machine translation models despite recent success deep neural network natural language processing sphere artificial intelligence , interpretability remain challenge . analyze representation learn neural machine translation ( nmt ) model level granularity evaluate quality relevant extrinsic property . particular , seek answer following question : ( ) accurately word structure capture learn representation , important aspect translate morphologically rich language ? ( ii ) representation capture long - range dependency , effectively handle syntactically divergent language ? ( iii ) representation capture lexical semantic ? conduct thorough investigation parameter : ( ) layer architecture capture linguistic phenomenon ; ( ii ) choice translation unit ( word , character , subword unit ) impact linguistic property capture underlie representation ? ( iii ) encoder decoder learn differently independently ? ( iv ) representation learn multilingual nmt model capture linguistic information bilingual counterpart ? data - drive , quantitative evaluation illuminate important aspect nmt model ability capture linguistic phenomenon . deep nmt model train end - - end fashion , provide direct supervision training process , learn non - trivial linguistic information . notable finding include following observation : ( ) word morphology - - speech information capture low layer model ; ( ii ) contrast , lexical semantic non - local syntactic semantic dependency well represent high layer model ; ( iii ) representation learn character informed word - morphology compare learn subword unit ; ( iv ) representation learn multilingual model rich compare bilingual model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 2, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,HAT: Hardware-Aware Transformers for Efficient Natural Language Processing,"Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but they are difficult to be deployed on hardware due to the intensive computation. To enable low-latency inference on resource-constrained hardware platforms, we propose to design Hardware-Aware Transformers (HAT) with neural architecture search. We first construct a large design space with arbitrary encoder-decoder attention and heterogeneous layers. Then we train a Super-Transformer that covers all candidates in the design space, and efficiently produces many SubTransformers with weight sharing. Finally, we perform an evolutionary search with a hardware latency constraint to find a specialized SubTransformer dedicated to run fast on the target hardware. Extensive experiments on four machine translation tasks demonstrate that HAT can discover efficient models for different hardware (CPU, GPU, IoT device). When running WMT'14 translation task on Raspberry Pi-4, HAT can achieve 3Ã— speedup, 3.7Ã— smaller size over baseline Transformer; 2.7Ã— speedup, 3.6Ã— smaller size over Evolved Transformer with 12,041Ã— less search cost and no performance loss. HAT is open-sourced.","HAT: Hardware-Aware Transformers for Efficient Natural Language Processing Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but they are difficult to be deployed on hardware due to the intensive computation. To enable low-latency inference on resource-constrained hardware platforms, we propose to design Hardware-Aware Transformers (HAT) with neural architecture search. We first construct a large design space with arbitrary encoder-decoder attention and heterogeneous layers. Then we train a Super-Transformer that covers all candidates in the design space, and efficiently produces many SubTransformers with weight sharing. Finally, we perform an evolutionary search with a hardware latency constraint to find a specialized SubTransformer dedicated to run fast on the target hardware. Extensive experiments on four machine translation tasks demonstrate that HAT can discover efficient models for different hardware (CPU, GPU, IoT device). When running WMT'14 translation task on Raspberry Pi-4, HAT can achieve 3Ã— speedup, 3.7Ã— smaller size over baseline Transformer; 2.7Ã— speedup, 3.6Ã— smaller size over Evolved Transformer with 12,041Ã— less search cost and no performance loss. HAT is open-sourced.","hat : hardware - aware transformers efficient natural language processing transformers ubiquitous natural language processing ( nlp ) task , difficult deploy hardware intensive computation . enable low - latency inference resource - constrain hardware platform , propose design hardware - aware transformers ( hat ) neural architecture search . construct large design space arbitrary encoder - decoder attention heterogeneous layer . train super - transformer cover candidate design space , efficiently produce subtransformers weight sharing . finally , perform evolutionary search hardware latency constraint find specialized subtransformer dedicate run fast target hardware . extensive experiment machine translation task demonstrate hat discover efficient model different hardware ( cpu , gpu , iot device ) . run wmt'14 translation task raspberry pi-4 , hat achieve 3Ã— speedup , 3.7Ã— small size baseline transformer ; 2.7Ã— speedup , 3.6Ã— small size evolved transformer 12,041Ã— search cost performance loss . hat open - source .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 11, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,A Retrieve-and-Rewrite Initialization Method for Unsupervised Machine Translation,"The commonly used framework for unsupervised machine translation builds initial translation models of both translation directions, and then performs iterative back-translation to jointly boost their translation performance. The initialization stage is very important since bad initialization may wrongly squeeze the search space, and too much noise introduced in this stage may hurt the final performance. In this paper, we propose a novel retrieval and rewriting based method to better initialize unsupervised translation models. We first retrieve semantically comparable sentences from monolingual corpora of two languages and then rewrite the target side to minimize the semantic gap between the source and retrieved targets with a designed rewriting model. The rewritten sentence pairs are used to initialize SMT models which are used to generate pseudo data for two NMT models, followed by the iterative back-translation. Experiments show that our method can build better initial unsupervised translation models and improve the final translation performance by over 4 BLEU scores.","A Retrieve-and-Rewrite Initialization Method for Unsupervised Machine Translation The commonly used framework for unsupervised machine translation builds initial translation models of both translation directions, and then performs iterative back-translation to jointly boost their translation performance. The initialization stage is very important since bad initialization may wrongly squeeze the search space, and too much noise introduced in this stage may hurt the final performance. In this paper, we propose a novel retrieval and rewriting based method to better initialize unsupervised translation models. We first retrieve semantically comparable sentences from monolingual corpora of two languages and then rewrite the target side to minimize the semantic gap between the source and retrieved targets with a designed rewriting model. The rewritten sentence pairs are used to initialize SMT models which are used to generate pseudo data for two NMT models, followed by the iterative back-translation. Experiments show that our method can build better initial unsupervised translation models and improve the final translation performance by over 4 BLEU scores.","retrieve - - rewrite initialization method unsupervised machine translation commonly framework unsupervised machine translation build initial translation model translation direction , perform iterative - translation jointly boost translation performance . initialization stage important bad initialization wrongly squeeze search space , noise introduce stage hurt final performance . paper , propose novel retrieval rewriting base method well initialize unsupervised translation model . retrieve semantically comparable sentence monolingual corpora language rewrite target minimize semantic gap source retrieve target design rewriting model . rewrite sentence pair initialize smt model generate pseudo datum nmt model , follow iterative - translation . experiment method build well initial unsupervised translation model improve final translation performance 4 bleu score .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Addressing Posterior Collapse with Mutual Information for Improved Variational Neural Machine Translation,"This paper proposes a simple and effective approach to address the problem of posterior collapse in conditional variational autoencoders (CVAEs). It thus improves performance of machine translation models that use noisy or monolingual data, as well as in conventional settings. Extending Transformer and conditional VAEs, our proposed latent variable model measurably prevents posterior collapse by (1) using a modified evidence lower bound (ELBO) objective which promotes mutual information between the latent variable and the target, and (2) guiding the latent variable with an auxiliary bag-of-words prediction task. As a result, the proposed model yields improved translation quality compared to existing variational NMT models on WMT Roâ†”En and Deâ†”En. With latent variables being effectively utilized, our model demonstrates improved robustness over non-latent Transformer in handling uncertainty: exploiting noisy source-side monolingual data (up to +3.2 BLEU), and training with weakly aligned web-mined parallel data (up to +4.7 BLEU).","Addressing Posterior Collapse with Mutual Information for Improved Variational Neural Machine Translation This paper proposes a simple and effective approach to address the problem of posterior collapse in conditional variational autoencoders (CVAEs). It thus improves performance of machine translation models that use noisy or monolingual data, as well as in conventional settings. Extending Transformer and conditional VAEs, our proposed latent variable model measurably prevents posterior collapse by (1) using a modified evidence lower bound (ELBO) objective which promotes mutual information between the latent variable and the target, and (2) guiding the latent variable with an auxiliary bag-of-words prediction task. As a result, the proposed model yields improved translation quality compared to existing variational NMT models on WMT Roâ†”En and Deâ†”En. With latent variables being effectively utilized, our model demonstrates improved robustness over non-latent Transformer in handling uncertainty: exploiting noisy source-side monolingual data (up to +3.2 BLEU), and training with weakly aligned web-mined parallel data (up to +4.7 BLEU).","address posterior collapse mutual information improve variational neural machine translation paper propose simple effective approach address problem posterior collapse conditional variational autoencoder ( cvaes ) . improve performance machine translation model use noisy monolingual datum , conventional setting . extend transformer conditional vae , propose latent variable model measurably prevent posterior collapse ( 1 ) modify evidence low bind ( elbo ) objective promote mutual information latent variable target , ( 2 ) guide latent variable auxiliary bag - - word prediction task . result , propose model yield improved translation quality compare exist variational nmt model wmt roâ†”en deâ†”en . latent variable effectively utilize , model demonstrate improved robustness non - latent transformer handle uncertainty : exploit noisy source - monolingual datum ( +3.2 bleu ) , train weakly align web - mine parallel datum ( +4.7 bleu ) .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation,"Non-autoregressive neural machine translation (NAT) predicts the entire target sequence simultaneously and significantly accelerates inference process. However, NAT discards the dependency information in a sentence, and thus inevitably suffers from the multi-modality problem: the target tokens may be provided by different possible translations, often causing token repetitions or missing. To alleviate this problem, we propose a novel semiautoregressive model RecoverSAT in this work, which generates a translation as a sequence of segments. The segments are generated simultaneously while each segment is predicted token-by-token. By dynamically determining segment length and deleting repetitive segments, RecoverSAT is capable of recovering from repetitive and missing token errors. Experimental results on three widelyused benchmark datasets show that our proposed model achieves more than 4Ã— speedup while maintaining comparable performance compared with the corresponding autoregressive model. * indicates equal contribution â€  indicates corresponding author Src. es gibt heute viele Farmer mit diesem Ansatz Feasible there are lots of farmers doing this today Trans. there are a lot of farmers doing this today Trans. 1 there are lots of of farmers doing this today Trans. 2 there are a lot farmers doing this today","Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation Non-autoregressive neural machine translation (NAT) predicts the entire target sequence simultaneously and significantly accelerates inference process. However, NAT discards the dependency information in a sentence, and thus inevitably suffers from the multi-modality problem: the target tokens may be provided by different possible translations, often causing token repetitions or missing. To alleviate this problem, we propose a novel semiautoregressive model RecoverSAT in this work, which generates a translation as a sequence of segments. The segments are generated simultaneously while each segment is predicted token-by-token. By dynamically determining segment length and deleting repetitive segments, RecoverSAT is capable of recovering from repetitive and missing token errors. Experimental results on three widelyused benchmark datasets show that our proposed model achieves more than 4Ã— speedup while maintaining comparable performance compared with the corresponding autoregressive model. * indicates equal contribution â€  indicates corresponding author Src. es gibt heute viele Farmer mit diesem Ansatz Feasible there are lots of farmers doing this today Trans. there are a lot of farmers doing this today Trans. 1 there are lots of of farmers doing this today Trans. 2 there are a lot farmers doing this today","learn recover multi - modality error non - autoregressive neural machine translation non - autoregressive neural machine translation ( nat ) predict entire target sequence simultaneously significantly accelerate inference process . , nat discard dependency information sentence , inevitably suffer multi - modality problem : target token provide different possible translation , cause token repetition miss . alleviate problem , propose novel semiautoregressive model recoversat work , generate translation sequence segment . segment generate simultaneously segment predict token - - token . dynamically determine segment length delete repetitive segment , recoversat capable recover repetitive miss token error . experimental result widelyused benchmark dataset propose model achieve 4Ã— speedup maintain comparable performance compare corresponding autoregressive model . * indicate equal contribution â€  indicate correspond author src . es gibt heute viele farmer mit diesem ansatz feasible lot farmer today trans . lot farmer today trans . 1 lot farmer today trans . 2 lot farmer today","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Location Attention for Extrapolation to Longer Sequences,"Neural networks are surprisingly good at interpolating and perform remarkably well when the training set examples resemble those in the test set. However, they are often unable to extrapolate patterns beyond the seen data, even when the abstractions required for such patterns are simple. In this paper, we first review the notion of extrapolation, why it is important, and how one could hope to tackle it. We then focus on a specific type of extrapolation, which is especially useful for natural language processing: generalization to sequences longer than those seen during training. We hypothesize that models with a separate contentand location-based attention are more likely to extrapolate than those with common attention mechanisms. We empirically support our claim for recurrent seq2seq models with our proposed attention on variants of the Lookup Table task . This sheds light on some striking failures of neural models for sequences and on possible methods to approaching such issues.","Location Attention for Extrapolation to Longer Sequences Neural networks are surprisingly good at interpolating and perform remarkably well when the training set examples resemble those in the test set. However, they are often unable to extrapolate patterns beyond the seen data, even when the abstractions required for such patterns are simple. In this paper, we first review the notion of extrapolation, why it is important, and how one could hope to tackle it. We then focus on a specific type of extrapolation, which is especially useful for natural language processing: generalization to sequences longer than those seen during training. We hypothesize that models with a separate contentand location-based attention are more likely to extrapolate than those with common attention mechanisms. We empirically support our claim for recurrent seq2seq models with our proposed attention on variants of the Lookup Table task . This sheds light on some striking failures of neural models for sequences and on possible methods to approaching such issues.","location attention extrapolation long sequence neural network surprisingly good interpolate perform remarkably training set example resemble test set . , unable extrapolate pattern see datum , abstraction require pattern simple . paper , review notion extrapolation , important , hope tackle . focus specific type extrapolation , especially useful natural language processing : generalization sequence long see training . hypothesize model separate contentand location - base attention likely extrapolate common attention mechanism . empirically support claim recurrent seq2seq model propose attention variant lookup table task . shed light striking failure neural model sequence possible method approach issue .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
Machine Translation and Multilinguality,On the Inference Calibration of Neural Machine Translation,"Confidence calibration, which aims to make model predictions equal to the true correctness measures, is important for neural machine translation (NMT) because it is able to offer useful indicators of translation errors in the generated output. While prior studies have shown that NMT models trained with label smoothing are well-calibrated on the groundtruth training data, we find that miscalibration still remains a severe challenge for NMT during inference due to the discrepancy between training and inference. By carefully designing experiments on three language pairs, our work provides in-depth analyses of the correlation between calibration and translation performance as well as linguistic properties of miscalibration and reports a number of interesting findings that might help humans better analyze, understand and improve NMT models. Based on these observations, we further propose a new graduated label smoothing method that can improve both inference calibration and translation performance. 1 * Work was done when Shuo Wang was interning at Tencent AI Lab under the Rhino-Bird Elite Training Program.","On the Inference Calibration of Neural Machine Translation Confidence calibration, which aims to make model predictions equal to the true correctness measures, is important for neural machine translation (NMT) because it is able to offer useful indicators of translation errors in the generated output. While prior studies have shown that NMT models trained with label smoothing are well-calibrated on the groundtruth training data, we find that miscalibration still remains a severe challenge for NMT during inference due to the discrepancy between training and inference. By carefully designing experiments on three language pairs, our work provides in-depth analyses of the correlation between calibration and translation performance as well as linguistic properties of miscalibration and reports a number of interesting findings that might help humans better analyze, understand and improve NMT models. Based on these observations, we further propose a new graduated label smoothing method that can improve both inference calibration and translation performance. 1 * Work was done when Shuo Wang was interning at Tencent AI Lab under the Rhino-Bird Elite Training Program.","inference calibration neural machine translation confidence calibration , aim model prediction equal true correctness measure , important neural machine translation ( nmt ) able offer useful indicator translation error generate output . prior study show nmt model train label smoothing - calibrate groundtruth training datum , find miscalibration remain severe challenge nmt inference discrepancy training inference . carefully design experiment language pair , work provide - depth analysis correlation calibration translation performance linguistic property miscalibration report number interesting finding help human well analyze , understand improve nmt model . base observation , propose new graduate label smooth method improve inference calibration translation performance . 1 * work shuo wang intern tencent ai lab rhino - bird elite training program .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Classification-Based Self-Learning for Weakly Supervised Bilingual Lexicon Induction,"Effective projection-based cross-lingual word embedding (CLWE) induction critically relies on the iterative self-learning procedure. It gradually expands the initial small seed dictionary to learn improved cross-lingual mappings. In this work, we present CLASSYMAP, a classification-based approach to self-learning, yielding a more robust and a more effective induction of projection-based CLWEs. Unlike prior self-learning methods, our approach allows for integration of diverse features into the iterative process. We show the benefits of CLASSYMAP for bilingual lexicon induction: we report consistent improvements in a weakly supervised setup (500 seed translation pairs) on a benchmark with 28 language pairs.","Classification-Based Self-Learning for Weakly Supervised Bilingual Lexicon Induction Effective projection-based cross-lingual word embedding (CLWE) induction critically relies on the iterative self-learning procedure. It gradually expands the initial small seed dictionary to learn improved cross-lingual mappings. In this work, we present CLASSYMAP, a classification-based approach to self-learning, yielding a more robust and a more effective induction of projection-based CLWEs. Unlike prior self-learning methods, our approach allows for integration of diverse features into the iterative process. We show the benefits of CLASSYMAP for bilingual lexicon induction: we report consistent improvements in a weakly supervised setup (500 seed translation pairs) on a benchmark with 28 language pairs.","classification - base self - learning weakly supervise bilingual lexicon induction effective projection - base cross - lingual word embedding ( clwe ) induction critically rely iterative self - learn procedure . gradually expand initial small seed dictionary learn improve cross - lingual mapping . work , present classymap , classification - base approach self - learning , yield robust effective induction projection - base clwe . unlike prior self - learn method , approach allow integration diverse feature iterative process . benefit classymap bilingual lexicon induction : report consistent improvement weakly supervised setup ( 500 seed translation pair ) benchmark 28 language pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Simultaneous Translation Policies: From Fixed to Adaptive,"Adaptive policies are better than fixed policies for simultaneous translation, since they can flexibly balance the tradeoff between translation quality and latency based on the current context information. But previous methods on obtaining adaptive policies either rely on complicated training process, or underperform simple fixed policies. We design an algorithm to achieve adaptive policies via a simple heuristic composition of a set of fixed policies. Experiments on Chineseâ†’English and Germanâ†’English show that our adaptive policies can outperform fixed ones by up to 4 BLEU points for the same latency, and more surprisingly, it even surpasses the BLEU score of full-sentence translation in the greedy mode (and very close to beam mode), but with much lower latency.","Simultaneous Translation Policies: From Fixed to Adaptive Adaptive policies are better than fixed policies for simultaneous translation, since they can flexibly balance the tradeoff between translation quality and latency based on the current context information. But previous methods on obtaining adaptive policies either rely on complicated training process, or underperform simple fixed policies. We design an algorithm to achieve adaptive policies via a simple heuristic composition of a set of fixed policies. Experiments on Chineseâ†’English and Germanâ†’English show that our adaptive policies can outperform fixed ones by up to 4 BLEU points for the same latency, and more surprisingly, it even surpasses the BLEU score of full-sentence translation in the greedy mode (and very close to beam mode), but with much lower latency.","simultaneous translation policy : fix adaptive adaptive policy well fix policy simultaneous translation , flexibly balance tradeoff translation quality latency base current context information . previous method obtain adaptive policy rely complicated training process , underperform simple fix policy . design algorithm achieve adaptive policy simple heuristic composition set fix policy . experiment chineseâ†’english germanâ†’english adaptive policy outperform fix one 4 bleu point latency , surprisingly , surpass bleu score - sentence translation greedy mode ( close beam mode ) , low latency .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Boosting Neural Machine Translation with Similar Translations,"This paper explores data augmentation methods for training Neural Machine Translation to make use of similar translations, in a comparable way a human translator employs fuzzy matches. In particular, we show how we can simply feed the neural model with information on both source and target sides of the fuzzy matches, we also extend the similarity to include semantically related translations retrieved using distributed sentence representations. We show that translations based on fuzzy matching provide the model with ""copy"" information while translations based on embedding similarities tend to extend the translation ""context"". Results indicate that the effect from both similar sentences are adding up to further boost accuracy, are combining naturally with model fine-tuning and are providing dynamic adaptation for unseen translation pairs. Tests on multiple data sets and domains show consistent accuracy improvements. To foster research around these techniques, we also release an Open-Source toolkit with efficient and flexible fuzzy-match implementation.","Boosting Neural Machine Translation with Similar Translations This paper explores data augmentation methods for training Neural Machine Translation to make use of similar translations, in a comparable way a human translator employs fuzzy matches. In particular, we show how we can simply feed the neural model with information on both source and target sides of the fuzzy matches, we also extend the similarity to include semantically related translations retrieved using distributed sentence representations. We show that translations based on fuzzy matching provide the model with ""copy"" information while translations based on embedding similarities tend to extend the translation ""context"". Results indicate that the effect from both similar sentences are adding up to further boost accuracy, are combining naturally with model fine-tuning and are providing dynamic adaptation for unseen translation pairs. Tests on multiple data sets and domains show consistent accuracy improvements. To foster research around these techniques, we also release an Open-Source toolkit with efficient and flexible fuzzy-match implementation.","boost neural machine translation similar translation paper explore data augmentation method train neural machine translation use similar translation , comparable way human translator employ fuzzy match . particular , simply feed neural model information source target side fuzzy match , extend similarity include semantically related translation retrieve distribute sentence representation . translation base fuzzy matching provide model "" copy "" information translation base embed similarity tend extend translation "" context "" . result indicate effect similar sentence add boost accuracy , combine naturally model fine - tuning provide dynamic adaptation unseen translation pair . test multiple data set domain consistent accuracy improvement . foster research technique , release open - source toolkit efficient flexible fuzzy - match implementation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 15, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,BPE-Dropout: Simple and Effective Subword Regularization,"Subword segmentation is widely used to address the open vocabulary problem in machine translation. The dominant approach to subword segmentation is Byte Pair Encoding (BPE), which keeps the most frequent words intact while splitting the rare ones into multiple tokens. While multiple segmentations are possible even with the same vocabulary, BPE splits words into unique sequences; this may prevent a model from better learning the compositionality of words and being robust to segmentation errors. So far, the only way to overcome this BPE imperfection, its deterministic nature, was to create another subword segmentation algorithm (Kudo, 2018) . In contrast, we show that BPE itself incorporates the ability to produce multiple segmentations of the same word. We introduce BPE-dropout -simple and effective subword regularization method based on and compatible with conventional BPE. It stochastically corrupts the segmentation procedure of BPE, which leads to producing multiple segmentations within the same fixed BPE framework. Using BPE-dropout during training and the standard BPE during inference improves translation quality up to 2.3 BLEU compared to BPE and up to 0.9 BLEU compared to the previous subword regularization.","BPE-Dropout: Simple and Effective Subword Regularization Subword segmentation is widely used to address the open vocabulary problem in machine translation. The dominant approach to subword segmentation is Byte Pair Encoding (BPE), which keeps the most frequent words intact while splitting the rare ones into multiple tokens. While multiple segmentations are possible even with the same vocabulary, BPE splits words into unique sequences; this may prevent a model from better learning the compositionality of words and being robust to segmentation errors. So far, the only way to overcome this BPE imperfection, its deterministic nature, was to create another subword segmentation algorithm (Kudo, 2018) . In contrast, we show that BPE itself incorporates the ability to produce multiple segmentations of the same word. We introduce BPE-dropout -simple and effective subword regularization method based on and compatible with conventional BPE. It stochastically corrupts the segmentation procedure of BPE, which leads to producing multiple segmentations within the same fixed BPE framework. Using BPE-dropout during training and the standard BPE during inference improves translation quality up to 2.3 BLEU compared to BPE and up to 0.9 BLEU compared to the previous subword regularization.","bpe - dropout : simple effective subword regularization subword segmentation widely address open vocabulary problem machine translation . dominant approach subword segmentation byte pair encoding ( bpe ) , keep frequent word intact split rare one multiple token . multiple segmentation possible vocabulary , bpe split word unique sequence ; prevent model well learn compositionality word robust segmentation error . far , way overcome bpe imperfection , deterministic nature , create subword segmentation algorithm ( kudo , 2018 ) . contrast , bpe incorporate ability produce multiple segmentation word . introduce bpe - dropout -simple effective subword regularization method base compatible conventional bpe . stochastically corrupt segmentation procedure bpe , lead produce multiple segmentation fix bpe framework . bpe - dropout training standard bpe inference improve translation quality 2.3 bleu compare bpe 0.9 bleu compare previous subword regularization .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 11, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Machine Translation and Multilinguality,"Worse WER, but Better BLEU? Leveraging Word Embedding as Intermediate in Multitask End-to-End Speech Translation","Speech translation (ST) aims to learn transformations from speech in the source language to the text in the target language. Previous works show that multitask learning improves the ST performance, in which the recognition decoder generates the text of the source language, and the translation decoder obtains the final translations based on the output of the recognition decoder. Because whether the output of the recognition decoder has the correct semantics is more critical than its accuracy, we propose to improve the multitask ST model by utilizing word embedding as the intermediate.","Worse WER, but Better BLEU? Leveraging Word Embedding as Intermediate in Multitask End-to-End Speech Translation Speech translation (ST) aims to learn transformations from speech in the source language to the text in the target language. Previous works show that multitask learning improves the ST performance, in which the recognition decoder generates the text of the source language, and the translation decoder obtains the final translations based on the output of the recognition decoder. Because whether the output of the recognition decoder has the correct semantics is more critical than its accuracy, we propose to improve the multitask ST model by utilizing word embedding as the intermediate.","bad wer , well bleu ? leverage word embedding intermediate multitask end - - end speech translation speech translation ( st ) aim learn transformation speech source language text target language . previous work multitask learning improve st performance , recognition decoder generate text source language , translation decoder obtain final translation base output recognition decoder . output recognition decoder correct semantic critical accuracy , propose improve multitask st model utilize word embedding intermediate .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 8, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Machine Translation and Multilinguality,Hard-Coded Gaussian Attention for Neural Machine Translation,"Recent work has questioned the importance of the Transformer's multi-headed attention for achieving high translation quality. We push further in this direction by developing a ""hardcoded"" attention variant without any learned parameters. Surprisingly, replacing all learned self-attention heads in the encoder and decoder with fixed, input-agnostic Gaussian distributions minimally impacts BLEU scores across four different language pairs. However, additionally hard-coding cross attention (which connects the decoder to the encoder) significantly lowers BLEU, suggesting that it is more important than self-attention. Much of this BLEU drop can be recovered by adding just a single learned cross attention head to an otherwise hard-coded Transformer. Taken as a whole, our results offer insight into which components of the Transformer are actually important, which we hope will guide future work into the development of simpler and more efficient attention-based models.","Hard-Coded Gaussian Attention for Neural Machine Translation Recent work has questioned the importance of the Transformer's multi-headed attention for achieving high translation quality. We push further in this direction by developing a ""hardcoded"" attention variant without any learned parameters. Surprisingly, replacing all learned self-attention heads in the encoder and decoder with fixed, input-agnostic Gaussian distributions minimally impacts BLEU scores across four different language pairs. However, additionally hard-coding cross attention (which connects the decoder to the encoder) significantly lowers BLEU, suggesting that it is more important than self-attention. Much of this BLEU drop can be recovered by adding just a single learned cross attention head to an otherwise hard-coded Transformer. Taken as a whole, our results offer insight into which components of the Transformer are actually important, which we hope will guide future work into the development of simpler and more efficient attention-based models.","hard - code gaussian attention neural machine translation recent work question importance transformer multi - headed attention achieve high translation quality . push direction develop "" hardcode "" attention variant learn parameter . surprisingly , replace learn self - attention head encoder decoder fix , input - agnostic gaussian distribution minimally impact bleu score different language pair . , additionally hard - code cross attention ( connect decoder encoder ) significantly lower bleu , suggest important self - attention . bleu drop recover add single learn cross attention head hard - code transformer . take , result offer insight component transformer actually important , hope guide future work development simple efficient attention - base model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 8, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 8, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,AdvAug: Robust Adversarial Augmentation for Neural Machine Translation,"In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT). The main idea is to minimize the vicinal risk over virtual sentences sampled from two vicinity distributions, of which the crucial one is a novel vicinity distribution for adversarial sentences that describes a smooth interpolated embedding space centered around observed training sentence pairs. We then discuss our approach, AdvAug, to train NMT models using the embeddings of virtual sentences in sequence-tosequence learning. Experiments on Chinese-English, English-French, and English-German translation benchmarks show that AdvAug achieves significant improvements over the Transformer (up to 4.9 BLEU points), and substantially outperforms other data augmentation techniques (e.g. back-translation) without using extra corpora.","AdvAug: Robust Adversarial Augmentation for Neural Machine Translation In this paper, we propose a new adversarial augmentation method for Neural Machine Translation (NMT). The main idea is to minimize the vicinal risk over virtual sentences sampled from two vicinity distributions, of which the crucial one is a novel vicinity distribution for adversarial sentences that describes a smooth interpolated embedding space centered around observed training sentence pairs. We then discuss our approach, AdvAug, to train NMT models using the embeddings of virtual sentences in sequence-tosequence learning. Experiments on Chinese-English, English-French, and English-German translation benchmarks show that AdvAug achieves significant improvements over the Transformer (up to 4.9 BLEU points), and substantially outperforms other data augmentation techniques (e.g. back-translation) without using extra corpora.","advaug : robust adversarial augmentation neural machine translation paper , propose new adversarial augmentation method neural machine translation ( nmt ) . main idea minimize vicinal risk virtual sentence sample vicinity distribution , crucial novel vicinity distribution adversarial sentence describe smooth interpolate embedding space center observe training sentence pair . discuss approach , advaug , train nmt model embedding virtual sentence sequence - tosequence learning . experiment chinese - english , english - french , english - german translation benchmark advaug achieve significant improvement transformer ( 4.9 bleu point ) , substantially outperform data augmentation technique ( e.g. - translation ) extra corpora .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Dynamically Adjusting Transformer Batch Size by Monitoring Gradient Direction Change,"The choice of hyper-parameters affects the performance of neural models. While much previous research (Sutskever et al., 2013; Duchi et al., 2011; Kingma and Ba, 2015) focuses on accelerating convergence and reducing the effects of the learning rate, comparatively few papers concentrate on the effect of batch size. In this paper, we analyze how increasing batch size affects gradient direction, and propose to evaluate the stability of gradients with their angle change. Based on our observations, the angle change of gradient direction first tends to stabilize (i.e. gradually decrease) while accumulating mini-batches, and then starts to fluctuate. We propose to automatically and dynamically determine batch sizes by accumulating gradients of mini-batches and performing an optimization step at just the time when the direction of gradients starts to fluctuate. To improve the efficiency of our approach for large models, we propose a sampling approach to select gradients of parameters sensitive to the batch size. Our approach dynamically determines proper and efficient batch sizes during training. In our experiments on the WMT 14 English to German and English to French tasks, our approach improves the Transformer with a fixed 25k batch size by +0.73 and +0.82 BLEU respectively.","Dynamically Adjusting Transformer Batch Size by Monitoring Gradient Direction Change The choice of hyper-parameters affects the performance of neural models. While much previous research (Sutskever et al., 2013; Duchi et al., 2011; Kingma and Ba, 2015) focuses on accelerating convergence and reducing the effects of the learning rate, comparatively few papers concentrate on the effect of batch size. In this paper, we analyze how increasing batch size affects gradient direction, and propose to evaluate the stability of gradients with their angle change. Based on our observations, the angle change of gradient direction first tends to stabilize (i.e. gradually decrease) while accumulating mini-batches, and then starts to fluctuate. We propose to automatically and dynamically determine batch sizes by accumulating gradients of mini-batches and performing an optimization step at just the time when the direction of gradients starts to fluctuate. To improve the efficiency of our approach for large models, we propose a sampling approach to select gradients of parameters sensitive to the batch size. Our approach dynamically determines proper and efficient batch sizes during training. In our experiments on the WMT 14 English to German and English to French tasks, our approach improves the Transformer with a fixed 25k batch size by +0.73 and +0.82 BLEU respectively.","dynamically adjust transformer batch size monitor gradient direction change choice hyper - parameter affect performance neural model . previous research ( sutskever et al . , 2013 ; duchi et al . , 2011 ; kingma ba , 2015 ) focus accelerate convergence reduce effect learning rate , comparatively paper concentrate effect batch size . paper , analyze increase batch size affect gradient direction , propose evaluate stability gradient angle change . base observation , angle change gradient direction tend stabilize ( i.e. gradually decrease ) accumulate mini - batch , start fluctuate . propose automatically dynamically determine batch size accumulate gradient mini - batch perform optimization step time direction gradient start fluctuate . improve efficiency approach large model , propose sampling approach select gradient parameter sensitive batch size . approach dynamically determine proper efficient batch size training . experiment wmt 14 english german english french task , approach improve transformer fix 25k batch size +0.73 +0.82 bleu respectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 9, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Machine Translation and Multilinguality,Enhancing Machine Translation with Dependency-Aware Self-Attention,"Most neural machine translation models only rely on pairs of parallel sentences, assuming syntactic information is automatically learned by an attention mechanism. In this work, we investigate different approaches to incorporate syntactic knowledge in the Transformer model and also propose a novel, parameter-free, dependency-aware self-attention mechanism that improves its translation quality, especially for long sentences and in low-resource scenarios. We show the efficacy of each approach on WMT Englishâ†”German and Englishâ†’Turkish, and WAT Englishâ†’Japanese translation tasks.","Enhancing Machine Translation with Dependency-Aware Self-Attention Most neural machine translation models only rely on pairs of parallel sentences, assuming syntactic information is automatically learned by an attention mechanism. In this work, we investigate different approaches to incorporate syntactic knowledge in the Transformer model and also propose a novel, parameter-free, dependency-aware self-attention mechanism that improves its translation quality, especially for long sentences and in low-resource scenarios. We show the efficacy of each approach on WMT Englishâ†”German and Englishâ†’Turkish, and WAT Englishâ†’Japanese translation tasks.","enhance machine translation dependency - aware self - attention neural machine translation model rely pair parallel sentence , assume syntactic information automatically learn attention mechanism . work , investigate different approach incorporate syntactic knowledge transformer model propose novel , parameter - free , dependency - aware self - attention mechanism improve translation quality , especially long sentence low - resource scenario . efficacy approach wmt englishâ†”german englishâ†’turkish , wat englishâ†’japanese translation task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Character-Level Translation with Self-attention,"We explore the suitability of self-attention models for character-level neural machine translation. We test the standard transformer model, as well as a novel variant in which the encoder block combines information from nearby characters using convolutions. We perform extensive experiments on WMT and UN datasets, testing both bilingual and multilingual translation to English using up to three input languages (French, Spanish, and Chinese). Our transformer variant consistently outperforms the standard transformer at the character-level and converges faster while learning more robust character-level alignments. 1","Character-Level Translation with Self-attention We explore the suitability of self-attention models for character-level neural machine translation. We test the standard transformer model, as well as a novel variant in which the encoder block combines information from nearby characters using convolutions. We perform extensive experiments on WMT and UN datasets, testing both bilingual and multilingual translation to English using up to three input languages (French, Spanish, and Chinese). Our transformer variant consistently outperforms the standard transformer at the character-level and converges faster while learning more robust character-level alignments. 1","character - level translation self - attention explore suitability self - attention model character - level neural machine translation . test standard transformer model , novel variant encoder block combine information nearby character convolution . perform extensive experiment wmt un dataset , test bilingual multilingual translation english input language ( french , spanish , chinese ) . transformer variant consistently outperform standard transformer character - level converge fast learn robust character - level alignment . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 12, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,Tagged Back-translation Revisited: Why Does It Really Work?,"In this paper, we show that neural machine translation (NMT) systems trained on large back-translated data overfit some of the characteristics of machine-translated texts. Such NMT systems better translate humanproduced translations, i.e., translationese, but may largely worsen the translation quality of original texts. Our analysis reveals that adding a simple tag to back-translations prevents this quality degradation and improves on average the overall translation quality by helping the NMT system to distinguish back-translated data from original parallel data during training. We also show that, in contrast to high-resource configurations, NMT systems trained in lowresource settings are much less vulnerable to overfit back-translations. We conclude that the back-translations in the training data should always be tagged especially when the origin of the text to be translated is unknown.","Tagged Back-translation Revisited: Why Does It Really Work? In this paper, we show that neural machine translation (NMT) systems trained on large back-translated data overfit some of the characteristics of machine-translated texts. Such NMT systems better translate humanproduced translations, i.e., translationese, but may largely worsen the translation quality of original texts. Our analysis reveals that adding a simple tag to back-translations prevents this quality degradation and improves on average the overall translation quality by helping the NMT system to distinguish back-translated data from original parallel data during training. We also show that, in contrast to high-resource configurations, NMT systems trained in lowresource settings are much less vulnerable to overfit back-translations. We conclude that the back-translations in the training data should always be tagged especially when the origin of the text to be translated is unknown.","tag - translation revisit : work ? paper , neural machine translation ( nmt ) system train large - translate datum overfit characteristic machine - translate text . nmt system well translate humanproduced translation , i.e. , translationese , largely worsen translation quality original text . analysis reveal add simple tag - translation prevent quality degradation improve average overall translation quality help nmt system distinguish - translate datum original parallel datum training . , contrast high - resource configuration , nmt system train lowresource setting vulnerable overfit - translation . conclude - translation training datum tag especially origin text translate unknown .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 19, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Unsupervised Word Translation with Adversarial Autoencoder,"Crosslingual word embeddings learned from monolingual embeddings have a crucial role in many downstream tasks, ranging from machine translation to transfer learning. Adversarial training has shown impressive success in learning crosslingual embeddings and the associated word translation task without any parallel data by mapping monolingual embeddings to a shared space. However, recent work has shown superior performance for non-adversarial methods in more challenging language pairs. In this article, we investigate adversarial autoencoder for unsupervised word translation and propose two novel extensions to it that yield more stable training and improved results. Our method includes regularization terms to enforce cycle consistency and input reconstruction, and puts the target encoders as an adversary against the corresponding discriminator. We use two types of refinement procedures sequentially after obtaining the trained encoders and mappings from the adversarial training, namely, refinement with Procrustes solution and refinement with symmetric re-weighting. Extensive experimentations with high-and low-resource languages from two different data sets show that our method achieves better performance than existing adversarial and non-adversarial approaches and is also competitive with the supervised system. Along with performing comprehensive ablation studies to understand the contribution of different components of our adversarial model, we also conduct a thorough analysis of the refinement procedures to understand their effects.","Unsupervised Word Translation with Adversarial Autoencoder Crosslingual word embeddings learned from monolingual embeddings have a crucial role in many downstream tasks, ranging from machine translation to transfer learning. Adversarial training has shown impressive success in learning crosslingual embeddings and the associated word translation task without any parallel data by mapping monolingual embeddings to a shared space. However, recent work has shown superior performance for non-adversarial methods in more challenging language pairs. In this article, we investigate adversarial autoencoder for unsupervised word translation and propose two novel extensions to it that yield more stable training and improved results. Our method includes regularization terms to enforce cycle consistency and input reconstruction, and puts the target encoders as an adversary against the corresponding discriminator. We use two types of refinement procedures sequentially after obtaining the trained encoders and mappings from the adversarial training, namely, refinement with Procrustes solution and refinement with symmetric re-weighting. Extensive experimentations with high-and low-resource languages from two different data sets show that our method achieves better performance than existing adversarial and non-adversarial approaches and is also competitive with the supervised system. Along with performing comprehensive ablation studies to understand the contribution of different components of our adversarial model, we also conduct a thorough analysis of the refinement procedures to understand their effects.","unsupervised word translation adversarial autoencoder crosslingual word embedding learn monolingual embedding crucial role downstream task , range machine translation transfer learning . adversarial training show impressive success learn crosslingual embedding associate word translation task parallel datum map monolingual embedding share space . , recent work show superior performance non - adversarial method challenging language pair . article , investigate adversarial autoencoder unsupervised word translation propose novel extension yield stable training improved result . method include regularization term enforce cycle consistency input reconstruction , put target encoder adversary correspond discriminator . use type refinement procedure sequentially obtain train encoder mapping adversarial training , , refinement procrustes solution refinement symmetric - weighting . extensive experimentation high - low - resource language different data set method achieve well performance exist adversarial non - adversarial approach competitive supervise system . perform comprehensive ablation study understand contribution different component adversarial model , conduct thorough analysis refinement procedure understand effect .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Variational Neural Machine Translation with Normalizing Flows,"Variational Neural Machine Translation (VNMT) is an attractive framework for modeling the generation of target translations, conditioned not only on the source sentence but also on some latent random variables. The latent variable modeling may introduce useful statistical dependencies that can improve translation accuracy. Unfortunately, learning informative latent variables is non-trivial, as the latent space can be prohibitively large, and the latent codes are prone to be ignored by many translation models at training time. Previous works impose strong assumptions on the distribution of the latent code and limit the choice of the NMT architecture. In this paper, we propose to apply the VNMT framework to the state-of-the-art Transformer and introduce a more flexible approximate posterior based on normalizing flows. We demonstrate the efficacy of our proposal under both in-domain and out-of-domain conditions, significantly outperforming strong baselines.","Variational Neural Machine Translation with Normalizing Flows Variational Neural Machine Translation (VNMT) is an attractive framework for modeling the generation of target translations, conditioned not only on the source sentence but also on some latent random variables. The latent variable modeling may introduce useful statistical dependencies that can improve translation accuracy. Unfortunately, learning informative latent variables is non-trivial, as the latent space can be prohibitively large, and the latent codes are prone to be ignored by many translation models at training time. Previous works impose strong assumptions on the distribution of the latent code and limit the choice of the NMT architecture. In this paper, we propose to apply the VNMT framework to the state-of-the-art Transformer and introduce a more flexible approximate posterior based on normalizing flows. We demonstrate the efficacy of our proposal under both in-domain and out-of-domain conditions, significantly outperforming strong baselines.","variational neural machine translation normalize flow variational neural machine translation ( vnmt ) attractive framework model generation target translation , condition source sentence latent random variable . latent variable modeling introduce useful statistical dependency improve translation accuracy . unfortunately , learn informative latent variable non - trivial , latent space prohibitively large , latent code prone ignore translation model training time . previous work impose strong assumption distribution latent code limit choice nmt architecture . paper , propose apply vnmt framework state - - - art transformer introduce flexible approximate posterior base normalize flow . demonstrate efficacy proposal - domain - - domain condition , significantly outperform strong baseline .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,End-to-End Neural Word Alignment Outperforms GIZA++,"Word alignment was once a core unsupervised learning task in natural language processing because of its essential role in training statistical machine translation (MT) models. Although unnecessary for training neural MT models, word alignment still plays an important role in interactive applications of neural machine translation, such as annotation transfer and lexicon injection. While statistical MT methods have been replaced by neural approaches with superior performance, the twenty-year-old GIZA++ toolkit remains a key component of state-of-the-art word alignment systems. Prior work on neural word alignment has only been able to outperform GIZA++ by using its output during training. We present the first end-to-end neural word alignment method that consistently outperforms GIZA++ on three data sets. Our approach repurposes a Transformer model trained for supervised translation to also serve as an unsupervised word alignment model in a manner that is tightly integrated and does not affect translation quality.","End-to-End Neural Word Alignment Outperforms GIZA++ Word alignment was once a core unsupervised learning task in natural language processing because of its essential role in training statistical machine translation (MT) models. Although unnecessary for training neural MT models, word alignment still plays an important role in interactive applications of neural machine translation, such as annotation transfer and lexicon injection. While statistical MT methods have been replaced by neural approaches with superior performance, the twenty-year-old GIZA++ toolkit remains a key component of state-of-the-art word alignment systems. Prior work on neural word alignment has only been able to outperform GIZA++ by using its output during training. We present the first end-to-end neural word alignment method that consistently outperforms GIZA++ on three data sets. Our approach repurposes a Transformer model trained for supervised translation to also serve as an unsupervised word alignment model in a manner that is tightly integrated and does not affect translation quality.","end - - end neural word alignment outperform giza++ word alignment core unsupervised learning task natural language processing essential role train statistical machine translation ( mt ) model . unnecessary train neural mt model , word alignment play important role interactive application neural machine translation , annotation transfer lexicon injection . statistical mt method replace neural approach superior performance , - year - old giza++ toolkit remain key component state - - - art word alignment system . prior work neural word alignment able outperform giza++ output training . present end - - end neural word alignment method consistently outperform giza++ data set . approach repurpose transformer model train supervise translation serve unsupervised word alignment model manner tightly integrate affect translation quality .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem,"Training data for NLP tasks often exhibits gender bias in that fewer sentences refer to women than to men. In Neural Machine Translation (NMT) gender bias has been shown to reduce translation quality, particularly when the target language has grammatical gender. The recent WinoMT challenge set allows us to measure this effect directly (Stanovsky et al., 2019) . Ideally we would reduce system bias by simply debiasing all data prior to training, but achieving this effectively is itself a challenge. Rather than attempt to create a 'balanced' dataset, we use transfer learning on a small set of trusted, gender-balanced examples. This approach gives strong and consistent improvements in gender debiasing with much less computational cost than training from scratch. A known pitfall of transfer learning on new domains is 'catastrophic forgetting', which we address both in adaptation and in inference. During adaptation we show that Elastic Weight Consolidation allows a performance trade-off between general translation quality and bias reduction. During inference we propose a latticerescoring scheme which outperforms all systems evaluated in Stanovsky et al. (2019) on WinoMT with no degradation of general test set BLEU, and we show this scheme can be applied to remove gender bias in the output of 'black box' online commercial MT systems. We demonstrate our approach translating from English into three languages with varied linguistic properties and data availability.","Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem Training data for NLP tasks often exhibits gender bias in that fewer sentences refer to women than to men. In Neural Machine Translation (NMT) gender bias has been shown to reduce translation quality, particularly when the target language has grammatical gender. The recent WinoMT challenge set allows us to measure this effect directly (Stanovsky et al., 2019) . Ideally we would reduce system bias by simply debiasing all data prior to training, but achieving this effectively is itself a challenge. Rather than attempt to create a 'balanced' dataset, we use transfer learning on a small set of trusted, gender-balanced examples. This approach gives strong and consistent improvements in gender debiasing with much less computational cost than training from scratch. A known pitfall of transfer learning on new domains is 'catastrophic forgetting', which we address both in adaptation and in inference. During adaptation we show that Elastic Weight Consolidation allows a performance trade-off between general translation quality and bias reduction. During inference we propose a latticerescoring scheme which outperforms all systems evaluated in Stanovsky et al. (2019) on WinoMT with no degradation of general test set BLEU, and we show this scheme can be applied to remove gender bias in the output of 'black box' online commercial MT systems. We demonstrate our approach translating from English into three languages with varied linguistic properties and data availability.","reduce gender bias neural machine translation domain adaptation problem training data nlp task exhibit gender bias few sentence refer woman man . neural machine translation ( nmt ) gender bias show reduce translation quality , particularly target language grammatical gender . recent winomt challenge set allow measure effect directly ( stanovsky et al . , 2019 ) . ideally reduce system bias simply debiase datum prior training , achieve effectively challenge . attempt create ' balanced ' dataset , use transfer learning small set trust , gender - balanced example . approach give strong consistent improvement gender debiasing computational cost train scratch . know pitfall transfer learning new domain ' catastrophic forgetting ' , address adaptation inference . adaptation elastic weight consolidation allow performance trade - general translation quality bias reduction . inference propose latticerescoring scheme outperform system evaluate stanovsky et al . ( 2019 ) winomt degradation general test set bleu , scheme apply remove gender bias output ' black box ' online commercial mt system . demonstrate approach translate english language varied linguistic property data availability .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 21, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 7, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Machine Translation and Multilinguality,Multiscale Collaborative Deep Models for Neural Machine Translation,"Recent evidence reveals that Neural Machine Translation (NMT) models with deeper neural networks can be more effective but are difficult to train. In this paper, we present a MultiScale Collaborative (MSC) framework to ease the training of NMT models that are substantially deeper than those used previously. We explicitly boost the gradient backpropagation from top to bottom levels by introducing a block-scale collaboration mechanism into deep NMT models. Then, instead of forcing the whole encoder stack directly learns a desired representation, we let each encoder block learns a fine-grained representation and enhance it by encoding spatial dependencies using a context-scale collaboration. We provide empirical evidence showing that the MSC nets are easy to optimize and can obtain improvements of translation quality from considerably increased depth. On IWSLT translation tasks with three translation directions, our extremely deep models (with 72-layer encoders) surpass strong baselines by +2.2âˆ¼+3.1 BLEU points. In addition, our deep MSC achieves a BLEU score of 30.56 on WMT14 Englishâ†’German task that significantly outperforms state-of-the-art deep NMT models.","Multiscale Collaborative Deep Models for Neural Machine Translation Recent evidence reveals that Neural Machine Translation (NMT) models with deeper neural networks can be more effective but are difficult to train. In this paper, we present a MultiScale Collaborative (MSC) framework to ease the training of NMT models that are substantially deeper than those used previously. We explicitly boost the gradient backpropagation from top to bottom levels by introducing a block-scale collaboration mechanism into deep NMT models. Then, instead of forcing the whole encoder stack directly learns a desired representation, we let each encoder block learns a fine-grained representation and enhance it by encoding spatial dependencies using a context-scale collaboration. We provide empirical evidence showing that the MSC nets are easy to optimize and can obtain improvements of translation quality from considerably increased depth. On IWSLT translation tasks with three translation directions, our extremely deep models (with 72-layer encoders) surpass strong baselines by +2.2âˆ¼+3.1 BLEU points. In addition, our deep MSC achieves a BLEU score of 30.56 on WMT14 Englishâ†’German task that significantly outperforms state-of-the-art deep NMT models.","multiscale collaborative deep models neural machine translation recent evidence reveal neural machine translation ( nmt ) model deep neural network effective difficult train . paper , present multiscale collaborative ( msc ) framework ease training nmt model substantially deep previously . explicitly boost gradient backpropagation level introduce block - scale collaboration mechanism deep nmt model . , instead force encoder stack directly learn desire representation , let encoder block learn fine - grained representation enhance encode spatial dependency context - scale collaboration . provide empirical evidence show msc net easy optimize obtain improvement translation quality considerably increase depth . iwslt translation task translation direction , extremely deep model ( 72 - layer encoder ) surpass strong baseline +2.2âˆ¼+3.1 bleu point . addition , deep msc achieve bleu score 30.56 wmt14 englishâ†’german task significantly outperform state - - - art deep nmt model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 24, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation,"Multi-modal neural machine translation (NMT) aims to translate source sentences into a target language paired with images. However, dominant multi-modal NMT models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have potential to refine multi-modal representation learning. To deal with this issue, in this paper, we propose a novel graph-based multi-modal fusion encoder for NMT. Specifically, we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units (words and visual objects). We then stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations. Finally, these representations provide an attention-based context vector for the decoder. We evaluate our proposed encoder on the Multi30K datasets. Experimental results and in-depth analysis show the superiority of our multi-modal NMT model.","A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation Multi-modal neural machine translation (NMT) aims to translate source sentences into a target language paired with images. However, dominant multi-modal NMT models do not fully exploit fine-grained semantic correspondences between semantic units of different modalities, which have potential to refine multi-modal representation learning. To deal with this issue, in this paper, we propose a novel graph-based multi-modal fusion encoder for NMT. Specifically, we first represent the input sentence and image using a unified multi-modal graph, which captures various semantic relationships between multi-modal semantic units (words and visual objects). We then stack multiple graph-based multi-modal fusion layers that iteratively perform semantic interactions to learn node representations. Finally, these representations provide an attention-based context vector for the decoder. We evaluate our proposed encoder on the Multi30K datasets. Experimental results and in-depth analysis show the superiority of our multi-modal NMT model.","novel graph - base multi - modal fusion encoder neural machine translation multi - modal neural machine translation ( nmt ) aim translate source sentence target language pair image . , dominant multi - modal nmt model fully exploit fine - grained semantic correspondence semantic unit different modality , potential refine multi - modal representation learning . deal issue , paper , propose novel graph - base multi - modal fusion encoder nmt . specifically , represent input sentence image unify multi - modal graph , capture semantic relationship multi - modal semantic unit ( word visual object ) . stack multiple graph - base multi - modal fusion layer iteratively perform semantic interaction learn node representation . finally , representation provide attention - base context vector decoder . evaluate propose encoder multi30 k dataset . experimental result - depth analysis superiority multi - modal nmt model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Successfully Applying the Stabilized Lottery Ticket Hypothesis to the Transformer Architecture,"Sparse models require less memory for storage and enable a faster inference by reducing the necessary number of FLOPs. This is relevant both for time-critical and on-device computations using neural networks. The stabilized lottery ticket hypothesis states that networks can be pruned after none or few training iterations, using a mask computed based on the unpruned converged model. On the transformer architecture and the WMT 2014 Englishâ†’German and Englishâ†’French tasks, we show that stabilized lottery ticket pruning performs similar to magnitude pruning for sparsity levels of up to 85%, and propose a new combination of pruning techniques that outperforms all other techniques for even higher levels of sparsity. Furthermore, we confirm that the parameter's initial sign and not its specific value is the primary factor for successful training, and show that magnitude pruning cannot be used to find winning lottery tickets.","Successfully Applying the Stabilized Lottery Ticket Hypothesis to the Transformer Architecture Sparse models require less memory for storage and enable a faster inference by reducing the necessary number of FLOPs. This is relevant both for time-critical and on-device computations using neural networks. The stabilized lottery ticket hypothesis states that networks can be pruned after none or few training iterations, using a mask computed based on the unpruned converged model. On the transformer architecture and the WMT 2014 Englishâ†’German and Englishâ†’French tasks, we show that stabilized lottery ticket pruning performs similar to magnitude pruning for sparsity levels of up to 85%, and propose a new combination of pruning techniques that outperforms all other techniques for even higher levels of sparsity. Furthermore, we confirm that the parameter's initial sign and not its specific value is the primary factor for successful training, and show that magnitude pruning cannot be used to find winning lottery tickets.","successfully apply stabilize lottery ticket hypothesis transformer architecture sparse model require memory storage enable fast inference reduce necessary number flop . relevant time - critical - device computation neural network . stabilize lottery ticket hypothesis state network prune training iteration , mask compute base unpruned converge model . transformer architecture wmt 2014 englishâ†’german englishâ†’french task , stabilize lottery ticket pruning perform similar magnitude pruning sparsity level 85 % , propose new combination pruning technique outperform technique high level sparsity . furthermore , confirm parameter initial sign specific value primary factor successful training , magnitude pruning find win lottery ticket .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,Balancing Training for Multilingual Neural Machine Translation,"When training multilingual machine translation (MT) models that can translate to/from multiple languages, we are faced with imbalanced training sets: some languages have much more training data than others. Standard practice is to up-sample less resourced languages to increase representation, and the degree of up-sampling has a large effect on the overall performance. In this paper, we propose a method that instead automatically learns how to weight training data through a data scorer that is optimized to maximize performance on all test languages. Experiments on two sets of languages under both one-to-many and manyto-one MT settings show our method not only consistently outperforms heuristic baselines in terms of average performance, but also offers flexible control over the performance of which languages are optimized. 1","Balancing Training for Multilingual Neural Machine Translation When training multilingual machine translation (MT) models that can translate to/from multiple languages, we are faced with imbalanced training sets: some languages have much more training data than others. Standard practice is to up-sample less resourced languages to increase representation, and the degree of up-sampling has a large effect on the overall performance. In this paper, we propose a method that instead automatically learns how to weight training data through a data scorer that is optimized to maximize performance on all test languages. Experiments on two sets of languages under both one-to-many and manyto-one MT settings show our method not only consistently outperforms heuristic baselines in terms of average performance, but also offers flexible control over the performance of which languages are optimized. 1","balancing training multilingual neural machine translation train multilingual machine translation ( mt ) model translate / multiple language , face imbalanced training set : language training datum . standard practice - sample resource language increase representation , degree - sampling large effect overall performance . paper , propose method instead automatically learn weight training datum data scorer optimize maximize performance test language . experiment set language - - manyto - mt setting method consistently outperform heuristic baseline term average performance , offer flexible control performance language optimize . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Reinforced Generation of Adversarial Examples for Neural Machine Translation,"Neural machine translation systems tend to fail on less decent inputs despite its significant efficacy, which may significantly harm the credibility of these systems-fathoming how and when neural-based systems fail in such cases is critical for industrial maintenance. Instead of collecting and analyzing bad cases using limited handcrafted error features, here we investigate this issue by generating adversarial examples via a new paradigm based on reinforcement learning. Our paradigm could expose pitfalls for a given performance metric, e.g., BLEU, and could target any given neural machine translation architecture. We conduct experiments of adversarial attacks on two mainstream neural machine translation architectures, RNN-search, and Transformer. The results show that our method efficiently produces stable attacks with meaning-preserving adversarial examples. We also present a qualitative and quantitative analysis for the preference pattern of the attack, demonstrating its capability of pitfall exposure.","A Reinforced Generation of Adversarial Examples for Neural Machine Translation Neural machine translation systems tend to fail on less decent inputs despite its significant efficacy, which may significantly harm the credibility of these systems-fathoming how and when neural-based systems fail in such cases is critical for industrial maintenance. Instead of collecting and analyzing bad cases using limited handcrafted error features, here we investigate this issue by generating adversarial examples via a new paradigm based on reinforcement learning. Our paradigm could expose pitfalls for a given performance metric, e.g., BLEU, and could target any given neural machine translation architecture. We conduct experiments of adversarial attacks on two mainstream neural machine translation architectures, RNN-search, and Transformer. The results show that our method efficiently produces stable attacks with meaning-preserving adversarial examples. We also present a qualitative and quantitative analysis for the preference pattern of the attack, demonstrating its capability of pitfall exposure.","reinforce generation adversarial example neural machine translation neural machine translation system tend fail decent input despite significant efficacy , significantly harm credibility system - fathom neural - base system fail case critical industrial maintenance . instead collect analyze bad case limited handcraft error feature , investigate issue generate adversarial example new paradigm base reinforcement learning . paradigm expose pitfall give performance metric , e.g. , bleu , target give neural machine translation architecture . conduct experiment adversarial attack mainstream neural machine translation architecture , rnn - search , transformer . result method efficiently produce stable attack meaning - preserve adversarial example . present qualitative quantitative analysis preference pattern attack , demonstrate capability pitfall exposure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Relaxed Matching Procedure for Unsupervised BLI,"Recently unsupervised Bilingual Lexicon Induction(BLI) without any parallel corpus has attracted much research interest. One of the crucial parts in methods for the BLI task is the matching procedure. Previous works impose a too strong constraint on the matching and lead to many counterintuitive translation pairings. Thus, We propose a relaxed matching procedure to find a more precise matching between two languages. We also find that aligning source and target language embedding space bidirectionally will bring significant improvement. We follow the previous iterative framework to conduct experiments. Results on standard benchmark demonstrate the effectiveness of our proposed method, which substantially outperforms previous unsupervised methods.","A Relaxed Matching Procedure for Unsupervised BLI Recently unsupervised Bilingual Lexicon Induction(BLI) without any parallel corpus has attracted much research interest. One of the crucial parts in methods for the BLI task is the matching procedure. Previous works impose a too strong constraint on the matching and lead to many counterintuitive translation pairings. Thus, We propose a relaxed matching procedure to find a more precise matching between two languages. We also find that aligning source and target language embedding space bidirectionally will bring significant improvement. We follow the previous iterative framework to conduct experiments. Results on standard benchmark demonstrate the effectiveness of our proposed method, which substantially outperforms previous unsupervised methods.","relaxed matching procedure unsupervised bli recently unsupervised bilingual lexicon induction(bli ) parallel corpus attract research interest . crucial part method bli task matching procedure . previous work impose strong constraint matching lead counterintuitive translation pairing . , propose relaxed matching procedure find precise matching language . find align source target language embedding space bidirectionally bring significant improvement . follow previous iterative framework conduct experiment . result standard benchmark demonstrate effectiveness propose method , substantially outperform previous unsupervised method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Machine Translation and Multilinguality,Contextual Neural Machine Translation Improves Translation of Cataphoric Pronouns,"The advent of context-aware NMT has resulted in promising improvements in the overall translation quality and specifically in the translation of discourse phenomena such as pronouns. Previous works have mainly focused on the use of past sentences as context with a focus on anaphora translation. In this work, we investigate the effect of future sentences as context by comparing the performance of a contextual NMT model trained with the future context to the one trained with the past context. Our experiments and evaluation, using generic and pronoun-focused automatic metrics, show that the use of future context not only achieves significant improvements over the context-agnostic Transformer, but also demonstrates comparable and in some cases improved performance over its counterpart trained on past context. We also perform an evaluation on a targeted cataphora test suite and report significant gains over the contextagnostic Transformer in terms of BLEU.","Contextual Neural Machine Translation Improves Translation of Cataphoric Pronouns The advent of context-aware NMT has resulted in promising improvements in the overall translation quality and specifically in the translation of discourse phenomena such as pronouns. Previous works have mainly focused on the use of past sentences as context with a focus on anaphora translation. In this work, we investigate the effect of future sentences as context by comparing the performance of a contextual NMT model trained with the future context to the one trained with the past context. Our experiments and evaluation, using generic and pronoun-focused automatic metrics, show that the use of future context not only achieves significant improvements over the context-agnostic Transformer, but also demonstrates comparable and in some cases improved performance over its counterpart trained on past context. We also perform an evaluation on a targeted cataphora test suite and report significant gains over the contextagnostic Transformer in terms of BLEU.","contextual neural machine translation improve translation cataphoric pronoun advent context - aware nmt result promising improvement overall translation quality specifically translation discourse phenomenon pronoun . previous work mainly focus use past sentence context focus anaphora translation . work , investigate effect future sentence context compare performance contextual nmt model train future context train past context . experiment evaluation , generic pronoun - focus automatic metric , use future context achieve significant improvement context - agnostic transformer , demonstrate comparable case improved performance counterpart train past context . perform evaluation targeted cataphora test suite report significant gain contextagnostic transformer term bleu .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences,"In this paper, we propose a new task of machine translation (MT), which is based on no parallel sentences but can refer to a groundtruth bilingual dictionary. Motivated by the ability of a monolingual speaker learning to translate via looking up the bilingual dictionary, we propose the task to see how much potential an MT system can attain using the bilingual dictionary and large scale monolingual corpora, while is independent on parallel sentences. We propose anchored training (AT) to tackle the task. AT uses the bilingual dictionary to establish anchoring points for closing the gap between source language and target language. Experiments on various language pairs show that our approaches are significantly better than various baselines, including dictionary-based word-byword translation, dictionary-supervised crosslingual word embedding transformation, and unsupervised MT. On distant language pairs that are hard for unsupervised MT to perform well, AT performs remarkably better, achieving performances comparable to supervised SMT trained on more than 4M parallel sentences 1 .","Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences In this paper, we propose a new task of machine translation (MT), which is based on no parallel sentences but can refer to a groundtruth bilingual dictionary. Motivated by the ability of a monolingual speaker learning to translate via looking up the bilingual dictionary, we propose the task to see how much potential an MT system can attain using the bilingual dictionary and large scale monolingual corpora, while is independent on parallel sentences. We propose anchored training (AT) to tackle the task. AT uses the bilingual dictionary to establish anchoring points for closing the gap between source language and target language. Experiments on various language pairs show that our approaches are significantly better than various baselines, including dictionary-based word-byword translation, dictionary-supervised crosslingual word embedding transformation, and unsupervised MT. On distant language pairs that are hard for unsupervised MT to perform well, AT performs remarkably better, achieving performances comparable to supervised SMT trained on more than 4M parallel sentences 1 .","bilingual dictionary base neural machine translation parallel sentence paper , propose new task machine translation ( mt ) , base parallel sentence refer groundtruth bilingual dictionary . motivate ability monolingual speaker learn translate look bilingual dictionary , propose task potential mt system attain bilingual dictionary large scale monolingual corpora , independent parallel sentence . propose anchor training ( ) tackle task . use bilingual dictionary establish anchoring point close gap source language target language . experiment language pair approach significantly well baseline , include dictionary - base word - byword translation , dictionary - supervise crosslingual word embedding transformation , unsupervised mt . distant language pair hard unsupervised mt perform , perform remarkably well , achieve performance comparable supervise smt train 4 m parallel sentence 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 7, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Learning Source Phrase Representations for Neural Machine Translation,"The Transformer translation model (Vaswani et al., 2017) based on a multi-head attention mechanism can be computed effectively in parallel and has significantly pushed forward the performance of Neural Machine Translation (NMT). Though intuitively the attentional network can connect distant words via shorter network paths than RNNs, empirical analysis demonstrates that it still has difficulty in fully capturing long-distance dependencies (Tang et al., 2018) . Considering that modeling phrases instead of words has significantly improved the Statistical Machine Translation (SMT) approach through the use of larger translation blocks (""phrases"") and its reordering ability, modeling NMT at phrase level is an intuitive proposal to help the model capture long-distance relationships. In this paper, we first propose an attentive phrase representation generation mechanism which is able to generate phrase representations from corresponding token representations. In addition, we incorporate the generated phrase representations into the Transformer translation model to enhance its ability to capture long-distance relationships. In our experiments, we obtain significant improvements on the WMT 14 English-German and English-French tasks on top of the strong Transformer baseline, which shows the effectiveness of our approach. Our approach helps Transformer Base models perform at the level of Transformer Big models, and even significantly better for long sentences, but with substantially fewer parameters and training steps. The fact that phrase representations help even in the big setting further supports our conjecture that they make a valuable contribution to long-distance relations.","Learning Source Phrase Representations for Neural Machine Translation The Transformer translation model (Vaswani et al., 2017) based on a multi-head attention mechanism can be computed effectively in parallel and has significantly pushed forward the performance of Neural Machine Translation (NMT). Though intuitively the attentional network can connect distant words via shorter network paths than RNNs, empirical analysis demonstrates that it still has difficulty in fully capturing long-distance dependencies (Tang et al., 2018) . Considering that modeling phrases instead of words has significantly improved the Statistical Machine Translation (SMT) approach through the use of larger translation blocks (""phrases"") and its reordering ability, modeling NMT at phrase level is an intuitive proposal to help the model capture long-distance relationships. In this paper, we first propose an attentive phrase representation generation mechanism which is able to generate phrase representations from corresponding token representations. In addition, we incorporate the generated phrase representations into the Transformer translation model to enhance its ability to capture long-distance relationships. In our experiments, we obtain significant improvements on the WMT 14 English-German and English-French tasks on top of the strong Transformer baseline, which shows the effectiveness of our approach. Our approach helps Transformer Base models perform at the level of Transformer Big models, and even significantly better for long sentences, but with substantially fewer parameters and training steps. The fact that phrase representations help even in the big setting further supports our conjecture that they make a valuable contribution to long-distance relations.","learn source phrase representation neural machine translation transformer translation model ( vaswani et al . , 2017 ) base multi - head attention mechanism compute effectively parallel significantly push forward performance neural machine translation ( nmt ) . intuitively attentional network connect distant word short network path rnn , empirical analysis demonstrate difficulty fully capture long - distance dependency ( tang et al . , 2018 ) . consider model phrase instead word significantly improve statistical machine translation ( smt ) approach use large translation block ( "" phrase "" ) reordering ability , model nmt phrase level intuitive proposal help model capture long - distance relationship . paper , propose attentive phrase representation generation mechanism able generate phrase representation correspond token representation . addition , incorporate generate phrase representation transformer translation model enhance ability capture long - distance relationship . experiment , obtain significant improvement wmt 14 english - german english - french task strong transformer baseline , show effectiveness approach . approach help transformer base model perform level transformer big model , significantly well long sentence , substantially few parameter training step . fact phrase representation help big setting support conjecture valuable contribution long - distance relation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 16, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation,"Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both oneto-many and many-to-many settings, and improves zero-shot performance by âˆ¼10 BLEU, approaching conventional pivot-based methods. 1","Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation Massively multilingual models for neural machine translation (NMT) are theoretically attractive, but often underperform bilingual models and deliver poor zero-shot translations. In this paper, we explore ways to improve them. We argue that multilingual NMT requires stronger modeling capacity to support language pairs with varying typological characteristics, and overcome this bottleneck via language-specific components and deepening NMT architectures. We identify the off-target translation issue (i.e. translating into a wrong target language) as the major source of the inferior zero-shot performance, and propose random online backtranslation to enforce the translation of unseen training language pairs. Experiments on OPUS-100 (a novel multilingual dataset with 100 languages) show that our approach substantially narrows the performance gap with bilingual models in both oneto-many and many-to-many settings, and improves zero-shot performance by âˆ¼10 BLEU, approaching conventional pivot-based methods. 1","improve massively multilingual neural machine translation zero - shot translation massively multilingual model neural machine translation ( nmt ) theoretically attractive , underperform bilingual model deliver poor zero - shot translation . paper , explore way improve . argue multilingual nmt require strong modeling capacity support language pair vary typological characteristic , overcome bottleneck language - specific component deepen nmt architecture . identify - target translation issue ( i.e. translate wrong target language ) major source inferior zero - shot performance , propose random online backtranslation enforce translation unseen training language pair . experiment opus-100 ( novel multilingual dataset 100 language ) approach substantially narrow performance gap bilingual model oneto - - - setting , improve zero - shot performance âˆ¼10 bleu , approach conventional pivot - base method . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 17, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Improving Non-autoregressive Neural Machine Translation with Monolingual Data,"Non-autoregressive (NAR) neural machine translation is usually done via knowledge distillation from an autoregressive (AR) model. Under this framework, we leverage large monolingual corpora to improve the NAR model's performance, with the goal of transferring the AR model's generalization ability while preventing overfitting. On top of a strong NAR baseline, our experimental results on the WMT14 En-De and WMT16 En-Ro news translation tasks confirm that monolingual data augmentation consistently improves the performance of the NAR model to approach the teacher AR model's performance, yields comparable or better results than the best non-iterative NAR methods in the literature and helps reduce overfitting in the training process.","Improving Non-autoregressive Neural Machine Translation with Monolingual Data Non-autoregressive (NAR) neural machine translation is usually done via knowledge distillation from an autoregressive (AR) model. Under this framework, we leverage large monolingual corpora to improve the NAR model's performance, with the goal of transferring the AR model's generalization ability while preventing overfitting. On top of a strong NAR baseline, our experimental results on the WMT14 En-De and WMT16 En-Ro news translation tasks confirm that monolingual data augmentation consistently improves the performance of the NAR model to approach the teacher AR model's performance, yields comparable or better results than the best non-iterative NAR methods in the literature and helps reduce overfitting in the training process.","improve non - autoregressive neural machine translation monolingual data non - autoregressive ( nar ) neural machine translation usually knowledge distillation autoregressive ( ar ) model . framework , leverage large monolingual corpus improve nar model performance , goal transfer ar model generalization ability prevent overfitting . strong nar baseline , experimental result wmt14 en - de wmt16 en - ro news translation task confirm monolingual datum augmentation consistently improve performance nar model approach teacher ar model performance , yield comparable well result good non - iterative nar method literature help reduce overfitting training process .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Gender in Danger? Evaluating Speech Translation Technology on the MuST-SHE Corpus,"Translating from languages without productive grammatical gender like English into gender-marked languages is a well-known difficulty for machines. This difficulty is also due to the fact that the training data on which models are built typically reflect the asymmetries of natural languages, gender bias included. Exclusively fed with textual data, machine translation is intrinsically constrained by the fact that the input sentence does not always contain clues about the gender identity of the referred human entities. But what happens with speech translation, where the input is an audio signal? Can audio provide additional information to reduce gender bias? We present the first thorough investigation of gender bias in speech translation, contributing with: i) the release of a benchmark useful for future studies, and ii) the comparison of different technologies (cascade and end-to-end) on two language directions (English-Italian/French).","Gender in Danger? Evaluating Speech Translation Technology on the MuST-SHE Corpus Translating from languages without productive grammatical gender like English into gender-marked languages is a well-known difficulty for machines. This difficulty is also due to the fact that the training data on which models are built typically reflect the asymmetries of natural languages, gender bias included. Exclusively fed with textual data, machine translation is intrinsically constrained by the fact that the input sentence does not always contain clues about the gender identity of the referred human entities. But what happens with speech translation, where the input is an audio signal? Can audio provide additional information to reduce gender bias? We present the first thorough investigation of gender bias in speech translation, contributing with: i) the release of a benchmark useful for future studies, and ii) the comparison of different technologies (cascade and end-to-end) on two language directions (English-Italian/French).","gender danger ? evaluate speech translation technology - corpus translate language productive grammatical gender like english gender - mark language - know difficulty machine . difficulty fact training datum model build typically reflect asymmetry natural language , gender bias include . exclusively feed textual datum , machine translation intrinsically constrain fact input sentence contain clue gender identity refer human entity . happen speech translation , input audio signal ? audio provide additional information reduce gender bias ? present thorough investigation gender bias speech translation , contribute : ) release benchmark useful future study , ii ) comparison different technology ( cascade end - - end ) language direction ( english - italian / french ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 13, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 7, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 12, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Machine Translation and Multilinguality,Geometry-aware domain adaptation for unsupervised alignment of word embeddings,"We propose a novel manifold based geometric approach for learning unsupervised alignment of word embeddings between the source and the target languages. Our approach formulates the alignment learning problem as a domain adaptation problem over the manifold of doubly stochastic matrices. This viewpoint arises from the aim to align the second order information of the two language spaces. The rich geometry of the doubly stochastic manifold allows to employ efficient Riemannian conjugate gradient algorithm for the proposed formulation. Empirically, the proposed approach outperforms state-of-the-art optimal transport based approach on the bilingual lexicon induction task across several language pairs. The performance improvement is more significant for distant language pairs.","Geometry-aware domain adaptation for unsupervised alignment of word embeddings We propose a novel manifold based geometric approach for learning unsupervised alignment of word embeddings between the source and the target languages. Our approach formulates the alignment learning problem as a domain adaptation problem over the manifold of doubly stochastic matrices. This viewpoint arises from the aim to align the second order information of the two language spaces. The rich geometry of the doubly stochastic manifold allows to employ efficient Riemannian conjugate gradient algorithm for the proposed formulation. Empirically, the proposed approach outperforms state-of-the-art optimal transport based approach on the bilingual lexicon induction task across several language pairs. The performance improvement is more significant for distant language pairs.","geometry - aware domain adaptation unsupervised alignment word embedding propose novel manifold base geometric approach learn unsupervised alignment word embedding source target language . approach formulate alignment learning problem domain adaptation problem manifold doubly stochastic matrix . viewpoint arise aim align second order information language space . rich geometry doubly stochastic manifold allow employ efficient riemannian conjugate gradient algorithm propose formulation . empirically , propose approach outperform state - - - art optimal transport base approach bilingual lexicon induction task language pair . performance improvement significant distant language pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Machine Translation and Multilinguality,On the Limitations of Cross-lingual Encoders as Exposed by Reference-Free Machine Translation Evaluation,"Evaluation of cross-lingual encoders is usually performed either via zero-shot cross-lingual transfer in supervised downstream tasks or via unsupervised cross-lingual textual similarity. In this paper, we concern ourselves with reference-free machine translation (MT) evaluation where we directly compare source texts to (sometimes low-quality) system translations, which represents a natural adversarial setup for multilingual encoders. Referencefree evaluation holds the promise of web-scale comparison of MT systems. We systematically investigate a range of metrics based on state-of-the-art cross-lingual semantic representations obtained with pretrained M-BERT and LASER. We find that they perform poorly as semantic encoders for reference-free MT evaluation and identify their two key limitations, namely, (a) a semantic mismatch between representations of mutual translations and, more prominently, (b) the inability to punish ""translationese"", i.e., low-quality literal translations. We propose two partial remedies: (1) post-hoc re-alignment of the vector spaces and (2) coupling of semantic-similarity based metrics with target-side language modeling. In segment-level MT evaluation, our best metric surpasses reference-based BLEU by 5.7 correlation points. We make our MT evaluation code available. 1","On the Limitations of Cross-lingual Encoders as Exposed by Reference-Free Machine Translation Evaluation Evaluation of cross-lingual encoders is usually performed either via zero-shot cross-lingual transfer in supervised downstream tasks or via unsupervised cross-lingual textual similarity. In this paper, we concern ourselves with reference-free machine translation (MT) evaluation where we directly compare source texts to (sometimes low-quality) system translations, which represents a natural adversarial setup for multilingual encoders. Referencefree evaluation holds the promise of web-scale comparison of MT systems. We systematically investigate a range of metrics based on state-of-the-art cross-lingual semantic representations obtained with pretrained M-BERT and LASER. We find that they perform poorly as semantic encoders for reference-free MT evaluation and identify their two key limitations, namely, (a) a semantic mismatch between representations of mutual translations and, more prominently, (b) the inability to punish ""translationese"", i.e., low-quality literal translations. We propose two partial remedies: (1) post-hoc re-alignment of the vector spaces and (2) coupling of semantic-similarity based metrics with target-side language modeling. In segment-level MT evaluation, our best metric surpasses reference-based BLEU by 5.7 correlation points. We make our MT evaluation code available. 1","limitation cross - lingual encoder expose reference - free machine translation evaluation evaluation cross - lingual encoder usually perform zero - shot cross - lingual transfer supervise downstream task unsupervised cross - lingual textual similarity . paper , concern reference - free machine translation ( mt ) evaluation directly compare source text ( low - quality ) system translation , represent natural adversarial setup multilingual encoder . referencefree evaluation hold promise web - scale comparison mt system . systematically investigate range metric base state - - - art cross - lingual semantic representation obtain pretrained m - bert laser . find perform poorly semantic encoder reference - free mt evaluation identify key limitation , , ( ) semantic mismatch representation mutual translation , prominently , ( b ) inability punish "" translationese "" , i.e. , low - quality literal translation . propose partial remedy : ( 1 ) post - hoc - alignment vector space ( 2 ) coupling semantic - similarity base metric target - language modeling . segment - level mt evaluation , good metric surpass reference - base bleu 5.7 correlation point . mt evaluation code available . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 15, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 17, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Machine Translation and Multilinguality,"In Neural Machine Translation, What Does Transfer Learning Transfer?","Transfer learning improves quality for lowresource machine translation, but it is unclear what exactly it transfers. We perform several ablation studies that limit information transfer, then measure the quality impact across three language pairs to gain a black-box understanding of transfer learning. Word embeddings play an important role in transfer learning, particularly if they are properly aligned. Although transfer learning can be performed without embeddings, results are sub-optimal. In contrast, transferring only the embeddings but nothing else yields catastrophic results. We then investigate diagonal alignments with auto-encoders over real languages and randomly generated sequences, finding even randomly generated sequences as parents yield noticeable but smaller gains. Finally, transfer learning can eliminate the need for a warmup phase when training transformer models in high resource language pairs.","In Neural Machine Translation, What Does Transfer Learning Transfer? Transfer learning improves quality for lowresource machine translation, but it is unclear what exactly it transfers. We perform several ablation studies that limit information transfer, then measure the quality impact across three language pairs to gain a black-box understanding of transfer learning. Word embeddings play an important role in transfer learning, particularly if they are properly aligned. Although transfer learning can be performed without embeddings, results are sub-optimal. In contrast, transferring only the embeddings but nothing else yields catastrophic results. We then investigate diagonal alignments with auto-encoders over real languages and randomly generated sequences, finding even randomly generated sequences as parents yield noticeable but smaller gains. Finally, transfer learning can eliminate the need for a warmup phase when training transformer models in high resource language pairs.","neural machine translation , transfer learning transfer ? transfer learning improve quality lowresource machine translation , unclear exactly transfer . perform ablation study limit information transfer , measure quality impact language pair gain black - box understanding transfer learning . word embedding play important role transfer learning , particularly properly align . transfer learning perform embedding , result sub - optimal . contrast , transfer embedding yield catastrophic result . investigate diagonal alignment auto - encoder real language randomly generate sequence , find randomly generate sequence parent yield noticeable small gain . finally , transfer learning eliminate need warmup phase training transformer model high resource language pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,It's Easier to Translate out of English than into it: Measuring Neural Translation Difficulty by Cross-Mutual Information,"The performance of neural machine translation systems is commonly evaluated in terms of BLEU. However, due to its reliance on target language properties and generation, the BLEU metric does not allow an assessment of which translation directions are more difficult to model. In this paper, we propose cross-mutual information (XMI): an asymmetric information-theoretic metric of machine translation difficulty that exploits the probabilistic nature of most neural machine translation models. XMI allows us to better evaluate the difficulty of translating text into the target language while controlling for the difficulty of the target-side generation component independent of the translation task. We then present the first systematic and controlled study of cross-lingual translation difficulties using modern neural translation systems. Code for replicating our experiments","It's Easier to Translate out of English than into it: Measuring Neural Translation Difficulty by Cross-Mutual Information The performance of neural machine translation systems is commonly evaluated in terms of BLEU. However, due to its reliance on target language properties and generation, the BLEU metric does not allow an assessment of which translation directions are more difficult to model. In this paper, we propose cross-mutual information (XMI): an asymmetric information-theoretic metric of machine translation difficulty that exploits the probabilistic nature of most neural machine translation models. XMI allows us to better evaluate the difficulty of translating text into the target language while controlling for the difficulty of the target-side generation component independent of the translation task. We then present the first systematic and controlled study of cross-lingual translation difficulties using modern neural translation systems. Code for replicating our experiments","easy translate english : measure neural translation difficulty cross - mutual information performance neural machine translation system commonly evaluate term bleu . , reliance target language property generation , bleu metric allow assessment translation direction difficult model . paper , propose cross - mutual information ( xmi ): asymmetric information - theoretic metric machine translation difficulty exploit probabilistic nature neural machine translation model . xmi allow well evaluate difficulty translate text target language control difficulty target - generation component independent translation task . present systematic control study cross - lingual translation difficulty modern neural translation system . code replicate experi","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 18, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,A Simple and Effective Unified Encoder for Document-Level Machine Translation,"Most of the existing models for documentlevel machine translation adopt dual-encoder structures. The representation of the source sentences and the document-level contexts 1 are modeled with two separate encoders. Although these models can make use of the document-level contexts, they do not fully model the interaction between the contexts and the source sentences, and can not directly adapt to the recent pre-training models (e.g., BERT) which encodes multiple sentences with a single encoder. In this work, we propose a simple and effective unified encoder that can outperform the baseline models of dualencoder models in terms of BLEU and ME-TEOR scores. Moreover, the pre-training models can further boost the performance of our proposed model.","A Simple and Effective Unified Encoder for Document-Level Machine Translation Most of the existing models for documentlevel machine translation adopt dual-encoder structures. The representation of the source sentences and the document-level contexts 1 are modeled with two separate encoders. Although these models can make use of the document-level contexts, they do not fully model the interaction between the contexts and the source sentences, and can not directly adapt to the recent pre-training models (e.g., BERT) which encodes multiple sentences with a single encoder. In this work, we propose a simple and effective unified encoder that can outperform the baseline models of dualencoder models in terms of BLEU and ME-TEOR scores. Moreover, the pre-training models can further boost the performance of our proposed model.","simple effective unified encoder document - level machine translation exist model documentlevel machine translation adopt dual - encoder structure . representation source sentence document - level context 1 model separate encoder . model use document - level context , fully model interaction context source sentence , directly adapt recent pre - training model ( e.g. , bert ) encode multiple sentence single encoder . work , propose simple effective unified encoder outperform baseline model dualencoder model term bleu - teor score . , pre - training model boost performance propose model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Evaluating Robustness to Input Perturbations for Neural Machine Translation,Neural Machine Translation (NMT) models are sensitive to small perturbations in the input. Robustness to such perturbations is typically measured using translation quality metrics such as BLEU on the noisy input. This paper proposes additional metrics which measure the relative degradation and changes in translation when small perturbations are added to the input. We focus on a class of models employing subword regularization to address robustness and perform extensive evaluations of these models using the robustness measures proposed. Results show that our proposed metrics reveal a clear trend of improved robustness to perturbations when subword regularization methods are used.,Evaluating Robustness to Input Perturbations for Neural Machine Translation Neural Machine Translation (NMT) models are sensitive to small perturbations in the input. Robustness to such perturbations is typically measured using translation quality metrics such as BLEU on the noisy input. This paper proposes additional metrics which measure the relative degradation and changes in translation when small perturbations are added to the input. We focus on a class of models employing subword regularization to address robustness and perform extensive evaluations of these models using the robustness measures proposed. Results show that our proposed metrics reveal a clear trend of improved robustness to perturbations when subword regularization methods are used.,evaluate robustness input perturbation neural machine translation neural machine translation ( nmt ) model sensitive small perturbation input . robustness perturbation typically measure translation quality metric bleu noisy input . paper propose additional metric measure relative degradation change translation small perturbation add input . focus class model employ subword regularization address robustness perform extensive evaluation model robustness measure propose . result propose metric reveal clear trend improve robustness perturbation subword regularization method .,"{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 13, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation,"Machine translation (MT) has benefited from using synthetic training data originating from translating monolingual corpora, a technique known as backtranslation. Combining backtranslated data from different sources has led to better results than when using such data in isolation. In this work we analyse the impact that data translated with rule-based, phrasebased statistical and neural MT systems has on new MT systems. We use a real-world low-resource use-case (Basque-to-Spanish in the clinical domain) as well as a high-resource language pair (German-to-English) to test different scenarios with backtranslation and employ data selection to optimise the synthetic corpora. We exploit different data selection strategies in order to reduce the amount of data used, while at the same time maintaining highquality MT systems. We further tune the data selection method by taking into account the quality of the MT systems used for backtranslation and lexical diversity of the resulting corpora. Our experiments show that incorporating backtranslated data from different sources can be beneficial, and that availing of data selection can yield improved performance.","Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation Machine translation (MT) has benefited from using synthetic training data originating from translating monolingual corpora, a technique known as backtranslation. Combining backtranslated data from different sources has led to better results than when using such data in isolation. In this work we analyse the impact that data translated with rule-based, phrasebased statistical and neural MT systems has on new MT systems. We use a real-world low-resource use-case (Basque-to-Spanish in the clinical domain) as well as a high-resource language pair (German-to-English) to test different scenarios with backtranslation and employ data selection to optimise the synthetic corpora. We exploit different data selection strategies in order to reduce the amount of data used, while at the same time maintaining highquality MT systems. We further tune the data selection method by taking into account the quality of the MT systems used for backtranslation and lexical diversity of the resulting corpora. Our experiments show that incorporating backtranslated data from different sources can be beneficial, and that availing of data selection can yield improved performance.","select backtranslate datum multiple source improved neural machine translation machine translation ( mt ) benefit synthetic training datum originate translate monolingual corpora , technique know backtranslation . combine backtranslate datum different source lead well result datum isolation . work analyse impact datum translate rule - base , phrasebased statistical neural mt system new mt system . use real - world low - resource use - case ( basque - - spanish clinical domain ) high - resource language pair ( german - - english ) test different scenario backtranslation employ datum selection optimise synthetic corpora . exploit different datum selection strategy order reduce datum , time maintain highquality mt system . tune datum selection method take account quality mt system backtranslation lexical diversity result corpora . experiment incorporate backtranslate datum different source beneficial , avail datum selection yield improve performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Content Word Aware Neural Machine Translation,"Neural machine translation (NMT) encodes the source sentence in a universal way to generate the target sentence word-byword. However, NMT does not consider the importance of word in the sentence meaning, for example, some words (i.e., content words) express more important meaning than others (i.e., function words). To address this limitation, we first utilize word frequency information to distinguish between content and function words in a sentence, and then design a content word-aware NMT to improve translation performance. Empirical results on the WMT14 English-to-German, WMT14 English-to-French, and WMT17 Chineseto-English translation tasks show that the proposed methods can significantly improve the performance of Transformer-based NMT.","Content Word Aware Neural Machine Translation Neural machine translation (NMT) encodes the source sentence in a universal way to generate the target sentence word-byword. However, NMT does not consider the importance of word in the sentence meaning, for example, some words (i.e., content words) express more important meaning than others (i.e., function words). To address this limitation, we first utilize word frequency information to distinguish between content and function words in a sentence, and then design a content word-aware NMT to improve translation performance. Empirical results on the WMT14 English-to-German, WMT14 English-to-French, and WMT17 Chineseto-English translation tasks show that the proposed methods can significantly improve the performance of Transformer-based NMT.","content word aware neural machine translation neural machine translation ( nmt ) encode source sentence universal way generate target sentence word - byword . , nmt consider importance word sentence meaning , example , word ( i.e. , content word ) express important meaning ( i.e. , function word ) . address limitation , utilize word frequency information distinguish content function word sentence , design content word - aware nmt improve translation performance . empirical result wmt14 english - - german , wmt14 english - - french , wmt17 chineseto - english translation task propose method significantly improve performance transformer - base nmt .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 10, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
Machine Translation and Multilinguality,Uncertainty-Aware Curriculum Learning for Neural Machine Translation,"Neural machine translation (NMT) has proven to be facilitated by curriculum learning which presents examples in an easy-to-hard order at different training stages. The keys lie in the assessment of data difficulty and model competence. We propose uncertainty-aware curriculum learning, which is motivated by the intuition that: 1) the higher the uncertainty in a translation pair, the more complex and rarer the information it contains; and 2) the end of the decline in model uncertainty indicates the completeness of current training stage. Specifically, we serve cross-entropy of an example as its data difficulty and exploit the variance of distributions over the weights of the network to present the model uncertainty. Extensive experiments on various translation tasks reveal that our approach outperforms the strong baseline and related methods on both translation quality and convergence speed. Quantitative analyses reveal that the proposed strategy offers NMT the ability to automatically govern its learning schedule.","Uncertainty-Aware Curriculum Learning for Neural Machine Translation Neural machine translation (NMT) has proven to be facilitated by curriculum learning which presents examples in an easy-to-hard order at different training stages. The keys lie in the assessment of data difficulty and model competence. We propose uncertainty-aware curriculum learning, which is motivated by the intuition that: 1) the higher the uncertainty in a translation pair, the more complex and rarer the information it contains; and 2) the end of the decline in model uncertainty indicates the completeness of current training stage. Specifically, we serve cross-entropy of an example as its data difficulty and exploit the variance of distributions over the weights of the network to present the model uncertainty. Extensive experiments on various translation tasks reveal that our approach outperforms the strong baseline and related methods on both translation quality and convergence speed. Quantitative analyses reveal that the proposed strategy offers NMT the ability to automatically govern its learning schedule.","uncertainty - aware curriculum learning neural machine translation neural machine translation ( nmt ) prove facilitate curriculum learning present example easy - - hard order different training stage . key lie assessment datum difficulty model competence . propose uncertainty - aware curriculum learning , motivate intuition : 1 ) high uncertainty translation pair , complex rare information contain ; 2 ) end decline model uncertainty indicate completeness current training stage . specifically , serve cross - entropy example data difficulty exploit variance distribution weight network present model uncertainty . extensive experiment translation task reveal approach outperform strong baseline related method translation quality convergence speed . quantitative analysis reveal propose strategy offer nmt ability automatically govern learning schedule .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 14, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,True
NLP Applications,Semantic Scaffolds for Pseudocode-to-Code Generation,"We propose a method for program generation based on semantic scaffolds, lightweight structures representing the high-level semantic and syntactic composition of a program. By first searching over plausible scaffolds then using these as constraints for a beam search over programs, we achieve better coverage of the search space when compared with existing techniques. We apply our hierarchical search method to the SPoC dataset for pseudocodeto-code generation, in which we are given line-level natural language pseudocode annotations and aim to produce a program satisfying execution-based test cases. By using semantic scaffolds during inference, we achieve a 10% absolute improvement in top-100 accuracy over the previous state-of-the-art. Additionally, we require only 11 candidates to reach the top-3000 performance of the previous best approach when tested against unseen problems, demonstrating a substantial improvement in efficiency.","Semantic Scaffolds for Pseudocode-to-Code Generation We propose a method for program generation based on semantic scaffolds, lightweight structures representing the high-level semantic and syntactic composition of a program. By first searching over plausible scaffolds then using these as constraints for a beam search over programs, we achieve better coverage of the search space when compared with existing techniques. We apply our hierarchical search method to the SPoC dataset for pseudocodeto-code generation, in which we are given line-level natural language pseudocode annotations and aim to produce a program satisfying execution-based test cases. By using semantic scaffolds during inference, we achieve a 10% absolute improvement in top-100 accuracy over the previous state-of-the-art. Additionally, we require only 11 candidates to reach the top-3000 performance of the previous best approach when tested against unseen problems, demonstrating a substantial improvement in efficiency.","semantic scaffold pseudocode - - code generation propose method program generation base semantic scaffold , lightweight structure represent high - level semantic syntactic composition program . search plausible scaffold constraint beam search program , achieve well coverage search space compare exist technique . apply hierarchical search method spoc dataset pseudocodeto - code generation , give line - level natural language pseudocode annotation aim produce program satisfy execution - base test case . semantic scaffold inference , achieve 10 % absolute improvement top-100 accuracy previous state - - - art . additionally , require 11 candidate reach top-3000 performance previous good approach test unseen problem , demonstrate substantial improvement efficiency .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,True
NLP Applications,Joint Modelling of Emotion and Abusive Language Detection,"The rise of online communication platforms has been accompanied by some undesirable effects, such as the proliferation of aggressive and abusive behaviour online. Aiming to tackle this problem, the natural language processing (NLP) community has experimented with a range of techniques for abuse detection. While achieving substantial success, these methods have so far only focused on modelling the linguistic properties of the comments and the online communities of users, disregarding the emotional state of the users and how this might affect their language. The latter is, however, inextricably linked to abusive behaviour. In this paper, we present the first joint model of emotion and abusive language detection, experimenting in a multi-task learning framework that allows one task to inform the other. Our results demonstrate that incorporating affective features leads to significant improvements in abuse detection performance across datasets.","Joint Modelling of Emotion and Abusive Language Detection The rise of online communication platforms has been accompanied by some undesirable effects, such as the proliferation of aggressive and abusive behaviour online. Aiming to tackle this problem, the natural language processing (NLP) community has experimented with a range of techniques for abuse detection. While achieving substantial success, these methods have so far only focused on modelling the linguistic properties of the comments and the online communities of users, disregarding the emotional state of the users and how this might affect their language. The latter is, however, inextricably linked to abusive behaviour. In this paper, we present the first joint model of emotion and abusive language detection, experimenting in a multi-task learning framework that allows one task to inform the other. Our results demonstrate that incorporating affective features leads to significant improvements in abuse detection performance across datasets.","joint modelling emotion abusive language detection rise online communication platform accompany undesirable effect , proliferation aggressive abusive behaviour online . aim tackle problem , natural language processing ( nlp ) community experiment range technique abuse detection . achieve substantial success , method far focus model linguistic property comment online community user , disregard emotional state user affect language . , , inextricably link abusive behaviour . paper , present joint model emotion abusive language detection , experiment multi - task learning framework allow task inform . result demonstrate incorporate affective feature lead significant improvement abuse detection performance dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
NLP Applications,Hiring Now: A Skill-Aware Multi-Attention Model for Job Posting Generation,"Writing a good job posting is a critical step in the recruiting process, but the task is often more difficult than many people think. It is challenging to specify the level of education, experience, relevant skills per the company information and job description. To this end, we propose a novel task of Job Posting Generation (JPG) that is cast as a conditional text generation problem to generate job requirements according to the job descriptions. To deal with this task, we devise a data-driven global Skill-Aware Multi-Attention generation model, named SAMA. Specifically, to model the complex mapping relationships between input and output, we design a hierarchical decoder that we first label the job description with multiple skills, then we generate a complete text guided by the skill labels. At the same time, to exploit the prior knowledge about the skills, we further construct a skill knowledge graph to capture the global prior knowledge of skills and refine the generated results. The proposed approach is evaluated on real-world job posting data. Experimental results clearly demonstrate the effectiveness of the proposed method 1 .","Hiring Now: A Skill-Aware Multi-Attention Model for Job Posting Generation Writing a good job posting is a critical step in the recruiting process, but the task is often more difficult than many people think. It is challenging to specify the level of education, experience, relevant skills per the company information and job description. To this end, we propose a novel task of Job Posting Generation (JPG) that is cast as a conditional text generation problem to generate job requirements according to the job descriptions. To deal with this task, we devise a data-driven global Skill-Aware Multi-Attention generation model, named SAMA. Specifically, to model the complex mapping relationships between input and output, we design a hierarchical decoder that we first label the job description with multiple skills, then we generate a complete text guided by the skill labels. At the same time, to exploit the prior knowledge about the skills, we further construct a skill knowledge graph to capture the global prior knowledge of skills and refine the generated results. The proposed approach is evaluated on real-world job posting data. Experimental results clearly demonstrate the effectiveness of the proposed method 1 .","hire : skill - aware multi - attention model job posting generation write good job posting critical step recruiting process , task difficult people think . challenging specify level education , experience , relevant skill company information job description . end , propose novel task job posting generation ( jpg ) cast conditional text generation problem generate job requirement accord job description . deal task , devise data - drive global skill - aware multi - attention generation model , name sama . specifically , model complex map relationship input output , design hierarchical decoder label job description multiple skill , generate complete text guide skill label . time , exploit prior knowledge skill , construct skill knowledge graph capture global prior knowledge skill refine generate result . propose approach evaluate real - world job posting datum . experimental result clearly demonstrate effectiveness propose method 1 .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 12, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,True
NLP Applications,A Girl Has A Name: Detecting Authorship Obfuscation,"Authorship attribution aims to identify the author of a text based on the stylometric analysis. Authorship obfuscation, on the other hand, aims to protect against authorship attribution by modifying a text's style. In this paper, we evaluate the stealthiness of state-of-the-art authorship obfuscation methods under an adversarial threat model. An obfuscator is stealthy to the extent an adversary finds it challenging to detect whether or not a text modified by the obfuscator is obfuscated -a decision that is key to the adversary interested in authorship attribution. We show that the existing authorship obfuscation methods are not stealthy as their obfuscated texts can be identified with an average F1 score of 0.87. The reason for the lack of stealthiness is that these obfuscators degrade text smoothness, as ascertained by neural language models, in a detectable manner. Our results highlight the need to develop stealthy authorship obfuscation methods that can better protect the identity of an author seeking anonymity.","A Girl Has A Name: Detecting Authorship Obfuscation Authorship attribution aims to identify the author of a text based on the stylometric analysis. Authorship obfuscation, on the other hand, aims to protect against authorship attribution by modifying a text's style. In this paper, we evaluate the stealthiness of state-of-the-art authorship obfuscation methods under an adversarial threat model. An obfuscator is stealthy to the extent an adversary finds it challenging to detect whether or not a text modified by the obfuscator is obfuscated -a decision that is key to the adversary interested in authorship attribution. We show that the existing authorship obfuscation methods are not stealthy as their obfuscated texts can be identified with an average F1 score of 0.87. The reason for the lack of stealthiness is that these obfuscators degrade text smoothness, as ascertained by neural language models, in a detectable manner. Our results highlight the need to develop stealthy authorship obfuscation methods that can better protect the identity of an author seeking anonymity.","girl : detect authorship obfuscation authorship attribution aim identify author text base stylometric analysis . authorship obfuscation , hand , aim protect authorship attribution modify text style . paper , evaluate stealthiness state - - - art authorship obfuscation method adversarial threat model . obfuscator stealthy extent adversary find challenging detect text modify obfuscator obfuscate -a decision key adversary interested authorship attribution . exist authorship obfuscation method stealthy obfuscate text identify average f1 score 0.87 . reason lack stealthiness obfuscator degrade text smoothness , ascertain neural language model , detectable manner . result highlight need develop stealthy authorship obfuscation method well protect identity author seek anonymity .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Fast and Accurate Deep Bidirectional Language Representations for Unsupervised Learning,"Even though BERT has achieved successful performance improvements in various supervised learning tasks, BERT is still limited by repetitive inferences on unsupervised tasks for the computation of contextual language representations. To resolve this limitation, we propose a novel deep bidirectional language model called a Transformer-based Text Autoencoder (T-TA). The T-TA computes contextual language representations without repetition and displays the benefits of a deep bidirectional architecture, such as that of BERT. In computation time experiments in a CPU environment, the proposed T-TA performs over six times faster than the BERT-like model on a reranking task and twelve times faster on a semantic similarity task. Furthermore, the T-TA shows competitive or even better accuracies than those of BERT on the above tasks. Code is available at https://github.com/joongbo/tta.","Fast and Accurate Deep Bidirectional Language Representations for Unsupervised Learning Even though BERT has achieved successful performance improvements in various supervised learning tasks, BERT is still limited by repetitive inferences on unsupervised tasks for the computation of contextual language representations. To resolve this limitation, we propose a novel deep bidirectional language model called a Transformer-based Text Autoencoder (T-TA). The T-TA computes contextual language representations without repetition and displays the benefits of a deep bidirectional architecture, such as that of BERT. In computation time experiments in a CPU environment, the proposed T-TA performs over six times faster than the BERT-like model on a reranking task and twelve times faster on a semantic similarity task. Furthermore, the T-TA shows competitive or even better accuracies than those of BERT on the above tasks. Code is available at https://github.com/joongbo/tta.","fast accurate deep bidirectional language representation unsupervised learning bert achieve successful performance improvement supervise learning task , bert limit repetitive inference unsupervised task computation contextual language representation . resolve limitation , propose novel deep bidirectional language model call transformer - base text autoencoder ( t - ta ) . t - ta compute contextual language representation repetition display benefit deep bidirectional architecture , bert . computation time experiment cpu environment , propose t - ta perform time fast bert - like model reranke task time fast semantic similarity task . furthermore , t - ta show competitive well accuracy bert task . code available https://github.com/joongbo/tta .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Programming in Natural Language with fuSE: Synthesizing Methods from Spoken Utterances Using Deep Natural Language Understanding,"The key to effortless end-user programming is natural language. We examine how to teach intelligent systems new functions, expressed in natural language. As a first step, we collected 3168 samples of teaching efforts in plain English. Then we built fu SE , a novel system that translates English function descriptions into code. Our approach is three-tiered and each task is evaluated separately. We first classify whether an intent to teach new functionality is present in the utterance (accuracy: 97.7% using BERT). Then we analyze the linguistic structure and construct a semantic model (accuracy: 97.6% using a BiLSTM). Finally, we synthesize the signature of the method, map the intermediate steps (instructions in the method body) to API calls and inject control structures (F 1 : 67.0% with information retrieval and knowledge-based methods). In an end-to-end evaluation on an unseen dataset fu SE synthesized 84.6% of the method signatures and 79.2% of the API calls correctly.","Programming in Natural Language with fuSE: Synthesizing Methods from Spoken Utterances Using Deep Natural Language Understanding The key to effortless end-user programming is natural language. We examine how to teach intelligent systems new functions, expressed in natural language. As a first step, we collected 3168 samples of teaching efforts in plain English. Then we built fu SE , a novel system that translates English function descriptions into code. Our approach is three-tiered and each task is evaluated separately. We first classify whether an intent to teach new functionality is present in the utterance (accuracy: 97.7% using BERT). Then we analyze the linguistic structure and construct a semantic model (accuracy: 97.6% using a BiLSTM). Finally, we synthesize the signature of the method, map the intermediate steps (instructions in the method body) to API calls and inject control structures (F 1 : 67.0% with information retrieval and knowledge-based methods). In an end-to-end evaluation on an unseen dataset fu SE synthesized 84.6% of the method signatures and 79.2% of the API calls correctly.","program natural language fuse : synthesize method spoken utterance deep natural language understanding key effortless end - user programming natural language . examine teach intelligent system new function , express natural language . step , collect 3168 sample teach effort plain english . build fu se , novel system translate english function description code . approach - tiered task evaluate separately . classify intent teach new functionality present utterance ( accuracy : 97.7 % bert ) . analyze linguistic structure construct semantic model ( accuracy : 97.6 % bilstm ) . finally , synthesize signature method , map intermediate step ( instruction method body ) api call inject control structure ( f 1 : 67.0 % information retrieval knowledge - base method ) . end - - end evaluation unseen dataset fu se synthesize 84.6 % method signature 79.2 % api call correctly .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Should All Cross-Lingual Embeddings Speak English?,"Most of recent work in cross-lingual word embeddings is severely Anglocentric. The vast majority of lexicon induction evaluation dictionaries are between English and another language, and the English embedding space is selected by default as the hub when learning in a multilingual setting. With this work, however, we challenge these practices. First, we show that the choice of hub language can significantly impact downstream lexicon induction and zero-shot POS tagging performance. Second, we both expand a standard Englishcentered evaluation dictionary collection to include all language pairs using triangulation, and create new dictionaries for under-represented languages. 1 Evaluating established methods over all these language pairs sheds light into their suitability for aligning embeddings from distant languages and presents new challenges for the field. Finally, in our analysis we identify general guidelines for strong cross-lingual embedding baselines, that extend to language pairs that do not include English.","Should All Cross-Lingual Embeddings Speak English? Most of recent work in cross-lingual word embeddings is severely Anglocentric. The vast majority of lexicon induction evaluation dictionaries are between English and another language, and the English embedding space is selected by default as the hub when learning in a multilingual setting. With this work, however, we challenge these practices. First, we show that the choice of hub language can significantly impact downstream lexicon induction and zero-shot POS tagging performance. Second, we both expand a standard Englishcentered evaluation dictionary collection to include all language pairs using triangulation, and create new dictionaries for under-represented languages. 1 Evaluating established methods over all these language pairs sheds light into their suitability for aligning embeddings from distant languages and presents new challenges for the field. Finally, in our analysis we identify general guidelines for strong cross-lingual embedding baselines, that extend to language pairs that do not include English.","cross - lingual embedding speak english ? recent work cross - lingual word embedding severely anglocentric . vast majority lexicon induction evaluation dictionary english language , english embedding space select default hub learn multilingual setting . work , , challenge practice . , choice hub language significantly impact downstream lexicon induction zero - shot pos tagging performance . second , expand standard englishcentered evaluation dictionary collection include language pair triangulation , create new dictionary - represent language . 1 evaluate establish method language pair shed light suitability align embedding distant language present new challenge field . finally , analysis identify general guideline strong cross - lingual embedding baseline , extend language pair include english .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,CorefQA: Coreference Resolution as Query-based Span Prediction,"In this paper, we present CorefQA, an accurate and extensible approach for the coreference resolution task. We formulate the problem as a span prediction task, like in question answering: A query is generated for each candidate mention using its surrounding context, and a span prediction module is employed to extract the text spans of the coreferences within the document using the generated query. This formulation comes with the following key advantages: (1) The span prediction strategy provides the flexibility of retrieving mentions left out at the mention proposal stage; (2) In the question answering framework, encoding the mention and its context explicitly in a query makes it possible to have a deep and thorough examination of cues embedded in the context of coreferent mentions; and (3) A plethora of existing question answering datasets can be used for data augmentation to improve the model's generalization capability. Experiments demonstrate significant performance boost over previous models, with 83.1 (+3.5) F1 score on the CoNLL-2012 benchmark and 87.5 (+2.5) F1 score on the GAP benchmark. 1","CorefQA: Coreference Resolution as Query-based Span Prediction In this paper, we present CorefQA, an accurate and extensible approach for the coreference resolution task. We formulate the problem as a span prediction task, like in question answering: A query is generated for each candidate mention using its surrounding context, and a span prediction module is employed to extract the text spans of the coreferences within the document using the generated query. This formulation comes with the following key advantages: (1) The span prediction strategy provides the flexibility of retrieving mentions left out at the mention proposal stage; (2) In the question answering framework, encoding the mention and its context explicitly in a query makes it possible to have a deep and thorough examination of cues embedded in the context of coreferent mentions; and (3) A plethora of existing question answering datasets can be used for data augmentation to improve the model's generalization capability. Experiments demonstrate significant performance boost over previous models, with 83.1 (+3.5) F1 score on the CoNLL-2012 benchmark and 87.5 (+2.5) F1 score on the GAP benchmark. 1","corefqa : coreference resolution query - base span prediction paper , present corefqa , accurate extensible approach coreference resolution task . formulate problem span prediction task , like question answering : query generate candidate mention surround context , span prediction module employ extract text span coreference document generate query . formulation come following key advantage : ( 1 ) span prediction strategy provide flexibility retrieve mention leave mention proposal stage ; ( 2 ) question answering framework , encode mention context explicitly query make possible deep thorough examination cue embed context coreferent mention ; ( 3 ) plethora exist question answer dataset data augmentation improve model generalization capability . experiment demonstrate significant performance boost previous model , 83.1 ( +3.5 ) f1 score conll-2012 benchmark 87.5 ( +2.5 ) f1 score gap benchmark . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 15, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
NLP Applications,Estimating predictive uncertainty for rumour verification models,"The inability to correctly resolve rumours circulating online can have harmful real-world consequences. We present a method for incorporating model and data uncertainty estimates into natural language processing models for automatic rumour verification. We show that these estimates can be used to filter out model predictions likely to be erroneous, so that these difficult instances can be prioritised by a human fact-checker. We propose two methods for uncertainty-based instance rejection, supervised and unsupervised. We also show how uncertainty estimates can be used to interpret model performance as a rumour unfolds.","Estimating predictive uncertainty for rumour verification models The inability to correctly resolve rumours circulating online can have harmful real-world consequences. We present a method for incorporating model and data uncertainty estimates into natural language processing models for automatic rumour verification. We show that these estimates can be used to filter out model predictions likely to be erroneous, so that these difficult instances can be prioritised by a human fact-checker. We propose two methods for uncertainty-based instance rejection, supervised and unsupervised. We also show how uncertainty estimates can be used to interpret model performance as a rumour unfolds.","estimate predictive uncertainty rumour verification model inability correctly resolve rumour circulate online harmful real - world consequence . present method incorporate model datum uncertainty estimate natural language processing model automatic rumour verification . estimate filter model prediction likely erroneous , difficult instance prioritise human fact - checker . propose method uncertainty - base instance rejection , supervised unsupervised . uncertainty estimate interpret model performance rumour unfold .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Modeling Code-Switch Languages Using Bilingual Parallel Corpus,"Language modeling is the technique to estimate the probability of a sequence of words. A bilingual language model is expected to model the sequential dependency for words across languages, which is difficult due to the inherent lack of suitable training data as well as diverse syntactic structure across languages. We propose a bilingual attention language model (BALM) that simultaneously performs language modeling objective with a quasi-translation objective to model both the monolingual as well as the cross-lingual sequential dependency. The attention mechanism learns the bilingual context from a parallel corpus. BALM achieves state-of-theart performance on the SEAME code-switch database by reducing the perplexity of 20.5% over the best-reported result. We also apply BALM in bilingual lexicon induction, and language normalization tasks to validate the idea.","Modeling Code-Switch Languages Using Bilingual Parallel Corpus Language modeling is the technique to estimate the probability of a sequence of words. A bilingual language model is expected to model the sequential dependency for words across languages, which is difficult due to the inherent lack of suitable training data as well as diverse syntactic structure across languages. We propose a bilingual attention language model (BALM) that simultaneously performs language modeling objective with a quasi-translation objective to model both the monolingual as well as the cross-lingual sequential dependency. The attention mechanism learns the bilingual context from a parallel corpus. BALM achieves state-of-theart performance on the SEAME code-switch database by reducing the perplexity of 20.5% over the best-reported result. We also apply BALM in bilingual lexicon induction, and language normalization tasks to validate the idea.","model code - switch language bilingual parallel corpus language modeling technique estimate probability sequence word . bilingual language model expect model sequential dependency word language , difficult inherent lack suitable training datum diverse syntactic structure language . propose bilingual attention language model ( balm ) simultaneously perform language modeling objective quasi - translation objective model monolingual cross - lingual sequential dependency . attention mechanism learn bilingual context parallel corpus . balm achieve state - - theart performance seame code - switch database reduce perplexity 20.5 % well - report result . apply balm bilingual lexicon induction , language normalization task validate idea .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,False
NLP Applications,Smart To-Do: Automatic Generation of To-Do Items from Emails,"Intelligent features in email service applications aim to increase productivity by helping people organize their folders, compose their emails and respond to pending tasks. In this work, we explore a new application, Smart-To-Do, that helps users with task management over emails. We introduce a new task and dataset for automatically generating To-Do items from emails where the sender has promised to perform an action. We design a two-stage process leveraging recent advances in neural text generation and sequenceto-sequence learning, obtaining BLEU and ROUGE scores of 0.23 and 0.63 for this task. To the best of our knowledge, this is the first work to address the problem of composing To-Do items from emails.","Smart To-Do: Automatic Generation of To-Do Items from Emails Intelligent features in email service applications aim to increase productivity by helping people organize their folders, compose their emails and respond to pending tasks. In this work, we explore a new application, Smart-To-Do, that helps users with task management over emails. We introduce a new task and dataset for automatically generating To-Do items from emails where the sender has promised to perform an action. We design a two-stage process leveraging recent advances in neural text generation and sequenceto-sequence learning, obtaining BLEU and ROUGE scores of 0.23 and 0.63 for this task. To the best of our knowledge, this is the first work to address the problem of composing To-Do items from emails.","smart - : automatic generation - item email intelligent feature email service application aim increase productivity help people organize folder , compose email respond pende task . work , explore new application , smart - - , help user task management email . introduce new task dataset automatically generate - item email sender promise perform action . design - stage process leverage recent advance neural text generation sequenceto - sequence learning , obtain bleu rouge score 0.23 0.63 task . good knowledge , work address problem compose - item email .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Paraphrase Generation by Learning How to Edit from Samples,"Neural sequence to sequence text generation has been proved to be a viable approach to paraphrase generation. Despite promising results, paraphrases generated by these models mostly suffer from lack of quality and diversity. To address these problems, we propose a novel retrieval-based method for paraphrase generation. Our model first retrieves a paraphrase pair similar to the input sentence from a pre-defined index. With its novel editor module, the model then paraphrases the input sequence by editing it using the extracted relations between the retrieved pair of sentences. In order to have fine-grained control over the editing process, our model uses the newly introduced concept of Micro Edit Vectors. It both extracts and exploits these vectors using the attention mechanism in the Transformer architecture. Experimental results show the superiority of our paraphrase generation method in terms of both automatic metrics, and human evaluation of relevance, grammaticality, and diversity of generated paraphrases.","Paraphrase Generation by Learning How to Edit from Samples Neural sequence to sequence text generation has been proved to be a viable approach to paraphrase generation. Despite promising results, paraphrases generated by these models mostly suffer from lack of quality and diversity. To address these problems, we propose a novel retrieval-based method for paraphrase generation. Our model first retrieves a paraphrase pair similar to the input sentence from a pre-defined index. With its novel editor module, the model then paraphrases the input sequence by editing it using the extracted relations between the retrieved pair of sentences. In order to have fine-grained control over the editing process, our model uses the newly introduced concept of Micro Edit Vectors. It both extracts and exploits these vectors using the attention mechanism in the Transformer architecture. Experimental results show the superiority of our paraphrase generation method in terms of both automatic metrics, and human evaluation of relevance, grammaticality, and diversity of generated paraphrases.","paraphrase generation learn edit sample neural sequence sequence text generation prove viable approach paraphrase generation . despite promising result , paraphrase generate model suffer lack quality diversity . address problem , propose novel retrieval - base method paraphrase generation . model retrieve paraphrase pair similar input sentence pre - defined index . novel editor module , model paraphrase input sequence edit extract relation retrieve pair sentence . order fine - grained control editing process , model use newly introduce concept micro edit vectors . extract exploit vector attention mechanism transformer architecture . experimental result superiority paraphrase generation method term automatic metric , human evaluation relevance , grammaticality , diversity generate paraphrase .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 14, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,DeSePtion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking,"The increased focus on misinformation has spurred development of data and systems for detecting the veracity of a claim as well as retrieving authoritative evidence. The Fact Extraction and VERification (FEVER) dataset provides such a resource for evaluating endto-end fact-checking, requiring retrieval of evidence from Wikipedia to validate a veracity prediction. We show that current systems for FEVER are vulnerable to three categories of realistic challenges for fact-checking -multiple propositions, temporal reasoning, and ambiguity and lexical variation -and introduce a resource with these types of claims. Then we present a system designed to be resilient to these ""attacks"" using multiple pointer networks for document selection and jointly modeling a sequence of evidence sentences and veracity relation predictions. We find that in handling these attacks we obtain state-of-the-art results on FEVER, largely due to improved evidence retrieval.","DeSePtion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking The increased focus on misinformation has spurred development of data and systems for detecting the veracity of a claim as well as retrieving authoritative evidence. The Fact Extraction and VERification (FEVER) dataset provides such a resource for evaluating endto-end fact-checking, requiring retrieval of evidence from Wikipedia to validate a veracity prediction. We show that current systems for FEVER are vulnerable to three categories of realistic challenges for fact-checking -multiple propositions, temporal reasoning, and ambiguity and lexical variation -and introduce a resource with these types of claims. Then we present a system designed to be resilient to these ""attacks"" using multiple pointer networks for document selection and jointly modeling a sequence of evidence sentences and veracity relation predictions. We find that in handling these attacks we obtain state-of-the-art results on FEVER, largely due to improved evidence retrieval.","deseption : dual sequence prediction adversarial example improve fact - checking increase focus misinformation spur development datum system detect veracity claim retrieve authoritative evidence . fact extraction verification ( fever ) dataset provide resource evaluate endto - end fact - checking , require retrieval evidence wikipedia validate veracity prediction . current system fever vulnerable category realistic challenge fact - checking -multiple proposition , temporal reasoning , ambiguity lexical variation -and introduce resource type claim . present system design resilient "" attack "" multiple pointer network document selection jointly model sequence evidence sentence veracity relation prediction . find handle attack obtain state - - - art result fever , largely improve evidence retrieval .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Improving Segmentation for Technical Support Problems,"Technical support problems are often long and complex. They typically contain user descriptions of the problem, the setup, and steps for attempted resolution. Often they also contain various non-natural language text elements like outputs of commands, snippets of code, error messages or stack traces. These elements contain potentially crucial information for problem resolution. However, they cannot be correctly parsed by tools designed for natural language. In this paper, we address the problem of segmentation for technical support questions. We formulate the problem as a sequence labelling task, and study the performance of state of the art approaches. We compare this against an intuitive contextual sentence-level classification baseline, and a state of the art supervised text-segmentation approach. We also introduce a novel component of combining contextual embeddings from multiple language models pre-trained on different data sources, which achieves a marked improvement over using embeddings from a single pre-trained language model. Finally, we also demonstrate the usefulness of such segmentation with improvements on the downstream task of answer retrieval.","Improving Segmentation for Technical Support Problems Technical support problems are often long and complex. They typically contain user descriptions of the problem, the setup, and steps for attempted resolution. Often they also contain various non-natural language text elements like outputs of commands, snippets of code, error messages or stack traces. These elements contain potentially crucial information for problem resolution. However, they cannot be correctly parsed by tools designed for natural language. In this paper, we address the problem of segmentation for technical support questions. We formulate the problem as a sequence labelling task, and study the performance of state of the art approaches. We compare this against an intuitive contextual sentence-level classification baseline, and a state of the art supervised text-segmentation approach. We also introduce a novel component of combining contextual embeddings from multiple language models pre-trained on different data sources, which achieves a marked improvement over using embeddings from a single pre-trained language model. Finally, we also demonstrate the usefulness of such segmentation with improvements on the downstream task of answer retrieval.","improve segmentation technical support problem technical support problem long complex . typically contain user description problem , setup , step attempt resolution . contain non - natural language text element like output command , snippet code , error message stack trace . element contain potentially crucial information problem resolution . , correctly parse tool design natural language . paper , address problem segmentation technical support question . formulate problem sequence labelling task , study performance state art approach . compare intuitive contextual sentence - level classification baseline , state art supervise text - segmentation approach . introduce novel component combine contextual embedding multiple language model pre - train different data source , achieve marked improvement embedding single pre - trained language model . finally , demonstrate usefulness segmentation improvement downstream task answer retrieval .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 2, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Toxicity Detection: Does Context Really Matter?,"Moderation is crucial to promoting healthy online discussions. Although several 'toxicity' detection datasets and models have been published, most of them ignore the context of the posts, implicitly assuming that comments may be judged independently. We investigate this assumption by focusing on two questions: (a) does context affect the human judgement, and (b) does conditioning on context improve performance of toxicity detection systems? We experiment with Wikipedia conversations, limiting the notion of context to the previous post in the thread and the discussion title. We find that context can both amplify or mitigate the perceived toxicity of posts. Moreover, a small but significant subset of manually labeled posts (5% in one of our experiments) end up having the opposite toxicity labels if the annotators are not provided with context. Surprisingly, we also find no evidence that context actually improves the performance of toxicity classifiers, having tried a range of classifiers and mechanisms to make them context aware. This points to the need for larger datasets of comments annotated in context. We make our code and data publicly available.","Toxicity Detection: Does Context Really Matter? Moderation is crucial to promoting healthy online discussions. Although several 'toxicity' detection datasets and models have been published, most of them ignore the context of the posts, implicitly assuming that comments may be judged independently. We investigate this assumption by focusing on two questions: (a) does context affect the human judgement, and (b) does conditioning on context improve performance of toxicity detection systems? We experiment with Wikipedia conversations, limiting the notion of context to the previous post in the thread and the discussion title. We find that context can both amplify or mitigate the perceived toxicity of posts. Moreover, a small but significant subset of manually labeled posts (5% in one of our experiments) end up having the opposite toxicity labels if the annotators are not provided with context. Surprisingly, we also find no evidence that context actually improves the performance of toxicity classifiers, having tried a range of classifiers and mechanisms to make them context aware. This points to the need for larger datasets of comments annotated in context. We make our code and data publicly available.","toxicity detection : context matter ? moderation crucial promote healthy online discussion . ' toxicity ' detection dataset model publish , ignore context post , implicitly assume comment judge independently . investigate assumption focus question : ( ) context affect human judgement , ( b ) condition context improve performance toxicity detection system ? experiment wikipedia conversation , limit notion context previous post thread discussion title . find context amplify mitigate perceive toxicity post . , small significant subset manually label post ( 5 % experiment ) end have opposite toxicity label annotator provide context . surprisingly , find evidence context actually improve performance toxicity classifier , have try range classifier mechanism context aware . point need large dataset comment annotate context . code datum publicly available .","{'Computational Social Science and Social Media': 5, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Empowering Active Learning to Jointly Optimize System and User Demands,"Existing approaches to active learning maximize the system performance by sampling unlabeled instances for annotation that yield the most efficient training. However, when active learning is integrated with an end-user application, this can lead to frustration for participating users, as they spend time labeling instances that they would not otherwise be interested in reading. In this paper, we propose a new active learning approach that jointly optimizes the seemingly counteracting objectives of the active learning system (training efficiently) and the user (receiving useful instances). We study our approach in an educational application, which particularly benefits from this technique as the system needs to rapidly learn to predict the appropriateness of an exercise to a particular user, while the users should receive only exercises that match their skills. We evaluate multiple learning strategies and user types with data from real users and find that our joint approach better satisfies both objectives when alternative methods lead to many unsuitable exercises for end users. 1","Empowering Active Learning to Jointly Optimize System and User Demands Existing approaches to active learning maximize the system performance by sampling unlabeled instances for annotation that yield the most efficient training. However, when active learning is integrated with an end-user application, this can lead to frustration for participating users, as they spend time labeling instances that they would not otherwise be interested in reading. In this paper, we propose a new active learning approach that jointly optimizes the seemingly counteracting objectives of the active learning system (training efficiently) and the user (receiving useful instances). We study our approach in an educational application, which particularly benefits from this technique as the system needs to rapidly learn to predict the appropriateness of an exercise to a particular user, while the users should receive only exercises that match their skills. We evaluate multiple learning strategies and user types with data from real users and find that our joint approach better satisfies both objectives when alternative methods lead to many unsuitable exercises for end users. 1","empower active learning jointly optimize system user demand exist approach active learning maximize system performance sample unlabeled instance annotation yield efficient training . , active learning integrate end - user application , lead frustration participate user , spend time label instance interested read . paper , propose new active learning approach jointly optimize seemingly counteract objective active learning system ( train efficiently ) user ( receive useful instance ) . study approach educational application , particularly benefit technique system need rapidly learn predict appropriateness exercise particular user , user receive exercise match skill . evaluate multiple learning strategy user type datum real user find joint approach well satisfy objective alternative method lead unsuitable exercise end user . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 16, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 13, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,True
NLP Applications,MMPE: A Multi-Modal Interface for Post-Editing Machine Translation,"Current advances in machine translation (MT) increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and reduces errors. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than mouse and keyboard, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while they are of limited use for longer insertions. On the other hand, speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions but offer less potential for deletion and reordering. Overall, participants were enthusiastic about the new modalities and saw them as good extensions to mouse & keyboard, but not as a complete substitute.","MMPE: A Multi-Modal Interface for Post-Editing Machine Translation Current advances in machine translation (MT) increase the need for translators to switch from traditional translation to post-editing (PE) of machine-translated text, a process that saves time and reduces errors. This affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than mouse and keyboard, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while they are of limited use for longer insertions. On the other hand, speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions but offer less potential for deletion and reordering. Overall, participants were enthusiastic about the new modalities and saw them as good extensions to mouse & keyboard, but not as a complete substitute.","mmpe : multi - modal interface post - editing machine translation current advance machine translation ( mt ) increase need translator switch traditional translation post - editing ( pe ) machine - translate text , process save time reduce error . affect design translation interface , task change mainly generate text correct error helpful translation proposal . paradigm shift offer potential modality mouse keyboard , present mmpe , prototype combine traditional input mode pen , touch , speech modality pe mt . result evaluation professional translator suggest pen touch interaction suitable deletion reordering task , limited use long insertion . hand , speech multi - modal combination select & speech consider suitable replacement insertion offer potential deletion reordering . overall , participant enthusiastic new modality see good extension mouse & keyboard , complete substitute .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
NLP Applications,SpellGCN: Incorporating Phonological and Visual Similarities into Language Models for Chinese Spelling Check,"Chinese Spelling Check (CSC) is a task to detect and correct spelling errors in Chinese natural language. Existing methods have made attempts to incorporate the similarity knowledge between Chinese characters. However, they take the similarity knowledge as either an external input resource or just heuristic rules. This paper proposes to incorporate phonological and visual similarity knowledge into language models for CSC via a specialized graph convolutional network (SpellGCN). The model builds a graph over the characters, and SpellGCN is learned to map this graph into a set of inter-dependent character classifiers. These classifiers are applied to the representations extracted by another network, such as BERT, enabling the whole network to be end-to-end trainable. Experiments 1 are conducted on three human-annotated datasets. Our method achieves superior performance against previous models by a large margin.","SpellGCN: Incorporating Phonological and Visual Similarities into Language Models for Chinese Spelling Check Chinese Spelling Check (CSC) is a task to detect and correct spelling errors in Chinese natural language. Existing methods have made attempts to incorporate the similarity knowledge between Chinese characters. However, they take the similarity knowledge as either an external input resource or just heuristic rules. This paper proposes to incorporate phonological and visual similarity knowledge into language models for CSC via a specialized graph convolutional network (SpellGCN). The model builds a graph over the characters, and SpellGCN is learned to map this graph into a set of inter-dependent character classifiers. These classifiers are applied to the representations extracted by another network, such as BERT, enabling the whole network to be end-to-end trainable. Experiments 1 are conducted on three human-annotated datasets. Our method achieves superior performance against previous models by a large margin.","spellgcn : incorporate phonological visual similarity language model chinese spelling check chinese spelling check ( csc ) task detect correct spelling error chinese natural language . exist method attempt incorporate similarity knowledge chinese character . , similarity knowledge external input resource heuristic rule . paper propose incorporate phonological visual similarity knowledge language model csc specialized graph convolutional network ( spellgcn ) . model build graph character , spellgcn learn map graph set inter - dependent character classifier . classifier apply representation extract network , bert , enable network end - - end trainable . experiment 1 conduct human - annotated dataset . method achieve superior performance previous model large margin .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
NLP Applications,Identifying Principals and Accessories in a Complex Case based on the Comprehension of Fact Description,"In this paper, we study the problem of identifying the principals and accessories from the fact description with multiple defendants in a criminal case. We treat the fact descriptions as narrative texts and the defendants as roles over the narrative story. We propose to model the defendants with behavioral semantic information and statistical characteristics, then learning the importances of defendants within a learning-to-rank framework. Experimental results on a real-world dataset demonstrate the behavior analysis can effectively model the defendants' impacts in a complex case.","Identifying Principals and Accessories in a Complex Case based on the Comprehension of Fact Description In this paper, we study the problem of identifying the principals and accessories from the fact description with multiple defendants in a criminal case. We treat the fact descriptions as narrative texts and the defendants as roles over the narrative story. We propose to model the defendants with behavioral semantic information and statistical characteristics, then learning the importances of defendants within a learning-to-rank framework. Experimental results on a real-world dataset demonstrate the behavior analysis can effectively model the defendants' impacts in a complex case.","identify principal accessory complex case base comprehension fact description paper , study problem identify principal accessory fact description multiple defendant criminal case . treat fact description narrative text defendant role narrative story . propose model defendant behavioral semantic information statistical characteristic , learn importance defendant learn - - rank framework . experimental result real - world dataset demonstrate behavior analysis effectively model defendant ' impact complex case .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
NLP Applications,Interpreting Twitter User Geolocation,"Identifying user geolocation in online social networks is an essential task in many locationbased applications. Existing methods rely on the similarity of text and network structure, however, they suffer from a lack of interpretability on the corresponding results, which is crucial for understanding model behavior. In this work, we adopt influence functions to interpret the behavior of GNN-based models by identifying the importance of training users when predicting the locations of the testing users. This methodology helps with providing meaningful explanations on prediction results. Furthermore, it also initiates an attempt to uncover the so-called ""black-box"" GNN-based models by investigating the effect of individual nodes.","Interpreting Twitter User Geolocation Identifying user geolocation in online social networks is an essential task in many locationbased applications. Existing methods rely on the similarity of text and network structure, however, they suffer from a lack of interpretability on the corresponding results, which is crucial for understanding model behavior. In this work, we adopt influence functions to interpret the behavior of GNN-based models by identifying the importance of training users when predicting the locations of the testing users. This methodology helps with providing meaningful explanations on prediction results. Furthermore, it also initiates an attempt to uncover the so-called ""black-box"" GNN-based models by investigating the effect of individual nodes.","interpret twitter user geolocation identify user geolocation online social network essential task locationbased application . exist method rely similarity text network structure , , suffer lack interpretability correspond result , crucial understand model behavior . work , adopt influence function interpret behavior gnn - base model identify importance train user predict location test user . methodology help provide meaningful explanation prediction result . furthermore , initiate attempt uncover - call "" black - box "" gnn - base model investigate effect individual node .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference,"Large-scale pre-trained language models such as BERT have brought significant improvements to NLP applications. However, they are also notorious for being slow in inference, which makes them difficult to deploy in realtime applications. We propose a simple but effective method, DeeBERT, to accelerate BERT inference. Our approach allows samples to exit earlier without passing through the entire model. Experiments show that DeeBERT is able to save up to âˆ¼40% inference time with minimal degradation in model quality. Further analyses show different behaviors in the BERT transformer layers and also reveal their redundancy. Our work provides new ideas to efficiently apply deep transformer-based models to downstream tasks. Code is available at https://github.com/castorini/ DeeBERT.","DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference Large-scale pre-trained language models such as BERT have brought significant improvements to NLP applications. However, they are also notorious for being slow in inference, which makes them difficult to deploy in realtime applications. We propose a simple but effective method, DeeBERT, to accelerate BERT inference. Our approach allows samples to exit earlier without passing through the entire model. Experiments show that DeeBERT is able to save up to âˆ¼40% inference time with minimal degradation in model quality. Further analyses show different behaviors in the BERT transformer layers and also reveal their redundancy. Our work provides new ideas to efficiently apply deep transformer-based models to downstream tasks. Code is available at https://github.com/castorini/ DeeBERT.","deebert : dynamic early exiting accelerate bert inference large - scale pre - trained language model bert bring significant improvement nlp application . , notorious slow inference , make difficult deploy realtime application . propose simple effective method , deebert , accelerate bert inference . approach allow sample exit early pass entire model . experiment deebert able save âˆ¼40 % inference time minimal degradation model quality . analysis different behavior bert transformer layer reveal redundancy . work provide new idea efficiently apply deep transformer - base model downstream task . code available https://github.com/castorini/ deebert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Investigating the effect of auxiliary objectives for the automated grading of learner English speech transcriptions,"We address the task of automatically grading the language proficiency of spontaneous speech based on textual features from automatic speech recognition transcripts. Motivated by recent advances in multi-task learning, we develop neural networks trained in a multi-task fashion that learn to predict the proficiency level of non-native English speakers by taking advantage of inductive transfer between the main task (grading) and auxiliary prediction tasks: morpho-syntactic labeling, language modeling, and native language identification (L1). We encode the transcriptions with both bi-directional recurrent neural networks and with bi-directional representations from transformers, compare against a featurerich baseline, and analyse performance at different proficiency levels and with transcriptions of varying error rates. Our best performance comes from a transformer encoder with L1 prediction as an auxiliary task. We discuss areas for improvement and potential applications for text-only speech scoring.","Investigating the effect of auxiliary objectives for the automated grading of learner English speech transcriptions We address the task of automatically grading the language proficiency of spontaneous speech based on textual features from automatic speech recognition transcripts. Motivated by recent advances in multi-task learning, we develop neural networks trained in a multi-task fashion that learn to predict the proficiency level of non-native English speakers by taking advantage of inductive transfer between the main task (grading) and auxiliary prediction tasks: morpho-syntactic labeling, language modeling, and native language identification (L1). We encode the transcriptions with both bi-directional recurrent neural networks and with bi-directional representations from transformers, compare against a featurerich baseline, and analyse performance at different proficiency levels and with transcriptions of varying error rates. Our best performance comes from a transformer encoder with L1 prediction as an auxiliary task. We discuss areas for improvement and potential applications for text-only speech scoring.","investigate effect auxiliary objective automate grading learner english speech transcription address task automatically grade language proficiency spontaneous speech base textual feature automatic speech recognition transcript . motivate recent advance multi - task learning , develop neural network train multi - task fashion learn predict proficiency level non - native english speaker take advantage inductive transfer main task ( grading ) auxiliary prediction task : morpho - syntactic labeling , language modeling , native language identification ( l1 ) . encode transcription bi - directional recurrent neural network bi - directional representation transformer , compare featurerich baseline , analyse performance different proficiency level transcription vary error rate . good performance come transformer encoder l1 prediction auxiliary task . discuss area improvement potential application text - speech scoring .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
NLP Applications,Language to Network: Conditional Parameter Adaptation with Natural Language Descriptions,"Transfer learning using ImageNet pre-trained models has been the de facto approach in a wide range of computer vision tasks. However, fine-tuning still requires task-specific training data. In this paper, we propose N 3 (Neural Networks from Natural Language) -a new paradigm of synthesizing task-specific neural networks from language descriptions and a generic pre-trained model. N 3 leverages language descriptions to generate parameter adaptations as well as a new task-specific classification layer for a pre-trained neural network, effectively ""fine-tuning"" the network for a new task using only language descriptions as input. To the best of our knowledge, N 3 is the first method to synthesize entire neural networks from natural language. Experimental results show that N 3 can out-perform previous natural-language based zero-shot learning methods across 4 different zero-shot image classification benchmarks. We also demonstrate a simple method to help identify keywords in language descriptions leveraged by N 3 when synthesizing model parameters. 1 * First two authors contributed equally. â™¦ This work was performed when Zhun Liu was affiliated with Carnegie Mellon University. 1 Code is released at https://github.com/tjingrant/n3cr . Husky This breed has a well rounded, apple like shaped head with a muzzle that is tiny in contrast to the head.","Language to Network: Conditional Parameter Adaptation with Natural Language Descriptions Transfer learning using ImageNet pre-trained models has been the de facto approach in a wide range of computer vision tasks. However, fine-tuning still requires task-specific training data. In this paper, we propose N 3 (Neural Networks from Natural Language) -a new paradigm of synthesizing task-specific neural networks from language descriptions and a generic pre-trained model. N 3 leverages language descriptions to generate parameter adaptations as well as a new task-specific classification layer for a pre-trained neural network, effectively ""fine-tuning"" the network for a new task using only language descriptions as input. To the best of our knowledge, N 3 is the first method to synthesize entire neural networks from natural language. Experimental results show that N 3 can out-perform previous natural-language based zero-shot learning methods across 4 different zero-shot image classification benchmarks. We also demonstrate a simple method to help identify keywords in language descriptions leveraged by N 3 when synthesizing model parameters. 1 * First two authors contributed equally. â™¦ This work was performed when Zhun Liu was affiliated with Carnegie Mellon University. 1 Code is released at https://github.com/tjingrant/n3cr . Husky This breed has a well rounded, apple like shaped head with a muzzle that is tiny in contrast to the head.","language network : conditional parameter adaptation natural language description transfer learning imagenet pre - train model de facto approach wide range computer vision task . , fine - tuning require task - specific training datum . paper , propose n 3 ( neural networks natural language ) -a new paradigm synthesize task - specific neural network language description generic pre - trained model . n 3 leverage language description generate parameter adaptation new task - specific classification layer pre - trained neural network , effectively "" fine - tune "" network new task language description input . good knowledge , n 3 method synthesize entire neural network natural language . experimental result n 3 - perform previous natural - language base zero - shot learning method 4 different zero - shot image classification benchmark . demonstrate simple method help identify keyword language description leverage n 3 synthesize model parameter . 1 * author contribute equally . â™¦ work perform zhun liu affiliate carnegie mellon university . 1 code release https://github.com/tjingrant/n3cr . husky breed rounded , apple like shape head muzzle tiny contrast head .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Closing the Gap: Joint De-Identification and Concept Extraction in the Clinical Domain,"Exploiting natural language processing in the clinical domain requires de-identification, i.e., anonymization of personal information in texts. However, current research considers de-identification and downstream tasks, such as concept extraction, only in isolation and does not study the effects of de-identification on other tasks. In this paper, we close this gap by reporting concept extraction performance on automatically anonymized data and investigating joint models for de-identification and concept extraction. In particular, we propose a stacked model with restricted access to privacy-sensitive information and a multitask model. We set the new state of the art on benchmark datasets in English (96.1% F1 for de-identification and 88.9% F1 for concept extraction) and Spanish (91.4% F1 for concept extraction).","Closing the Gap: Joint De-Identification and Concept Extraction in the Clinical Domain Exploiting natural language processing in the clinical domain requires de-identification, i.e., anonymization of personal information in texts. However, current research considers de-identification and downstream tasks, such as concept extraction, only in isolation and does not study the effects of de-identification on other tasks. In this paper, we close this gap by reporting concept extraction performance on automatically anonymized data and investigating joint models for de-identification and concept extraction. In particular, we propose a stacked model with restricted access to privacy-sensitive information and a multitask model. We set the new state of the art on benchmark datasets in English (96.1% F1 for de-identification and 88.9% F1 for concept extraction) and Spanish (91.4% F1 for concept extraction).","close gap : joint de - identification concept extraction clinical domain exploit natural language processing clinical domain require de - identification , i.e. , anonymization personal information text . , current research consider de - identification downstream task , concept extraction , isolation study effect de - identification task . paper , close gap report concept extraction performance automatically anonymize datum investigate joint model de - identification concept extraction . particular , propose stack model restricted access privacy - sensitive information multitask model . set new state art benchmark dataset english ( 96.1 % f1 de - identification 88.9 % f1 concept extraction ) spanish ( 91.4 % f1 concept extraction ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
NLP Applications,Towards Interpretable Clinical Diagnosis with Bayesian Network Ensembles Stacked on Entity-Aware CNNs,"The automatic text-based diagnosis remains a challenging task for clinical use because it requires appropriate balance between accuracy and interpretability. In this paper, we attempt to propose a solution by introducing a novel framework that stacks Bayesian Network Ensembles on top of Entity-Aware Convolutional Neural Networks (CNN) towards building an accurate yet interpretable diagnosis system. The proposed framework takes advantage of the high accuracy and generality of deep neural networks as well as the interpretability of Bayesian Networks, which is critical for AI-empowered healthcare. The evaluation conducted on the real Electronic Medical Record (EMR) documents from hospitals and annotated by professional doctors proves that, the proposed framework outperforms the previous automatic diagnosis methods in accuracy performance and the diagnosis explanation of the framework is reasonable.","Towards Interpretable Clinical Diagnosis with Bayesian Network Ensembles Stacked on Entity-Aware CNNs The automatic text-based diagnosis remains a challenging task for clinical use because it requires appropriate balance between accuracy and interpretability. In this paper, we attempt to propose a solution by introducing a novel framework that stacks Bayesian Network Ensembles on top of Entity-Aware Convolutional Neural Networks (CNN) towards building an accurate yet interpretable diagnosis system. The proposed framework takes advantage of the high accuracy and generality of deep neural networks as well as the interpretability of Bayesian Networks, which is critical for AI-empowered healthcare. The evaluation conducted on the real Electronic Medical Record (EMR) documents from hospitals and annotated by professional doctors proves that, the proposed framework outperforms the previous automatic diagnosis methods in accuracy performance and the diagnosis explanation of the framework is reasonable.","interpretable clinical diagnosis bayesian network ensembles stack entity - aware cnns automatic text - base diagnosis remain challenging task clinical use require appropriate balance accuracy interpretability . paper , attempt propose solution introduce novel framework stack bayesian network ensembles entity - aware convolutional neural networks ( cnn ) build accurate interpretable diagnosis system . propose framework take advantage high accuracy generality deep neural network interpretability bayesian networks , critical ai - empower healthcare . evaluation conduct real electronic medical record ( emr ) document hospital annotate professional doctor prove , propose framework outperform previous automatic diagnosis method accuracy performance diagnosis explanation framework reasonable .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Distinguish Confusing Law Articles for Legal Judgment Prediction,"Legal Judgment Prediction (LJP) is the task of automatically predicting a law case's judgment results given a text describing its facts, which has excellent prospects in judicial assistance systems and convenient services for the public. In practice, confusing charges are frequent, because law cases applicable to similar law articles are easily misjudged. For addressing this issue, the existing method relies heavily on domain experts, which hinders its application in different law systems. In this paper, we present an end-to-end model, LADAN, to solve the task of LJP. To distinguish confusing charges, we propose a novel graph neural network to automatically learn subtle differences between confusing law articles and design a novel attention mechanism that fully exploits the learned differences to extract compelling discriminative features from fact descriptions attentively. Experiments conducted on realworld datasets demonstrate the superiority of our LADAN.","Distinguish Confusing Law Articles for Legal Judgment Prediction Legal Judgment Prediction (LJP) is the task of automatically predicting a law case's judgment results given a text describing its facts, which has excellent prospects in judicial assistance systems and convenient services for the public. In practice, confusing charges are frequent, because law cases applicable to similar law articles are easily misjudged. For addressing this issue, the existing method relies heavily on domain experts, which hinders its application in different law systems. In this paper, we present an end-to-end model, LADAN, to solve the task of LJP. To distinguish confusing charges, we propose a novel graph neural network to automatically learn subtle differences between confusing law articles and design a novel attention mechanism that fully exploits the learned differences to extract compelling discriminative features from fact descriptions attentively. Experiments conducted on realworld datasets demonstrate the superiority of our LADAN.","distinguish confuse law article legal judgment prediction legal judgment prediction ( ljp ) task automatically predict law case judgment result give text describe fact , excellent prospect judicial assistance system convenient service public . practice , confuse charge frequent , law case applicable similar law article easily misjudge . address issue , exist method rely heavily domain expert , hinder application different law system . paper , present end - - end model , ladan , solve task ljp . distinguish confusing charge , propose novel graph neural network automatically learn subtle difference confuse law article design novel attention mechanism fully exploit learn difference extract compelling discriminative feature fact description attentively . experiment conduct realworld dataset demonstrate superiority ladan .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Multi-Label and Multilingual News Framing Analysis,"News framing refers to the practice in which aspects of specific issues are highlighted in the news to promote a particular interpretation. In NLP, although recent works have studied framing in English news, few have studied how the analysis can be extended to other languages and in a multi-label setting. In this work, we explore multilingual transfer learning to detect multiple frames from just the news headline in a genuinely low-resource context where there are few/no frame annotations in the target language. We propose a novel method that can leverage elementary resources consisting of a dictionary and few annotations to detect frames in the target language. Our method performs comparably or better than translating the entire target language headline to the source language for which we have annotated data. This work opens up an exciting new capability of scaling up frame analysis to many languages, even those without existing translation technologies. Lastly, we apply our method to detect frames on the issue of U.S. gun violence in multiple languages and obtain exciting insights on the relationship between different frames of the same problem across different countries with different languages.","Multi-Label and Multilingual News Framing Analysis News framing refers to the practice in which aspects of specific issues are highlighted in the news to promote a particular interpretation. In NLP, although recent works have studied framing in English news, few have studied how the analysis can be extended to other languages and in a multi-label setting. In this work, we explore multilingual transfer learning to detect multiple frames from just the news headline in a genuinely low-resource context where there are few/no frame annotations in the target language. We propose a novel method that can leverage elementary resources consisting of a dictionary and few annotations to detect frames in the target language. Our method performs comparably or better than translating the entire target language headline to the source language for which we have annotated data. This work opens up an exciting new capability of scaling up frame analysis to many languages, even those without existing translation technologies. Lastly, we apply our method to detect frames on the issue of U.S. gun violence in multiple languages and obtain exciting insights on the relationship between different frames of the same problem across different countries with different languages.","multi - label multilingual news framing analysis news framing refer practice aspect specific issue highlight news promote particular interpretation . nlp , recent work study framing english news , study analysis extend language multi - label setting . work , explore multilingual transfer learning detect multiple frame news headline genuinely low - resource context / frame annotation target language . propose novel method leverage elementary resource consist dictionary annotation detect frame target language . method perform comparably well translate entire target language headline source language annotate datum . work open exciting new capability scale frame analysis language , exist translation technology . lastly , apply method detect frame issue u.s. gun violence multiple language obtain exciting insight relationship different frame problem different country different language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,True
NLP Applications,Fine-grained Interest Matching for Neural News Recommendation,"Personalized news recommendation is a critical technology to improve users' online news reading experience. The core of news recommendation is accurate matching between user's interests and candidate news. The same user usually has diverse interests that are reflected in different news she has browsed. Meanwhile, important semantic features of news are implied in text segments of different granularities. Existing studies generally represent each user as a single vector and then match the candidate news vector, which may lose fine-grained information for recommendation. In this paper, we propose FIM, a Finegrained Interest Matching method for neural news recommendation. Instead of aggregating user's all historical browsed news into a unified vector, we hierarchically construct multilevel representations for each news via stacked dilated convolutions. Then we perform finegrained matching between segment pairs of each browsed news and the candidate news at each semantic level. High-order salient signals are then identified by resembling the hierarchy of image recognition for final click prediction. Extensive experiments on a real-world dataset from MSN news validate the effectiveness of our model on news recommendation.","Fine-grained Interest Matching for Neural News Recommendation Personalized news recommendation is a critical technology to improve users' online news reading experience. The core of news recommendation is accurate matching between user's interests and candidate news. The same user usually has diverse interests that are reflected in different news she has browsed. Meanwhile, important semantic features of news are implied in text segments of different granularities. Existing studies generally represent each user as a single vector and then match the candidate news vector, which may lose fine-grained information for recommendation. In this paper, we propose FIM, a Finegrained Interest Matching method for neural news recommendation. Instead of aggregating user's all historical browsed news into a unified vector, we hierarchically construct multilevel representations for each news via stacked dilated convolutions. Then we perform finegrained matching between segment pairs of each browsed news and the candidate news at each semantic level. High-order salient signals are then identified by resembling the hierarchy of image recognition for final click prediction. Extensive experiments on a real-world dataset from MSN news validate the effectiveness of our model on news recommendation.","fine - grained interest matching neural news recommendation personalized news recommendation critical technology improve user ' online news reading experience . core news recommendation accurate matching user interest candidate news . user usually diverse interest reflect different news browse . , important semantic feature news imply text segment different granularity . exist study generally represent user single vector match candidate news vector , lose fine - grained information recommendation . paper , propose fim , finegrained interest matching method neural news recommendation . instead aggregate user historical browse news unified vector , hierarchically construct multilevel representation news stack dilate convolution . perform finegrained matching segment pair browse news candidate news semantic level . high - order salient signal identify resemble hierarchy image recognition final click prediction . extensive experiment real - world dataset msn news validate effectiveness model news recommendation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 31, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",NLP Applications,True
NLP Applications,Predicting Performance for Natural Language Processing Tasks,"Given the complexity of combinations of tasks, languages, and domains in natural language processing (NLP) research, it is computationally prohibitive to exhaustively test newly proposed models on each possible experimental setting. In this work, we attempt to explore the possibility of gaining plausible judgments of how well an NLP model can perform under an experimental setting, without actually training or testing the model. To do so, we build regression models to predict the evaluation score of an NLP experiment given the experimental settings as input. Experimenting on 9 different NLP tasks, we find that our predictors can produce meaningful predictions over unseen languages and different modeling architectures, outperforming reasonable baselines as well as human experts. Going further, we outline how our predictor can be used to find a small subset of representative experiments that should be run in order to obtain plausible predictions for all other experimental settings. 1","Predicting Performance for Natural Language Processing Tasks Given the complexity of combinations of tasks, languages, and domains in natural language processing (NLP) research, it is computationally prohibitive to exhaustively test newly proposed models on each possible experimental setting. In this work, we attempt to explore the possibility of gaining plausible judgments of how well an NLP model can perform under an experimental setting, without actually training or testing the model. To do so, we build regression models to predict the evaluation score of an NLP experiment given the experimental settings as input. Experimenting on 9 different NLP tasks, we find that our predictors can produce meaningful predictions over unseen languages and different modeling architectures, outperforming reasonable baselines as well as human experts. Going further, we outline how our predictor can be used to find a small subset of representative experiments that should be run in order to obtain plausible predictions for all other experimental settings. 1","predict performance natural language processing task give complexity combination task , language , domain natural language processing ( nlp ) research , computationally prohibitive exhaustively test newly propose model possible experimental setting . work , attempt explore possibility gain plausible judgment nlp model perform experimental setting , actually train test model . , build regression model predict evaluation score nlp experiment give experimental setting input . experiment 9 different nlp task , find predictor produce meaningful prediction unseen language different model architecture , outperform reasonable baseline human expert . go , outline predictor find small subset representative experiment run order obtain plausible prediction experimental setting . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction,"This paper investigates how to effectively incorporate a pre-trained masked language model (MLM), such as BERT, into an encoderdecoder (EncDec) model for grammatical error correction (GEC). The answer to this question is not as straightforward as one might expect because the previous common methods for incorporating a MLM into an EncDec model have potential drawbacks when applied to GEC. For example, the distribution of the inputs to a GEC model can be considerably different (erroneous, clumsy, etc.) from that of the corpora used for pre-training MLMs; however, this issue is not addressed in the previous methods. Our experiments show that our proposed method, where we first fine-tune a MLM with a given GEC corpus and then use the output of the finetuned MLM as additional features in the GEC model, maximizes the benefit of the MLM. The best-performing model achieves state-ofthe-art performances on the BEA-2019 and CoNLL-2014 benchmarks. Our code is publicly available at: https://github.com/ kanekomasahiro/bert-gec.","Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction This paper investigates how to effectively incorporate a pre-trained masked language model (MLM), such as BERT, into an encoderdecoder (EncDec) model for grammatical error correction (GEC). The answer to this question is not as straightforward as one might expect because the previous common methods for incorporating a MLM into an EncDec model have potential drawbacks when applied to GEC. For example, the distribution of the inputs to a GEC model can be considerably different (erroneous, clumsy, etc.) from that of the corpora used for pre-training MLMs; however, this issue is not addressed in the previous methods. Our experiments show that our proposed method, where we first fine-tune a MLM with a given GEC corpus and then use the output of the finetuned MLM as additional features in the GEC model, maximizes the benefit of the MLM. The best-performing model achieves state-ofthe-art performances on the BEA-2019 and CoNLL-2014 benchmarks. Our code is publicly available at: https://github.com/ kanekomasahiro/bert-gec.","encoder - decoder model benefit pre - trained masked language model grammatical error correction paper investigate effectively incorporate pre - trained mask language model ( mlm ) , bert , encoderdecoder ( encdec ) model grammatical error correction ( gec ) . answer question straightforward expect previous common method incorporate mlm encdec model potential drawback apply gec . example , distribution input gec model considerably different ( erroneous , clumsy , etc . ) corpus pre - training mlm ; , issue address previous method . experiment propose method , fine - tune mlm give gec corpus use output finetune mlm additional feature gec model , maximize benefit mlm . well - perform model achieve state - ofthe - art performance bea-2019 conll-2014 benchmark . code publicly available : https://github.com/ kanekomasahiro / bert - gec .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 2, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,HyperCore: Hyperbolic and Co-graph Representation for Automatic ICD Coding,"The International Classification of Diseases (ICD) provides a standardized way for classifying diseases, which endows each disease with a unique code. ICD coding aims to assign proper ICD codes to a medical record. Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task. However, most of existing methods independently predict each code, ignoring two important characteristics: Code Hierarchy and Code Co-occurrence. In this paper, we propose a Hyperbolic and Co-graph Representation method (HyperCore) to address the above problem. Specifically, we propose a hyperbolic representation method to leverage the code hierarchy. Moreover, we propose a graph convolutional network to utilize the code co-occurrence. Experimental results on two widely used datasets demonstrate that our proposed model outperforms previous state-ofthe-art methods.","HyperCore: Hyperbolic and Co-graph Representation for Automatic ICD Coding The International Classification of Diseases (ICD) provides a standardized way for classifying diseases, which endows each disease with a unique code. ICD coding aims to assign proper ICD codes to a medical record. Since manual coding is very laborious and prone to errors, many methods have been proposed for the automatic ICD coding task. However, most of existing methods independently predict each code, ignoring two important characteristics: Code Hierarchy and Code Co-occurrence. In this paper, we propose a Hyperbolic and Co-graph Representation method (HyperCore) to address the above problem. Specifically, we propose a hyperbolic representation method to leverage the code hierarchy. Moreover, we propose a graph convolutional network to utilize the code co-occurrence. Experimental results on two widely used datasets demonstrate that our proposed model outperforms previous state-ofthe-art methods.","hypercore : hyperbolic co - graph representation automatic icd coding international classification diseases ( icd ) provide standardized way classify disease , endow disease unique code . icd coding aim assign proper icd code medical record . manual coding laborious prone error , method propose automatic icd coding task . , exist method independently predict code , ignore important characteristic : code hierarchy code co - occurrence . paper , propose hyperbolic co - graph representation method ( hypercore ) address problem . specifically , propose hyperbolic representation method leverage code hierarchy . , propose graph convolutional network utilize code co - occurrence . experimental result widely dataset demonstrate propose model outperform previous state - ofthe - art method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",NLP Applications,True
NLP Applications,A Multi-Perspective Architecture for Semantic Code Search,"The ability to match pieces of code to their corresponding natural language descriptions and vice versa is fundamental for natural language search interfaces to software repositories. In this paper, we propose a novel multiperspective cross-lingual neural framework for code-text matching, inspired in part by a previous model for monolingual text-to-text matching, to capture both global and local similarities. Our experiments on the CoNaLa dataset show that our proposed model yields better performance on this cross-lingual text-to-code matching task than previous approaches that map code and text to a single joint embedding space.","A Multi-Perspective Architecture for Semantic Code Search The ability to match pieces of code to their corresponding natural language descriptions and vice versa is fundamental for natural language search interfaces to software repositories. In this paper, we propose a novel multiperspective cross-lingual neural framework for code-text matching, inspired in part by a previous model for monolingual text-to-text matching, to capture both global and local similarities. Our experiments on the CoNaLa dataset show that our proposed model yields better performance on this cross-lingual text-to-code matching task than previous approaches that map code and text to a single joint embedding space.","multi - perspective architecture semantic code search ability match piece code corresponding natural language description vice versa fundamental natural language search interface software repository . paper , propose novel multiperspective cross - lingual neural framework code - text matching , inspire previous model monolingual text - - text matching , capture global local similarity . experiment conala dataset propose model yield well performance cross - lingual text - - code matching task previous approach map code text single joint embedding space .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,True
NLP Applications,Graph Neural News Recommendation with Unsupervised Preference Disentanglement,"With the explosion of news information, personalized news recommendation has become very important for users to quickly find their interested contents. Most existing methods usually learn the representations of users and news from news contents for recommendation. However, they seldom consider highorder connectivity underlying the user-news interactions. Moreover, existing methods failed to disentangle a user's latent preference factors which cause her clicks on different news. In this paper, we model the usernews interactions as a bipartite graph and propose a novel Graph Neural News Recommendation model with Unsupervised Preference Disentanglement, named GNUD. Our model can encode high-order relationships into user and news representations by information propagation along the graph. Furthermore, the learned representations are disentangled with latent preference factors by a neighborhood routing algorithm, which can enhance expressiveness and interpretability. A preference regularizer is also designed to force each disentangled subspace to independently reflect an isolated preference, improving the quality of the disentangled representations. Experimental results on real-world news datasets demonstrate that our proposed model can effectively improve the performance of news recommendation and outperform state-of-the-art news recommendation methods.","Graph Neural News Recommendation with Unsupervised Preference Disentanglement With the explosion of news information, personalized news recommendation has become very important for users to quickly find their interested contents. Most existing methods usually learn the representations of users and news from news contents for recommendation. However, they seldom consider highorder connectivity underlying the user-news interactions. Moreover, existing methods failed to disentangle a user's latent preference factors which cause her clicks on different news. In this paper, we model the usernews interactions as a bipartite graph and propose a novel Graph Neural News Recommendation model with Unsupervised Preference Disentanglement, named GNUD. Our model can encode high-order relationships into user and news representations by information propagation along the graph. Furthermore, the learned representations are disentangled with latent preference factors by a neighborhood routing algorithm, which can enhance expressiveness and interpretability. A preference regularizer is also designed to force each disentangled subspace to independently reflect an isolated preference, improving the quality of the disentangled representations. Experimental results on real-world news datasets demonstrate that our proposed model can effectively improve the performance of news recommendation and outperform state-of-the-art news recommendation methods.","graph neural news recommendation unsupervised preference disentanglement explosion news information , personalize news recommendation important user quickly find interested content . exist method usually learn representation user news news content recommendation . , seldom consider highorder connectivity underlie user - news interaction . , exist method fail disentangle user latent preference factor cause click different news . paper , model usernew interaction bipartite graph propose novel graph neural news recommendation model unsupervised preference disentanglement , name gnud . model encode high - order relationship user news representation information propagation graph . furthermore , learn representation disentangle latent preference factor neighborhood routing algorithm , enhance expressiveness interpretability . preference regularizer design force disentangle subspace independently reflect isolate preference , improve quality disentangled representation . experimental result real - world news dataset demonstrate propose model effectively improve performance news recommendation outperform state - - - art news recommendation method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 15, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 30, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,True
NLP Applications,SPECTER: Document-level Representation Learning using Citation-informed Transformers,"Representation learning is a critical ingredient for natural language processing systems. Recent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token-and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on scientific documents, such as classification and recommendation, the embeddings power strong performance on end tasks. We propose SPECTER, a new method to generate document-level embedding of scientific documents based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph. Unlike existing pretrained language models, SPECTER can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce SCIDOCS, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that SPECTER outperforms a variety of competitive baselines on the benchmark. 1 * Equal contribution 1 https://github.com/allenai/specter A simple but tough-to-beat baseline for sentence embeddings. In ICLR.","SPECTER: Document-level Representation Learning using Citation-informed Transformers Representation learning is a critical ingredient for natural language processing systems. Recent Transformer language models like BERT learn powerful textual representations, but these models are targeted towards token-and sentence-level training objectives and do not leverage information on inter-document relatedness, which limits their document-level representation power. For applications on scientific documents, such as classification and recommendation, the embeddings power strong performance on end tasks. We propose SPECTER, a new method to generate document-level embedding of scientific documents based on pretraining a Transformer language model on a powerful signal of document-level relatedness: the citation graph. Unlike existing pretrained language models, SPECTER can be easily applied to downstream applications without task-specific fine-tuning. Additionally, to encourage further research on document-level models, we introduce SCIDOCS, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. We show that SPECTER outperforms a variety of competitive baselines on the benchmark. 1 * Equal contribution 1 https://github.com/allenai/specter A simple but tough-to-beat baseline for sentence embeddings. In ICLR.","specter : document - level representation learn citation - inform transformers representation learning critical ingredient natural language processing system . recent transformer language model like bert learn powerful textual representation , model target token - sentence - level training objective leverage information inter - document relatedness , limit document - level representation power . application scientific document , classification recommendation , embedding power strong performance end task . propose specter , new method generate document - level embedding scientific document base pretraine transformer language model powerful signal document - level relatedness : citation graph . unlike existing pretrained language model , specter easily apply downstream application task - specific fine - tuning . additionally , encourage research document - level model , introduce scidocs , new evaluation benchmark consist seven document - level task range citation prediction , document classification recommendation . specter outperform variety competitive baseline benchmark . 1 * equal contribution 1 https://github.com/allenai/specter simple tough - - beat baseline sentence embedding . iclr .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 12, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 10, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains,"Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB). It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge. The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs. Existing approaches are mostly inappropriate for this, as they depend on training data. However, in the above scenario, there exists hardly annotated data, and it needs to be created from scratch. We therefore present a novel domain-agnostic Human-In-The-Loop annotation approach: we use recommenders that suggest potential concepts and adaptive candidate ranking, thereby speeding up the overall annotation process and making it less tedious for users. We evaluate our ranking approach in a simulation on difficult texts and show that it greatly outperforms a strong baseline in ranking accuracy. In a user study, the annotation speed improves by 35 % compared to annotating without interactive support; users report that they strongly prefer our system. An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .","From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains Entity linking (EL) is concerned with disambiguating entity mentions in a text against knowledge bases (KB). It is crucial in a considerable number of fields like humanities, technical writing and biomedical sciences to enrich texts with semantics and discover more knowledge. The use of EL in such domains requires handling noisy texts, low resource settings and domain-specific KBs. Existing approaches are mostly inappropriate for this, as they depend on training data. However, in the above scenario, there exists hardly annotated data, and it needs to be created from scratch. We therefore present a novel domain-agnostic Human-In-The-Loop annotation approach: we use recommenders that suggest potential concepts and adaptive candidate ranking, thereby speeding up the overall annotation process and making it less tedious for users. We evaluate our ranking approach in a simulation on difficult texts and show that it greatly outperforms a strong baseline in ranking accuracy. In a user study, the annotation speed improves by 35 % compared to annotating without interactive support; users report that they strongly prefer our system. An open-source and ready-to-use implementation based on the text annotation platform INCEpTION 1 is made available 2 .","zero hero : human - - - loop entity linking low resource domain entity linking ( el ) concern disambiguate entity mention text knowledge basis ( kb ) . crucial considerable number field like humanity , technical writing biomedical science enrich text semantic discover knowledge . use el domain require handle noisy text , low resource setting domain - specific kb . exist approach inappropriate , depend training datum . , scenario , exist hardly annotate datum , need create scratch . present novel domain - agnostic human - - - loop annotation approach : use recommender suggest potential concept adaptive candidate ranking , speed overall annotation process make tedious user . evaluate ranking approach simulation difficult text greatly outperform strong baseline ranking accuracy . user study , annotation speed improve 35 % compare annotate interactive support ; user report strongly prefer system . open - source ready - - use implementation base text annotation platform inception 1 available 2 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Neural-DINF: A Neural Network based Framework for Measuring Document Influence,"Measuring the scholarly impact of a document without citations is an important and challenging problem. Existing approaches such as Document Influence Model (DIM) are based on dynamic topic models, which only consider the word frequency change. In this paper, we use both frequency changes and word semantic shifts to measure document influence by developing a neural network based framework. Our model has three steps. Firstly, we train word embeddings for different time periods. Subsequently, we propose an unsupervised method to align vectors for different time periods. Finally, we compute the influence value of documents. Our experimental results show that our model outperforms DIM.","Neural-DINF: A Neural Network based Framework for Measuring Document Influence Measuring the scholarly impact of a document without citations is an important and challenging problem. Existing approaches such as Document Influence Model (DIM) are based on dynamic topic models, which only consider the word frequency change. In this paper, we use both frequency changes and word semantic shifts to measure document influence by developing a neural network based framework. Our model has three steps. Firstly, we train word embeddings for different time periods. Subsequently, we propose an unsupervised method to align vectors for different time periods. Finally, we compute the influence value of documents. Our experimental results show that our model outperforms DIM.","neural - dinf : neural network base framework measure document influence measure scholarly impact document citation important challenging problem . exist approach document influence model ( dim ) base dynamic topic model , consider word frequency change . paper , use frequency change word semantic shift measure document influence develop neural network base framework . model step . firstly , train word embedding different time period . subsequently , propose unsupervised method align vector different time period . finally , compute influence value document . experimental result model outperform dim .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
NLP Applications,Hyperbolic Capsule Networks for Multi-Label Classification,"Although deep neural networks are effective at extracting high-level features, classification methods usually encode an input into a vector representation via simple feature aggregation operations (e.g. pooling). Such operations limit the performance. For instance, a multi-label document may contain several concepts. In this case, one vector can not sufficiently capture its salient and discriminative content. Thus, we propose Hyperbolic Capsule Networks (HYPERCAPS) for Multi-Label Classification (MLC), which have two merits. First, hyperbolic capsules are designed to capture fine-grained document information for each label, which has the ability to characterize complicated structures among labels and documents. Second, Hyperbolic Dynamic Routing (HDR) is introduced to aggregate hyperbolic capsules in a label-aware manner, so that the label-level discriminative information can be preserved along the depth of neural networks. To efficiently handle large-scale MLC datasets, we additionally present a new routing method to adaptively adjust the capsule number during routing. Extensive experiments are conducted on four benchmark datasets. Compared with the state-of-the-art methods, HY-PERCAPS significantly improves the performance of MLC especially on tail labels.","Hyperbolic Capsule Networks for Multi-Label Classification Although deep neural networks are effective at extracting high-level features, classification methods usually encode an input into a vector representation via simple feature aggregation operations (e.g. pooling). Such operations limit the performance. For instance, a multi-label document may contain several concepts. In this case, one vector can not sufficiently capture its salient and discriminative content. Thus, we propose Hyperbolic Capsule Networks (HYPERCAPS) for Multi-Label Classification (MLC), which have two merits. First, hyperbolic capsules are designed to capture fine-grained document information for each label, which has the ability to characterize complicated structures among labels and documents. Second, Hyperbolic Dynamic Routing (HDR) is introduced to aggregate hyperbolic capsules in a label-aware manner, so that the label-level discriminative information can be preserved along the depth of neural networks. To efficiently handle large-scale MLC datasets, we additionally present a new routing method to adaptively adjust the capsule number during routing. Extensive experiments are conducted on four benchmark datasets. Compared with the state-of-the-art methods, HY-PERCAPS significantly improves the performance of MLC especially on tail labels.","hyperbolic capsule networks multi - label classification deep neural network effective extract high - level feature , classification method usually encode input vector representation simple feature aggregation operation ( e.g. pooling ) . operation limit performance . instance , multi - label document contain concept . case , vector sufficiently capture salient discriminative content . , propose hyperbolic capsule networks ( hypercaps ) multi - label classification ( mlc ) , merit . , hyperbolic capsule design capture fine - grained document information label , ability characterize complicated structure label document . second , hyperbolic dynamic routing ( hdr ) introduce aggregate hyperbolic capsule label - aware manner , label - level discriminative information preserve depth neural network . efficiently handle large - scale mlc dataset , additionally present new routing method adaptively adjust capsule number routing . extensive experiment conduct benchmark dataset . compare state - - - art method , hy - percaps significantly improve performance mlc especially tail label .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
NLP Applications,Interpretable Operational Risk Classification with Semi-Supervised Variational Autoencoder,"Operational risk management is one of the biggest challenges nowadays faced by financial institutions. There are several major challenges of building a text classification system for automatic operational risk prediction, including imbalanced labeled/unlabeled data and lacking interpretability. To tackle these challenges, we present a semi-supervised text classification framework that integrates multi-head attention mechanism with Semisupervised variational inference for Operational Risk Classification (SemiORC). We empirically evaluate the framework on a realworld dataset. The results demonstrate that our method can better utilize unlabeled data and learn visually interpretable document representations. SemiORC also outperforms other baseline methods on operational risk classification.","Interpretable Operational Risk Classification with Semi-Supervised Variational Autoencoder Operational risk management is one of the biggest challenges nowadays faced by financial institutions. There are several major challenges of building a text classification system for automatic operational risk prediction, including imbalanced labeled/unlabeled data and lacking interpretability. To tackle these challenges, we present a semi-supervised text classification framework that integrates multi-head attention mechanism with Semisupervised variational inference for Operational Risk Classification (SemiORC). We empirically evaluate the framework on a realworld dataset. The results demonstrate that our method can better utilize unlabeled data and learn visually interpretable document representations. SemiORC also outperforms other baseline methods on operational risk classification.","interpretable operational risk classification semi - supervised variational autoencoder operational risk management big challenge nowadays face financial institution . major challenge build text classification system automatic operational risk prediction , include imbalanced label / unlabeled datum lack interpretability . tackle challenge , present semi - supervised text classification framework integrate multi - head attention mechanism semisupervised variational inference operational risk classification ( semiorc ) . empirically evaluate framework realworld dataset . result demonstrate method well utilize unlabeled datum learn visually interpretable document representation . semiorc outperform baseline method operational risk classification .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,ScriptWriter: Narrative-Guided Script Generation,"It is appealing to have a system that generates a story or scripts automatically from a storyline, even though this is still out of our reach. In dialogue systems, it would also be useful to drive dialogues by a dialogue plan. In this paper, we address a key problem involved in these applications -guiding a dialogue by a narrative. The proposed model ScriptWriter selects the best response among the candidates that fit the context as well as the given narrative. It keeps track of what in the narrative has been said and what is to be said. A narrative plays a different role than the context (i.e., previous utterances), which is generally used in current dialogue systems. Due to the unavailability of data for this new application, we construct a new large-scale data collection GraphMovie from a movie website where endusers can upload their narratives freely when watching a movie. Experimental results on the dataset show that our proposed approach based on narratives significantly outperforms the baselines that simply use the narrative as a kind of context.","ScriptWriter: Narrative-Guided Script Generation It is appealing to have a system that generates a story or scripts automatically from a storyline, even though this is still out of our reach. In dialogue systems, it would also be useful to drive dialogues by a dialogue plan. In this paper, we address a key problem involved in these applications -guiding a dialogue by a narrative. The proposed model ScriptWriter selects the best response among the candidates that fit the context as well as the given narrative. It keeps track of what in the narrative has been said and what is to be said. A narrative plays a different role than the context (i.e., previous utterances), which is generally used in current dialogue systems. Due to the unavailability of data for this new application, we construct a new large-scale data collection GraphMovie from a movie website where endusers can upload their narratives freely when watching a movie. Experimental results on the dataset show that our proposed approach based on narratives significantly outperforms the baselines that simply use the narrative as a kind of context.","scriptwriter : narrative - guide script generation appealing system generate story script automatically storyline , reach . dialogue system , useful drive dialogue dialogue plan . paper , address key problem involve application -guide dialogue narrative . proposed model scriptwriter select good response candidate fit context give narrative . keep track narrative say say . narrative play different role context ( i.e. , previous utterance ) , generally current dialogue system . unavailability datum new application , construct new large - scale datum collection graphmovie movie website enduser upload narrative freely watch movie . experimental result dataset propose approach base narrative significantly outperform baseline simply use narrative kind context .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
NLP Applications,Automated Topical Component Extraction Using Neural Network Attention Scores from Source-based Essay Scoring,"While automated essay scoring (AES) can reliably grade essays at scale, automated writing evaluation (AWE) additionally provides formative feedback to guide essay revision. However, a neural AES typically does not provide useful feature representations for supporting AWE. This paper presents a method for linking AWE and neural AES, by extracting Topical Components (TCs) representing evidence from a source text using the intermediate output of attention layers. We evaluate performance using a feature-based AES requiring TCs. Results show that performance is comparable whether using automatically or manually constructed TCs for 1) representing essays as rubric-based features, 2) grading essays.","Automated Topical Component Extraction Using Neural Network Attention Scores from Source-based Essay Scoring While automated essay scoring (AES) can reliably grade essays at scale, automated writing evaluation (AWE) additionally provides formative feedback to guide essay revision. However, a neural AES typically does not provide useful feature representations for supporting AWE. This paper presents a method for linking AWE and neural AES, by extracting Topical Components (TCs) representing evidence from a source text using the intermediate output of attention layers. We evaluate performance using a feature-based AES requiring TCs. Results show that performance is comparable whether using automatically or manually constructed TCs for 1) representing essays as rubric-based features, 2) grading essays.","automate topical component extraction neural network attention score source - base essay scoring automated essay scoring ( aes ) reliably grade essay scale , automated writing evaluation ( awe ) additionally provide formative feedback guide essay revision . , neural aes typically provide useful feature representation support awe . paper present method link awe neural aes , extract topical components ( tcs ) represent evidence source text intermediate output attention layer . evaluate performance feature - base aes require tc . result performance comparable automatically manually construct tc 1 ) represent essay rubric - base feature , 2 ) grade essay .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,Understanding Advertisements with BERT,"We consider a task based on CVPR 2018 challenge dataset on advertisement (Ad) understanding. The task involves detecting the viewer's interpretation of an Ad image captured as text. Recent results have shown that the embedded scene-text in the image holds a vital cue for this task. Motivated by this, we fine-tune the base BERT model for a sentencepair classification task. Despite utilizing the scene-text as the only source of visual information, we could achieve a hit-or-miss accuracy of 84.95% on the challenge test data. To enable BERT to process other visual information, we append image captions to the scene-text. This achieves an accuracy of 89.69%, which is an improvement of 4.7%. This is the best reported result for this task.","Understanding Advertisements with BERT We consider a task based on CVPR 2018 challenge dataset on advertisement (Ad) understanding. The task involves detecting the viewer's interpretation of an Ad image captured as text. Recent results have shown that the embedded scene-text in the image holds a vital cue for this task. Motivated by this, we fine-tune the base BERT model for a sentencepair classification task. Despite utilizing the scene-text as the only source of visual information, we could achieve a hit-or-miss accuracy of 84.95% on the challenge test data. To enable BERT to process other visual information, we append image captions to the scene-text. This achieves an accuracy of 89.69%, which is an improvement of 4.7%. This is the best reported result for this task.","understand advertisement bert consider task base cvpr 2018 challenge dataset advertisement ( ad ) understanding . task involve detect viewer interpretation ad image capture text . recent result show embed scene - text image hold vital cue task . motivate , fine - tune base bert model sentencepair classification task . despite utilize scene - text source visual information , achieve hit - - miss accuracy 84.95 % challenge test datum . enable bert process visual information , append image caption scene - text . achieve accuracy 89.69 % , improvement 4.7 % . good report result task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
NLP Applications,Let Me Choose: From Verbal Context to Font Selection,"In this paper, we aim to learn associations between visual attributes of fonts and the verbal context of the texts they are typically applied to. Compared to related work leveraging the surrounding visual context, we choose to focus only on the input text as this can enable new applications for which the text is the only visual element in the document. We introduce a new dataset, containing examples of different topics in social media posts and ads, labeled through crowd-sourcing. Due to the subjective nature of the task, multiple fonts might be perceived as acceptable for an input text, which makes this problem challenging. To this end, we investigate different end-to-end models to learn label distributions on crowd-sourced data and capture inter-subjectivity across all annotations.","Let Me Choose: From Verbal Context to Font Selection In this paper, we aim to learn associations between visual attributes of fonts and the verbal context of the texts they are typically applied to. Compared to related work leveraging the surrounding visual context, we choose to focus only on the input text as this can enable new applications for which the text is the only visual element in the document. We introduce a new dataset, containing examples of different topics in social media posts and ads, labeled through crowd-sourcing. Due to the subjective nature of the task, multiple fonts might be perceived as acceptable for an input text, which makes this problem challenging. To this end, we investigate different end-to-end models to learn label distributions on crowd-sourced data and capture inter-subjectivity across all annotations.","let choose : verbal context font selection paper , aim learn association visual attribute font verbal context text typically apply . compare related work leverage surround visual context , choose focus input text enable new application text visual element document . introduce new dataset , contain example different topic social medium post ad , label crowd - sourcing . subjective nature task , multiple font perceive acceptable input text , make problem challenging . end , investigate different end - - end model learn label distribution crowd - source datum capture inter - subjectivity annotation .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Spelling Error Correction with Soft-Masked BERT,"Spelling error correction is an important yet challenging task because a satisfactory solution of it essentially needs human-level language understanding ability. Without loss of generality we consider Chinese spelling error correction (CSC) in this paper. A state-ofthe-art method for the task selects a character from a list of candidates for correction (including non-correction) at each position of the sentence on the basis of BERT, the language representation model. The accuracy of the method can be sub-optimal, however, because BERT does not have sufficient capability to detect whether there is an error at each position, apparently due to the way of pre-training it using mask language modeling. In this work, we propose a novel neural architecture to address the aforementioned issue, which consists of a network for error detection and a network for error correction based on BERT, with the former being connected to the latter with what we call soft-masking technique. Our method of using 'Soft-Masked BERT' is general, and it may be employed in other language detectioncorrection problems. Experimental results on two datasets demonstrate that the performance of our proposed method is significantly better than the baselines including the one solely based on BERT.","Spelling Error Correction with Soft-Masked BERT Spelling error correction is an important yet challenging task because a satisfactory solution of it essentially needs human-level language understanding ability. Without loss of generality we consider Chinese spelling error correction (CSC) in this paper. A state-ofthe-art method for the task selects a character from a list of candidates for correction (including non-correction) at each position of the sentence on the basis of BERT, the language representation model. The accuracy of the method can be sub-optimal, however, because BERT does not have sufficient capability to detect whether there is an error at each position, apparently due to the way of pre-training it using mask language modeling. In this work, we propose a novel neural architecture to address the aforementioned issue, which consists of a network for error detection and a network for error correction based on BERT, with the former being connected to the latter with what we call soft-masking technique. Our method of using 'Soft-Masked BERT' is general, and it may be employed in other language detectioncorrection problems. Experimental results on two datasets demonstrate that the performance of our proposed method is significantly better than the baselines including the one solely based on BERT.","spelling error correction soft - masked bert spelling error correction important challenging task satisfactory solution essentially need human - level language understanding ability . loss generality consider chinese spelling error correction ( csc ) paper . state - ofthe - art method task select character list candidate correction ( include non - correction ) position sentence basis bert , language representation model . accuracy method sub - optimal , , bert sufficient capability detect error position , apparently way pre - train mask language modeling . work , propose novel neural architecture address aforementioned issue , consist network error detection network error correction base bert , connect soft - masking technique . method ' soft - masked bert ' general , employ language detectioncorrection problem . experimental result dataset demonstrate performance propose method significantly well baseline include solely base bert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
NLP Applications,MOOCCube: A Large-scale Data Repository for NLP Applications in MOOCs,"The prosperity of Massive Open Online Courses (MOOCs) provides fodder for many NLP and AI research for education applications, e.g., course concept extraction, prerequisite relation discovery, etc. However, the publicly available datasets of MOOC are limited in size with few types of data, which hinders advanced models and novel attempts in related topics. Therefore, we present MOOCCube, a large-scale data repository of over 700 MOOC courses, 100k concepts, 8 million student behaviors with an external resource. Moreover, we conduct a prerequisite discovery task as an example application to show the potential of MOOCCube in facilitating relevant research. The data repository is now available at http: //moocdata.cn/data/MOOCCube.","MOOCCube: A Large-scale Data Repository for NLP Applications in MOOCs The prosperity of Massive Open Online Courses (MOOCs) provides fodder for many NLP and AI research for education applications, e.g., course concept extraction, prerequisite relation discovery, etc. However, the publicly available datasets of MOOC are limited in size with few types of data, which hinders advanced models and novel attempts in related topics. Therefore, we present MOOCCube, a large-scale data repository of over 700 MOOC courses, 100k concepts, 8 million student behaviors with an external resource. Moreover, we conduct a prerequisite discovery task as an example application to show the potential of MOOCCube in facilitating relevant research. The data repository is now available at http: //moocdata.cn/data/MOOCCube.","mooccube : large - scale datum repository nlp application moocs prosperity massive open online courses ( moocs ) provide fodder nlp ai research education application , e.g. , course concept extraction , prerequisite relation discovery , etc . , publicly available dataset mooc limited size type datum , hinder advanced model novel attempt related topic . , present mooccube , large - scale datum repository 700 mooc course , 100k concept , 8 million student behavior external resource . , conduct prerequisite discovery task example application potential mooccube facilitate relevant research . datum repository available http : //moocdata.cn / data / mooccube .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
NLP Applications,Camouflaged Chinese Spam Content Detection with Semi-supervised Generative Active Learning,"We propose a Semi-supervIsed GeNerative Active Learning (SIGNAL) model to address the imbalance, efficiency, and text camouflage problems of Chinese text spam detection task. A ""self-diversity"" criterion is proposed for measuring the ""worthiness"" of a candidate for annotation. A semi-supervised variational autoencoder with masked attention learning approach and a character variation graph-enhanced augmentation procedure are proposed for data augmentation. The preliminary experiment demonstrates the proposed SIGNAL model is not only sensitive to spam sample selection, but also can improve the performance of a series of conventional active learning models for Chinese spam detection task. To the best of our knowledge, this is the first work to integrate active learning and semisupervised generative learning for text spam detection.","Camouflaged Chinese Spam Content Detection with Semi-supervised Generative Active Learning We propose a Semi-supervIsed GeNerative Active Learning (SIGNAL) model to address the imbalance, efficiency, and text camouflage problems of Chinese text spam detection task. A ""self-diversity"" criterion is proposed for measuring the ""worthiness"" of a candidate for annotation. A semi-supervised variational autoencoder with masked attention learning approach and a character variation graph-enhanced augmentation procedure are proposed for data augmentation. The preliminary experiment demonstrates the proposed SIGNAL model is not only sensitive to spam sample selection, but also can improve the performance of a series of conventional active learning models for Chinese spam detection task. To the best of our knowledge, this is the first work to integrate active learning and semisupervised generative learning for text spam detection.","camouflage chinese spam content detection semi - supervised generative active learning propose semi - supervised generative active learning ( signal ) model address imbalance , efficiency , text camouflage problem chinese text spam detection task . "" self - diversity "" criterion propose measure "" worthiness "" candidate annotation . semi - supervised variational autoencoder mask attention learning approach character variation graph - enhance augmentation procedure propose datum augmentation . preliminary experiment demonstrate propose signal model sensitive spam sample selection , improve performance series conventional active learning model chinese spam detection task . good knowledge , work integrate active learning semisupervised generative learning text spam detection .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,True
NLP Applications,Clinical Concept Linking with Contextualized Neural Representations,"In traditional approaches to entity linking, linking decisions are based on three sources of information -the similarity of the mention string to an entity's name, the similarity of the context of the document to the entity, and broader information about the knowledge base (KB). In some domains, there is little contextual information present in the KB and thus we rely more heavily on mention string similarity. We consider one example of this, concept linking, which seeks to link mentions of medical concepts to a medical concept ontology. We propose an approach to concept linking that leverages recent work in contextualized neural models, such as ELMo (Peters et al., 2018) , which create a token representation that integrates the surrounding context of the mention and concept name. We find a neural ranking approach paired with contextualized embeddings provides gains over a competitive baseline (Leaman et al., 2013) . Additionally, we find that a pre-training step using synonyms from the ontology offers a useful initialization for the ranker.","Clinical Concept Linking with Contextualized Neural Representations In traditional approaches to entity linking, linking decisions are based on three sources of information -the similarity of the mention string to an entity's name, the similarity of the context of the document to the entity, and broader information about the knowledge base (KB). In some domains, there is little contextual information present in the KB and thus we rely more heavily on mention string similarity. We consider one example of this, concept linking, which seeks to link mentions of medical concepts to a medical concept ontology. We propose an approach to concept linking that leverages recent work in contextualized neural models, such as ELMo (Peters et al., 2018) , which create a token representation that integrates the surrounding context of the mention and concept name. We find a neural ranking approach paired with contextualized embeddings provides gains over a competitive baseline (Leaman et al., 2013) . Additionally, we find that a pre-training step using synonyms from the ontology offers a useful initialization for the ranker.","clinical concept linking contextualized neural representation traditional approach entity linking , link decision base source information -the similarity mention string entity , similarity context document entity , broad information knowledge base ( kb ) . domain , little contextual information present kb rely heavily mention string similarity . consider example , concept linking , seek link mention medical concept medical concept ontology . propose approach concept linking leverage recent work contextualize neural model , elmo ( peters et al . , 2018 ) , create token representation integrate surround context mention concept . find neural ranking approach pair contextualize embedding provide gain competitive baseline ( leaman et al . , 2013 ) . additionally , find pre - training step synonym ontology offer useful initialization ranker .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
NLP Applications,Efficient Strategies for Hierarchical Text Classification: External Knowledge and Auxiliary Tasks,"In hierarchical text classification, we perform a sequence of inference steps to predict the category of a document from top to bottom of a given class taxonomy. Most of the studies have focused on developing novels neural network architectures to deal with the hierarchical structure, but we prefer to look for efficient ways to strengthen a baseline model. We first define the task as a sequence-to-sequence problem. Afterwards, we propose an auxiliary synthetic task of bottom-up-classification. Then, from external dictionaries, we retrieve textual definitions for the classes of all the hierarchy's layers, and map them into the word vector space. We use the class-definition embeddings as an additional input to condition the prediction of the next layer and in an adapted beam search. Whereas the modified search did not provide large gains, the combination of the auxiliary task and the additional input of classdefinitions significantly enhance the classification accuracy. With our efficient approaches, we outperform previous studies, using a drastically reduced number of parameters, in two well-known English datasets.","Efficient Strategies for Hierarchical Text Classification: External Knowledge and Auxiliary Tasks In hierarchical text classification, we perform a sequence of inference steps to predict the category of a document from top to bottom of a given class taxonomy. Most of the studies have focused on developing novels neural network architectures to deal with the hierarchical structure, but we prefer to look for efficient ways to strengthen a baseline model. We first define the task as a sequence-to-sequence problem. Afterwards, we propose an auxiliary synthetic task of bottom-up-classification. Then, from external dictionaries, we retrieve textual definitions for the classes of all the hierarchy's layers, and map them into the word vector space. We use the class-definition embeddings as an additional input to condition the prediction of the next layer and in an adapted beam search. Whereas the modified search did not provide large gains, the combination of the auxiliary task and the additional input of classdefinitions significantly enhance the classification accuracy. With our efficient approaches, we outperform previous studies, using a drastically reduced number of parameters, in two well-known English datasets.","efficient strategy hierarchical text classification : external knowledge auxiliary task hierarchical text classification , perform sequence inference step predict category document give class taxonomy . study focus develop novel neural network architecture deal hierarchical structure , prefer look efficient way strengthen baseline model . define task sequence - - sequence problem . , propose auxiliary synthetic task - - classification . , external dictionary , retrieve textual definition class hierarchy layer , map word vector space . use class - definition embedding additional input condition prediction layer adapt beam search . modify search provide large gain , combination auxiliary task additional input classdefinition significantly enhance classification accuracy . efficient approach , outperform previous study , drastically reduce number parameter , - know english dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 11, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Information Retrieval and Text Mining,False
"Phonology, Morphology and Word Segmentation",Joint Chinese Word Segmentation and Part-of-speech Tagging via Two-way Attentions of Auto-analyzed Knowledge,"Chinese word segmentation (CWS) and partof-speech (POS) tagging are important fundamental tasks for Chinese language processing, where joint learning of them is an effective one-step solution for both tasks. Previous studies for joint CWS and POS tagging mainly follow the character-based tagging paradigm with introducing contextual information such as n-gram features or sentential representations from recurrent neural models. However, for many cases, the joint tagging needs not only modeling from context features but also knowledge attached to them (e.g., syntactic relations among words); limited efforts have been made by existing research to meet such needs. In this paper, we propose a neural model named TWASP for joint CWS and POS tagging following the character-based sequence labeling paradigm, where a two-way attention mechanism is used to incorporate both context feature and their corresponding syntactic knowledge for each input character. Particularly, we use existing language processing toolkits to obtain the auto-analyzed syntactic knowledge for the context, and the proposed attention module can learn and benefit from them although their quality may not be perfect. Our experiments illustrate the effectiveness of the two-way attentions for joint CWS and POS tagging, where state-of-the-art performance is achieved on five benchmark datasets. 1 * Partially done as an intern at Sinovation Ventures. â€  Corresponding author. 1 TWASP (code and the best performing models) is released at https://github.com/SVAIGBA/TwASP.","Joint Chinese Word Segmentation and Part-of-speech Tagging via Two-way Attentions of Auto-analyzed Knowledge Chinese word segmentation (CWS) and partof-speech (POS) tagging are important fundamental tasks for Chinese language processing, where joint learning of them is an effective one-step solution for both tasks. Previous studies for joint CWS and POS tagging mainly follow the character-based tagging paradigm with introducing contextual information such as n-gram features or sentential representations from recurrent neural models. However, for many cases, the joint tagging needs not only modeling from context features but also knowledge attached to them (e.g., syntactic relations among words); limited efforts have been made by existing research to meet such needs. In this paper, we propose a neural model named TWASP for joint CWS and POS tagging following the character-based sequence labeling paradigm, where a two-way attention mechanism is used to incorporate both context feature and their corresponding syntactic knowledge for each input character. Particularly, we use existing language processing toolkits to obtain the auto-analyzed syntactic knowledge for the context, and the proposed attention module can learn and benefit from them although their quality may not be perfect. Our experiments illustrate the effectiveness of the two-way attentions for joint CWS and POS tagging, where state-of-the-art performance is achieved on five benchmark datasets. 1 * Partially done as an intern at Sinovation Ventures. â€  Corresponding author. 1 TWASP (code and the best performing models) is released at https://github.com/SVAIGBA/TwASP.","joint chinese word segmentation - - speech tagging - way attention auto - analyze knowledge chinese word segmentation ( cws ) partof - speech ( pos ) tagging important fundamental task chinese language processing , joint learning effective - step solution task . previous study joint cws pos tagging mainly follow character - base tagging paradigm introduce contextual information n - gram feature sentential representation recurrent neural model . , case , joint tagging need model context feature knowledge attach ( e.g. , syntactic relation word ) ; limited effort exist research meet need . paper , propose neural model name twasp joint cws pos tag follow character - base sequence labeling paradigm , - way attention mechanism incorporate context feature corresponding syntactic knowledge input character . particularly , use exist language processing toolkit obtain auto - analyze syntactic knowledge context , propose attention module learn benefit quality perfect . experiment illustrate effectiveness - way attention joint cws pos tagging , state - - - art performance achieve benchmark dataset . 1 * partially intern sinovation ventures . â€  correspond author . 1 twasp ( code well perform model ) release https://github.com/svaigba/twasp .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 17, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",The Paradigm Discovery Problem,"This work treats the paradigm discovery problem (PDP)-the task of learning an inflectional morphological system from unannotated sentences. We formalize the PDP and develop evaluation metrics for judging systems. Using currently available resources, we construct datasets for the task. We also devise a heuristic benchmark for the PDP and report empirical results on five diverse languages. Our benchmark system first makes use of word embeddings and string similarity to cluster forms by cell and by paradigm. Then, we bootstrap a neural transducer on top of the clustered data to predict words to realize the empty paradigm slots. An error analysis of our system suggests clustering by cell across different inflection classes is the most pressing challenge for future work. Our code and data are available at https://github.com/ alexerdmann/ParadigmDiscovery.","The Paradigm Discovery Problem This work treats the paradigm discovery problem (PDP)-the task of learning an inflectional morphological system from unannotated sentences. We formalize the PDP and develop evaluation metrics for judging systems. Using currently available resources, we construct datasets for the task. We also devise a heuristic benchmark for the PDP and report empirical results on five diverse languages. Our benchmark system first makes use of word embeddings and string similarity to cluster forms by cell and by paradigm. Then, we bootstrap a neural transducer on top of the clustered data to predict words to realize the empty paradigm slots. An error analysis of our system suggests clustering by cell across different inflection classes is the most pressing challenge for future work. Our code and data are available at https://github.com/ alexerdmann/ParadigmDiscovery.","paradigm discovery problem work treat paradigm discovery problem ( pdp)-the task learn inflectional morphological system unannotated sentence . formalize pdp develop evaluation metric judge system . currently available resource , construct dataset task . devise heuristic benchmark pdp report empirical result diverse language . benchmark system make use word embedding string similarity cluster form cell paradigm . , bootstrap neural transducer cluster datum predict word realize paradigm slot . error analysis system suggest cluster cell different inflection class pressing challenge future work . code datum available https://github.com/ alexerdmann / paradigmdiscovery .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Phonotactic Complexity and Its Trade-offs,"We present methods for calculating a measure of phonotactic complexity-bits per phonemethat permits a straightforward cross-linguistic comparison. When given a word, represented as a sequence of phonemic segments such as symbols in the international phonetic alphabet, and a statistical model trained on a sample of word types from the language, we can approximately measure bits per phoneme using the negative log-probability of that word under the model. This simple measure allows us to compare the entropy across languages, giving insight into how complex a language's phonotactics is. Using a collection of 1016 basic concept words across 106 languages, we demonstrate a very strong negative correlation of âˆ’0.74 between bits per phoneme and the average length of words.","Phonotactic Complexity and Its Trade-offs We present methods for calculating a measure of phonotactic complexity-bits per phonemethat permits a straightforward cross-linguistic comparison. When given a word, represented as a sequence of phonemic segments such as symbols in the international phonetic alphabet, and a statistical model trained on a sample of word types from the language, we can approximately measure bits per phoneme using the negative log-probability of that word under the model. This simple measure allows us to compare the entropy across languages, giving insight into how complex a language's phonotactics is. Using a collection of 1016 basic concept words across 106 languages, we demonstrate a very strong negative correlation of âˆ’0.74 between bits per phoneme and the average length of words.","phonotactic complexity trade - off present method calculate measure phonotactic complexity - bit phonemethat permit straightforward cross - linguistic comparison . give word , represent sequence phonemic segment symbol international phonetic alphabet , statistical model train sample word type language , approximately measure bit phoneme negative log - probability word model . simple measure allow compare entropy language , give insight complex language phonotactics . collection 1016 basic concept word 106 language , demonstrate strong negative correlation âˆ’0.74 bit phoneme average length word .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
"Phonology, Morphology and Word Segmentation",A Multitask Learning Approach for Diacritic Restoration,"In many languages like Arabic, diacritics are used to specify pronunciations as well as meanings. Such diacritics are often omitted in written text, increasing the number of possible pronunciations and meanings for a word. This results in a more ambiguous text making computational processing on such text more difficult. Diacritic restoration is the task of restoring missing diacritics in the written text. Most state-of-the-art diacritic restoration models are built on character level information which helps generalize the model to unseen data, but presumably lose useful information at the word level. Thus, to compensate for this loss, we investigate the use of multi-task learning to jointly optimize diacritic restoration with related NLP problems namely word segmentation, part-of-speech tagging, and syntactic diacritization. We use Arabic as a case study since it has sufficient data resources for tasks that we consider in our joint modeling. Our joint models significantly outperform the baselines and are comparable to the state-ofthe-art models that are more complex relying on morphological analyzers and/or a lot more data (e.g. dialectal data). * * The work was conducted while the author was with AWS, Amazon AI. 1 Diacritics are marks that are added above, below, or inbetween the letters to compose a new letter or characterize the letter with a different sound (Wells, 2000) .","A Multitask Learning Approach for Diacritic Restoration In many languages like Arabic, diacritics are used to specify pronunciations as well as meanings. Such diacritics are often omitted in written text, increasing the number of possible pronunciations and meanings for a word. This results in a more ambiguous text making computational processing on such text more difficult. Diacritic restoration is the task of restoring missing diacritics in the written text. Most state-of-the-art diacritic restoration models are built on character level information which helps generalize the model to unseen data, but presumably lose useful information at the word level. Thus, to compensate for this loss, we investigate the use of multi-task learning to jointly optimize diacritic restoration with related NLP problems namely word segmentation, part-of-speech tagging, and syntactic diacritization. We use Arabic as a case study since it has sufficient data resources for tasks that we consider in our joint modeling. Our joint models significantly outperform the baselines and are comparable to the state-ofthe-art models that are more complex relying on morphological analyzers and/or a lot more data (e.g. dialectal data). * * The work was conducted while the author was with AWS, Amazon AI. 1 Diacritics are marks that are added above, below, or inbetween the letters to compose a new letter or characterize the letter with a different sound (Wells, 2000) .","multitask learning approach diacritic restoration language like arabic , diacritic specify pronunciation meaning . diacritic omit write text , increase number possible pronunciation meaning word . result ambiguous text make computational processing text difficult . diacritic restoration task restore miss diacritic write text . state - - - art diacritic restoration model build character level information help generalize model unseen datum , presumably lose useful information word level . , compensate loss , investigate use multi - task learning jointly optimize diacritic restoration related nlp problem word segmentation , - - speech tagging , syntactic diacritization . use arabic case study sufficient data resource task consider joint modeling . joint model significantly outperform baseline comparable state - ofthe - art model complex rely morphological analyzer and/or lot datum ( e.g. dialectal datum ) . * * work conduct author aws , amazon ai . 1 diacritic mark add , , inbetween letter compose new letter characterize letter different sound ( wells , 2000 ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 14, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation","Joint Diacritization, Lemmatization, Normalization, and Fine-Grained Morphological Tagging","The written forms of Semitic languages are both highly ambiguous and morphologically rich: a word can have multiple interpretations and is one of many inflected forms of the same concept or lemma. This is further exacerbated for dialectal content, which is more prone to noise and lacks a standard orthography. The morphological features can be lexicalized, like lemmas and diacritized forms, or non-lexicalized, like gender, number, and partof-speech tags, among others. Joint modeling of the lexicalized and non-lexicalized features can identify more intricate morphological patterns, which provide better context modeling, and further disambiguate ambiguous lexical choices. However, the different modeling granularity can make joint modeling more difficult. Our approach models the different features jointly, whether lexicalized (on the characterlevel), or non-lexicalized (on the word-level). We use Arabic as a test case, and achieve stateof-the-art results for Modern Standard Arabic with 20% relative error reduction, and Egyptian Arabic with 11% relative error reduction.","Joint Diacritization, Lemmatization, Normalization, and Fine-Grained Morphological Tagging The written forms of Semitic languages are both highly ambiguous and morphologically rich: a word can have multiple interpretations and is one of many inflected forms of the same concept or lemma. This is further exacerbated for dialectal content, which is more prone to noise and lacks a standard orthography. The morphological features can be lexicalized, like lemmas and diacritized forms, or non-lexicalized, like gender, number, and partof-speech tags, among others. Joint modeling of the lexicalized and non-lexicalized features can identify more intricate morphological patterns, which provide better context modeling, and further disambiguate ambiguous lexical choices. However, the different modeling granularity can make joint modeling more difficult. Our approach models the different features jointly, whether lexicalized (on the characterlevel), or non-lexicalized (on the word-level). We use Arabic as a test case, and achieve stateof-the-art results for Modern Standard Arabic with 20% relative error reduction, and Egyptian Arabic with 11% relative error reduction.","joint diacritization , lemmatization , normalization , fine - grained morphological tagging write form semitic language highly ambiguous morphologically rich : word multiple interpretation inflect form concept lemma . exacerbate dialectal content , prone noise lack standard orthography . morphological feature lexicalize , like lemma diacritized form , non - lexicalized , like gender , number , partof - speech tag , . joint modeling lexicalize non - lexicalized feature identify intricate morphological pattern , provide well context modeling , disambiguate ambiguous lexical choice . , different modeling granularity joint modeling difficult . approach model different feature jointly , lexicalize ( characterlevel ) , non - lexicalized ( word - level ) . use arabic test case , achieve stateof - - art result modern standard arabic 20 % relative error reduction , egyptian arabic 11 % relative error reduction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Predicting the Growth of Morphological Families from Social and Linguistic Factors,"We present the first study that examines the evolution of morphological families, i.e., sets of morphologically related words such as ""trump"", ""antitrumpism"", and ""detrumpify"", in social media. We introduce the novel task of Morphological Family Expansion Prediction (MFEP) as predicting the increase in the size of a morphological family. We create a ten-year Reddit corpus as a benchmark for MFEP and evaluate a number of baselines on this benchmark. Our experiments demonstrate very good performance on MFEP.","Predicting the Growth of Morphological Families from Social and Linguistic Factors We present the first study that examines the evolution of morphological families, i.e., sets of morphologically related words such as ""trump"", ""antitrumpism"", and ""detrumpify"", in social media. We introduce the novel task of Morphological Family Expansion Prediction (MFEP) as predicting the increase in the size of a morphological family. We create a ten-year Reddit corpus as a benchmark for MFEP and evaluate a number of baselines on this benchmark. Our experiments demonstrate very good performance on MFEP.","predict growth morphological family social linguistic factor present study examine evolution morphological family , i.e. , set morphologically related word "" trump "" , "" antitrumpism "" , "" detrumpify "" , social medium . introduce novel task morphological family expansion prediction ( mfep ) predict increase size morphological family . create - year reddit corpus benchmark mfep evaluate number baseline benchmark . experiment demonstrate good performance mfep .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Modeling Morphological Typology for Unsupervised Learning of Language Morphology,"This paper describes a language-independent model for fully unsupervised morphological analysis that exploits a universal framework leveraging morphological typology. By modeling morphological processes including suffixation, prefixation, infixation, and full and partial reduplication with constrained stem change rules, our system effectively constrains the search space and offers a wide coverage in terms of morphological typology. The system is tested on nine typologically and genetically diverse languages, and shows superior performance over leading systems. We also investigate the effect of an oracle that provides only a handful of bits per language to signal morphological type.","Modeling Morphological Typology for Unsupervised Learning of Language Morphology This paper describes a language-independent model for fully unsupervised morphological analysis that exploits a universal framework leveraging morphological typology. By modeling morphological processes including suffixation, prefixation, infixation, and full and partial reduplication with constrained stem change rules, our system effectively constrains the search space and offers a wide coverage in terms of morphological typology. The system is tested on nine typologically and genetically diverse languages, and shows superior performance over leading systems. We also investigate the effect of an oracle that provides only a handful of bits per language to signal morphological type.","model morphological typology unsupervised learning language morphology paper describe language - independent model fully unsupervised morphological analysis exploit universal framework leverage morphological typology . model morphological process include suffixation , prefixation , infixation , partial reduplication constrain stem change rule , system effectively constrain search space offer wide coverage term morphological typology . system test typologically genetically diverse language , show superior performance lead system . investigate effect oracle provide handful bit language signal morphological type .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Predicting Declension Class from Form and Meaning,"The noun lexica of many natural languages are divided into several declension classes with characteristic morphological properties. Class membership is far from deterministic, but the phonological form of a noun and its meaning can often provide imperfect clues. Here, we investigate the strength of those clues. More specifically, we operationalize ""strength"" as measuring how much information, in bits, we can glean about declension class from knowing the form and meaning of nouns. We know that form and meaning are often also indicative of grammatical gender-which, as we quantitatively verify, can itself share information with declension class-so we also control for gender. We find for two Indo-European languages (Czech and German) that form and meaning share a significant amount of information with class (and contribute additional information beyond gender). The three-way interaction between class, form, and meaning (given gender) is also significant. Our study is important for two reasons: First, we introduce a new method that provides additional quantitative support for a classic linguistic finding that form and meaning are relevant for the classification of nouns into declensions. Second, we show not only that individual declension classes vary in the strength of their clues within a language, but also that the variations between classes vary across languages. The code is publicly available at https://github.com/ rycolab/declension-mi.","Predicting Declension Class from Form and Meaning The noun lexica of many natural languages are divided into several declension classes with characteristic morphological properties. Class membership is far from deterministic, but the phonological form of a noun and its meaning can often provide imperfect clues. Here, we investigate the strength of those clues. More specifically, we operationalize ""strength"" as measuring how much information, in bits, we can glean about declension class from knowing the form and meaning of nouns. We know that form and meaning are often also indicative of grammatical gender-which, as we quantitatively verify, can itself share information with declension class-so we also control for gender. We find for two Indo-European languages (Czech and German) that form and meaning share a significant amount of information with class (and contribute additional information beyond gender). The three-way interaction between class, form, and meaning (given gender) is also significant. Our study is important for two reasons: First, we introduce a new method that provides additional quantitative support for a classic linguistic finding that form and meaning are relevant for the classification of nouns into declensions. Second, we show not only that individual declension classes vary in the strength of their clues within a language, but also that the variations between classes vary across languages. The code is publicly available at https://github.com/ rycolab/declension-mi.","predict declension class form meaning noun lexica natural language divide declension class characteristic morphological property . class membership far deterministic , phonological form noun meaning provide imperfect clue . , investigate strength clue . specifically , operationalize "" strength "" measure information , bit , glean declension class know form meaning noun . know form meaning indicative grammatical gender - , quantitatively verify , share information declension class - control gender . find indo - european language ( czech german ) form meaning share significant information class ( contribute additional information gender ) . - way interaction class , form , meaning ( give gender ) significant . study important reason : , introduce new method provide additional quantitative support classic linguistic finding form meaning relevant classification noun declension . second , individual declension class vary strength clue language , variation class vary language . code publicly available https://github.com/ rycolab / declension - mi .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 4, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 20, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Bootstrapping Techniques for Polysynthetic Morphological Analysis,"Polysynthetic languages have exceptionally large and sparse vocabularies, thanks to the number of morpheme slots and combinations in a word. This complexity, together with a general scarcity of written data, poses a challenge to the development of natural language technologies. To address this challenge, we offer linguistically-informed approaches for bootstrapping a neural morphological analyzer, and demonstrate its application to Kunwinjku, a polysynthetic Australian language. We generate data from a finite state transducer to train an encoderdecoder model. We improve the model by ""hallucinating"" missing linguistic structure into the training data, and by resampling from a Zipf distribution to simulate a more natural distribution of morphemes. The best model accounts for all instances of reduplication in the test set and achieves an accuracy of 94.7% overall, a 10 percentage point improvement over the FST baseline. This process demonstrates the feasibility of bootstrapping a neural morph analyzer from minimal resources.","Bootstrapping Techniques for Polysynthetic Morphological Analysis Polysynthetic languages have exceptionally large and sparse vocabularies, thanks to the number of morpheme slots and combinations in a word. This complexity, together with a general scarcity of written data, poses a challenge to the development of natural language technologies. To address this challenge, we offer linguistically-informed approaches for bootstrapping a neural morphological analyzer, and demonstrate its application to Kunwinjku, a polysynthetic Australian language. We generate data from a finite state transducer to train an encoderdecoder model. We improve the model by ""hallucinating"" missing linguistic structure into the training data, and by resampling from a Zipf distribution to simulate a more natural distribution of morphemes. The best model accounts for all instances of reduplication in the test set and achieves an accuracy of 94.7% overall, a 10 percentage point improvement over the FST baseline. This process demonstrates the feasibility of bootstrapping a neural morph analyzer from minimal resources.","bootstrapping technique polysynthetic morphological analysis polysynthetic language exceptionally large sparse vocabulary , thank number morpheme slot combination word . complexity , general scarcity write datum , pose challenge development natural language technology . address challenge , offer linguistically - inform approach bootstrappe neural morphological analyzer , demonstrate application kunwinjku , polysynthetic australian language . generate datum finite state transducer train encoderdecoder model . improve model "" hallucinate "" miss linguistic structure training datum , resample zipf distribution simulate natural distribution morpheme . good model account instance reduplication test set achieve accuracy 94.7 % overall , 10 percentage point improvement fst baseline . process demonstrate feasibility bootstrappe neural morph analyzer minimal resource .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
"Phonology, Morphology and Word Segmentation",2kenize: Tying Subword Sequences for Chinese Script Conversion,"Simplified Chinese to Traditional Chinese character conversion is a common preprocessing step in Chinese NLP. Despite this, current approaches have insufficient performance because they do not take into account that a simplified Chinese character can correspond to multiple traditional characters. Here, we propose a model that can disambiguate between mappings and convert between the two scripts. The model is based on subword segmentation, two language models, as well as a method for mapping between subword sequences. We further construct benchmark datasets for topic classification and script conversion. Our proposed method outperforms previous Chinese Character conversion approaches by 6 points in accuracy. These results are further confirmed in a downstream application, where 2kenize is used to convert pretraining dataset for topic classification. An error analysis reveals that our method's particular strengths are in dealing with code mixing and named entities. The code and dataset is available at https: //github.com/pranav-ust/2kenize","2kenize: Tying Subword Sequences for Chinese Script Conversion Simplified Chinese to Traditional Chinese character conversion is a common preprocessing step in Chinese NLP. Despite this, current approaches have insufficient performance because they do not take into account that a simplified Chinese character can correspond to multiple traditional characters. Here, we propose a model that can disambiguate between mappings and convert between the two scripts. The model is based on subword segmentation, two language models, as well as a method for mapping between subword sequences. We further construct benchmark datasets for topic classification and script conversion. Our proposed method outperforms previous Chinese Character conversion approaches by 6 points in accuracy. These results are further confirmed in a downstream application, where 2kenize is used to convert pretraining dataset for topic classification. An error analysis reveals that our method's particular strengths are in dealing with code mixing and named entities. The code and dataset is available at https: //github.com/pranav-ust/2kenize","2kenize : tie subword sequence chinese script conversion simplified chinese traditional chinese character conversion common preprocessing step chinese nlp . despite , current approach insufficient performance account simplified chinese character correspond multiple traditional character . , propose model disambiguate mapping convert script . model base subword segmentation , language model , method map subword sequence . construct benchmark dataset topic classification script conversion . propose method outperform previous chinese character conversion approach 6 point accuracy . result confirm downstream application , 2kenize convert pretraine dataset topic classification . error analysis reveal method particular strength deal code mixing name entity . code dataset available https : //github.com / pranav - ust/2ken","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 12, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Semi-supervised Contextual Historical Text Normalization,"Historical text normalization, the task of mapping historical word forms to their modern counterparts, has recently attracted a lot of interest (","Semi-supervised Contextual Historical Text Normalization Historical text normalization, the task of mapping historical word forms to their modern counterparts, has recently attracted a lot of interest (","semi - supervised contextual historical text normalization historical text normalization , task map historical word form modern counterpart , recently attract lot interest (","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Phonology, Morphology and Word Segmentation",Coupling Distant Annotation and Adversarial Training for Cross-Domain Chinese Word Segmentation,"Fully supervised neural approaches have achieved significant progress in the task of Chinese word segmentation (CWS). Nevertheless, the performance of supervised models tends to drop dramatically when they are applied to outof-domain data. Performance degradation is caused by the distribution gap across domains and the out of vocabulary (OOV) problem. In order to simultaneously alleviate these two issues, this paper proposes to couple distant annotation and adversarial training for crossdomain CWS. For distant annotation, we rethink the essence of ""Chinese words"" and design an automatic distant annotation mechanism that does not need any supervision or pre-defined dictionaries from the target domain. The approach could effectively explore domain-specific words and distantly annotate the raw texts for the target domain. For adversarial training, we develop a sentence-level training procedure to perform noise reduction and maximum utilization of the source domain information. Experiments on multiple realworld datasets across various domains show the superiority and robustness of our model, significantly outperforming previous state-ofthe-art cross-domain CWS methods.","Coupling Distant Annotation and Adversarial Training for Cross-Domain Chinese Word Segmentation Fully supervised neural approaches have achieved significant progress in the task of Chinese word segmentation (CWS). Nevertheless, the performance of supervised models tends to drop dramatically when they are applied to outof-domain data. Performance degradation is caused by the distribution gap across domains and the out of vocabulary (OOV) problem. In order to simultaneously alleviate these two issues, this paper proposes to couple distant annotation and adversarial training for crossdomain CWS. For distant annotation, we rethink the essence of ""Chinese words"" and design an automatic distant annotation mechanism that does not need any supervision or pre-defined dictionaries from the target domain. The approach could effectively explore domain-specific words and distantly annotate the raw texts for the target domain. For adversarial training, we develop a sentence-level training procedure to perform noise reduction and maximum utilization of the source domain information. Experiments on multiple realworld datasets across various domains show the superiority and robustness of our model, significantly outperforming previous state-ofthe-art cross-domain CWS methods.","couple distant annotation adversarial training cross - domain chinese word segmentation fully supervise neural approach achieve significant progress task chinese word segmentation ( cws ) . , performance supervise model tend drop dramatically apply outof - domain datum . performance degradation cause distribution gap domain vocabulary ( oov ) problem . order simultaneously alleviate issue , paper propose couple distant annotation adversarial training crossdomain cws . distant annotation , rethink essence "" chinese word "" design automatic distant annotation mechanism need supervision pre - defined dictionary target domain . approach effectively explore domain - specific word distantly annotate raw text target domain . adversarial training , develop sentence - level training procedure perform noise reduction maximum utilization source domain information . experiment multiple realworld dataset domain superiority robustness model , significantly outperform previous state - ofthe - art cross - domain cws method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 14, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Frugal Paradigm Completion,"Lexica distinguishing all morphologically related forms of each lexeme are crucial to many language technologies, yet building them is expensive. We propose Frugal Paradigm Completion, an approach that predicts all related forms in a morphological paradigm from as few manually provided forms as possible. It induces typological information during training which it uses to determine the best sources at test time. We evaluate our language-agnostic approach on 7 diverse languages. Compared to popular alternative approaches, our Frugal Paradigm Completion approach reduces manual labor by 16-63% and is the most robust to typological variation.","Frugal Paradigm Completion Lexica distinguishing all morphologically related forms of each lexeme are crucial to many language technologies, yet building them is expensive. We propose Frugal Paradigm Completion, an approach that predicts all related forms in a morphological paradigm from as few manually provided forms as possible. It induces typological information during training which it uses to determine the best sources at test time. We evaluate our language-agnostic approach on 7 diverse languages. Compared to popular alternative approaches, our Frugal Paradigm Completion approach reduces manual labor by 16-63% and is the most robust to typological variation.","frugal paradigm completion lexica distinguish morphologically relate form lexeme crucial language technology , build expensive . propose frugal paradigm completion , approach predict relate form morphological paradigm manually provide form possible . induce typological information training use determine good source test time . evaluate language - agnostic approach 7 diverse language . compare popular alternative approach , frugal paradigm completion approach reduce manual labor 16 - 63 % robust typological variation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 10, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Unsupervised Morphological Paradigm Completion,"We propose the task of unsupervised morphological paradigm completion. Given only raw text and a lemma list, the task consists of generating the morphological paradigms, i.e., all inflected forms, of the lemmas. From a natural language processing (NLP) perspective, this is a challenging unsupervised task, and high-performing systems have the potential to improve tools for low-resource languages or to assist linguistic annotators. From a cognitive science perspective, this can shed light on how children acquire morphological knowledge. We further introduce a system for the task, which generates morphological paradigms via the following steps: (i) EDIT TREE retrieval, (ii) additional lemma retrieval, (iii) paradigm size discovery, and (iv) inflection generation. We perform an evaluation on 14 typologically diverse languages. Our system outperforms trivial baselines with ease and, for some languages, even obtains a higher accuracy than minimally supervised systems. 1","Unsupervised Morphological Paradigm Completion We propose the task of unsupervised morphological paradigm completion. Given only raw text and a lemma list, the task consists of generating the morphological paradigms, i.e., all inflected forms, of the lemmas. From a natural language processing (NLP) perspective, this is a challenging unsupervised task, and high-performing systems have the potential to improve tools for low-resource languages or to assist linguistic annotators. From a cognitive science perspective, this can shed light on how children acquire morphological knowledge. We further introduce a system for the task, which generates morphological paradigms via the following steps: (i) EDIT TREE retrieval, (ii) additional lemma retrieval, (iii) paradigm size discovery, and (iv) inflection generation. We perform an evaluation on 14 typologically diverse languages. Our system outperforms trivial baselines with ease and, for some languages, even obtains a higher accuracy than minimally supervised systems. 1","unsupervised morphological paradigm completion propose task unsupervised morphological paradigm completion . give raw text lemma list , task consist generate morphological paradigm , i.e. , inflect form , lemma . natural language processing ( nlp ) perspective , challenging unsupervised task , high - perform system potential improve tool low - resource language assist linguistic annotator . cognitive science perspective , shed light child acquire morphological knowledge . introduce system task , generate morphological paradigm following step : ( ) edit tree retrieval , ( ii ) additional lemma retrieval , ( iii ) paradigm size discovery , ( iv ) inflection generation . perform evaluation 14 typologically diverse language . system outperform trivial baseline ease , language , obtain high accuracy minimally supervise system . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 14, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Improving Chinese Word Segmentation with Wordhood Memory Networks,"Contextual features always play an important role in Chinese word segmentation (CWS). Wordhood information, being one of the contextual features, is proved to be useful in many conventional character-based segmenters. However, this feature receives less attention in recent neural models and it is also challenging to design a framework that can properly integrate wordhood information from different wordhood measures to existing neural frameworks. In this paper, we therefore propose a neural framework, WMSEG, which uses memory networks to incorporate wordhood information with several popular encoder-decoder combinations for CWS. Experimental results on five benchmark datasets indicate the memory mechanism successfully models wordhood information for neural segmenters and helps WMSEG achieve state-ofthe-art performance on all those datasets. Further experiments and analyses also demonstrate the robustness of our proposed framework with respect to different wordhood measures and the efficiency of wordhood information in cross-domain experiments. 1 * Partially done as an intern at Sinovation Ventures. â€  Corresponding author. 1 WMSEG (code and the best performing models) is released at https://github.com/SVAIGBA/WMSeg.","Improving Chinese Word Segmentation with Wordhood Memory Networks Contextual features always play an important role in Chinese word segmentation (CWS). Wordhood information, being one of the contextual features, is proved to be useful in many conventional character-based segmenters. However, this feature receives less attention in recent neural models and it is also challenging to design a framework that can properly integrate wordhood information from different wordhood measures to existing neural frameworks. In this paper, we therefore propose a neural framework, WMSEG, which uses memory networks to incorporate wordhood information with several popular encoder-decoder combinations for CWS. Experimental results on five benchmark datasets indicate the memory mechanism successfully models wordhood information for neural segmenters and helps WMSEG achieve state-ofthe-art performance on all those datasets. Further experiments and analyses also demonstrate the robustness of our proposed framework with respect to different wordhood measures and the efficiency of wordhood information in cross-domain experiments. 1 * Partially done as an intern at Sinovation Ventures. â€  Corresponding author. 1 WMSEG (code and the best performing models) is released at https://github.com/SVAIGBA/WMSeg.","improve chinese word segmentation wordhood memory networks contextual feature play important role chinese word segmentation ( cws ) . wordhood information , contextual feature , prove useful conventional character - base segmenter . , feature receive attention recent neural model challenging design framework properly integrate wordhood information different wordhood measure exist neural framework . paper , propose neural framework , wmseg , use memory network incorporate wordhood information popular encoder - decoder combination cws . experimental result benchmark dataset indicate memory mechanism successfully model wordhood information neural segmenter help wmseg achieve state - ofthe - art performance dataset . experiment analysis demonstrate robustness propose framework respect different wordhood measure efficiency wordhood information cross - domain experiment . 1 * partially intern sinovation ventures . â€  correspond author . 1 wmseg ( code well perform model ) release https://github.com/svaigba/wmseg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 22, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 10, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",Supervised Grapheme-to-Phoneme Conversion of Orthographic Schwas in Hindi and Punjabi,"Hindi grapheme-to-phoneme (G2P) conversion is mostly trivial, with one exception: whether a schwa represented in the orthography is pronounced or unpronounced (deleted). Previous work has attempted to predict schwa deletion in a rule-based fashion using prosodic or phonetic analysis. We present the first statistical schwa deletion classifier for Hindi, which relies solely on the orthography as the input and outperforms previous approaches. We trained our model on a newly-compiled pronunciation lexicon extracted from various online dictionaries. Our best Hindi model achieves state of the art performance, and also achieves good performance on a closely related language, Punjabi, without modification.","Supervised Grapheme-to-Phoneme Conversion of Orthographic Schwas in Hindi and Punjabi Hindi grapheme-to-phoneme (G2P) conversion is mostly trivial, with one exception: whether a schwa represented in the orthography is pronounced or unpronounced (deleted). Previous work has attempted to predict schwa deletion in a rule-based fashion using prosodic or phonetic analysis. We present the first statistical schwa deletion classifier for Hindi, which relies solely on the orthography as the input and outperforms previous approaches. We trained our model on a newly-compiled pronunciation lexicon extracted from various online dictionaries. Our best Hindi model achieves state of the art performance, and also achieves good performance on a closely related language, Punjabi, without modification.","supervise grapheme - - phoneme conversion orthographic schwas hindi punjabi hindi grapheme - - phoneme ( g2p ) conversion trivial , exception : schwa represent orthography pronounced unpronounced ( delete ) . previous work attempt predict schwa deletion rule - base fashion prosodic phonetic analysis . present statistical schwa deletion classifier hindi , rely solely orthography input outperform previous approach . train model newly - compile pronunciation lexicon extract online dictionary . good hindi model achieve state art performance , achieve good performance closely relate language , punjabi , modification .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
"Phonology, Morphology and Word Segmentation",Phonetic and Visual Priors for Decipherment of Informal Romanization,"Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into Latin character sets found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languagesnamely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our model directly on romanized data from two languages: Egyptian Arabic and Russian. We demonstrate that adding inductive bias through phonetic and visual priors on character mappings substantially improves the model's performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new dataset of romanized Russian, collected from a Russian social network website and partially annotated for our experiments. 1","Phonetic and Visual Priors for Decipherment of Informal Romanization Informal romanization is an idiosyncratic process used by humans in informal digital communication to encode non-Latin script languages into Latin character sets found on common keyboards. Character substitution choices differ between users but have been shown to be governed by the same main principles observed across a variety of languagesnamely, character pairs are often associated through phonetic or visual similarity. We propose a noisy-channel WFST cascade model for deciphering the original non-Latin script from observed romanized text in an unsupervised fashion. We train our model directly on romanized data from two languages: Egyptian Arabic and Russian. We demonstrate that adding inductive bias through phonetic and visual priors on character mappings substantially improves the model's performance on both languages, yielding results much closer to the supervised skyline. Finally, we introduce a new dataset of romanized Russian, collected from a Russian social network website and partially annotated for our experiments. 1","phonetic visual prior decipherment informal romanization informal romanization idiosyncratic process human informal digital communication encode non - latin script language latin character set find common keyboard . character substitution choice differ user show govern main principle observe variety languagesnamely , character pair associate phonetic visual similarity . propose noisy - channel wfst cascade model decipher original non - latin script observed romanized text unsupervised fashion . train model directly romanized datum language : egyptian arabic russian . demonstrate add inductive bias phonetic visual prior character mapping substantially improve model performance language , yield result close supervise skyline . finally , introduce new dataset romanized russian , collect russian social network website partially annotate experiment . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}","Phonology, Morphology and Word Segmentation",True
"Phonology, Morphology and Word Segmentation",A Graph Auto-encoder Model of Derivational Morphology,"There has been little work on modeling the morphological well-formedness (MWF) of derivatives, a problem judged to be complex and difficult in linguistics (Bauer, 2019) . We present a graph auto-encoder that learns embeddings capturing information about the compatibility of affixes and stems in derivation. The auto-encoder models MWF in English surprisingly well by combining syntactic and semantic information with associative information from the mental lexicon.","A Graph Auto-encoder Model of Derivational Morphology There has been little work on modeling the morphological well-formedness (MWF) of derivatives, a problem judged to be complex and difficult in linguistics (Bauer, 2019) . We present a graph auto-encoder that learns embeddings capturing information about the compatibility of affixes and stems in derivation. The auto-encoder models MWF in English surprisingly well by combining syntactic and semantic information with associative information from the mental lexicon.","graph auto - encoder model derivational morphology little work model morphological - formedness ( mwf ) derivative , problem judge complex difficult linguistic ( bauer , 2019 ) . present graph auto - encoder learn embedding capture information compatibility affix stem derivation . auto - encoder model mwf english surprisingly combine syntactic semantic information associative information mental lexicon .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",True
Question Answering,DeFormer: Decomposing Pre-trained Transformers for Faster Question Answering,"Transformer-based QA models use input-wide self-attention -i.e. across both the question and the input passage -at all layers, causing them to be slow and memory-intensive. It turns out that we can get by without inputwide self-attention at all layers, especially in the lower layers. We introduce DeFormer, a decomposed transformer, which substitutes the full self-attention with question-wide and passage-wide self-attentions in the lower layers. This allows for question-independent processing of the input text representations, which in turn enables pre-computing passage representations reducing runtime compute drastically. Furthermore, because DeFormer is largely similar to the original model, we can initialize DeFormer with the pre-training weights of a standard transformer, and directly fine-tune on the target QA dataset. We show DeFormer versions of BERT and XLNet can be used to speed up QA by over 4.3x and with simple distillation-based losses they incur only a 1% drop in accuracy. We open source the code at https://github.com/ StonyBrookNLP/deformer.","DeFormer: Decomposing Pre-trained Transformers for Faster Question Answering Transformer-based QA models use input-wide self-attention -i.e. across both the question and the input passage -at all layers, causing them to be slow and memory-intensive. It turns out that we can get by without inputwide self-attention at all layers, especially in the lower layers. We introduce DeFormer, a decomposed transformer, which substitutes the full self-attention with question-wide and passage-wide self-attentions in the lower layers. This allows for question-independent processing of the input text representations, which in turn enables pre-computing passage representations reducing runtime compute drastically. Furthermore, because DeFormer is largely similar to the original model, we can initialize DeFormer with the pre-training weights of a standard transformer, and directly fine-tune on the target QA dataset. We show DeFormer versions of BERT and XLNet can be used to speed up QA by over 4.3x and with simple distillation-based losses they incur only a 1% drop in accuracy. We open source the code at https://github.com/ StonyBrookNLP/deformer.","deformer : decompose pre - train transformer fast question answering transformer - base qa model use input - wide self - attention -i.e . question input passage -at layer , cause slow memory - intensive . turn inputwide self - attention layer , especially low layer . introduce deformer , decompose transformer , substitute self - attention question - wide passage - wide self - attention low layer . allow question - independent processing input text representation , turn enable pre - compute passage representation reduce runtime compute drastically . furthermore , deformer largely similar original model , initialize deformer pre - training weight standard transformer , directly fine - tune target qa dataset . deformer version bert xlnet speed qa 4.3x simple distillation - base loss incur 1 % drop accuracy . open source code https://github.com/ stonybrooknlp / deformer .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 10, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering,"Evidence retrieval is a critical stage of question answering (QA), necessary not only to improve performance, but also to explain the decisions of the corresponding QA method. We introduce a simple, fast, and unsupervised iterative evidence retrieval method, which relies on three ideas: (a) an unsupervised alignment approach to soft-align questions and answers with justification sentences using only GloVe embeddings, (b) an iterative process that reformulates queries focusing on terms that are not covered by existing justifications, which (c) a stopping criterion that terminates retrieval when the terms in the given question and candidate answers are covered by the retrieved justifications. Despite its simplicity, our approach outperforms all the previous methods (including supervised methods) on the evidence selection task on two datasets: MultiRC and QASC. When these evidence sentences are fed into a RoBERTa answer classification component, we achieve state-of-the-art QA performance on these two datasets.","Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering Evidence retrieval is a critical stage of question answering (QA), necessary not only to improve performance, but also to explain the decisions of the corresponding QA method. We introduce a simple, fast, and unsupervised iterative evidence retrieval method, which relies on three ideas: (a) an unsupervised alignment approach to soft-align questions and answers with justification sentences using only GloVe embeddings, (b) an iterative process that reformulates queries focusing on terms that are not covered by existing justifications, which (c) a stopping criterion that terminates retrieval when the terms in the given question and candidate answers are covered by the retrieved justifications. Despite its simplicity, our approach outperforms all the previous methods (including supervised methods) on the evidence selection task on two datasets: MultiRC and QASC. When these evidence sentences are fed into a RoBERTa answer classification component, we achieve state-of-the-art QA performance on these two datasets.","unsupervised alignment - base iterative evidence retrieval multi - hop question answering evidence retrieval critical stage question answering ( qa ) , necessary improve performance , explain decision corresponding qa method . introduce simple , fast , unsupervised iterative evidence retrieval method , rely idea : ( ) unsupervised alignment approach soft - align question answer justification sentence glove embedding , ( b ) iterative process reformulate query focus term cover exist justification , ( c ) stopping criterion terminate retrieval term give question candidate answer cover retrieve justification . despite simplicity , approach outperform previous method ( include supervised method ) evidence selection task dataset : multirc qasc . evidence sentence feed roberta answer classification component , achieve state - - - art qa performance dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 20, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings,"Knowledge Graphs (KG) are multi-relational graphs consisting of entities as nodes and relations among them as typed edges. Goal of the Question Answering over KG (KGQA) task is to answer natural language queries posed over the KG. Multi-hop KGQA requires reasoning over multiple edges of the KG to arrive at the right answer. KGs are often incomplete with many missing links, posing additional challenges for KGQA, especially for multi-hop KGQA. Recent research on multihop KGQA has attempted to handle KG sparsity using relevant external text, which isn't always readily available. In a separate line of research, KG embedding methods have been proposed to reduce KG sparsity by performing missing link prediction. Such KG embedding methods, even though highly relevant, have not been explored for multi-hop KGQA so far. We fill this gap in this paper and propose EmbedKGQA. EmbedKGQA is particularly effective in performing multi-hop KGQA over sparse KGs. EmbedKGQA also relaxes the requirement of answer selection from a prespecified neighborhood, a sub-optimal constraint enforced by previous multi-hop KGQA methods. Through extensive experiments on multiple benchmark datasets, we demonstrate EmbedKGQA's effectiveness over other stateof-the-art baselines.","Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings Knowledge Graphs (KG) are multi-relational graphs consisting of entities as nodes and relations among them as typed edges. Goal of the Question Answering over KG (KGQA) task is to answer natural language queries posed over the KG. Multi-hop KGQA requires reasoning over multiple edges of the KG to arrive at the right answer. KGs are often incomplete with many missing links, posing additional challenges for KGQA, especially for multi-hop KGQA. Recent research on multihop KGQA has attempted to handle KG sparsity using relevant external text, which isn't always readily available. In a separate line of research, KG embedding methods have been proposed to reduce KG sparsity by performing missing link prediction. Such KG embedding methods, even though highly relevant, have not been explored for multi-hop KGQA so far. We fill this gap in this paper and propose EmbedKGQA. EmbedKGQA is particularly effective in performing multi-hop KGQA over sparse KGs. EmbedKGQA also relaxes the requirement of answer selection from a prespecified neighborhood, a sub-optimal constraint enforced by previous multi-hop KGQA methods. Through extensive experiments on multiple benchmark datasets, we demonstrate EmbedKGQA's effectiveness over other stateof-the-art baselines.","improve multi - hop question answering knowledge graphs knowledge base embeddings knowledge graphs ( kg ) multi - relational graph consist entity node relation type edge . goal question answer kg ( kgqa ) task answer natural language query pose kg . multi - hop kgqa require reason multiple edge kg arrive right answer . kgs incomplete miss link , pose additional challenge kgqa , especially multi - hop kgqa . recent research multihop kgqa attempt handle kg sparsity relevant external text , readily available . separate line research , kg embedding method propose reduce kg sparsity perform miss link prediction . kg embedding method , highly relevant , explore multi - hop kgqa far . fill gap paper propose embedkgqa . embedkgqa particularly effective perform multi - hop kgqa sparse kg . embedkgqa relax requirement answer selection prespecified neighborhood , sub - optimal constraint enforce previous multi - hop kgqa method . extensive experiment multiple benchmark dataset , demonstrate embedkgqa effectiveness stateof - - art baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 23, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,A Self-Training Method for Machine Reading Comprehension with Soft Evidence Extraction,"Neural models have achieved great success on machine reading comprehension (MRC), many of which typically consist of two components: an evidence extractor and an answer predictor. The former seeks the most relevant information from a reference text, while the latter is to locate or generate answers from the extracted evidence. Despite the importance of evidence labels for training the evidence extractor, they are not cheaply accessible, particularly in many non-extractive MRC tasks such as YES/NO question answering and multi-choice MRC. To address this problem, we present a Self-Training method (STM), which supervises the evidence extractor with auto-generated evidence labels in an iterative process. At each iteration, a base MRC model is trained with golden answers and noisy evidence labels. The trained model will predict pseudo evidence labels as extra supervision in the next iteration. We evaluate STM on seven datasets over three MRC tasks. Experimental results demonstrate the improvement on existing MRC models, and we also analyze how and why such a self-training method works in MRC.","A Self-Training Method for Machine Reading Comprehension with Soft Evidence Extraction Neural models have achieved great success on machine reading comprehension (MRC), many of which typically consist of two components: an evidence extractor and an answer predictor. The former seeks the most relevant information from a reference text, while the latter is to locate or generate answers from the extracted evidence. Despite the importance of evidence labels for training the evidence extractor, they are not cheaply accessible, particularly in many non-extractive MRC tasks such as YES/NO question answering and multi-choice MRC. To address this problem, we present a Self-Training method (STM), which supervises the evidence extractor with auto-generated evidence labels in an iterative process. At each iteration, a base MRC model is trained with golden answers and noisy evidence labels. The trained model will predict pseudo evidence labels as extra supervision in the next iteration. We evaluate STM on seven datasets over three MRC tasks. Experimental results demonstrate the improvement on existing MRC models, and we also analyze how and why such a self-training method works in MRC.","self - training method machine reading comprehension soft evidence extraction neural model achieve great success machine reading comprehension ( mrc ) , typically consist component : evidence extractor answer predictor . seek relevant information reference text , locate generate answer extract evidence . despite importance evidence label train evidence extractor , cheaply accessible , particularly non - extractive mrc task yes / question answering multi - choice mrc . address problem , present self - training method ( stm ) , supervise evidence extractor auto - generate evidence label iterative process . iteration , base mrc model train golden answer noisy evidence label . train model predict pseudo evidence label extra supervision iteration . evaluate stm seven dataset mrc task . experimental result demonstrate improvement exist mrc model , analyze self - train method work mrc .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 16, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension,"Machine reading comprehension tasks require a machine reader to answer questions relevant to the given document. In this paper, we present the first free-form multiple-Choice Chinese machine reading Comprehension dataset (C 3 ), containing 13,369 documents (dialogues or more formally written mixed-genre texts) and their associated 19,577 multiple-choice free-form questions collected from Chineseas-a-second-language examinations. We present a comprehensive analysis of the prior knowledge (i.e., linguistic, domainspecific, and general world knowledge) needed for these real-world problems. We implement rule-based and popular neural methods and find that there is still a significant performance gap between the best performing model (68.5%) and human readers (96.0%), especiallyon problems that require prior knowledge. We further study the effects of distractor plausibility and data augmentation based on translated relevant datasets for English on model performance. We expect C 3 to present great challenges to existing systems as answering 86.8% of questions requires both knowledge within and beyond the accompanying document, and we hope that C 3 can serve as a platform to study how to leverage various kinds of prior knowledge to better understand a given written or orally oriented text. C 3 is available at https://dataset.org/c3/.","Investigating Prior Knowledge for Challenging Chinese Machine Reading Comprehension Machine reading comprehension tasks require a machine reader to answer questions relevant to the given document. In this paper, we present the first free-form multiple-Choice Chinese machine reading Comprehension dataset (C 3 ), containing 13,369 documents (dialogues or more formally written mixed-genre texts) and their associated 19,577 multiple-choice free-form questions collected from Chineseas-a-second-language examinations. We present a comprehensive analysis of the prior knowledge (i.e., linguistic, domainspecific, and general world knowledge) needed for these real-world problems. We implement rule-based and popular neural methods and find that there is still a significant performance gap between the best performing model (68.5%) and human readers (96.0%), especiallyon problems that require prior knowledge. We further study the effects of distractor plausibility and data augmentation based on translated relevant datasets for English on model performance. We expect C 3 to present great challenges to existing systems as answering 86.8% of questions requires both knowledge within and beyond the accompanying document, and we hope that C 3 can serve as a platform to study how to leverage various kinds of prior knowledge to better understand a given written or orally oriented text. C 3 is available at https://dataset.org/c3/.","investigate prior knowledge challenge chinese machine reading comprehension machine reading comprehension task require machine reader answer question relevant give document . paper , present free - form multiple - choice chinese machine reading comprehension dataset ( c 3 ) , contain 13,369 document ( dialogue formally write mixed - genre text ) associate 19,577 multiple - choice free - form question collect chineseas - - second - language examination . present comprehensive analysis prior knowledge ( i.e. , linguistic , domainspecific , general world knowledge ) need real - world problem . implement rule - base popular neural method find significant performance gap good perform model ( 68.5 % ) human reader ( 96.0 % ) , especiallyon problem require prior knowledge . study effect distractor plausibility datum augmentation base translate relevant dataset english model performance . expect c 3 present great challenge exist system answer 86.8 % question require knowledge accompanying document , hope c 3 serve platform study leverage kind prior knowledge well understand give write orally orient text . c 3 available https://dataset.org/c3/.","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 10, 'Question Answering': 17, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Question Answering,True
Question Answering,A Frame-based Sentence Representation for Machine Reading Comprehension,"Sentence representation (SR) is the most crucial and challenging task in Machine Reading Comprehension (MRC). MRC systems typically only utilize the information contained in the sentence itself, while human beings can leverage their semantic knowledge. To bridge the gap, we proposed a novel Frame-based Sentence Representation (FSR) method, which employs frame semantic knowledge to facilitate sentence modelling. Specifically, different from existing methods that only model lexical units (LUs), Frame Representation Models, which utilize both LUs in frame and Frame-to-Frame (F-to-F) relations, are designed to model frames and sentences with attention schema. Our proposed FSR method is able to integrate multiple-frame semantic information to get much better sentence representations. Our extensive experimental results show that it performs better than state-of-the-art technologies on machine reading comprehension task.","A Frame-based Sentence Representation for Machine Reading Comprehension Sentence representation (SR) is the most crucial and challenging task in Machine Reading Comprehension (MRC). MRC systems typically only utilize the information contained in the sentence itself, while human beings can leverage their semantic knowledge. To bridge the gap, we proposed a novel Frame-based Sentence Representation (FSR) method, which employs frame semantic knowledge to facilitate sentence modelling. Specifically, different from existing methods that only model lexical units (LUs), Frame Representation Models, which utilize both LUs in frame and Frame-to-Frame (F-to-F) relations, are designed to model frames and sentences with attention schema. Our proposed FSR method is able to integrate multiple-frame semantic information to get much better sentence representations. Our extensive experimental results show that it performs better than state-of-the-art technologies on machine reading comprehension task.","frame - base sentence representation machine reading comprehension sentence representation ( sr ) crucial challenging task machine reading comprehension ( mrc ) . mrc system typically utilize information contain sentence , human being leverage semantic knowledge . bridge gap , propose novel frame - base sentence representation ( fsr ) method , employ frame semantic knowledge facilitate sentence modelling . specifically , different exist method model lexical unit ( lu ) , frame representation model , utilize lu frame frame - - frame ( f - - f ) relation , design model frame sentence attention schema . propose fsr method able integrate multiple - frame semantic information well sentence representation . extensive experimental result perform well state - - - art technology machine reading comprehension task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 12, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering,"We address the problem of extractive question answering using document-level distant supervision, pairing questions and relevant documents with answer strings. We compare previously used probability space and distant supervision assumptions (assumptions on the correspondence between the weak answer string labels and possible answer mention spans). We show that these assumptions interact, and that different configurations provide complementary benefits. We demonstrate that a multiobjective model can efficiently combine the advantages of multiple assumptions and outperform the best individual formulation. Our approach outperforms previous state-of-the-art models by 4.3 points in F1 on TriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries. 1","Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering We address the problem of extractive question answering using document-level distant supervision, pairing questions and relevant documents with answer strings. We compare previously used probability space and distant supervision assumptions (assumptions on the correspondence between the weak answer string labels and possible answer mention spans). We show that these assumptions interact, and that different configurations provide complementary benefits. We demonstrate that a multiobjective model can efficiently combine the advantages of multiple assumptions and outperform the best individual formulation. Our approach outperforms previous state-of-the-art models by 4.3 points in F1 on TriviaQA-Wiki and 1.7 points in Rouge-L on NarrativeQA summaries. 1","probabilistic assumption matter : improve model distantly - supervise document - level question answering address problem extractive question answer document - level distant supervision , pair question relevant document answer string . compare previously probability space distant supervision assumption ( assumption correspondence weak answer string label possible answer mention span ) . assumption interact , different configuration provide complementary benefit . demonstrate multiobjective model efficiently combine advantage multiple assumption outperform good individual formulation . approach outperform previous state - - - art model 4.3 point f1 triviaqa - wiki 1.7 point rouge - l narrativeqa summary . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 14, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering,"Multiple-choice question answering (MCQA) is one of the most challenging tasks in machine reading comprehension since it requires more advanced reading comprehension skills such as logical reasoning, summarization, and arithmetic operations. Unfortunately, most existing MCQA datasets are small in size, which increases the difficulty of model learning and generalization. To address this challenge, we propose a multi-source meta transfer (MMT) for low-resource MCQA. In this framework, we first extend meta learning by incorporating multiple training sources to learn a generalized feature representation across domains. To bridge the distribution gap between training sources and the target, we further introduce the meta transfer that can be integrated into the multi-source meta training. More importantly, the proposed MMT is independent of backbone language models. Extensive experiments demonstrate the superiority of MMT over state-of-the-arts, and continuous improvements can be achieved on different backbone networks on both supervised and unsupervised domain adaptation settings.","Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering Multiple-choice question answering (MCQA) is one of the most challenging tasks in machine reading comprehension since it requires more advanced reading comprehension skills such as logical reasoning, summarization, and arithmetic operations. Unfortunately, most existing MCQA datasets are small in size, which increases the difficulty of model learning and generalization. To address this challenge, we propose a multi-source meta transfer (MMT) for low-resource MCQA. In this framework, we first extend meta learning by incorporating multiple training sources to learn a generalized feature representation across domains. To bridge the distribution gap between training sources and the target, we further introduce the meta transfer that can be integrated into the multi-source meta training. More importantly, the proposed MMT is independent of backbone language models. Extensive experiments demonstrate the superiority of MMT over state-of-the-arts, and continuous improvements can be achieved on different backbone networks on both supervised and unsupervised domain adaptation settings.","multi - source meta transfer low resource multiple - choice question answer multiple - choice question answering ( mcqa ) challenging task machine reading comprehension require advanced reading comprehension skill logical reasoning , summarization , arithmetic operation . unfortunately , exist mcqa dataset small size , increase difficulty model learning generalization . address challenge , propose multi - source meta transfer ( mmt ) low - resource mcqa . framework , extend meta learning incorporate multiple training source learn generalized feature representation domain . bridge distribution gap training source target , introduce meta transfer integrate multi - source meta training . importantly , propose mmt independent backbone language model . extensive experiment demonstrate superiority mmt state - - - art , continuous improvement achieve different backbone network supervised unsupervised domain adaptation setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 18, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Clinical Reading Comprehension: A Thorough Analysis of the emrQA Dataset,"Machine reading comprehension has made great progress in recent years owing to largescale annotated datasets. In the clinical domain, however, creating such datasets is quite difficult due to the domain expertise required for annotation. Recently, Pampari et al. (2018)   tackled this issue by using expert-annotated question templates and existing i2b2 annotations to create emrQA, the first large-scale dataset for question answering (QA) based on clinical notes. In this paper, we provide an indepth analysis of this dataset and the clinical reading comprehension (CliniRC) task. From our qualitative analysis, we find that (i) emrQA answers are often incomplete, and (ii) emrQA questions are often answerable without using domain knowledge. From our quantitative experiments, surprising results include that (iii) using a small sampled subset (5%-20%), we can obtain roughly equal performance compared to the model trained on the entire dataset, (iv) this performance is close to human expert's performance, and (v) BERT models do not beat the best performing base model. Following our analysis of the emrQA, we further explore two desired aspects of CliniRC systems: the ability to utilize clinical domain knowledge and to generalize to unseen questions and contexts. We argue that both should be considered when creating future datasets. 1","Clinical Reading Comprehension: A Thorough Analysis of the emrQA Dataset Machine reading comprehension has made great progress in recent years owing to largescale annotated datasets. In the clinical domain, however, creating such datasets is quite difficult due to the domain expertise required for annotation. Recently, Pampari et al. (2018)   tackled this issue by using expert-annotated question templates and existing i2b2 annotations to create emrQA, the first large-scale dataset for question answering (QA) based on clinical notes. In this paper, we provide an indepth analysis of this dataset and the clinical reading comprehension (CliniRC) task. From our qualitative analysis, we find that (i) emrQA answers are often incomplete, and (ii) emrQA questions are often answerable without using domain knowledge. From our quantitative experiments, surprising results include that (iii) using a small sampled subset (5%-20%), we can obtain roughly equal performance compared to the model trained on the entire dataset, (iv) this performance is close to human expert's performance, and (v) BERT models do not beat the best performing base model. Following our analysis of the emrQA, we further explore two desired aspects of CliniRC systems: the ability to utilize clinical domain knowledge and to generalize to unseen questions and contexts. We argue that both should be considered when creating future datasets. 1","clinical reading comprehension : thorough analysis emrqa dataset machine reading comprehension great progress recent year owe largescale annotate dataset . clinical domain , , create dataset difficult domain expertise require annotation . recently , pampari et al . ( 2018 )    tackle issue expert - annotate question template exist i2b2 annotation create emrqa , large - scale dataset question answering ( qa ) base clinical note . paper , provide indepth analysis dataset clinical reading comprehension ( clinirc ) task . qualitative analysis , find ( ) emrqa answer incomplete , ( ii ) emrqa question answerable domain knowledge . quantitative experiment , surprising result include ( iii ) small sample subset ( 5%-20 % ) , obtain roughly equal performance compare model train entire dataset , ( iv ) performance close human expert performance , ( v ) bert model beat well perform base model . follow analysis emrqa , explore desire aspect clinirc system : ability utilize clinical domain knowledge generalize unseen question context . argue consider create future dataset . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 27, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Dynamic Sampling Strategies for Multi-Task Reading Comprehension,"Building general reading comprehension systems, capable of solving multiple datasets at the same time, is a recent aspirational goal in the research community. Prior work has focused on model architectures or generalization to held out datasets, and largely passed over the particulars of the multi-task learning set up. We show that a simple dynamic sampling strategy, selecting instances for training proportional to the multi-task model's current performance on a dataset relative to its singletask performance, gives substantive gains over prior multi-task sampling strategies, mitigating the catastrophic forgetting that is common in multi-task learning. We also demonstrate that allowing instances of different tasks to be interleaved as much as possible between each epoch and batch has a clear benefit in multitask performance over forcing task homogeneity at the epoch or batch level. Our final model shows greatly increased performance over the best model on ORB, a recently-released multitask reading comprehension benchmark.","Dynamic Sampling Strategies for Multi-Task Reading Comprehension Building general reading comprehension systems, capable of solving multiple datasets at the same time, is a recent aspirational goal in the research community. Prior work has focused on model architectures or generalization to held out datasets, and largely passed over the particulars of the multi-task learning set up. We show that a simple dynamic sampling strategy, selecting instances for training proportional to the multi-task model's current performance on a dataset relative to its singletask performance, gives substantive gains over prior multi-task sampling strategies, mitigating the catastrophic forgetting that is common in multi-task learning. We also demonstrate that allowing instances of different tasks to be interleaved as much as possible between each epoch and batch has a clear benefit in multitask performance over forcing task homogeneity at the epoch or batch level. Our final model shows greatly increased performance over the best model on ORB, a recently-released multitask reading comprehension benchmark.","dynamic sampling strategy multi - task reading comprehension build general reading comprehension system , capable solve multiple dataset time , recent aspirational goal research community . prior work focus model architecture generalization hold dataset , largely pass particular multi - task learning set . simple dynamic sampling strategy , select instance training proportional multi - task model current performance dataset relative singletask performance , give substantive gain prior multi - task sampling strategy , mitigate catastrophic forgetting common multi - task learning . demonstrate allow instance different task interleave possible epoch batch clear benefit multitask performance force task homogeneity epoch batch level . final model show greatly increase performance good model orb , recently - release multitask reading comprehension benchmark .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 9, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational Machine Reading,"The goal of conversational machine reading is to answer user questions given a knowledge base text which may require asking clarification questions. Existing approaches are limited in their decision making due to struggles in extracting question-related rules and reasoning about them. In this paper, we present a new framework of conversational machine reading that comprises a novel Explicit Memory Tracker (EMT) to track whether conditions listed in the rule text have already been satisfied to make a decision. Moreover, our framework generates clarification questions by adopting a coarse-to-fine reasoning strategy, utilizing sentence-level entailment scores to weight token-level distributions. On the ShARC benchmark (blind, heldout) testset, EMT achieves new state-of-theart results of 74.6% micro-averaged decision accuracy and 49.5 BLEU4. We also show that EMT is more interpretable by visualizing the entailment-oriented reasoning process as the conversation flows. Code and models are released at https://github.com/ Yifan-Gao/explicit_memory_tracker.","Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational Machine Reading The goal of conversational machine reading is to answer user questions given a knowledge base text which may require asking clarification questions. Existing approaches are limited in their decision making due to struggles in extracting question-related rules and reasoning about them. In this paper, we present a new framework of conversational machine reading that comprises a novel Explicit Memory Tracker (EMT) to track whether conditions listed in the rule text have already been satisfied to make a decision. Moreover, our framework generates clarification questions by adopting a coarse-to-fine reasoning strategy, utilizing sentence-level entailment scores to weight token-level distributions. On the ShARC benchmark (blind, heldout) testset, EMT achieves new state-of-theart results of 74.6% micro-averaged decision accuracy and 49.5 BLEU4. We also show that EMT is more interpretable by visualizing the entailment-oriented reasoning process as the conversation flows. Code and models are released at https://github.com/ Yifan-Gao/explicit_memory_tracker.","explicit memory tracker coarse - - fine reasoning conversational machine reading goal conversational machine reading answer user question give knowledge base text require ask clarification question . exist approach limit decision making struggle extract question - relate rule reason . paper , present new framework conversational machine reading comprise novel explicit memory tracker ( emt ) track condition list rule text satisfy decision . , framework generate clarification question adopt coarse - - fine reasoning strategy , utilize sentence - level entailment score weight token - level distribution . sharc benchmark ( blind , heldout ) testset , emt achieve new state - - theart result 74.6 % micro - averaged decision accuracy 49.5 bleu4 . emt interpretable visualize entailment - orient reasoning process conversation flow . code model release https://github.com/ yifan - gao / explicit_memory_tracker .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 5, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 11, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Logic-Guided Data Augmentation and Regularization for Consistent Question Answering,"Many natural language questions require qualitative, quantitative or logical comparisons between two entities or events. This paper addresses the problem of improving the accuracy and consistency of responses to comparison questions by integrating logic rules and neural models. Our method leverages logical and linguistic knowledge to augment labeled training data and then uses a consistency-based regularizer to train the model. Improving the global consistency of predictions, our approach achieves large improvements over previous methods in a variety of question answering (QA) tasks including multiple-choice qualitative reasoning, cause-effect reasoning, and extractive machine reading comprehension. In particular, our method significantly improves the performance of RoBERTa-based models by 1-5% across datasets. We advance state of the art by around 5-8% on WIQA and QuaRel and reduce consistency violations by 58% on HotpotQA. We further demonstrate that our approach can learn effectively from limited data. 1 1 Our code and data is available at https://github. com/AkariAsai/logic_guided_qa. Q: The ceramic vase was less flexible than the plastic ball so it was A: more breakable Q: The ceramic vase was more flexible than the plastic ball so it was A: less breakable Q: If it is silent, does the outer ear collect less sound waves? A: more [positive causal relationship] Q: If the outer ear collect less sound waves, is less sound being detected? A: more [positive causal relationship] Q: If it is silent, is less sound being detected? A: more [positive causal relationship] RoBERTa more breakable more breakable RoBERTa more more less Conflict Conflict","Logic-Guided Data Augmentation and Regularization for Consistent Question Answering Many natural language questions require qualitative, quantitative or logical comparisons between two entities or events. This paper addresses the problem of improving the accuracy and consistency of responses to comparison questions by integrating logic rules and neural models. Our method leverages logical and linguistic knowledge to augment labeled training data and then uses a consistency-based regularizer to train the model. Improving the global consistency of predictions, our approach achieves large improvements over previous methods in a variety of question answering (QA) tasks including multiple-choice qualitative reasoning, cause-effect reasoning, and extractive machine reading comprehension. In particular, our method significantly improves the performance of RoBERTa-based models by 1-5% across datasets. We advance state of the art by around 5-8% on WIQA and QuaRel and reduce consistency violations by 58% on HotpotQA. We further demonstrate that our approach can learn effectively from limited data. 1 1 Our code and data is available at https://github. com/AkariAsai/logic_guided_qa. Q: The ceramic vase was less flexible than the plastic ball so it was A: more breakable Q: The ceramic vase was more flexible than the plastic ball so it was A: less breakable Q: If it is silent, does the outer ear collect less sound waves? A: more [positive causal relationship] Q: If the outer ear collect less sound waves, is less sound being detected? A: more [positive causal relationship] Q: If it is silent, is less sound being detected? A: more [positive causal relationship] RoBERTa more breakable more breakable RoBERTa more more less Conflict Conflict","logic - guide datum augmentation regularization consistent question answering natural language question require qualitative , quantitative logical comparison entity event . paper address problem improve accuracy consistency response comparison question integrate logic rule neural model . method leverage logical linguistic knowledge augment label training datum use consistency - base regularizer train model . improve global consistency prediction , approach achieve large improvement previous method variety question answering ( qa ) task include multiple - choice qualitative reasoning , cause - effect reasoning , extractive machine reading comprehension . particular , method significantly improve performance roberta - base model 1 - 5 % dataset . advance state art 5 - 8 % wiqa quarel reduce consistency violation 58 % hotpotqa . demonstrate approach learn effectively limited datum . 1 1 code datum available https://github . com / akariasai / logic_guided_qa . q : ceramic vase flexible plastic ball : breakable q : ceramic vase flexible plastic ball : breakable q : silent , outer ear collect sound wave ? : [ positive causal relationship ] q : outer ear collect sound wave , sound detect ? : [ positive causal relationship ] q : silent , sound detect ? : [ positive causal relationship ] roberta breakable breakable roberta conflict conflict","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 20, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,On the Importance of Diversity in Question Generation for QA,"Automatic question generation (QG) has shown promise as a source of synthetic training data for question answering (QA). In this paper we ask: Is textual diversity in QG beneficial for downstream QA? Using top-p nucleus sampling to derive samples from a transformer-based question generator, we show that diversity-promoting QG indeed provides better QA training than likelihood maximization approaches such as beam search. We also show that standard QG evaluation metrics such as BLEU, ROUGE and METEOR are inversely correlated with diversity, and propose a diversity-aware intrinsic measure of overall QG quality that correlates well with extrinsic evaluation on QA. 1 http://aqleaderboard.tomhosking.co.uk/squad","On the Importance of Diversity in Question Generation for QA Automatic question generation (QG) has shown promise as a source of synthetic training data for question answering (QA). In this paper we ask: Is textual diversity in QG beneficial for downstream QA? Using top-p nucleus sampling to derive samples from a transformer-based question generator, we show that diversity-promoting QG indeed provides better QA training than likelihood maximization approaches such as beam search. We also show that standard QG evaluation metrics such as BLEU, ROUGE and METEOR are inversely correlated with diversity, and propose a diversity-aware intrinsic measure of overall QG quality that correlates well with extrinsic evaluation on QA. 1 http://aqleaderboard.tomhosking.co.uk/squad","importance diversity question generation qa automatic question generation ( qg ) show promise source synthetic training datum question answering ( qa ) . paper ask : textual diversity qg beneficial downstream qa ? - p nucleus sampling derive sample transformer - base question generator , diversity - promote qg provide well qa training likelihood maximization approach beam search . standard qg evaluation metric bleu , rouge meteor inversely correlate diversity , propose diversity - aware intrinsic measure overall qg quality correlate extrinsic evaluation qa . 1 http://aqleaderboard.tomhosking.co.uk/squad","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 13, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,RikiNet: Reading Wikipedia Pages for Natural Question Answering,"Reading long documents to answer opendomain questions remains challenging in natural language understanding. In this paper, we introduce a new model, called RikiNet, which reads Wikipedia pages for natural question answering. RikiNet contains a dynamic paragraph dual-attention reader and a multi-level cascaded answer predictor. The reader dynamically represents the document and question by utilizing a set of complementary attention mechanisms. The representations are then fed into the predictor to obtain the span of the short answer, the paragraph of the long answer, and the answer type in a cascaded manner. On the Natural Questions (NQ) dataset, a single RikiNet achieves 74.3 F1 and 57.9 F1 on longanswer and short-answer tasks. To our best knowledge, it is the first single model that outperforms the single human performance. Furthermore, an ensemble RikiNet obtains 76.1 F1 and 61.3 F1 on long-answer and shortanswer tasks, achieving the best performance on the official NQ leaderboard 1 .","RikiNet: Reading Wikipedia Pages for Natural Question Answering Reading long documents to answer opendomain questions remains challenging in natural language understanding. In this paper, we introduce a new model, called RikiNet, which reads Wikipedia pages for natural question answering. RikiNet contains a dynamic paragraph dual-attention reader and a multi-level cascaded answer predictor. The reader dynamically represents the document and question by utilizing a set of complementary attention mechanisms. The representations are then fed into the predictor to obtain the span of the short answer, the paragraph of the long answer, and the answer type in a cascaded manner. On the Natural Questions (NQ) dataset, a single RikiNet achieves 74.3 F1 and 57.9 F1 on longanswer and short-answer tasks. To our best knowledge, it is the first single model that outperforms the single human performance. Furthermore, an ensemble RikiNet obtains 76.1 F1 and 61.3 F1 on long-answer and shortanswer tasks, achieving the best performance on the official NQ leaderboard 1 .","rikinet : read wikipedia page natural question answering read long document answer opendomain question remain challenging natural language understanding . paper , introduce new model , call rikinet , read wikipedia page natural question answering . rikinet contain dynamic paragraph dual - attention reader multi - level cascade answer predictor . reader dynamically represent document question utilize set complementary attention mechanism . representation feed predictor obtain span short answer , paragraph long answer , answer type cascade manner . natural questions ( nq ) dataset , single rikinet achieve 74.3 f1 57.9 f1 longanswer short - answer task . good knowledge , single model outperform single human performance . furthermore , ensemble rikinet obtain 76.1 f1 61.3 f1 long - answer shortanswer task , achieve good performance official nq leaderboard 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 22, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Low-Resource Generation of Multi-hop Reasoning Questions,"This paper focuses on generating multi-hop reasoning questions from the raw text in a low resource circumstance. Such questions have to be syntactically valid and need to logically correlate with the answers by deducing over multiple relations on several sentences in the text. Specifically, we first build a multi-hop generation model and guide it to satisfy the logical rationality by the reasoning chain extracted from a given text. Since the labeled data is limited and insufficient for training, we propose to learn the model with the help of a large scale of unlabeled data that is much easier to obtain. Such data contains rich expressive forms of the questions with structural patterns on syntax and semantics. These patterns can be estimated by the neural hidden semi-Markov model using latent variables. With latent patterns as a prior, we can regularize the generation model and produce the optimal results. Experimental results on the HotpotQA data set demonstrate the effectiveness of our model. Moreover, we apply the generated results to the task of machine reading comprehension and achieve significant performance improvements.","Low-Resource Generation of Multi-hop Reasoning Questions This paper focuses on generating multi-hop reasoning questions from the raw text in a low resource circumstance. Such questions have to be syntactically valid and need to logically correlate with the answers by deducing over multiple relations on several sentences in the text. Specifically, we first build a multi-hop generation model and guide it to satisfy the logical rationality by the reasoning chain extracted from a given text. Since the labeled data is limited and insufficient for training, we propose to learn the model with the help of a large scale of unlabeled data that is much easier to obtain. Such data contains rich expressive forms of the questions with structural patterns on syntax and semantics. These patterns can be estimated by the neural hidden semi-Markov model using latent variables. With latent patterns as a prior, we can regularize the generation model and produce the optimal results. Experimental results on the HotpotQA data set demonstrate the effectiveness of our model. Moreover, we apply the generated results to the task of machine reading comprehension and achieve significant performance improvements.","low - resource generation multi - hop reasoning question paper focus generate multi - hop reasoning question raw text low resource circumstance . question syntactically valid need logically correlate answer deduce multiple relation sentence text . specifically , build multi - hop generation model guide satisfy logical rationality reasoning chain extract give text . label data limited insufficient training , propose learn model help large scale unlabeled datum easy obtain . data contain rich expressive form question structural pattern syntax semantic . pattern estimate neural hide semi - markov model latent variable . latent pattern prior , regularize generation model produce optimal result . experimental result hotpotqa datum set demonstrate effectiveness model . , apply generate result task machine reading comprehension achieve significant performance improvement .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 10, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Question Answering,True
Question Answering,ClarQ: A large-scale and diverse dataset for Clarification Question Generation,"Question answering and conversational systems are often baffled and need help clarifying certain ambiguities. However, limitations of existing datasets hinder the development of large-scale models capable of generating and utilising clarification questions. In order to overcome these limitations, we devise a novel bootstrapping framework (based on self-supervision) that assists in the creation of a diverse, large-scale dataset of clarification questions based on post-comment tuples extracted from stackexchange. The framework utilises a neural network based architecture for classifying clarification questions. It is a two-step method where the first aims to increase the precision of the classifier and second aims to increase its recall. We quantitatively demonstrate the utility of the newly created dataset by applying it to the downstream task of question-answering. The final dataset, ClarQ, consists of âˆ¼2M examples distributed across 173 domains of stackexchange. We release this dataset 1 in order to foster research into the field of clarification question generation with the larger goal of enhancing dialog and question answering systems.","ClarQ: A large-scale and diverse dataset for Clarification Question Generation Question answering and conversational systems are often baffled and need help clarifying certain ambiguities. However, limitations of existing datasets hinder the development of large-scale models capable of generating and utilising clarification questions. In order to overcome these limitations, we devise a novel bootstrapping framework (based on self-supervision) that assists in the creation of a diverse, large-scale dataset of clarification questions based on post-comment tuples extracted from stackexchange. The framework utilises a neural network based architecture for classifying clarification questions. It is a two-step method where the first aims to increase the precision of the classifier and second aims to increase its recall. We quantitatively demonstrate the utility of the newly created dataset by applying it to the downstream task of question-answering. The final dataset, ClarQ, consists of âˆ¼2M examples distributed across 173 domains of stackexchange. We release this dataset 1 in order to foster research into the field of clarification question generation with the larger goal of enhancing dialog and question answering systems.","clarq : large - scale diverse dataset clarification question generation question answering conversational system baffle need help clarify certain ambiguity . , limitation exist dataset hinder development large - scale model capable generate utilise clarification question . order overcome limitation , devise novel bootstrappe framework ( base self - supervision ) assist creation diverse , large - scale dataset clarification question base post - comment tuple extract stackexchange . framework utilise neural network base architecture classify clarification question . - step method aim increase precision classifier second aim increase recall . quantitatively demonstrate utility newly create dataset apply downstream task question - answering . final dataset , clarq , consist âˆ¼2 m example distribute 173 domain stackexchange . release dataset 1 order foster research field clarification question generation large goal enhance dialog question answering system .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 18, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering,"We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue. First, three language modeling tasks are used to pre-train the transformers, token-and utterance-level language modeling and utterance order prediction, that learn both token and utterance embeddings for better understanding in dialogue contexts. Then, multitask learning between the utterance prediction and the token span prediction is applied to finetune for span-based question answering (QA). Our approach is evaluated on the FRIENDSQA dataset and shows improvements of 3.8% and 1.4% over the two state-of-the-art transformer models, BERT and RoBERTa, respectively.","Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for Span-based Question Answering We introduce a novel approach to transformers that learns hierarchical representations in multiparty dialogue. First, three language modeling tasks are used to pre-train the transformers, token-and utterance-level language modeling and utterance order prediction, that learn both token and utterance embeddings for better understanding in dialogue contexts. Then, multitask learning between the utterance prediction and the token span prediction is applied to finetune for span-based question answering (QA). Our approach is evaluated on the FRIENDSQA dataset and shows improvements of 3.8% and 1.4% over the two state-of-the-art transformer models, BERT and RoBERTa, respectively.","transformer learn hierarchical context multiparty dialogue span - base question answering introduce novel approach transformer learn hierarchical representation multiparty dialogue . , language modeling task pre - train transformer , token - utterance - level language modeling utterance order prediction , learn token utterance embedding well understanding dialogue context . , multitask learning utterance prediction token span prediction apply finetune span - base question answering ( qa ) . approach evaluate friendsqa dataset show improvement 3.8 % 1.4 % state - - - art transformer model , bert roberta , respectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 12, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension,"In this paper, we study machine reading comprehension (MRC) on long texts, where a model takes as inputs a lengthy document and a question and then extracts a text span from the document as an answer. State-of-the-art models tend to use a pretrained transformer model (e.g., BERT) to encode the joint contextual information of document and question. However, these transformer-based models can only take a fixed-length (e.g., 512) text as its input. To deal with even longer text inputs, previous approaches usually chunk them into equally-spaced segments and predict answers based on each segment independently without considering the information from other segments. As a result, they may form segments that fail to cover the correct answer span or retain insufficient contexts around it, which significantly degrades the performance. Moreover, they are less capable of answering questions that need cross-segment information. We propose to let a model learn to chunk in a more flexible way via reinforcement learning: a model can decide the next segment that it wants to process in either direction. We also employ recurrent mechanisms to enable information to flow across segments. Experiments on three MRC datasets -CoQA, QuAC, and TriviaQA -demonstrate the effectiveness of our proposed recurrent chunking mechanisms: we can obtain segments that are more likely to contain complete answers and at the same time provide sufficient contexts around the ground truth answers for better predictions.","Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension In this paper, we study machine reading comprehension (MRC) on long texts, where a model takes as inputs a lengthy document and a question and then extracts a text span from the document as an answer. State-of-the-art models tend to use a pretrained transformer model (e.g., BERT) to encode the joint contextual information of document and question. However, these transformer-based models can only take a fixed-length (e.g., 512) text as its input. To deal with even longer text inputs, previous approaches usually chunk them into equally-spaced segments and predict answers based on each segment independently without considering the information from other segments. As a result, they may form segments that fail to cover the correct answer span or retain insufficient contexts around it, which significantly degrades the performance. Moreover, they are less capable of answering questions that need cross-segment information. We propose to let a model learn to chunk in a more flexible way via reinforcement learning: a model can decide the next segment that it wants to process in either direction. We also employ recurrent mechanisms to enable information to flow across segments. Experiments on three MRC datasets -CoQA, QuAC, and TriviaQA -demonstrate the effectiveness of our proposed recurrent chunking mechanisms: we can obtain segments that are more likely to contain complete answers and at the same time provide sufficient contexts around the ground truth answers for better predictions.","recurrent chunking mechanism long - text machine reading comprehension paper , study machine reading comprehension ( mrc ) long text , model take input lengthy document question extract text span document answer . state - - - art model tend use pretrained transformer model ( e.g. , bert ) encode joint contextual information document question . , transformer - base model fixed - length ( e.g. , 512 ) text input . deal long text input , previous approach usually chunk equally - space segment predict answer base segment independently consider information segment . result , form segment fail cover correct answer span retain insufficient context , significantly degrade performance . , capable answer question need cross - segment information . propose let model learn chunk flexible way reinforcement learning : model decide segment want process direction . employ recurrent mechanism enable information flow segment . experiment mrc dataset -coqa , quac , triviaqa -demonstrate effectiveness propose recurrent chunking mechanism : obtain segment likely contain complete answer time provide sufficient context ground truth answer well prediction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 19, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,R4C: A Benchmark for Evaluating RC Systems to Get the Right Answer for the Right Reason,"Recent studies have revealed that reading comprehension (RC) systems learn to exploit annotation artifacts and other biases in current datasets. This prevents the community from reliably measuring the progress of RC systems. To address this issue, we introduce R 4 C, a new task for evaluating RC systems' internal reasoning. R 4 C requires giving not only answers but also derivations: explanations that justify predicted answers. We present a reliable, crowdsourced framework for scalably annotating RC datasets with derivations. We create and publicly release the R 4 C dataset, the first, quality-assured dataset consisting of 4.6k questions, each of which is annotated with 3 reference derivations (i.e. 13.8k derivations). Experiments show that our automatic evaluation metrics using multiple reference derivations are reliable, and that R 4 C assesses different skills from an existing benchmark.","R4C: A Benchmark for Evaluating RC Systems to Get the Right Answer for the Right Reason Recent studies have revealed that reading comprehension (RC) systems learn to exploit annotation artifacts and other biases in current datasets. This prevents the community from reliably measuring the progress of RC systems. To address this issue, we introduce R 4 C, a new task for evaluating RC systems' internal reasoning. R 4 C requires giving not only answers but also derivations: explanations that justify predicted answers. We present a reliable, crowdsourced framework for scalably annotating RC datasets with derivations. We create and publicly release the R 4 C dataset, the first, quality-assured dataset consisting of 4.6k questions, each of which is annotated with 3 reference derivations (i.e. 13.8k derivations). Experiments show that our automatic evaluation metrics using multiple reference derivations are reliable, and that R 4 C assesses different skills from an existing benchmark.","r4c : benchmark evaluate rc system right answer right reason recent study reveal reading comprehension ( rc ) system learn exploit annotation artifact bias current dataset . prevent community reliably measure progress rc system . address issue , introduce r 4 c , new task evaluate rc system ' internal reasoning . r 4 c require give answer derivation : explanation justify predict answer . present reliable , crowdsource framework scalably annotate rc dataset derivation . create publicly release r 4 c dataset , , quality - assure dataset consist 4.6k question , annotate 3 reference derivation ( i.e. 13.8k derivation ) . experiment automatic evaluation metric multiple reference derivation reliable , r 4 c assess different skill exist benchmark .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 7, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension,"Natural Questions is a new challenging machine reading comprehension benchmark with two-grained answers, which are a long answer (typically a paragraph) and a short answer (one or more entities inside the long answer). Despite the effectiveness of existing methods on this benchmark, they treat these two sub-tasks individually during training while ignoring their dependencies. To address this issue, we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity: documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of representations so that they can be learned simultaneously. The long and short answers can be extracted from paragraphlevel representation and token-level representation, respectively. In this way, we can model the dependencies between the two-grained answers to provide evidence for each other. We jointly train the two sub-tasks, and our experiments show that our approach significantly outperforms previous systems at both long and short answer criteria.","Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension Natural Questions is a new challenging machine reading comprehension benchmark with two-grained answers, which are a long answer (typically a paragraph) and a short answer (one or more entities inside the long answer). Despite the effectiveness of existing methods on this benchmark, they treat these two sub-tasks individually during training while ignoring their dependencies. To address this issue, we present a novel multi-grained machine reading comprehension framework that focuses on modeling documents at their hierarchical nature, which are different levels of granularity: documents, paragraphs, sentences, and tokens. We utilize graph attention networks to obtain different levels of representations so that they can be learned simultaneously. The long and short answers can be extracted from paragraphlevel representation and token-level representation, respectively. In this way, we can model the dependencies between the two-grained answers to provide evidence for each other. We jointly train the two sub-tasks, and our experiments show that our approach significantly outperforms previous systems at both long and short answer criteria.","document modeling graph attention networks multi - grained machine reading comprehension natural questions new challenging machine reading comprehension benchmark - grained answer , long answer ( typically paragraph ) short answer ( entity inside long answer ) . despite effectiveness exist method benchmark , treat sub - task individually training ignore dependency . address issue , present novel multi - grained machine reading comprehension framework focus model document hierarchical nature , different level granularity : document , paragraph , sentence , token . utilize graph attention network obtain different level representation learn simultaneously . long short answer extract paragraphlevel representation token - level representation , respectively . way , model dependency - grained answer provide evidence . jointly train sub - task , experiment approach significantly outperform previous system long short answer criterion .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 20, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Injecting Numerical Reasoning Skills into Language Models,"Large pre-trained language models (LMs) are known to encode substantial amounts of linguistic information. However, high-level reasoning skills, such as numerical reasoning, are difficult to learn from a language-modeling objective only. Consequently, existing models for numerical reasoning have used specialized architectures with limited flexibility. In this work, we show that numerical reasoning is amenable to automatic data generation, and thus one can inject this skill into pre-trained LMs, by generating large amounts of data, and training in a multi-task setup. We show that pre-training our model, GENBERT, on this data, dramatically improves performance on DROP (49.3 â†’ 72.3 F 1 ), reaching performance that matches state-of-the-art models of comparable size, while using a simple and general-purpose encoder-decoder architecture. Moreover, GENBERT generalizes well to math word problem datasets, while maintaining high performance on standard RC tasks. Our approach provides a general recipe for injecting skills into large pre-trained LMs, whenever the skill is amenable to automatic data augmentation.","Injecting Numerical Reasoning Skills into Language Models Large pre-trained language models (LMs) are known to encode substantial amounts of linguistic information. However, high-level reasoning skills, such as numerical reasoning, are difficult to learn from a language-modeling objective only. Consequently, existing models for numerical reasoning have used specialized architectures with limited flexibility. In this work, we show that numerical reasoning is amenable to automatic data generation, and thus one can inject this skill into pre-trained LMs, by generating large amounts of data, and training in a multi-task setup. We show that pre-training our model, GENBERT, on this data, dramatically improves performance on DROP (49.3 â†’ 72.3 F 1 ), reaching performance that matches state-of-the-art models of comparable size, while using a simple and general-purpose encoder-decoder architecture. Moreover, GENBERT generalizes well to math word problem datasets, while maintaining high performance on standard RC tasks. Our approach provides a general recipe for injecting skills into large pre-trained LMs, whenever the skill is amenable to automatic data augmentation.","inject numerical reasoning skill language model large pre - trained language model ( lms ) know encode substantial amount linguistic information . , high - level reasoning skill , numerical reasoning , difficult learn language - model objective . consequently , exist model numerical reasoning specialize architecture limited flexibility . work , numerical reasoning amenable automatic datum generation , inject skill pre - trained lms , generate large amount datum , train multi - task setup . pre - train model , genbert , data , dramatically improve performance drop ( 49.3 â†’ 72.3 f 1 ) , reach performance match state - - - art model comparable size , simple general - purpose encoder - decoder architecture . , genbert generalize math word problem dataset , maintain high performance standard rc task . approach provide general recipe inject skill large pre - train lm , skill amenable automatic datum augmentation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Question Answering,Selective Question Answering under Domain Shift,"To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuADtrained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.","Selective Question Answering under Domain Shift To avoid giving wrong answers, question answering (QA) models need to know when to abstain from answering. Moreover, users often ask questions that diverge from the model's training data, making errors more likely and thus abstention more critical. In this work, we propose the setting of selective question answering under domain shift, in which a QA model is tested on a mixture of in-domain and out-of-domain data, and must answer (i.e., not abstain on) as many questions as possible while maintaining high accuracy. Abstention policies based solely on the model's softmax probabilities fare poorly, since models are overconfident on out-of-domain inputs. Instead, we train a calibrator to identify inputs on which the QA model errs, and abstain when it predicts an error is likely. Crucially, the calibrator benefits from observing the model's behavior on out-of-domain data, even if from a different domain than the test data. We combine this method with a SQuADtrained QA model and evaluate on mixtures of SQuAD and five other QA datasets. Our method answers 56% of questions while maintaining 80% accuracy; in contrast, directly using the model's probabilities only answers 48% at 80% accuracy.","selective question answering domain shift avoid give wrong answer , question answer ( qa ) model need know abstain answer . , user ask question diverge model training datum , make error likely abstention critical . work , propose setting selective question answering domain shift , qa model test mixture - domain - - domain datum , answer ( i.e. , abstain ) question possible maintain high accuracy . abstention policy base solely model softmax probability fare poorly , model overconfident - - domain input . instead , train calibrator identify input qa model err , abstain predict error likely . crucially , calibrator benefit observe model behavior - - domain datum , different domain test datum . combine method squadtrained qa model evaluate mixture squad qa dataset . method answer 56 % question maintain 80 % accuracy ; contrast , directly model probability answer 48 % 80 % accuracy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 26, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Template-Based Question Generation from Retrieved Sentences for Improved Unsupervised Question Answering,"Question Answering (QA) is in increasing demand as the amount of information available online and the desire for quick access to this content grows. A common approach to QA has been to fine-tune a pretrained language model on a task-specific labeled dataset. This paradigm, however, relies on scarce, and costly to obtain, large-scale human-labeled data. We propose an unsupervised approach to training QA models with generated pseudotraining data. We show that generating questions for QA training by applying a simple template on a related, retrieved sentence rather than the original context sentence improves downstream QA performance by allowing the model to learn more complex context-question relationships. Training a QA model on this data gives a relative improvement over a previous unsupervised model in F1 score on the SQuAD dataset by about 14%, and 20% when the answer is a named entity, achieving stateof-the-art performance on SQuAD for unsupervised QA.","Template-Based Question Generation from Retrieved Sentences for Improved Unsupervised Question Answering Question Answering (QA) is in increasing demand as the amount of information available online and the desire for quick access to this content grows. A common approach to QA has been to fine-tune a pretrained language model on a task-specific labeled dataset. This paradigm, however, relies on scarce, and costly to obtain, large-scale human-labeled data. We propose an unsupervised approach to training QA models with generated pseudotraining data. We show that generating questions for QA training by applying a simple template on a related, retrieved sentence rather than the original context sentence improves downstream QA performance by allowing the model to learn more complex context-question relationships. Training a QA model on this data gives a relative improvement over a previous unsupervised model in F1 score on the SQuAD dataset by about 14%, and 20% when the answer is a named entity, achieving stateof-the-art performance on SQuAD for unsupervised QA.","template - base question generation retrieve sentence improved unsupervised question answering question answering ( qa ) increase demand information available online desire quick access content grow . common approach qa fine - tune pretraine language model task - specific label dataset . paradigm , , rely scarce , costly obtain , large - scale human - label datum . propose unsupervised approach train qa model generate pseudotraining datum . generate question qa training apply simple template relate , retrieve sentence original context sentence improve downstream qa performance allow model learn complex context - question relationship . train qa model datum give relative improvement previous unsupervised model f1 score squad dataset 14 % , 20 % answer name entity , achieve stateof - - art performance squad unsupervised qa .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 21, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,SCDE: Sentence Cloze Dataset with High Quality Distractors From Examinations,"We introduce SCDE, a dataset to evaluate the performance of computational models through sentence prediction. SCDE is a humancreated sentence cloze dataset, collected from public school English examinations. Our task requires a model to fill up multiple blanks in a passage from a shared candidate set with distractors designed by English teachers. Experimental results demonstrate that this task requires the use of non-local, discourse-level context beyond the immediate sentence neighborhood. The blanks require joint solving and significantly impair each other's context. Furthermore, through ablations, we show that the distractors are of high quality and make the task more challenging. Our experiments show that there is a significant performance gap between advanced models (72%) and humans (87%), encouraging future models to bridge this gap. 1 2 * Equal Contribution 1 Data: vgtomahawk.github.io/sced.html 2 Code: https://github.com/shawnkx/SCDE Passage: A student's life is never easy. And it is even more difficult if you will have to complete your study in a foreign land. 1 The following are some basic things you need to do before even seizing that passport and boarding on the plane. Knowing the country. You shouldn't bother researching the country's hottest tourist spots or historical places. You won't go there as a tourist, but as a student. 2 In addition, read about their laws. You surely don't want to face legal problems, especially if you're away from home. 3 Don't expect that you can graduate abroad without knowing even the basics of the language. Before leaving your home country, take online lessons to at least master some of their words and sentences. This will be useful in living and studying there. Doing this will also prepare you in communicating with those who can't speak English. Preparing for other needs. Check the conversion of your money to their local currency. 4. The Internet of your intended school will be very helpful in findings an apartment and helping you understand local currency. Remember, you're not only carrying your own reputation but your country's reputation as well. If you act foolishly, people there might think that all of your countrymen are foolish as well. 5 Candidates: A. Studying their language. B. That would surely be a very bad start for your study abroad program. C. Going with their trends will keep it from being too obvious that you're a foreigner. D. Set up your bank account so you can use it there, get an insurance, and find an apartment. E. It'll be helpful to read the most important points in their history and to read up on their culture. F. A lot of preparations are needed so you can be sure to go back home with a diploma and a bright future waiting for you. G. Packing your clothes. Answers with Reasoning Type: 1â†’F (Summary) , 2â†’E (Inference) , 3â†’A (Paraphrase) , 4â†’D (WordMatch), 5â†’B (Inference) (C and G are distractors) Discussion: Blank 3 is the easiest to solve, since ""Studying their language"" is a near-paraphrase of ""Knowing even the basics of the language"". Blank 2 needs to be reasoned out by Inference -specifically E can be inferred from the previous sentence. Note however that C is also a possible inference from the previous sentence -it is only after reading the entire context, which seems to be about learning various aspects of a country, that E seems to fit better. Blank 1 needs Summary â†’ it requires understanding several later sentences and abstracting out that they all refer to lots of preparations. Finally, Blank 5 can be mapped to B by inferring that people thinking all your countrymen are foolish is bad, while Blank 4 is a easy WordMatch on apartment to D. The other distractor G, although topically related to preparation for going abroad, does not directly fit into any of the blank contexts","SCDE: Sentence Cloze Dataset with High Quality Distractors From Examinations We introduce SCDE, a dataset to evaluate the performance of computational models through sentence prediction. SCDE is a humancreated sentence cloze dataset, collected from public school English examinations. Our task requires a model to fill up multiple blanks in a passage from a shared candidate set with distractors designed by English teachers. Experimental results demonstrate that this task requires the use of non-local, discourse-level context beyond the immediate sentence neighborhood. The blanks require joint solving and significantly impair each other's context. Furthermore, through ablations, we show that the distractors are of high quality and make the task more challenging. Our experiments show that there is a significant performance gap between advanced models (72%) and humans (87%), encouraging future models to bridge this gap. 1 2 * Equal Contribution 1 Data: vgtomahawk.github.io/sced.html 2 Code: https://github.com/shawnkx/SCDE Passage: A student's life is never easy. And it is even more difficult if you will have to complete your study in a foreign land. 1 The following are some basic things you need to do before even seizing that passport and boarding on the plane. Knowing the country. You shouldn't bother researching the country's hottest tourist spots or historical places. You won't go there as a tourist, but as a student. 2 In addition, read about their laws. You surely don't want to face legal problems, especially if you're away from home. 3 Don't expect that you can graduate abroad without knowing even the basics of the language. Before leaving your home country, take online lessons to at least master some of their words and sentences. This will be useful in living and studying there. Doing this will also prepare you in communicating with those who can't speak English. Preparing for other needs. Check the conversion of your money to their local currency. 4. The Internet of your intended school will be very helpful in findings an apartment and helping you understand local currency. Remember, you're not only carrying your own reputation but your country's reputation as well. If you act foolishly, people there might think that all of your countrymen are foolish as well. 5 Candidates: A. Studying their language. B. That would surely be a very bad start for your study abroad program. C. Going with their trends will keep it from being too obvious that you're a foreigner. D. Set up your bank account so you can use it there, get an insurance, and find an apartment. E. It'll be helpful to read the most important points in their history and to read up on their culture. F. A lot of preparations are needed so you can be sure to go back home with a diploma and a bright future waiting for you. G. Packing your clothes. Answers with Reasoning Type: 1â†’F (Summary) , 2â†’E (Inference) , 3â†’A (Paraphrase) , 4â†’D (WordMatch), 5â†’B (Inference) (C and G are distractors) Discussion: Blank 3 is the easiest to solve, since ""Studying their language"" is a near-paraphrase of ""Knowing even the basics of the language"". Blank 2 needs to be reasoned out by Inference -specifically E can be inferred from the previous sentence. Note however that C is also a possible inference from the previous sentence -it is only after reading the entire context, which seems to be about learning various aspects of a country, that E seems to fit better. Blank 1 needs Summary â†’ it requires understanding several later sentences and abstracting out that they all refer to lots of preparations. Finally, Blank 5 can be mapped to B by inferring that people thinking all your countrymen are foolish is bad, while Blank 4 is a easy WordMatch on apartment to D. The other distractor G, although topically related to preparation for going abroad, does not directly fit into any of the blank contexts","scde : sentence cloze dataset high quality distractor examination introduce scde , dataset evaluate performance computational model sentence prediction . scde humancreate sentence cloze dataset , collect public school english examination . task require model fill multiple blank passage share candidate set distractor design english teacher . experimental result demonstrate task require use non - local , discourse - level context immediate sentence neighborhood . blank require joint solving significantly impair context . furthermore , ablation , distractor high quality task challenging . experiment significant performance gap advanced model ( 72 % ) human ( 87 % ) , encourage future model bridge gap . 1 2 * equal contribution 1 data : vgtomahawk.github.io/sced.html 2 code : https://github.com/shawnkx/scde passage : student life easy . difficult complete study foreign land . 1 follow basic thing need seize passport board plane . know country . bother research country hot tourist spot historical place . will tourist , student . 2 addition , read law . surely want face legal problem , especially away home . 3 expect graduate abroad know basic language . leave home country , online lesson master word sentence . useful live study . prepare communicate speak english . prepare need . check conversion money local currency . 4 . internet intended school helpful finding apartment help understand local currency . remember , carry reputation country reputation . act foolishly , people think countryman foolish . 5 candidate : a. study language . b. surely bad start study abroad program . c. go trend obvious foreigner . d. set bank account use , insurance , find apartment . e. helpful read important point history read culture . f. lot preparation need sure home diploma bright future wait . g. pack clothe . answer reasoning type : 1â†’f ( summary ) , 2â†’e ( inference ) , 3â†’a ( paraphrase ) , 4â†’d ( wordmatch ) , 5â†’b ( inference ) ( c g distractor ) discussion : blank 3 easy solve , "" study language "" near - paraphrase "" know basic language "" . blank 2 need reason inference -specifically e infer previous sentence . note c possible inference previous sentence -it read entire context , learn aspect country , e fit well . blank 1 need summary â†’ require understand later sentence abstract refer lot preparation . finally , blank 5 map b infer people think countryman foolish bad , blank 4 easy wordmatch apartment d. distractor g , topically relate preparation go abroad , directly fit blank context","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Question Answering,Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases,"Previous work on answering complex questions from knowledge bases usually separately addresses two types of complexity: questions with constraints and questions with multiple hops of relations. In this paper, we handle both types of complexity at the same time. Motivated by the observation that early incorporation of constraints into query graphs can more effectively prune the search space, we propose a modified staged query graph generation method with more flexible ways to generate query graphs. Our experiments clearly show that our method achieves the state of the art on three benchmark KBQA datasets.","Query Graph Generation for Answering Multi-hop Complex Questions from Knowledge Bases Previous work on answering complex questions from knowledge bases usually separately addresses two types of complexity: questions with constraints and questions with multiple hops of relations. In this paper, we handle both types of complexity at the same time. Motivated by the observation that early incorporation of constraints into query graphs can more effectively prune the search space, we propose a modified staged query graph generation method with more flexible ways to generate query graphs. Our experiments clearly show that our method achieves the state of the art on three benchmark KBQA datasets.","query graph generation answer multi - hop complex question knowledge basis previous work answer complex question knowledge basis usually separately address type complexity : question constraint question multiple hop relation . paper , handle type complexity time . motivate observation early incorporation constraint query graph effectively prune search space , propose modify stage query graph generation method flexible way generate query graph . experiment clearly method achieve state art benchmark kbqa dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Question Answering,A Methodology for Creating Question Answering Corpora Using Inverse Data Annotation,"In this paper, we introduce a novel methodology to efficiently construct a corpus for question answering over structured data. For this, we introduce an intermediate representation that is based on the logical query plan in a database called Operation Trees (OT). This representation allows us to invert the annotation process without losing flexibility in the types of queries that we generate. Furthermore, it allows for fine-grained alignment of query tokens to OT operations. In our method, we randomly generate OTs from a context-free grammar. Afterwards, annotators have to write the appropriate natural language question that is represented by the OT. Finally, the annotators assign the tokens to the OT operations. We apply the method to create a new corpus OTTA (Operation Trees and Token Assignment), a large semantic parsing corpus for evaluating natural language interfaces to databases. We compare OTTA to Spider and LC-QuaD 2.0 and show that our methodology more than triples the annotation speed while maintaining the complexity of the queries. Finally, we train a state-of-the-art semantic parsing model on our data and show that our corpus is a challenging dataset and that the token alignment can be leveraged to increase the performance significantly.","A Methodology for Creating Question Answering Corpora Using Inverse Data Annotation In this paper, we introduce a novel methodology to efficiently construct a corpus for question answering over structured data. For this, we introduce an intermediate representation that is based on the logical query plan in a database called Operation Trees (OT). This representation allows us to invert the annotation process without losing flexibility in the types of queries that we generate. Furthermore, it allows for fine-grained alignment of query tokens to OT operations. In our method, we randomly generate OTs from a context-free grammar. Afterwards, annotators have to write the appropriate natural language question that is represented by the OT. Finally, the annotators assign the tokens to the OT operations. We apply the method to create a new corpus OTTA (Operation Trees and Token Assignment), a large semantic parsing corpus for evaluating natural language interfaces to databases. We compare OTTA to Spider and LC-QuaD 2.0 and show that our methodology more than triples the annotation speed while maintaining the complexity of the queries. Finally, we train a state-of-the-art semantic parsing model on our data and show that our corpus is a challenging dataset and that the token alignment can be leveraged to increase the performance significantly.","methodology create question answer corpus inverse data annotation paper , introduce novel methodology efficiently construct corpus question answering structured datum . , introduce intermediate representation base logical query plan database call operation trees ( ot ) . representation allow invert annotation process lose flexibility type query generate . furthermore , allow fine - grained alignment query token ot operation . method , randomly generate ot context - free grammar . , annotator write appropriate natural language question represent ot . finally , annotator assign token ot operation . apply method create new corpus otta ( operation trees token assignment ) , large semantic parsing corpus evaluate natural language interface database . compare otta spider lc - quad 2.0 methodology triple annotation speed maintain complexity query . finally , train state - - - art semantic parsing model datum corpus challenging dataset token alignment leverage increase performance significantly .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 9, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Graph-to-Tree Learning for Solving Math Word Problems,"While the recent tree-based neural models have demonstrated promising results in generating solution expression for the math word problem (MWP), most of these models do not capture the relationships and order information among the quantities well. This results in poor quantity representations and incorrect solution expressions. In this paper, we propose Graph2Tree, a novel deep learning architecture that combines the merits of the graph-based encoder and tree-based decoder to generate better solution expressions. Included in our Graph2Tree framework are two graphs, namely the Quantity Cell Graph and Quantity Comparison Graph, which are designed to address limitations of existing methods by effectively representing the relationships and order information among the quantities in MWPs. We conduct extensive experiments on two available datasets. Our experiment results show that Graph2Tree outperforms the state-of-the-art baselines on two benchmark datasets significantly. We also discuss case studies and empirically examine Graph2Tree's effectiveness in translating the MWP text into solution expressions 1 .","Graph-to-Tree Learning for Solving Math Word Problems While the recent tree-based neural models have demonstrated promising results in generating solution expression for the math word problem (MWP), most of these models do not capture the relationships and order information among the quantities well. This results in poor quantity representations and incorrect solution expressions. In this paper, we propose Graph2Tree, a novel deep learning architecture that combines the merits of the graph-based encoder and tree-based decoder to generate better solution expressions. Included in our Graph2Tree framework are two graphs, namely the Quantity Cell Graph and Quantity Comparison Graph, which are designed to address limitations of existing methods by effectively representing the relationships and order information among the quantities in MWPs. We conduct extensive experiments on two available datasets. Our experiment results show that Graph2Tree outperforms the state-of-the-art baselines on two benchmark datasets significantly. We also discuss case studies and empirically examine Graph2Tree's effectiveness in translating the MWP text into solution expressions 1 .","graph - - tree learning solve math word problem recent tree - base neural model demonstrate promising result generate solution expression math word problem ( mwp ) , model capture relationship order information quantity . result poor quantity representation incorrect solution expression . paper , propose graph2tree , novel deep learning architecture combine merit graph - base encoder tree - base decoder generate well solution expression . include graph2tree framework graph , quantity cell graph quantity comparison graph , design address limitation exist method effectively represent relationship order information quantity mwps . conduct extensive experiment available dataset . experiment result graph2tree outperform state - - - art baseline benchmark dataset significantly . discuss case study empirically examine graph2tree effectiveness translate mwp text solution expression 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Question Answering,Learning to Identify Follow-Up Questions in Conversational Question Answering,"Despite recent progress in conversational question answering, most prior work does not focus on follow-up questions. Practical conversational question answering systems often receive follow-up questions in an ongoing conversation, and it is crucial for a system to be able to determine whether a question is a follow-up question of the current conversation, for more effective answer finding subsequently. In this paper, we introduce a new follow-up question identification task. We propose a three-way attentive pooling network that determines the suitability of a follow-up question by capturing pair-wise interactions between the associated passage, the conversation history, and a candidate follow-up question. It enables the model to capture topic continuity and topic shift while scoring a particular candidate follow-up question. Experiments show that our proposed three-way attentive pooling network outperforms all baseline systems by significant margins.","Learning to Identify Follow-Up Questions in Conversational Question Answering Despite recent progress in conversational question answering, most prior work does not focus on follow-up questions. Practical conversational question answering systems often receive follow-up questions in an ongoing conversation, and it is crucial for a system to be able to determine whether a question is a follow-up question of the current conversation, for more effective answer finding subsequently. In this paper, we introduce a new follow-up question identification task. We propose a three-way attentive pooling network that determines the suitability of a follow-up question by capturing pair-wise interactions between the associated passage, the conversation history, and a candidate follow-up question. It enables the model to capture topic continuity and topic shift while scoring a particular candidate follow-up question. Experiments show that our proposed three-way attentive pooling network outperforms all baseline systems by significant margins.","learn identify follow - question conversational question answering despite recent progress conversational question answering , prior work focus follow - question . practical conversational question answer system receive follow - question ongoing conversation , crucial system able determine question follow - question current conversation , effective answer finding subsequently . paper , introduce new follow - question identification task . propose - way attentive pooling network determine suitability follow - question capture pair - wise interaction associate passage , conversation history , candidate follow - question . enable model capture topic continuity topic shift score particular candidate follow - question . experiment propose - way attentive pooling network outperform baseline system significant margin .","{'Computational Social Science and Social Media': 6, 'Dialogue and Interactive Systems': 6, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 23, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Harvesting and Refining Question-Answer Pairs for Unsupervised QA,"Question Answering (QA) has shown great success thanks to the availability of largescale datasets and the effectiveness of neural models. Recent research works have attempted to extend these successes to the settings with few or no labeled data available. In this work, we introduce two approaches to improve unsupervised QA. First, we harvest lexically and syntactically divergent questions from Wikipedia to automatically construct a corpus of question-answer pairs (named as REFQA). Second, we take advantage of the QA model to extract more appropriate answers, which iteratively refines data over RE-FQA. We conduct experiments 1 on SQuAD 1.1, and NewsQA by fine-tuning BERT without access to manually annotated data. Our approach outperforms previous unsupervised approaches by a large margin and is competitive with early supervised models. We also show the effectiveness of our approach in the fewshot learning setting.","Harvesting and Refining Question-Answer Pairs for Unsupervised QA Question Answering (QA) has shown great success thanks to the availability of largescale datasets and the effectiveness of neural models. Recent research works have attempted to extend these successes to the settings with few or no labeled data available. In this work, we introduce two approaches to improve unsupervised QA. First, we harvest lexically and syntactically divergent questions from Wikipedia to automatically construct a corpus of question-answer pairs (named as REFQA). Second, we take advantage of the QA model to extract more appropriate answers, which iteratively refines data over RE-FQA. We conduct experiments 1 on SQuAD 1.1, and NewsQA by fine-tuning BERT without access to manually annotated data. Our approach outperforms previous unsupervised approaches by a large margin and is competitive with early supervised models. We also show the effectiveness of our approach in the fewshot learning setting.","harvest refine question - answer pair unsupervised qa question answering ( qa ) show great success thank availability largescale dataset effectiveness neural model . recent research work attempt extend success setting label datum available . work , introduce approach improve unsupervised qa . , harvest lexically syntactically divergent question wikipedia automatically construct corpus question - answer pair ( name refqa ) . second , advantage qa model extract appropriate answer , iteratively refine datum - fqa . conduct experiment 1 squad 1.1 , newsqa fine - tune bert access manually annotate datum . approach outperform previous unsupervised approach large margin competitive early supervise model . effectiveness approach fewshot learning setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 18, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,The Cascade Transformer: an Application for Efficient Answer Sentence Selection,"Large transformer-based language models have been shown to be very effective in many classification tasks. However, their computational complexity prevents their use in applications requiring the classification of a large set of candidates. While previous works have investigated approaches to reduce model size, relatively little attention has been paid to techniques to improve batch throughput during inference. In this paper, we introduce the Cascade Transformer, a simple yet effective technique to adapt transformer-based models into a cascade of rankers. Each ranker is used to prune a subset of candidates in a batch, thus dramatically increasing throughput at inference time. Partial encodings from the transformer model are shared among rerankers, providing further speed-up. When compared to a state-of-the-art transformer model, our approach reduces computation by 37% with almost no impact on accuracy, as measured on two English Question Answering datasets.","The Cascade Transformer: an Application for Efficient Answer Sentence Selection Large transformer-based language models have been shown to be very effective in many classification tasks. However, their computational complexity prevents their use in applications requiring the classification of a large set of candidates. While previous works have investigated approaches to reduce model size, relatively little attention has been paid to techniques to improve batch throughput during inference. In this paper, we introduce the Cascade Transformer, a simple yet effective technique to adapt transformer-based models into a cascade of rankers. Each ranker is used to prune a subset of candidates in a batch, thus dramatically increasing throughput at inference time. Partial encodings from the transformer model are shared among rerankers, providing further speed-up. When compared to a state-of-the-art transformer model, our approach reduces computation by 37% with almost no impact on accuracy, as measured on two English Question Answering datasets.","cascade transformer : application efficient answer sentence selection large transformer - base language model show effective classification task . , computational complexity prevent use application require classification large set candidate . previous work investigate approach reduce model size , relatively little attention pay technique improve batch throughput inference . paper , introduce cascade transformer , simple effective technique adapt transformer - base model cascade ranker . ranker prune subset candidate batch , dramatically increase throughput inference time . partial encoding transformer model share reranker , provide speed - . compare state - - - art transformer model , approach reduce computation 37 % impact accuracy , measure english question answering dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 6, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Question Answering,Benefits of Intermediate Annotations in Reading Comprehension,"Complex, compositional reading comprehension datasets require performing latent sequential decisions that are learned via supervision from the final answer. A large combinatorial space of possible decision paths that result in the same answer, compounded by the lack of intermediate supervision to help choose the right path, makes the learning particularly hard for this task. In this work, we study the benefits of collecting intermediate reasoning supervision along with the answer during data collection. We find that these intermediate annotations can provide two-fold benefits. First, we observe that for any collection budget, spending a fraction of it on intermediate annotations results in improved model performance, for two complex compositional datasets: DROP and Quoref. Second, these annotations encourage the model to learn the correct latent reasoning steps, helping combat some of the biases introduced during the data collection process.","Benefits of Intermediate Annotations in Reading Comprehension Complex, compositional reading comprehension datasets require performing latent sequential decisions that are learned via supervision from the final answer. A large combinatorial space of possible decision paths that result in the same answer, compounded by the lack of intermediate supervision to help choose the right path, makes the learning particularly hard for this task. In this work, we study the benefits of collecting intermediate reasoning supervision along with the answer during data collection. We find that these intermediate annotations can provide two-fold benefits. First, we observe that for any collection budget, spending a fraction of it on intermediate annotations results in improved model performance, for two complex compositional datasets: DROP and Quoref. Second, these annotations encourage the model to learn the correct latent reasoning steps, helping combat some of the biases introduced during the data collection process.","benefit intermediate annotation reading comprehension complex , compositional reading comprehension dataset require perform latent sequential decision learn supervision final answer . large combinatorial space possible decision path result answer , compound lack intermediate supervision help choose right path , make learning particularly hard task . work , study benefit collect intermediate reasoning supervision answer datum collection . find intermediate annotation provide - fold benefit . , observe collection budget , spend fraction intermediate annotation result improve model performance , complex compositional dataset : drop quoref . second , annotation encourage model learn correct latent reasoning step , help combat bias introduce datum collection process .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 9, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension,"Multilingual pre-trained models could leverage the training data from a rich source language (such as English) to improve the performance on low resource languages. However, the transfer effectiveness on the multilingual Machine Reading Comprehension (MRC) task is substantially poorer than that for sentence classification tasks, mainly due to the requirement of MRC to detect the word level answer boundary. In this paper, we propose two auxiliary tasks to introduce additional phrase boundary supervision in the fine-tuning stage: (1) a mixed MRC task, which translates the question or passage to other languages and builds cross-lingual question-passage pairs; and (2) a language-agnostic knowledge masking task by leveraging knowledge phrases mined from the Web. Extensive experiments on two cross-lingual MRC datasets show the effectiveness of our proposed approach.","Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension Multilingual pre-trained models could leverage the training data from a rich source language (such as English) to improve the performance on low resource languages. However, the transfer effectiveness on the multilingual Machine Reading Comprehension (MRC) task is substantially poorer than that for sentence classification tasks, mainly due to the requirement of MRC to detect the word level answer boundary. In this paper, we propose two auxiliary tasks to introduce additional phrase boundary supervision in the fine-tuning stage: (1) a mixed MRC task, which translates the question or passage to other languages and builds cross-lingual question-passage pairs; and (2) a language-agnostic knowledge masking task by leveraging knowledge phrases mined from the Web. Extensive experiments on two cross-lingual MRC datasets show the effectiveness of our proposed approach.","enhance answer boundary detection multilingual machine reading comprehension multilingual pre - trained model leverage training datum rich source language ( english ) improve performance low resource language . , transfer effectiveness multilingual machine reading comprehension ( mrc ) task substantially poor sentence classification task , mainly requirement mrc detect word level answer boundary . paper , propose auxiliary task introduce additional phrase boundary supervision fine - tuning stage : ( 1 ) mix mrc task , translate question passage language build cross - lingual question - passage pair ; ( 2 ) language - agnostic knowledge masking task leverage knowledge phrase mine web . extensive experiment cross - lingual mrc dataset effectiveness propose approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 12, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Contextualized Sparse Representations for Real-Time Open-Domain Question Answering,"Open-domain question answering can be formulated as a phrase retrieval problem, in which we can expect huge scalability and speed benefit but often suffer from low accuracy due to the limitation of existing phrase representation models. In this paper, we aim to improve the quality of each phrase embedding by augmenting it with a contextualized sparse representation (SPARC). Unlike previous sparse vectors that are term-frequencybased (e.g., tf-idf) or directly learned (only few thousand dimensions), we leverage rectified self-attention to indirectly learn sparse vectors in n-gram vocabulary space. By augmenting the previous phrase retrieval model (Seo et al., 2019) with SPARC, we show 4%+ improvement in CuratedTREC and SQuAD-Open. Our CuratedTREC score is even better than the best known retrieve & read model with at least 45x faster inference speed. 1","Contextualized Sparse Representations for Real-Time Open-Domain Question Answering Open-domain question answering can be formulated as a phrase retrieval problem, in which we can expect huge scalability and speed benefit but often suffer from low accuracy due to the limitation of existing phrase representation models. In this paper, we aim to improve the quality of each phrase embedding by augmenting it with a contextualized sparse representation (SPARC). Unlike previous sparse vectors that are term-frequencybased (e.g., tf-idf) or directly learned (only few thousand dimensions), we leverage rectified self-attention to indirectly learn sparse vectors in n-gram vocabulary space. By augmenting the previous phrase retrieval model (Seo et al., 2019) with SPARC, we show 4%+ improvement in CuratedTREC and SQuAD-Open. Our CuratedTREC score is even better than the best known retrieve & read model with at least 45x faster inference speed. 1","contextualized sparse representation real - time open - domain question answer open - domain question answering formulate phrase retrieval problem , expect huge scalability speed benefit suffer low accuracy limitation exist phrase representation model . paper , aim improve quality phrase embedding augment contextualize sparse representation ( sparc ) . unlike previous sparse vector term - frequencybase ( e.g. , tf - idf ) directly learn ( thousand dimension ) , leverage rectify self - attention indirectly learn sparse vector n - gram vocabulary space . augment previous phrase retrieval model ( seo et al . , 2019 ) sparc , 4%+ improvement curatedtrec squad - open . curatedtrec score well well know retrieve & read model 45x fast inference speed . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 8, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,DoQA - Accessing Domain-Specific FAQs via Conversational QA,"The goal of this work is to build conversational Question Answering (QA) interfaces for the large body of domain-specific information available in FAQ sites. We present DoQA, a dataset with 2,437 dialogues and 10,917 QA pairs. The dialogues are collected from three Stack Exchange sites using the Wizard of Oz method with crowdsourcing. Compared to previous work, DoQA comprises well-defined information needs, leading to more coherent and natural conversations with less factoid questions and is multi-domain. In addition, we introduce a more realistic information retrieval (IR) scenario where the system needs to find the answer in any of the FAQ documents. The results of an existing, strong, system show that, thanks to transfer learning from a Wikipedia QA dataset and fine tuning on a single FAQ domain, it is possible to build high quality conversational QA systems for FAQs without indomain training data. The good results carry over into the more challenging IR scenario. In both cases, there is still ample room for improvement, as indicated by the higher human upperbound.","DoQA - Accessing Domain-Specific FAQs via Conversational QA The goal of this work is to build conversational Question Answering (QA) interfaces for the large body of domain-specific information available in FAQ sites. We present DoQA, a dataset with 2,437 dialogues and 10,917 QA pairs. The dialogues are collected from three Stack Exchange sites using the Wizard of Oz method with crowdsourcing. Compared to previous work, DoQA comprises well-defined information needs, leading to more coherent and natural conversations with less factoid questions and is multi-domain. In addition, we introduce a more realistic information retrieval (IR) scenario where the system needs to find the answer in any of the FAQ documents. The results of an existing, strong, system show that, thanks to transfer learning from a Wikipedia QA dataset and fine tuning on a single FAQ domain, it is possible to build high quality conversational QA systems for FAQs without indomain training data. The good results carry over into the more challenging IR scenario. In both cases, there is still ample room for improvement, as indicated by the higher human upperbound.","doqa - access domain - specific faq conversational qa goal work build conversational question answering ( qa ) interface large body domain - specific information available faq site . present doqa , dataset 2,437 dialogue 10,917 qa pair . dialogue collect stack exchange site wizard oz method crowdsourcing . compare previous work , doqa comprise - define information need , lead coherent natural conversation factoid question multi - domain . addition , introduce realistic information retrieval ( ir ) scenario system need find answer faq document . result exist , strong , system , thank transfer learning wikipedia qa dataset fine tuning single faq domain , possible build high quality conversational qa system faq indomain training datum . good result carry challenging ir scenario . case , ample room improvement , indicate high human upperbound .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 15, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Break It Down: A Question Understanding Benchmark,"Understanding natural language questions entails the ability to break down a question into the requisite steps for computing its answer. In this work, we introduce a Question Decomposition Meaning Representation (QDMR) for questions. QDMR constitutes the ordered list of steps, expressed through natural language, that are necessary for answering a question. We develop a crowdsourcing pipeline, showing that quality QDMRs can be annotated at scale, and release the BREAK dataset, containing over 83K pairs of questions and their QDMRs. We demonstrate the utility of QDMR by showing that (a) it can be used to improve open-domain question answering on the HOTPOTQA dataset, (b) it can be deterministically converted to a pseudo-SQL formal language, which can alleviate annotation in semantic parsing applications. Last, we use BREAK to train a sequence-to-sequence model with copying that parses questions into QDMR structures, and show that it substantially outperforms several natural baselines.","Break It Down: A Question Understanding Benchmark Understanding natural language questions entails the ability to break down a question into the requisite steps for computing its answer. In this work, we introduce a Question Decomposition Meaning Representation (QDMR) for questions. QDMR constitutes the ordered list of steps, expressed through natural language, that are necessary for answering a question. We develop a crowdsourcing pipeline, showing that quality QDMRs can be annotated at scale, and release the BREAK dataset, containing over 83K pairs of questions and their QDMRs. We demonstrate the utility of QDMR by showing that (a) it can be used to improve open-domain question answering on the HOTPOTQA dataset, (b) it can be deterministically converted to a pseudo-SQL formal language, which can alleviate annotation in semantic parsing applications. Last, we use BREAK to train a sequence-to-sequence model with copying that parses questions into QDMR structures, and show that it substantially outperforms several natural baselines.","break : question understanding benchmark understand natural language question entail ability break question requisite step compute answer . work , introduce question decomposition meaning representation ( qdmr ) question . qdmr constitute ordered list step , express natural language , necessary answer question . develop crowdsourcing pipeline , show quality qdmr annotate scale , release break dataset , contain 83 k pair question qdmr . demonstrate utility qdmr show ( ) improve open - domain question answering hotpotqa dataset , ( b ) deterministically convert pseudo - sql formal language , alleviate annotation semantic parsing application . , use break train sequence - - sequence model copying parse question qdmr structure , substantially outperform natural baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 16, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Question Answering,True
Question Answering,MLQA: Evaluating Cross-lingual Extractive Question Answering,"Question answering (QA) models have shown rapid progress enabled by the availability of large, high-quality benchmark datasets. Such annotated datasets are difficult and costly to collect, and rarely exist in languages other than English, making building QA systems that work well in other languages challenging. In order to develop such systems, it is crucial to invest in high quality multilingual evaluation benchmarks to measure progress. We present MLQA, a multi-way aligned extractive QA evaluation benchmark intended to spur research in this area. 1 MLQA contains QA instances in 7 languages, English, Arabic, German, Spanish, Hindi, Vietnamese and Simplified Chinese. MLQA has over 12K instances in English and 5K in each other language, with each instance parallel between 4 languages on average. We evaluate stateof-the-art cross-lingual models and machinetranslation-based baselines on MLQA. In all cases, transfer results are significantly behind training-language performance.","MLQA: Evaluating Cross-lingual Extractive Question Answering Question answering (QA) models have shown rapid progress enabled by the availability of large, high-quality benchmark datasets. Such annotated datasets are difficult and costly to collect, and rarely exist in languages other than English, making building QA systems that work well in other languages challenging. In order to develop such systems, it is crucial to invest in high quality multilingual evaluation benchmarks to measure progress. We present MLQA, a multi-way aligned extractive QA evaluation benchmark intended to spur research in this area. 1 MLQA contains QA instances in 7 languages, English, Arabic, German, Spanish, Hindi, Vietnamese and Simplified Chinese. MLQA has over 12K instances in English and 5K in each other language, with each instance parallel between 4 languages on average. We evaluate stateof-the-art cross-lingual models and machinetranslation-based baselines on MLQA. In all cases, transfer results are significantly behind training-language performance.","mlqa : evaluate cross - lingual extractive question answering question answering ( qa ) model show rapid progress enable availability large , high - quality benchmark dataset . annotate dataset difficult costly collect , rarely exist language english , make build qa system work language challenging . order develop system , crucial invest high quality multilingual evaluation benchmark measure progress . present mlqa , multi - way align extractive qa evaluation benchmark intend spur research area . 1 mlqa contain qa instance 7 language , english , arabic , german , spanish , hindi , vietnamese simplified chinese . mlqa 12 k instance english 5 k language , instance parallel 4 language average . evaluate stateof - - art cross - lingual model machinetranslation - base baseline mlqa . case , transfer result significantly training - language performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 19, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Question Answering,Crossing Variational Autoencoders for Answer Retrieval,"Answer retrieval is to find the most aligned answer from a large set of candidates given a question. Learning vector representations of questions/answers is the key factor. Questionanswer alignment and question/answer semantics are two important signals for learning the representations. Existing methods learned semantic representations with dual encoders or dual variational auto-encoders. The semantic information was learned from language models or question-to-question (answer-to-answer) generative processes. However, the alignment and semantics were too separate to capture the aligned semantics between question and answer. In this work, we propose to cross variational auto-encoders by generating questions with aligned answers and generating answers with aligned questions. Experiments show that our method outperforms the state-of-theart answer retrieval method on SQuAD. ð‘§ "" ~ð‘(ð‘§ "" ) ð‘(ð‘§ "" |ð‘Ž) Question Answer ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) ð‘(ð‘ž|ð‘§ ! ) ð‘(ð‘Ž|ð‘§ "" ) ð‘§ ! ~ð‘(ð‘§ ! ) Encoder ð‘(ð‘§ ! |ð‘ž) ð‘§ "" ~ð‘(ð‘§ "" ) ð‘(ð‘§ "" |ð‘Ž) Question Answer Decoder ð‘(ð‘ž|ð’› ð’‚ ) ð‘(ð‘Ž|ð’› ð’’ ) ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) Question Answer Question Answer Decoder","Crossing Variational Autoencoders for Answer Retrieval Answer retrieval is to find the most aligned answer from a large set of candidates given a question. Learning vector representations of questions/answers is the key factor. Questionanswer alignment and question/answer semantics are two important signals for learning the representations. Existing methods learned semantic representations with dual encoders or dual variational auto-encoders. The semantic information was learned from language models or question-to-question (answer-to-answer) generative processes. However, the alignment and semantics were too separate to capture the aligned semantics between question and answer. In this work, we propose to cross variational auto-encoders by generating questions with aligned answers and generating answers with aligned questions. Experiments show that our method outperforms the state-of-theart answer retrieval method on SQuAD. ð‘§ "" ~ð‘(ð‘§ "" ) ð‘(ð‘§ "" |ð‘Ž) Question Answer ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) ð‘(ð‘ž|ð‘§ ! ) ð‘(ð‘Ž|ð‘§ "" ) ð‘§ ! ~ð‘(ð‘§ ! ) Encoder ð‘(ð‘§ ! |ð‘ž) ð‘§ "" ~ð‘(ð‘§ "" ) ð‘(ð‘§ "" |ð‘Ž) Question Answer Decoder ð‘(ð‘ž|ð’› ð’‚ ) ð‘(ð‘Ž|ð’› ð’’ ) ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) Question Answer Question Answer Decoder","cross variational autoencoder answer retrieval answer retrieval find align answer large set candidate give question . learn vector representation question / answer key factor . questionanswer alignment question / answer semantic important signal learn representation . exist method learn semantic representation dual encoder dual variational auto - encoder . semantic information learn language model question - - question ( answer - - answer ) generative process . , alignment semantic separate capture align semantic question answer . work , propose cross variational auto - encoder generate question align answer generate answer align question . experiment method outperform state - - theart answer retrieval method squad . ð‘§ "" ~ð‘(ð‘§ "" ) ð‘(ð‘§ "" |ð‘Ž ) question answer ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) ð‘(ð‘ž|ð‘§ ! ) ð‘(ð‘Ž|ð‘§ "" ) ð‘§ ! ~ð‘(ð‘§ ! ) encoder ð‘(ð‘§ ! |ð‘ž ) ð‘§ "" ~ð‘(ð‘§ "" ) ð‘(ð‘§ "" |ð‘Ž ) question answer decoder ð‘(ð‘ž|ð’› ð’‚ ) ð‘(ð‘Ž|ð’› ð’’ ) ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) ð‘(ð‘¦|ð‘§ ! , ð‘§ "" ) question answer question answer decod","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 34, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,True
Resources and Evaluation,Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation,"Open-domain dialogue generation has gained increasing attention in Natural Language Processing. Its evaluation requires a holistic means. Human ratings are deemed as the gold standard. As human evaluation is inefficient and costly, an automated substitute is highly desirable. In this paper, we propose holistic evaluation metrics that capture different aspects of open-domain dialogues. Our metrics consist of (1) GPT-2 based context coherence between sentences in a dialogue, (2) GPT-2 based fluency in phrasing, (3) n-gram based diversity in responses to augmented queries, and (4) textual-entailment-inference based logical self-consistency. The empirical validity of our metrics is demonstrated by strong correlations with human judgments. We open source the code and relevant materials. 1 * Equal contributions","Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation Open-domain dialogue generation has gained increasing attention in Natural Language Processing. Its evaluation requires a holistic means. Human ratings are deemed as the gold standard. As human evaluation is inefficient and costly, an automated substitute is highly desirable. In this paper, we propose holistic evaluation metrics that capture different aspects of open-domain dialogues. Our metrics consist of (1) GPT-2 based context coherence between sentences in a dialogue, (2) GPT-2 based fluency in phrasing, (3) n-gram based diversity in responses to augmented queries, and (4) textual-entailment-inference based logical self-consistency. The empirical validity of our metrics is demonstrated by strong correlations with human judgments. We open source the code and relevant materials. 1 * Equal contributions","holistic automatic evaluation open - domain dialogue generation open - domain dialogue generation gain increase attention natural language processing . evaluation require holistic means . human rating deem gold standard . human evaluation inefficient costly , automate substitute highly desirable . paper , propose holistic evaluation metric capture different aspect open - domain dialogue . metric consist ( 1 ) gpt-2 base context coherence sentence dialogue , ( 2 ) gpt-2 base fluency phrasing , ( 3 ) n - gram base diversity response augment query , ( 4 ) textual - entailment - inference base logical self - consistency . empirical validity metric demonstrate strong correlation human judgment . open source code relevant material . 1 * equal contribut","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Resources and Evaluation,Revisiting the Context Window for Cross-lingual Word Embeddings,"Existing approaches to mapping-based crosslingual word embeddings are based on the assumption that the source and target embedding spaces are structurally similar. The structures of embedding spaces largely depend on the cooccurrence statistics of each word, which the choice of context window determines. Despite this obvious connection between the context window and mapping-based cross-lingual embeddings, their relationship has been underexplored in prior work. In this work, we provide a thorough evaluation, in various languages, domains, and tasks, of bilingual embeddings trained with different context windows. The highlight of our findings is that increasing the size of both the source and target window sizes improves the performance of bilingual lexicon induction, especially the performance on frequent nouns.","Revisiting the Context Window for Cross-lingual Word Embeddings Existing approaches to mapping-based crosslingual word embeddings are based on the assumption that the source and target embedding spaces are structurally similar. The structures of embedding spaces largely depend on the cooccurrence statistics of each word, which the choice of context window determines. Despite this obvious connection between the context window and mapping-based cross-lingual embeddings, their relationship has been underexplored in prior work. In this work, we provide a thorough evaluation, in various languages, domains, and tasks, of bilingual embeddings trained with different context windows. The highlight of our findings is that increasing the size of both the source and target window sizes improves the performance of bilingual lexicon induction, especially the performance on frequent nouns.","revisit context window cross - lingual word embedding exist approach mapping - base crosslingual word embedding base assumption source target embedding space structurally similar . structure embedding space largely depend cooccurrence statistic word , choice context window determine . despite obvious connection context window mapping - base cross - lingual embedding , relationship underexplored prior work . work , provide thorough evaluation , language , domain , task , bilingual embedding train different context window . highlight finding increase size source target window size improve performance bilingual lexicon induction , especially performance frequent noun .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Resources and Evaluation,ChartDialogs: Plotting from Natural Language Instructions,"This paper presents the problem of conversational plotting agents that carry out plotting actions from natural language instructions. To facilitate the development of such agents, we introduce CHARTDIALOGS, a new multi-turn dialog dataset, covering a popular plotting library, matplotlib. The dataset contains over 15, 000 dialog turns from 3, 200 dialogs covering the majority of matplotlib plot types. Extensive experiments show the bestperforming method achieving 61% plotting accuracy, demonstrating that the dataset presents a non-trivial challenge for future research on this task.","ChartDialogs: Plotting from Natural Language Instructions This paper presents the problem of conversational plotting agents that carry out plotting actions from natural language instructions. To facilitate the development of such agents, we introduce CHARTDIALOGS, a new multi-turn dialog dataset, covering a popular plotting library, matplotlib. The dataset contains over 15, 000 dialog turns from 3, 200 dialogs covering the majority of matplotlib plot types. Extensive experiments show the bestperforming method achieving 61% plotting accuracy, demonstrating that the dataset presents a non-trivial challenge for future research on this task.","chartdialog : plotting natural language instruction paper present problem conversational plot agent carry plot action natural language instruction . facilitate development agent , introduce chartdialogs , new multi - turn dialog dataset , cover popular plotting library , matplotlib . dataset contain 15 , 000 dialog turn 3 , 200 dialog cover majority matplotlib plot type . extensive experiment bestperforme method achieve 61 % plotting accuracy , demonstrate dataset present non - trivial challenge future research task .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 8, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Resources and Evaluation,Tangled up in BLEU: Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics,"Automatic metrics are fundamental for the development and evaluation of machine translation systems. Judging whether, and to what extent, automatic metrics concur with the gold standard of human evaluation is not a straightforward problem. We show that current methods for judging metrics are highly sensitive to the translations used for assessment, particularly the presence of outliers, which often leads to falsely confident conclusions about a metric's efficacy. Finally, we turn to pairwise system ranking, developing a method for thresholding performance improvement under an automatic metric against human judgements, which allows quantification of type I versus type II errors incurred, i.e., insignificant human differences in system quality that are accepted, and significant human differences that are rejected. Together, these findings suggest improvements to the protocols for metric evaluation and system performance evaluation in machine translation.","Tangled up in BLEU: Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics Automatic metrics are fundamental for the development and evaluation of machine translation systems. Judging whether, and to what extent, automatic metrics concur with the gold standard of human evaluation is not a straightforward problem. We show that current methods for judging metrics are highly sensitive to the translations used for assessment, particularly the presence of outliers, which often leads to falsely confident conclusions about a metric's efficacy. Finally, we turn to pairwise system ranking, developing a method for thresholding performance improvement under an automatic metric against human judgements, which allows quantification of type I versus type II errors incurred, i.e., insignificant human differences in system quality that are accepted, and significant human differences that are rejected. Together, these findings suggest improvements to the protocols for metric evaluation and system performance evaluation in machine translation.","tangle bleu : reevaluate evaluation automatic machine translation evaluation metric automatic metric fundamental development evaluation machine translation system . judge , extent , automatic metric concur gold standard human evaluation straightforward problem . current method judge metric highly sensitive translation assessment , particularly presence outlier , lead falsely confident conclusion metric efficacy . finally , turn pairwise system ranking , develop method thresholde performance improvement automatic metric human judgement , allow quantification type versus type ii error incur , i.e. , insignificant human difference system quality accept , significant human difference reject . , finding suggest improvement protocol metric evaluation system performance evaluation machine translation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 11, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 13, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,True
Resources and Evaluation,KLEJ: Comprehensive Benchmark for Polish Language Understanding,"In recent years, a series of Transformer-based models unlocked major improvements in general natural language understanding (NLU) tasks. Such a fast pace of research would not be possible without general NLU benchmarks, which allow for a fair comparison of the proposed methods. However, such benchmarks are available only for a handful of languages. To alleviate this issue, we introduce a comprehensive multi-task benchmark for the Polish language understanding, accompanied by an online leaderboard. It consists of a diverse set of tasks, adopted from existing datasets for named entity recognition, question-answering, textual entailment, and others. We also introduce a new sentiment analysis task for the e-commerce domain, named Allegro Reviews (AR). To ensure a common evaluation scheme and promote models that generalize to different NLU tasks, the benchmark includes datasets from varying domains and applications. Additionally, we release HerBERT, a Transformer-based model trained specifically for the Polish language, which has the best average performance and obtains the best results for three out of nine tasks. Finally, we provide an extensive evaluation, including several standard baselines and recently proposed, multilingual Transformer-based models.","KLEJ: Comprehensive Benchmark for Polish Language Understanding In recent years, a series of Transformer-based models unlocked major improvements in general natural language understanding (NLU) tasks. Such a fast pace of research would not be possible without general NLU benchmarks, which allow for a fair comparison of the proposed methods. However, such benchmarks are available only for a handful of languages. To alleviate this issue, we introduce a comprehensive multi-task benchmark for the Polish language understanding, accompanied by an online leaderboard. It consists of a diverse set of tasks, adopted from existing datasets for named entity recognition, question-answering, textual entailment, and others. We also introduce a new sentiment analysis task for the e-commerce domain, named Allegro Reviews (AR). To ensure a common evaluation scheme and promote models that generalize to different NLU tasks, the benchmark includes datasets from varying domains and applications. Additionally, we release HerBERT, a Transformer-based model trained specifically for the Polish language, which has the best average performance and obtains the best results for three out of nine tasks. Finally, we provide an extensive evaluation, including several standard baselines and recently proposed, multilingual Transformer-based models.","klej : comprehensive benchmark polish language understanding recent year , series transformer - base model unlock major improvement general natural language understanding ( nlu ) task . fast pace research possible general nlu benchmark , allow fair comparison propose method . , benchmark available handful language . alleviate issue , introduce comprehensive multi - task benchmark polish language understanding , accompany online leaderboard . consist diverse set task , adopt exist dataset name entity recognition , question - answering , textual entailment , . introduce new sentiment analysis task e - commerce domain , name allegro reviews ( ar ) . ensure common evaluation scheme promote model generalize different nlu task , benchmark include dataset vary domain application . additionally , release herbert , transformer - base model train specifically polish language , good average performance obtain good result task . finally , provide extensive evaluation , include standard baseline recently propose , multilingual transformer - base model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 3, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Resources and Evaluation,A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages,"We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCARbased and Wikipedia-based ELMo embeddings for these languages on the part-ofspeech tagging and parsing tasks. We show that, despite the noise in the Common-Crawlbased OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the crosslingual benefit of multilingual embedding architectures.","A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages We use the multilingual OSCAR corpus, extracted from Common Crawl via language classification, filtering and cleaning, to train monolingual contextualized word embeddings (ELMo) for five mid-resource languages. We then compare the performance of OSCARbased and Wikipedia-based ELMo embeddings for these languages on the part-ofspeech tagging and parsing tasks. We show that, despite the noise in the Common-Crawlbased OSCAR data, embeddings trained on OSCAR perform much better than monolingual embeddings trained on Wikipedia. They actually equal or improve the current state of the art in tagging and parsing for all five languages. In particular, they also improve over multilingual Wikipedia-based contextual embeddings (multilingual BERT), which almost always constitutes the previous state of the art, thereby showing that the benefit of a larger, more diverse corpus surpasses the crosslingual benefit of multilingual embedding architectures.","monolingual approach contextualize word embedding mid - resource language use multilingual oscar corpus , extract common crawl language classification , filtering cleaning , train monolingual contextualize word embedding ( elmo ) mid - resource language . compare performance oscarbased wikipedia - base elmo embedding language - ofspeech tagging parsing task . , despite noise common - crawlbased oscar datum , embedding train oscar perform well monolingual embedding train wikipedia . actually equal improve current state art tagging parsing language . particular , improve multilingual wikipedia - base contextual embedding ( multilingual bert ) , constitute previous state art , show benefit large , diverse corpus surpass crosslingual benefit multilingual embedding architecture .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Resources and Evaluation,WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge,"In this paper, we present the first comprehensive categorization of essential commonsense knowledge for answering the Winograd Schema Challenge (WSC). For each of the questions, we invite annotators to first provide reasons for making correct decisions and then categorize them into six major knowledge categories. By doing so, we better understand the limitation of existing methods (i.e., what kind of knowledge cannot be effectively represented or inferred with existing methods) and shed some light on the commonsense knowledge that we need to acquire in the future for better commonsense reasoning. Moreover, to investigate whether current WSC models can understand the commonsense or they simply solve the WSC questions based on the statistical bias of the dataset, we leverage the collected reasons to develop a new task called WinoWhy, which requires models to distinguish plausible reasons from very similar but wrong reasons for all WSC questions. Experimental results prove that even though pre-trained language representation models have achieved promising progress on the original WSC dataset, they are still struggling at WinoWhy. Further experiments show that even though supervised models can achieve better performance, the performance of these models can be sensitive to the dataset distribution. WinoWhy and all codes are available at: https://github.com/ HKUST-KnowComp/WinoWhy.","WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge In this paper, we present the first comprehensive categorization of essential commonsense knowledge for answering the Winograd Schema Challenge (WSC). For each of the questions, we invite annotators to first provide reasons for making correct decisions and then categorize them into six major knowledge categories. By doing so, we better understand the limitation of existing methods (i.e., what kind of knowledge cannot be effectively represented or inferred with existing methods) and shed some light on the commonsense knowledge that we need to acquire in the future for better commonsense reasoning. Moreover, to investigate whether current WSC models can understand the commonsense or they simply solve the WSC questions based on the statistical bias of the dataset, we leverage the collected reasons to develop a new task called WinoWhy, which requires models to distinguish plausible reasons from very similar but wrong reasons for all WSC questions. Experimental results prove that even though pre-trained language representation models have achieved promising progress on the original WSC dataset, they are still struggling at WinoWhy. Further experiments show that even though supervised models can achieve better performance, the performance of these models can be sensitive to the dataset distribution. WinoWhy and all codes are available at: https://github.com/ HKUST-KnowComp/WinoWhy.","winowhy : deep diagnosis essential commonsense knowledge answer winograd schema challenge paper , present comprehensive categorization essential commonsense knowledge answer winograd schema challenge ( wsc ) . question , invite annotator provide reason make correct decision categorize major knowledge category . , well understand limitation exist method ( i.e. , kind knowledge effectively represent infer exist method ) shed light commonsense knowledge need acquire future well commonsense reasoning . , investigate current wsc model understand commonsense simply solve wsc question base statistical bias dataset , leverage collect reason develop new task call winowhy , require model distinguish plausible reason similar wrong reason wsc question . experimental result prove pre - trained language representation model achieve promising progress original wsc dataset , struggle winowhy . experiment supervise model achieve well performance , performance model sensitive dataset distribution . winowhy code available : https://github.com/ hkust - knowcomp / winowhy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Resources and Evaluation,A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers,"We present ASDiv (Academia Sinica Diverse MWP Dataset), a diverse (in terms of both language patterns and problem types) English math word problem (MWP) corpus for evaluating the capability of various MWP solvers. Existing MWP corpora for studying AI progress remain limited either in language usage patterns or in problem types. We thus present a new English MWP corpus with 2,305 MWPs that cover more text patterns and most problem types taught in elementary school. Each MWP is annotated with its problem type and grade level (for indicating the level of difficulty). Furthermore, we propose a metric to measure the lexicon usage diversity of a given MWP corpus, and demonstrate that ASDiv is more diverse than existing corpora. Experiments show that our proposed corpus reflects the true capability of MWP solvers more faithfully.","A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers We present ASDiv (Academia Sinica Diverse MWP Dataset), a diverse (in terms of both language patterns and problem types) English math word problem (MWP) corpus for evaluating the capability of various MWP solvers. Existing MWP corpora for studying AI progress remain limited either in language usage patterns or in problem types. We thus present a new English MWP corpus with 2,305 MWPs that cover more text patterns and most problem types taught in elementary school. Each MWP is annotated with its problem type and grade level (for indicating the level of difficulty). Furthermore, we propose a metric to measure the lexicon usage diversity of a given MWP corpus, and demonstrate that ASDiv is more diverse than existing corpora. Experiments show that our proposed corpus reflects the true capability of MWP solvers more faithfully.","diverse corpus evaluate develop english math word problem solver present asdiv ( academia sinica diverse mwp dataset ) , diverse ( term language pattern problem type ) english math word problem ( mwp ) corpus evaluate capability mwp solver . exist mwp corpus study ai progress remain limited language usage pattern problem type . present new english mwp corpus 2,305 mwp cover text pattern problem type teach elementary school . mwp annotate problem type grade level ( indicate level difficulty ) . furthermore , propose metric measure lexicon usage diversity give mwp corpus , demonstrate asdiv diverse exist corpus . experiment propose corpus reflect true capability mwp solver faithfully .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 17, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 7, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,True
Resources and Evaluation,STARC: Structured Annotations for Reading Comprehension,"We present STARC (Structured Annotations for Reading Comprehension), a new annotation framework for assessing reading comprehension with multiple choice questions. Our framework introduces a principled structure for the answer choices and ties them to textual span annotations. The framework is implemented in OneStopQA, a new high-quality dataset for evaluation and analysis of reading comprehension in English. We use this dataset to demonstrate that STARC can be leveraged for a key new application for the development of SAT-like reading comprehension materials: automatic annotation quality probing via span ablation experiments. We further show that it enables in-depth analyses and comparisons between machine and human reading comprehension behavior, including error distributions and guessing ability. Our experiments also reveal that the standard multiple choice dataset in NLP, RACE (Lai et al., 2017) , is limited in its ability to measure reading comprehension. 47% of its questions can be guessed by machines without accessing the passage, and 18% are unanimously judged by humans as not having a unique correct answer. OneStopQA provides an alternative test set for reading comprehension which alleviates these shortcomings and has a substantially higher human ceiling performance. 1","STARC: Structured Annotations for Reading Comprehension We present STARC (Structured Annotations for Reading Comprehension), a new annotation framework for assessing reading comprehension with multiple choice questions. Our framework introduces a principled structure for the answer choices and ties them to textual span annotations. The framework is implemented in OneStopQA, a new high-quality dataset for evaluation and analysis of reading comprehension in English. We use this dataset to demonstrate that STARC can be leveraged for a key new application for the development of SAT-like reading comprehension materials: automatic annotation quality probing via span ablation experiments. We further show that it enables in-depth analyses and comparisons between machine and human reading comprehension behavior, including error distributions and guessing ability. Our experiments also reveal that the standard multiple choice dataset in NLP, RACE (Lai et al., 2017) , is limited in its ability to measure reading comprehension. 47% of its questions can be guessed by machines without accessing the passage, and 18% are unanimously judged by humans as not having a unique correct answer. OneStopQA provides an alternative test set for reading comprehension which alleviates these shortcomings and has a substantially higher human ceiling performance. 1","starc : structured annotations reading comprehension present starc ( structured annotations reading comprehension ) , new annotation framework assess reading comprehension multiple choice question . framework introduce principled structure answer choice tie textual span annotation . framework implement onestopqa , new high - quality dataset evaluation analysis reading comprehension english . use dataset demonstrate starc leverage key new application development sat - like reading comprehension material : automatic annotation quality probing span ablation experiment . enable - depth analysis comparison machine human reading comprehension behavior , include error distribution guessing ability . experiment reveal standard multiple choice dataset nlp , race ( lai et al . , 2017 ) , limited ability measure reading comprehension . 47 % question guess machine access passage , 18 % unanimously judge human have unique correct answer . onestopqa provide alternative test set reading comprehension alleviate shortcoming substantially high human ceiling performance . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 30, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Resources and Evaluation,Adversarial NLI: A New Benchmark for Natural Language Understanding,"We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-theart models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.","Adversarial NLI: A New Benchmark for Natural Language Understanding We introduce a new large-scale NLI benchmark dataset, collected via an iterative, adversarial human-and-model-in-the-loop procedure. We show that training models on this new dataset leads to state-of-the-art performance on a variety of popular NLI benchmarks, while posing a more difficult challenge with its new test set. Our analysis sheds light on the shortcomings of current state-of-theart models, and shows that non-expert annotators are successful at finding their weaknesses. The data collection method can be applied in a never-ending learning scenario, becoming a moving target for NLU, rather than a static benchmark that will quickly saturate.","adversarial nli : new benchmark natural language understanding introduce new large - scale nli benchmark dataset , collect iterative , adversarial human - - model - - - loop procedure . train model new dataset lead state - - - art performance variety popular nli benchmark , pose difficult challenge new test set . analysis shed light shortcoming current state - - theart model , show non - expert annotator successful find weakness . datum collection method apply - end learning scenario , move target nlu , static benchmark quickly saturate .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Resources and Evaluation,Generating Counter Narratives against Online Hate Speech: Data and Strategies,"Recently research has started focusing on avoiding undesired effects that come with content moderation, such as censorship and overblocking, when dealing with hatred online. The core idea is to directly intervene in the discussion with textual responses that are meant to counter the hate content and prevent it from further spreading. Accordingly, automation strategies, such as natural language generation, are beginning to be investigated. Still, they suffer from the lack of sufficient amount of quality data and tend to produce generic/repetitive responses. Being aware of the aforementioned limitations, we present a study on how to collect responses to hate effectively, employing large scale unsupervised language models such as GPT-2 for the generation of silver data, and the best annotation strategies/neural architectures that can be used for data filtering before expert validation/postediting.","Generating Counter Narratives against Online Hate Speech: Data and Strategies Recently research has started focusing on avoiding undesired effects that come with content moderation, such as censorship and overblocking, when dealing with hatred online. The core idea is to directly intervene in the discussion with textual responses that are meant to counter the hate content and prevent it from further spreading. Accordingly, automation strategies, such as natural language generation, are beginning to be investigated. Still, they suffer from the lack of sufficient amount of quality data and tend to produce generic/repetitive responses. Being aware of the aforementioned limitations, we present a study on how to collect responses to hate effectively, employing large scale unsupervised language models such as GPT-2 for the generation of silver data, and the best annotation strategies/neural architectures that can be used for data filtering before expert validation/postediting.","generate counter narrative online hate speech : datum strategy recently research start focus avoid undesired effect come content moderation , censorship overblocking , deal hatred online . core idea directly intervene discussion textual response mean counter hate content prevent spread . accordingly , automation strategy , natural language generation , begin investigate . , suffer lack sufficient quality datum tend produce generic / repetitive response . aware aforementioned limitation , present study collect response hate effectively , employ large scale unsupervised language model gpt-2 generation silver datum , good annotation strategy / neural architecture datum filtering expert validation / postediting .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Resources and Evaluation,Fine-Grained Analysis of Cross-Linguistic Syntactic Divergences,"The patterns in which the syntax of different languages converges and diverges are often used to inform work on cross-lingual transfer. Nevertheless, little empirical work has been done on quantifying the prevalence of different syntactic divergences across language pairs. We propose a framework for extracting divergence patterns for any language pair from a parallel corpus, building on Universal Dependencies (UD; Nivre et al., 2016) . We show that our framework provides a detailed picture of cross-language divergences, generalizes previous approaches, and lends itself to full automation. We further present a novel dataset, a manually word-aligned subset of the Parallel UD corpus in five languages, and use it to perform a detailed corpus study. We demonstrate the usefulness of the resulting analysis by showing that it can help account for performance patterns of a cross-lingual parser.","Fine-Grained Analysis of Cross-Linguistic Syntactic Divergences The patterns in which the syntax of different languages converges and diverges are often used to inform work on cross-lingual transfer. Nevertheless, little empirical work has been done on quantifying the prevalence of different syntactic divergences across language pairs. We propose a framework for extracting divergence patterns for any language pair from a parallel corpus, building on Universal Dependencies (UD; Nivre et al., 2016) . We show that our framework provides a detailed picture of cross-language divergences, generalizes previous approaches, and lends itself to full automation. We further present a novel dataset, a manually word-aligned subset of the Parallel UD corpus in five languages, and use it to perform a detailed corpus study. We demonstrate the usefulness of the resulting analysis by showing that it can help account for performance patterns of a cross-lingual parser.","fine - grained analysis cross - linguistic syntactic divergence pattern syntax different language converge diverge inform work cross - lingual transfer . , little empirical work quantify prevalence different syntactic divergence language pair . propose framework extract divergence pattern language pair parallel corpus , build universal dependencies ( ud ; nivre et al . , 2016 ) . framework provide detailed picture cross - language divergence , generalize previous approach , lend automation . present novel dataset , manually word - align subset parallel ud corpus language , use perform detailed corpus study . demonstrate usefulness result analysis show help account performance pattern cross - lingual parser .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 5, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Student Research Workshop,False
Resources and Evaluation,iSarcasm: A Dataset of Intended Sarcasm,"We consider the distinction between intended and perceived sarcasm in the context of textual sarcasm detection. The former occurs when an utterance is sarcastic from the perspective of its author, while the latter occurs when the utterance is interpreted as sarcastic by the audience. We show the limitations of previous labelling methods in capturing intended sarcasm and introduce the iSarcasm dataset of tweets labeled for sarcasm directly by their authors. Examining the state-of-theart sarcasm detection models on our dataset showed low performance compared to previously studied datasets, which indicates that these datasets might be biased or obvious and sarcasm could be a phenomenon under-studied computationally thus far. By providing the iSarcasm dataset, we aim to encourage future NLP research to develop methods for detecting sarcasm in text as intended by the authors of the text, not as labeled under assumptions that we demonstrate to be sub-optimal.","iSarcasm: A Dataset of Intended Sarcasm We consider the distinction between intended and perceived sarcasm in the context of textual sarcasm detection. The former occurs when an utterance is sarcastic from the perspective of its author, while the latter occurs when the utterance is interpreted as sarcastic by the audience. We show the limitations of previous labelling methods in capturing intended sarcasm and introduce the iSarcasm dataset of tweets labeled for sarcasm directly by their authors. Examining the state-of-theart sarcasm detection models on our dataset showed low performance compared to previously studied datasets, which indicates that these datasets might be biased or obvious and sarcasm could be a phenomenon under-studied computationally thus far. By providing the iSarcasm dataset, we aim to encourage future NLP research to develop methods for detecting sarcasm in text as intended by the authors of the text, not as labeled under assumptions that we demonstrate to be sub-optimal.","isarcasm : dataset intended sarcasm consider distinction intended perceive sarcasm context textual sarcasm detection . occur utterance sarcastic perspective author , occur utterance interpret sarcastic audience . limitation previous labelling method capture intend sarcasm introduce isarcasm dataset tweet label sarcasm directly author . examine state - - theart sarcasm detection model dataset show low performance compare previously study dataset , indicate dataset biased obvious sarcasm phenomenon - study computationally far . provide isarcasm dataset , aim encourage future nlp research develop method detect sarcasm text intend author text , label assumption demonstrate sub - optimal .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 15, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Resources and Evaluation,Dialogue-Based Relation Extraction,"We present the first human-annotated dialoguebased relation extraction (RE) dataset Dialo-gRE, aiming to support the prediction of relation(s) between two arguments that appear in a dialogue. We further offer DialogRE as a platform for studying cross-sentence RE as most facts span multiple sentences. We argue that speaker-related information plays a critical role in the proposed task, based on an analysis of similarities and differences between dialogue-based and traditional RE tasks. Considering the timeliness of communication in a dialogue, we design a new metric to evaluate the performance of RE methods in a conversational setting and investigate the performance of several representative RE methods on DialogRE. Experimental results demonstrate that a speaker-aware extension on the best-performing model leads to gains in both the standard and conversational evaluation settings. DialogRE is available at https:// dataset.org/dialogre/.","Dialogue-Based Relation Extraction We present the first human-annotated dialoguebased relation extraction (RE) dataset Dialo-gRE, aiming to support the prediction of relation(s) between two arguments that appear in a dialogue. We further offer DialogRE as a platform for studying cross-sentence RE as most facts span multiple sentences. We argue that speaker-related information plays a critical role in the proposed task, based on an analysis of similarities and differences between dialogue-based and traditional RE tasks. Considering the timeliness of communication in a dialogue, we design a new metric to evaluate the performance of RE methods in a conversational setting and investigate the performance of several representative RE methods on DialogRE. Experimental results demonstrate that a speaker-aware extension on the best-performing model leads to gains in both the standard and conversational evaluation settings. DialogRE is available at https:// dataset.org/dialogre/.","dialogue - base relation extraction present human - annotate dialoguebase relation extraction ( ) dataset dialo - gre , aim support prediction relation( ) argument appear dialogue . offer dialogre platform study cross - sentence fact span multiple sentence . argue speaker - relate information play critical role propose task , base analysis similarity difference dialogue - base traditional task . consider timeliness communication dialogue , design new metric evaluate performance method conversational setting investigate performance representative method dialogre . experimental result demonstrate speaker - aware extension well - perform model lead gain standard conversational evaluation setting . dialogre available https:// dataset.org/dialogre/.","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 16, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Resources and Evaluation,Beyond Accuracy: Behavioral Testing of NLP Models with CheckList,"Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a taskagnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.","Beyond Accuracy: Behavioral Testing of NLP Models with CheckList Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of NLP models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce CheckList, a taskagnostic methodology for testing NLP models. CheckList includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of CheckList with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, NLP practitioners with CheckList created twice as many tests, and found almost three times as many bugs as users without it.","accuracy : behavioral testing nlp model checklist measure hold - accuracy primary approach evaluate generalization , overestimate performance nlp model , alternative approach evaluate model focus individual task specific behavior . inspire principle behavioral testing software engineering , introduce checklist , taskagnostic methodology test nlp model . checklist include matrix general linguistic capability test type facilitate comprehensive test ideation , software tool generate large diverse number test case quickly . illustrate utility checklist test task , identify critical failure commercial state - - art model . user study , team responsible commercial sentiment analysis model find new actionable bug extensively test model . user study , nlp practitioner checklist create twice test , find time bug user .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Resources and Evaluation,Improving Image Captioning Evaluation by Considering Inter References Variance,"Evaluating image captions is very challenging partially due to the fact that there are multiple correct captions for every single image. Most of the existing one-to-one metrics operate by penalizing mismatches between reference and generative caption without considering the intrinsic variance between ground truth captions. It usually leads to over-penalization and thus a bad correlation to human judgment. Recently, the latest one-to-one metric BERTScore can achieve high human correlation in system-level tasks while some issues can be fixed for better performance. In this paper, we propose a novel metric based on BERTScore that could handle such a challenge and extend BERTScore with a few new features appropriately for image captioning evaluation. The experimental results show that our metric achieves state-of-the-art human judgment correlation.","Improving Image Captioning Evaluation by Considering Inter References Variance Evaluating image captions is very challenging partially due to the fact that there are multiple correct captions for every single image. Most of the existing one-to-one metrics operate by penalizing mismatches between reference and generative caption without considering the intrinsic variance between ground truth captions. It usually leads to over-penalization and thus a bad correlation to human judgment. Recently, the latest one-to-one metric BERTScore can achieve high human correlation in system-level tasks while some issues can be fixed for better performance. In this paper, we propose a novel metric based on BERTScore that could handle such a challenge and extend BERTScore with a few new features appropriately for image captioning evaluation. The experimental results show that our metric achieves state-of-the-art human judgment correlation.","improve image captioning evaluation consider inter reference variance evaluate image caption challenging partially fact multiple correct caption single image . exist - - metric operate penalize mismatch reference generative caption consider intrinsic variance ground truth caption . usually lead - penalization bad correlation human judgment . recently , late - - metric bertscore achieve high human correlation system - level task issue fix well performance . paper , propose novel metric base bertscore handle challenge extend bertscore new feature appropriately image captioning evaluation . experimental result metric achieve state - - - art human judgment correlation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 10, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 8, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Resources and Evaluation,Dscorer: A Fast Evaluation Metric for Discourse Representation Structure Parsing,"Discourse representation structures (DRSs) are scoped semantic representations for texts of arbitrary length. Evaluation of the accuracy of predicted DRSs plays a key role in developing semantic parsers and improving their performance. DRSs are typically visualized as nested boxes, in a way that is not straightforward to process automatically. COUNTER, an evaluation algorithm for DRSs, transforms them to clauses and measures clause overlap by searching for variable mappings between two DRSs. Unfortunately, COUNTER is computationally costly (with respect to memory and CPU time) and does not scale with longer texts. We introduce DSCORER, an efficient new metric which converts box-style DRSs to graphs and then measures the overlap of n-grams in the graphs. Experiments show that DSCORER computes accuracy scores that correlate with scores from COUNTER at a fraction of the time.","Dscorer: A Fast Evaluation Metric for Discourse Representation Structure Parsing Discourse representation structures (DRSs) are scoped semantic representations for texts of arbitrary length. Evaluation of the accuracy of predicted DRSs plays a key role in developing semantic parsers and improving their performance. DRSs are typically visualized as nested boxes, in a way that is not straightforward to process automatically. COUNTER, an evaluation algorithm for DRSs, transforms them to clauses and measures clause overlap by searching for variable mappings between two DRSs. Unfortunately, COUNTER is computationally costly (with respect to memory and CPU time) and does not scale with longer texts. We introduce DSCORER, an efficient new metric which converts box-style DRSs to graphs and then measures the overlap of n-grams in the graphs. Experiments show that DSCORER computes accuracy scores that correlate with scores from COUNTER at a fraction of the time.","dscorer : fast evaluation metric discourse representation structure parsing discourse representation structure ( drss ) scope semantic representation text arbitrary length . evaluation accuracy predict drs play key role develop semantic parser improve performance . drs typically visualize nest box , way straightforward process automatically . counter , evaluation algorithm drs , transform clause measure clause overlap search variable mapping drs . unfortunately , counter computationally costly ( respect memory cpu time ) scale long text . introduce dscorer , efficient new metric convert box - style drs graph measure overlap n - gram graph . experiment dscorer compute accuracy score correlate score counter fraction time .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 9, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,False
Resources and Evaluation,More Diverse Dialogue Datasets via Diversity-Informed Data Collection,"Automated generation of conversational dialogue using modern neural architectures has made notable advances. However, these models are known to have a drawback of often producing uninteresting, predictable responses; this is known as the diversity problem. We introduce a new strategy to address this problem, called Diversity-Informed Data Collection. Unlike prior approaches, which modify model architectures to solve the problem, this method uses dynamically computed corpuslevel statistics to determine which conversational participants to collect data from. Diversity-Informed Data Collection produces significantly more diverse data than baseline data collection methods, and better results on two downstream tasks: emotion classification and dialogue generation. This method is generalizable and can be used with other corpuslevel metrics.","More Diverse Dialogue Datasets via Diversity-Informed Data Collection Automated generation of conversational dialogue using modern neural architectures has made notable advances. However, these models are known to have a drawback of often producing uninteresting, predictable responses; this is known as the diversity problem. We introduce a new strategy to address this problem, called Diversity-Informed Data Collection. Unlike prior approaches, which modify model architectures to solve the problem, this method uses dynamically computed corpuslevel statistics to determine which conversational participants to collect data from. Diversity-Informed Data Collection produces significantly more diverse data than baseline data collection methods, and better results on two downstream tasks: emotion classification and dialogue generation. This method is generalizable and can be used with other corpuslevel metrics.","diverse dialogue dataset diversity - informed data collection automate generation conversational dialogue modern neural architecture notable advance . , model know drawback produce uninteresting , predictable response ; know diversity problem . introduce new strategy address problem , call diversity - informed data collection . unlike prior approach , modify model architecture solve problem , method use dynamically compute corpuslevel statistic determine conversational participant collect datum . diversity - informed data collection produce significantly diverse datum baseline data collection method , well result downstream task : emotion classification dialogue generation . method generalizable corpuslevel metric .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Resources and Evaluation,Will-They-Won't-They: A Very Large Dataset for Stance Detection on Twitter,"We present a new challenging stance detection dataset, called Will-They-Won't-They 1 (WT-WT), which contains 51,284 tweets in English, making it by far the largest available dataset of the type. All the annotations are carried out by experts; therefore, the dataset constitutes a high-quality and reliable benchmark for future research in stance detection. Our experiments with a wide range of recent state-of-the-art stance detection systems show that the dataset poses a strong challenge to existing models in this domain. The entire dataset is released for future research 2 .","Will-They-Won't-They: A Very Large Dataset for Stance Detection on Twitter We present a new challenging stance detection dataset, called Will-They-Won't-They 1 (WT-WT), which contains 51,284 tweets in English, making it by far the largest available dataset of the type. All the annotations are carried out by experts; therefore, the dataset constitutes a high-quality and reliable benchmark for future research in stance detection. Our experiments with a wide range of recent state-of-the-art stance detection systems show that the dataset poses a strong challenge to existing models in this domain. The entire dataset is released for future research 2 .","- - won't - : large dataset stance detection twitter present new challenging stance detection dataset , call - - won't - 1 ( wt - wt ) , contain 51,284 tweet english , make far large available dataset type . annotation carry expert ; , dataset constitute high - quality reliable benchmark future research stance detection . experiment wide range recent state - - - art stance detection system dataset pose strong challenge exist model domain . entire dataset release future research 2 .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Resources and Evaluation,ParaCrawl: Web-Scale Acquisition of Parallel Corpora,"We report on methods to create the largest publicly available parallel corpora by crawling the web, using open source software. We empirically compare alternative methods and publish benchmark data sets for sentence alignment and sentence pair filtering. We also describe the parallel corpora released and evaluate their quality and their usefulness to create machine translation systems.","ParaCrawl: Web-Scale Acquisition of Parallel Corpora We report on methods to create the largest publicly available parallel corpora by crawling the web, using open source software. We empirically compare alternative methods and publish benchmark data sets for sentence alignment and sentence pair filtering. We also describe the parallel corpora released and evaluate their quality and their usefulness to create machine translation systems.","paracrawl : web - scale acquisition parallel corpora report method create large publicly available parallel corpora crawl web , open source software . empirically compare alternative method publish benchmark data set sentence alignment sentence pair filtering . describe parallel corpus release evaluate quality usefulness create machine translation system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,False
Resources and Evaluation,GLUECoS: An Evaluation Benchmark for Code-Switched NLP,"Code-switching is the use of more than one language in the same conversation or utterance. Recently, multilingual contextual embedding models, trained on multiple monolingual corpora, have shown promising results on cross-lingual and multilingual tasks. We present an evaluation benchmark, GLUECoS, for code-switched languages, that spans several NLP tasks in English-Hindi and English-Spanish. Specifically, our evaluation benchmark includes Language Identification from text, POS tagging, Named Entity Recognition, Sentiment Analysis, Question Answering and a new task for code-switching, Natural Language Inference. We present results on all these tasks using cross-lingual word embedding models and multilingual models. In addition, we fine-tune multilingual models on artificially generated code-switched data. Although multilingual models perform significantly better than cross-lingual models, our results show that in most tasks, across both language pairs, multilingual models fine-tuned on code-switched data perform best, showing that multilingual models can be further optimized for code-switching tasks.","GLUECoS: An Evaluation Benchmark for Code-Switched NLP Code-switching is the use of more than one language in the same conversation or utterance. Recently, multilingual contextual embedding models, trained on multiple monolingual corpora, have shown promising results on cross-lingual and multilingual tasks. We present an evaluation benchmark, GLUECoS, for code-switched languages, that spans several NLP tasks in English-Hindi and English-Spanish. Specifically, our evaluation benchmark includes Language Identification from text, POS tagging, Named Entity Recognition, Sentiment Analysis, Question Answering and a new task for code-switching, Natural Language Inference. We present results on all these tasks using cross-lingual word embedding models and multilingual models. In addition, we fine-tune multilingual models on artificially generated code-switched data. Although multilingual models perform significantly better than cross-lingual models, our results show that in most tasks, across both language pairs, multilingual models fine-tuned on code-switched data perform best, showing that multilingual models can be further optimized for code-switching tasks.","gluecos : evaluation benchmark code - switch nlp code - switching use language conversation utterance . recently , multilingual contextual embedding model , train multiple monolingual corpus , show promising result cross - lingual multilingual task . present evaluation benchmark , gluecos , code - switch language , span nlp task english - hindi english - spanish . specifically , evaluation benchmark include language identification text , pos tagging , name entity recognition , sentiment analysis , question answering new task code - switching , natural language inference . present result task cross - lingual word embedding model multilingual model . addition , fine - tune multilingual model artificially generate code - switch datum . multilingual model perform significantly well cross - lingual model , result task , language pair , multilingual model fine - tune code - switch datum perform well , show multilingual model optimize code - switching task .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 5, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Resources and Evaluation,LINSPECTOR: Multilingual Probing Tasks for Word Representations,"Despite an ever-growing number of word representation models introduced for a large number of languages, there is a lack of a standardized technique to provide insights into what is captured by these models. Such insights would help the community to get an estimate of the downstream task performance, as well as to design more informed neural architectures, while avoiding extensive experimentation that requires substantial computational resources not all researchers have access to. A recent development in NLP is to use simple classification tasks, also called probing tasks, that test for a single linguistic feature such as part-of-speech. Existing studies mostly focus on exploring the linguistic information encoded by the continuous representations of English text. However, from a typological perspective the morphologically poor English is rather an outlier: The information encoded by the word order and function words in English is often stored on a subword, morphological level in other languages. To address this, we introduce 15 type-level * Work done while Clara Vania was a PhD student at the","LINSPECTOR: Multilingual Probing Tasks for Word Representations Despite an ever-growing number of word representation models introduced for a large number of languages, there is a lack of a standardized technique to provide insights into what is captured by these models. Such insights would help the community to get an estimate of the downstream task performance, as well as to design more informed neural architectures, while avoiding extensive experimentation that requires substantial computational resources not all researchers have access to. A recent development in NLP is to use simple classification tasks, also called probing tasks, that test for a single linguistic feature such as part-of-speech. Existing studies mostly focus on exploring the linguistic information encoded by the continuous representations of English text. However, from a typological perspective the morphologically poor English is rather an outlier: The information encoded by the word order and function words in English is often stored on a subword, morphological level in other languages. To address this, we introduce 15 type-level * Work done while Clara Vania was a PhD student at the","linspector : multilingual probing task word representation despite - grow number word representation model introduce large number language , lack standardized technique provide insight capture model . insight help community estimate downstream task performance , design informed neural architecture , avoid extensive experimentation require substantial computational resource researcher access . recent development nlp use simple classification task , call probe task , test single linguistic feature - - speech . exist study focus explore linguistic information encode continuous representation english text . , typological perspective morphologically poor english outlier : information encode word order function word english store subword , morphological level language . address , introduce 15 type - level * work clara vania phd stud","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Phonology, Morphology and Word Segmentation",False
Resources and Evaluation,"MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization","Recently, large-scale datasets have vastly facilitated the development in nearly all domains of Natural Language Processing. However, there is currently no cross-task dataset in NLP, which hinders the development of multi-task learning. We propose MATINF, the first jointly labeled large-scale dataset for classification, question answering and summarization. MAT-INF contains 1.07 million question-answer pairs with human-labeled categories and usergenerated question descriptions. Based on such rich information, MATINF is applicable for three major NLP tasks, including classification, question answering, and summarization. We benchmark existing methods and a novel multi-task baseline over MATINF to inspire further research. Our comprehensive comparison and experiments over MATINF and other datasets demonstrate the merits held by MAT-INF. 1","MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization Recently, large-scale datasets have vastly facilitated the development in nearly all domains of Natural Language Processing. However, there is currently no cross-task dataset in NLP, which hinders the development of multi-task learning. We propose MATINF, the first jointly labeled large-scale dataset for classification, question answering and summarization. MAT-INF contains 1.07 million question-answer pairs with human-labeled categories and usergenerated question descriptions. Based on such rich information, MATINF is applicable for three major NLP tasks, including classification, question answering, and summarization. We benchmark existing methods and a novel multi-task baseline over MATINF to inspire further research. Our comprehensive comparison and experiments over MATINF and other datasets demonstrate the merits held by MAT-INF. 1","matinf : jointly label large - scale dataset classification , question answering summarization recently , large - scale dataset vastly facilitate development nearly domain natural language processing . , currently cross - task dataset nlp , hinder development multi - task learning . propose matinf , jointly label large - scale dataset classification , question answering summarization . mat - inf contain 1.07 million question - answer pair human - label category usergenerate question description . base rich information , matinf applicable major nlp task , include classification , question answering , summarization . benchmark exist method novel multi - task baseline matinf inspire research . comprehensive comparison experiment matinf dataset demonstrate merit hold mat - inf . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 18, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Resources and Evaluation,Code and Named Entity Recognition in StackOverflow,"There is an increasing interest in studying natural language and computer code together, as large corpora of programming texts become readily available on the Internet. For example, StackOverflow currently has over 15 million programming related questions written by 8.5 million users. Meanwhile, there is still a lack of fundamental NLP techniques for identifying code tokens or software-related named entities that appear within natural language sentences. In this paper, we introduce a new named entity recognition (NER) corpus for the computer programming domain, consisting of 15,372 sentences annotated with 20 fine-grained entity types. We trained indomain BERT representations (BERTOverflow) on 152 million sentences from Stack-Overflow, which lead to an absolute increase of +10 F 1 score over off-the-shelf BERT. We also present the SoftNER model which achieves an overall 79.10 F 1 score for code and named entity recognition on StackOverflow data. Our SoftNER model incorporates a context-independent code token classifier with corpus-level features to improve the BERTbased tagging model. 1","Code and Named Entity Recognition in StackOverflow There is an increasing interest in studying natural language and computer code together, as large corpora of programming texts become readily available on the Internet. For example, StackOverflow currently has over 15 million programming related questions written by 8.5 million users. Meanwhile, there is still a lack of fundamental NLP techniques for identifying code tokens or software-related named entities that appear within natural language sentences. In this paper, we introduce a new named entity recognition (NER) corpus for the computer programming domain, consisting of 15,372 sentences annotated with 20 fine-grained entity types. We trained indomain BERT representations (BERTOverflow) on 152 million sentences from Stack-Overflow, which lead to an absolute increase of +10 F 1 score over off-the-shelf BERT. We also present the SoftNER model which achieves an overall 79.10 F 1 score for code and named entity recognition on StackOverflow data. Our SoftNER model incorporates a context-independent code token classifier with corpus-level features to improve the BERTbased tagging model. 1","code name entity recognition stackoverflow increase interest study natural language computer code , large corpus programming text readily available internet . example , stackoverflow currently 15 million programming relate question write 8.5 million user . , lack fundamental nlp technique identify code token software - relate name entity appear natural language sentence . paper , introduce new name entity recognition ( ner ) corpus computer programming domain , consist 15,372 sentence annotate 20 fine - grained entity type . train indomain bert representation ( bertoverflow ) 152 million sentence stack - overflow , lead absolute increase +10 f 1 score - - shelf bert . present softner model achieve overall 79.10 f 1 score code name entity recognition stackoverflow datum . softner model incorporate context - independent code token classifier corpus - level feature improve bertbased tagging model . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 22, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Resources and Evaluation,The TechQA Dataset,"We introduce TECHQA, a domain-adaptation question answering dataset for the technical support domain. The TECHQA corpus highlights two real-world issues from the automated customer support domain. First, it contains actual questions posed by users on a technical forum, rather than questions generated specifically for a competition or a task. Second, it has a real-world size -600 training, 310 dev, and 490 evaluation question/answer pairs -thus reflecting the cost of creating large labeled datasets with actual data. Hence, TECHQA is meant to stimulate research in domain adaptation rather than as a resource to build QA systems from scratch. TECHQA was obtained by crawling the IB-MDeveloper and DeveloperWorks forums for questions with accepted answers provided in an IBM Technote-a technical document that addresses a specific technical issue. We also release a collection of the 801,998 Technotes available on the web as of April 4, 2019 as a companion resource that can be used to learn representations of the IT domain language.","The TechQA Dataset We introduce TECHQA, a domain-adaptation question answering dataset for the technical support domain. The TECHQA corpus highlights two real-world issues from the automated customer support domain. First, it contains actual questions posed by users on a technical forum, rather than questions generated specifically for a competition or a task. Second, it has a real-world size -600 training, 310 dev, and 490 evaluation question/answer pairs -thus reflecting the cost of creating large labeled datasets with actual data. Hence, TECHQA is meant to stimulate research in domain adaptation rather than as a resource to build QA systems from scratch. TECHQA was obtained by crawling the IB-MDeveloper and DeveloperWorks forums for questions with accepted answers provided in an IBM Technote-a technical document that addresses a specific technical issue. We also release a collection of the 801,998 Technotes available on the web as of April 4, 2019 as a companion resource that can be used to learn representations of the IT domain language.","techqa dataset introduce techqa , domain - adaptation question answer dataset technical support domain . techqa corpus highlight real - world issue automate customer support domain . , contain actual question pose user technical forum , question generate specifically competition task . second , real - world size -600 training , 310 dev , 490 evaluation question / answer pair -thus reflect cost create large label dataset actual datum . , techqa mean stimulate research domain adaptation resource build qa system scratch . techqa obtain crawl ib - mdeveloper developerworks forum question accept answer provide ibm technote - technical document address specific technical issue . release collection 801,998 technotes available web april 4 , 2019 companion resource learn representation domain language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 15, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Resources and Evaluation,Learning and Evaluating Emotion Lexicons for 91 Languages,"Emotion lexicons describe the affective meaning of words and thus constitute a centerpiece for advanced sentiment and emotion analysis. Yet, manually curated lexicons are only available for a handful of languages, leaving most languages of the world without such a precious resource for downstream applications. Even worse, their coverage is often limited both in terms of the lexical units they contain and the emotional variables they feature. In order to break this bottleneck, we here introduce a methodology for creating almost arbitrarily large emotion lexicons for any target language. Our approach requires nothing but a source language emotion lexicon, a bilingual word translation model, and a target language embedding model. Fulfilling these requirements for 91 languages, we are able to generate representationally rich high-coverage lexicons comprising eight emotional variables with more than 100k lexical entries each. We evaluated the automatically generated lexicons against human judgment from 26 datasets, spanning 12 typologically diverse languages, and found that our approach produces results in line with state-of-the-art monolingual approaches to lexicon creation and even surpasses human reliability for some languages and variables. Code and data are available at github.com/JULIELab/MEmoLon archived under","Learning and Evaluating Emotion Lexicons for 91 Languages Emotion lexicons describe the affective meaning of words and thus constitute a centerpiece for advanced sentiment and emotion analysis. Yet, manually curated lexicons are only available for a handful of languages, leaving most languages of the world without such a precious resource for downstream applications. Even worse, their coverage is often limited both in terms of the lexical units they contain and the emotional variables they feature. In order to break this bottleneck, we here introduce a methodology for creating almost arbitrarily large emotion lexicons for any target language. Our approach requires nothing but a source language emotion lexicon, a bilingual word translation model, and a target language embedding model. Fulfilling these requirements for 91 languages, we are able to generate representationally rich high-coverage lexicons comprising eight emotional variables with more than 100k lexical entries each. We evaluated the automatically generated lexicons against human judgment from 26 datasets, spanning 12 typologically diverse languages, and found that our approach produces results in line with state-of-the-art monolingual approaches to lexicon creation and even surpasses human reliability for some languages and variables. Code and data are available at github.com/JULIELab/MEmoLon archived under","learn evaluate emotion lexicon 91 language emotion lexicon describe affective meaning word constitute centerpiece advanced sentiment emotion analysis . , manually curate lexicon available handful language , leave language world precious resource downstream application . worse , coverage limited term lexical unit contain emotional variable feature . order break bottleneck , introduce methodology create arbitrarily large emotion lexicon target language . approach require source language emotion lexicon , bilingual word translation model , target language embedding model . fulfil requirement 91 language , able generate representationally rich high - coverage lexicon comprise emotional variable 100k lexical entry . evaluate automatically generate lexicon human judgment 26 dataset , span 12 typologically diverse language , find approach produce result line state - - - art monolingual approach lexicon creation surpass human reliability language variable . code datum available github.com/julielab/memolon arch","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 7, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",False
Resources and Evaluation,Automatic Machine Translation Evaluation using Source Language Inputs and Cross-lingual Language Model,"We propose an automatic evaluation method of machine translation that uses source language sentences regarded as additional pseudo references. The proposed method evaluates a translation hypothesis in a regression model. The model takes the paired source, reference, and hypothesis sentence all together as an input. A pretrained large scale cross-lingual language model encodes the input to sentence-pair vectors, and the model predicts a human evaluation score with those vectors. Our experiments show that our proposed method using Crosslingual Language Model (XLM) trained with a translation language modeling (TLM) objective achieves a higher correlation with human judgments than a baseline method that uses only hypothesis and reference sentences. Additionally, using source sentences in our proposed method is confirmed to improve the evaluation performance.","Automatic Machine Translation Evaluation using Source Language Inputs and Cross-lingual Language Model We propose an automatic evaluation method of machine translation that uses source language sentences regarded as additional pseudo references. The proposed method evaluates a translation hypothesis in a regression model. The model takes the paired source, reference, and hypothesis sentence all together as an input. A pretrained large scale cross-lingual language model encodes the input to sentence-pair vectors, and the model predicts a human evaluation score with those vectors. Our experiments show that our proposed method using Crosslingual Language Model (XLM) trained with a translation language modeling (TLM) objective achieves a higher correlation with human judgments than a baseline method that uses only hypothesis and reference sentences. Additionally, using source sentences in our proposed method is confirmed to improve the evaluation performance.","automatic machine translation evaluation source language input cross - lingual language model propose automatic evaluation method machine translation use source language sentence regard additional pseudo reference . propose method evaluate translation hypothesis regression model . model take pair source , reference , hypothesis sentence input . pretrained large scale cross - lingual language model encode input sentence - pair vector , model predict human evaluation score vector . experiment propose method crosslingual language model ( xlm ) train translation language modeling ( tlm ) objective achieve high correlation human judgment baseline method use hypothesis reference sentence . additionally , source sentence propose method confirm improve evaluation performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 8, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Resources and Evaluation,A Corpus for Large-Scale Phonetic Typology,"A major hurdle in data-driven research on typology is having sufficient data in many languages to draw meaningful conclusions. We present VoxClamantis V1.0, the first largescale corpus for phonetic typology, with aligned segments and estimated phonemelevel labels in 690 readings spanning 635 languages, along with acoustic-phonetic measures of vowels and sibilants. Access to such data can greatly facilitate investigation of phonetic typology at a large scale and across many languages. However, it is nontrivial and computationally intensive to obtain such alignments for hundreds of languages, many of which have few to no resources presently available. We describe the methodology to create our corpus, discuss caveats with current methods and their impact on the utility of this data, and illustrate possible research directions through a series of case studies on the 48 highest-quality readings. Our corpus and scripts are publicly available for non-commercial use at https:// voxclamantisproject.github.io.","A Corpus for Large-Scale Phonetic Typology A major hurdle in data-driven research on typology is having sufficient data in many languages to draw meaningful conclusions. We present VoxClamantis V1.0, the first largescale corpus for phonetic typology, with aligned segments and estimated phonemelevel labels in 690 readings spanning 635 languages, along with acoustic-phonetic measures of vowels and sibilants. Access to such data can greatly facilitate investigation of phonetic typology at a large scale and across many languages. However, it is nontrivial and computationally intensive to obtain such alignments for hundreds of languages, many of which have few to no resources presently available. We describe the methodology to create our corpus, discuss caveats with current methods and their impact on the utility of this data, and illustrate possible research directions through a series of case studies on the 48 highest-quality readings. Our corpus and scripts are publicly available for non-commercial use at https:// voxclamantisproject.github.io.","corpus large - scale phonetic typology major hurdle data - drive research typology have sufficient datum language draw meaningful conclusion . present voxclamantis v1.0 , largescale corpus phonetic typology , align segment estimate phonemelevel label 690 reading span 635 language , acoustic - phonetic measure vowel sibilant . access datum greatly facilitate investigation phonetic typology large scale language . , nontrivial computationally intensive obtain alignment hundred language , resource presently available . describe methodology create corpus , discuss caveat current method impact utility datum , illustrate possible research direction series case study 48 high - quality reading . corpus script publicly available non - commercial use https:// voxclamantisproject.github.io .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 2, 'Resources and Evaluation': 11, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 8, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,True
Resources and Evaluation,Not All Claims are Created Equal: Choosing the Right Statistical Approach to Assess Hypotheses,"Empirical research in Natural Language Processing (NLP) has adopted a narrow set of principles for assessing hypotheses, relying mainly on p-value computation, which suffers from several known issues. While alternative proposals have been well-debated and adopted in other fields, they remain rarely discussed or used within the NLP community. We address this gap by contrasting various hypothesis assessment techniques, especially those not commonly used in the field (such as evaluations based on Bayesian inference). Since these statistical techniques differ in the hypotheses they can support, we argue that practitioners should first decide their target hypothesis before choosing an assessment method. This is crucial because common fallacies, misconceptions, and misinterpretation surrounding hypothesis assessment methods often stem from a discrepancy between what one would like to claim versus what the method used actually assesses. Our survey reveals that these issues are omnipresent in the NLP research community. As a step forward, we provide best practices and guidelines tailored towards NLP research, as well as an easy-to-use package called HyBayes for Bayesian assessment of hypotheses, 1 complementing existing tools.","Not All Claims are Created Equal: Choosing the Right Statistical Approach to Assess Hypotheses Empirical research in Natural Language Processing (NLP) has adopted a narrow set of principles for assessing hypotheses, relying mainly on p-value computation, which suffers from several known issues. While alternative proposals have been well-debated and adopted in other fields, they remain rarely discussed or used within the NLP community. We address this gap by contrasting various hypothesis assessment techniques, especially those not commonly used in the field (such as evaluations based on Bayesian inference). Since these statistical techniques differ in the hypotheses they can support, we argue that practitioners should first decide their target hypothesis before choosing an assessment method. This is crucial because common fallacies, misconceptions, and misinterpretation surrounding hypothesis assessment methods often stem from a discrepancy between what one would like to claim versus what the method used actually assesses. Our survey reveals that these issues are omnipresent in the NLP research community. As a step forward, we provide best practices and guidelines tailored towards NLP research, as well as an easy-to-use package called HyBayes for Bayesian assessment of hypotheses, 1 complementing existing tools.","claim create equal : choose right statistical approach assess hypothesis empirical research natural language processing ( nlp ) adopt narrow set principle assess hypothesis , rely mainly p - value computation , suffer know issue . alternative proposal - debate adopt field , remain rarely discuss nlp community . address gap contrast hypothesis assessment technique , especially commonly field ( evaluation base bayesian inference ) . statistical technique differ hypothesis support , argue practitioner decide target hypothesis choose assessment method . crucial common fallacy , misconception , misinterpretation surround hypothesis assessment method stem discrepancy like claim versus method actually assess . survey reveal issue omnipresent nlp research community . step forward , provide good practice guideline tailor nlp research , easy - - use package call hybayes bayesian assessment hypothesis , 1 complement exist tool .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,False
Resources and Evaluation,Multi-Hypothesis Machine Translation Evaluation,"Reliably evaluating Machine Translation (MT) through automated metrics is a long-standing problem. One of the main challenges is the fact that multiple outputs can be equally valid. Attempts to minimise this issue include metrics that relax the matching of MT output and reference strings, and the use of multiple references. The latter has been shown to significantly improve the performance of evaluation metrics. However, collecting multiple references is expensive and in practice a single reference is generally used. In this paper, we propose an alternative approach: instead of modelling linguistic variation in human reference we exploit the MT model uncertainty to generate multiple diverse translations and use these: (i) as surrogates to reference translations; (ii) to obtain a quantification of translation variability to either complement existing metric scores or (iii) replace references altogether. We show that for a number of popular evaluation metrics our variability estimates lead to substantial improvements in correlation with human judgements of quality by up 15%.","Multi-Hypothesis Machine Translation Evaluation Reliably evaluating Machine Translation (MT) through automated metrics is a long-standing problem. One of the main challenges is the fact that multiple outputs can be equally valid. Attempts to minimise this issue include metrics that relax the matching of MT output and reference strings, and the use of multiple references. The latter has been shown to significantly improve the performance of evaluation metrics. However, collecting multiple references is expensive and in practice a single reference is generally used. In this paper, we propose an alternative approach: instead of modelling linguistic variation in human reference we exploit the MT model uncertainty to generate multiple diverse translations and use these: (i) as surrogates to reference translations; (ii) to obtain a quantification of translation variability to either complement existing metric scores or (iii) replace references altogether. We show that for a number of popular evaluation metrics our variability estimates lead to substantial improvements in correlation with human judgements of quality by up 15%.","multi - hypothesis machine translation evaluation reliably evaluate machine translation ( mt ) automate metric long - stand problem . main challenge fact multiple output equally valid . attempt minimise issue include metric relax matching mt output reference string , use multiple reference . show significantly improve performance evaluation metric . , collect multiple reference expensive practice single reference generally . paper , propose alternative approach : instead model linguistic variation human reference exploit mt model uncertainty generate multiple diverse translation use : ( ) surrogate reference translation ; ( ii ) obtain quantification translation variability complement exist metric score ( iii ) replace reference altogether . number popular evaluation metric variability estimate lead substantial improvement correlation human judgement quality 15 % .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 15, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,True
Resources and Evaluation,An Effectiveness Metric for Ordinal Classification: Formal Properties and Experimental Results,"In Ordinal Classification tasks, items have to be assigned to classes that have a relative ordering, such as positive, neutral, negative in sentiment analysis. Remarkably, the most popular evaluation metrics for ordinal classification tasks either ignore relevant information (for instance, precision/recall on each of the classes ignores their relative ordering) or assume additional information (for instance, Mean Average Error assumes absolute distances between classes). In this paper we propose a new metric for Ordinal Classification, Closeness Evaluation Measure, that is rooted on Measurement Theory and Information Theory. Our theoretical analysis and experimental results over both synthetic data and data from NLP shared tasks indicate that the proposed metric captures quality aspects from different traditional tasks simultaneously. In addition, it generalizes some popular classification (nominal scale) and error minimization (interval scale) metrics, depending on the measurement scale in which it is instantiated.","An Effectiveness Metric for Ordinal Classification: Formal Properties and Experimental Results In Ordinal Classification tasks, items have to be assigned to classes that have a relative ordering, such as positive, neutral, negative in sentiment analysis. Remarkably, the most popular evaluation metrics for ordinal classification tasks either ignore relevant information (for instance, precision/recall on each of the classes ignores their relative ordering) or assume additional information (for instance, Mean Average Error assumes absolute distances between classes). In this paper we propose a new metric for Ordinal Classification, Closeness Evaluation Measure, that is rooted on Measurement Theory and Information Theory. Our theoretical analysis and experimental results over both synthetic data and data from NLP shared tasks indicate that the proposed metric captures quality aspects from different traditional tasks simultaneously. In addition, it generalizes some popular classification (nominal scale) and error minimization (interval scale) metrics, depending on the measurement scale in which it is instantiated.","effectiveness metric ordinal classification : formal property experimental result ordinal classification task , item assign class relative ordering , positive , neutral , negative sentiment analysis . remarkably , popular evaluation metric ordinal classification task ignore relevant information ( instance , precision / recall class ignore relative ordering ) assume additional information ( instance , mean average error assume absolute distance class ) . paper propose new metric ordinal classification , closeness evaluation measure , root measurement theory information theory . theoretical analysis experimental result synthetic datum datum nlp share task indicate propose metric capture quality aspect different traditional task simultaneously . addition , generalize popular classification ( nominal scale ) error minimization ( interval scale ) metric , depend measurement scale instantiate .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Resources and Evaluation,True
Resources and Evaluation,That is a Known Lie: Detecting Previously Fact-Checked Claims,"The recent proliferation of ""fake news"" has triggered a number of responses, most notably the emergence of several manual fact-checking initiatives. As a result and over time, a large number of fact-checked claims have been accumulated, which increases the likelihood that a new claim in social media or a new statement by a politician might have already been factchecked by some trusted fact-checking organization, as viral claims often come back after a while in social media, and politicians like to repeat their favorite statements, true or false, over and over again. As manual fact-checking is very time-consuming (and fully automatic fact-checking has credibility issues), it is important to try to save this effort and to avoid wasting time on claims that have already been fact-checked. Interestingly, despite the importance of the task, it has been largely ignored by the research community so far. Here, we aim to bridge this gap. In particular, we formulate the task and we discuss how it relates to, but also differs from, previous work. We further create a specialized dataset, which we release to the research community. Finally, we present learning-to-rank experiments that demonstrate sizable improvements over state-of-the-art retrieval and textual similarity approaches.","That is a Known Lie: Detecting Previously Fact-Checked Claims The recent proliferation of ""fake news"" has triggered a number of responses, most notably the emergence of several manual fact-checking initiatives. As a result and over time, a large number of fact-checked claims have been accumulated, which increases the likelihood that a new claim in social media or a new statement by a politician might have already been factchecked by some trusted fact-checking organization, as viral claims often come back after a while in social media, and politicians like to repeat their favorite statements, true or false, over and over again. As manual fact-checking is very time-consuming (and fully automatic fact-checking has credibility issues), it is important to try to save this effort and to avoid wasting time on claims that have already been fact-checked. Interestingly, despite the importance of the task, it has been largely ignored by the research community so far. Here, we aim to bridge this gap. In particular, we formulate the task and we discuss how it relates to, but also differs from, previous work. We further create a specialized dataset, which we release to the research community. Finally, we present learning-to-rank experiments that demonstrate sizable improvements over state-of-the-art retrieval and textual similarity approaches.","known lie : detect previously fact - check claim recent proliferation "" fake news "" trigger number response , notably emergence manual fact - checking initiative . result time , large number fact - check claim accumulate , increase likelihood new claim social medium new statement politician factchecke trusted fact - check organization , viral claim come social medium , politician like repeat favorite statement , true false , . manual fact - checking time - consume ( fully automatic fact - checking credibility issue ) , important try save effort avoid waste time claim fact - check . interestingly , despite importance task , largely ignore research community far . , aim bridge gap . particular , formulate task discuss relate , differ , previous work . create specialized dataset , release research community . finally , present learn - - rank experiment demonstrate sizable improvement state - - - art retrieval textual similarity approach .","{'Computational Social Science and Social Media': 11, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Resources and Evaluation,PuzzLing Machines: A Challenge on Learning From Small Data,"Deep neural models have repeatedly proved excellent at memorizing surface patterns from large datasets for various ML and NLP benchmarks. They struggle to achieve human-like thinking, however, because they lack the skill of iterative reasoning upon knowledge. To expose this problem in a new light, we introduce a challenge on learning from small data, PuzzLing Machines, which consists of Rosetta Stone puzzles from Linguistic Olympiads for high school students. These puzzles are carefully designed to contain only the minimal amount of parallel text necessary to deduce the form of unseen expressions. Solving them does not require external information (e.g., knowledge bases, visual signals) or linguistic expertise, but meta-linguistic awareness and deductive skills. Our challenge contains around 100 puzzles covering a wide range of linguistic phenomena from 81 languages. We show that both simple statistical algorithms and state-of-the-art deep neural models perform inadequately on this challenge, as expected. We hope that this benchmark, available at https://ukplab.github.io/ PuzzLing-Machines/, inspires further efforts towards a new paradigm in NLP-one that is grounded in human-like reasoning and understanding.","PuzzLing Machines: A Challenge on Learning From Small Data Deep neural models have repeatedly proved excellent at memorizing surface patterns from large datasets for various ML and NLP benchmarks. They struggle to achieve human-like thinking, however, because they lack the skill of iterative reasoning upon knowledge. To expose this problem in a new light, we introduce a challenge on learning from small data, PuzzLing Machines, which consists of Rosetta Stone puzzles from Linguistic Olympiads for high school students. These puzzles are carefully designed to contain only the minimal amount of parallel text necessary to deduce the form of unseen expressions. Solving them does not require external information (e.g., knowledge bases, visual signals) or linguistic expertise, but meta-linguistic awareness and deductive skills. Our challenge contains around 100 puzzles covering a wide range of linguistic phenomena from 81 languages. We show that both simple statistical algorithms and state-of-the-art deep neural models perform inadequately on this challenge, as expected. We hope that this benchmark, available at https://ukplab.github.io/ PuzzLing-Machines/, inspires further efforts towards a new paradigm in NLP-one that is grounded in human-like reasoning and understanding.","puzzling machines : challenge learn small datum deep neural model repeatedly prove excellent memorize surface pattern large dataset ml nlp benchmark . struggle achieve human - like thinking , , lack skill iterative reasoning knowledge . expose problem new light , introduce challenge learn small datum , puzzling machines , consist rosetta stone puzzle linguistic olympiads high school student . puzzle carefully design contain minimal parallel text necessary deduce form unseen expression . solve require external information ( e.g. , knowledge basis , visual signal ) linguistic expertise , meta - linguistic awareness deductive skill . challenge contain 100 puzzle cover wide range linguistic phenomenon 81 language . simple statistical algorithm state - - - art deep neural model perform inadequately challenge , expect . hope benchmark , available https://ukplab.github.io/ puzzling - machines/ , inspire effort new paradigm nlp - ground human - like reasoning understanding .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Resources and Evaluation,Multimodal Quality Estimation for Machine Translation,"We propose approaches to Quality Estimation (QE) for Machine Translation that explore both text and visual modalities for Multimodal QE. We compare various multimodality integration and fusion strategies. For both sentence-level and document-level predictions, we show that state-of-the-art neural and feature-based QE frameworks obtain better results when using the additional modality.","Multimodal Quality Estimation for Machine Translation We propose approaches to Quality Estimation (QE) for Machine Translation that explore both text and visual modalities for Multimodal QE. We compare various multimodality integration and fusion strategies. For both sentence-level and document-level predictions, we show that state-of-the-art neural and feature-based QE frameworks obtain better results when using the additional modality.","multimodal quality estimation machine translation propose approach quality estimation ( qe ) machine translation explore text visual modality multimodal qe . compare multimodality integration fusion strategy . sentence - level document - level prediction , state - - - art neural feature - base qe framework obtain well result additional modality .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Resources and Evaluation,A Recipe for Creating Multimodal Aligned Datasets for Sequential Tasks,"Many high-level procedural tasks can be decomposed into sequences of instructions that vary in their order and choice of tools. In the cooking domain, the web offers many partially-overlapping text and video recipes (i.e. procedures) that describe how to make the same dish (i.e. high-level task). Aligning instructions for the same dish across different sources can yield descriptive visual explanations that are far richer semantically than conventional textual instructions, providing commonsense insight into how real-world procedures are structured. Learning to align these different instruction sets is challenging because: a) different recipes vary in their order of instructions and use of ingredients; and b) video instructions can be noisy and tend to contain far more information than text instructions. To address these challenges, we first use an unsupervised alignment algorithm that learns pairwise alignments between instructions of different recipes for the same dish. We then use a graph algorithm to derive a joint alignment between multiple text and multiple video recipes for the same dish. We release the MICROSOFT RESEARCH MUL-TIMODAL ALIGNED RECIPE CORPUS 1 containing âˆ¼150K pairwise alignments between recipes across 4,262 dishes with rich commonsense information. * Work done when the author was an intern at Microsoft. 1 https://github.com/microsoft/ multimodal-aligned-recipe-corpus 7. Add 12 ounces of thawed peas and bean sprouts. 3. Add onion, garlic, peas and carrots. 4. Transfer shrimp to the hot skillet and cook them one minute per side. 4. Stir fry until tender. 1. Hi everyone. Today we're making shrimp fried rice, a family favorite.","A Recipe for Creating Multimodal Aligned Datasets for Sequential Tasks Many high-level procedural tasks can be decomposed into sequences of instructions that vary in their order and choice of tools. In the cooking domain, the web offers many partially-overlapping text and video recipes (i.e. procedures) that describe how to make the same dish (i.e. high-level task). Aligning instructions for the same dish across different sources can yield descriptive visual explanations that are far richer semantically than conventional textual instructions, providing commonsense insight into how real-world procedures are structured. Learning to align these different instruction sets is challenging because: a) different recipes vary in their order of instructions and use of ingredients; and b) video instructions can be noisy and tend to contain far more information than text instructions. To address these challenges, we first use an unsupervised alignment algorithm that learns pairwise alignments between instructions of different recipes for the same dish. We then use a graph algorithm to derive a joint alignment between multiple text and multiple video recipes for the same dish. We release the MICROSOFT RESEARCH MUL-TIMODAL ALIGNED RECIPE CORPUS 1 containing âˆ¼150K pairwise alignments between recipes across 4,262 dishes with rich commonsense information. * Work done when the author was an intern at Microsoft. 1 https://github.com/microsoft/ multimodal-aligned-recipe-corpus 7. Add 12 ounces of thawed peas and bean sprouts. 3. Add onion, garlic, peas and carrots. 4. Transfer shrimp to the hot skillet and cook them one minute per side. 4. Stir fry until tender. 1. Hi everyone. Today we're making shrimp fried rice, a family favorite.","recipe create multimodal align dataset sequential task high - level procedural task decompose sequence instruction vary order choice tool . cooking domain , web offer partially - overlap text video recipe ( i.e. procedure ) describe dish ( i.e. high - level task ) . align instruction dish different source yield descriptive visual explanation far rich semantically conventional textual instruction , provide commonsense insight real - world procedure structure . learn align different instruction set challenging : ) different recipe vary order instruction use ingredient ; b ) video instruction noisy tend contain far information text instruction . address challenge , use unsupervised alignment algorithm learn pairwise alignment instruction different recipe dish . use graph algorithm derive joint alignment multiple text multiple video recipe dish . release microsoft research mul - timodal aligned recipe corpus 1 contain âˆ¼150 k pairwise alignment recipe 4,262 dish rich commonsense information . * work author intern microsoft . 1 https://github.com/microsoft/ multimodal - aligned - recipe - corpus 7 . add 12 ounce thaw pea bean sprout . 3 . add onion , garlic , pea carrot . 4 . transfer shrimp hot skillet cook minute . 4 . stir fry tender . 1 . hi . today make shrimp fry rice , family favorite .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 12, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 19, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,True
Resources and Evaluation,Building a User-Generated Content North-African Arabizi Treebank: Tackling Hell,"We introduce the first treebank for a romanized user-generated content variety of Algerian, a North-African Arabic dialect known for its frequent usage of code-switching. Made of 1500 sentences, fully annotated in morpho-syntax and Universal Dependency syntax, with full translation at both the word and the sentence levels, this treebank is made freely available. It is supplemented with 50k unlabeled sentences collected from Common Crawl and webcrawled data using intensive data-mining techniques. Preliminary experiments demonstrate its usefulness for POS tagging and dependency parsing. We believe that what we present in this paper is useful beyond the low-resource language community. This is the first time that enough unlabeled and annotated data is provided for an emerging user-generated content dialectal language with rich morphology and code switching, making it an challenging testbed for most recent NLP approaches.","Building a User-Generated Content North-African Arabizi Treebank: Tackling Hell We introduce the first treebank for a romanized user-generated content variety of Algerian, a North-African Arabic dialect known for its frequent usage of code-switching. Made of 1500 sentences, fully annotated in morpho-syntax and Universal Dependency syntax, with full translation at both the word and the sentence levels, this treebank is made freely available. It is supplemented with 50k unlabeled sentences collected from Common Crawl and webcrawled data using intensive data-mining techniques. Preliminary experiments demonstrate its usefulness for POS tagging and dependency parsing. We believe that what we present in this paper is useful beyond the low-resource language community. This is the first time that enough unlabeled and annotated data is provided for an emerging user-generated content dialectal language with rich morphology and code switching, making it an challenging testbed for most recent NLP approaches.","build user - generate content north - african arabizi treebank : tackle hell introduce treebank romanize user - generate content variety algerian , north - african arabic dialect know frequent usage code - switching . 1500 sentence , fully annotate morpho - syntax universal dependency syntax , translation word sentence level , treebank freely available . supplement 50k unlabeled sentence collect common crawl webcrawle datum intensive data - mining technique . preliminary experiment demonstrate usefulness pos tagging dependency parsing . believe present paper useful low - resource language community . time unlabeled annotate datum provide emerge user - generate content dialectal language rich morphology code switching , make challenging testbed recent nlp approach .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}","Syntax: Tagging, Chunking and Parsing",False
Resources and Evaluation,The SOFC-Exp Corpus and Neural Approaches to Information Extraction in the Materials Science Domain,"This paper presents a new challenging information extraction task in the domain of materials science. We develop an annotation scheme for marking information on experiments related to solid oxide fuel cells in scientific publications, such as involved materials and measurement conditions. With this paper, we publish our annotation guidelines, as well as our SOFC-Exp corpus consisting of 45 openaccess scholarly articles annotated by domain experts. A corpus and an inter-annotator agreement study demonstrate the complexity of the suggested named entity recognition and slot filling tasks as well as high annotation quality. We also present strong neural-network based models for a variety of tasks that can be addressed on the basis of our new data set. On all tasks, using BERT embeddings leads to large performance gains, but with increasing task complexity, adding a recurrent neural network on top seems beneficial. Our models will serve as competitive baselines in future work, and analysis of their performance highlights difficult cases when modeling the data and suggests promising research directions.","The SOFC-Exp Corpus and Neural Approaches to Information Extraction in the Materials Science Domain This paper presents a new challenging information extraction task in the domain of materials science. We develop an annotation scheme for marking information on experiments related to solid oxide fuel cells in scientific publications, such as involved materials and measurement conditions. With this paper, we publish our annotation guidelines, as well as our SOFC-Exp corpus consisting of 45 openaccess scholarly articles annotated by domain experts. A corpus and an inter-annotator agreement study demonstrate the complexity of the suggested named entity recognition and slot filling tasks as well as high annotation quality. We also present strong neural-network based models for a variety of tasks that can be addressed on the basis of our new data set. On all tasks, using BERT embeddings leads to large performance gains, but with increasing task complexity, adding a recurrent neural network on top seems beneficial. Our models will serve as competitive baselines in future work, and analysis of their performance highlights difficult cases when modeling the data and suggests promising research directions.","sofc - exp corpus neural approach information extraction material science domain paper present new challenging information extraction task domain material science . develop annotation scheme mark information experiment relate solid oxide fuel cell scientific publication , involved material measurement condition . paper , publish annotation guideline , sofc - exp corpus consist 45 openaccess scholarly article annotate domain expert . corpus inter - annotator agreement study demonstrate complexity suggest name entity recognition slot filling task high annotation quality . present strong neural - network base model variety task address basis new data set . task , bert embedding lead large performance gain , increase task complexity , add recurrent neural network beneficial . model serve competitive baseline future work , analysis performance highlight difficult case model datum suggest promising research direction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Resources and Evaluation,Facet-Aware Evaluation for Extractive Summarization,"Commonly adopted metrics for extractive summarization focus on lexical overlap at the token level. In this paper, we present a facetaware evaluation setup for better assessment of the information coverage in extracted summaries. Specifically, we treat each sentence in the reference summary as a facet, identify the sentences in the document that express the semantics of each facet as support sentences of the facet, and automatically evaluate extractive summarization methods by comparing the indices of extracted sentences and support sentences of all the facets in the reference summary. To facilitate this new evaluation setup, we construct an extractive version of the CNN/Daily Mail dataset and perform a thorough quantitative investigation, through which we demonstrate that facet-aware evaluation manifests better correlation with human judgment than ROUGE, enables fine-grained evaluation as well as comparative analysis, and reveals valuable insights of state-of-the-art summarization methods. 1 Reference: Three people in Kansas have died from a listeria outbreak. Lexical Overlap: But they did not appear identical to listeria samples taken from patients infected in the Kansas outbreak. (ROUGE-1 F1=37.0, multiple token matches but totally different semantics) Manual Extract: Five people were infected and three died in the past year in Kansas from listeria that might be linked to blue bell creameries products, according to the CDC. (ROUGE-1 F1=36.9, semantics covered but lower ROUGE due to the presence of other details) Reference: Chelsea boss Jose Mourinho and United manager Louis van Gaal are pals. Lexical Overlap: Gary Neville believes Louis van Gaal's greatest achievement as a football manager is the making of Jose Mourinho. Manual Extract: The duo have been friends since they first worked together at Barcelona in 1997 where they enjoyed a successful relationship at the Camp Nou. (ROUGE Recall/F1=0, no lexical overlap at all)","Facet-Aware Evaluation for Extractive Summarization Commonly adopted metrics for extractive summarization focus on lexical overlap at the token level. In this paper, we present a facetaware evaluation setup for better assessment of the information coverage in extracted summaries. Specifically, we treat each sentence in the reference summary as a facet, identify the sentences in the document that express the semantics of each facet as support sentences of the facet, and automatically evaluate extractive summarization methods by comparing the indices of extracted sentences and support sentences of all the facets in the reference summary. To facilitate this new evaluation setup, we construct an extractive version of the CNN/Daily Mail dataset and perform a thorough quantitative investigation, through which we demonstrate that facet-aware evaluation manifests better correlation with human judgment than ROUGE, enables fine-grained evaluation as well as comparative analysis, and reveals valuable insights of state-of-the-art summarization methods. 1 Reference: Three people in Kansas have died from a listeria outbreak. Lexical Overlap: But they did not appear identical to listeria samples taken from patients infected in the Kansas outbreak. (ROUGE-1 F1=37.0, multiple token matches but totally different semantics) Manual Extract: Five people were infected and three died in the past year in Kansas from listeria that might be linked to blue bell creameries products, according to the CDC. (ROUGE-1 F1=36.9, semantics covered but lower ROUGE due to the presence of other details) Reference: Chelsea boss Jose Mourinho and United manager Louis van Gaal are pals. Lexical Overlap: Gary Neville believes Louis van Gaal's greatest achievement as a football manager is the making of Jose Mourinho. Manual Extract: The duo have been friends since they first worked together at Barcelona in 1997 where they enjoyed a successful relationship at the Camp Nou. (ROUGE Recall/F1=0, no lexical overlap at all)","facet - aware evaluation extractive summarization commonly adopt metric extractive summarization focus lexical overlap token level . paper , present facetaware evaluation setup well assessment information coverage extract summary . specifically , treat sentence reference summary facet , identify sentence document express semantic facet support sentence facet , automatically evaluate extractive summarization method compare index extract sentence support sentence facet reference summary . facilitate new evaluation setup , construct extractive version cnn / daily mail dataset perform thorough quantitative investigation , demonstrate facet - aware evaluation manifest well correlation human judgment rouge , enable fine - grained evaluation comparative analysis , reveal valuable insight state - - - art summarization method . 1 reference : people kansas die listeria outbreak . lexical overlap : appear identical listeria sample take patient infect kansas outbreak . ( rouge-1 f1=37.0 , multiple token match totally different semantic ) manual extract : people infect die past year kansas listeria link blue bell creamery product , accord cdc . ( rouge-1 f1=36.9 , semantic cover low rouge presence detail ) reference : chelsea boss jose mourinho united manager louis van gaal pal . lexical overlap : gary neville believe louis van gaal great achievement football manager making jose mourinho . manual extract : duo friend work barcelona 1997 enjoy successful relationship camp nou . ( rouge recall / f1=0 , lexical overlap )","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 12, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,False
Resources and Evaluation,ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations,"In order to simplify a sentence, human editors perform multiple rewriting transformations: they split it into several shorter sentences, paraphrase words (i.e. replacing complex words or phrases by simpler synonyms), reorder components, and/or delete information deemed unnecessary. Despite these varied range of possible text alterations, current models for automatic sentence simplification are evaluated using datasets that are focused on a single transformation, such as lexical paraphrasing or splitting. This makes it impossible to understand the ability of simplification models in more realistic settings. To alleviate this limitation, this paper introduces ASSET, a new dataset for assessing sentence simplification in English. ASSET is a crowdsourced multi-reference corpus where each simplification was produced by executing several rewriting transformations. Through quantitative and qualitative experiments, we show that simplifications in ASSET are better at capturing characteristics of simplicity when compared to other standard evaluation datasets for the task. Furthermore, we motivate the need for developing better methods for automatic evaluation using ASSET, since we show that current popular metrics may not be suitable when multiple simplification transformations are performed.","ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations In order to simplify a sentence, human editors perform multiple rewriting transformations: they split it into several shorter sentences, paraphrase words (i.e. replacing complex words or phrases by simpler synonyms), reorder components, and/or delete information deemed unnecessary. Despite these varied range of possible text alterations, current models for automatic sentence simplification are evaluated using datasets that are focused on a single transformation, such as lexical paraphrasing or splitting. This makes it impossible to understand the ability of simplification models in more realistic settings. To alleviate this limitation, this paper introduces ASSET, a new dataset for assessing sentence simplification in English. ASSET is a crowdsourced multi-reference corpus where each simplification was produced by executing several rewriting transformations. Through quantitative and qualitative experiments, we show that simplifications in ASSET are better at capturing characteristics of simplicity when compared to other standard evaluation datasets for the task. Furthermore, we motivate the need for developing better methods for automatic evaluation using ASSET, since we show that current popular metrics may not be suitable when multiple simplification transformations are performed.","asset : dataset tune evaluation sentence simplification model multiple rewriting transformation order simplify sentence , human editor perform multiple rewriting transformation : split short sentence , paraphrase word ( i.e. replace complex word phrase simple synonym ) , reorder component , and/or delete information deem unnecessary . despite varied range possible text alteration , current model automatic sentence simplification evaluate dataset focus single transformation , lexical paraphrasing splitting . make impossible understand ability simplification model realistic setting . alleviate limitation , paper introduce asset , new dataset assess sentence simplification english . asset crowdsource multi - reference corpus simplification produce execute rewriting transformation . quantitative qualitative experiment , simplification asset well capture characteristic simplicity compare standard evaluation dataset task . furthermore , motivate need develop well method automatic evaluation asset , current popular metric suitable multiple simplification transformation perform .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 9, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Resources and Evaluation,MIND: A Large-scale Dataset for News Recommendation,"News recommendation is an important technique for personalized news service. Compared with product and movie recommendations which have been comprehensively studied, the research on news recommendation is much more limited, mainly due to the lack of a high-quality benchmark dataset. In this paper, we present a large-scale dataset named MIND for news recommendation. Constructed from the user click logs of Microsoft News, MIND contains 1 million users and more than 160k English news articles, each of which has rich textual content such as title, abstract and body. We demonstrate MIND a good testbed for news recommendation through a comparative study of several state-of-the-art news recommendation methods which are originally developed on different proprietary datasets. Our results show the performance of news recommendation highly relies on the quality of news content understanding and user interest modeling. Many natural language processing techniques such as effective text representation methods and pre-trained language models can effectively improve the performance of news recommendation. The MIND dataset will be available at https://msnews.github.io.","MIND: A Large-scale Dataset for News Recommendation News recommendation is an important technique for personalized news service. Compared with product and movie recommendations which have been comprehensively studied, the research on news recommendation is much more limited, mainly due to the lack of a high-quality benchmark dataset. In this paper, we present a large-scale dataset named MIND for news recommendation. Constructed from the user click logs of Microsoft News, MIND contains 1 million users and more than 160k English news articles, each of which has rich textual content such as title, abstract and body. We demonstrate MIND a good testbed for news recommendation through a comparative study of several state-of-the-art news recommendation methods which are originally developed on different proprietary datasets. Our results show the performance of news recommendation highly relies on the quality of news content understanding and user interest modeling. Many natural language processing techniques such as effective text representation methods and pre-trained language models can effectively improve the performance of news recommendation. The MIND dataset will be available at https://msnews.github.io.","mind : large - scale dataset news recommendation news recommendation important technique personalize news service . compare product movie recommendation comprehensively study , research news recommendation limited , mainly lack high - quality benchmark dataset . paper , present large - scale dataset name mind news recommendation . construct user click log microsoft news , mind contain 1 million user 160k english news article , rich textual content title , abstract body . demonstrate mind good testbed news recommendation comparative study state - - - art news recommendation method originally develop different proprietary dataset . result performance news recommendation highly rely quality news content understanding user interest modeling . natural language processing technique effective text representation method pre - trained language model effectively improve performance news recommendation . mind dataset available https://msnews.github.io .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 33, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 9, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Resources and Evaluation,"Fatality Killed the Cat or: BabelPic, a Multimodal Dataset for Non-Concrete Concepts","Thanks to the wealth of high-quality annotated images available in popular repositories such as ImageNet, multimodal language-vision research is in full bloom. However, events, feelings and many other kinds of concepts which can be visually grounded are not well represented in current datasets. Nevertheless, we would expect a wide-coverage language understanding system to be able to classify images depicting RECESS and REMORSE, not just CATS, DOGS and BRIDGES. We fill this gap by presenting BabelPic, a hand-labeled dataset built by cleaning the image-synset association found within the BabelNet Lexical Knowledge Base (LKB). BabelPic explicitly targets nonconcrete concepts, thus providing refreshing new data for the community. We also show that pre-trained language-vision systems can be used to further expand the resource by exploiting natural language knowledge available in the LKB. BabelPic is available for download at http://babelpic.org.","Fatality Killed the Cat or: BabelPic, a Multimodal Dataset for Non-Concrete Concepts Thanks to the wealth of high-quality annotated images available in popular repositories such as ImageNet, multimodal language-vision research is in full bloom. However, events, feelings and many other kinds of concepts which can be visually grounded are not well represented in current datasets. Nevertheless, we would expect a wide-coverage language understanding system to be able to classify images depicting RECESS and REMORSE, not just CATS, DOGS and BRIDGES. We fill this gap by presenting BabelPic, a hand-labeled dataset built by cleaning the image-synset association found within the BabelNet Lexical Knowledge Base (LKB). BabelPic explicitly targets nonconcrete concepts, thus providing refreshing new data for the community. We also show that pre-trained language-vision systems can be used to further expand the resource by exploiting natural language knowledge available in the LKB. BabelPic is available for download at http://babelpic.org.","fatality kill cat : babelpic , multimodal dataset non - concrete concept thank wealth high - quality annotate image available popular repository imagenet , multimodal language - vision research bloom . , event , feeling kind concept visually ground represent current dataset . , expect wide - coverage language understanding system able classify image depict recess remorse , cat , dog bridge . fill gap present babelpic , hand - label dataset build clean image - synset association find babelnet lexical knowledge base ( lkb ) . babelpic explicitly target nonconcrete concept , provide refreshing new datum community . pre - trained language - vision system expand resource exploit natural language knowledge available lkb . babelpic available download http://babelpic.org .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Resources and Evaluation,S2ORC: The Semantic Scholar Open Research Corpus,"We introduce S2ORC, 1 a large corpus of 81.1M English-language academic papers spanning many academic disciplines. The corpus consists of rich metadata, paper abstracts, resolved bibliographic references, as well as structured full text for 8.1M open access papers. Full text is annotated with automaticallydetected inline mentions of citations, figures, and tables, each linked to their corresponding paper objects. In S2ORC, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. We hope this resource will facilitate research and development of tools and tasks for text mining over academic text. * denotes equal contribution 1 Instructions for access to the data and model are available at https://github.com/allenai/s2orc/.","S2ORC: The Semantic Scholar Open Research Corpus We introduce S2ORC, 1 a large corpus of 81.1M English-language academic papers spanning many academic disciplines. The corpus consists of rich metadata, paper abstracts, resolved bibliographic references, as well as structured full text for 8.1M open access papers. Full text is annotated with automaticallydetected inline mentions of citations, figures, and tables, each linked to their corresponding paper objects. In S2ORC, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. We hope this resource will facilitate research and development of tools and tasks for text mining over academic text. * denotes equal contribution 1 Instructions for access to the data and model are available at https://github.com/allenai/s2orc/.","s2orc : semantic scholar open research corpus introduce s2orc , 1 large corpus 81.1 m english - language academic paper span academic discipline . corpus consist rich metadata , paper abstract , resolve bibliographic reference , structured text 8.1 m open access paper . text annotate automaticallydetecte inline mention citation , figure , table , link correspond paper object . s2orc , aggregate paper hundred academic publisher digital archive unified source , create large publicly - available collection machine - readable academic text date . hope resource facilitate research development tool task text mining academic text . * denote equal contribution 1 instruction access datum model available https://github.com/allenai/s2orc/.","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 9, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,True
Resources and Evaluation,Crawling and Preprocessing Mailing Lists At Scale for Dialog Analysis,"This paper introduces the Webis Gmane Email Corpus 2019, the largest publicly available and fully preprocessed email corpus to date. We crawled more than 153 million emails from 14,699 mailing lists and segmented them into semantically consistent components using a new neural segmentation model. With 96% accuracy on 15 classes of email segments, our model achieves state-of-the-art performance while being more efficient to train than previous ones. All data, code, and trained models are made freely available alongside the paper. 1","Crawling and Preprocessing Mailing Lists At Scale for Dialog Analysis This paper introduces the Webis Gmane Email Corpus 2019, the largest publicly available and fully preprocessed email corpus to date. We crawled more than 153 million emails from 14,699 mailing lists and segmented them into semantically consistent components using a new neural segmentation model. With 96% accuracy on 15 classes of email segments, our model achieves state-of-the-art performance while being more efficient to train than previous ones. All data, code, and trained models are made freely available alongside the paper. 1","crawl preprocesse mailing list scale dialog analysis paper introduce webis gmane email corpus 2019 , large publicly available fully preprocesse email corpus date . crawl 153 million email 14,699 mailing list segment semantically consistent component new neural segmentation model . 96 % accuracy 15 class email segment , model achieve state - - - art performance efficient train previous one . datum , code , train model freely available alongside paper . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,True
Semantics: Lexical Semantics,Hypernymy Detection for Low-Resource Languages via Meta Learning,"Hypernymy detection, a.k.a. lexical entailment, is a fundamental sub-task of many natural language understanding tasks. Previous explorations mostly focus on monolingual hypernymy detection on high-resource languages, e.g., English, but few investigate the lowresource scenarios. This paper addresses the problem of low-resource hypernymy detection by combining high-resource languages. We extensively compare three joint training paradigms and for the first time propose applying meta learning to relieve the low-resource issue. Experiments demonstrate the superiority of our method among the three settings, which substantially improves the performance of extremely low-resource languages by preventing over-fitting on small datasets.","Hypernymy Detection for Low-Resource Languages via Meta Learning Hypernymy detection, a.k.a. lexical entailment, is a fundamental sub-task of many natural language understanding tasks. Previous explorations mostly focus on monolingual hypernymy detection on high-resource languages, e.g., English, but few investigate the lowresource scenarios. This paper addresses the problem of low-resource hypernymy detection by combining high-resource languages. We extensively compare three joint training paradigms and for the first time propose applying meta learning to relieve the low-resource issue. Experiments demonstrate the superiority of our method among the three settings, which substantially improves the performance of extremely low-resource languages by preventing over-fitting on small datasets.","hypernymy detection low - resource language meta learning hypernymy detection , a.k.a . lexical entailment , fundamental sub - task natural language understanding task . previous exploration focus monolingual hypernymy detection high - resource language , e.g. , english , investigate lowresource scenario . paper address problem low - resource hypernymy detection combine high - resource language . extensively compare joint training paradigm time propose apply meta learning relieve low - resource issue . experiment demonstrate superiority method setting , substantially improve performance extremely low - resource language prevent - fitting small dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Non-Linear Instance-Based Cross-Lingual Mapping for Non-Isomorphic Embedding Spaces,"We present INSTAMAP, an instance-based method for learning projection-based crosslingual word embeddings. Unlike prior work, it deviates from learning a single global linear projection. INSTAMAP is a non-parametric model that learns a non-linear projection by iteratively: (1) finding a globally optimal rotation of the source embedding space relying on the Kabsch algorithm, and then (2) moving each point along an instance-specific translation vector estimated from the translation vectors of the point's nearest neighbours in the training dictionary. We report performance gains with INSTAMAP over four representative state-of-the-art projection-based models on bilingual lexicon induction across a set of 28 diverse language pairs. We note prominent improvements, especially for more distant language pairs (i.e., languages with nonisomorphic monolingual spaces).","Non-Linear Instance-Based Cross-Lingual Mapping for Non-Isomorphic Embedding Spaces We present INSTAMAP, an instance-based method for learning projection-based crosslingual word embeddings. Unlike prior work, it deviates from learning a single global linear projection. INSTAMAP is a non-parametric model that learns a non-linear projection by iteratively: (1) finding a globally optimal rotation of the source embedding space relying on the Kabsch algorithm, and then (2) moving each point along an instance-specific translation vector estimated from the translation vectors of the point's nearest neighbours in the training dictionary. We report performance gains with INSTAMAP over four representative state-of-the-art projection-based models on bilingual lexicon induction across a set of 28 diverse language pairs. We note prominent improvements, especially for more distant language pairs (i.e., languages with nonisomorphic monolingual spaces).","non - linear instance - base cross - lingual mapping non - isomorphic embedding space present instamap , instance - base method learn projection - base crosslingual word embedding . unlike prior work , deviate learn single global linear projection . instamap non - parametric model learn non - linear projection iteratively : ( 1 ) find globally optimal rotation source embedding space rely kabsch algorithm , ( 2 ) move point instance - specific translation vector estimate translation vector point near neighbour training dictionary . report performance gain instamap representative state - - - art projection - base model bilingual lexicon induction set 28 diverse language pair . note prominent improvement , especially distant language pair ( i.e. , language nonisomorphic monolingual space ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,Analysing Lexical Semantic Change with Contextualised Word Representations,"This paper presents the first unsupervised approach to lexical semantic change that makes use of contextualised word representations. We propose a novel method that exploits the BERT neural language model to obtain representations of word usages, clusters these representations into usage types, and measures change along time with three proposed metrics. We create a new evaluation dataset and show that the model representations and the detected semantic shifts are positively correlated with human judgements. Our extensive qualitative analysis demonstrates that our method captures a variety of synchronic and diachronic linguistic phenomena. We expect our work to inspire further research in this direction.","Analysing Lexical Semantic Change with Contextualised Word Representations This paper presents the first unsupervised approach to lexical semantic change that makes use of contextualised word representations. We propose a novel method that exploits the BERT neural language model to obtain representations of word usages, clusters these representations into usage types, and measures change along time with three proposed metrics. We create a new evaluation dataset and show that the model representations and the detected semantic shifts are positively correlated with human judgements. Our extensive qualitative analysis demonstrates that our method captures a variety of synchronic and diachronic linguistic phenomena. We expect our work to inspire further research in this direction.","analyse lexical semantic change contextualised word representation paper present unsupervised approach lexical semantic change make use contextualise word representation . propose novel method exploit bert neural language model obtain representation word usage , cluster representation usage type , measure change time propose metric . create new evaluation dataset model representation detect semantic shift positively correlate human judgement . extensive qualitative analysis demonstrate method capture variety synchronic diachronic linguistic phenomenon . expect work inspire research direction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,Autoencoding Pixies: Amortised Variational Inference with Graph Convolutions for Functional Distributional Semantics,"Functional Distributional Semantics provides a linguistically interpretable framework for distributional semantics, by representing the meaning of a word as a function (a binary classifier), instead of a vector. However, the large number of latent variables means that inference is computationally expensive, and training a model is therefore slow to converge. In this paper, I introduce the Pixie Autoencoder, which augments the generative model of Functional Distributional Semantics with a graphconvolutional neural network to perform amortised variational inference. This allows the model to be trained more effectively, achieving better results on two tasks (semantic similarity in context and semantic composition), and outperforming BERT, a large pre-trained language model.","Autoencoding Pixies: Amortised Variational Inference with Graph Convolutions for Functional Distributional Semantics Functional Distributional Semantics provides a linguistically interpretable framework for distributional semantics, by representing the meaning of a word as a function (a binary classifier), instead of a vector. However, the large number of latent variables means that inference is computationally expensive, and training a model is therefore slow to converge. In this paper, I introduce the Pixie Autoencoder, which augments the generative model of Functional Distributional Semantics with a graphconvolutional neural network to perform amortised variational inference. This allows the model to be trained more effectively, achieving better results on two tasks (semantic similarity in context and semantic composition), and outperforming BERT, a large pre-trained language model.","autoencoding pixie : amortise variational inference graph convolution functional distributional semantics functional distributional semantics provide linguistically interpretable framework distributional semantic , represent meaning word function ( binary classifier ) , instead vector . , large number latent variable mean inference computationally expensive , train model slow converge . paper , introduce pixie autoencoder , augment generative model functional distributional semantics graphconvolutional neural network perform amortised variational inference . allow model train effectively , achieve well result task ( semantic similarity context semantic composition ) , outperform bert , large pre - trained language model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 12, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Semantics: Lexical Semantics,Glyph2Vec: Learning Chinese Out-of-Vocabulary Word Embedding from Glyphs,"Chinese NLP applications that rely on large text often contain huge amounts of vocabulary which are sparse in corpus. We show that characters' written form, Glyphs, in ideographic languages could carry rich semantics. We present a multi-modal model, Glyph2Vec, to tackle Chinese out-of-vocabulary word embedding problem. Glyph2Vec extracts visual features from word glyphs to expand current word embedding space for out-of-vocabulary word embedding, without the need of accessing any corpus, which is useful for improving Chinese NLP systems, especially for lowresource scenarios. Experiments across different applications show the significant effectiveness of our model.","Glyph2Vec: Learning Chinese Out-of-Vocabulary Word Embedding from Glyphs Chinese NLP applications that rely on large text often contain huge amounts of vocabulary which are sparse in corpus. We show that characters' written form, Glyphs, in ideographic languages could carry rich semantics. We present a multi-modal model, Glyph2Vec, to tackle Chinese out-of-vocabulary word embedding problem. Glyph2Vec extracts visual features from word glyphs to expand current word embedding space for out-of-vocabulary word embedding, without the need of accessing any corpus, which is useful for improving Chinese NLP systems, especially for lowresource scenarios. Experiments across different applications show the significant effectiveness of our model.","glyph2vec : learn chinese - - vocabulary word embedding glyphs chinese nlp application rely large text contain huge amount vocabulary sparse corpus . character ' write form , glyphs , ideographic language carry rich semantic . present multi - modal model , glyph2vec , tackle chinese - - vocabulary word embedding problem . glyph2vec extract visual feature word glyph expand current word embedding space - - vocabulary word embedding , need access corpus , useful improve chinese nlp system , especially lowresource scenario . experiment different application significant effectiveness model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 9, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Predicting Degrees of Technicality in Automatic Terminology Extraction,"While automatic term extraction is a wellresearched area, computational approaches to distinguish between degrees of technicality are still understudied. We semi-automatically create a German gold standard of technicality across four domains, and illustrate the impact of a web-crawled general-language corpus on predicting technicality. When defining a classification approach that combines general-language and domain-specific word embeddings, we go beyond previous work and align vector spaces to gain comparative embeddings. We suggest two novel models to exploit general-vs. domain-specific comparisons: a simple neural network model with pre-computed comparative-embedding information as input, and a multi-channel model computing the comparison internally. Both models outperform previous approaches, with the multi-channel model performing best.","Predicting Degrees of Technicality in Automatic Terminology Extraction While automatic term extraction is a wellresearched area, computational approaches to distinguish between degrees of technicality are still understudied. We semi-automatically create a German gold standard of technicality across four domains, and illustrate the impact of a web-crawled general-language corpus on predicting technicality. When defining a classification approach that combines general-language and domain-specific word embeddings, we go beyond previous work and align vector spaces to gain comparative embeddings. We suggest two novel models to exploit general-vs. domain-specific comparisons: a simple neural network model with pre-computed comparative-embedding information as input, and a multi-channel model computing the comparison internally. Both models outperform previous approaches, with the multi-channel model performing best.","predict degree technicality automatic terminology extraction automatic term extraction wellresearched area , computational approach distinguish degree technicality understudy . semi - automatically create german gold standard technicality domain , illustrate impact web - crawl general - language corpus predict technicality . define classification approach combine general - language domain - specific word embedding , previous work align vector space gain comparative embedding . suggest novel model exploit general - vs. domain - specific comparison : simple neural network model pre - computed comparative - embed information input , multi - channel model compute comparison internally . model outperform previous approach , multi - channel model perform well .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,Verbal Multiword Expressions for Identification of Metaphor,"Metaphor is a linguistic device in which a concept is expressed by mentioning another. Identifying metaphorical expressions, therefore, requires a non-compositional understanding of semantics. Multiword Expressions (MWEs), on the other hand, are linguistic phenomena with varying degrees of semantic opacity and their identification poses a challenge to computational models. This work is the first attempt at analysing the interplay of metaphor and MWEs processing through the design of a neural architecture whereby classification of metaphors is enhanced by informing the model of the presence of MWEs. To the best of our knowledge, this is the first ""MWE-aware"" metaphor identification system paving the way for further experiments on the complex interactions of these phenomena. The results and analyses show that this proposed architecture reach state-of-the-art on two different established metaphor datasets.","Verbal Multiword Expressions for Identification of Metaphor Metaphor is a linguistic device in which a concept is expressed by mentioning another. Identifying metaphorical expressions, therefore, requires a non-compositional understanding of semantics. Multiword Expressions (MWEs), on the other hand, are linguistic phenomena with varying degrees of semantic opacity and their identification poses a challenge to computational models. This work is the first attempt at analysing the interplay of metaphor and MWEs processing through the design of a neural architecture whereby classification of metaphors is enhanced by informing the model of the presence of MWEs. To the best of our knowledge, this is the first ""MWE-aware"" metaphor identification system paving the way for further experiments on the complex interactions of these phenomena. The results and analyses show that this proposed architecture reach state-of-the-art on two different established metaphor datasets.","verbal multiword expressions identification metaphor metaphor linguistic device concept express mention . identify metaphorical expression , , require non - compositional understanding semantic . multiword expressions ( mwes ) , hand , linguistic phenomenon vary degree semantic opacity identification pose challenge computational model . work attempt analyse interplay metaphor mwes processing design neural architecture classification metaphor enhance inform model presence mwe . good knowledge , "" mwe - aware "" metaphor identification system pave way experiment complex interaction phenomenon . result analysis propose architecture reach state - - - art different establish metaphor dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 9, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance,"Pretraining deep language models has led to large performance gains in NLP. Despite this success, Schick and SchÃ¼tze (2020) recently showed that these models struggle to understand rare words. For static word embeddings, this problem has been addressed by separately learning representations for rare words. In this work, we transfer this idea to pretrained language models: We introduce BERTRAM, a powerful architecture based on BERT that is capable of inferring high-quality embeddings for rare words that are suitable as input representations for deep language models. This is achieved by enabling the surface form and contexts of a word to interact with each other in a deep architecture. Integrating BERTRAM into BERT leads to large performance increases due to improved representations of rare and medium frequency words on both a rare word probing task and three downstream tasks. 1","BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance Pretraining deep language models has led to large performance gains in NLP. Despite this success, Schick and SchÃ¼tze (2020) recently showed that these models struggle to understand rare words. For static word embeddings, this problem has been addressed by separately learning representations for rare words. In this work, we transfer this idea to pretrained language models: We introduce BERTRAM, a powerful architecture based on BERT that is capable of inferring high-quality embeddings for rare words that are suitable as input representations for deep language models. This is achieved by enabling the surface form and contexts of a word to interact with each other in a deep architecture. Integrating BERTRAM into BERT leads to large performance increases due to improved representations of rare and medium frequency words on both a rare word probing task and three downstream tasks. 1","bertram : improve word embedding big impact contextualize model performance pretraine deep language model lead large performance gain nlp . despite success , schick schÃ¼tze ( 2020 ) recently show model struggle understand rare word . static word embedding , problem address separately learn representation rare word . work , transfer idea pretrained language model : introduce bertram , powerful architecture base bert capable infer high - quality embedding rare word suitable input representation deep language model . achieve enable surface form context word interact deep architecture . integrate bertram bert lead large performance increase improve representation rare medium frequency word rare word probe task downstream task . 1","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 13, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 15, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Multidirectional Associative Optimization of Function-Specific Word Representations,"We present a neural framework for learning associations between interrelated groups of words such as the ones found in Subject-Verb-Object (SVO) structures. Our model induces a joint function-specific word vector space, where vectors of e.g. plausible SVO compositions lie close together. The model retains information about word group membership even in the joint space, and can thereby effectively be applied to a number of tasks reasoning over the SVO structure. We show the robustness and versatility of the proposed framework by reporting state-of-the-art results on the tasks of estimating selectional preference and event similarity. The results indicate that the combinations of representations learned with our task-independent model outperform task-specific architectures from prior work, while reducing the number of parameters by up to 95%.","Multidirectional Associative Optimization of Function-Specific Word Representations We present a neural framework for learning associations between interrelated groups of words such as the ones found in Subject-Verb-Object (SVO) structures. Our model induces a joint function-specific word vector space, where vectors of e.g. plausible SVO compositions lie close together. The model retains information about word group membership even in the joint space, and can thereby effectively be applied to a number of tasks reasoning over the SVO structure. We show the robustness and versatility of the proposed framework by reporting state-of-the-art results on the tasks of estimating selectional preference and event similarity. The results indicate that the combinations of representations learned with our task-independent model outperform task-specific architectures from prior work, while reducing the number of parameters by up to 95%.","multidirectional associative optimization function - specific word representation present neural framework learn association interrelated group word one find subject - verb - object ( svo ) structure . model induce joint function - specific word vector space , vector e.g. plausible svo composition lie close . model retain information word group membership joint space , effectively apply number task reason svo structure . robustness versatility propose framework report state - - - art result task estimate selectional preference event similarity . result indicate combination representation learn task - independent model outperform task - specific architecture prior work , reduce number parameter 95 % .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 6, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,Moving Down the Long Tail of Word Sense Disambiguation with Gloss Informed Bi-encoders,"A major obstacle in Word Sense Disambiguation (WSD) is that word senses are not uniformly distributed, causing existing models to generally perform poorly on senses that are either rare or unseen during training. We propose a bi-encoder model that independently embeds (1) the target word with its surrounding context and (2) the dictionary definition, or gloss, of each sense. The encoders are jointly optimized in the same representation space, so that sense disambiguation can be performed by finding the nearest sense embedding for each target word embedding. Our system outperforms previous state-of-the-art models on English all-words WSD; these gains predominantly come from improved performance on rare senses, leading to a 31.1% error reduction on less frequent senses over prior work. This demonstrates that rare senses can be more effectively disambiguated by modeling their definitions.","Moving Down the Long Tail of Word Sense Disambiguation with Gloss Informed Bi-encoders A major obstacle in Word Sense Disambiguation (WSD) is that word senses are not uniformly distributed, causing existing models to generally perform poorly on senses that are either rare or unseen during training. We propose a bi-encoder model that independently embeds (1) the target word with its surrounding context and (2) the dictionary definition, or gloss, of each sense. The encoders are jointly optimized in the same representation space, so that sense disambiguation can be performed by finding the nearest sense embedding for each target word embedding. Our system outperforms previous state-of-the-art models on English all-words WSD; these gains predominantly come from improved performance on rare senses, leading to a 31.1% error reduction on less frequent senses over prior work. This demonstrates that rare senses can be more effectively disambiguated by modeling their definitions.","move long tail word sense disambiguation gloss inform bi - encoder major obstacle word sense disambiguation ( wsd ) word sense uniformly distribute , cause exist model generally perform poorly sense rare unseen training . propose bi - encoder model independently embed ( 1 ) target word surround context ( 2 ) dictionary definition , gloss , sense . encoder jointly optimize representation space , sense disambiguation perform find near sense embedding target word embedding . system outperform previous state - - - art model english - word wsd ; gain predominantly come improve performance rare sense , lead 31.1 % error reduction frequent sense prior work . demonstrate rare sense effectively disambiguate model definition .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 23, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Adaptive Compression of Word Embeddings,"Distributed representations of words have been an indispensable component for natural language processing (NLP) tasks. However, the large memory footprint of word embeddings makes it challenging to deploy NLP models to memory-constrained devices (e.g., selfdriving cars, mobile devices). In this paper, we propose a novel method to adaptively compress word embeddings. We fundamentally follow a code-book approach that represents words as discrete codes such as (8, 5, 2, 4). However, unlike prior works that assign the same length of codes to all words, we adaptively assign different lengths of codes to each word by learning downstream tasks. The proposed method works in two steps. First, each word directly learns to select its code length in an end-to-end manner by applying the Gumbel-softmax tricks. After selecting the code length, each word learns discrete codes through a neural network with a binary constraint. To showcase the general applicability of the proposed method, we evaluate the performance on four different downstream tasks. Comprehensive evaluation results clearly show that our method is effective and makes the highly compressed word embeddings without hurting the task accuracy. Moreover, we show that our model assigns word to each code-book by considering the significance of tasks.","Adaptive Compression of Word Embeddings Distributed representations of words have been an indispensable component for natural language processing (NLP) tasks. However, the large memory footprint of word embeddings makes it challenging to deploy NLP models to memory-constrained devices (e.g., selfdriving cars, mobile devices). In this paper, we propose a novel method to adaptively compress word embeddings. We fundamentally follow a code-book approach that represents words as discrete codes such as (8, 5, 2, 4). However, unlike prior works that assign the same length of codes to all words, we adaptively assign different lengths of codes to each word by learning downstream tasks. The proposed method works in two steps. First, each word directly learns to select its code length in an end-to-end manner by applying the Gumbel-softmax tricks. After selecting the code length, each word learns discrete codes through a neural network with a binary constraint. To showcase the general applicability of the proposed method, we evaluate the performance on four different downstream tasks. Comprehensive evaluation results clearly show that our method is effective and makes the highly compressed word embeddings without hurting the task accuracy. Moreover, we show that our model assigns word to each code-book by considering the significance of tasks.","adaptive compression word embedding distribute representation word indispensable component natural language processing ( nlp ) task . , large memory footprint word embedding make challenging deploy nlp model memory - constrain device ( e.g. , selfdrive car , mobile device ) . paper , propose novel method adaptively compress word embedding . fundamentally follow code - book approach represent word discrete code ( 8 , 5 , 2 , 4 ) . , unlike prior work assign length code word , adaptively assign different length code word learn downstream task . propose method work step . , word directly learn select code length end - - end manner apply gumbel - softmax trick . select code length , word learn discrete code neural network binary constraint . showcase general applicability propose method , evaluate performance different downstream task . comprehensive evaluation result clearly method effective make highly compress word embedding hurt task accuracy . , model assign word code - book consider significance task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 8, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 15, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Biomedical Entity Representations with Synonym Marginalization,"Biomedical named entities often play important roles in many biomedical text mining tools. However, due to the incompleteness of provided synonyms and numerous variations in their surface forms, normalization of biomedical entities is very challenging. In this paper, we focus on learning representations of biomedical entities solely based on the synonyms of entities. To learn from the incomplete synonyms, we use a model-based candidate selection and maximize the marginal likelihood of the synonyms present in top candidates. Our model-based candidates are iteratively updated to contain more difficult negative samples as our model evolves. In this way, we avoid the explicit pre-selection of negative samples from more than 400K candidates. On four biomedical entity normalization datasets having three different entity types (disease, chemical, adverse reaction), our model BIOSYN consistently outperforms previous state-of-the-art models almost reaching the upper bound on each dataset.","Biomedical Entity Representations with Synonym Marginalization Biomedical named entities often play important roles in many biomedical text mining tools. However, due to the incompleteness of provided synonyms and numerous variations in their surface forms, normalization of biomedical entities is very challenging. In this paper, we focus on learning representations of biomedical entities solely based on the synonyms of entities. To learn from the incomplete synonyms, we use a model-based candidate selection and maximize the marginal likelihood of the synonyms present in top candidates. Our model-based candidates are iteratively updated to contain more difficult negative samples as our model evolves. In this way, we avoid the explicit pre-selection of negative samples from more than 400K candidates. On four biomedical entity normalization datasets having three different entity types (disease, chemical, adverse reaction), our model BIOSYN consistently outperforms previous state-of-the-art models almost reaching the upper bound on each dataset.","biomedical entity representation synonym marginalization biomedical name entity play important role biomedical text mining tool . , incompleteness provide synonym numerous variation surface form , normalization biomedical entity challenging . paper , focus learn representation biomedical entity solely base synonym entity . learn incomplete synonym , use model - base candidate selection maximize marginal likelihood synonym present candidate . model - base candidate iteratively update contain difficult negative sample model evolve . way , avoid explicit pre - selection negative sample 400 k candidate . biomedical entity normalization dataset have different entity type ( disease , chemical , adverse reaction ) , model biosyn consistently outperform previous state - - - art model reach upper bound dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Semantics: Lexical Semantics,Investigating Word-Class Distributions in Word Vector Spaces,"This paper presents an investigation on the distribution of word vectors belonging to a certain word class in a pre-trained word vector space. To this end, we made several assumptions about the distribution, modeled the distribution accordingly, and validated each assumption by comparing the goodness of each model. Specifically, we considered two types of word classes -the semantic class of direct objects of a verb and the semantic class in a thesaurus -and tried to build models that properly estimate how likely it is that a word in the vector space is a member of a given word class. Our results on selectional preference and WordNet datasets show that the centroid-based model will fail to achieve good enough performance, the geometry of the distribution and the existence of subgroups will have limited impact, and also the negative instances need to be considered for adequate modeling of the distribution. We further investigated the relationship between the scores calculated by each model and the degree of membership and found that discriminative learning-based models are best in finding the boundaries of a class, while models based on the offset between positive and negative instances perform best in determining the degree of membership.","Investigating Word-Class Distributions in Word Vector Spaces This paper presents an investigation on the distribution of word vectors belonging to a certain word class in a pre-trained word vector space. To this end, we made several assumptions about the distribution, modeled the distribution accordingly, and validated each assumption by comparing the goodness of each model. Specifically, we considered two types of word classes -the semantic class of direct objects of a verb and the semantic class in a thesaurus -and tried to build models that properly estimate how likely it is that a word in the vector space is a member of a given word class. Our results on selectional preference and WordNet datasets show that the centroid-based model will fail to achieve good enough performance, the geometry of the distribution and the existence of subgroups will have limited impact, and also the negative instances need to be considered for adequate modeling of the distribution. We further investigated the relationship between the scores calculated by each model and the degree of membership and found that discriminative learning-based models are best in finding the boundaries of a class, while models based on the offset between positive and negative instances perform best in determining the degree of membership.","investigate word - class distribution word vector space paper present investigation distribution word vector belong certain word class pre - trained word vector space . end , assumption distribution , model distribution accordingly , validate assumption compare goodness model . specifically , consider type word class -the semantic class direct object verb semantic class thesaurus -and try build model properly estimate likely word vector space member give word class . result selectional preference wordnet dataset centroid - base model fail achieve good performance , geometry distribution existence subgroup limited impact , negative instance need consider adequate modeling distribution . investigate relationship score calculate model degree membership find discriminative learning - base model good find boundary class , model base offset positive negative instance perform well determine degree membership .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 19, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,BiRRE: Learning Bidirectional Residual Relation Embeddings for Supervised Hypernymy Detection,"The hypernymy detection task has been addressed under various frameworks. Previously, the design of unsupervised hypernymy scores has been extensively studied. In contrast, supervised classifiers, especially distributional models, leverage the global contexts of terms to make predictions, but are more likely to suffer from ""lexical memorization"". In this work, we revisit supervised distributional models for hypernymy detection. Rather than taking embeddings of two terms as classification inputs, we introduce a representation learning framework named Bidirectional Residual Relation Embeddings (BiRRE). In this model, a term pair is represented by a BiRRE vector as features for hypernymy classification, which models the possibility of a term being mapped to another in the embedding space by hypernymy relations. A Latent Projection Model with Negative Regularization (LPMNR) is proposed to simulate how hypernyms and hyponyms are generated by neural language models, and to generate BiRRE vectors based on bidirectional residuals of projections. Experiments verify BiRRE outperforms strong baselines over various evaluation frameworks.","BiRRE: Learning Bidirectional Residual Relation Embeddings for Supervised Hypernymy Detection The hypernymy detection task has been addressed under various frameworks. Previously, the design of unsupervised hypernymy scores has been extensively studied. In contrast, supervised classifiers, especially distributional models, leverage the global contexts of terms to make predictions, but are more likely to suffer from ""lexical memorization"". In this work, we revisit supervised distributional models for hypernymy detection. Rather than taking embeddings of two terms as classification inputs, we introduce a representation learning framework named Bidirectional Residual Relation Embeddings (BiRRE). In this model, a term pair is represented by a BiRRE vector as features for hypernymy classification, which models the possibility of a term being mapped to another in the embedding space by hypernymy relations. A Latent Projection Model with Negative Regularization (LPMNR) is proposed to simulate how hypernyms and hyponyms are generated by neural language models, and to generate BiRRE vectors based on bidirectional residuals of projections. Experiments verify BiRRE outperforms strong baselines over various evaluation frameworks.","birre : learn bidirectional residual relation embedding supervised hypernymy detection hypernymy detection task address framework . previously , design unsupervised hypernymy score extensively study . contrast , supervise classifier , especially distributional model , leverage global context term prediction , likely suffer "" lexical memorization "" . work , revisit supervise distributional model hypernymy detection . take embedding term classification input , introduce representation learning framework name bidirectional residual relation embeddings ( birre ) . model , term pair represent birre vector feature hypernymy classification , model possibility term map embed space hypernymy relation . latent projection model negative regularization ( lpmnr ) propose simulate hypernym hyponym generate neural language model , generate birre vector base bidirectional residual projection . experiment verify birre outperform strong baseline evaluation framework .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 13, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
Semantics: Lexical Semantics,Autoencoding Keyword Correlation Graph for Document Clustering,"Document clustering requires a deep understanding of the complex structure of longtext; in particular, the intra-sentential (local) and inter-sentential features (global). Existing representation learning models do not fully capture these features. To address this, we present a novel graph-based representation for document clustering that builds a graph autoencoder (GAE) on a Keyword Correlation Graph. The graph is constructed with topical keywords as nodes and multiple local and global features as edges. A GAE is employed to aggregate the two sets of features by learning a latent representation which can jointly reconstruct them. Clustering is then performed on the learned representations, using vector dimensions as features for inducing document classes. Extensive experiments on two datasets show that the features learned by our approach can achieve better clustering performance than other existing features, including term frequency-inverse document frequency and average embedding.","Autoencoding Keyword Correlation Graph for Document Clustering Document clustering requires a deep understanding of the complex structure of longtext; in particular, the intra-sentential (local) and inter-sentential features (global). Existing representation learning models do not fully capture these features. To address this, we present a novel graph-based representation for document clustering that builds a graph autoencoder (GAE) on a Keyword Correlation Graph. The graph is constructed with topical keywords as nodes and multiple local and global features as edges. A GAE is employed to aggregate the two sets of features by learning a latent representation which can jointly reconstruct them. Clustering is then performed on the learned representations, using vector dimensions as features for inducing document classes. Extensive experiments on two datasets show that the features learned by our approach can achieve better clustering performance than other existing features, including term frequency-inverse document frequency and average embedding.","autoencode keyword correlation graph document clustering document clustering require deep understanding complex structure longtext ; particular , intra - sentential ( local ) inter - sentential feature ( global ) . exist representation learning model fully capture feature . address , present novel graph - base representation document clustering build graph autoencoder ( gae ) keyword correlation graph . graph construct topical keyword node multiple local global feature edge . gae employ aggregate set feature learn latent representation jointly reconstruct . clustering perform learn representation , vector dimension feature induce document class . extensive experiment dataset feature learn approach achieve well clustering performance exist feature , include term frequency - inverse document frequency average embedding .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Semantics: Lexical Semantics,CluBERT: A Cluster-Based Approach for Learning Sense Distributions in Multiple Languages,"Knowing the Most Frequent Sense (MFS) of a word has been proved to help Word Sense Disambiguation (WSD) models significantly. However, the scarcity of sense-annotated data makes it difficult to induce a reliable and highcoverage distribution of the meanings in a language vocabulary. To address this issue, in this paper we present CluBERT, an automatic and multilingual approach for inducing the distributions of word senses from a corpus of raw sentences. Our experiments show that Clu-BERT learns distributions over English senses that are of higher quality than those extracted by alternative approaches. When used to induce the MFS of a lemma, CluBERT attains state-of-the-art results on the English Word Sense Disambiguation tasks and helps to improve the disambiguation performance of two off-the-shelf WSD models. Moreover, our distributions also prove to be effective in other languages, beating all their alternatives for computing the MFS on the multilingual WSD tasks. We release our sense distributions in five different languages at https://github. com/SapienzaNLP/clubert.","CluBERT: A Cluster-Based Approach for Learning Sense Distributions in Multiple Languages Knowing the Most Frequent Sense (MFS) of a word has been proved to help Word Sense Disambiguation (WSD) models significantly. However, the scarcity of sense-annotated data makes it difficult to induce a reliable and highcoverage distribution of the meanings in a language vocabulary. To address this issue, in this paper we present CluBERT, an automatic and multilingual approach for inducing the distributions of word senses from a corpus of raw sentences. Our experiments show that Clu-BERT learns distributions over English senses that are of higher quality than those extracted by alternative approaches. When used to induce the MFS of a lemma, CluBERT attains state-of-the-art results on the English Word Sense Disambiguation tasks and helps to improve the disambiguation performance of two off-the-shelf WSD models. Moreover, our distributions also prove to be effective in other languages, beating all their alternatives for computing the MFS on the multilingual WSD tasks. We release our sense distributions in five different languages at https://github. com/SapienzaNLP/clubert.","clubert : cluster - base approach learn sense distribution multiple language know frequent sense ( mfs ) word prove help word sense disambiguation ( wsd ) model significantly . , scarcity sense - annotate datum make difficult induce reliable highcoverage distribution meaning language vocabulary . address issue , paper present clubert , automatic multilingual approach induce distribution word sense corpus raw sentence . experiment clu - bert learn distribution english sense high quality extract alternative approach . induce mfs lemma , clubert attain state - - - art result english word sense disambiguation task help improve disambiguation performance - - shelf wsd model . , distribution prove effective language , beat alternative compute mfs multilingual wsd task . release sense distribution different language https://github . com / sapienzanlp / clubert .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 21, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",LogicalFactChecker: Leveraging Logical Operations for Fact Checking with Graph Module Network,"Verifying the correctness of a textual statement requires not only semantic reasoning about the meaning of words, but also symbolic reasoning about logical operations like count, superlative, aggregation, etc. In this work, we propose LogicalFactChecker, a neural network approach capable of leveraging logical operations for fact checking. It achieves the state-of-the-art performance on TABFACT, a large-scale, benchmark dataset built for verifying a textual statement with semi-structured tables. This is achieved by a graph module network built upon the Transformer-based architecture. With a textual statement and a table as the input, LogicalFactChecker automatically derives a program (a.k.a. logical form) of the statement in a semantic parsing manner. A heterogeneous graph is then constructed to capture not only the structures of the table and the program, but also the connections between inputs with different modalities. Such a graph reveals the related contexts of each word in the statement, the table and the program. The graph is used to obtain graphenhanced contextual representations of words in Transformer-based architecture. After that, a program-driven module network is further introduced to exploit the hierarchical structure of the program, where semantic compositionality is dynamically modeled along the program structure with a set of function-specific modules. Ablation experiments suggest that both the heterogeneous graph and the module network are important to obtain strong results.","LogicalFactChecker: Leveraging Logical Operations for Fact Checking with Graph Module Network Verifying the correctness of a textual statement requires not only semantic reasoning about the meaning of words, but also symbolic reasoning about logical operations like count, superlative, aggregation, etc. In this work, we propose LogicalFactChecker, a neural network approach capable of leveraging logical operations for fact checking. It achieves the state-of-the-art performance on TABFACT, a large-scale, benchmark dataset built for verifying a textual statement with semi-structured tables. This is achieved by a graph module network built upon the Transformer-based architecture. With a textual statement and a table as the input, LogicalFactChecker automatically derives a program (a.k.a. logical form) of the statement in a semantic parsing manner. A heterogeneous graph is then constructed to capture not only the structures of the table and the program, but also the connections between inputs with different modalities. Such a graph reveals the related contexts of each word in the statement, the table and the program. The graph is used to obtain graphenhanced contextual representations of words in Transformer-based architecture. After that, a program-driven module network is further introduced to exploit the hierarchical structure of the program, where semantic compositionality is dynamically modeled along the program structure with a set of function-specific modules. Ablation experiments suggest that both the heterogeneous graph and the module network are important to obtain strong results.","logicalfactchecker : leverage logical operation fact checking graph module network verify correctness textual statement require semantic reasoning meaning word , symbolic reasoning logical operation like count , superlative , aggregation , etc . work , propose logicalfactchecker , neural network approach capable leverage logical operation fact checking . achieve state - - - art performance tabfact , large - scale , benchmark dataset build verify textual statement semi - structured table . achieve graph module network build transformer - base architecture . textual statement table input , logicalfactchecker automatically derive program ( a.k.a . logical form ) statement semantic parsing manner . heterogeneous graph construct capture structure table program , connection input different modality . graph reveal related context word statement , table program . graph obtain graphenhance contextual representation word transformer - base architecture . , program - drive module network introduce exploit hierarchical structure program , semantic compositionality dynamically model program structure set function - specific module . ablation experiment suggest heterogeneous graph module network important obtain strong result .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 22, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Controlled Crowdsourcing for High-Quality QA-SRL Annotation,"Question-answer driven Semantic Role Labeling (QA-SRL) was proposed as an attractive open and natural flavour of SRL, potentially attainable from laymen. Recently, a large-scale crowdsourced QA-SRL corpus and a trained parser were released. Trying to replicate the QA-SRL annotation for new texts, we found that the resulting annotations were lacking in quality, particularly in coverage, making them insufficient for further research and evaluation. In this paper, we present an improved crowdsourcing protocol for complex semantic annotation, involving worker selection and training, and a data consolidation phase. Applying this protocol to QA-SRL yielded highquality annotation with drastically higher coverage, producing a new gold evaluation dataset. We believe that our annotation protocol and gold standard will facilitate future replicable research of natural semantic annotations.","Controlled Crowdsourcing for High-Quality QA-SRL Annotation Question-answer driven Semantic Role Labeling (QA-SRL) was proposed as an attractive open and natural flavour of SRL, potentially attainable from laymen. Recently, a large-scale crowdsourced QA-SRL corpus and a trained parser were released. Trying to replicate the QA-SRL annotation for new texts, we found that the resulting annotations were lacking in quality, particularly in coverage, making them insufficient for further research and evaluation. In this paper, we present an improved crowdsourcing protocol for complex semantic annotation, involving worker selection and training, and a data consolidation phase. Applying this protocol to QA-SRL yielded highquality annotation with drastically higher coverage, producing a new gold evaluation dataset. We believe that our annotation protocol and gold standard will facilitate future replicable research of natural semantic annotations.","control crowdsourcing high - quality qa - srl annotation question - answer drive semantic role labeling ( qa - srl ) propose attractive open natural flavour srl , potentially attainable layman . recently , large - scale crowdsource qa - srl corpus train parser release . try replicate qa - srl annotation new text , find result annotation lack quality , particularly coverage , make insufficient research evaluation . paper , present improved crowdsourcing protocol complex semantic annotation , involve worker selection training , data consolidation phase . apply protocol qa - srl yield highquality annotation drastically high coverage , produce new gold evaluation dataset . believe annotation protocol gold standard facilitate future replicable research natural semantic annotation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 7, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Semi-Supervised Semantic Dependency Parsing Using CRF Autoencoders,"Semantic dependency parsing, which aims to find rich bi-lexical relationships, allows words to have multiple dependency heads, resulting in graph-structured representations. We propose an approach to semi-supervised learning of semantic dependency parsers based on the CRF autoencoder framework. Our encoder is a discriminative neural semantic dependency parser that predicts the latent parse graph of the input sentence. Our decoder is a generative neural model that reconstructs the input sentence conditioned on the latent parse graph. Our model is arc-factored and therefore parsing and learning are both tractable. Experiments show our model achieves significant and consistent improvement over the supervised baseline.","Semi-Supervised Semantic Dependency Parsing Using CRF Autoencoders Semantic dependency parsing, which aims to find rich bi-lexical relationships, allows words to have multiple dependency heads, resulting in graph-structured representations. We propose an approach to semi-supervised learning of semantic dependency parsers based on the CRF autoencoder framework. Our encoder is a discriminative neural semantic dependency parser that predicts the latent parse graph of the input sentence. Our decoder is a generative neural model that reconstructs the input sentence conditioned on the latent parse graph. Our model is arc-factored and therefore parsing and learning are both tractable. Experiments show our model achieves significant and consistent improvement over the supervised baseline.","semi - supervised semantic dependency parse crf autoencoder semantic dependency parsing , aim find rich bi - lexical relationship , allow word multiple dependency head , result graph - structured representation . propose approach semi - supervised learning semantic dependency parser base crf autoencoder framework . encoder discriminative neural semantic dependency parser predict latent parse graph input sentence . decoder generative neural model reconstruct input sentence condition latent parse graph . model arc - factor parsing learning tractable . experiment model achieve significant consistent improvement supervise baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 10, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Exploring Unexplored Generalization Challenges for Cross-Database Semantic Parsing,"We study the task of cross-database semantic parsing (XSP), where a system that maps natural language utterances to executable SQL queries is evaluated on databases unseen during training. Recently, several datasets, including Spider, were proposed to support development of XSP systems. We propose a challenging evaluation setup for cross-database semantic parsing, focusing on variation across database schemas and in-domain language use. We re-purpose eight semantic parsing datasets that have been well-studied in the setting where in-domain training data is available, and instead use them as additional evaluation data for XSP systems instead. We build a system that performs well on Spider, and find that it struggles to generalize to our re-purposed set. Our setup uncovers several generalization challenges for cross-database semantic parsing, demonstrating the need to use and develop diverse training and evaluation datasets. * Work done during an internship at Google. Advising (Finegan-Dollak et al., 2018) NL: For EECS 478, how many credits is it? SQL: select distinct credits from course where department ='EECS' and number = 478; GeoQuery (Zelle and Mooney, 1996) NL: How many people live in mississippi? SQL: select population from state where state name = 'mississippi';","Exploring Unexplored Generalization Challenges for Cross-Database Semantic Parsing We study the task of cross-database semantic parsing (XSP), where a system that maps natural language utterances to executable SQL queries is evaluated on databases unseen during training. Recently, several datasets, including Spider, were proposed to support development of XSP systems. We propose a challenging evaluation setup for cross-database semantic parsing, focusing on variation across database schemas and in-domain language use. We re-purpose eight semantic parsing datasets that have been well-studied in the setting where in-domain training data is available, and instead use them as additional evaluation data for XSP systems instead. We build a system that performs well on Spider, and find that it struggles to generalize to our re-purposed set. Our setup uncovers several generalization challenges for cross-database semantic parsing, demonstrating the need to use and develop diverse training and evaluation datasets. * Work done during an internship at Google. Advising (Finegan-Dollak et al., 2018) NL: For EECS 478, how many credits is it? SQL: select distinct credits from course where department ='EECS' and number = 478; GeoQuery (Zelle and Mooney, 1996) NL: How many people live in mississippi? SQL: select population from state where state name = 'mississippi';","explore unexplored generalization challenge cross - database semantic parsing study task cross - database semantic parsing ( xsp ) , system map natural language utterance executable sql query evaluate database unseen training . recently , dataset , include spider , propose support development xsp system . propose challenging evaluation setup cross - database semantic parsing , focus variation database schema - domain language use . - purpose semantic parsing dataset - study setting - domain training data available , instead use additional evaluation datum xsp system instead . build system perform spider , find struggle generalize - purpose set . setup uncover generalization challenge cross - database semantic parsing , demonstrate need use develop diverse training evaluation dataset . * work internship google . advise ( finegan - dollak et al . , 2018 ) nl : eecs 478 , credit ? sql : select distinct credit course department = ' eecs ' number = 478 ; geoquery ( zelle mooney , 1996 ) nl : people live mississippi ? sql : select population state state = ' mississippi ' ;","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 16, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",tBERT: Topic Models and BERT Joining Forces for Semantic Similarity Detection,Semantic similarity detection is a fundamental task in natural language understanding. Adding topic information has been useful for previous feature-engineered semantic similarity models as well as neural models for other tasks. There is currently no standard way of combining topics with pretrained contextual representations such as BERT. We propose a novel topic-informed BERT-based architecture for pairwise semantic similarity detection and show that our model improves performance over strong neural baselines across a variety of English language datasets. We find that the addition of topics to BERT helps particularly with resolving domain-specific cases.,tBERT: Topic Models and BERT Joining Forces for Semantic Similarity Detection Semantic similarity detection is a fundamental task in natural language understanding. Adding topic information has been useful for previous feature-engineered semantic similarity models as well as neural models for other tasks. There is currently no standard way of combining topics with pretrained contextual representations such as BERT. We propose a novel topic-informed BERT-based architecture for pairwise semantic similarity detection and show that our model improves performance over strong neural baselines across a variety of English language datasets. We find that the addition of topics to BERT helps particularly with resolving domain-specific cases.,tbert : topic model bert join force semantic similarity detection semantic similarity detection fundamental task natural language understanding . add topic information useful previous feature - engineer semantic similarity model neural model task . currently standard way combine topic pretrained contextual representation bert . propose novel topic - inform bert - base architecture pairwise semantic similarity detection model improve performance strong neural baseline variety english language dataset . find addition topic bert help particularly resolve domain - specific case .,"{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Semantic Parsing for English as a Second Language,"This paper is concerned with semantic parsing for English as a second language (ESL). Motivated by the theoretical emphasis on the learning challenges that occur at the syntaxsemantics interface during second language acquisition, we formulate the task based on the divergence between literal and intended meanings. We combine the complementary strengths of English Resource Grammar, a linguistically-precise hand-crafted deep grammar, and TLE, an existing manually annotated ESL UD-TreeBank with a novel reranking model. Experiments demonstrate that in comparison to human annotations, our method can obtain a very promising SemBanking quality. By means of the newly created corpus, we evaluate state-of-the-art semantic parsing as well as grammatical error correction models. The evaluation profiles the performance of neural NLP techniques for handling ESL data and suggests some research directions.","Semantic Parsing for English as a Second Language This paper is concerned with semantic parsing for English as a second language (ESL). Motivated by the theoretical emphasis on the learning challenges that occur at the syntaxsemantics interface during second language acquisition, we formulate the task based on the divergence between literal and intended meanings. We combine the complementary strengths of English Resource Grammar, a linguistically-precise hand-crafted deep grammar, and TLE, an existing manually annotated ESL UD-TreeBank with a novel reranking model. Experiments demonstrate that in comparison to human annotations, our method can obtain a very promising SemBanking quality. By means of the newly created corpus, we evaluate state-of-the-art semantic parsing as well as grammatical error correction models. The evaluation profiles the performance of neural NLP techniques for handling ESL data and suggests some research directions.","semantic parsing english second language paper concern semantic parsing english second language ( esl ) . motivate theoretical emphasis learning challenge occur syntaxsemantic interface second language acquisition , formulate task base divergence literal intended meaning . combine complementary strength english resource grammar , linguistically - precise hand - craft deep grammar , tle , exist manually annotate esl ud - treebank novel reranking model . experiment demonstrate comparison human annotation , method obtain promising sembanking quality . mean newly create corpus , evaluate state - - - art semantic parsing grammatical error correction model . evaluation profile performance neural nlp technique handle esl datum suggest research direction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Beyond Possession Existence: Duration and Co-Possession,"This paper introduces two tasks: determining (a) the duration of possession relations and (b) co-possessions, i.e., whether multiple possessors possess a possessee at the same time. We present new annotations on top of corpora annotating possession existence, and experimental results. Regarding possession duration, we derive the time spans we work with empirically from annotations indicating lower and upper bounds. Regarding co-possessions, we use a binary label. Cohen's kappa coefficients indicate substantial agreement, and experimental results show that text is more useful than the image for solving these tasks.","Beyond Possession Existence: Duration and Co-Possession This paper introduces two tasks: determining (a) the duration of possession relations and (b) co-possessions, i.e., whether multiple possessors possess a possessee at the same time. We present new annotations on top of corpora annotating possession existence, and experimental results. Regarding possession duration, we derive the time spans we work with empirically from annotations indicating lower and upper bounds. Regarding co-possessions, we use a binary label. Cohen's kappa coefficients indicate substantial agreement, and experimental results show that text is more useful than the image for solving these tasks.","possession existence : duration co - possession paper introduce task : determine ( ) duration possession relation ( b ) co - possession , i.e. , multiple possessor possess possessee time . present new annotation corpus annotate possession existence , experimental result . possession duration , derive time span work empirically annotation indicate low upper bound . co - possession , use binary label . cohen kappa coefficient indicate substantial agreement , experimental result text useful image solve task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",FastBERT: a Self-distilling BERT with Adaptive Inference Time,"Pre-trained language models like BERT have proven to be highly performant. However, they are often computationally expensive in many practical scenarios, for such heavy models can hardly be readily implemented with limited resources. To improve their efficiency with an assured model performance, we propose a novel speed-tunable FastBERT with adaptive inference time. The speed at inference can be flexibly adjusted under varying demands, while redundant calculation of samples is avoided. Moreover, this model adopts a unique selfdistillation mechanism at fine-tuning, further enabling a greater computational efficacy with minimal loss in performance. Our model achieves promising results in twelve English and Chinese datasets. It is able to speed up by a wide range from 1 to 12 times than BERT if given different speedup thresholds to make a speed-performance tradeoff.","FastBERT: a Self-distilling BERT with Adaptive Inference Time Pre-trained language models like BERT have proven to be highly performant. However, they are often computationally expensive in many practical scenarios, for such heavy models can hardly be readily implemented with limited resources. To improve their efficiency with an assured model performance, we propose a novel speed-tunable FastBERT with adaptive inference time. The speed at inference can be flexibly adjusted under varying demands, while redundant calculation of samples is avoided. Moreover, this model adopts a unique selfdistillation mechanism at fine-tuning, further enabling a greater computational efficacy with minimal loss in performance. Our model achieves promising results in twelve English and Chinese datasets. It is able to speed up by a wide range from 1 to 12 times than BERT if given different speedup thresholds to make a speed-performance tradeoff.","fastbert : self - distil bert adaptive inference time pre - trained language model like bert prove highly performant . , computationally expensive practical scenario , heavy model hardly readily implement limited resource . improve efficiency assured model performance , propose novel speed - tunable fastbert adaptive inference time . speed inference flexibly adjust vary demand , redundant calculation sample avoid . , model adopt unique selfdistillation mechanism fine - tuning , enable great computational efficacy minimal loss performance . model achieve promising result english chinese dataset . able speed wide range 1 12 time bert give different speedup threshold speed - performance tradeoff .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Incorporating External Knowledge through Pre-training for Natural Language to Code Generation,"Open-domain code generation aims to generate code in a general-purpose programming language (such as Python) from natural language (NL) intents. Motivated by the intuition that developers usually retrieve resources on the web when writing code, we explore the effectiveness of incorporating two varieties of external knowledge into NL-to-code generation: automatically mined NL-code pairs from the online programming QA forum StackOverflow and programming language API documentation. Our evaluations show that combining the two sources with data augmentation and retrieval-based data re-sampling improves the current state-of-the-art by up to 2.2% absolute BLEU score on the code generation testbed CoNaLa.","Incorporating External Knowledge through Pre-training for Natural Language to Code Generation Open-domain code generation aims to generate code in a general-purpose programming language (such as Python) from natural language (NL) intents. Motivated by the intuition that developers usually retrieve resources on the web when writing code, we explore the effectiveness of incorporating two varieties of external knowledge into NL-to-code generation: automatically mined NL-code pairs from the online programming QA forum StackOverflow and programming language API documentation. Our evaluations show that combining the two sources with data augmentation and retrieval-based data re-sampling improves the current state-of-the-art by up to 2.2% absolute BLEU score on the code generation testbed CoNaLa.","incorporate external knowledge pre - training natural language code generation open - domain code generation aim generate code general - purpose programming language ( python ) natural language ( nl ) intent . motivate intuition developer usually retrieve resource web write code , explore effectiveness incorporate variety external knowledge nl - - code generation : automatically mine nl - code pair online programming qa forum stackoverflow programming language api documentation . evaluation combine source datum augmentation retrieval - base datum - sampling improve current state - - - art 2.2 % absolute bleu score code generation testbed conala .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Active Learning for Coreference Resolution using Discrete Annotation,"We improve upon pairwise annotation for active learning in coreference resolution, by asking annotators to identify mention antecedents if a presented mention pair is deemed not coreferent. This simple modification, when combined with a novel mention clustering algorithm for selecting which examples to label, is much more efficient in terms of the performance obtained per annotation budget. In experiments with existing benchmark coreference datasets, we show that the signal from this additional question leads to significant performance gains per human-annotation hour. Future work can use our annotation protocol to effectively develop coreference models for new domains. Our code is publicly available. 1","Active Learning for Coreference Resolution using Discrete Annotation We improve upon pairwise annotation for active learning in coreference resolution, by asking annotators to identify mention antecedents if a presented mention pair is deemed not coreferent. This simple modification, when combined with a novel mention clustering algorithm for selecting which examples to label, is much more efficient in terms of the performance obtained per annotation budget. In experiments with existing benchmark coreference datasets, we show that the signal from this additional question leads to significant performance gains per human-annotation hour. Future work can use our annotation protocol to effectively develop coreference models for new domains. Our code is publicly available. 1","active learning coreference resolution discrete annotation improve pairwise annotation active learning coreference resolution , ask annotator identify mention antecedent present mention pair deem coreferent . simple modification , combine novel mention clustering algorithm select example label , efficient term performance obtain annotation budget . experiment exist benchmark coreference dataset , signal additional question lead significant performance gain human - annotation hour . future work use annotation protocol effectively develop coreference model new domain . code publicly available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Structured Tuning for Semantic Role Labeling,"Recent neural network-driven semantic role labeling (SRL) systems have shown impressive improvements in F1 scores. These improvements are due to expressive input representations, which, at least at the surface, are orthogonal to knowledge-rich constrained decoding mechanisms that helped linear SRL models. Introducing the benefits of structure to inform neural models presents a methodological challenge. In this paper, we present a structured tuning framework to improve models using softened constraints only at training time. Our framework leverages the expressiveness of neural networks and provides supervision with structured loss components. We start with a strong baseline (RoBERTa) to validate the impact of our approach, and show that our framework outperforms the baseline by learning to comply with declarative constraints. Additionally, our experiments with smaller training sizes show that we can achieve consistent improvements under low-resource scenarios.","Structured Tuning for Semantic Role Labeling Recent neural network-driven semantic role labeling (SRL) systems have shown impressive improvements in F1 scores. These improvements are due to expressive input representations, which, at least at the surface, are orthogonal to knowledge-rich constrained decoding mechanisms that helped linear SRL models. Introducing the benefits of structure to inform neural models presents a methodological challenge. In this paper, we present a structured tuning framework to improve models using softened constraints only at training time. Our framework leverages the expressiveness of neural networks and provides supervision with structured loss components. We start with a strong baseline (RoBERTa) to validate the impact of our approach, and show that our framework outperforms the baseline by learning to comply with declarative constraints. Additionally, our experiments with smaller training sizes show that we can achieve consistent improvements under low-resource scenarios.","structured tuning semantic role labeling recent neural network - drive semantic role labeling ( srl ) system show impressive improvement f1 score . improvement expressive input representation , , surface , orthogonal knowledge - rich constrain decoding mechanism help linear srl model . introduce benefit structure inform neural model present methodological challenge . paper , present structured tuning framework improve model soften constraint training time . framework leverage expressiveness neural network provide supervision structured loss component . start strong baseline ( roberta ) validate impact approach , framework outperform baseline learn comply declarative constraint . additionally , experiment small training size achieve consistent improvement low - resource scenario .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Good-Enough Compositional Data Augmentation,"We propose a simple data augmentation protocol aimed at providing a compositional inductive bias in conditional and unconditional sequence models. Under this protocol, synthetic training examples are constructed by taking real training examples and replacing (possibly discontinuous) fragments with other fragments that appear in at least one similar environment. The protocol is model-agnostic and useful for a variety of tasks. Applied to neural sequence-to-sequence models, it reduces error rate by as much as 87% on diagnostic tasks from the SCAN dataset and 16% on a semantic parsing task. Applied to n-gram language models, it reduces perplexity by roughly 1% on small corpora in several languages.","Good-Enough Compositional Data Augmentation We propose a simple data augmentation protocol aimed at providing a compositional inductive bias in conditional and unconditional sequence models. Under this protocol, synthetic training examples are constructed by taking real training examples and replacing (possibly discontinuous) fragments with other fragments that appear in at least one similar environment. The protocol is model-agnostic and useful for a variety of tasks. Applied to neural sequence-to-sequence models, it reduces error rate by as much as 87% on diagnostic tasks from the SCAN dataset and 16% on a semantic parsing task. Applied to n-gram language models, it reduces perplexity by roughly 1% on small corpora in several languages.","good - compositional datum augmentation propose simple data augmentation protocol aim provide compositional inductive bias conditional unconditional sequence model . protocol , synthetic training example construct take real training example replace ( possibly discontinuous ) fragment fragment appear similar environment . protocol model - agnostic useful variety task . apply neural sequence - - sequence model , reduce error rate 87 % diagnostic task scan dataset 16 % semantic parsing task . apply n - gram language model , reduce perplexity roughly 1 % small corpus language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Parsing into Variable-in-situ Logico-Semantic Graphs,"We propose variable-in-situ logico-semantic graphs to bridge the gap between semantic graph and logical form parsing. The new type of graph-based meaning representation allows us to include analysis for scope-related phenomena, such as quantification, negation and modality, in a way that is consistent with the state-of-the-art underspecification approach. Moreover, the well-formedness of such a graph is clear, since model-theoretic interpretation is available. We demonstrate the effectiveness of this new perspective by developing a new state-of-the-art semantic parser for Minimal Recursion Semantics. At the core of this parser is a novel neural graph rewriting system which combines the strengths of Hyperedge Replacement Grammar, a knowledgeintensive model, and Graph Neural Networks, a data-intensive model. Our parser achieves an accuracy of 92.39% in terms of ELEMENTARY DEPENDENCY MATCH, which is a 2.88 point improvement over the best data-driven model in the literature. The output of our parser is highly coherent: at least 91% graphs are valid, in that they allow at least one sound scoperesolved logical form.","Parsing into Variable-in-situ Logico-Semantic Graphs We propose variable-in-situ logico-semantic graphs to bridge the gap between semantic graph and logical form parsing. The new type of graph-based meaning representation allows us to include analysis for scope-related phenomena, such as quantification, negation and modality, in a way that is consistent with the state-of-the-art underspecification approach. Moreover, the well-formedness of such a graph is clear, since model-theoretic interpretation is available. We demonstrate the effectiveness of this new perspective by developing a new state-of-the-art semantic parser for Minimal Recursion Semantics. At the core of this parser is a novel neural graph rewriting system which combines the strengths of Hyperedge Replacement Grammar, a knowledgeintensive model, and Graph Neural Networks, a data-intensive model. Our parser achieves an accuracy of 92.39% in terms of ELEMENTARY DEPENDENCY MATCH, which is a 2.88 point improvement over the best data-driven model in the literature. The output of our parser is highly coherent: at least 91% graphs are valid, in that they allow at least one sound scoperesolved logical form.","parse variable - - situ logico - semantic graph propose variable - - situ logico - semantic graph bridge gap semantic graph logical form parsing . new type graph - base meaning representation allow include analysis scope - relate phenomenon , quantification , negation modality , way consistent state - - - art underspecification approach . , - formedness graph clear , model - theoretic interpretation available . demonstrate effectiveness new perspective develop new state - - - art semantic parser minimal recursion semantics . core parser novel neural graph rewrite system combine strength hyperedge replacement grammar , knowledgeintensive model , graph neural networks , data - intensive model . parser achieve accuracy 92.39 % term elementary dependency match , 2.88 point improvement good data - drive model literature . output parser highly coherent : 91 % graph valid , allow sound scoperesolve logical form .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 14, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing,"One daunting problem for semantic parsing is the scarcity of annotation. Aiming to reduce nontrivial human labor, we propose a two-stage semantic parsing framework, where the first stage utilizes an unsupervised paraphrase model to convert an unlabeled natural language utterance into the canonical utterance. The downstream naive semantic parser accepts the intermediate output and returns the target logical form. Furthermore, the entire training process is split into two phases: pre-training and cycle learning. Three tailored self-supervised tasks are introduced throughout training to activate the unsupervised paraphrase model. Experimental results on benchmarks OVERNIGHT and GE-OGRANNO demonstrate that our framework is effective and compatible with supervised training.","Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing One daunting problem for semantic parsing is the scarcity of annotation. Aiming to reduce nontrivial human labor, we propose a two-stage semantic parsing framework, where the first stage utilizes an unsupervised paraphrase model to convert an unlabeled natural language utterance into the canonical utterance. The downstream naive semantic parser accepts the intermediate output and returns the target logical form. Furthermore, the entire training process is split into two phases: pre-training and cycle learning. Three tailored self-supervised tasks are introduced throughout training to activate the unsupervised paraphrase model. Experimental results on benchmarks OVERNIGHT and GE-OGRANNO demonstrate that our framework is effective and compatible with supervised training.","unsupervised dual paraphrasing - stage semantic parsing daunting problem semantic parsing scarcity annotation . aim reduce nontrivial human labor , propose - stage semantic parsing framework , stage utilize unsupervised paraphrase model convert unlabeled natural language utterance canonical utterance . downstream naive semantic parser accept intermediate output return target logical form . furthermore , entire training process split phase : pre - training cycle learning . tailored self - supervise task introduce training activate unsupervised paraphrase model . experimental result benchmark overnight ge - ogranno demonstrate framework effective compatible supervise training .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Word-level Textual Adversarial Attacking as Combinatorial Optimization,"Adversarial attacks are carried out to reveal the vulnerability of deep neural networks. Textual adversarial attacking is challenging because text is discrete and a small perturbation can bring significant change to the original input. Word-level attacking, which can be regarded as a combinatorial optimization problem, is a well-studied class of textual attack methods. However, existing word-level attack models are far from perfect, largely because unsuitable search space reduction methods and inefficient optimization algorithms are employed. In this paper, we propose a novel attack model, which incorporates the sememebased word substitution method and particle swarm optimization-based search algorithm to solve the two problems separately. We conduct exhaustive experiments to evaluate our attack model by attacking BiLSTM and BERT on three benchmark datasets. Experimental results demonstrate that our model consistently achieves much higher attack success rates and crafts more high-quality adversarial examples as compared to baseline methods. Also, further experiments show our model has higher transferability and can bring more robustness enhancement to victim models by adversarial training. All the code and data of this paper can be obtained on https://github.com/ thunlp/SememePSO-Attack.","Word-level Textual Adversarial Attacking as Combinatorial Optimization Adversarial attacks are carried out to reveal the vulnerability of deep neural networks. Textual adversarial attacking is challenging because text is discrete and a small perturbation can bring significant change to the original input. Word-level attacking, which can be regarded as a combinatorial optimization problem, is a well-studied class of textual attack methods. However, existing word-level attack models are far from perfect, largely because unsuitable search space reduction methods and inefficient optimization algorithms are employed. In this paper, we propose a novel attack model, which incorporates the sememebased word substitution method and particle swarm optimization-based search algorithm to solve the two problems separately. We conduct exhaustive experiments to evaluate our attack model by attacking BiLSTM and BERT on three benchmark datasets. Experimental results demonstrate that our model consistently achieves much higher attack success rates and crafts more high-quality adversarial examples as compared to baseline methods. Also, further experiments show our model has higher transferability and can bring more robustness enhancement to victim models by adversarial training. All the code and data of this paper can be obtained on https://github.com/ thunlp/SememePSO-Attack.","word - level textual adversarial attacking combinatorial optimization adversarial attack carry reveal vulnerability deep neural network . textual adversarial attacking challenging text discrete small perturbation bring significant change original input . word - level attacking , regard combinatorial optimization problem , - study class textual attack method . , exist word - level attack model far perfect , largely unsuitable search space reduction method inefficient optimization algorithm employ . paper , propose novel attack model , incorporate sememebased word substitution method particle swarm optimization - base search algorithm solve problem separately . conduct exhaustive experiment evaluate attack model attack bilstm bert benchmark dataset . experimental result demonstrate model consistently achieve high attack success rate craft high - quality adversarial example compare baseline method . , experiment model high transferability bring robustness enhancement victim model adversarial training . code datum paper obtain https://github.com/ thunlp / sememepso - attack .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Universal Decompositional Semantic Parsing,"We introduce a transductive model for parsing into Universal Decompositional Semantics (UDS) representations, which jointly learns to map natural language utterances into UDS graph structures and annotate the graph with decompositional semantic attribute scores. We also introduce a strong pipeline model for parsing into the UDS graph structure, and show that our transductive parser performs comparably while additionally performing attribute prediction. By analyzing the attribute prediction errors, we find the model captures natural relationships between attribute groups.","Universal Decompositional Semantic Parsing We introduce a transductive model for parsing into Universal Decompositional Semantics (UDS) representations, which jointly learns to map natural language utterances into UDS graph structures and annotate the graph with decompositional semantic attribute scores. We also introduce a strong pipeline model for parsing into the UDS graph structure, and show that our transductive parser performs comparably while additionally performing attribute prediction. By analyzing the attribute prediction errors, we find the model captures natural relationships between attribute groups.","universal decompositional semantic parsing introduce transductive model parse universal decompositional semantics ( uds ) representation , jointly learn map natural language utterance uds graph structure annotate graph decompositional semantic attribute score . introduce strong pipeline model parse uds graph structure , transductive parser perform comparably additionally perform attribute prediction . analyze attribute prediction error , find model capture natural relationship attribute group .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers,"When translating natural language questions into SQL queries to answer questions from a database, contemporary semantic parsing models struggle to generalize to unseen database schemas. The generalization challenge lies in (a) encoding the database relations in an accessible way for the semantic parser, and (b) modeling alignment between database columns and their mentions in a given query. We present a unified framework, based on the relation-aware self-attention mechanism, to address schema encoding, schema linking, and feature representation within a text-to-SQL encoder. On the challenging Spider dataset this framework boosts the exact match accuracy to 57.2%, surpassing its best counterparts by 8.7% absolute improvement. Further augmented with BERT, it achieves the new state-of-the-art performance of 65.6% on the Spider leaderboard. In addition, we observe qualitative improvements in the model's understanding of schema linking and alignment. Our implementation will be open-sourced at https://github.com/Microsoft/rat-sql.","RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers When translating natural language questions into SQL queries to answer questions from a database, contemporary semantic parsing models struggle to generalize to unseen database schemas. The generalization challenge lies in (a) encoding the database relations in an accessible way for the semantic parser, and (b) modeling alignment between database columns and their mentions in a given query. We present a unified framework, based on the relation-aware self-attention mechanism, to address schema encoding, schema linking, and feature representation within a text-to-SQL encoder. On the challenging Spider dataset this framework boosts the exact match accuracy to 57.2%, surpassing its best counterparts by 8.7% absolute improvement. Further augmented with BERT, it achieves the new state-of-the-art performance of 65.6% on the Spider leaderboard. In addition, we observe qualitative improvements in the model's understanding of schema linking and alignment. Our implementation will be open-sourced at https://github.com/Microsoft/rat-sql.","rat - sql : relation - aware schema encoding linking text - - sql parser translate natural language question sql query answer question database , contemporary semantic parsing model struggle generalize unseen database schema . generalization challenge lie ( ) encode database relation accessible way semantic parser , ( b ) model alignment database column mention give query . present unified framework , base relation - aware self - attention mechanism , address schema encoding , schema linking , feature representation text - - sql encoder . challenging spider dataset framework boost exact match accuracy 57.2 % , surpass good counterpart 8.7 % absolute improvement . augment bert , achieve new state - - - art performance 65.6 % spider leaderboard . addition , observe qualitative improvement model understanding schema linking alignment . implementation open - source https://github.com/microsoft/rat-sql .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 3, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Predicting the Focus of Negation: Model and Error Analysis,"The focus of a negation is the set of tokens intended to be negated, and a key component for revealing affirmative alternatives to negated utterances. In this paper, we experiment with neural networks to predict the focus of negation. Our main novelty is leveraging a scope detector to introduce the scope of negation as an additional input to the network. Experimental results show that doing so obtains the best results to date. Additionally, we perform a detailed error analysis providing insights into the main error categories, and analyze errors depending on whether the model takes into account scope and context information.","Predicting the Focus of Negation: Model and Error Analysis The focus of a negation is the set of tokens intended to be negated, and a key component for revealing affirmative alternatives to negated utterances. In this paper, we experiment with neural networks to predict the focus of negation. Our main novelty is leveraging a scope detector to introduce the scope of negation as an additional input to the network. Experimental results show that doing so obtains the best results to date. Additionally, we perform a detailed error analysis providing insights into the main error categories, and analyze errors depending on whether the model takes into account scope and context information.","predict focus negation : model error analysis focus negation set token intend negate , key component reveal affirmative alternative negate utterance . paper , experiment neural network predict focus negation . main novelty leverage scope detector introduce scope negation additional input network . experimental result obtain good result date . additionally , perform detailed error analysis provide insight main error category , analyze error depend model take account scope context information .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Unsupervised Cross-lingual Representation Learning at Scale,"This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of crosslingual transfer tasks. We train a Transformerbased masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6% average accuracy on XNLI, +13% average F1 score on MLQA, and +2.4% F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7% in XNLI accuracy for Swahili and 11.4% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing perlanguage performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code, data and models publicly available. 1","Unsupervised Cross-lingual Representation Learning at Scale This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of crosslingual transfer tasks. We train a Transformerbased masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6% average accuracy on XNLI, +13% average F1 score on MLQA, and +2.4% F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7% in XNLI accuracy for Swahili and 11.4% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing perlanguage performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code, data and models publicly available. 1","unsupervised cross - lingual representation learning scale paper show pretraine multilingual language model scale lead significant performance gain wide range crosslingual transfer task . train transformerbased mask language model language , terabyte filter commoncrawl datum . model , dub xlm - r , significantly outperform multilingual bert ( mbert ) variety cross - lingual benchmark , include +14.6 % average accuracy xnli , +13 % average f1 score mlqa , +2.4 % f1 score ner . xlm - r perform particularly low - resource language , improve 15.7 % xnli accuracy swahili 11.4 % urdu previous xlm model . present detailed empirical analysis key factor require achieve gain , include trade - off ( 1 ) positive transfer capacity dilution ( 2 ) performance high low resource language scale . finally , , time , possibility multilingual modeling sacrifice perlanguage performance ; xlm - r competitive strong monolingual model glue xnli benchmark . code , datum model publicly available . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 1, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Sentence Meta-Embeddings for Unsupervised Semantic Textual Similarity,"We address the task of unsupervised Semantic Textual Similarity (STS) by ensembling diverse pre-trained sentence encoders into sentence meta-embeddings. We apply, extend and evaluate different meta-embedding methods from the word embedding literature at the sentence level, including dimensionality reduction (Yin and SchÃ¼tze, 2016), generalized Canonical Correlation Analysis (Rastogi et al., 2015) and cross-view auto-encoders (Bollegala and Bao, 2018). Our sentence metaembeddings set a new unsupervised State of The Art (SoTA) on the STS Benchmark and on the STS12-STS16 datasets, with gains of between 3.7% and 6.4% Pearson's r over singlesource systems.","Sentence Meta-Embeddings for Unsupervised Semantic Textual Similarity We address the task of unsupervised Semantic Textual Similarity (STS) by ensembling diverse pre-trained sentence encoders into sentence meta-embeddings. We apply, extend and evaluate different meta-embedding methods from the word embedding literature at the sentence level, including dimensionality reduction (Yin and SchÃ¼tze, 2016), generalized Canonical Correlation Analysis (Rastogi et al., 2015) and cross-view auto-encoders (Bollegala and Bao, 2018). Our sentence metaembeddings set a new unsupervised State of The Art (SoTA) on the STS Benchmark and on the STS12-STS16 datasets, with gains of between 3.7% and 6.4% Pearson's r over singlesource systems.","sentence meta - embedding unsupervised semantic textual similarity address task unsupervised semantic textual similarity ( sts ) ensemble diverse pre - trained sentence encoder sentence meta - embedding . apply , extend evaluate different meta - embedding method word embedding literature sentence level , include dimensionality reduction ( yin schÃ¼tze , 2016 ) , generalized canonical correlation analysis ( rastogi et al . , 2015 ) cross - view auto - encoder ( bollegala bao , 2018 ) . sentence metaembedding set new unsupervised state art ( sota ) sts benchmark sts12 - sts16 dataset , gain 3.7 % 6.4 % pearson r singlesource system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Emerging Cross-lingual Structure in Pretrained Language Models,"We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from monolingual BERT models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries are automatically discovered and aligned during the joint training process. * Equal contribution. Work done while Shijie was interning at Facebook AI.","Emerging Cross-lingual Structure in Pretrained Language Models We study the problem of multilingual masked language modeling, i.e. the training of a single model on concatenated text from multiple languages, and present a detailed study of several factors that influence why these models are so effective for cross-lingual transfer. We show, contrary to what was previously hypothesized, that transfer is possible even when there is no shared vocabulary across the monolingual corpora and also when the text comes from very different domains. The only requirement is that there are some shared parameters in the top layers of the multi-lingual encoder. To better understand this result, we also show that representations from monolingual BERT models in different languages can be aligned post-hoc quite effectively, strongly suggesting that, much like for non-contextual word embeddings, there are universal latent symmetries in the learned embedding spaces. For multilingual masked language modeling, these symmetries are automatically discovered and aligned during the joint training process. * Equal contribution. Work done while Shijie was interning at Facebook AI.","emerge cross - lingual structure pretrained language model study problem multilingual mask language modeling , i.e. training single model concatenate text multiple language , present detailed study factor influence model effective cross - lingual transfer . , contrary previously hypothesize , transfer possible share vocabulary monolingual corpora text come different domain . requirement share parameter layer multi - lingual encoder . well understand result , representation monolingual bert model different language align post - hoc effectively , strongly suggest , like non - contextual word embedding , universal latent symmetry learn embedding space . multilingual mask language modeling , symmetry automatically discover align joint training process . * equal contribution . work shijie intern facebook ai .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Transition-based Semantic Dependency Parsing with Pointer Networks,"Transition-based parsers implemented with Pointer Networks have become the new state of the art in dependency parsing, excelling in producing labelled syntactic trees and outperforming graph-based models in this task. In order to further test the capabilities of these powerful neural networks on a harder NLP problem, we propose a transition system that, thanks to Pointer Networks, can straightforwardly produce labelled directed acyclic graphs and perform semantic dependency parsing. In addition, we enhance our approach with deep contextualized word embeddings extracted from BERT. The resulting system not only outperforms all existing transitionbased models, but also matches the best fullysupervised accuracy to date on the SemEval 2015 Task 18 English datasets among previous state-of-the-art graph-based parsers.","Transition-based Semantic Dependency Parsing with Pointer Networks Transition-based parsers implemented with Pointer Networks have become the new state of the art in dependency parsing, excelling in producing labelled syntactic trees and outperforming graph-based models in this task. In order to further test the capabilities of these powerful neural networks on a harder NLP problem, we propose a transition system that, thanks to Pointer Networks, can straightforwardly produce labelled directed acyclic graphs and perform semantic dependency parsing. In addition, we enhance our approach with deep contextualized word embeddings extracted from BERT. The resulting system not only outperforms all existing transitionbased models, but also matches the best fullysupervised accuracy to date on the SemEval 2015 Task 18 English datasets among previous state-of-the-art graph-based parsers.","transition - base semantic dependency parsing pointer networks transition - base parser implement pointer networks new state art dependency parsing , excel produce label syntactic tree outperform graph - base model task . order test capability powerful neural network hard nlp problem , propose transition system , thank pointer networks , straightforwardly produce label direct acyclic graph perform semantic dependency parsing . addition , enhance approach deep contextualized word embedding extract bert . result system outperform exist transitionbased model , match good fullysupervised accuracy date semeval 2015 task 18 english dataset previous state - - - art graph - base parser .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 12, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",AMR Parsing with Latent Structural Information,"Meaning Representations (AMRs) capture sentence-level semantics structural representations to broad-coverage natural sentences. We investigate parsing AMR with explicit dependency structures and interpretable latent structures. We generate the latent soft structure without additional annotations, and fuse both dependency and latent structure via an extended graph neural networks. The fused structural information helps our experiments results to achieve the best reported results on both AMR 2.0 (77.5% Smatch F1 on LDC2017T10) and AMR 1.0 (71.8% Smatch F1 on LDC2014T12).","AMR Parsing with Latent Structural Information Meaning Representations (AMRs) capture sentence-level semantics structural representations to broad-coverage natural sentences. We investigate parsing AMR with explicit dependency structures and interpretable latent structures. We generate the latent soft structure without additional annotations, and fuse both dependency and latent structure via an extended graph neural networks. The fused structural information helps our experiments results to achieve the best reported results on both AMR 2.0 (77.5% Smatch F1 on LDC2017T10) and AMR 1.0 (71.8% Smatch F1 on LDC2014T12).","amr parsing latent structural information meaning representation ( amrs ) capture sentence - level semantic structural representation broad - coverage natural sentence . investigate parse amr explicit dependency structure interpretable latent structure . generate latent soft structure additional annotation , fuse dependency latent structure extended graph neural network . fuse structural information help experiment result achieve good report result amr 2.0 ( 77.5 % smatch f1 ldc2017t10 ) amr 1.0 ( 71.8 % smatch f1 ldc2014t12 ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data,"Recent years have witnessed the burgeoning of pretrained language models (LMs) for textbased natural language (NL) understanding tasks. Such models are typically trained on free-form NL text, hence may not be suitable for tasks like semantic parsing over structured data, which require reasoning over both free-form NL questions and structured tabular data (e.g., database tables). In this paper we present TABERT, a pretrained LM that jointly learns representations for NL sentences and (semi-)structured tables. TABERT is trained on a large corpus of 26 million tables and their English contexts. In experiments, neural semantic parsers using TABERT as feature representation layers achieve new best results on the challenging weakly-supervised semantic parsing benchmark WIKITABLEQUESTIONS, while performing competitively on the text-to-SQL dataset SPIDER. 1","TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data Recent years have witnessed the burgeoning of pretrained language models (LMs) for textbased natural language (NL) understanding tasks. Such models are typically trained on free-form NL text, hence may not be suitable for tasks like semantic parsing over structured data, which require reasoning over both free-form NL questions and structured tabular data (e.g., database tables). In this paper we present TABERT, a pretrained LM that jointly learns representations for NL sentences and (semi-)structured tables. TABERT is trained on a large corpus of 26 million tables and their English contexts. In experiments, neural semantic parsers using TABERT as feature representation layers achieve new best results on the challenging weakly-supervised semantic parsing benchmark WIKITABLEQUESTIONS, while performing competitively on the text-to-SQL dataset SPIDER. 1","tabert : pretraine joint understanding textual tabular datum recent year witness burgeoning pretrained language model ( lms ) textbased natural language ( nl ) understanding task . model typically train free - form nl text , suitable task like semantic parsing structured datum , require reasoning free - form nl question structured tabular datum ( e.g. , database table ) . paper present tabert , pretrained lm jointly learn representation nl sentence ( semi-)structured table . tabert train large corpus 26 million table english context . experiment , neural semantic parser tabert feature representation layer achieve new good result challenge weakly - supervise semantic parsing benchmark wikitablequestions , perform competitively text - - sql dataset spider . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 2, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 12, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",TaPas: Weakly Supervised Table Parsing via Pre-training,"Answering natural language questions over tables is usually seen as a semantic parsing task. To alleviate the collection cost of full logical forms, one popular approach focuses on weak supervision consisting of denotations instead of logical forms. However, training semantic parsers from weak supervision poses difficulties, and in addition, the generated logical forms are only used as an intermediate step prior to retrieving the denotation. In this paper, we present TAPAS, an approach to question answering over tables without generating logical forms. TAPAS trains from weak supervision, and predicts the denotation by selecting table cells and optionally applying a corresponding aggregation operator to such selection. TAPAS extends BERT's architecture to encode tables as input, initializes from an effective joint pre-training of text segments and tables crawled from Wikipedia, and is trained end-to-end. We experiment with three different semantic parsing datasets, and find that TAPAS outperforms or rivals semantic parsing models by improving state-of-the-art accuracy on SQA from 55.1 to 67.2 and performing on par with the state-of-the-art on WIKISQL and WIKITQ, but with a simpler model architecture. We additionally find that transfer learning, which is trivial in our setting, from WIK-ISQL to WIKITQ, yields 48.7 accuracy, 4.2 points above the state-of-the-art.","TaPas: Weakly Supervised Table Parsing via Pre-training Answering natural language questions over tables is usually seen as a semantic parsing task. To alleviate the collection cost of full logical forms, one popular approach focuses on weak supervision consisting of denotations instead of logical forms. However, training semantic parsers from weak supervision poses difficulties, and in addition, the generated logical forms are only used as an intermediate step prior to retrieving the denotation. In this paper, we present TAPAS, an approach to question answering over tables without generating logical forms. TAPAS trains from weak supervision, and predicts the denotation by selecting table cells and optionally applying a corresponding aggregation operator to such selection. TAPAS extends BERT's architecture to encode tables as input, initializes from an effective joint pre-training of text segments and tables crawled from Wikipedia, and is trained end-to-end. We experiment with three different semantic parsing datasets, and find that TAPAS outperforms or rivals semantic parsing models by improving state-of-the-art accuracy on SQA from 55.1 to 67.2 and performing on par with the state-of-the-art on WIKISQL and WIKITQ, but with a simpler model architecture. We additionally find that transfer learning, which is trivial in our setting, from WIK-ISQL to WIKITQ, yields 48.7 accuracy, 4.2 points above the state-of-the-art.","tapas : weakly supervise table parsing pre - train answer natural language question table usually see semantic parsing task . alleviate collection cost logical form , popular approach focus weak supervision consist denotation instead logical form . , train semantic parser weak supervision pose difficulty , addition , generate logical form intermediate step prior retrieve denotation . paper , present tapas , approach question answering table generate logical form . tapas train weak supervision , predict denotation select table cell optionally apply correspond aggregation operator selection . tapas extend bert architecture encode table input , initialize effective joint pre - training text segment table crawl wikipedia , train end - - end . experiment different semantic parsing dataset , find tapas outperform rival semantic parsing model improve state - - - art accuracy sqa 55.1 67.2 perform par state - - - art wikisql wikitq , simple model architecture . additionally find transfer learning , trivial setting , wik - isql wikitq , yield 48.7 accuracy , 4.2 point state - - - art .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 8, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 17, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Cross-Lingual Semantic Role Labeling with High-Quality Translated Training Corpus,"Many efforts of research are devoted to semantic role labeling (SRL) which is crucial for natural language understanding. Supervised approaches have achieved impressing performances when large-scale corpora are available for resource-rich languages such as English. While for the low-resource languages with no annotated SRL dataset, it is still challenging to obtain competitive performances. Cross-lingual SRL is one promising way to address the problem, which has achieved great advances with the help of model transferring and annotation projection. In this paper, we propose a novel alternative based on corpus translation, constructing high-quality training datasets for the target languages from the source gold-standard SRL annotations. Experimental results on Universal Proposition Bank show that the translation-based method is highly effective, and the automatic pseudo datasets can improve the target-language SRL performances significantly.","Cross-Lingual Semantic Role Labeling with High-Quality Translated Training Corpus Many efforts of research are devoted to semantic role labeling (SRL) which is crucial for natural language understanding. Supervised approaches have achieved impressing performances when large-scale corpora are available for resource-rich languages such as English. While for the low-resource languages with no annotated SRL dataset, it is still challenging to obtain competitive performances. Cross-lingual SRL is one promising way to address the problem, which has achieved great advances with the help of model transferring and annotation projection. In this paper, we propose a novel alternative based on corpus translation, constructing high-quality training datasets for the target languages from the source gold-standard SRL annotations. Experimental results on Universal Proposition Bank show that the translation-based method is highly effective, and the automatic pseudo datasets can improve the target-language SRL performances significantly.","cross - lingual semantic role labeling high - quality translate training corpus effort research devote semantic role labeling ( srl ) crucial natural language understanding . supervised approach achieve impress performance large - scale corpus available resource - rich language english . low - resource language annotate srl dataset , challenging obtain competitive performance . cross - lingual srl promising way address problem , achieve great advance help model transferring annotation projection . paper , propose novel alternative base corpus translation , construct high - quality training dataset target language source gold - standard srl annotation . experimental result universal proposition bank translation - base method highly effective , automatic pseudo dataset improve target - language srl performance significantly .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",AMR Parsing via Graph-Sequence Iterative Inference,"We propose a new end-to-end model that treats AMR parsing as a series of dual decisions on the input sequence and the incrementally constructed graph. At each time step, our model performs multiple rounds of attention, reasoning, and composition that aim to answer two critical questions: (1) which part of the input sequence to abstract; and (2) where in the output graph to construct the new concept. We show that the answers to these two questions are mutually causalities. We design a model based on iterative inference that helps achieve better answers in both perspectives, leading to greatly improved parsing accuracy. Our experimental results significantly outperform all previously reported SMATCH scores by large margins. Remarkably, without the help of any large-scale pre-trained language model (e.g., BERT), our model already surpasses previous state-of-the-art using BERT. With the help of BERT, we can push the state-of-the-art results to 80.2% on LDC2017T10 (AMR 2.0) and 75.4% on LDC2014T12 (AMR 1.0).","AMR Parsing via Graph-Sequence Iterative Inference We propose a new end-to-end model that treats AMR parsing as a series of dual decisions on the input sequence and the incrementally constructed graph. At each time step, our model performs multiple rounds of attention, reasoning, and composition that aim to answer two critical questions: (1) which part of the input sequence to abstract; and (2) where in the output graph to construct the new concept. We show that the answers to these two questions are mutually causalities. We design a model based on iterative inference that helps achieve better answers in both perspectives, leading to greatly improved parsing accuracy. Our experimental results significantly outperform all previously reported SMATCH scores by large margins. Remarkably, without the help of any large-scale pre-trained language model (e.g., BERT), our model already surpasses previous state-of-the-art using BERT. With the help of BERT, we can push the state-of-the-art results to 80.2% on LDC2017T10 (AMR 2.0) and 75.4% on LDC2014T12 (AMR 1.0).","amr parsing graph - sequence iterative inference propose new end - - end model treat amr parsing series dual decision input sequence incrementally construct graph . time step , model perform multiple round attention , reasoning , composition aim answer critical question : ( 1 ) input sequence abstract ; ( 2 ) output graph construct new concept . answer question mutually causality . design model base iterative inference help achieve well answer perspective , lead greatly improve parsing accuracy . experimental result significantly outperform previously report smatch score large margin . remarkably , help large - scale pre - trained language model ( e.g. , bert ) , model surpass previous state - - - art bert . help bert , push state - - - art result 80.2 % ldc2017t10 ( amr 2.0 ) 75.4 % ldc2014t12 ( amr 1.0 ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 5, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Estimating Mutual Information Between Dense Word Embeddings,"Word embedding-based similarity measures are currently among the top-performing methods on unsupervised semantic textual similarity (STS) tasks. Recent work has increasingly adopted a statistical view on these embeddings, with some of the top approaches being essentially various correlations (which include the famous cosine similarity). Another excellent candidate for a similarity measure is mutual information (MI), which can capture arbitrary dependencies between the variables and has a simple and intuitive expression. Unfortunately, its use in the context of dense word embeddings has so far been avoided due to difficulties with estimating MI for continuous data. In this work we go through a vast literature on estimating MI in such cases and single out the most promising methods, yielding a simple and elegant similarity measure for word embeddings. We show that mutual information is a viable alternative to correlations, gives an excellent signal that correlates well with human judgements of similarity and rivals existing state-of-the-art unsupervised methods.","Estimating Mutual Information Between Dense Word Embeddings Word embedding-based similarity measures are currently among the top-performing methods on unsupervised semantic textual similarity (STS) tasks. Recent work has increasingly adopted a statistical view on these embeddings, with some of the top approaches being essentially various correlations (which include the famous cosine similarity). Another excellent candidate for a similarity measure is mutual information (MI), which can capture arbitrary dependencies between the variables and has a simple and intuitive expression. Unfortunately, its use in the context of dense word embeddings has so far been avoided due to difficulties with estimating MI for continuous data. In this work we go through a vast literature on estimating MI in such cases and single out the most promising methods, yielding a simple and elegant similarity measure for word embeddings. We show that mutual information is a viable alternative to correlations, gives an excellent signal that correlates well with human judgements of similarity and rivals existing state-of-the-art unsupervised methods.","estimate mutual information dense word embedding word embedding - base similarity measure currently - perform method unsupervised semantic textual similarity ( sts ) task . recent work increasingly adopt statistical view embedding , approach essentially correlation ( include famous cosine similarity ) . excellent candidate similarity measure mutual information ( mi ) , capture arbitrary dependency variable simple intuitive expression . unfortunately , use context dense word embedding far avoid difficulty estimate mi continuous datum . work vast literature estimate mi case single promising method , yield simple elegant similarity measure word embedding . mutual information viable alternative correlation , give excellent signal correlate human judgement similarity rival exist state - - - art unsupervised method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",AMR-To-Text Generation with Graph Transformer,"meaning representation (AMR)-totext generation is the challenging task of generating natural language texts from AMR graphs, where nodes represent concepts and edges denote relations. The current state-of-the-art methods use graph-to-sequence models; however, they still cannot significantly outperform the previous sequence-to-sequence models or statistical approaches. In this paper, we propose a novel graph-to-sequence model (Graph  Transformer)  to address this task. The model directly encodes the AMR graphs and learns the node representations. A pairwise interaction function is used for computing the semantic relations between the concepts. Moreover, attention mechanisms are used for aggregating the information from the incoming and outgoing neighbors, which help the model to capture the semantic information effectively. Our model outperforms the state-of-the-art neural approach by 1.5 BLEU points on LDC2015E86 and 4.8 BLEU points on LDC2017T10 and achieves new state-of-the-art performances.","AMR-To-Text Generation with Graph Transformer meaning representation (AMR)-totext generation is the challenging task of generating natural language texts from AMR graphs, where nodes represent concepts and edges denote relations. The current state-of-the-art methods use graph-to-sequence models; however, they still cannot significantly outperform the previous sequence-to-sequence models or statistical approaches. In this paper, we propose a novel graph-to-sequence model (Graph  Transformer)  to address this task. The model directly encodes the AMR graphs and learns the node representations. A pairwise interaction function is used for computing the semantic relations between the concepts. Moreover, attention mechanisms are used for aggregating the information from the incoming and outgoing neighbors, which help the model to capture the semantic information effectively. Our model outperforms the state-of-the-art neural approach by 1.5 BLEU points on LDC2015E86 and 4.8 BLEU points on LDC2017T10 and achieves new state-of-the-art performances.","amr - - text generation graph transformer meaning representation ( amr)-totext generation challenging task generate natural language text amr graph , node represent concept edge denote relation . current state - - - art method use graph - - sequence model ; , significantly outperform previous sequence - - sequence model statistical approach . paper , propose novel graph - - sequence model ( graph   transformer )   address task . model directly encode amr graph learn node representation . pairwise interaction function compute semantic relation concept . , attention mechanism aggregate information incoming outgoing neighbor , help model capture semantic information effectively . model outperform state - - - art neural approach 1.5 bleu point ldc2015e86 4.8 bleu point ldc2017t10 achieve new state - - - art performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 14, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 8, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Temporal Common Sense Acquisition with Minimal Supervision,"Temporal common sense (e.g., duration and frequency of events) is crucial for understanding natural language. However, its acquisition is challenging, partly because such information is often not expressed explicitly in text, and human annotation on such concepts is costly. This work proposes a novel sequence modeling approach that exploits explicit and implicit mentions of temporal common sense, extracted from a large corpus, to build TACOLM, 1 a temporal common sense language model. Our method is shown to give quality predictions of various dimensions of temporal common sense (on UDST and a newly collected dataset from Real-News). It also produces representations of events for relevant tasks such as duration comparison, parent-child relations, event coreference and temporal QA (on TimeBank, HiEVE and MCTACO) that are better than using the standard BERT. Thus, it will be an important component of temporal NLP.","Temporal Common Sense Acquisition with Minimal Supervision Temporal common sense (e.g., duration and frequency of events) is crucial for understanding natural language. However, its acquisition is challenging, partly because such information is often not expressed explicitly in text, and human annotation on such concepts is costly. This work proposes a novel sequence modeling approach that exploits explicit and implicit mentions of temporal common sense, extracted from a large corpus, to build TACOLM, 1 a temporal common sense language model. Our method is shown to give quality predictions of various dimensions of temporal common sense (on UDST and a newly collected dataset from Real-News). It also produces representations of events for relevant tasks such as duration comparison, parent-child relations, event coreference and temporal QA (on TimeBank, HiEVE and MCTACO) that are better than using the standard BERT. Thus, it will be an important component of temporal NLP.","temporal common sense acquisition minimal supervision temporal common sense ( e.g. , duration frequency event ) crucial understand natural language . , acquisition challenging , partly information express explicitly text , human annotation concept costly . work propose novel sequence modeling approach exploit explicit implicit mention temporal common sense , extract large corpus , build tacolm , 1 temporal common sense language model . method show quality prediction dimension temporal common sense ( udst newly collect dataset real - news ) . produce representation event relevant task duration comparison , parent - child relation , event coreference temporal qa ( timebank , hieve mctaco ) well standard bert . , important component temporal nlp .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Neural Mixed Counting Models for Dispersed Topic Discovery,"Mixed counting models that use the negative binomial distribution as the prior can well model over-dispersed and hierarchically dependent random variables; thus they have attracted much attention in mining dispersed document topics. However, the existing parameter inference method like Monte Carlo sampling is quite time-consuming. In this paper, we propose two efficient neural mixed counting models, i.e., the Negative Binomial-Neural Topic Model (NB-NTM) and the Gamma Negative Binomial-Neural Topic Model (GNB-NTM) for dispersed topic discovery. Neural variational inference algorithms are developed to infer model parameters by using the reparameterization of Gamma distribution and the Gaussian approximation of Poisson distribution. Experiments on real-world datasets indicate that our models outperform state-of-theart baseline models in terms of perplexity and topic coherence. The results also validate that both NB-NTM and GNB-NTM can produce explainable intermediate variables by generating dispersed proportions of document topics.","Neural Mixed Counting Models for Dispersed Topic Discovery Mixed counting models that use the negative binomial distribution as the prior can well model over-dispersed and hierarchically dependent random variables; thus they have attracted much attention in mining dispersed document topics. However, the existing parameter inference method like Monte Carlo sampling is quite time-consuming. In this paper, we propose two efficient neural mixed counting models, i.e., the Negative Binomial-Neural Topic Model (NB-NTM) and the Gamma Negative Binomial-Neural Topic Model (GNB-NTM) for dispersed topic discovery. Neural variational inference algorithms are developed to infer model parameters by using the reparameterization of Gamma distribution and the Gaussian approximation of Poisson distribution. Experiments on real-world datasets indicate that our models outperform state-of-theart baseline models in terms of perplexity and topic coherence. The results also validate that both NB-NTM and GNB-NTM can produce explainable intermediate variables by generating dispersed proportions of document topics.","neural mixed counting models dispersed topic discovery mixed counting model use negative binomial distribution prior model - dispersed hierarchically dependent random variable ; attract attention mine disperse document topic . , exist parameter inference method like monte carlo sampling time - consume . paper , propose efficient neural mix counting model , i.e. , negative binomial - neural topic model ( nb - ntm ) gamma negative binomial - neural topic model ( gnb - ntm ) disperse topic discovery . neural variational inference algorithm develop infer model parameter reparameterization gamma distribution gaussian approximation poisson distribution . experiment real - world dataset indicate model outperform state - - theart baseline model term perplexity topic coherence . result validate nb - ntm gnb - ntm produce explainable intermediate variable generate disperse proportion document topic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 12, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?,"Despite the success of language models using neural networks, it remains unclear to what extent neural models have the generalization ability to perform inferences. In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition. We consider four aspects of monotonicity inferences and test whether the models can systematically interpret lexical and logical phenomena on different training/test splits. A series of experiments show that three neural models systematically draw inferences on unseen combinations of lexical and logical phenomena when the syntactic structures of the sentences are similar between the training and test sets. However, the performance of the models significantly decreases when the structures are slightly changed in the test set while retaining all vocabularies and constituents already appearing in the training set. This indicates that the generalization ability of neural models is limited to cases where the syntactic structures are nearly the same as those in the training set. (1) P : Some [puppies â†‘] ran. H: Some dogs ran. (2) P : No [cats â†“] ran. H: No small cats ran. (3) P : Some [puppies which chased no [cats â†“]] ran. H: Some dogs which chased no small cats ran.","Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language? Despite the success of language models using neural networks, it remains unclear to what extent neural models have the generalization ability to perform inferences. In this paper, we introduce a method for evaluating whether neural models can learn systematicity of monotonicity inference in natural language, namely, the regularity for performing arbitrary inferences with generalization on composition. We consider four aspects of monotonicity inferences and test whether the models can systematically interpret lexical and logical phenomena on different training/test splits. A series of experiments show that three neural models systematically draw inferences on unseen combinations of lexical and logical phenomena when the syntactic structures of the sentences are similar between the training and test sets. However, the performance of the models significantly decreases when the structures are slightly changed in the test set while retaining all vocabularies and constituents already appearing in the training set. This indicates that the generalization ability of neural models is limited to cases where the syntactic structures are nearly the same as those in the training set. (1) P : Some [puppies â†‘] ran. H: Some dogs ran. (2) P : No [cats â†“] ran. H: No small cats ran. (3) P : Some [puppies which chased no [cats â†“]] ran. H: Some dogs which chased no small cats ran.","neural model learn systematicity monotonicity inference natural language ? despite success language model neural network , remain unclear extent neural model generalization ability perform inference . paper , introduce method evaluate neural model learn systematicity monotonicity inference natural language , , regularity perform arbitrary inference generalization composition . consider aspect monotonicity inference test model systematically interpret lexical logical phenomenon different training / test split . series experiment neural model systematically draw inference unseen combination lexical logical phenomenon syntactic structure sentence similar training test set . , performance model significantly decrease structure slightly change test set retain vocabulary constituent appear training set . indicate generalization ability neural model limit case syntactic structure nearly training set . ( 1 ) p : [ puppy â†‘ ] run . h : dog run . ( 2 ) p : [ cat â†“ ] run . h : small cat run . ( 3 ) p : [ puppy chase [ cat â†“ ] ] run . h : dog chase small cat run .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Neural Graph Matching Networks for Chinese Short Text Matching,"Chinese short text matching usually employs word sequences rather than character sequences to get better performance. However, Chinese word segmentation can be erroneous, ambiguous or inconsistent, which consequently hurts the final matching performance. To address this problem, we propose neural graph matching networks, a novel sentence matching framework capable of dealing with multi-granular input information. Instead of a character sequence or a single word sequence, paired word lattices formed from multiple word segmentation hypotheses are used as input and the model learns a graph representation according to an attentive graph matching mechanism. Experiments on two Chinese datasets show that our models outperform the state-of-the-art short text matching models.","Neural Graph Matching Networks for Chinese Short Text Matching Chinese short text matching usually employs word sequences rather than character sequences to get better performance. However, Chinese word segmentation can be erroneous, ambiguous or inconsistent, which consequently hurts the final matching performance. To address this problem, we propose neural graph matching networks, a novel sentence matching framework capable of dealing with multi-granular input information. Instead of a character sequence or a single word sequence, paired word lattices formed from multiple word segmentation hypotheses are used as input and the model learns a graph representation according to an attentive graph matching mechanism. Experiments on two Chinese datasets show that our models outperform the state-of-the-art short text matching models.","neural graph matching network chinese short text matching chinese short text matching usually employ word sequence character sequence well performance . , chinese word segmentation erroneous , ambiguous inconsistent , consequently hurt final matching performance . address problem , propose neural graph matching network , novel sentence matching framework capable deal multi - granular input information . instead character sequence single word sequence , pair word lattice form multiple word segmentation hypothesis input model learn graph representation accord attentive graph matching mechanism . experiment chinese dataset model outperform state - - - art short text matching model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 12, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Generating Fact Checking Explanations,"Most existing work on automated fact checking is concerned with predicting the veracity of claims based on metadata, social network spread, language used in claims, and, more recently, evidence supporting or denying claims. A crucial piece of the puzzle that is still missing is to understand how to automate the most elaborate part of the process -generating justifications for verdicts on claims. This paper provides the first study of how these explanations can be generated automatically based on available claim context, and how this task can be modelled jointly with veracity prediction. Our results indicate that optimising both objectives at the same time, rather than training them separately, improves the performance of a fact checking system. The results of a manual evaluation further suggest that the informativeness, coverage and overall quality of the generated explanations are also improved in the multi-task model. Claim: The last major oil spill from a drilling accident in America happened over 40 years ago in 1969. Ruling Comments: (...) The last major oil spill from a drilling accident in America happened over 40 years ago in 1969. (...) The largest in volume was the Santa Barbara spill of 1969 referenced by Murdock and Johnson, in which an estimated 100,000 barrels of oil spilled into the Pacific Ocean, according to the API. The Santa Barbara spill was so big it ranked seventh among the 10 largest oil spills caused by marine well blowouts in the world, the report states. Two other U.S. spills, both in 1970, rank eighth and 10th. Fourteen marine blowouts have taken place in the U.S. between 1969 and 2007. Six of them took place after 1990 and spilled a total of nearly 13,700 barrels. (...) We interviewed three scientists who said that the impact of a spill has little to do with its volume. Scientists have proven that spills far smaller than Santa Barbara's have been devastating. Justification: While the nation's largest oil well blowout did take place in 1969, it's not factually correct to call it the ""last major oil spill"". First of all, two of the largest blowouts in the world took place in the U. S. the following year. More importantly, experts agree that spills far smaller in volume to the 1969 disaster have been devastating. From a scientific perspective, Johnson's decision to single out the 1969 blowout as the last ""major"" one makes no sense.","Generating Fact Checking Explanations Most existing work on automated fact checking is concerned with predicting the veracity of claims based on metadata, social network spread, language used in claims, and, more recently, evidence supporting or denying claims. A crucial piece of the puzzle that is still missing is to understand how to automate the most elaborate part of the process -generating justifications for verdicts on claims. This paper provides the first study of how these explanations can be generated automatically based on available claim context, and how this task can be modelled jointly with veracity prediction. Our results indicate that optimising both objectives at the same time, rather than training them separately, improves the performance of a fact checking system. The results of a manual evaluation further suggest that the informativeness, coverage and overall quality of the generated explanations are also improved in the multi-task model. Claim: The last major oil spill from a drilling accident in America happened over 40 years ago in 1969. Ruling Comments: (...) The last major oil spill from a drilling accident in America happened over 40 years ago in 1969. (...) The largest in volume was the Santa Barbara spill of 1969 referenced by Murdock and Johnson, in which an estimated 100,000 barrels of oil spilled into the Pacific Ocean, according to the API. The Santa Barbara spill was so big it ranked seventh among the 10 largest oil spills caused by marine well blowouts in the world, the report states. Two other U.S. spills, both in 1970, rank eighth and 10th. Fourteen marine blowouts have taken place in the U.S. between 1969 and 2007. Six of them took place after 1990 and spilled a total of nearly 13,700 barrels. (...) We interviewed three scientists who said that the impact of a spill has little to do with its volume. Scientists have proven that spills far smaller than Santa Barbara's have been devastating. Justification: While the nation's largest oil well blowout did take place in 1969, it's not factually correct to call it the ""last major oil spill"". First of all, two of the largest blowouts in the world took place in the U. S. the following year. More importantly, experts agree that spills far smaller in volume to the 1969 disaster have been devastating. From a scientific perspective, Johnson's decision to single out the 1969 blowout as the last ""major"" one makes no sense.","generate fact checking explanation exist work automate fact checking concern predict veracity claim base metadata , social network spread , language claim , , recently , evidence support deny claim . crucial piece puzzle miss understand automate elaborate process -generate justification verdict claim . paper provide study explanation generate automatically base available claim context , task model jointly veracity prediction . result indicate optimise objective time , train separately , improve performance fact check system . result manual evaluation suggest informativeness , coverage overall quality generate explanation improve multi - task model . claim : major oil spill drilling accident america happen 40 year ago 1969 . ruling comment : ( ... ) major oil spill drilling accident america happen 40 year ago 1969 . ( ... ) large volume santa barbara spill 1969 reference murdock johnson , estimate 100,000 barrel oil spill pacific ocean , accord api . santa barbara spill big rank seventh 10 large oil spill cause marine blowout world , report state . u.s. spill , 1970 , rank eighth 10th . fourteen marine blowout take place u.s. 1969 2007 . take place 1990 spill total nearly 13,700 barrel . ( ... ) interview scientist say impact spill little volume . scientist prove spill far small santa barbara devastating . justification : nation large oil blowout place 1969 , factually correct "" major oil spill "" . , large blowout world take place u. s. follow year . importantly , expert agree spill far small volume 1969 disaster devastating . scientific perspective , johnson decision single 1969 blowout "" major "" make sense .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 5, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 16, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Fine-grained Fact Verification with Kernel Graph Attention Network,"Fact Verification requires fine-grained natural language inference capability that finds subtle clues to identify the syntactical and semantically correct but not well-supported claims. This paper presents Kernel Graph Attention Network (KGAT), which conducts more finegrained fact verification with kernel-based attentions. Given a claim and a set of potential evidence sentences that form an evidence graph, KGAT introduces node kernels, which better measure the importance of the evidence node, and edge kernels, which conduct fine-grained evidence propagation in the graph, into Graph Attention Networks for more accurate fact verification. KGAT achieves a 70.38% FEVER score and significantly outperforms existing fact verification models on FEVER, a large-scale benchmark for fact verification. Our analyses illustrate that, compared to dot-product attentions, the kernelbased attention concentrates more on relevant evidence sentences and meaningful clues in the evidence graph, which is the main source of KGAT's effectiveness. All source codes of this work are available at https://github. com/thunlp/KernelGAT.","Fine-grained Fact Verification with Kernel Graph Attention Network Fact Verification requires fine-grained natural language inference capability that finds subtle clues to identify the syntactical and semantically correct but not well-supported claims. This paper presents Kernel Graph Attention Network (KGAT), which conducts more finegrained fact verification with kernel-based attentions. Given a claim and a set of potential evidence sentences that form an evidence graph, KGAT introduces node kernels, which better measure the importance of the evidence node, and edge kernels, which conduct fine-grained evidence propagation in the graph, into Graph Attention Networks for more accurate fact verification. KGAT achieves a 70.38% FEVER score and significantly outperforms existing fact verification models on FEVER, a large-scale benchmark for fact verification. Our analyses illustrate that, compared to dot-product attentions, the kernelbased attention concentrates more on relevant evidence sentences and meaningful clues in the evidence graph, which is the main source of KGAT's effectiveness. All source codes of this work are available at https://github. com/thunlp/KernelGAT.","fine - grained fact verification kernel graph attention network fact verification require fine - grained natural language inference capability find subtle clue identify syntactical semantically correct - support claim . paper present kernel graph attention network ( kgat ) , conduct finegrained fact verification kernel - base attention . give claim set potential evidence sentence form evidence graph , kgat introduce node kernel , well measure importance evidence node , edge kernel , conduct fine - grained evidence propagation graph , graph attention networks accurate fact verification . kgat achieve 70.38 % fever score significantly outperform exist fact verification model fever , large - scale benchmark fact verification . analysis illustrate , compare dot - product attention , kernelbase attention concentrate relevant evidence sentence meaningful clue evidence graph , main source kgat effectiveness . source code work available https://github . com / thunlp / kernelgat .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 6, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 14, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",QuASE: Question-Answer Driven Sentence Encoding,"Question-answering (QA) data often encodes essential information in many facets. This paper studies a natural question: Can we get supervision from QA data for other tasks (typically, non-QA ones)? For example, can we use QAMR (Michael et al., 2017)  to improve named entity recognition? We suggest that simply further pre-training BERT is often not the best option, and propose the questionanswer driven sentence encoding (QUASE) framework. QUASE learns representations from QA data, using BERT or other state-ofthe-art contextual language models. In particular, we observe the need to distinguish between two types of sentence encodings, depending on whether the target task is a single-or multisentence input; in both cases, the resulting encoding is shown to be an easy-to-use plugin for many downstream tasks. This work may point out an alternative way to supervise NLP tasks. 1","QuASE: Question-Answer Driven Sentence Encoding Question-answering (QA) data often encodes essential information in many facets. This paper studies a natural question: Can we get supervision from QA data for other tasks (typically, non-QA ones)? For example, can we use QAMR (Michael et al., 2017)  to improve named entity recognition? We suggest that simply further pre-training BERT is often not the best option, and propose the questionanswer driven sentence encoding (QUASE) framework. QUASE learns representations from QA data, using BERT or other state-ofthe-art contextual language models. In particular, we observe the need to distinguish between two types of sentence encodings, depending on whether the target task is a single-or multisentence input; in both cases, the resulting encoding is shown to be an easy-to-use plugin for many downstream tasks. This work may point out an alternative way to supervise NLP tasks. 1","quase : question - answer drive sentence encoding question - answering ( qa ) data encode essential information facet . paper study natural question : supervision qa datum task ( typically , non - qa one ) ? example , use qamr ( michael et al . , 2017 )   improve name entity recognition ? suggest simply pre - training bert good option , propose questionanswer drive sentence encoding ( quase ) framework . quase learn representation qa datum , bert state - ofthe - art contextual language model . particular , observe need distinguish type sentence encoding , depend target task single - multisentence input ; case , result encoding show easy - - use plugin downstream task . work point alternative way supervise nlp task . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 13, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Curriculum Learning for Natural Language Understanding,"With the great success of pre-trained language models, the pretrain-finetune paradigm now becomes the undoubtedly dominant solution for natural language understanding (NLU) tasks. At the fine-tune stage, target task data is usually introduced in a completely random order and treated equally. However, examples in NLU tasks can vary greatly in difficulty, and similar to human learning procedure, language models can benefit from an easy-to-difficult curriculum. Based on this idea, we propose our Curriculum Learning approach. By reviewing the trainset in a crossed way, we are able to distinguish easy examples from difficult ones, and arrange a curriculum for language models. Without any manual model architecture design or use of external data, our Curriculum Learning approach obtains significant and universal performance improvements on a wide range of NLU tasks.","Curriculum Learning for Natural Language Understanding With the great success of pre-trained language models, the pretrain-finetune paradigm now becomes the undoubtedly dominant solution for natural language understanding (NLU) tasks. At the fine-tune stage, target task data is usually introduced in a completely random order and treated equally. However, examples in NLU tasks can vary greatly in difficulty, and similar to human learning procedure, language models can benefit from an easy-to-difficult curriculum. Based on this idea, we propose our Curriculum Learning approach. By reviewing the trainset in a crossed way, we are able to distinguish easy examples from difficult ones, and arrange a curriculum for language models. Without any manual model architecture design or use of external data, our Curriculum Learning approach obtains significant and universal performance improvements on a wide range of NLU tasks.","curriculum learning natural language understanding great success pre - trained language model , pretrain - finetune paradigm undoubtedly dominant solution natural language understanding ( nlu ) task . fine - tune stage , target task datum usually introduce completely random order treat equally . , example nlu task vary greatly difficulty , similar human learning procedure , language model benefit easy - - difficult curriculum . base idea , propose curriculum learning approach . review trainset crossed way , able distinguish easy example difficult one , arrange curriculum language model . manual model architecture design use external datum , curriculum learning approach obtain significant universal performance improvement wide range nlu task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Towards Robustifying NLI Models Against Lexical Dataset Biases,"While deep learning models are making fast progress on the task of Natural Language Inference, recent studies have also shown that these models achieve high accuracy by exploiting several dataset biases, and without deep understanding of the language semantics. Using contradiction-word bias and word-overlapping bias as our two bias examples, this paper explores both data-level and model-level debiasing methods to robustify models against lexical dataset biases. First, we debias the dataset through data augmentation and enhancement, but show that the model bias cannot be fully removed via this method. Next, we also compare two ways of directly debiasing the model without knowing what the dataset biases are in advance. The first approach aims to remove the label bias at the embedding level. The second approach employs a bag-of-words submodel to capture the features that are likely to exploit the bias and prevents the original model from learning these biased features by forcing orthogonality between these two submodels. We performed evaluations on new balanced datasets extracted from the original MNLI dataset as well as the NLI stress tests, and show that the orthogonality approach is better at debiasing the model while maintaining competitive overall accuracy. 1","Towards Robustifying NLI Models Against Lexical Dataset Biases While deep learning models are making fast progress on the task of Natural Language Inference, recent studies have also shown that these models achieve high accuracy by exploiting several dataset biases, and without deep understanding of the language semantics. Using contradiction-word bias and word-overlapping bias as our two bias examples, this paper explores both data-level and model-level debiasing methods to robustify models against lexical dataset biases. First, we debias the dataset through data augmentation and enhancement, but show that the model bias cannot be fully removed via this method. Next, we also compare two ways of directly debiasing the model without knowing what the dataset biases are in advance. The first approach aims to remove the label bias at the embedding level. The second approach employs a bag-of-words submodel to capture the features that are likely to exploit the bias and prevents the original model from learning these biased features by forcing orthogonality between these two submodels. We performed evaluations on new balanced datasets extracted from the original MNLI dataset as well as the NLI stress tests, and show that the orthogonality approach is better at debiasing the model while maintaining competitive overall accuracy. 1","robustifye nli model lexical dataset bias deep learning model make fast progress task natural language inference , recent study show model achieve high accuracy exploit dataset bias , deep understanding language semantic . contradiction - word bias word - overlap bias bias example , paper explore data - level model - level debiase method robustify model lexical dataset bias . , debia dataset datum augmentation enhancement , model bias fully remove method . , compare way directly debiase model know dataset bias advance . approach aim remove label bias embedding level . second approach employ bag - - word submodel capture feature likely exploit bias prevent original model learn bias feature force orthogonality submodel . perform evaluation new balanced dataset extract original mnli dataset nli stress test , orthogonality approach well debiase model maintain competitive overall accuracy . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 17, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",NILE : Natural Language Inference with Faithful Natural Language Explanations,"The recent growth in the popularity and success of deep learning models on NLP classification tasks has accompanied the need for generating some form of natural language explanation of the predicted labels. Such generated natural language (NL) explanations are expected to be faithful, i.e., they should correlate well with the model's internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question: can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Naturallanguage Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE's effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate systems capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE's explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model's explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity.","NILE : Natural Language Inference with Faithful Natural Language Explanations The recent growth in the popularity and success of deep learning models on NLP classification tasks has accompanied the need for generating some form of natural language explanation of the predicted labels. Such generated natural language (NL) explanations are expected to be faithful, i.e., they should correlate well with the model's internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question: can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Naturallanguage Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE's effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate systems capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE's explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model's explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity.","nile : natural language inference faithful natural language explanation recent growth popularity success deep learning model nlp classification task accompany need generate form natural language explanation predict label . generate natural language ( nl ) explanation expect faithful , i.e. , correlate model internal decision making . work , focus task natural language inference ( nli ) address follow question : build nli system produce label high accuracy , generate faithful explanation decision ? propose naturallanguage inference label - specific explanation ( nile ) , novel nli method utilize auto - generate label - specific nl explanation produce label faithful explanation . demonstrate nile effectiveness previously report method automate human evaluation produce label explanation . evaluation nile support claim accurate system capable provide testable explanation decision design . discuss faithfulness nile explanation term sensitivity decision corresponding explanation . argue explicit evaluation faithfulness , addition label explanation accuracy , important step evaluate model explanation . , demonstrate task - specific probe necessary establish sensitivity .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 20, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",NeuInfer: Knowledge Inference on N-ary Facts,"Knowledge inference on knowledge graph has attracted extensive attention, which aims to find out connotative valid facts in knowledge graph and is very helpful for improving the performance of many downstream applications. However, researchers have mainly poured attention to knowledge inference on binary facts. The studies on n-ary facts are relatively scarcer, although they are also ubiquitous in the real world. Therefore, this paper addresses knowledge inference on n-ary facts. We represent each n-ary fact as a primary triple coupled with a set of its auxiliary descriptive attribute-value pair(s). We further propose a neural network model, NeuInfer, for knowledge inference on n-ary facts. Besides handling the common task to infer an unknown element in a whole fact, NeuInfer can cope with a new type of task, flexible knowledge inference. It aims to infer an unknown element in a partial fact consisting of the primary triple coupled with any number of its auxiliary description(s). Experimental results demonstrate the remarkable superiority of NeuInfer.","NeuInfer: Knowledge Inference on N-ary Facts Knowledge inference on knowledge graph has attracted extensive attention, which aims to find out connotative valid facts in knowledge graph and is very helpful for improving the performance of many downstream applications. However, researchers have mainly poured attention to knowledge inference on binary facts. The studies on n-ary facts are relatively scarcer, although they are also ubiquitous in the real world. Therefore, this paper addresses knowledge inference on n-ary facts. We represent each n-ary fact as a primary triple coupled with a set of its auxiliary descriptive attribute-value pair(s). We further propose a neural network model, NeuInfer, for knowledge inference on n-ary facts. Besides handling the common task to infer an unknown element in a whole fact, NeuInfer can cope with a new type of task, flexible knowledge inference. It aims to infer an unknown element in a partial fact consisting of the primary triple coupled with any number of its auxiliary description(s). Experimental results demonstrate the remarkable superiority of NeuInfer.","neuinfer : knowledge inference n - ary fact knowledge inference knowledge graph attract extensive attention , aim find connotative valid fact knowledge graph helpful improve performance downstream application . , researcher mainly pour attention knowledge inference binary fact . study n - ary fact relatively scarce , ubiquitous real world . , paper address knowledge inference n - ary fact . represent n - ary fact primary triple couple set auxiliary descriptive attribute - value pair( ) . propose neural network model , neuinfer , knowledge inference n - ary fact . handle common task infer unknown element fact , neuinfer cope new type task , flexible knowledge inference . aim infer unknown element partial fact consist primary triple couple number auxiliary description(s ) . experimental result demonstrate remarkable superiority neuinfer .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 17, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Benchmarking Multimodal Regex Synthesis with Complex Structures,"Existing datasets for regular expression (regex) generation from natural language are limited in complexity; compared to regex tasks that users post on StackOverflow, the regexes in these datasets are simple, and the language used to describe them is not diverse. We introduce STRUCTUREDREGEX, a new regex synthesis dataset differing from prior ones in three aspects. First, to obtain structurally complex and realistic regexes, we generate the regexes using a probabilistic grammar with pre-defined macros observed from real-world StackOverflow posts. Second, to obtain linguistically diverse natural language descriptions, we show crowdworkers abstract depictions of the underlying regex and ask them to describe the pattern they see, rather than having them paraphrase synthetic language. Third, we augment each regex example with a collection of strings that are and are not matched by the ground truth regex, similar to how real users give examples. Our quantitative and qualitative analysis demonstrates the advantages of STRUCTUREDREGEX over prior datasets. Further experimental results using various multimodal synthesis techniques highlight the challenge presented by our dataset, including non-local constraints and multi-modal inputs. 1","Benchmarking Multimodal Regex Synthesis with Complex Structures Existing datasets for regular expression (regex) generation from natural language are limited in complexity; compared to regex tasks that users post on StackOverflow, the regexes in these datasets are simple, and the language used to describe them is not diverse. We introduce STRUCTUREDREGEX, a new regex synthesis dataset differing from prior ones in three aspects. First, to obtain structurally complex and realistic regexes, we generate the regexes using a probabilistic grammar with pre-defined macros observed from real-world StackOverflow posts. Second, to obtain linguistically diverse natural language descriptions, we show crowdworkers abstract depictions of the underlying regex and ask them to describe the pattern they see, rather than having them paraphrase synthetic language. Third, we augment each regex example with a collection of strings that are and are not matched by the ground truth regex, similar to how real users give examples. Our quantitative and qualitative analysis demonstrates the advantages of STRUCTUREDREGEX over prior datasets. Further experimental results using various multimodal synthesis techniques highlight the challenge presented by our dataset, including non-local constraints and multi-modal inputs. 1","benchmarke multimodal regex synthesis complex structure exist dataset regular expression ( regex ) generation natural language limit complexity ; compare regex task user post stackoverflow , regexe dataset simple , language describe diverse . introduce structuredregex , new regex synthesis dataset differ prior one aspect . , obtain structurally complex realistic regexe , generate regexe probabilistic grammar pre - defined macro observe real - world stackoverflow post . second , obtain linguistically diverse natural language description , crowdworker abstract depiction underlie regex ask describe pattern , have paraphrase synthetic language . , augment regex example collection string match ground truth regex , similar real user example . quantitative qualitative analysis demonstrate advantage structuredregex prior dataset . experimental result multimodal synthesis technique highlight challenge present dataset , include non - local constraint multi - modal input . 1","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction,"Open Information Extraction systems extract (""subject text"", ""relation text"", ""object text"") triples from raw text. Some triples are textual versions of facts, i.e., non-canonicalized mentions of entities and relations. In this paper, we investigate whether it is possible to infer new facts directly from the open knowledge graph without any canonicalization or any supervision from curated knowledge. For this purpose, we propose the open link prediction task, i.e., predicting test facts by completing (""subject text"", ""relation text"", ?) questions. An evaluation in such a setup raises the question if a correct prediction is actually a new fact that was induced by reasoning over the open knowledge graph or if it can be trivially explained. For example, facts can appear in different paraphrased textual variants, which can lead to test leakage. To this end, we propose an evaluation protocol and a methodology for creating the open link prediction benchmark OLPBENCH. We performed experiments with a prototypical knowledge graph embedding model for open link prediction. While the task is very challenging, our results suggests that it is possible to predict genuinely new facts, which can not be trivially explained.","Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction Open Information Extraction systems extract (""subject text"", ""relation text"", ""object text"") triples from raw text. Some triples are textual versions of facts, i.e., non-canonicalized mentions of entities and relations. In this paper, we investigate whether it is possible to infer new facts directly from the open knowledge graph without any canonicalization or any supervision from curated knowledge. For this purpose, we propose the open link prediction task, i.e., predicting test facts by completing (""subject text"", ""relation text"", ?) questions. An evaluation in such a setup raises the question if a correct prediction is actually a new fact that was induced by reasoning over the open knowledge graph or if it can be trivially explained. For example, facts can appear in different paraphrased textual variants, which can lead to test leakage. To this end, we propose an evaluation protocol and a methodology for creating the open link prediction benchmark OLPBENCH. We performed experiments with a prototypical knowledge graph embedding model for open link prediction. While the task is very challenging, our results suggests that it is possible to predict genuinely new facts, which can not be trivially explained.","predict new fact open knowledge graph embedding ? benchmark open link prediction open information extraction system extract ( "" subject text "" , "" relation text "" , "" object text "" ) triple raw text . triple textual version fact , i.e. , non - canonicalized mention entity relation . paper , investigate possible infer new fact directly open knowledge graph canonicalization supervision curate knowledge . purpose , propose open link prediction task , i.e. , predict test fact complete ( "" subject text "" , "" relation text "" , ? ) question . evaluation setup raise question correct prediction actually new fact induce reason open knowledge graph trivially explain . example , fact appear different paraphrase textual variant , lead test leakage . end , propose evaluation protocol methodology create open link prediction benchmark olpbench . perform experiment prototypical knowledge graph embedding model open link prediction . task challenging , result suggest possible predict genuinely new fact , trivially explain .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 12, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 2, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Uncertain Natural Language Inference,"We introduce Uncertain Natural Language Inference (UNLI), a refinement of Natural Language Inference (NLI) that shifts away from categorical labels, targeting instead the direct prediction of subjective probability assessments. We demonstrate the feasibility of collecting annotations for UNLI by relabeling a portion of the SNLI dataset under a probabilistic scale, where items even with the same categorical label differ in how likely people judge them to be true given a premise. We describe a direct scalar regression modeling approach, and find that existing categorically labeled NLI data can be used in pre-training. Our best models approach human performance, demonstrating models may be capable of more subtle inferences than the categorical bin assignment employed in current NLI tasks.","Uncertain Natural Language Inference We introduce Uncertain Natural Language Inference (UNLI), a refinement of Natural Language Inference (NLI) that shifts away from categorical labels, targeting instead the direct prediction of subjective probability assessments. We demonstrate the feasibility of collecting annotations for UNLI by relabeling a portion of the SNLI dataset under a probabilistic scale, where items even with the same categorical label differ in how likely people judge them to be true given a premise. We describe a direct scalar regression modeling approach, and find that existing categorically labeled NLI data can be used in pre-training. Our best models approach human performance, demonstrating models may be capable of more subtle inferences than the categorical bin assignment employed in current NLI tasks.","uncertain natural language inference introduce uncertain natural language inference ( unli ) , refinement natural language inference ( nli ) shift away categorical label , target instead direct prediction subjective probability assessment . demonstrate feasibility collect annotation unli relabele portion snli dataset probabilistic scale , item categorical label differ likely people judge true give premise . describe direct scalar regression modeling approach , find exist categorically label nli datum pre - training . good model approach human performance , demonstrate model capable subtle inference categorical bin assignment employ current nli task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",INFOTABS: Inference on Tables as Semi-structured Data,"In this paper, we observe that semi-structured tabulated text is ubiquitous; understanding them requires not only comprehending the meaning of text fragments, but also implicit relationships between them. We argue that such data can prove as a testing ground for understanding how we reason about information. To study this, we introduce a new dataset called INFOTABS, comprising of human-written textual hypotheses based on premises that are tables extracted from Wikipedia info-boxes. Our analysis shows that the semi-structured, multi-domain and heterogeneous nature of the premises admits complex, multi-faceted reasoning. Experiments reveal that, while human annotators agree on the relationships between a table-hypothesis pair, several standard modeling strategies are unsuccessful at the task, suggesting that reasoning about tables can pose a difficult modeling challenge.","INFOTABS: Inference on Tables as Semi-structured Data In this paper, we observe that semi-structured tabulated text is ubiquitous; understanding them requires not only comprehending the meaning of text fragments, but also implicit relationships between them. We argue that such data can prove as a testing ground for understanding how we reason about information. To study this, we introduce a new dataset called INFOTABS, comprising of human-written textual hypotheses based on premises that are tables extracted from Wikipedia info-boxes. Our analysis shows that the semi-structured, multi-domain and heterogeneous nature of the premises admits complex, multi-faceted reasoning. Experiments reveal that, while human annotators agree on the relationships between a table-hypothesis pair, several standard modeling strategies are unsuccessful at the task, suggesting that reasoning about tables can pose a difficult modeling challenge.","infotabs : inference table semi - structured datum paper , observe semi - structured tabulate text ubiquitous ; understand require comprehend meaning text fragment , implicit relationship . argue datum prove test ground understand reason information . study , introduce new dataset call infotabs , comprise human - write textual hypothesis base premise table extract wikipedia info - box . analysis show semi - structured , multi - domain heterogeneous nature premise admit complex , multi - faceted reasoning . experiment reveal , human annotator agree relationship table - hypothesis pair , standard modeling strategy unsuccessful task , suggest reason table pose difficult modeling challenge .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder,"Generating inferential texts about an event in different perspectives requires reasoning over different contexts that the event occurs. Existing works usually ignore the context that is not explicitly provided, resulting in a context-independent semantic representation that struggles to support the generation. To address this, we propose an approach that automatically finds evidence for an event from a large text corpus, and leverages the evidence to guide the generation of inferential texts. Our approach works in an encoderdecoder manner and is equipped with a Vector Quantised-Variational Autoencoder, where the encoder outputs representations from a distribution over discrete variables. Such discrete representations enable automatically selecting relevant evidence, which not only facilitates evidence-aware generation, but also provides a natural way to uncover rationales behind the generation. Our approach provides state-ofthe-art performance on both Event2Mind and ATOMIC datasets. More importantly, we find that with discrete representations, our model selectively uses evidence to generate different inferential texts.","Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder Generating inferential texts about an event in different perspectives requires reasoning over different contexts that the event occurs. Existing works usually ignore the context that is not explicitly provided, resulting in a context-independent semantic representation that struggles to support the generation. To address this, we propose an approach that automatically finds evidence for an event from a large text corpus, and leverages the evidence to guide the generation of inferential texts. Our approach works in an encoderdecoder manner and is equipped with a Vector Quantised-Variational Autoencoder, where the encoder outputs representations from a distribution over discrete variables. Such discrete representations enable automatically selecting relevant evidence, which not only facilitates evidence-aware generation, but also provides a natural way to uncover rationales behind the generation. Our approach provides state-ofthe-art performance on both Event2Mind and ATOMIC datasets. More importantly, we find that with discrete representations, our model selectively uses evidence to generate different inferential texts.","evidence - aware inferential text generation vector quantised variational autoencoder generate inferential text event different perspective require reason different context event occur . exist work usually ignore context explicitly provide , result context - independent semantic representation struggle support generation . address , propose approach automatically find evidence event large text corpus , leverage evidence guide generation inferential text . approach work encoderdecoder manner equip vector quantised - variational autoencoder , encoder output representation distribution discrete variable . discrete representation enable automatically select relevant evidence , facilitate evidence - aware generation , provide natural way uncover rationale generation . approach provide state - ofthe - art performance event2mind atomic dataset . importantly , find discrete representation , model selectively use evidence generate different inferential text .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 16, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Syntactic Data Augmentation Increases Robustness to Inference Heuristics,"Pretrained neural models such as BERT, when fine-tuned to perform natural language inference (NLI), often show high accuracy on standard datasets, but display a surprising lack of sensitivity to word order on controlled challenge sets. We hypothesize that this issue is not primarily caused by the pretrained model's limitations, but rather by the paucity of crowdsourced NLI examples that might convey the importance of syntactic structure at the finetuning stage. We explore several methods to augment standard training sets with syntactically informative examples, generated by applying syntactic transformations to sentences from the MNLI corpus. The best-performing augmentation method, subject/object inversion, improved BERT's accuracy on controlled examples that diagnose sensitivity to word order from 0.28 to 0.73, without affecting performance on the MNLI test set. This improvement generalized beyond the particular construction used for data augmentation, suggesting that augmentation causes BERT to recruit abstract syntactic representations.","Syntactic Data Augmentation Increases Robustness to Inference Heuristics Pretrained neural models such as BERT, when fine-tuned to perform natural language inference (NLI), often show high accuracy on standard datasets, but display a surprising lack of sensitivity to word order on controlled challenge sets. We hypothesize that this issue is not primarily caused by the pretrained model's limitations, but rather by the paucity of crowdsourced NLI examples that might convey the importance of syntactic structure at the finetuning stage. We explore several methods to augment standard training sets with syntactically informative examples, generated by applying syntactic transformations to sentences from the MNLI corpus. The best-performing augmentation method, subject/object inversion, improved BERT's accuracy on controlled examples that diagnose sensitivity to word order from 0.28 to 0.73, without affecting performance on the MNLI test set. This improvement generalized beyond the particular construction used for data augmentation, suggesting that augmentation causes BERT to recruit abstract syntactic representations.","syntactic data augmentation increase robustness inference heuristic pretrained neural model bert , fine - tune perform natural language inference ( nli ) , high accuracy standard dataset , display surprising lack sensitivity word order control challenge set . hypothesize issue primarily cause pretrained model limitation , paucity crowdsource nli example convey importance syntactic structure finetuning stage . explore method augment standard training set syntactically informative example , generate apply syntactic transformation sentence mnli corpus . well - perform augmentation method , subject / object inversion , improve bert accuracy control example diagnose sensitivity word order 0.28 0.73 , affect performance mnli test set . improvement generalize particular construction datum augmentation , suggest augmentation cause bert recruit abstract syntactic representation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Machine Learning for NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition,"Natural language inference (NLI) is an increasingly important task for natural language understanding, which requires one to infer whether a sentence entails another. However, the ability of NLI models to make pragmatic inferences remains understudied. We create an IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types. We use IMPPRES to evaluate whether BERT, InferSent, and BOW NLI models trained on MultiNLI (Williams et al., 2018) learn to make pragmatic inferences. Although MultiNLI appears to contain very few pairs illustrating these inference types, we find that BERT learns to draw pragmatic inferences. It reliably treats scalar implicatures triggered by ""some"" as entailments. For some presupposition triggers like only, BERT reliably recognizes the presupposition as an entailment, even when the trigger is embedded under an entailment canceling operator like negation. BOW and InferSent show weaker evidence of pragmatic reasoning. We conclude that NLI training encourages models to learn some, but not all, pragmatic inferences.","Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition Natural language inference (NLI) is an increasingly important task for natural language understanding, which requires one to infer whether a sentence entails another. However, the ability of NLI models to make pragmatic inferences remains understudied. We create an IMPlicature and PRESupposition diagnostic dataset (IMPPRES), consisting of >25k semiautomatically generated sentence pairs illustrating well-studied pragmatic inference types. We use IMPPRES to evaluate whether BERT, InferSent, and BOW NLI models trained on MultiNLI (Williams et al., 2018) learn to make pragmatic inferences. Although MultiNLI appears to contain very few pairs illustrating these inference types, we find that BERT learns to draw pragmatic inferences. It reliably treats scalar implicatures triggered by ""some"" as entailments. For some presupposition triggers like only, BERT reliably recognizes the presupposition as an entailment, even when the trigger is embedded under an entailment canceling operator like negation. BOW and InferSent show weaker evidence of pragmatic reasoning. We conclude that NLI training encourages models to learn some, but not all, pragmatic inferences.","natural language inference model imppressive ? learn implicature presupposition natural language inference ( nli ) increasingly important task natural language understanding , require infer sentence entail . , ability nli model pragmatic inference remain understudied . create implicature presupposition diagnostic dataset ( imppres ) , consist > 25k semiautomatically generate sentence pair illustrate - study pragmatic inference type . use imppres evaluate bert , infersent , bow nli model train multinli ( williams et al . , 2018 ) learn pragmatic inference . multinli appear contain pair illustrate inference type , find bert learn draw pragmatic inference . reliably treat scalar implicature trigger "" "" entailment . presupposition trigger like , bert reliably recognize presupposition entailment , trigger embed entailment cancel operator like negation . bow infersent weak evidence pragmatic reasoning . conclude nli training encourage model learn , , pragmatic inference .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 14, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",True
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance,"Models for natural language understanding (NLU) tasks often rely on the idiosyncratic biases of the dataset, which make them brittle against test cases outside the training distribution. Recently, several proposed debiasing methods are shown to be very effective in improving out-of-distribution performance. However, their improvements come at the expense of performance drop when models are evaluated on the in-distribution data, which contain examples with higher diversity. This seemingly inevitable trade-off may not tell us much about the changes in the reasoning and understanding capabilities of the resulting models on broader types of examples beyond the small subset represented in the outof-distribution data. In this paper, we address this trade-off by introducing a novel debiasing method, called confidence regularization, which discourage models from exploiting biases while enabling them to receive enough incentive to learn from all the training examples. We evaluate our method on three NLU tasks and show that, in contrast to its predecessors, it improves the performance on out-of-distribution datasets (e.g., 7pp gain on HANS dataset) while maintaining the original in-distribution accuracy. 1","Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance Models for natural language understanding (NLU) tasks often rely on the idiosyncratic biases of the dataset, which make them brittle against test cases outside the training distribution. Recently, several proposed debiasing methods are shown to be very effective in improving out-of-distribution performance. However, their improvements come at the expense of performance drop when models are evaluated on the in-distribution data, which contain examples with higher diversity. This seemingly inevitable trade-off may not tell us much about the changes in the reasoning and understanding capabilities of the resulting models on broader types of examples beyond the small subset represented in the outof-distribution data. In this paper, we address this trade-off by introducing a novel debiasing method, called confidence regularization, which discourage models from exploiting biases while enabling them to receive enough incentive to learn from all the training examples. We evaluate our method on three NLU tasks and show that, in contrast to its predecessors, it improves the performance on out-of-distribution datasets (e.g., 7pp gain on HANS dataset) while maintaining the original in-distribution accuracy. 1","mind trade - : debiase nlu model degrade - distribution performance model natural language understanding ( nlu ) task rely idiosyncratic bias dataset , brittle test case outside training distribution . recently , propose debiase method show effective improve - - distribution performance . , improvement come expense performance drop model evaluate - distribution datum , contain example high diversity . seemingly inevitable trade - tell change reasoning understanding capability result model broad type example small subset represent outof - distribution datum . paper , address trade - introduce novel debiase method , call confidence regularization , discourage model exploit bias enable receive incentive learn training example . evaluate method nlu task , contrast predecessor , improve performance - - distribution dataset ( e.g. , 7pp gain hans dataset ) maintain original - distribution accuracy . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 8, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",How to Ask Good Questions? Try to Leverage Paraphrases,"Given a sentence and its relevant answer, how to ask good questions is a challenging task, which has many real applications. Inspired by human's paraphrasing capability to ask questions of the same meaning but with diverse expressions, we propose to incorporate paraphrase knowledge into question generation(QG) to generate human-like questions. Specifically, we present a two-hand hybrid model leveraging a self-built paraphrase resource, which is automatically conducted by a simple back-translation method. On the one hand, we conduct multi-task learning with sentence-level paraphrase generation (PG) as an auxiliary task to supplement paraphrase knowledge to the task-share encoder. On the other hand, we adopt a new loss function for diversity training to introduce more question patterns to QG. Extensive experimental results show that our proposed model obtains obvious performance gain over several strong baselines, and further human evaluation validates that our model can ask questions of high quality by leveraging paraphrase knowledge.","How to Ask Good Questions? Try to Leverage Paraphrases Given a sentence and its relevant answer, how to ask good questions is a challenging task, which has many real applications. Inspired by human's paraphrasing capability to ask questions of the same meaning but with diverse expressions, we propose to incorporate paraphrase knowledge into question generation(QG) to generate human-like questions. Specifically, we present a two-hand hybrid model leveraging a self-built paraphrase resource, which is automatically conducted by a simple back-translation method. On the one hand, we conduct multi-task learning with sentence-level paraphrase generation (PG) as an auxiliary task to supplement paraphrase knowledge to the task-share encoder. On the other hand, we adopt a new loss function for diversity training to introduce more question patterns to QG. Extensive experimental results show that our proposed model obtains obvious performance gain over several strong baselines, and further human evaluation validates that our model can ask questions of high quality by leveraging paraphrase knowledge.","ask good question ? try leverage paraphrase give sentence relevant answer , ask good question challenging task , real application . inspire human paraphrase capability ask question meaning diverse expression , propose incorporate paraphrase knowledge question generation(qg ) generate human - like question . specifically , present - hand hybrid model leverage self - build paraphrase resource , automatically conduct simple - translation method . hand , conduct multi - task learning sentence - level paraphrase generation ( pg ) auxiliary task supplement paraphrase knowledge task - share encoder . hand , adopt new loss function diversity training introduce question pattern qg . extensive experimental result propose model obtain obvious performance gain strong baseline , human evaluation validate model ask question high quality leverage paraphrase knowledge .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 8, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Interactive Machine Comprehension with Information Seeking Agents,"Existing machine reading comprehension (MRC) models do not scale effectively to realworld applications like web-level information retrieval and question answering (QA). We argue that this stems from the nature of MRC datasets: most of these are static environments wherein the supporting documents and all necessary information are fully observed. In this paper, we propose a simple method that reframes existing MRC datasets as interactive, partially observable environments. Specifically, we ""occlude"" the majority of a document's text and add context-sensitive commands that reveal ""glimpses"" of the hidden text to a model. We repurpose SQuAD and NewsQA as an initial case study, and then show how the interactive corpora can be used to train a model that seeks relevant information through sequential decision making. We believe that this setting can contribute in scaling models to web-level QA scenarios. 1 * Equal contribution. 1 The dataset and implementation of our baseline agents are publicly available at https://github.com/ xingdi-eric-yuan/imrc_public.","Interactive Machine Comprehension with Information Seeking Agents Existing machine reading comprehension (MRC) models do not scale effectively to realworld applications like web-level information retrieval and question answering (QA). We argue that this stems from the nature of MRC datasets: most of these are static environments wherein the supporting documents and all necessary information are fully observed. In this paper, we propose a simple method that reframes existing MRC datasets as interactive, partially observable environments. Specifically, we ""occlude"" the majority of a document's text and add context-sensitive commands that reveal ""glimpses"" of the hidden text to a model. We repurpose SQuAD and NewsQA as an initial case study, and then show how the interactive corpora can be used to train a model that seeks relevant information through sequential decision making. We believe that this setting can contribute in scaling models to web-level QA scenarios. 1 * Equal contribution. 1 The dataset and implementation of our baseline agents are publicly available at https://github.com/ xingdi-eric-yuan/imrc_public.","interactive machine comprehension information seeking agent exist machine reading comprehension ( mrc ) model scale effectively realworld application like web - level information retrieval question answering ( qa ) . argue stem nature mrc dataset : static environment support document necessary information fully observe . paper , propose simple method reframe exist mrc dataset interactive , partially observable environment . specifically , "" occlude "" majority document text add context - sensitive command reveal "" glimpse "" hide text model . repurpose squad newsqa initial case study , interactive corpora train model seek relevant information sequential decision making . believe setting contribute scale model web - level qa scenario . 1 * equal contribution . 1 dataset implementation baseline agent publicly available https://github.com/ xingdi - eric - yuan / imrc_public .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 13, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",The Sensitivity of Language Models and Humans to Winograd Schema Perturbations,"Large-scale pretrained language models are the major driving force behind recent improvements in performance on the Winograd Schema Challenge, a widely employed test of commonsense reasoning ability. We show, however, with a new diagnostic dataset, that these models are sensitive to linguistic perturbations of the Winograd examples that minimally affect human understanding. Our results highlight interesting differences between humans and language models: language models are more sensitive to number or gender alternations and synonym replacements than humans, and humans are more stable and consistent in their predictions, maintain a much higher absolute performance, and perform better on non-associative instances than associative ones. Overall, humans are correct more often than out-of-the-box models, and the models are sometimes right for the wrong reasons. Finally, we show that fine-tuning on a large, task-specific dataset can offer a solution to these issues. Instance / Perturbed Instance Count Original Sid explained his theory to Mark but he couldn't convince him. 285 Tense Sid is explaining his theory to Mark but he can't convince him. 281 Number Sid and Johnny explained their theory to Mark and Andrew but they couldn't convince them. 253 Gender Lucy explained her theory to Emma but she couldn't convince her. 155 Voice The theory was explained by Sid to Mark but he couldn't convince him. 220 Relative clause Sid, which we had seen on the discussion panel with Chris, explained his theory to Mark but he couldn't convince him. 283 Adverb Sid diligently explained his theory to Mark but he couldn't convince him. 283 Synonyms/Names John explained his theory to Jad but he couldn't convince him.","The Sensitivity of Language Models and Humans to Winograd Schema Perturbations Large-scale pretrained language models are the major driving force behind recent improvements in performance on the Winograd Schema Challenge, a widely employed test of commonsense reasoning ability. We show, however, with a new diagnostic dataset, that these models are sensitive to linguistic perturbations of the Winograd examples that minimally affect human understanding. Our results highlight interesting differences between humans and language models: language models are more sensitive to number or gender alternations and synonym replacements than humans, and humans are more stable and consistent in their predictions, maintain a much higher absolute performance, and perform better on non-associative instances than associative ones. Overall, humans are correct more often than out-of-the-box models, and the models are sometimes right for the wrong reasons. Finally, we show that fine-tuning on a large, task-specific dataset can offer a solution to these issues. Instance / Perturbed Instance Count Original Sid explained his theory to Mark but he couldn't convince him. 285 Tense Sid is explaining his theory to Mark but he can't convince him. 281 Number Sid and Johnny explained their theory to Mark and Andrew but they couldn't convince them. 253 Gender Lucy explained her theory to Emma but she couldn't convince her. 155 Voice The theory was explained by Sid to Mark but he couldn't convince him. 220 Relative clause Sid, which we had seen on the discussion panel with Chris, explained his theory to Mark but he couldn't convince him. 283 Adverb Sid diligently explained his theory to Mark but he couldn't convince him. 283 Synonyms/Names John explained his theory to Jad but he couldn't convince him.","sensitivity language model human winograd schema perturbation large - scale pretrained language model major drive force recent improvement performance winograd schema challenge , widely employ test commonsense reasoning ability . , , new diagnostic dataset , model sensitive linguistic perturbation winograd example minimally affect human understanding . result highlight interesting difference human language model : language model sensitive number gender alternation synonym replacement human , human stable consistent prediction , maintain high absolute performance , perform well non - associative instance associative one . overall , human correct - - - box model , model right wrong reason . finally , fine - tuning large , task - specific dataset offer solution issue . instance / perturbed instance count original sid explain theory mark convince . 285 tense sid explain theory mark convince . 281 number sid johnny explain theory mark andrew convince . 253 gender lucy explain theory emma convince . 155 voice theory explain sid mark convince . 220 relative clause sid , see discussion panel chris , explain theory mark convince . 283 adverb sid diligently explain theory mark convince . 283 synonym / name john explain theory jad convince .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",End-to-End Bias Mitigation by Modelling Biases in Corpora,"Several recent studies have shown that strong natural language understanding (NLU) models are prone to relying on unwanted dataset biases without learning the underlying task, resulting in models that fail to generalize to out-of-domain datasets and are likely to perform poorly in real-world scenarios. We propose two learning strategies to train neural models, which are more robust to such biases and transfer better to out-of-domain datasets. The biases are specified in terms of one or more bias-only models, which learn to leverage the dataset biases. During training, the bias-only models' predictions are used to adjust the loss of the base model to reduce its reliance on biases by down-weighting the biased examples and focusing training on the hard examples. We experiment on large-scale natural language inference and fact verification benchmarks, evaluating on out-of-domain datasets that are specifically designed to assess the robustness of models against known biases in the training data. Results show that our debiasing methods greatly improve robustness in all settings and better transfer to other textual entailment datasets. Our code and data are publicly available in https: //github.com/rabeehk/robust-nli.","End-to-End Bias Mitigation by Modelling Biases in Corpora Several recent studies have shown that strong natural language understanding (NLU) models are prone to relying on unwanted dataset biases without learning the underlying task, resulting in models that fail to generalize to out-of-domain datasets and are likely to perform poorly in real-world scenarios. We propose two learning strategies to train neural models, which are more robust to such biases and transfer better to out-of-domain datasets. The biases are specified in terms of one or more bias-only models, which learn to leverage the dataset biases. During training, the bias-only models' predictions are used to adjust the loss of the base model to reduce its reliance on biases by down-weighting the biased examples and focusing training on the hard examples. We experiment on large-scale natural language inference and fact verification benchmarks, evaluating on out-of-domain datasets that are specifically designed to assess the robustness of models against known biases in the training data. Results show that our debiasing methods greatly improve robustness in all settings and better transfer to other textual entailment datasets. Our code and data are publicly available in https: //github.com/rabeehk/robust-nli.","end - - end bias mitigation model bias corpora recent study show strong natural language understanding ( nlu ) model prone rely unwanted dataset bias learn underlie task , result model fail generalize - - domain dataset likely perform poorly real - world scenario . propose learning strategy train neural model , robust bias transfer well - - domain dataset . bias specify term bias - model , learn leverage dataset bias . training , bias - model ' prediction adjust loss base model reduce reliance bias - weight biased example focus training hard example . experiment large - scale natural language inference fact verification benchmark , evaluate - - domain dataset specifically design assess robustness model know bias training datum . result debiase method greatly improve robustness setting well transfer textual entailment dataset . code datum publicly available https : //github.com / rabeehk / robust - nli .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 15, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
"Semantics: Sentence-level Semantics, Textual Inference and Other areas",Premise Selection in Natural Language Mathematical Texts,"The discovery of supporting evidence for addressing complex mathematical problems is a semantically challenging task, which is still unexplored in the field of natural language processing for mathematical text. The natural language premise selection task consists in using conjectures written in both natural language and mathematical formulae to recommend premises that most likely will be useful to prove a particular statement. We propose an approach to solve this task as a link prediction problem, using Deep Convolutional Graph Neural Networks. This paper also analyses how different baselines perform in this task and shows that a graph structure can provide higher F1-score, especially when considering multi-hop premise selection.","Premise Selection in Natural Language Mathematical Texts The discovery of supporting evidence for addressing complex mathematical problems is a semantically challenging task, which is still unexplored in the field of natural language processing for mathematical text. The natural language premise selection task consists in using conjectures written in both natural language and mathematical formulae to recommend premises that most likely will be useful to prove a particular statement. We propose an approach to solve this task as a link prediction problem, using Deep Convolutional Graph Neural Networks. This paper also analyses how different baselines perform in this task and shows that a graph structure can provide higher F1-score, especially when considering multi-hop premise selection.","premise selection natural language mathematical text discovery support evidence address complex mathematical problem semantically challenging task , unexplored field natural language processing mathematical text . natural language premise selection task consist conjecture write natural language mathematical formula recommend premise likely useful prove particular statement . propose approach solve task link prediction problem , deep convolutional graph neural networks . paper analyse different baseline perform task show graph structure provide high f1 - score , especially consider multi - hop premise selection .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",From Arguments to Key Points: Towards Automatic Argument Summarization,"Generating a concise summary from a large collection of arguments on a given topic is an intriguing yet understudied problem. We propose to represent such summaries as a small set of talking points, termed key points, each scored according to its salience. We show, by analyzing a large dataset of crowd-contributed arguments, that a small number of key points per topic is typically sufficient for covering the vast majority of the arguments. Furthermore, we found that a domain expert can often predict these key points in advance. We study the task of argument-to-key point mapping, and introduce a novel large-scale dataset for this task. We report empirical results for an extensive set of experiments with this dataset, showing promising performance.","From Arguments to Key Points: Towards Automatic Argument Summarization Generating a concise summary from a large collection of arguments on a given topic is an intriguing yet understudied problem. We propose to represent such summaries as a small set of talking points, termed key points, each scored according to its salience. We show, by analyzing a large dataset of crowd-contributed arguments, that a small number of key points per topic is typically sufficient for covering the vast majority of the arguments. Furthermore, we found that a domain expert can often predict these key points in advance. We study the task of argument-to-key point mapping, and introduce a novel large-scale dataset for this task. We report empirical results for an extensive set of experiments with this dataset, showing promising performance.","argument key point : automatic argument summarization generate concise summary large collection argument give topic intriguing understudy problem . propose represent summary small set talking point , term key point , score accord salience . , analyze large dataset crowd - contribute argument , small number key point topic typically sufficient cover vast majority argument . furthermore , find domain expert predict key point advance . study task argument - - key point mapping , introduce novel large - scale dataset task . report empirical result extensive set experiment dataset , show promising performance .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 6, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",SpanMlt: A Span-based Multi-Task Learning Framework for Pair-wise Aspect and Opinion Terms Extraction,"Aspect terms extraction and opinion terms extraction are two key problems of fine-grained Aspect Based Sentiment Analysis (ABSA). The aspect-opinion pairs can provide a global profile about a product or service for consumers and opinion mining systems. However, traditional methods can not directly output aspect-opinion pairs without given aspect terms or opinion terms. Although some recent co-extraction methods have been proposed to extract both terms jointly, they fail to extract them as pairs. To this end, this paper proposes an end-to-end method to solve the task of Pair-wise Aspect and Opinion Terms Extraction (PAOTE). Furthermore, this paper treats the problem from a perspective of joint term and relation extraction rather than under the sequence tagging formulation performed in most prior works. We propose a multi-task learning framework based on shared spans, where the terms are extracted under the supervision of span boundaries. Meanwhile, the pair-wise relations are jointly identified using the span representations. Extensive experiments show that our model consistently outperforms stateof-the-art methods.","SpanMlt: A Span-based Multi-Task Learning Framework for Pair-wise Aspect and Opinion Terms Extraction Aspect terms extraction and opinion terms extraction are two key problems of fine-grained Aspect Based Sentiment Analysis (ABSA). The aspect-opinion pairs can provide a global profile about a product or service for consumers and opinion mining systems. However, traditional methods can not directly output aspect-opinion pairs without given aspect terms or opinion terms. Although some recent co-extraction methods have been proposed to extract both terms jointly, they fail to extract them as pairs. To this end, this paper proposes an end-to-end method to solve the task of Pair-wise Aspect and Opinion Terms Extraction (PAOTE). Furthermore, this paper treats the problem from a perspective of joint term and relation extraction rather than under the sequence tagging formulation performed in most prior works. We propose a multi-task learning framework based on shared spans, where the terms are extracted under the supervision of span boundaries. Meanwhile, the pair-wise relations are jointly identified using the span representations. Extensive experiments show that our model consistently outperforms stateof-the-art methods.","spanmlt : span - base multi - task learning framework pair - wise aspect opinion term extraction aspect term extraction opinion term extraction key problem fine - grained aspect based sentiment analysis ( absa ) . aspect - opinion pair provide global profile product service consumer opinion mining system . , traditional method directly output aspect - opinion pair give aspect term opinion term . recent co - extraction method propose extract term jointly , fail extract pair . end , paper propose end - - end method solve task pair - wise aspect opinion terms extraction ( paote ) . furthermore , paper treat problem perspective joint term relation extraction sequence tagging formulation perform prior work . propose multi - task learning framework base share span , term extract supervision span boundary . , pair - wise relation jointly identify span representation . extensive experiment model consistently outperform stateof - - art method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 6, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 22, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Out of the Echo Chamber: Detecting Countering Debate Speeches,"An educated and informed consumption of media content has become a challenge in modern times. With the shift from traditional news outlets to social media and similar venues, a major concern is that readers are becoming encapsulated in ""echo chambers"" and may fall prey to fake news and disinformation, lacking easy access to dissenting views. We suggest a novel task aiming to alleviate some of these concerns -that of detecting articles that most effectively counter the arguments -and not just the stance -made in a given text. We study this problem in the context of debate speeches. Given such a speech, we aim to identify, from among a set of speeches on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community. We explore several algorithms addressing this task, and while some are successful, all fall short of expert human performance, suggesting room for further research. All data collected during this work is freely available for research 1 .","Out of the Echo Chamber: Detecting Countering Debate Speeches An educated and informed consumption of media content has become a challenge in modern times. With the shift from traditional news outlets to social media and similar venues, a major concern is that readers are becoming encapsulated in ""echo chambers"" and may fall prey to fake news and disinformation, lacking easy access to dissenting views. We suggest a novel task aiming to alleviate some of these concerns -that of detecting articles that most effectively counter the arguments -and not just the stance -made in a given text. We study this problem in the context of debate speeches. Given such a speech, we aim to identify, from among a set of speeches on the same topic and with an opposing stance, the ones that directly counter it. We provide a large dataset of 3685 such speeches (in English), annotated for this relation, which hopefully would be of general interest to the NLP community. We explore several algorithms addressing this task, and while some are successful, all fall short of expert human performance, suggesting room for further research. All data collected during this work is freely available for research 1 .","echo chamber : detect counter debate speech educated informed consumption medium content challenge modern time . shift traditional news outlet social medium similar venue , major concern reader encapsulate "" echo chamber "" fall prey fake news disinformation , lack easy access dissent view . suggest novel task aim alleviate concern -that detect article effectively counter argument -and stance -made give text . study problem context debate speech . give speech , aim identify , set speech topic opposing stance , one directly counter . provide large dataset 3685 speech ( english ) , annotate relation , hopefully general interest nlp community . explore algorithm address task , successful , fall short expert human performance , suggest room research . data collect work freely available research 1 .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Relational Graph Attention Network for Aspect-based Sentiment Analysis,"Aspect-based sentiment analysis aims to determine the sentiment polarity towards a specific aspect in online reviews. Most recent efforts adopt attention-based neural network models to implicitly connect aspects with opinion words. However, due to the complexity of language and the existence of multiple aspects in a single sentence, these models often confuse the connections. In this paper, we address this problem by means of effective encoding of syntax information. Firstly, we define a unified aspect-oriented dependency tree structure rooted at a target aspect by reshaping and pruning an ordinary dependency parse tree. Then, we propose a relational graph attention network (R-GAT) to encode the new tree structure for sentiment prediction. Extensive experiments are conducted on the SemEval 2014 and Twitter datasets, and the experimental results confirm that the connections between aspects and opinion words can be better established with our approach, and the performance of the graph attention network (GAT) is significantly improved as a consequence.","Relational Graph Attention Network for Aspect-based Sentiment Analysis Aspect-based sentiment analysis aims to determine the sentiment polarity towards a specific aspect in online reviews. Most recent efforts adopt attention-based neural network models to implicitly connect aspects with opinion words. However, due to the complexity of language and the existence of multiple aspects in a single sentence, these models often confuse the connections. In this paper, we address this problem by means of effective encoding of syntax information. Firstly, we define a unified aspect-oriented dependency tree structure rooted at a target aspect by reshaping and pruning an ordinary dependency parse tree. Then, we propose a relational graph attention network (R-GAT) to encode the new tree structure for sentiment prediction. Extensive experiments are conducted on the SemEval 2014 and Twitter datasets, and the experimental results confirm that the connections between aspects and opinion words can be better established with our approach, and the performance of the graph attention network (GAT) is significantly improved as a consequence.","relational graph attention network aspect - base sentiment analysis aspect - base sentiment analysis aim determine sentiment polarity specific aspect online review . recent effort adopt attention - base neural network model implicitly connect aspect opinion word . , complexity language existence multiple aspect single sentence , model confuse connection . paper , address problem mean effective encoding syntax information . firstly , define unified aspect - orient dependency tree structure root target aspect reshape prune ordinary dependency parse tree . , propose relational graph attention network ( r - gat ) encode new tree structure sentiment prediction . extensive experiment conduct semeval 2014 twitter dataset , experimental result confirm connection aspect opinion word well establish approach , performance graph attention network ( gat ) significantly improve consequence .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 16, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining","ECPE-2D: Emotion-Cause Pair Extraction based on Joint Two-Dimensional Representation, Interaction and Prediction","In recent years, a new interesting task, called emotion-cause pair extraction (ECPE), has emerged in the area of text emotion analysis. It aims at extracting the potential pairs of emotions and their corresponding causes in a document. To solve this task, the existing research employed a two-step framework, which first extracts individual emotion set and cause set, and then pair the corresponding emotions and causes. However, such a pipeline of two steps contains some inherent flaws: 1) the modeling does not aim at extracting the final emotion-cause pair directly; 2) the errors from the first step will affect the performance of the second step. To address these shortcomings, in this paper we propose a new end-toend approach, called ECPE-Two-Dimensional (ECPE-2D), to represent the emotion-cause pairs by a 2D representation scheme. A 2D transformer module and two variants, windowconstrained and cross-road 2D transformers, are further proposed to model the interactions of different emotion-cause pairs. The 2D representation, interaction, and prediction are integrated into a joint framework. In addition to the advantages of joint modeling, the experimental results on the benchmark emotion cause corpus show that our approach improves the F1 score of the state-of-the-art from 61.28% to 68.89%.","ECPE-2D: Emotion-Cause Pair Extraction based on Joint Two-Dimensional Representation, Interaction and Prediction In recent years, a new interesting task, called emotion-cause pair extraction (ECPE), has emerged in the area of text emotion analysis. It aims at extracting the potential pairs of emotions and their corresponding causes in a document. To solve this task, the existing research employed a two-step framework, which first extracts individual emotion set and cause set, and then pair the corresponding emotions and causes. However, such a pipeline of two steps contains some inherent flaws: 1) the modeling does not aim at extracting the final emotion-cause pair directly; 2) the errors from the first step will affect the performance of the second step. To address these shortcomings, in this paper we propose a new end-toend approach, called ECPE-Two-Dimensional (ECPE-2D), to represent the emotion-cause pairs by a 2D representation scheme. A 2D transformer module and two variants, windowconstrained and cross-road 2D transformers, are further proposed to model the interactions of different emotion-cause pairs. The 2D representation, interaction, and prediction are integrated into a joint framework. In addition to the advantages of joint modeling, the experimental results on the benchmark emotion cause corpus show that our approach improves the F1 score of the state-of-the-art from 61.28% to 68.89%.","ecpe-2d : emotion - cause pair extraction base joint - dimensional representation , interaction prediction recent year , new interesting task , call emotion - cause pair extraction ( ecpe ) , emerge area text emotion analysis . aim extract potential pair emotion corresponding cause document . solve task , exist research employ - step framework , extract individual emotion set cause set , pair correspond emotion cause . , pipeline step contain inherent flaw : 1 ) modeling aim extract final emotion - cause pair directly ; 2 ) error step affect performance second step . address shortcoming , paper propose new end - toend approach , call ecpe - - dimensional ( ecpe-2d ) , represent emotion - cause pair 2d representation scheme . 2d transformer module variant , windowconstrained cross - road 2d transformer , propose model interaction different emotion - cause pair . 2d representation , interaction , prediction integrate joint framework . addition advantage joint modeling , experimental result benchmark emotion cause corpus approach improve f1 score state - - - art 61.28 % 68.89 % .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 23, 'Speech and Multimodality': 12, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Cross-Lingual Unsupervised Sentiment Classification with Multi-View Transfer Learning,"Recent neural network models have achieved impressive performance on sentiment classification in English as well as other languages. Their success heavily depends on the availability of a large amount of labeled data or parallel corpus. In this paper, we investigate an extreme scenario of cross-lingual sentiment classification, in which the low-resource language does not have any labels or parallel corpus. We propose an unsupervised cross-lingual sentiment classification model named multi-view encoder-classifier (MVEC) that leverages an unsupervised machine translation (UMT) system and a language discriminator. Unlike previous language model (LM) based fine-tuning approaches that adjust parameters solely based on the classification error on training data, we employ the encoder-decoder framework of a UMT as a regularization component on the shared network parameters. In particular, the cross-lingual encoder of our model learns a shared representation, which is effective for both reconstructing input sentences of two languages and generating more representative views from the input for classification. Extensive experiments on five language pairs verify that our model significantly outperforms other models for 8/11 sentiment classification tasks.","Cross-Lingual Unsupervised Sentiment Classification with Multi-View Transfer Learning Recent neural network models have achieved impressive performance on sentiment classification in English as well as other languages. Their success heavily depends on the availability of a large amount of labeled data or parallel corpus. In this paper, we investigate an extreme scenario of cross-lingual sentiment classification, in which the low-resource language does not have any labels or parallel corpus. We propose an unsupervised cross-lingual sentiment classification model named multi-view encoder-classifier (MVEC) that leverages an unsupervised machine translation (UMT) system and a language discriminator. Unlike previous language model (LM) based fine-tuning approaches that adjust parameters solely based on the classification error on training data, we employ the encoder-decoder framework of a UMT as a regularization component on the shared network parameters. In particular, the cross-lingual encoder of our model learns a shared representation, which is effective for both reconstructing input sentences of two languages and generating more representative views from the input for classification. Extensive experiments on five language pairs verify that our model significantly outperforms other models for 8/11 sentiment classification tasks.","cross - lingual unsupervised sentiment classification multi - view transfer learning recent neural network model achieve impressive performance sentiment classification english language . success heavily depend availability large label datum parallel corpus . paper , investigate extreme scenario cross - lingual sentiment classification , low - resource language label parallel corpus . propose unsupervised cross - lingual sentiment classification model name multi - view encoder - classifier ( mvec ) leverage unsupervised machine translation ( umt ) system language discriminator . unlike previous language model ( lm ) base fine - tuning approach adjust parameter solely base classification error train datum , employ encoder - decoder framework umt regularization component share network parameter . particular , cross - lingual encoder model learn share representation , effective reconstruct input sentence language generate representative view input classification . extensive experiment language pair verify model significantly outperform model 8/11 sentiment classification task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 1, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Modelling Context and Syntactical Features for Aspect-based Sentiment Analysis,"The aspect-based sentiment analysis (ABSA) consists of two conceptual tasks, namely an aspect extraction and an aspect sentiment classification. Rather than considering the tasks separately, we build an end-to-end ABSA solution. Previous works in ABSA tasks did not fully leverage the importance of syntactical information. Hence, the aspect extraction model often failed to detect the boundaries of multi-word aspect terms. On the other hand, the aspect sentiment classifier was unable to account for the syntactical correlation between aspect terms and the context words. This paper explores the grammatical aspect of the sentence and employs the self-attention mechanism for syntactical learning. We combine part-of-speech embeddings, dependencybased embeddings and contextualized embeddings (e.g. BERT, RoBERTa) to enhance the performance of the aspect extractor. We also propose the syntactic relative distance to de-emphasize the adverse effects of unrelated words, having weak syntactic connection with the aspect terms. This increases the accuracy of the aspect sentiment classifier. Our solutions outperform the state-of-the-art models on SemEval-2014 dataset in both two subtasks.","Modelling Context and Syntactical Features for Aspect-based Sentiment Analysis The aspect-based sentiment analysis (ABSA) consists of two conceptual tasks, namely an aspect extraction and an aspect sentiment classification. Rather than considering the tasks separately, we build an end-to-end ABSA solution. Previous works in ABSA tasks did not fully leverage the importance of syntactical information. Hence, the aspect extraction model often failed to detect the boundaries of multi-word aspect terms. On the other hand, the aspect sentiment classifier was unable to account for the syntactical correlation between aspect terms and the context words. This paper explores the grammatical aspect of the sentence and employs the self-attention mechanism for syntactical learning. We combine part-of-speech embeddings, dependencybased embeddings and contextualized embeddings (e.g. BERT, RoBERTa) to enhance the performance of the aspect extractor. We also propose the syntactic relative distance to de-emphasize the adverse effects of unrelated words, having weak syntactic connection with the aspect terms. This increases the accuracy of the aspect sentiment classifier. Our solutions outperform the state-of-the-art models on SemEval-2014 dataset in both two subtasks.","model context syntactical feature aspect - base sentiment analysis aspect - base sentiment analysis ( absa ) consist conceptual task , aspect extraction aspect sentiment classification . consider task separately , build end - - end absa solution . previous work absa task fully leverage importance syntactical information . , aspect extraction model fail detect boundary multi - word aspect term . hand , aspect sentiment classifier unable account syntactical correlation aspect term context word . paper explore grammatical aspect sentence employ self - attention mechanism syntactical learning . combine - - speech embedding , dependencybased embedding contextualize embedding ( e.g. bert , roberta ) enhance performance aspect extractor . propose syntactic relative distance de - emphasize adverse effect unrelated word , have weak syntactic connection aspect term . increase accuracy aspect sentiment classifier . solution outperform state - - - art model semeval-2014 dataset subtask .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 7, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 22, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Efficient Pairwise Annotation of Argument Quality,"We present an efficient annotation framework for argument quality, a feature difficult to be measured reliably as per previous work. A stochastic transitivity model is combined with an effective sampling strategy to infer highquality labels with low effort from crowdsourced pairwise judgments. The model's capabilities are showcased by compiling Webis-ArgQuality-20, an argument quality corpus that comprises scores for rhetorical, logical, dialectical, and overall quality inferred from a total of 41,859 pairwise judgments among 1,271 arguments. With up to 93% cost savings, our approach significantly outperforms existing annotation procedures. Furthermore, novel insight into argument quality is provided through statistical analysis, and a new aggregation method to infer overall quality from individual quality dimensions is proposed.","Efficient Pairwise Annotation of Argument Quality We present an efficient annotation framework for argument quality, a feature difficult to be measured reliably as per previous work. A stochastic transitivity model is combined with an effective sampling strategy to infer highquality labels with low effort from crowdsourced pairwise judgments. The model's capabilities are showcased by compiling Webis-ArgQuality-20, an argument quality corpus that comprises scores for rhetorical, logical, dialectical, and overall quality inferred from a total of 41,859 pairwise judgments among 1,271 arguments. With up to 93% cost savings, our approach significantly outperforms existing annotation procedures. Furthermore, novel insight into argument quality is provided through statistical analysis, and a new aggregation method to infer overall quality from individual quality dimensions is proposed.","efficient pairwise annotation argument quality present efficient annotation framework argument quality , feature difficult measure reliably previous work . stochastic transitivity model combine effective sampling strategy infer highquality label low effort crowdsource pairwise judgment . model capability showcase compile webis - argquality-20 , argument quality corpus comprise score rhetorical , logical , dialectical , overall quality infer total 41,859 pairwise judgment 1,271 argument . 93 % cost saving , approach significantly outperform exist annotation procedure . furthermore , novel insight argument quality provide statistical analysis , new aggregation method infer overall quality individual quality dimension propose .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",GoEmotions: A Dataset of Fine-Grained Emotions,"Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERTbased model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement. 1","GoEmotions: A Dataset of Fine-Grained Emotions Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERTbased model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement. 1","goemotions : dataset fine - grained emotion understand emotion express language wide range application , build empathetic chatbot detect harmful online behavior . advancement area improve large - scale dataset fine - grained typology , adaptable multiple downstream task . introduce goemotions , large manually annotate dataset 58k english reddit comment , label 27 emotion category neutral . demonstrate high quality annotation principal preserved component analysis . conduct transfer learning experiment exist emotion benchmark dataset generalize domain different emotion taxonomy . bertbased model achieve average f1 - score .46 propose taxonomy , leave room improvement . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 7, 'Speech and Multimodality': 7, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Effective Inter-Clause Modeling for End-to-End Emotion-Cause Pair Extraction,"Emotion-cause pair extraction aims to extract all emotion clauses coupled with their cause clauses from a given document. Previous work employs two-step approaches, in which the first step extracts emotion clauses and cause clauses separately, and the second step trains a classifier to filter out negative pairs. However, such pipeline-style system for emotion-cause pair extraction is suboptimal because it suffers from error propagation and the two steps may not adapt to each other well. In this paper, we tackle emotion-cause pair extraction from a ranking perspective, i.e., ranking clause pair candidates in a document, and propose a onestep neural approach which emphasizes interclause modeling to perform end-to-end extraction. It models the interrelations between the clauses in a document to learn clause representations with graph attention, and enhances clause pair representations with kernel-based relative position embedding for effective ranking. Experimental results show that our approach significantly outperforms the current two-step systems, especially in the condition of extracting multiple pairs in one document.","Effective Inter-Clause Modeling for End-to-End Emotion-Cause Pair Extraction Emotion-cause pair extraction aims to extract all emotion clauses coupled with their cause clauses from a given document. Previous work employs two-step approaches, in which the first step extracts emotion clauses and cause clauses separately, and the second step trains a classifier to filter out negative pairs. However, such pipeline-style system for emotion-cause pair extraction is suboptimal because it suffers from error propagation and the two steps may not adapt to each other well. In this paper, we tackle emotion-cause pair extraction from a ranking perspective, i.e., ranking clause pair candidates in a document, and propose a onestep neural approach which emphasizes interclause modeling to perform end-to-end extraction. It models the interrelations between the clauses in a document to learn clause representations with graph attention, and enhances clause pair representations with kernel-based relative position embedding for effective ranking. Experimental results show that our approach significantly outperforms the current two-step systems, especially in the condition of extracting multiple pairs in one document.","effective inter - clause modeling end - - end emotion - cause pair extraction emotion - cause pair extraction aim extract emotion clause couple cause clause give document . previous work employ - step approach , step extract emotion clause cause clause separately , second step train classifier filter negative pair . , pipeline - style system emotion - cause pair extraction suboptimal suffer error propagation step adapt . paper , tackle emotion - cause pair extraction ranking perspective , i.e. , rank clause pair candidate document , propose onestep neural approach emphasize interclause modeling perform end - - end extraction . model interrelation clause document learn clause representation graph attention , enhance clause pair representation kernel - base relative position embedding effective ranking . experimental result approach significantly outperform current - step system , especially condition extract multiple pair document .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 17, 'Speech and Multimodality': 10, 'Student Research Workshop': 0, 'Summarization': 4, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Agreement Prediction of Arguments in Cyber Argumentation for Detecting Stance Polarity and Intensity,"In online debates, users express different levels of agreement/disagreement with one another's arguments and ideas. Often levels of agreement/disagreement are implicit in the text and must be predicted to analyze collective opinions. Existing stance detection methods predict the polarity of a post's stance toward a topic or post, but don't consider the stance's degree of intensity. We introduce a new research problem, stance polarity and intensity prediction in response relationships between posts. This problem is challenging because differences in stance intensity are often subtle and require nuanced language understanding. Cyber argumentation research has shown that incorporating both stance polarity and intensity data in online debates leads to better discussion analysis. We explore five different learning models: Ridge-M regression, Ridge-S regression, SVR-RF-R, pkudblab-PIP, and T-PAN-PIP for predicting stance polarity and intensity in argumentation. These models are evaluated using a new dataset for stance polarity and intensity prediction collected using a cyber argumentation platform. The SVR-RF-R model performs best for prediction of stance polarity with an accuracy of 70.43% and intensity with RMSE of 0.596. This work is the first to train models for predicting a post's stance polarity and intensity in one combined value in cyber argumentation with reasonably good accuracy.","Agreement Prediction of Arguments in Cyber Argumentation for Detecting Stance Polarity and Intensity In online debates, users express different levels of agreement/disagreement with one another's arguments and ideas. Often levels of agreement/disagreement are implicit in the text and must be predicted to analyze collective opinions. Existing stance detection methods predict the polarity of a post's stance toward a topic or post, but don't consider the stance's degree of intensity. We introduce a new research problem, stance polarity and intensity prediction in response relationships between posts. This problem is challenging because differences in stance intensity are often subtle and require nuanced language understanding. Cyber argumentation research has shown that incorporating both stance polarity and intensity data in online debates leads to better discussion analysis. We explore five different learning models: Ridge-M regression, Ridge-S regression, SVR-RF-R, pkudblab-PIP, and T-PAN-PIP for predicting stance polarity and intensity in argumentation. These models are evaluated using a new dataset for stance polarity and intensity prediction collected using a cyber argumentation platform. The SVR-RF-R model performs best for prediction of stance polarity with an accuracy of 70.43% and intensity with RMSE of 0.596. This work is the first to train models for predicting a post's stance polarity and intensity in one combined value in cyber argumentation with reasonably good accuracy.","agreement prediction argument cyber argumentation detect stance polarity intensity online debate , user express different level agreement / disagreement argument idea . level agreement / disagreement implicit text predict analyze collective opinion . exist stance detection method predict polarity post stance topic post , consider stance degree intensity . introduce new research problem , stance polarity intensity prediction response relationship post . problem challenging difference stance intensity subtle require nuanced language understanding . cyber argumentation research show incorporate stance polarity intensity datum online debate lead well discussion analysis . explore different learning model : ridge - m regression , ridge - s regression , svr - rf - r , pkudblab - pip , t - pan - pip predict stance polarity intensity argumentation . model evaluate new dataset stance polarity intensity prediction collect cyber argumentation platform . svr - rf - r model perform well prediction stance polarity accuracy 70.43 % intensity rmse 0.596 . work train model predict post stance polarity intensity combine value cyber argumentation reasonably good accuracy .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 9, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 9, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 19, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Entity-Aware Dependency-Based Deep Graph Attention Network for Comparative Preference Classification,"This paper studies the task of comparative preference classification (CPC). Given two entities in a sentence, our goal is to classify whether the first (or the second) entity is preferred over the other or no comparison is expressed at all between the two entities. Existing works either do not learn entity-aware representations well and fail to deal with sentences involving multiple entity pairs or use sequential modeling approaches that are unable to capture long-range dependencies between the entities. Some also use traditional machine learning approaches that do not generalize well. This paper proposes a novel Entityaware Dependency-based Deep Graph Attention Network (ED-GAT) that employs a multihop graph attention over a dependency graph sentence representation to leverage both the semantic information from word embeddings and the syntactic information from the dependency graph to solve the problem. Empirical evaluation shows that the proposed model achieves the state-of-the-art performance in comparative preference classification.","Entity-Aware Dependency-Based Deep Graph Attention Network for Comparative Preference Classification This paper studies the task of comparative preference classification (CPC). Given two entities in a sentence, our goal is to classify whether the first (or the second) entity is preferred over the other or no comparison is expressed at all between the two entities. Existing works either do not learn entity-aware representations well and fail to deal with sentences involving multiple entity pairs or use sequential modeling approaches that are unable to capture long-range dependencies between the entities. Some also use traditional machine learning approaches that do not generalize well. This paper proposes a novel Entityaware Dependency-based Deep Graph Attention Network (ED-GAT) that employs a multihop graph attention over a dependency graph sentence representation to leverage both the semantic information from word embeddings and the syntactic information from the dependency graph to solve the problem. Empirical evaluation shows that the proposed model achieves the state-of-the-art performance in comparative preference classification.","entity - aware dependency - base deep graph attention network comparative preference classification paper study task comparative preference classification ( cpc ) . give entity sentence , goal classify ( second ) entity prefer comparison express entity . exist work learn entity - aware representation fail deal sentence involve multiple entity pair use sequential modeling approach unable capture long - range dependency entity . use traditional machine learning approach generalize . paper propose novel entityaware dependency - base deep graph attention network ( ed - gat ) employ multihop graph attention dependency graph sentence representation leverage semantic information word embedding syntactic information dependency graph solve problem . empirical evaluation show propose model achieve state - - - art performance comparative preference classification .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis,"Recently, sentiment analysis has seen remarkable advance with the help of pre-training approaches. However, sentiment knowledge, such as sentiment words and aspect-sentiment pairs, is ignored in the process of pre-training, despite the fact that they are widely used in traditional sentiment analysis approaches. In this paper, we introduce Sentiment Knowledge Enhanced Pre-training (SKEP) in order to learn a unified sentiment representation for multiple sentiment analysis tasks. With the help of automatically-mined knowledge, SKEP conducts sentiment masking and constructs three sentiment knowledge prediction objectives, so as to embed sentiment information at the word, polarity and aspect level into pre-trained sentiment representation. In particular, the prediction of aspect-sentiment pairs is converted into multi-label classification, aiming to capture the dependency between words in a pair. Experiments on three kinds of sentiment tasks show that SKEP significantly outperforms strong pre-training baseline, and achieves new state-of-the-art results on most of the test datasets. We release our code at https://github.com/baidu/Senta.","SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis Recently, sentiment analysis has seen remarkable advance with the help of pre-training approaches. However, sentiment knowledge, such as sentiment words and aspect-sentiment pairs, is ignored in the process of pre-training, despite the fact that they are widely used in traditional sentiment analysis approaches. In this paper, we introduce Sentiment Knowledge Enhanced Pre-training (SKEP) in order to learn a unified sentiment representation for multiple sentiment analysis tasks. With the help of automatically-mined knowledge, SKEP conducts sentiment masking and constructs three sentiment knowledge prediction objectives, so as to embed sentiment information at the word, polarity and aspect level into pre-trained sentiment representation. In particular, the prediction of aspect-sentiment pairs is converted into multi-label classification, aiming to capture the dependency between words in a pair. Experiments on three kinds of sentiment tasks show that SKEP significantly outperforms strong pre-training baseline, and achieves new state-of-the-art results on most of the test datasets. We release our code at https://github.com/baidu/Senta.","skep : sentiment knowledge enhanced pre - training sentiment analysis recently , sentiment analysis see remarkable advance help pre - training approach . , sentiment knowledge , sentiment word aspect - sentiment pair , ignore process pre - training , despite fact widely traditional sentiment analysis approach . paper , introduce sentiment knowledge enhanced pre - training ( skep ) order learn unified sentiment representation multiple sentiment analysis task . help automatically - mine knowledge , skep conduct sentiment masking construct sentiment knowledge prediction objective , embed sentiment information word , polarity aspect level pre - trained sentiment representation . particular , prediction aspect - sentiment pair convert multi - label classification , aim capture dependency word pair . experiment kind sentiment task skep significantly outperform strong pre - training baseline , achieve new state - - - art result test dataset . release code https://github.com/baidu/senta .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 23, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics,"We propose SentiBERT, a variant of BERT that effectively captures compositional sentiment semantics. The model incorporates contextualized representation with binary constituency parse tree to capture semantic composition. Comprehensive experiments demonstrate that SentiBERT achieves competitive performance on phrase-level sentiment classification. We further demonstrate that the sentiment composition learned from the phrase-level annotations on SST can be transferred to other sentiment analysis tasks as well as related tasks, such as emotion classification tasks. Moreover, we conduct ablation studies and design visualization methods to understand SentiBERT. We show that SentiBERT is better than baseline approaches in capturing negation and the contrastive relation and model the compositional sentiment semantics.","SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics We propose SentiBERT, a variant of BERT that effectively captures compositional sentiment semantics. The model incorporates contextualized representation with binary constituency parse tree to capture semantic composition. Comprehensive experiments demonstrate that SentiBERT achieves competitive performance on phrase-level sentiment classification. We further demonstrate that the sentiment composition learned from the phrase-level annotations on SST can be transferred to other sentiment analysis tasks as well as related tasks, such as emotion classification tasks. Moreover, we conduct ablation studies and design visualization methods to understand SentiBERT. We show that SentiBERT is better than baseline approaches in capturing negation and the contrastive relation and model the compositional sentiment semantics.","sentibert : transferable transformer - base architecture compositional sentiment semantic propose sentibert , variant bert effectively capture compositional sentiment semantic . model incorporate contextualize representation binary constituency parse tree capture semantic composition . comprehensive experiment demonstrate sentibert achieve competitive performance phrase - level sentiment classification . demonstrate sentiment composition learn phrase - level annotation sst transfer sentiment analysis task related task , emotion classification task . , conduct ablation study design visualization method understand sentibert . sentibert well baseline approach capture negation contrastive relation model compositional sentiment semantic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Relation-Aware Collaborative Learning for Unified Aspect-Based Sentiment Analysis,"Aspect-based sentiment analysis (ABSA) involves three subtasks, i.e., aspect term extraction, opinion term extraction, and aspect-level sentiment classification. Most existing studies focused on one of these subtasks only. Several recent researches made successful attempts to solve the complete ABSA problem with a unified framework. However, the interactive relations among three subtasks are still underexploited. We argue that such relations encode collaborative signals between different subtasks. For example, when the opinion term is ""delicious"", the aspect term must be ""food"" rather than ""place"". In order to fully exploit these relations, we propose a Relation-Aware Collaborative Learning (RACL) framework which allows the subtasks to work coordinately via the multi-task learning and relation propagation mechanisms in a stacked multi-layer network. Extensive experiments on three real-world datasets demonstrate that RACL significantly outperforms the state-ofthe-art methods for the complete ABSA task.","Relation-Aware Collaborative Learning for Unified Aspect-Based Sentiment Analysis Aspect-based sentiment analysis (ABSA) involves three subtasks, i.e., aspect term extraction, opinion term extraction, and aspect-level sentiment classification. Most existing studies focused on one of these subtasks only. Several recent researches made successful attempts to solve the complete ABSA problem with a unified framework. However, the interactive relations among three subtasks are still underexploited. We argue that such relations encode collaborative signals between different subtasks. For example, when the opinion term is ""delicious"", the aspect term must be ""food"" rather than ""place"". In order to fully exploit these relations, we propose a Relation-Aware Collaborative Learning (RACL) framework which allows the subtasks to work coordinately via the multi-task learning and relation propagation mechanisms in a stacked multi-layer network. Extensive experiments on three real-world datasets demonstrate that RACL significantly outperforms the state-ofthe-art methods for the complete ABSA task.","relation - aware collaborative learning unified aspect - base sentiment analysis aspect - base sentiment analysis ( absa ) involve subtask , i.e. , aspect term extraction , opinion term extraction , aspect - level sentiment classification . exist study focus subtask . recent research successful attempt solve complete absa problem unify framework . , interactive relation subtask underexploited . argue relation encode collaborative signal different subtask . example , opinion term "" delicious "" , aspect term "" food "" "" place "" . order fully exploit relation , propose relation - aware collaborative learning ( racl ) framework allow subtask work coordinately multi - task learning relation propagation mechanism stack multi - layer network . extensive experiment real - world dataset demonstrate racl significantly outperform state - ofthe - art method complete absa task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 14, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",KinGDOM: Knowledge-Guided DOMain Adaptation for Sentiment Analysis,"Cross-domain sentiment analysis has received significant attention in recent years, prompted by the need to combat the domain gap between different applications that make use of sentiment analysis. In this paper, we take a novel perspective on this task by exploring the role of external commonsense knowledge. We introduce a new framework, KinGDOM, which utilizes the ConceptNet knowledge graph to enrich the semantics of a document by providing both domain-specific and domain-general background concepts. These concepts are learned by training a graph convolutional autoencoder that leverages inter-domain concepts in a domain-invariant manner. Conditioning a popular domain-adversarial baseline method with these learned concepts helps improve its performance over state-of-the-art approaches, demonstrating the efficacy of our proposed framework.","KinGDOM: Knowledge-Guided DOMain Adaptation for Sentiment Analysis Cross-domain sentiment analysis has received significant attention in recent years, prompted by the need to combat the domain gap between different applications that make use of sentiment analysis. In this paper, we take a novel perspective on this task by exploring the role of external commonsense knowledge. We introduce a new framework, KinGDOM, which utilizes the ConceptNet knowledge graph to enrich the semantics of a document by providing both domain-specific and domain-general background concepts. These concepts are learned by training a graph convolutional autoencoder that leverages inter-domain concepts in a domain-invariant manner. Conditioning a popular domain-adversarial baseline method with these learned concepts helps improve its performance over state-of-the-art approaches, demonstrating the efficacy of our proposed framework.","kingdom : knowledge - guide domain adaptation sentiment analysis cross - domain sentiment analysis receive significant attention recent year , prompt need combat domain gap different application use sentiment analysis . paper , novel perspective task explore role external commonsense knowledge . introduce new framework , kingdom , utilize conceptnet knowledge graph enrich semantic document provide domain - specific domain - general background concept . concept learn train graph convolutional autoencoder leverage inter - domain concept domain - invariant manner . condition popular domain - adversarial baseline method learn concept help improve performance state - - - art approach , demonstrate efficacy propose framework .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Syntax-Aware Opinion Role Labeling with Dependency Graph Convolutional Networks,"Opinion role labeling (ORL) is a fine-grained opinion analysis task and aims to answer ""who expressed what kind of sentiment towards what?"". Due to the scarcity of labeled data, ORL remains challenging for data-driven methods. In this work, we try to enhance neural ORL models with syntactic knowledge by comparing and integrating different representations. We also propose dependency graph convolutional networks (DEPGCN) to encode parser information at different processing levels. In order to compensate for parser inaccuracy and reduce error propagation, we introduce multi-task learning (MTL) to train the parser and the ORL model simultaneously. We verify our methods on the benchmark MPQA corpus. The experimental results show that syntactic information is highly valuable for ORL, and our final MTL model effectively boosts the F1 score by 9.29 over the syntaxagnostic baseline. In addition, we find that the contributions from syntactic knowledge do not fully overlap with contextualized word representations (BERT). Our best model achieves 4.34 higher F1 score than the current state-ofthe-art.","Syntax-Aware Opinion Role Labeling with Dependency Graph Convolutional Networks Opinion role labeling (ORL) is a fine-grained opinion analysis task and aims to answer ""who expressed what kind of sentiment towards what?"". Due to the scarcity of labeled data, ORL remains challenging for data-driven methods. In this work, we try to enhance neural ORL models with syntactic knowledge by comparing and integrating different representations. We also propose dependency graph convolutional networks (DEPGCN) to encode parser information at different processing levels. In order to compensate for parser inaccuracy and reduce error propagation, we introduce multi-task learning (MTL) to train the parser and the ORL model simultaneously. We verify our methods on the benchmark MPQA corpus. The experimental results show that syntactic information is highly valuable for ORL, and our final MTL model effectively boosts the F1 score by 9.29 over the syntaxagnostic baseline. In addition, we find that the contributions from syntactic knowledge do not fully overlap with contextualized word representations (BERT). Our best model achieves 4.34 higher F1 score than the current state-ofthe-art.","syntax - aware opinion role labeling dependency graph convolutional networks opinion role labeling ( orl ) fine - grained opinion analysis task aim answer "" express kind sentiment ? "" . scarcity label datum , orl remain challenging data - drive method . work , try enhance neural orl model syntactic knowledge compare integrate different representation . propose dependency graph convolutional network ( depgcn ) encode parser information different processing level . order compensate parser inaccuracy reduce error propagation , introduce multi - task learning ( mtl ) train parser orl model simultaneously . verify method benchmark mpqa corpus . experimental result syntactic information highly valuable orl , final mtl model effectively boost f1 score 9.29 syntaxagnostic baseline . addition , find contribution syntactic knowledge fully overlap contextualized word representation ( bert ) . good model achieve 4.34 high f1 score current state - ofthe - art .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 2, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}","Syntax: Tagging, Chunking and Parsing",False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Adversarial and Domain-Aware BERT for Cross-Domain Sentiment Analysis,"Cross-domain sentiment classification aims to address the lack of massive amounts of labeled data. It demands to predict sentiment polarity on a target domain utilizing a classifier learned from a source domain. In this paper, we investigate how to efficiently apply the pre-training language model BERT on the unsupervised domain adaptation. Due to the pre-training task and corpus, BERT is taskagnostic, which lacks domain awareness and can not distinguish the characteristic of source and target domain when transferring knowledge. To tackle these problems, we design a post-training procedure, which contains the target domain masked language model task and a novel domain-distinguish pre-training task. The post-training procedure will encourage BERT to be domain-aware and distill the domain-specific features in a self-supervised way. Based on this, we could then conduct the adversarial training to derive the enhanced domain-invariant features. Extensive experiments on Amazon dataset show that our model outperforms state-of-the-art methods by a large margin. The ablation study demonstrates that the remarkable improvement is not only from BERT but also from our method.","Adversarial and Domain-Aware BERT for Cross-Domain Sentiment Analysis Cross-domain sentiment classification aims to address the lack of massive amounts of labeled data. It demands to predict sentiment polarity on a target domain utilizing a classifier learned from a source domain. In this paper, we investigate how to efficiently apply the pre-training language model BERT on the unsupervised domain adaptation. Due to the pre-training task and corpus, BERT is taskagnostic, which lacks domain awareness and can not distinguish the characteristic of source and target domain when transferring knowledge. To tackle these problems, we design a post-training procedure, which contains the target domain masked language model task and a novel domain-distinguish pre-training task. The post-training procedure will encourage BERT to be domain-aware and distill the domain-specific features in a self-supervised way. Based on this, we could then conduct the adversarial training to derive the enhanced domain-invariant features. Extensive experiments on Amazon dataset show that our model outperforms state-of-the-art methods by a large margin. The ablation study demonstrates that the remarkable improvement is not only from BERT but also from our method.","adversarial domain - aware bert cross - domain sentiment analysis cross - domain sentiment classification aim address lack massive amount label datum . demand predict sentiment polarity target domain utilize classifier learn source domain . paper , investigate efficiently apply pre - training language model bert unsupervised domain adaptation . pre - training task corpus , bert taskagnostic , lack domain awareness distinguish characteristic source target domain transfer knowledge . tackle problem , design post - training procedure , contain target domain mask language model task novel domain - distinguish pre - training task . post - training procedure encourage bert domain - aware distill domain - specific feature self - supervise way . base , conduct adversarial training derive enhanced domain - invariant feature . extensive experiment amazon dataset model outperform state - - - art method large margin . ablation study demonstrate remarkable improvement bert method .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks,"Affective tasks such as sentiment analysis, emotion classification and sarcasm detection have been popular in recent years due to abundance of user-generated data, accurate computational linguistic models, and broad range of relevant applications in various domains. At the same time, many studies have highlighted the importance of text preprocessing, as an integral step to any natural language processing prediction model and downstream task. While preprocessing in affective systems is well-studied, preprocessing in word vector based models applied to affective systems, is not. To address this limitation, we conduct a comprehensive analysis of the role of preprocessing techniques in affective analysis based on word vector models. Our analysis is the first of its kind and provides useful insights of the importance of each preprocessing technique when applied at the training phase, commonly ignored in pretrained word vector models, and/or at the downstream task phase.","A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks Affective tasks such as sentiment analysis, emotion classification and sarcasm detection have been popular in recent years due to abundance of user-generated data, accurate computational linguistic models, and broad range of relevant applications in various domains. At the same time, many studies have highlighted the importance of text preprocessing, as an integral step to any natural language processing prediction model and downstream task. While preprocessing in affective systems is well-studied, preprocessing in word vector based models applied to affective systems, is not. To address this limitation, we conduct a comprehensive analysis of the role of preprocessing techniques in affective analysis based on word vector models. Our analysis is the first of its kind and provides useful insights of the importance of each preprocessing technique when applied at the training phase, commonly ignored in pretrained word vector models, and/or at the downstream task phase.","comprehensive analysis preprocessing word representation learning affective task affective task sentiment analysis , emotion classification sarcasm detection popular recent year abundance user - generate datum , accurate computational linguistic model , broad range relevant application domain . time , study highlight importance text preprocessing , integral step natural language processing prediction model downstream task . preprocesse affective system - study , preprocessing word vector base model apply affective system , . address limitation , conduct comprehensive analysis role preprocessing technique affective analysis base word vector model . analysis kind provide useful insight importance preprocessing technique apply training phase , commonly ignore pretrained word vector model , and/or downstream task phase .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Transition-based Directed Graph Construction for Emotion-Cause Pair Extraction,"Emotion-cause pair extraction aims to extract all potential pairs of emotions and corresponding causes from unannotated emotion text. Most existing methods are pipelined framework, which identifies emotions and extracts causes separately, leading to a drawback of error propagation. Towards this issue, we propose a transition-based model to transform the task into a procedure of parsing-like directed graph construction. The proposed model incrementally generates the directed graph with labeled edges based on a sequence of actions, from which we can recognize emotions with the corresponding causes simultaneously, thereby optimizing separate subtasks jointly and maximizing mutual benefits of tasks interdependently. Experimental results show that our approach achieves the best performance, outperforming the state-of-the-art methods by 6.71% (p < 0.01) in F 1 measure.","Transition-based Directed Graph Construction for Emotion-Cause Pair Extraction Emotion-cause pair extraction aims to extract all potential pairs of emotions and corresponding causes from unannotated emotion text. Most existing methods are pipelined framework, which identifies emotions and extracts causes separately, leading to a drawback of error propagation. Towards this issue, we propose a transition-based model to transform the task into a procedure of parsing-like directed graph construction. The proposed model incrementally generates the directed graph with labeled edges based on a sequence of actions, from which we can recognize emotions with the corresponding causes simultaneously, thereby optimizing separate subtasks jointly and maximizing mutual benefits of tasks interdependently. Experimental results show that our approach achieves the best performance, outperforming the state-of-the-art methods by 6.71% (p < 0.01) in F 1 measure.","transition - base directed graph construction emotion - cause pair extraction emotion - cause pair extraction aim extract potential pair emotion corresponding cause unannotated emotion text . exist method pipelined framework , identify emotion extract cause separately , lead drawback error propagation . issue , propose transition - base model transform task procedure parsing - like direct graph construction . propose model incrementally generate direct graph label edge base sequence action , recognize emotion corresponding cause simultaneously , optimize separate subtask jointly maximize mutual benefit task interdependently . experimental result approach achieve good performance , outperform state - - - art method 6.71 % ( p < 0.01 ) f 1 measure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 13, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Target Inference in Argument Conclusion Generation,"In argumentation, people state premises to reason towards a conclusion. The conclusion conveys a stance towards some target, such as a concept or statement. Often, the conclusion remains implicit, though, since it is self-evident in a discussion or left out for rhetorical reasons. However, the conclusion is key to understanding an argument, and hence, to any application that processes argumentation. We thus study the question to what extent an argument's conclusion can be reconstructed from its premises. In particular, we argue here that a decisive step is to infer a conclusion's target, and we hypothesize that this target is related to the premises' targets. We develop two complementary target inference approaches: one ranks premise targets and selects the top-ranked target as the conclusion target, the other finds a new conclusion target in a learned embedding space using a triplet neural network. Our evaluation on corpora from two domains indicates that a hybrid of both approaches is best, outperforming several strong baselines. According to human annotators, we infer a reasonably adequate conclusion target in 89% of the cases.","Target Inference in Argument Conclusion Generation In argumentation, people state premises to reason towards a conclusion. The conclusion conveys a stance towards some target, such as a concept or statement. Often, the conclusion remains implicit, though, since it is self-evident in a discussion or left out for rhetorical reasons. However, the conclusion is key to understanding an argument, and hence, to any application that processes argumentation. We thus study the question to what extent an argument's conclusion can be reconstructed from its premises. In particular, we argue here that a decisive step is to infer a conclusion's target, and we hypothesize that this target is related to the premises' targets. We develop two complementary target inference approaches: one ranks premise targets and selects the top-ranked target as the conclusion target, the other finds a new conclusion target in a learned embedding space using a triplet neural network. Our evaluation on corpora from two domains indicates that a hybrid of both approaches is best, outperforming several strong baselines. According to human annotators, we infer a reasonably adequate conclusion target in 89% of the cases.","target inference argument conclusion generation argumentation , people state premise reason conclusion . conclusion convey stance target , concept statement . , conclusion remain implicit , , self - evident discussion leave rhetorical reason . , conclusion key understand argument , , application process argumentation . study question extent argument conclusion reconstruct premise . particular , argue decisive step infer conclusion target , hypothesize target relate premise ' target . develop complementary target inference approach : rank premise target select - rank target conclusion target , find new conclusion target learn embed space triplet neural network . evaluation corpus domain indicate hybrid approach good , outperform strong baseline . accord human annotator , infer reasonably adequate conclusion target 89 % case .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Embarrassingly Simple Unsupervised Aspect Extraction,"We present a simple but effective method for aspect identification in sentiment analysis. Our unsupervised method only requires word embeddings and a POS tagger, and is therefore straightforward to apply to new domains and languages. We introduce Contrastive Attention (CAt ), a novel single-head attention mechanism based on an RBF kernel, which gives a considerable boost in performance and makes the model interpretable. Previous work relied on syntactic features and complex neural models. We show that given the simplicity of current benchmark datasets for aspect extraction, such complex models are not needed. The code to reproduce the experiments reported in this paper is available at https://github.com/clips/cat.","Embarrassingly Simple Unsupervised Aspect Extraction We present a simple but effective method for aspect identification in sentiment analysis. Our unsupervised method only requires word embeddings and a POS tagger, and is therefore straightforward to apply to new domains and languages. We introduce Contrastive Attention (CAt ), a novel single-head attention mechanism based on an RBF kernel, which gives a considerable boost in performance and makes the model interpretable. Previous work relied on syntactic features and complex neural models. We show that given the simplicity of current benchmark datasets for aspect extraction, such complex models are not needed. The code to reproduce the experiments reported in this paper is available at https://github.com/clips/cat.","embarrassingly simple unsupervised aspect extraction present simple effective method aspect identification sentiment analysis . unsupervised method require word embedding pos tagger , straightforward apply new domain language . introduce contrastive attention ( cat ) , novel single - head attention mechanism base rbf kernel , give considerable boost performance make model interpretable . previous work rely syntactic feature complex neural model . give simplicity current benchmark dataset aspect extraction , complex model need . code reproduce experiment report paper available https://github.com/clips/cat .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 7, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Aspect Sentiment Classification with Document-level Sentiment Preference Modeling,"In the literature, existing studies always consider Aspect Sentiment Classification (ASC) as an independent sentence-level classification problem aspect by aspect, which largely ignore the document-level sentiment preference information, though obviously such information is crucial for alleviating the information deficiency problem in ASC. In this paper, we explore two kinds of sentiment preference information inside a document, i.e., contextual sentiment consistency w.r.t. the same aspect (namely intra-aspect sentiment consistency) and contextual sentiment tendency w.r.t. all the related aspects (namely inter-aspect sentiment tendency). On the basis, we propose a Cooperative Graph Attention Networks (Co-GAN) approach for cooperatively learning the aspect-related sentence representation. Specifically, two graph attention networks are leveraged to model above two kinds of documentlevel sentiment preference information respectively, followed by an interactive mechanism to integrate the two-fold preference. Detailed evaluation demonstrates the great advantage of the proposed approach to ASC over the stateof-the-art baselines. This justifies the importance of the document-level sentiment preference information to ASC and the effectiveness of our approach capturing such information.","Aspect Sentiment Classification with Document-level Sentiment Preference Modeling In the literature, existing studies always consider Aspect Sentiment Classification (ASC) as an independent sentence-level classification problem aspect by aspect, which largely ignore the document-level sentiment preference information, though obviously such information is crucial for alleviating the information deficiency problem in ASC. In this paper, we explore two kinds of sentiment preference information inside a document, i.e., contextual sentiment consistency w.r.t. the same aspect (namely intra-aspect sentiment consistency) and contextual sentiment tendency w.r.t. all the related aspects (namely inter-aspect sentiment tendency). On the basis, we propose a Cooperative Graph Attention Networks (Co-GAN) approach for cooperatively learning the aspect-related sentence representation. Specifically, two graph attention networks are leveraged to model above two kinds of documentlevel sentiment preference information respectively, followed by an interactive mechanism to integrate the two-fold preference. Detailed evaluation demonstrates the great advantage of the proposed approach to ASC over the stateof-the-art baselines. This justifies the importance of the document-level sentiment preference information to ASC and the effectiveness of our approach capturing such information.","aspect sentiment classification document - level sentiment preference modeling literature , exist study consider aspect sentiment classification ( asc ) independent sentence - level classification problem aspect aspect , largely ignore document - level sentiment preference information , obviously information crucial alleviate information deficiency problem asc . paper , explore kind sentiment preference information inside document , i.e. , contextual sentiment consistency w.r.t . aspect ( intra - aspect sentiment consistency ) contextual sentiment tendency w.r.t . related aspect ( inter - aspect sentiment tendency ) . basis , propose cooperative graph attention networks ( co - gan ) approach cooperatively learn aspect - relate sentence representation . specifically , graph attention network leverage model kind documentlevel sentiment preference information respectively , follow interactive mechanism integrate - fold preference . detailed evaluation demonstrate great advantage propose approach asc stateof - - art baseline . justify importance document - level sentiment preference information asc effectiveness approach capture information .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 20, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",OpinionDigest: A Simple Framework for Opinion Summarization,"We present OPINIONDIGEST, an abstractive opinion summarization framework, which does not rely on gold-standard summaries for training. The framework uses an Aspect-based Sentiment Analysis model to extract opinion phrases from reviews, and trains a Transformer model to reconstruct the original reviews from these extractions. At summarization time, we merge extractions from multiple reviews and select the most popular ones. The selected opinions are used as input to the trained Transformer model, which verbalizes them into an opinion summary. OPINIONDIGEST can also generate customized summaries, tailored to specific user needs, by filtering the selected opinions according to their aspect and/or sentiment. Automatic evaluation on YELP data shows that our framework outperforms competitive baselines. Human studies on two corpora verify that OPINIONDIGEST produces informative summaries and shows promising customization capabilities 1 .","OpinionDigest: A Simple Framework for Opinion Summarization We present OPINIONDIGEST, an abstractive opinion summarization framework, which does not rely on gold-standard summaries for training. The framework uses an Aspect-based Sentiment Analysis model to extract opinion phrases from reviews, and trains a Transformer model to reconstruct the original reviews from these extractions. At summarization time, we merge extractions from multiple reviews and select the most popular ones. The selected opinions are used as input to the trained Transformer model, which verbalizes them into an opinion summary. OPINIONDIGEST can also generate customized summaries, tailored to specific user needs, by filtering the selected opinions according to their aspect and/or sentiment. Automatic evaluation on YELP data shows that our framework outperforms competitive baselines. Human studies on two corpora verify that OPINIONDIGEST produces informative summaries and shows promising customization capabilities 1 .","opiniondigest : simple framework opinion summarization present opiniondigest , abstractive opinion summarization framework , rely gold - standard summary training . framework use aspect - base sentiment analysis model extract opinion phrase review , train transformer model reconstruct original review extraction . summarization time , merge extraction multiple review select popular one . select opinion input train transformer model , verbalize opinion summary . opiniondigest generate customize summary , tailor specific user need , filter select opinion accord aspect and/or sentiment . automatic evaluation yelp datum show framework outperform competitive baseline . human study corpus verify opiniondigest produce informative summary show promising customization capability 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 17, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 11, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Analyzing the Persuasive Effect of Style in News Editorial Argumentation,"News editorials argue about political issues in order to challenge or reinforce the stance of readers with different ideologies. Previous research has investigated such persuasive effects for argumentative content. In contrast, this paper studies how important the style of news editorials is to achieve persuasion. To this end, we first compare content-and style-oriented classifiers on editorials from the liberal NYTimes with ideology-specific effect annotations. We find that conservative readers are resistant to NYTimes style, but on liberals, style even has more impact than content. Focusing on liberals, we then cluster the leads, bodies, and endings of editorials, in order to learn about writing style patterns of effective argumentation.","Analyzing the Persuasive Effect of Style in News Editorial Argumentation News editorials argue about political issues in order to challenge or reinforce the stance of readers with different ideologies. Previous research has investigated such persuasive effects for argumentative content. In contrast, this paper studies how important the style of news editorials is to achieve persuasion. To this end, we first compare content-and style-oriented classifiers on editorials from the liberal NYTimes with ideology-specific effect annotations. We find that conservative readers are resistant to NYTimes style, but on liberals, style even has more impact than content. Focusing on liberals, we then cluster the leads, bodies, and endings of editorials, in order to learn about writing style patterns of effective argumentation.","analyze persuasive effect style news editorial argumentation news editorial argue political issue order challenge reinforce stance reader different ideology . previous research investigate persuasive effect argumentative content . contrast , paper study important style news editorial achieve persuasion . end , compare content - style - orient classifier editorial liberal nytimes ideology - specific effect annotation . find conservative reader resistant nytimes style , liberal , style impact content . focus liberal , cluster lead , body , ending editorial , order learn write style pattern effective argumentation .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Don't Eclipse Your Arts Due to Small Discrepancies: Boundary Repositioning with a Pointer Network for Aspect Extraction,"The current aspect extraction methods suffer from boundary errors. These errors lead to a relatively minor difference between the extracted aspects and the ground-truth. However, they hurt the performance severely. In this paper, we propose to utilize a pointer network for repositioning the boundaries. Recycling mechanism is used which enables the training data to be collected without manual intervention. We conduct the experiments on the benchmark datasets SE14 of laptop and SE14-16 of restaurant. Experimental results show that our method achieves substantial improvements over the baseline, and outperforms stateof-the-art methods.","Don't Eclipse Your Arts Due to Small Discrepancies: Boundary Repositioning with a Pointer Network for Aspect Extraction The current aspect extraction methods suffer from boundary errors. These errors lead to a relatively minor difference between the extracted aspects and the ground-truth. However, they hurt the performance severely. In this paper, we propose to utilize a pointer network for repositioning the boundaries. Recycling mechanism is used which enables the training data to be collected without manual intervention. We conduct the experiments on the benchmark datasets SE14 of laptop and SE14-16 of restaurant. Experimental results show that our method achieves substantial improvements over the baseline, and outperforms stateof-the-art methods.","eclipse art small discrepancy : boundary repositioning pointer network aspect extraction current aspect extraction method suffer boundary error . error lead relatively minor difference extract aspect ground - truth . , hurt performance severely . paper , propose utilize pointer network reposition boundary . recycling mechanism enable training datum collect manual intervention . conduct experiment benchmark dataset se14 laptop se14 - 16 restaurant . experimental result method achieve substantial improvement baseline , outperform stateof - - art method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Parallel Data Augmentation for Formality Style Transfer,"The main barrier to progress in the task of Formality Style Transfer is the inadequacy of training data. In this paper, we study how to augment parallel data and propose novel and simple data augmentation methods for this task to obtain useful sentence pairs with easily accessible models and systems. Experiments demonstrate that our augmented parallel data largely helps improve formality style transfer when it is used to pre-train the model, leading to the state-of-the-art results in the GYAFC benchmark dataset 1 .","Parallel Data Augmentation for Formality Style Transfer The main barrier to progress in the task of Formality Style Transfer is the inadequacy of training data. In this paper, we study how to augment parallel data and propose novel and simple data augmentation methods for this task to obtain useful sentence pairs with easily accessible models and systems. Experiments demonstrate that our augmented parallel data largely helps improve formality style transfer when it is used to pre-train the model, leading to the state-of-the-art results in the GYAFC benchmark dataset 1 .","parallel datum augmentation formality style transfer main barrier progress task formality style transfer inadequacy training datum . paper , study augment parallel datum propose novel simple data augmentation method task obtain useful sentence pair easily accessible model system . experiment demonstrate augment parallel datum largely help improve formality style transfer pre - train model , lead state - - - art result gyafc benchmark dataset 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}","Phonology, Morphology and Word Segmentation",False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Conditional Augmentation for Aspect Term Extraction via Masked Sequence-to-Sequence Generation,"Aspect term extraction aims to extract aspect terms from review texts as opinion targets for sentiment analysis. One of the big challenges with this task is the lack of sufficient annotated data. While data augmentation is potentially an effective technique to address the above issue, it is uncontrollable as it may change aspect words and aspect labels unexpectedly. In this paper, we formulate the data augmentation as a conditional generation task: generating a new sentence while preserving the original opinion targets and labels. We propose a masked sequence-to-sequence method for conditional augmentation of aspect term extraction. Unlike existing augmentation approaches, ours is controllable and allows us to generate more diversified sentences. Experimental results confirm that our method alleviates the data scarcity problem significantly. It also effectively boosts the performances of several current models for aspect term extraction.","Conditional Augmentation for Aspect Term Extraction via Masked Sequence-to-Sequence Generation Aspect term extraction aims to extract aspect terms from review texts as opinion targets for sentiment analysis. One of the big challenges with this task is the lack of sufficient annotated data. While data augmentation is potentially an effective technique to address the above issue, it is uncontrollable as it may change aspect words and aspect labels unexpectedly. In this paper, we formulate the data augmentation as a conditional generation task: generating a new sentence while preserving the original opinion targets and labels. We propose a masked sequence-to-sequence method for conditional augmentation of aspect term extraction. Unlike existing augmentation approaches, ours is controllable and allows us to generate more diversified sentences. Experimental results confirm that our method alleviates the data scarcity problem significantly. It also effectively boosts the performances of several current models for aspect term extraction.","conditional augmentation aspect term extraction mask sequence - - sequence generation aspect term extraction aim extract aspect term review text opinion target sentiment analysis . big challenge task lack sufficient annotate datum . datum augmentation potentially effective technique address issue , uncontrollable change aspect word aspect label unexpectedly . paper , formulate data augmentation conditional generation task : generate new sentence preserve original opinion target label . propose mask sequence - - sequence method conditional augmentation aspect term extraction . unlike exist augmentation approach , controllable allow generate diversified sentence . experimental result confirm method alleviate datum scarcity problem significantly . effectively boost performance current model aspect term extraction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 15, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Towards Better Non-Tree Argument Mining: Proposition-Level Biaffine Parsing with Task-Specific Parameterization,"State-of-the-art argument mining studies have advanced the techniques for predicting argument structures. However, the technology for capturing non-tree-structured arguments is still in its infancy. In this paper, we focus on non-tree argument mining with a neural model. We jointly predict proposition types and edges between propositions. Our proposed model incorporates (i) task-specific parameterization (TSP) that effectively encodes a sequence of propositions and (ii) a proposition-level biaffine attention (PLBA) that can predict a non-tree argument consisting of edges. Experimental results show that both TSP and PLBA boost edge prediction performance compared to baselines.","Towards Better Non-Tree Argument Mining: Proposition-Level Biaffine Parsing with Task-Specific Parameterization State-of-the-art argument mining studies have advanced the techniques for predicting argument structures. However, the technology for capturing non-tree-structured arguments is still in its infancy. In this paper, we focus on non-tree argument mining with a neural model. We jointly predict proposition types and edges between propositions. Our proposed model incorporates (i) task-specific parameterization (TSP) that effectively encodes a sequence of propositions and (ii) a proposition-level biaffine attention (PLBA) that can predict a non-tree argument consisting of edges. Experimental results show that both TSP and PLBA boost edge prediction performance compared to baselines.","well non - tree argument mining : proposition - level biaffine parsing task - specific parameterization state - - - art argument mining study advance technique predict argument structure . , technology capture non - tree - structured argument infancy . paper , focus non - tree argument mining neural model . jointly predict proposition type edge proposition . propose model incorporate ( ) task - specific parameterization ( tsp ) effectively encode sequence proposition ( ii ) proposition - level biaffine attention ( plba ) predict non - tree argument consist edge . experimental result tsp plba boost edge prediction performance compare baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Enhancing Cross-target Stance Detection with Transferable Semantic-Emotion Knowledge,"Stance detection is an important task, which aims to classify the attitude of an opinionated text towards a given target. Remarkable success has been achieved when sufficient labeled training data is available. However, annotating sufficient data is labor-intensive, which establishes significant barriers for generalizing the stance classifier to the data with new targets. In this paper, we proposed a Semantic-Emotion Knowledge Transferring (SEKT) model for cross-target stance detection, which uses the external knowledge (semantic and emotion lexicons) as a bridge to enable knowledge transfer across different targets. Specifically, a semantic-emotion heterogeneous graph is constructed from external semantic and emotion lexicons, which is then fed into a graph convolutional network to learn multi-hop semantic connections between words and emotion tags. Then, the learned semantic-emotion graph representation, which serves as prior knowledge bridging the gap between the source and target domains, is fully integrated into the bidirectional long short-term memory (BiLSTM) stance classifier by adding a novel knowledgeaware memory unit to the BiLSTM cell. Extensive experiments on a large real-world dataset demonstrate the superiority of SEKT against the state-of-the-art baseline methods.","Enhancing Cross-target Stance Detection with Transferable Semantic-Emotion Knowledge Stance detection is an important task, which aims to classify the attitude of an opinionated text towards a given target. Remarkable success has been achieved when sufficient labeled training data is available. However, annotating sufficient data is labor-intensive, which establishes significant barriers for generalizing the stance classifier to the data with new targets. In this paper, we proposed a Semantic-Emotion Knowledge Transferring (SEKT) model for cross-target stance detection, which uses the external knowledge (semantic and emotion lexicons) as a bridge to enable knowledge transfer across different targets. Specifically, a semantic-emotion heterogeneous graph is constructed from external semantic and emotion lexicons, which is then fed into a graph convolutional network to learn multi-hop semantic connections between words and emotion tags. Then, the learned semantic-emotion graph representation, which serves as prior knowledge bridging the gap between the source and target domains, is fully integrated into the bidirectional long short-term memory (BiLSTM) stance classifier by adding a novel knowledgeaware memory unit to the BiLSTM cell. Extensive experiments on a large real-world dataset demonstrate the superiority of SEKT against the state-of-the-art baseline methods.","enhance cross - target stance detection transferable semantic - emotion knowledge stance detection important task , aim classify attitude opinionated text give target . remarkable success achieve sufficient label training data available . , annotate sufficient datum labor - intensive , establish significant barrier generalize stance classifier datum new target . paper , propose semantic - emotion knowledge transferring ( sekt ) model cross - target stance detection , use external knowledge ( semantic emotion lexicon ) bridge enable knowledge transfer different target . specifically , semantic - emotion heterogeneous graph construct external semantic emotion lexicon , feed graph convolutional network learn multi - hop semantic connection word emotion tag . , learn semantic - emotion graph representation , serve prior knowledge bridge gap source target domain , fully integrate bidirectional long short - term memory ( bilstm ) stance classifier add novel knowledgeaware memory unit bilstm cell . extensive experiment large real - world dataset demonstrate superiority sekt state - - - art baseline method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 10, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 13, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Modeling Label Semantics for Predicting Emotional Reactions,"Predicting how events induce emotions in the characters of a story is typically seen as a standard multi-label classification task, which usually treats labels as anonymous classes to predict. They ignore information that may be conveyed by the emotion labels themselves. We propose that the semantics of emotion labels can guide a model's attention when representing the input story. Further, we observe that the emotions evoked by an event are often related: an event that evokes joy is unlikely to also evoke sadness. In this work, we explicitly model label classes via label embeddings, and add mechanisms that track label-label correlations both during training and inference. We also introduce a new semi-supervision strategy that regularizes for the correlations on unlabeled data. Our empirical evaluations show that modeling label semantics yields consistent benefits, and we advance the state-of-theart on an emotion inference task.","Modeling Label Semantics for Predicting Emotional Reactions Predicting how events induce emotions in the characters of a story is typically seen as a standard multi-label classification task, which usually treats labels as anonymous classes to predict. They ignore information that may be conveyed by the emotion labels themselves. We propose that the semantics of emotion labels can guide a model's attention when representing the input story. Further, we observe that the emotions evoked by an event are often related: an event that evokes joy is unlikely to also evoke sadness. In this work, we explicitly model label classes via label embeddings, and add mechanisms that track label-label correlations both during training and inference. We also introduce a new semi-supervision strategy that regularizes for the correlations on unlabeled data. Our empirical evaluations show that modeling label semantics yields consistent benefits, and we advance the state-of-theart on an emotion inference task.","model label semantic predict emotional reaction predict event induce emotion character story typically see standard multi - label classification task , usually treat label anonymous class predict . ignore information convey emotion label . propose semantic emotion label guide model attention represent input story . , observe emotion evoke event related : event evoke joy unlikely evoke sadness . work , explicitly model label class label embedding , add mechanism track label - label correlation training inference . introduce new semi - supervision strategy regularize correlation unlabeled datum . empirical evaluation model label semantic yield consistent benefit , advance state - - theart emotion inference task .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
"Sentiment Analysis, Stylistic Analysis, and Argument Mining",Exploiting Personal Characteristics of Debaters for Predicting Persuasiveness,"Predicting the persuasiveness of arguments has applications as diverse as writing assistance, essay scoring, and advertising. While clearly relevant to the task, the personal characteristics of an argument's source and audience have not yet been fully exploited toward automated persuasiveness prediction. In this paper, we model debaters' prior beliefs, interests, and personality traits based on their previous activity, without dependence on explicit user profiles or questionnaires. Using a dataset of over 60,000 argumentative discussions, comprising more than three million individual posts collected from the subreddit r/ChangeMyView, we demonstrate that our modeling of debater's characteristics enhances the prediction of argument persuasiveness as well as of debaters' resistance to persuasion.","Exploiting Personal Characteristics of Debaters for Predicting Persuasiveness Predicting the persuasiveness of arguments has applications as diverse as writing assistance, essay scoring, and advertising. While clearly relevant to the task, the personal characteristics of an argument's source and audience have not yet been fully exploited toward automated persuasiveness prediction. In this paper, we model debaters' prior beliefs, interests, and personality traits based on their previous activity, without dependence on explicit user profiles or questionnaires. Using a dataset of over 60,000 argumentative discussions, comprising more than three million individual posts collected from the subreddit r/ChangeMyView, we demonstrate that our modeling of debater's characteristics enhances the prediction of argument persuasiveness as well as of debaters' resistance to persuasion.","exploit personal characteristic debater predict persuasiveness predict persuasiveness argument application diverse writing assistance , essay scoring , advertising . clearly relevant task , personal characteristic argument source audience fully exploit automate persuasiveness prediction . paper , model debater ' prior belief , interest , personality trait base previous activity , dependence explicit user profile questionnaire . dataset 60,000 argumentative discussion , comprise million individual post collect subreddit r / changemyview , demonstrate modeling debater characteristic enhance prediction argument persuasiveness debater ' resistance persuasion .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Sentiment Analysis, Stylistic Analysis, and Argument Mining",True
Speech and Multimodality,Curriculum Pre-training for End-to-End Speech Translation,"End-to-end speech translation poses a heavy burden on the encoder because it has to transcribe, understand, and learn cross-lingual semantics simultaneously. To obtain a powerful encoder, traditional methods pre-train it on ASR data to capture speech features. However, we argue that pre-training the encoder only through simple speech recognition is not enough, and high-level linguistic knowledge should be considered. Inspired by this, we propose a curriculum pre-training method that includes an elementary course for transcription learning and two advanced courses for understanding the utterance and mapping words in two languages. The difficulty of these courses is gradually increasing. Experiments show that our curriculum pre-training method leads to significant improvements on En-De and En-Fr speech translation benchmarks. * Works are done during internship at Microsoft (a) previous encoder pre-training (b) curriculum encoder pre-training","Curriculum Pre-training for End-to-End Speech Translation End-to-end speech translation poses a heavy burden on the encoder because it has to transcribe, understand, and learn cross-lingual semantics simultaneously. To obtain a powerful encoder, traditional methods pre-train it on ASR data to capture speech features. However, we argue that pre-training the encoder only through simple speech recognition is not enough, and high-level linguistic knowledge should be considered. Inspired by this, we propose a curriculum pre-training method that includes an elementary course for transcription learning and two advanced courses for understanding the utterance and mapping words in two languages. The difficulty of these courses is gradually increasing. Experiments show that our curriculum pre-training method leads to significant improvements on En-De and En-Fr speech translation benchmarks. * Works are done during internship at Microsoft (a) previous encoder pre-training (b) curriculum encoder pre-training","curriculum pre - training end - - end speech translation end - - end speech translation pose heavy burden encoder transcribe , understand , learn cross - lingual semantic simultaneously . obtain powerful encoder , traditional method pre - train asr datum capture speech feature . , argue pre - train encoder simple speech recognition , high - level linguistic knowledge consider . inspire , propose curriculum pre - training method include elementary course transcription learning advanced course understand utterance map word language . difficulty course gradually increase . experiment curriculum pre - training method lead significant improvement en - de en - fr speech translation benchmark . * work internship microsoft ( ) previous encoder pre - training ( b ) curriculum encoder pre - train","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 12, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,"Sentiment and Emotion help Sarcasm? A Multi-task Learning Framework for Multi-Modal Sarcasm, Sentiment and Emotion Analysis","In this paper, we hypothesize that sarcasm is closely related to sentiment and emotion, and thereby propose a multi-task deep learning framework to solve all these three problems simultaneously in a multi-modal conversational scenario. We, at first, manually annotate the recently released multi-modal MUStARD sarcasm dataset with sentiment and emotion classes, both implicit and explicit. For multitasking, we propose two attention mechanisms, viz. Inter-segment Inter-modal Attention (I e -Attention) and Intra-segment Inter-modal Attention (I a -Attention). The main motivation of I e -Attention is to learn the relationship between the different segments of the sentence across the modalities. In contrast, I a -Attention focuses within the same segment of the sentence across the modalities. Finally, representations from both the attentions are concatenated and shared across the five classes (i.e., sarcasm, implicit sentiment, explicit sentiment, implicit emotion, explicit emotion) for multi-tasking. Experimental results on the extended version of the MUStARD dataset show the efficacy of our proposed approach for sarcasm detection over the existing state-of-theart systems. The evaluation also shows that the proposed multi-task framework yields better performance for the primary task, i.e., sarcasm detection, with the help of two secondary tasks, emotion and sentiment analysis.","Sentiment and Emotion help Sarcasm? A Multi-task Learning Framework for Multi-Modal Sarcasm, Sentiment and Emotion Analysis In this paper, we hypothesize that sarcasm is closely related to sentiment and emotion, and thereby propose a multi-task deep learning framework to solve all these three problems simultaneously in a multi-modal conversational scenario. We, at first, manually annotate the recently released multi-modal MUStARD sarcasm dataset with sentiment and emotion classes, both implicit and explicit. For multitasking, we propose two attention mechanisms, viz. Inter-segment Inter-modal Attention (I e -Attention) and Intra-segment Inter-modal Attention (I a -Attention). The main motivation of I e -Attention is to learn the relationship between the different segments of the sentence across the modalities. In contrast, I a -Attention focuses within the same segment of the sentence across the modalities. Finally, representations from both the attentions are concatenated and shared across the five classes (i.e., sarcasm, implicit sentiment, explicit sentiment, implicit emotion, explicit emotion) for multi-tasking. Experimental results on the extended version of the MUStARD dataset show the efficacy of our proposed approach for sarcasm detection over the existing state-of-theart systems. The evaluation also shows that the proposed multi-task framework yields better performance for the primary task, i.e., sarcasm detection, with the help of two secondary tasks, emotion and sentiment analysis.","sentiment emotion help sarcasm ? multi - task learning framework multi - modal sarcasm , sentiment emotion analysis paper , hypothesize sarcasm closely relate sentiment emotion , propose multi - task deep learning framework solve problem simultaneously multi - modal conversational scenario . , , manually annotate recently release multi - modal mustard sarcasm dataset sentiment emotion class , implicit explicit . multitasking , propose attention mechanism , viz . inter - segment inter - modal attention ( e -attention ) intra - segment inter - modal attention ( -attention ) . main motivation e -attention learn relationship different segment sentence modality . contrast , -attention focus segment sentence modality . finally , representation attention concatenate share class ( i.e. , sarcasm , implicit sentiment , explicit sentiment , implicit emotion , explicit emotion ) multi - tasking . experimental result extended version mustard dataset efficacy propose approach sarcasm detection exist state - - theart system . evaluation show propose multi - task framework yield well performance primary task , i.e. , sarcasm detection , help secondary task , emotion sentiment analysis .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 8, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 15, 'Speech and Multimodality': 17, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Meta-Transfer Learning for Code-Switched Speech Recognition,"An increasing number of people in the world today speak a mixed-language as a result of being multilingual. However, building a speech recognition system for code-switching remains difficult due to the availability of limited resources and the expense and significant effort required to collect mixed-language data. We therefore propose a new learning method, meta-transfer learning, to transfer learn on a code-switched speech recognition system in a low-resource setting by judiciously extracting information from high-resource monolingual datasets. Our model learns to recognize individual languages, and transfer them so as to better recognize mixed-language speech by conditioning the optimization on the codeswitching data. Based on experimental results, our model outperforms existing baselines on speech recognition and language modeling tasks, and is faster to converge.","Meta-Transfer Learning for Code-Switched Speech Recognition An increasing number of people in the world today speak a mixed-language as a result of being multilingual. However, building a speech recognition system for code-switching remains difficult due to the availability of limited resources and the expense and significant effort required to collect mixed-language data. We therefore propose a new learning method, meta-transfer learning, to transfer learn on a code-switched speech recognition system in a low-resource setting by judiciously extracting information from high-resource monolingual datasets. Our model learns to recognize individual languages, and transfer them so as to better recognize mixed-language speech by conditioning the optimization on the codeswitching data. Based on experimental results, our model outperforms existing baselines on speech recognition and language modeling tasks, and is faster to converge.","meta - transfer learning code - switch speech recognition increase number people world today speak mixed - language result multilingual . , build speech recognition system code - switching remain difficult availability limited resource expense significant effort require collect mixed - language datum . propose new learning method , meta - transfer learning , transfer learn code - switch speech recognition system low - resource setting judiciously extract information high - resource monolingual dataset . model learn recognize individual language , transfer well recognize mixed - language speech condition optimization codeswitching datum . base experimental result , model outperform exist baseline speech recognition language modeling task , fast converge .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 13, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,How Accents Confound: Probing for Accent Information in End-to-End Speech Recognition Systems,"In this work, we present a detailed analysis of how accent information is reflected in the internal representation of speech in an end-toend automatic speech recognition (ASR) system. We use a state-of-the-art end-to-end ASR system, comprising convolutional and recurrent layers, that is trained on a large amount of US-accented English speech and evaluate the model on speech samples from seven different English accents. We examine the effects of accent on the internal representation using three main probing techniques: a) Gradient-based explanation methods, b) Information-theoretic measures, and c) Outputs of accent and phone classifiers. We find different accents exhibiting similar trends irrespective of the probing technique used. We also find that most accent information is encoded within the first recurrent layer, which is suggestive of how one could adapt such an end-to-end model to learn representations that are invariant to accents.","How Accents Confound: Probing for Accent Information in End-to-End Speech Recognition Systems In this work, we present a detailed analysis of how accent information is reflected in the internal representation of speech in an end-toend automatic speech recognition (ASR) system. We use a state-of-the-art end-to-end ASR system, comprising convolutional and recurrent layers, that is trained on a large amount of US-accented English speech and evaluate the model on speech samples from seven different English accents. We examine the effects of accent on the internal representation using three main probing techniques: a) Gradient-based explanation methods, b) Information-theoretic measures, and c) Outputs of accent and phone classifiers. We find different accents exhibiting similar trends irrespective of the probing technique used. We also find that most accent information is encoded within the first recurrent layer, which is suggestive of how one could adapt such an end-to-end model to learn representations that are invariant to accents.","accent confound : probe accent information end - - end speech recognition system work , present detailed analysis accent information reflect internal representation speech end - toend automatic speech recognition ( asr ) system . use state - - - art end - - end asr system , comprise convolutional recurrent layer , train large - accent english speech evaluate model speech sample seven different english accent . examine effect accent internal representation main probe technique : ) gradient - base explanation method , b ) information - theoretic measure , c ) output accent phone classifier . find different accent exhibit similar trend irrespective probe technique . find accent information encode recurrent layer , suggestive adapt end - - end model learn representation invariant accent .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 30, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Integrating Multimodal Information in Large Pretrained Transformers,"Recent Transformer-based contextual word representations, including BERT and XLNet, have shown state-of-the-art performance in multiple disciplines within NLP. Fine-tuning the trained contextual models on task-specific datasets has been the key to achieving superior performance downstream. While finetuning these pre-trained models is straightforward for lexical applications (applications with only language modality), it is not trivial for multimodal language (a growing area in NLP focused on modeling face-to-face communication). Pre-trained models don't have the necessary components to accept two extra modalities of vision and acoustic. In this paper, we proposed an attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG allows BERT and XL-Net to accept multimodal nonverbal data during fine-tuning. It does so by generating a shift to internal representation of BERT and XLNet; a shift that is conditioned on the visual and acoustic modalities. In our experiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for multimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly boosts the sentiment analysis performance over previous baselines as well as language-only finetuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet achieves humanlevel multimodal sentiment analysis performance for the first time in the NLP community.","Integrating Multimodal Information in Large Pretrained Transformers Recent Transformer-based contextual word representations, including BERT and XLNet, have shown state-of-the-art performance in multiple disciplines within NLP. Fine-tuning the trained contextual models on task-specific datasets has been the key to achieving superior performance downstream. While finetuning these pre-trained models is straightforward for lexical applications (applications with only language modality), it is not trivial for multimodal language (a growing area in NLP focused on modeling face-to-face communication). Pre-trained models don't have the necessary components to accept two extra modalities of vision and acoustic. In this paper, we proposed an attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG allows BERT and XL-Net to accept multimodal nonverbal data during fine-tuning. It does so by generating a shift to internal representation of BERT and XLNet; a shift that is conditioned on the visual and acoustic modalities. In our experiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for multimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly boosts the sentiment analysis performance over previous baselines as well as language-only finetuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet achieves humanlevel multimodal sentiment analysis performance for the first time in the NLP community.","integrate multimodal information large pretrained transformer recent transformer - base contextual word representation , include bert xlnet , show state - - - art performance multiple discipline nlp . fine - tune train contextual model task - specific dataset key achieve superior performance downstream . finetune pre - train model straightforward lexical application ( application language modality ) , trivial multimodal language ( grow area nlp focus model face - - face communication ) . pre - trained model necessary component accept extra modality vision acoustic . paper , propose attachment bert xlnet call multimodal adaptation gate ( mag ) . mag allow bert xl - net accept multimodal nonverbal datum fine - tuning . generate shift internal representation bert xlnet ; shift condition visual acoustic modality . experiment , study commonly cmu - mosi cmu - mosei dataset multimodal sentiment analysis . fine - tune mag - bert mag - xlnet significantly boost sentiment analysis performance previous baseline language - finetuning bert xlnet . cmu - mosi dataset , mag - xlnet achieve humanlevel multimodal sentiment analysis performance time nlp community .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 12, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 6, 'Speech and Multimodality': 9, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Speech and Multimodality,Towards end-2-end learning for predicting behavior codes from spoken utterances in psychotherapy conversations,"Spoken language understanding tasks usually rely on pipelines involving complex processing blocks such as voice activity detection, speaker diarization and Automatic speech recognition (ASR). We propose a novel framework for predicting utterance level labels directly from speech features, thus removing the dependency on first generating transcripts, and transcription free behavioral coding. Our classifier uses a pretrained Speech-2-Vector encoder as bottleneck to generate word-level representations from speech features. This pretrained encoder learns to encode speech features for a word using an objective similar to Word2Vec. Our proposed approach just uses speech features and word segmentation information for predicting spoken utterance-level target labels. We show that our model achieves competitive results to other state-of-the-art approaches which use transcribed text for the task of predicting psychotherapy-relevant behavior codes.","Towards end-2-end learning for predicting behavior codes from spoken utterances in psychotherapy conversations Spoken language understanding tasks usually rely on pipelines involving complex processing blocks such as voice activity detection, speaker diarization and Automatic speech recognition (ASR). We propose a novel framework for predicting utterance level labels directly from speech features, thus removing the dependency on first generating transcripts, and transcription free behavioral coding. Our classifier uses a pretrained Speech-2-Vector encoder as bottleneck to generate word-level representations from speech features. This pretrained encoder learns to encode speech features for a word using an objective similar to Word2Vec. Our proposed approach just uses speech features and word segmentation information for predicting spoken utterance-level target labels. We show that our model achieves competitive results to other state-of-the-art approaches which use transcribed text for the task of predicting psychotherapy-relevant behavior codes.","end-2 - end learning predict behavior code speak utterance psychotherapy conversation spoken language understanding task usually rely pipeline involve complex processing block voice activity detection , speaker diarization automatic speech recognition ( asr ) . propose novel framework predict utterance level label directly speech feature , remove dependency generate transcript , transcription free behavioral coding . classifier use pretrained speech-2 - vector encoder bottleneck generate word - level representation speech feature . pretrained encoder learn encode speech feature word objective similar word2vec . propose approach use speech feature word segmentation information predict speak utterance - level target label . model achieve competitive result state - - - art approach use transcribe text task predict psychotherapy - relevant behavior code .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 6, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 12, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Reasoning with Multimodal Sarcastic Tweets via Modeling Cross-Modality Contrast and Semantic Association,"Sarcasm is a sophisticated linguistic phenomenon to express the opposite of what one really means. With the rapid growth of social media, multimodal sarcastic tweets are widely posted on various social platforms. In multimodal context, sarcasm is no longer a pure linguistic phenomenon, and due to the nature of social media short text, the opposite is more often manifested via cross-modality expressions. Thus traditional text-based methods are insufficient to detect multimodal sarcasm. To reason with multimodal sarcastic tweets, in this paper, we propose a novel method for modeling cross-modality contrast in the associated context. Our method models both cross-modality contrast and semantic association by constructing the Decomposition and Relation Network (namely D&R Net). The decomposition network represents the commonality and discrepancy between image and text, and the relation network models the semantic association in cross-modality context. Experimental results on a public dataset demonstrate the effectiveness of our model in multimodal sarcasm detection.","Reasoning with Multimodal Sarcastic Tweets via Modeling Cross-Modality Contrast and Semantic Association Sarcasm is a sophisticated linguistic phenomenon to express the opposite of what one really means. With the rapid growth of social media, multimodal sarcastic tweets are widely posted on various social platforms. In multimodal context, sarcasm is no longer a pure linguistic phenomenon, and due to the nature of social media short text, the opposite is more often manifested via cross-modality expressions. Thus traditional text-based methods are insufficient to detect multimodal sarcasm. To reason with multimodal sarcastic tweets, in this paper, we propose a novel method for modeling cross-modality contrast in the associated context. Our method models both cross-modality contrast and semantic association by constructing the Decomposition and Relation Network (namely D&R Net). The decomposition network represents the commonality and discrepancy between image and text, and the relation network models the semantic association in cross-modality context. Experimental results on a public dataset demonstrate the effectiveness of our model in multimodal sarcasm detection.","reason multimodal sarcastic tweet model cross - modality contrast semantic association sarcasm sophisticated linguistic phenomenon express opposite mean . rapid growth social medium , multimodal sarcastic tweet widely post social platform . multimodal context , sarcasm long pure linguistic phenomenon , nature social medium short text , opposite manifest cross - modality expression . traditional text - base method insufficient detect multimodal sarcasm . reason multimodal sarcastic tweet , paper , propose novel method model cross - modality contrast associate context . method model cross - modality contrast semantic association construct decomposition relation network ( d&r net ) . decomposition network represent commonality discrepancy image text , relation network model semantic association cross - modality context . experimental result public dataset demonstrate effectiveness model multimodal sarcasm detection .","{'Computational Social Science and Social Media': 11, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 3, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 15, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Towards Emotion-aided Multi-modal Dialogue Act Classification,"The task of Dialogue Act Classification (DAC) that purports to capture communicative intent has been studied extensively. But these studies limit themselves to text. Non-verbal features (change of tone, facial expressions etc.) can provide cues to identify DAs, thus stressing the benefit of incorporating multi-modal inputs in the task. Also, the emotional state of the speaker has a substantial effect on the choice of the dialogue act, since conversations are often influenced by emotions. Hence, the effect of emotion too on automatic identification of DAs needs to be studied. In this work, we address the role of both multi-modality and emotion recognition (ER) in DAC. DAC and ER help each other by way of multi-task learning. One of the major contributions of this work is a new dataset-multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multimodality and multi-tasking achieve better performance of DAC compared to uni-modal and single task DAC variants. amounting to a total of 13708 utterances across the dataset. Each utterance is annotated for the presence of 7 emotions namely sadness, anger, fear, joy, surprise, disgust, and neutral.","Towards Emotion-aided Multi-modal Dialogue Act Classification The task of Dialogue Act Classification (DAC) that purports to capture communicative intent has been studied extensively. But these studies limit themselves to text. Non-verbal features (change of tone, facial expressions etc.) can provide cues to identify DAs, thus stressing the benefit of incorporating multi-modal inputs in the task. Also, the emotional state of the speaker has a substantial effect on the choice of the dialogue act, since conversations are often influenced by emotions. Hence, the effect of emotion too on automatic identification of DAs needs to be studied. In this work, we address the role of both multi-modality and emotion recognition (ER) in DAC. DAC and ER help each other by way of multi-task learning. One of the major contributions of this work is a new dataset-multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multimodality and multi-tasking achieve better performance of DAC compared to uni-modal and single task DAC variants. amounting to a total of 13708 utterances across the dataset. Each utterance is annotated for the presence of 7 emotions namely sadness, anger, fear, joy, surprise, disgust, and neutral.","emotion - aid multi - modal dialogue act classification task dialogue act classification ( dac ) purport capture communicative intent study extensively . study limit text . non - verbal feature ( change tone , facial expression etc . ) provide cue identify da , stress benefit incorporate multi - modal input task . , emotional state speaker substantial effect choice dialogue act , conversation influence emotion . , effect emotion automatic identification da need study . work , address role multi - modality emotion recognition ( er ) dac . dac er help way multi - task learning . major contribution work new dataset - multimodal emotion aware dialogue act dataset call emotyda , collect open - source dialogue dataset . demonstrate utility emotyda , build attention base ( self , inter - modal , inter - task ) multi - modal , multi - task deep neural network ( dnn ) joint learning da emotion . empirically multimodality multi - tasking achieve well performance dac compare uni - modal single task dac variant . amount total 13708 utterance dataset . utterance annotate presence 7 emotion sadness , anger , fear , joy , surprise , disgust , neutral .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 11, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 8, 'Speech and Multimodality': 13, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,SimulSpeech: End-to-End Simultaneous Speech to Text Translation,"In this work, we develop SimulSpeech, an endto-end simultaneous speech to text translation system which translates speech in source language to text in target language concurrently.","SimulSpeech: End-to-End Simultaneous Speech to Text Translation In this work, we develop SimulSpeech, an endto-end simultaneous speech to text translation system which translates speech in source language to text in target language concurrently.","simulspeech : end - - end simultaneous speech text translation work , develop simulspeech , endto - end simultaneous speech text translation system translate speech source language text target language concurrently .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 9, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Multimodal and Multiresolution Speech Recognition with Transformers,"This paper presents an audio visual automatic speech recognition (AV-ASR) system using a Transformer-based architecture. We particularly focus on the scene context provided by the visual information, to ground the ASR. We extract representations for audio features in the encoder layers of the transformer and fuse video features using an additional crossmodal multihead attention layer. Additionally, we incorporate a multitask training criterion for multiresolution ASR, where we train the model to generate both character and subword level transcriptions. Experimental results on the How2 dataset, indicate that multiresolution training can speed up convergence by around 50% and relatively improves word error rate (WER) performance by upto 18% over subword prediction models. Further, incorporating visual information improves performance with relative gains upto 3.76% over audio only models. Our results are comparable to state-of-the-art Listen, Attend and Spell-based architectures.","Multimodal and Multiresolution Speech Recognition with Transformers This paper presents an audio visual automatic speech recognition (AV-ASR) system using a Transformer-based architecture. We particularly focus on the scene context provided by the visual information, to ground the ASR. We extract representations for audio features in the encoder layers of the transformer and fuse video features using an additional crossmodal multihead attention layer. Additionally, we incorporate a multitask training criterion for multiresolution ASR, where we train the model to generate both character and subword level transcriptions. Experimental results on the How2 dataset, indicate that multiresolution training can speed up convergence by around 50% and relatively improves word error rate (WER) performance by upto 18% over subword prediction models. Further, incorporating visual information improves performance with relative gains upto 3.76% over audio only models. Our results are comparable to state-of-the-art Listen, Attend and Spell-based architectures.","multimodal multiresolution speech recognition transformers paper present audio visual automatic speech recognition ( av - asr ) system transformer - base architecture . particularly focus scene context provide visual information , ground asr . extract representation audio feature encoder layer transformer fuse video feature additional crossmodal multihead attention layer . additionally , incorporate multitask training criterion multiresolution asr , train model generate character subword level transcription . experimental result how2 dataset , indicate multiresolution training speed convergence 50 % relatively improve word error rate ( wer ) performance upto 18 % subword prediction model . , incorporate visual information improve performance relative gain upto 3.76 % audio model . result comparable state - - - art listen , attend spell - base architecture .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 8, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 11, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Acoustic-Prosodic and Lexical Cues to Deception and Trust: Deciphering How People Detect Lies,"Humans rarely perform better than chance at lie detection. To better understand human perception of deception, we created a game framework, LieCatcher, to collect ratings of perceived deception using a large corpus of deceptive and truthful interviews. We analyzed the acoustic-prosodic and linguistic characteristics of language trusted and mistrusted by raters and compared these to characteristics of actual truthful and deceptive language to understand how perception aligns with reality. With this data we built classifiers to automatically distinguish trusted from mistrusted speech, achieving an F1 of 66.1%. We next evaluated whether the strategies raters said they used to discriminate between truthful and deceptive responses were in fact useful. Our results show that, although several prosodic and lexical features were consistently perceived as trustworthy, they were not reliable cues. Also, the strategies that judges reported using in deception detection were not helpful for the task. Our work sheds light on the nature of trusted language and provides insight into the challenging problem of human deception detection.","Acoustic-Prosodic and Lexical Cues to Deception and Trust: Deciphering How People Detect Lies Humans rarely perform better than chance at lie detection. To better understand human perception of deception, we created a game framework, LieCatcher, to collect ratings of perceived deception using a large corpus of deceptive and truthful interviews. We analyzed the acoustic-prosodic and linguistic characteristics of language trusted and mistrusted by raters and compared these to characteristics of actual truthful and deceptive language to understand how perception aligns with reality. With this data we built classifiers to automatically distinguish trusted from mistrusted speech, achieving an F1 of 66.1%. We next evaluated whether the strategies raters said they used to discriminate between truthful and deceptive responses were in fact useful. Our results show that, although several prosodic and lexical features were consistently perceived as trustworthy, they were not reliable cues. Also, the strategies that judges reported using in deception detection were not helpful for the task. Our work sheds light on the nature of trusted language and provides insight into the challenging problem of human deception detection.","acoustic - prosodic lexical cue deception trust : decipher people detect lie human rarely perform well chance lie detection . well understand human perception deception , create game framework , liecatcher , collect rating perceive deception large corpus deceptive truthful interview . analyze acoustic - prosodic linguistic characteristic language trust mistrust rater compare characteristic actual truthful deceptive language understand perception align reality . datum build classifier automatically distinguish trust mistrust speech , achieve f1 66.1 % . evaluate strategy rater say discriminate truthful deceptive response fact useful . result , prosodic lexical feature consistently perceive trustworthy , reliable cue . , strategy judge report deception detection helpful task . work shed light nature trust language provide insight challenging problem human deception detection .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Speech and Multimodality,MultiQT: Multimodal learning for real-time question tracking in speech,"We address a challenging and practical task of labeling questions in speech in real time during telephone calls to emergency medical services in English, which embeds within a broader decision support system for emergency call-takers. We propose a novel multimodal approach to real-time sequence labeling in speech. Our model treats speech and its own textual representation as two separate modalities or views, as it jointly learns from streamed audio and its noisy transcription into text via automatic speech recognition. Our results show significant gains of jointly learning from the two modalities when compared to text or audio only, under adverse noise and limited volume of training data. The results generalize to medical symptoms detection where we observe a similar pattern of improvements with multimodal learning.","MultiQT: Multimodal learning for real-time question tracking in speech We address a challenging and practical task of labeling questions in speech in real time during telephone calls to emergency medical services in English, which embeds within a broader decision support system for emergency call-takers. We propose a novel multimodal approach to real-time sequence labeling in speech. Our model treats speech and its own textual representation as two separate modalities or views, as it jointly learns from streamed audio and its noisy transcription into text via automatic speech recognition. Our results show significant gains of jointly learning from the two modalities when compared to text or audio only, under adverse noise and limited volume of training data. The results generalize to medical symptoms detection where we observe a similar pattern of improvements with multimodal learning.","multiqt : multimodal learning real - time question tracking speech address challenging practical task label question speech real time telephone call emergency medical service english , embed broad decision support system emergency - taker . propose novel multimodal approach real - time sequence labeling speech . model treat speech textual representation separate modality view , jointly learn stream audio noisy transcription text automatic speech recognition . result significant gain jointly learn modality compare text audio , adverse noise limited volume training datum . result generalize medical symptom detection observe similar pattern improvement multimodal learning .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 2, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 12, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Multimodal Transformer for Multimodal Machine Translation,"Multimodal Machine Translation (MMT) aims to introduce information from other modality, generally static images, to improve the translation quality. Previous works propose various incorporation methods, but most of them do not consider the relative importance of multiple modalities. In MMT, equally treating text and images may encode too much irrelevant information from images which may introduce noise. In this paper, we propose the multimodal self-attention in Transformer to solve the issues above. The proposed method learns the representations of images based on the text, which avoids encoding irrelevant information in images. Experiments and visualization analysis demonstrate that our model benefits from visual information and substantially outperforms previous works and competitive baselines in terms of various metrics.","Multimodal Transformer for Multimodal Machine Translation Multimodal Machine Translation (MMT) aims to introduce information from other modality, generally static images, to improve the translation quality. Previous works propose various incorporation methods, but most of them do not consider the relative importance of multiple modalities. In MMT, equally treating text and images may encode too much irrelevant information from images which may introduce noise. In this paper, we propose the multimodal self-attention in Transformer to solve the issues above. The proposed method learns the representations of images based on the text, which avoids encoding irrelevant information in images. Experiments and visualization analysis demonstrate that our model benefits from visual information and substantially outperforms previous works and competitive baselines in terms of various metrics.","multimodal transformer multimodal machine translation multimodal machine translation ( mmt ) aim introduce information modality , generally static image , improve translation quality . previous work propose incorporation method , consider relative importance multiple modality . mmt , equally treat text image encode irrelevant information image introduce noise . paper , propose multimodal self - attention transformer solve issue . propose method learn representation image base text , avoid encode irrelevant information image . experiment visualization analysis demonstrate model benefit visual information substantially outperform previous work competitive baseline term metric .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Speech and Multimodality,CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality,"Previous studies in multimodal sentiment analysis have used limited datasets, which only contain unified multimodal annotations. However, the unified annotations do not always reflect the independent sentiment of single modalities and limit the model to capture the difference between modalities. In this paper, we introduce a Chinese single-and multimodal sentiment analysis dataset, CH-SIMS, which contains 2,281 refined video segments in the wild with both multimodal and independent unimodal annotations. It allows researchers to study the interaction between modalities or use independent unimodal annotations for unimodal sentiment analysis. Furthermore, we propose a multi-task learning framework based on late fusion as the baseline. Extensive experiments on the CH-SIMS show that our methods achieve state-of-the-art performance and learn more distinctive unimodal representations. The full dataset and codes are available for use at https://github.com/ thuiar/MMSA.","CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality Previous studies in multimodal sentiment analysis have used limited datasets, which only contain unified multimodal annotations. However, the unified annotations do not always reflect the independent sentiment of single modalities and limit the model to capture the difference between modalities. In this paper, we introduce a Chinese single-and multimodal sentiment analysis dataset, CH-SIMS, which contains 2,281 refined video segments in the wild with both multimodal and independent unimodal annotations. It allows researchers to study the interaction between modalities or use independent unimodal annotations for unimodal sentiment analysis. Furthermore, we propose a multi-task learning framework based on late fusion as the baseline. Extensive experiments on the CH-SIMS show that our methods achieve state-of-the-art performance and learn more distinctive unimodal representations. The full dataset and codes are available for use at https://github.com/ thuiar/MMSA.","ch - sims : chinese multimodal sentiment analysis dataset fine - grained annotation modality previous study multimodal sentiment analysis limited dataset , contain unify multimodal annotation . , unify annotation reflect independent sentiment single modality limit model capture difference modality . paper , introduce chinese single - multimodal sentiment analysis dataset , ch - sims , contain 2,281 refined video segment wild multimodal independent unimodal annotation . allow researcher study interaction modality use independent unimodal annotation unimodal sentiment analysis . furthermore , propose multi - task learning framework base late fusion baseline . extensive experiment ch - sims method achieve state - - - art performance learn distinctive unimodal representation . dataset code available use https://github.com/ thuiar / mmsa .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 9, 'Speech and Multimodality': 12, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Speech and Multimodality,Learning Spoken Language Representations with Neural Lattice Language Modeling,"Pre-trained language models have achieved huge improvement on many NLP tasks. However, these methods are usually designed for written text, so they do not consider the properties of spoken language. Therefore, this paper aims at generalizing the idea of language model pre-training to lattices generated by recognition systems. We propose a framework that trains neural lattice language models to provide contextualized representations for spoken language understanding tasks. The proposed two-stage pre-training approach reduces the demands of speech data and has better efficiency. Experiments on intent detection and dialogue act recognition datasets demonstrate that our proposed method consistently outperforms strong baselines when evaluated on spoken inputs. 1","Learning Spoken Language Representations with Neural Lattice Language Modeling Pre-trained language models have achieved huge improvement on many NLP tasks. However, these methods are usually designed for written text, so they do not consider the properties of spoken language. Therefore, this paper aims at generalizing the idea of language model pre-training to lattices generated by recognition systems. We propose a framework that trains neural lattice language models to provide contextualized representations for spoken language understanding tasks. The proposed two-stage pre-training approach reduces the demands of speech data and has better efficiency. Experiments on intent detection and dialogue act recognition datasets demonstrate that our proposed method consistently outperforms strong baselines when evaluated on spoken inputs. 1","learn spoken language representation neural lattice language modeling pre - trained language model achieve huge improvement nlp task . , method usually design write text , consider property speak language . , paper aim generalize idea language model pre - training lattice generate recognition system . propose framework train neural lattice language model provide contextualize representation speak language understanding task . propose - stage pre - training approach reduce demand speech datum well efficiency . experiment intent detection dialogue act recognition dataset demonstrate propose method consistently outperform strong baseline evaluate speak input . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Speech and Multimodality,Improved Speech Representations with Multi-Target Autoregressive Predictive Coding,"Training objectives based on predictive coding have recently been shown to be very effective at learning meaningful representations from unlabeled speech. One example is Autoregressive Predictive Coding (Chung et al., 2019) , which trains an autoregressive RNN to generate an unseen future frame given a context such as recent past frames. The basic hypothesis of these approaches is that hidden states that can accurately predict future frames are a useful representation for many downstream tasks. In this paper we extend this hypothesis and aim to enrich the information encoded in the hidden states by training the model to make more accurate future predictions. We propose an auxiliary objective that serves as a regularization to improve generalization of the future frame prediction task. Experimental results on phonetic classification, speech recognition, and speech translation not only support the hypothesis, but also demonstrate the effectiveness of our approach in learning representations that contain richer phonetic content.","Improved Speech Representations with Multi-Target Autoregressive Predictive Coding Training objectives based on predictive coding have recently been shown to be very effective at learning meaningful representations from unlabeled speech. One example is Autoregressive Predictive Coding (Chung et al., 2019) , which trains an autoregressive RNN to generate an unseen future frame given a context such as recent past frames. The basic hypothesis of these approaches is that hidden states that can accurately predict future frames are a useful representation for many downstream tasks. In this paper we extend this hypothesis and aim to enrich the information encoded in the hidden states by training the model to make more accurate future predictions. We propose an auxiliary objective that serves as a regularization to improve generalization of the future frame prediction task. Experimental results on phonetic classification, speech recognition, and speech translation not only support the hypothesis, but also demonstrate the effectiveness of our approach in learning representations that contain richer phonetic content.","improved speech representation multi - target autoregressive predictive coding training objective base predictive coding recently show effective learn meaningful representation unlabeled speech . example autoregressive predictive coding ( chung et al . , 2019 ) , train autoregressive rnn generate unseen future frame give context recent past frame . basic hypothesis approach hidden state accurately predict future frame useful representation downstream task . paper extend hypothesis aim enrich information encode hidden state train model accurate future prediction . propose auxiliary objective serve regularization improve generalization future frame prediction task . experimental result phonetic classification , speech recognition , speech translation support hypothesis , demonstrate effectiveness approach learn representation contain rich phonetic content .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 11, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,False
Speech and Multimodality,Improving Disfluency Detection by Self-Training a Self-Attentive Model,"Self-attentive neural syntactic parsers using contextualized word embeddings (e.g. ELMo or BERT) currently produce state-of-the-art results in joint parsing and disfluency detection in speech transcripts. Since the contextualized word embeddings are pre-trained on a large amount of unlabeled data, using additional unlabeled data to train a neural model might seem redundant. However, we show that self-training -a semi-supervised technique for incorporating unlabeled data -sets a new state-of-the-art for the self-attentive parser on disfluency detection, demonstrating that self-training provides benefits orthogonal to the pre-trained contextualized word representations. We also show that ensembling selftrained parsers provides further gains for disfluency detection.","Improving Disfluency Detection by Self-Training a Self-Attentive Model Self-attentive neural syntactic parsers using contextualized word embeddings (e.g. ELMo or BERT) currently produce state-of-the-art results in joint parsing and disfluency detection in speech transcripts. Since the contextualized word embeddings are pre-trained on a large amount of unlabeled data, using additional unlabeled data to train a neural model might seem redundant. However, we show that self-training -a semi-supervised technique for incorporating unlabeled data -sets a new state-of-the-art for the self-attentive parser on disfluency detection, demonstrating that self-training provides benefits orthogonal to the pre-trained contextualized word representations. We also show that ensembling selftrained parsers provides further gains for disfluency detection.","improve disfluency detection self - train self - attentive model self - attentive neural syntactic parser contextualize word embedding ( e.g. elmo bert ) currently produce state - - - art result joint parsing disfluency detection speech transcript . contextualize word embedding pre - train large unlabeled datum , additional unlabeled datum train neural model redundant . , self - training -a semi - supervised technique incorporate unlabeled datum -set new state - - - art self - attentive parser disfluency detection , demonstrate self - training provide benefit orthogonal pre - trained contextualized word representation . ensemble selftraine parser provide gain disfluency detection .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Speech and Multimodality,Phone Features Improve Speech Translation,"End-to-end models for speech translation (ST) more tightly couple speech recognition (ASR) and machine translation (MT) than a traditional cascade of separate ASR and MT models, with simpler model architectures and the potential for reduced error propagation. Their performance is often assumed to be superior, though in many conditions this is not yet the case. We compare cascaded and end-to-end models across high, medium, and low-resource conditions, and show that cascades remain stronger baselines. Further, we introduce two methods to incorporate phone features into ST models. We show that these features improve both architectures, closing the gap between end-to-end models and cascades, and outperforming previous academic work -by up to 9 BLEU on our low-resource setting.","Phone Features Improve Speech Translation End-to-end models for speech translation (ST) more tightly couple speech recognition (ASR) and machine translation (MT) than a traditional cascade of separate ASR and MT models, with simpler model architectures and the potential for reduced error propagation. Their performance is often assumed to be superior, though in many conditions this is not yet the case. We compare cascaded and end-to-end models across high, medium, and low-resource conditions, and show that cascades remain stronger baselines. Further, we introduce two methods to incorporate phone features into ST models. We show that these features improve both architectures, closing the gap between end-to-end models and cascades, and outperforming previous academic work -by up to 9 BLEU on our low-resource setting.","phone feature improve speech translation end - - end model speech translation ( st ) tightly couple speech recognition ( asr ) machine translation ( mt ) traditional cascade separate asr mt model , simple model architecture potential reduce error propagation . performance assume superior , condition case . compare cascade end - - end model high , medium , low - resource condition , cascade remain strong baseline . , introduce method incorporate phone feature st model . feature improve architecture , close gap end - - end model cascade , outperform previous academic work -by 9 bleu low - resource setting .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 13, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,True
Summarization,Multi-Granularity Interaction Network for Extractive and Abstractive Multi-Document Summarization,"In this paper, we propose a multi-granularity interaction network for extractive and abstractive multi-document summarization, which jointly learn semantic representations for words, sentences, and documents. The word representations are used to generate an abstractive summary while the sentence representations are used to produce an extractive summary. We employ attention mechanisms to interact between different granularity of semantic representations, which helps to capture multi-granularity key information and improves the performance of both abstractive and extractive summarization. Experiment results show that our proposed model substantially outperforms all strong baseline methods and achieves the best results on the Multi-News dataset.","Multi-Granularity Interaction Network for Extractive and Abstractive Multi-Document Summarization In this paper, we propose a multi-granularity interaction network for extractive and abstractive multi-document summarization, which jointly learn semantic representations for words, sentences, and documents. The word representations are used to generate an abstractive summary while the sentence representations are used to produce an extractive summary. We employ attention mechanisms to interact between different granularity of semantic representations, which helps to capture multi-granularity key information and improves the performance of both abstractive and extractive summarization. Experiment results show that our proposed model substantially outperforms all strong baseline methods and achieves the best results on the Multi-News dataset.","multi - granularity interaction network extractive abstractive multi - document summarization paper , propose multi - granularity interaction network extractive abstractive multi - document summarization , jointly learn semantic representation word , sentence , document . word representation generate abstractive summary sentence representation produce extractive summary . employ attention mechanism interact different granularity semantic representation , help capture multi - granularity key information improve performance abstractive extractive summarization . experiment result propose model substantially outperform strong baseline method achieve good result multi - news dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 16, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization,"Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA, 1 which leverages recent advances in reading comprehension. Given questionanswer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.","FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA, 1 which leverages recent advances in reading comprehension. Given questionanswer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.","feqa : question answer evaluation framework faithfulness assessment abstractive summarization neural abstractive summarization model prone generate content inconsistent source document , i.e. unfaithful . exist automatic metric capture mistake effectively . tackle problem evaluate faithfulness generate summary give source document . collect human annotation faithfulness output numerous model dataset . find current model exhibit trade - abstractiveness faithfulness : output word overlap source document likely unfaithful . , propose automatic question answering ( qa ) base metric faithfulness , feqa , 1 leverage recent advance reading comprehension . give questionanswer pair generate summary , qa model extract answer document ; non - matched answer indicate unfaithful information summary . metric base word overlap , embed similarity , learn language understanding model , qa - base metric significantly high correlation human faithfulness score , especially highly abstractive summary .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 9, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 20, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 18, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Summarization,Hooks in the Headline: Learning to Generate Headlines with Controlled Styles,"Current summarization systems only produce plain, factual headlines, but do not meet the practical needs of creating memorable titles to increase exposure. We propose a new task, Stylistic Headline Generation (SHG), to enrich the headlines with three style options (humor, romance and clickbait), in order to attract more readers. With no style-specific article-headline pair (only a standard headline summarization dataset and mono-style corpora), our method TitleStylist generates style-specific headlines by combining the summarization and reconstruction tasks into a multitasking framework. We also introduced a novel parameter sharing scheme to further disentangle the style from the text. Through both automatic and human evaluation, we demonstrate that TitleStylist can generate relevant, fluent headlines with three target styles: humor, romance, and clickbait. The attraction score of our model generated headlines surpasses that of the state-ofthe-art summarization model by 9.68%, and even outperforms human-written references. 1","Hooks in the Headline: Learning to Generate Headlines with Controlled Styles Current summarization systems only produce plain, factual headlines, but do not meet the practical needs of creating memorable titles to increase exposure. We propose a new task, Stylistic Headline Generation (SHG), to enrich the headlines with three style options (humor, romance and clickbait), in order to attract more readers. With no style-specific article-headline pair (only a standard headline summarization dataset and mono-style corpora), our method TitleStylist generates style-specific headlines by combining the summarization and reconstruction tasks into a multitasking framework. We also introduced a novel parameter sharing scheme to further disentangle the style from the text. Through both automatic and human evaluation, we demonstrate that TitleStylist can generate relevant, fluent headlines with three target styles: humor, romance, and clickbait. The attraction score of our model generated headlines surpasses that of the state-ofthe-art summarization model by 9.68%, and even outperforms human-written references. 1","hooks headline : learn generate headline control style current summarization system produce plain , factual headline , meet practical need create memorable title increase exposure . propose new task , stylistic headline generation ( shg ) , enrich headline style option ( humor , romance clickbait ) , order attract reader . style - specific article - headline pair ( standard headline summarization dataset mono - style corpora ) , method titlestylist generate style - specific headline combine summarization reconstruction task multitasking framework . introduce novel parameter sharing scheme disentangle style text . automatic human evaluation , demonstrate titlestylist generate relevant , fluent headline target style : humor , romance , clickbait . attraction score model generate headline surpass state - ofthe - art summarization model 9.68 % , outperform human - write reference . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 15, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset,"This paper describes the Critical Role Dungeons and Dragons Dataset (CRD3) and related analyses. Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an openended role-playing game. The dataset is collected from 159 Critical Role episodes transcribed to text dialogues, consisting of 398,682 turns. It also includes corresponding abstractive summaries collected from the Fandom wiki. The dataset is linguistically unique in that the narratives are generated entirely through player collaboration and spoken interaction. For each dialogue, there are a large number of turns, multiple abstractive summaries with varying levels of detail, and semantic ties to the previous dialogues. In addition, we provide a data augmentation method that produces 34,243 summarydialogue chunk pairs to support current neural ML approaches, and we provide an abstractive summarization benchmark and evaluation.","Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset This paper describes the Critical Role Dungeons and Dragons Dataset (CRD3) and related analyses. Critical Role is an unscripted, live-streamed show where a fixed group of people play Dungeons and Dragons, an openended role-playing game. The dataset is collected from 159 Critical Role episodes transcribed to text dialogues, consisting of 398,682 turns. It also includes corresponding abstractive summaries collected from the Fandom wiki. The dataset is linguistically unique in that the narratives are generated entirely through player collaboration and spoken interaction. For each dialogue, there are a large number of turns, multiple abstractive summaries with varying levels of detail, and semantic ties to the previous dialogues. In addition, we provide a data augmentation method that produces 34,243 summarydialogue chunk pairs to support current neural ML approaches, and we provide an abstractive summarization benchmark and evaluation.","storytelling dialogue : critical role dungeons dragons dataset paper describe critical role dungeons dragons dataset ( crd3 ) related analysis . critical role unscripted , live - stream fix group people play dungeons dragons , openended role - play game . dataset collect 159 critical role episode transcribe text dialogue , consist 398,682 turn . include correspond abstractive summary collect fandom wiki . dataset linguistically unique narrative generate entirely player collaboration speak interaction . dialogue , large number turn , multiple abstractive summary vary level detail , semantic tie previous dialogue . addition , provide data augmentation method produce 34,243 summarydialogue chunk pair support current neural ml approach , provide abstractive summarization benchmark evaluation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 12, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Summarization,A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal,"Multi-document summarization (MDS) aims to compress the content in large document collections into short summaries and has important applications in story clustering for newsfeeds, presentation of search results, and timeline generation. However, there is a lack of datasets that realistically address such use cases at a scale large enough for training supervised models for this task. This work presents a new dataset for MDS that is large both in the total number of document clusters and in the size of individual clusters. We build this dataset by leveraging the Wikipedia Current Events Portal (WCEP), which provides concise and neutral human-written summaries of news events, with links to external source articles. We also automatically extend these source articles by looking for related articles in the Common Crawl archive. We provide a quantitative analysis of the dataset and empirical results for several state-of-the-art MDS techniques. The dataset is available at https://github.com/complementizer/ wcep-mds-dataset.","A Large-Scale Multi-Document Summarization Dataset from the Wikipedia Current Events Portal Multi-document summarization (MDS) aims to compress the content in large document collections into short summaries and has important applications in story clustering for newsfeeds, presentation of search results, and timeline generation. However, there is a lack of datasets that realistically address such use cases at a scale large enough for training supervised models for this task. This work presents a new dataset for MDS that is large both in the total number of document clusters and in the size of individual clusters. We build this dataset by leveraging the Wikipedia Current Events Portal (WCEP), which provides concise and neutral human-written summaries of news events, with links to external source articles. We also automatically extend these source articles by looking for related articles in the Common Crawl archive. We provide a quantitative analysis of the dataset and empirical results for several state-of-the-art MDS techniques. The dataset is available at https://github.com/complementizer/ wcep-mds-dataset.","large - scale multi - document summarization dataset wikipedia current events portal multi - document summarization ( mds ) aim compress content large document collection short summary important application story clustering newsfeed , presentation search result , timeline generation . , lack dataset realistically address use case scale large train supervise model task . work present new dataset mds large total number document cluster size individual cluster . build dataset leverage wikipedia current events portal ( wcep ) , provide concise neutral human - write summary news event , link external source article . automatically extend source article look related article common crawl archive . provide quantitative analysis dataset empirical result state - - - art mds technique . dataset available https://github.com/complementizer/ wcep - mds - dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 4, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward,"Sequence-to-sequence models for abstractive summarization have been studied extensively, yet the generated summaries commonly suffer from fabricated content, and are often found to be near-extractive. We argue that, to address these issues, the summarizer should acquire semantic interpretation over input, e.g., via structured representation, to allow the generation of more informative summaries. In this paper, we present ASGARD, a novel framework for Abstractive Summarization with Graph-Augmentation and semantic-driven RewarD. We propose the use of dual encoders-a sequential document encoder and a graphstructured encoder-to maintain the global context and local characteristics of entities, complementing each other. We further design a reward based on a multiple choice cloze test to drive the model to better capture entity interactions. Results show that our models produce significantly higher ROUGE scores than a variant without knowledge graph as input on both New York Times and CNN/Daily Mail datasets. We also obtain better or comparable performance compared to systems that are finetuned from large pretrained language models. Human judges further rate our model outputs as more informative and containing fewer unfaithful errors. Input Article of New York Times: John M. Fabrizi, the mayor of Bridgeport, admitted on Tuesday that he had used cocaine and abused alcohol while in office. Mr. Fabrizi, who was appointed mayor in 2003 after the former mayor, Joseph P. Ganim, went to prison on corruption charges, said he had sought help for his drug problem about 18 months ago and that he had not used drugs since. About four months ago, he added, he stopped drinking alcohol.","Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward Sequence-to-sequence models for abstractive summarization have been studied extensively, yet the generated summaries commonly suffer from fabricated content, and are often found to be near-extractive. We argue that, to address these issues, the summarizer should acquire semantic interpretation over input, e.g., via structured representation, to allow the generation of more informative summaries. In this paper, we present ASGARD, a novel framework for Abstractive Summarization with Graph-Augmentation and semantic-driven RewarD. We propose the use of dual encoders-a sequential document encoder and a graphstructured encoder-to maintain the global context and local characteristics of entities, complementing each other. We further design a reward based on a multiple choice cloze test to drive the model to better capture entity interactions. Results show that our models produce significantly higher ROUGE scores than a variant without knowledge graph as input on both New York Times and CNN/Daily Mail datasets. We also obtain better or comparable performance compared to systems that are finetuned from large pretrained language models. Human judges further rate our model outputs as more informative and containing fewer unfaithful errors. Input Article of New York Times: John M. Fabrizi, the mayor of Bridgeport, admitted on Tuesday that he had used cocaine and abused alcohol while in office. Mr. Fabrizi, who was appointed mayor in 2003 after the former mayor, Joseph P. Ganim, went to prison on corruption charges, said he had sought help for his drug problem about 18 months ago and that he had not used drugs since. About four months ago, he added, he stopped drinking alcohol.","knowledge graph - augmented abstractive summarization semantic - drive cloze reward sequence - - sequence model abstractive summarization study extensively , generate summary commonly suffer fabricate content , find near - extractive . argue , address issue , summarizer acquire semantic interpretation input , e.g. , structure representation , allow generation informative summary . paper , present asgard , novel framework abstractive summarization graph - augmentation semantic - drive reward. propose use dual encoder - sequential document encoder graphstructured encoder - maintain global context local characteristic entity , complement . design reward base multiple choice cloze test drive model well capture entity interaction . result model produce significantly high rouge score variant knowledge graph input new york times cnn / daily mail dataset . obtain well comparable performance compare system finetune large pretrained language model . human judge rate model output informative contain few unfaithful error . input article new york times : john m. fabrizi , mayor bridgeport , admit tuesday cocaine abuse alcohol office . mr. fabrizi , appoint mayor 2003 mayor , joseph p. ganim , go prison corruption charge , say seek help drug problem 18 month ago drug . month ago , add , stop drink alcohol .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 14, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Leveraging Graph to Improve Abstractive Multi-Document Summarization,"Graphs that capture relations between textual units have great benefits for detecting salient information from multiple documents and generating overall coherent summaries. In this paper, we develop a neural abstractive multidocument summarization (MDS) model which can leverage well-known graph representations of documents such as similarity graph and discourse graph, to more effectively process multiple input documents and produce abstractive summaries. Our model utilizes graphs to encode documents in order to capture cross-document relations, which is crucial to summarizing long documents. Our model can also take advantage of graphs to guide the summary generation process, which is beneficial for generating coherent and concise summaries. Furthermore, pre-trained language models can be easily combined with our model, which further improve the summarization performance significantly. Empirical results on the WikiSum and MultiNews dataset show that the proposed architecture brings substantial improvements over several strong baselines.","Leveraging Graph to Improve Abstractive Multi-Document Summarization Graphs that capture relations between textual units have great benefits for detecting salient information from multiple documents and generating overall coherent summaries. In this paper, we develop a neural abstractive multidocument summarization (MDS) model which can leverage well-known graph representations of documents such as similarity graph and discourse graph, to more effectively process multiple input documents and produce abstractive summaries. Our model utilizes graphs to encode documents in order to capture cross-document relations, which is crucial to summarizing long documents. Our model can also take advantage of graphs to guide the summary generation process, which is beneficial for generating coherent and concise summaries. Furthermore, pre-trained language models can be easily combined with our model, which further improve the summarization performance significantly. Empirical results on the WikiSum and MultiNews dataset show that the proposed architecture brings substantial improvements over several strong baselines.","leverage graph improve abstractive multi - document summarization graph capture relation textual unit great benefit detect salient information multiple document generate overall coherent summary . paper , develop neural abstractive multidocument summarization ( mds ) model leverage - know graph representation document similarity graph discourse graph , effectively process multiple input document produce abstractive summary . model utilize graph encode document order capture cross - document relation , crucial summarize long document . model advantage graph guide summary generation process , beneficial generate coherent concise summary . furthermore , pre - trained language model easily combine model , improve summarization performance significantly . empirical result wikisum multinews dataset propose architecture bring substantial improvement strong baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 11, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 8, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 18, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Heterogeneous Graph Neural Networks for Extractive Document Summarization,"As a crucial step in extractive document summarization, learning cross-sentence relations has been explored by a plethora of approaches. An intuitive way is to put them in the graphbased neural network, which has a more complex structure for capturing inter-sentence relationships. In this paper, we present a heterogeneous graph-based neural network for extractive summarization (HETERSUMGRAPH), which contains semantic nodes of different granularity levels apart from sentences. These additional nodes act as the intermediary between sentences and enrich the cross-sentence relations. Besides, our graph structure is flexible in natural extension from a singledocument setting to multi-document via introducing document nodes. To our knowledge, we are the first one to introduce different types of nodes into graph-based neural networks for extractive document summarization and perform a comprehensive qualitative analysis to investigate their benefits. The code will be released on Github 1 .","Heterogeneous Graph Neural Networks for Extractive Document Summarization As a crucial step in extractive document summarization, learning cross-sentence relations has been explored by a plethora of approaches. An intuitive way is to put them in the graphbased neural network, which has a more complex structure for capturing inter-sentence relationships. In this paper, we present a heterogeneous graph-based neural network for extractive summarization (HETERSUMGRAPH), which contains semantic nodes of different granularity levels apart from sentences. These additional nodes act as the intermediary between sentences and enrich the cross-sentence relations. Besides, our graph structure is flexible in natural extension from a singledocument setting to multi-document via introducing document nodes. To our knowledge, we are the first one to introduce different types of nodes into graph-based neural networks for extractive document summarization and perform a comprehensive qualitative analysis to investigate their benefits. The code will be released on Github 1 .","heterogeneous graph neural networks extractive document summarization crucial step extractive document summarization , learn cross - sentence relation explore plethora approach . intuitive way graphbased neural network , complex structure capture inter - sentence relationship . paper , present heterogeneous graph - base neural network extractive summarization ( hetersumgraph ) , contain semantic node different granularity level apart sentence . additional node act intermediary sentence enrich cross - sentence relation . , graph structure flexible natural extension singledocument setting multi - document introduce document node . knowledge , introduce different type node graph - base neural network extractive document summarization perform comprehensive qualitative analysis investigate benefit . code release github 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 6, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 14, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Discourse-Aware Neural Extractive Text Summarization,"Recently BERT has been adopted for document encoding in state-of-the-art text summarization models. However, sentence-based extractive models often result in redundant or uninformative phrases in the extracted summaries. Also, long-range dependencies throughout a document are not well captured by BERT, which is pre-trained on sentence pairs instead of documents. To address these issues, we present a discourse-aware neural summarization model -DISCOBERT 1 . DISCOBERT extracts sub-sentential discourse units (instead of sentences) as candidates for extractive selection on a finer granularity. To capture the long-range dependencies among discourse units, structural discourse graphs are constructed based on RST trees and coreference mentions, encoded with Graph Convolutional Networks. Experiments show that the proposed model outperforms state-of-the-art methods by a significant margin on popular summarization benchmarks compared to other BERT-base models.","Discourse-Aware Neural Extractive Text Summarization Recently BERT has been adopted for document encoding in state-of-the-art text summarization models. However, sentence-based extractive models often result in redundant or uninformative phrases in the extracted summaries. Also, long-range dependencies throughout a document are not well captured by BERT, which is pre-trained on sentence pairs instead of documents. To address these issues, we present a discourse-aware neural summarization model -DISCOBERT 1 . DISCOBERT extracts sub-sentential discourse units (instead of sentences) as candidates for extractive selection on a finer granularity. To capture the long-range dependencies among discourse units, structural discourse graphs are constructed based on RST trees and coreference mentions, encoded with Graph Convolutional Networks. Experiments show that the proposed model outperforms state-of-the-art methods by a significant margin on popular summarization benchmarks compared to other BERT-base models.","discourse - aware neural extractive text summarization recently bert adopt document encoding state - - - art text summarization model . , sentence - base extractive model result redundant uninformative phrase extract summary . , long - range dependency document capture bert , pre - train sentence pair instead document . address issue , present discourse - aware neural summarization model -discobert 1 . discobert extract sub - sentential discourse unit ( instead sentence ) candidate extractive selection fine granularity . capture long - range dependency discourse unit , structural discourse graph construct base rst tree coreference mention , encode graph convolutional networks . experiment propose model outperform state - - - art method significant margin popular summarization benchmark compare bert - base model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 5, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 11, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Screenplay Summarization Using Latent Narrative Structure,"Most general-purpose extractive summarization models are trained on news articles, which are short and present all important information upfront. As a result, such models are biased by position and often perform a smart selection of sentences from the beginning of the document. When summarizing long narratives, which have complex structure and present information piecemeal, simple position heuristics are not sufficient. In this paper, we propose to explicitly incorporate the underlying structure of narratives into general unsupervised and supervised extractive summarization models. We formalize narrative structure in terms of key narrative events (turning points) and treat it as latent in order to summarize screenplays (i.e., extract an optimal sequence of scenes). Experimental results on the CSI corpus of TV screenplays, which we augment with scene-level summarization labels, show that latent turning points correlate with important aspects of a CSI episode and improve summarization performance over general extractive algorithms, leading to more complete and diverse summaries.","Screenplay Summarization Using Latent Narrative Structure Most general-purpose extractive summarization models are trained on news articles, which are short and present all important information upfront. As a result, such models are biased by position and often perform a smart selection of sentences from the beginning of the document. When summarizing long narratives, which have complex structure and present information piecemeal, simple position heuristics are not sufficient. In this paper, we propose to explicitly incorporate the underlying structure of narratives into general unsupervised and supervised extractive summarization models. We formalize narrative structure in terms of key narrative events (turning points) and treat it as latent in order to summarize screenplays (i.e., extract an optimal sequence of scenes). Experimental results on the CSI corpus of TV screenplays, which we augment with scene-level summarization labels, show that latent turning points correlate with important aspects of a CSI episode and improve summarization performance over general extractive algorithms, leading to more complete and diverse summaries.","screenplay summarization latent narrative structure general - purpose extractive summarization model train news article , short present important information upfront . result , model bias position perform smart selection sentence beginning document . summarize long narrative , complex structure present information piecemeal , simple position heuristic sufficient . paper , propose explicitly incorporate underlie structure narrative general unsupervised supervised extractive summarization model . formalize narrative structure term key narrative event ( turning point ) treat latent order summarize screenplay ( i.e. , extract optimal sequence scene ) . experimental result csi corpus tv screenplay , augment scene - level summarization label , latent turning point correlate important aspect csi episode improve summarization performance general extractive algorithm , lead complete diverse summary .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 10, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Summarization,True
Summarization,Jointly Learning to Align and Summarize for Neural Cross-Lingual Summarization,"Cross-lingual summarization is the task of generating a summary in one language given a text in a different language. Previous works on cross-lingual summarization mainly focus on using pipeline methods or training an endto-end model using the translated parallel data. However, it is a big challenge for the model to directly learn cross-lingual summarization as it requires learning to understand different languages and learning how to summarize at the same time. In this paper, we propose to ease the cross-lingual summarization training by jointly learning to align and summarize. We design relevant loss functions to train this framework and propose several methods to enhance the isomorphism and cross-lingual transfer between languages. Experimental results show that our model can outperform competitive models in most cases. In addition, we show that our model even has the ability to generate cross-lingual summaries without access to any cross-lingual corpus.","Jointly Learning to Align and Summarize for Neural Cross-Lingual Summarization Cross-lingual summarization is the task of generating a summary in one language given a text in a different language. Previous works on cross-lingual summarization mainly focus on using pipeline methods or training an endto-end model using the translated parallel data. However, it is a big challenge for the model to directly learn cross-lingual summarization as it requires learning to understand different languages and learning how to summarize at the same time. In this paper, we propose to ease the cross-lingual summarization training by jointly learning to align and summarize. We design relevant loss functions to train this framework and propose several methods to enhance the isomorphism and cross-lingual transfer between languages. Experimental results show that our model can outperform competitive models in most cases. In addition, we show that our model even has the ability to generate cross-lingual summaries without access to any cross-lingual corpus.","jointly learn align summarize neural cross - lingual summarization cross - lingual summarization task generate summary language give text different language . previous work cross - lingual summarization mainly focus pipeline method train endto - end model translate parallel datum . , big challenge model directly learn cross - lingual summarization require learn understand different language learn summarize time . paper , propose ease cross - lingual summarization training jointly learn align summarize . design relevant loss function train framework propose method enhance isomorphism cross - lingual transfer language . experimental result model outperform competitive model case . addition , model ability generate cross - lingual summary access cross - lingual corpus .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports,"Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by factchecking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of humanauthored ones.","Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by factchecking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of humanauthored ones.","optimizing factual correctness summary : study summarize radiology report neural abstractive summarization model able generate summary high overlap human reference . , exist model optimize factual correctness , critical metric real - world application . work , develop general framework evaluate factual correctness generate summary factchecke automatically reference information extraction module . propose training strategy optimize neural summarization model factual correctness reward reinforcement learning . apply propose method summarization radiology report , factual correctness key requirement . separate dataset collect hospital , automatic human evaluation propose approach substantially improve factual correctness overall quality output competitive neural summarization system , produce radiology summary approach quality humanauthored one .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 18, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Examining the State-of-the-Art in News Timeline Summarization,"Previous work on automatic news timeline summarization (TLS) leaves an unclear picture about how this task can generally be approached and how well it is currently solved. This is mostly due to the focus on individual subtasks, such as date selection and date summarization, and to the previous lack of appropriate evaluation metrics for the full TLS task. In this paper, we compare different TLS strategies using appropriate evaluation frameworks, and propose a simple and effective combination of methods that improves over the stateof-the-art on all tested benchmarks. For a more robust evaluation, we also present a new TLS dataset, which is larger and spans longer time periods than previous datasets. The dataset will be made available at https://github. com/complementizer/news-tls.","Examining the State-of-the-Art in News Timeline Summarization Previous work on automatic news timeline summarization (TLS) leaves an unclear picture about how this task can generally be approached and how well it is currently solved. This is mostly due to the focus on individual subtasks, such as date selection and date summarization, and to the previous lack of appropriate evaluation metrics for the full TLS task. In this paper, we compare different TLS strategies using appropriate evaluation frameworks, and propose a simple and effective combination of methods that improves over the stateof-the-art on all tested benchmarks. For a more robust evaluation, we also present a new TLS dataset, which is larger and spans longer time periods than previous datasets. The dataset will be made available at https://github. com/complementizer/news-tls.","examine state - - - art news timeline summarization previous work automatic news timeline summarization ( tls ) leave unclear picture task generally approach currently solve . focus individual subtask , date selection date summarization , previous lack appropriate evaluation metric tls task . paper , compare different tls strategy appropriate evaluation framework , propose simple effective combination method improve stateof - - art test benchmark . robust evaluation , present new tls dataset , large span long time period previous dataset . dataset available https://github . com / complementizer / news - tls .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Summarization,The Summary Loop: Learning to Write Abstractive Summaries Without Examples,"This work presents a new approach to unsupervised abstractive summarization based on maximizing a combination of coverage and fluency for a given length constraint. It introduces a novel method that encourages the inclusion of key terms from the original document into the summary: key terms are masked out of the original document and must be filled in by a coverage model using the current generated summary. A novel unsupervised training procedure leverages this coverage model along with a fluency model to generate and score summaries. When tested on popular news summarization datasets, the method outperforms previous unsupervised methods by more than 2 R-1 points, and approaches results of competitive supervised methods. Our model attains higher levels of abstraction with copied passages roughly two times shorter than prior work, and learns to compress and merge sentences without supervision.","The Summary Loop: Learning to Write Abstractive Summaries Without Examples This work presents a new approach to unsupervised abstractive summarization based on maximizing a combination of coverage and fluency for a given length constraint. It introduces a novel method that encourages the inclusion of key terms from the original document into the summary: key terms are masked out of the original document and must be filled in by a coverage model using the current generated summary. A novel unsupervised training procedure leverages this coverage model along with a fluency model to generate and score summaries. When tested on popular news summarization datasets, the method outperforms previous unsupervised methods by more than 2 R-1 points, and approaches results of competitive supervised methods. Our model attains higher levels of abstraction with copied passages roughly two times shorter than prior work, and learns to compress and merge sentences without supervision.","summary loop : learn write abstractive summary example work present new approach unsupervised abstractive summarization base maximize combination coverage fluency give length constraint . introduce novel method encourage inclusion key term original document summary : key term mask original document fill coverage model current generate summary . novel unsupervised training procedure leverage coverage model fluency model generate score summary . test popular news summarization dataset , method outperform previous unsupervised method 2 r-1 point , approach result competitive supervise method . model attain high level abstraction copy passage roughly time short prior work , learn compress merge sentence supervision .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 13, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Composing Elementary Discourse Units in Abstractive Summarization,"In this paper, we argue that elementary discourse unit (EDU) is a more appropriate textual unit of content selection than the sentence unit in abstractive summarization. To well handle the problem of composing EDUs into an informative and fluent summary, we propose a novel summarization method that first designs an EDU selection model to extract and group informative EDUs and then an EDU fusion model to fuse the EDUs in each group into one sentence. We also design the reinforcement learning mechanism to use EDU fusion results to reward the EDU selection action, boosting the final summarization performance. Experiments on CNN/Daily Mail have demonstrated the effectiveness of our model.","Composing Elementary Discourse Units in Abstractive Summarization In this paper, we argue that elementary discourse unit (EDU) is a more appropriate textual unit of content selection than the sentence unit in abstractive summarization. To well handle the problem of composing EDUs into an informative and fluent summary, we propose a novel summarization method that first designs an EDU selection model to extract and group informative EDUs and then an EDU fusion model to fuse the EDUs in each group into one sentence. We also design the reinforcement learning mechanism to use EDU fusion results to reward the EDU selection action, boosting the final summarization performance. Experiments on CNN/Daily Mail have demonstrated the effectiveness of our model.","compose elementary discourse unit abstractive summarization paper , argue elementary discourse unit ( edu ) appropriate textual unit content selection sentence unit abstractive summarization . handle problem compose edu informative fluent summary , propose novel summarization method design edu selection model extract group informative edu edu fusion model fuse edu group sentence . design reinforcement learning mechanism use edu fusion result reward edu selection action , boost final summarization performance . experiment cnn / daily mail demonstrate effectiveness model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 9, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Discrete Optimization for Unsupervised Sentence Summarization with Word-Level Extraction,"Automatic sentence summarization produces a shorter version of a sentence, while preserving its most important information. A good summary is characterized by language fluency and high information overlap with the source sentence. We model these two aspects in an unsupervised objective function, consisting of language modeling and semantic similarity metrics. We search for a high-scoring summary by discrete optimization. Our proposed method achieves a new state-of-the art for unsupervised sentence summarization according to ROUGE scores. Additionally, we demonstrate that the commonly reported ROUGE F1 metric is sensitive to summary length. Since this is unwillingly exploited in recent work, we emphasize that future evaluation should explicitly group summarization systems by output length brackets. 1","Discrete Optimization for Unsupervised Sentence Summarization with Word-Level Extraction Automatic sentence summarization produces a shorter version of a sentence, while preserving its most important information. A good summary is characterized by language fluency and high information overlap with the source sentence. We model these two aspects in an unsupervised objective function, consisting of language modeling and semantic similarity metrics. We search for a high-scoring summary by discrete optimization. Our proposed method achieves a new state-of-the art for unsupervised sentence summarization according to ROUGE scores. Additionally, we demonstrate that the commonly reported ROUGE F1 metric is sensitive to summary length. Since this is unwillingly exploited in recent work, we emphasize that future evaluation should explicitly group summarization systems by output length brackets. 1","discrete optimization unsupervised sentence summarization word - level extraction automatic sentence summarization produce short version sentence , preserve important information . good summary characterize language fluency high information overlap source sentence . model aspect unsupervised objective function , consist language modeling semantic similarity metric . search high - score summary discrete optimization . propose method achieve new state - - art unsupervised sentence summarization accord rouge score . additionally , demonstrate commonly report rouge f1 metric sensitive summary length . unwillingly exploit recent work , emphasize future evaluation explicitly group summarization system output length bracket . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Extractive Summarization as Text Matching,"This paper creates a paradigm shift with regard to the way we build neural extractive summarization systems. Instead of following the commonly used framework of extracting sentences individually and modeling the relationship between sentences, we formulate the extractive summarization task as a semantic text matching problem, in which a source document and candidate summaries will be (extracted from the original text) matched in a semantic space. Notably, this paradigm shift to semantic matching framework is well-grounded in our comprehensive analysis of the inherent gap between sentence-level and summary-level extractors based on the property of the dataset. Besides, even instantiating the framework with a simple form of a matching model, we have driven the state-of-the-art extractive result on CNN/DailyMail to a new level (44.41 in ROUGE-1). Experiments on the other five datasets also show the effectiveness of the matching framework. We believe the power of this matching-based summarization framework has not been fully exploited. To encourage more instantiations in the future, we have released our codes, processed dataset, as well as generated summaries in https://github. com/maszhongming/MatchSum.","Extractive Summarization as Text Matching This paper creates a paradigm shift with regard to the way we build neural extractive summarization systems. Instead of following the commonly used framework of extracting sentences individually and modeling the relationship between sentences, we formulate the extractive summarization task as a semantic text matching problem, in which a source document and candidate summaries will be (extracted from the original text) matched in a semantic space. Notably, this paradigm shift to semantic matching framework is well-grounded in our comprehensive analysis of the inherent gap between sentence-level and summary-level extractors based on the property of the dataset. Besides, even instantiating the framework with a simple form of a matching model, we have driven the state-of-the-art extractive result on CNN/DailyMail to a new level (44.41 in ROUGE-1). Experiments on the other five datasets also show the effectiveness of the matching framework. We believe the power of this matching-based summarization framework has not been fully exploited. To encourage more instantiations in the future, we have released our codes, processed dataset, as well as generated summaries in https://github. com/maszhongming/MatchSum.","extractive summarization text matching paper create paradigm shift regard way build neural extractive summarization system . instead follow commonly framework extract sentence individually model relationship sentence , formulate extractive summarization task semantic text matching problem , source document candidate summary ( extract original text ) match semantic space . notably , paradigm shift semantic matching framework - ground comprehensive analysis inherent gap sentence - level summary - level extractor base property dataset . , instantiate framework simple form matching model , drive state - - - art extractive result cnn / dailymail new level ( 44.41 rouge-1 ) . experiment dataset effectiveness matching framework . believe power matching - base summarization framework fully exploit . encourage instantiation future , release code , process dataset , generate summary https://github . com / maszhongming / matchsum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 13, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Exploring Content Selection in Summarization of Novel Chapters,"We present a new summarization task, generating summaries of novel chapters using summary/chapter pairs from online study guides. This is a harder task than the news summarization task, given the chapter length as well as the extreme paraphrasing and generalization found in the summaries. We focus on extractive summarization, which requires the creation of a gold-standard set of extractive summaries. We present a new metric for aligning reference summary sentences with chapter sentences to create gold extracts and also experiment with different alignment methods. Our experiments demonstrate significant improvement over prior alignment approaches for our task as shown through automatic metrics and a crowd-sourced pyramid analysis. * Equal contribution. Work done while at Amazon. 1 We tried two abstractive models (Chen and Bansal, 2018; Liu and Lapata, 2019) but ROUGE was low and the output was poor with many repetitions and hallucinations.","Exploring Content Selection in Summarization of Novel Chapters We present a new summarization task, generating summaries of novel chapters using summary/chapter pairs from online study guides. This is a harder task than the news summarization task, given the chapter length as well as the extreme paraphrasing and generalization found in the summaries. We focus on extractive summarization, which requires the creation of a gold-standard set of extractive summaries. We present a new metric for aligning reference summary sentences with chapter sentences to create gold extracts and also experiment with different alignment methods. Our experiments demonstrate significant improvement over prior alignment approaches for our task as shown through automatic metrics and a crowd-sourced pyramid analysis. * Equal contribution. Work done while at Amazon. 1 We tried two abstractive models (Chen and Bansal, 2018; Liu and Lapata, 2019) but ROUGE was low and the output was poor with many repetitions and hallucinations.","explore content selection summarization novel chapter present new summarization task , generate summary novel chapter summary / chapter pair online study guide . hard task news summarization task , give chapter length extreme paraphrasing generalization find summary . focus extractive summarization , require creation gold - standard set extractive summary . present new metric align reference summary sentence chapter sentence create gold extract experiment different alignment method . experiment demonstrate significant improvement prior alignment approach task show automatic metric crowd - source pyramid analysis . * equal contribution . work amazon . 1 try abstractive model ( chen bansal , 2018 ; liu lapata , 2019 ) rouge low output poor repetition hallucination .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 13, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Self-Attention Guided Copy Mechanism for Abstractive Summarization,"Copy module has been widely equipped in the recent abstractive summarization models, which facilitates the decoder to extract words from the source into the summary. Generally, the encoder-decoder attention is served as the copy distribution, while how to guarantee that important words in the source are copied remains a challenge. In this work, we propose a Transformer-based model to enhance the copy mechanism. Specifically, we identify the importance of each source word based on the degree centrality with a directed graph built by the self-attention layer in the Transformer. We use the centrality of each source word to guide the copy process explicitly. Experimental results show that the self-attention graph provides useful guidance for the copy distribution. Our proposed models significantly outperform the baseline methods on the CNN/Daily Mail dataset and the Gigaword dataset.","Self-Attention Guided Copy Mechanism for Abstractive Summarization Copy module has been widely equipped in the recent abstractive summarization models, which facilitates the decoder to extract words from the source into the summary. Generally, the encoder-decoder attention is served as the copy distribution, while how to guarantee that important words in the source are copied remains a challenge. In this work, we propose a Transformer-based model to enhance the copy mechanism. Specifically, we identify the importance of each source word based on the degree centrality with a directed graph built by the self-attention layer in the Transformer. We use the centrality of each source word to guide the copy process explicitly. Experimental results show that the self-attention graph provides useful guidance for the copy distribution. Our proposed models significantly outperform the baseline methods on the CNN/Daily Mail dataset and the Gigaword dataset.","self - attention guide copy mechanism abstractive summarization copy module widely equip recent abstractive summarization model , facilitate decoder extract word source summary . generally , encoder - decoder attention serve copy distribution , guarantee important word source copy remain challenge . work , propose transformer - base model enhance copy mechanism . specifically , identify importance source word base degree centrality direct graph build self - attention layer transformer . use centrality source word guide copy process explicitly . experimental result self - attention graph provide useful guidance copy distribution . propose model significantly outperform baseline method cnn / daily mail dataset gigaword dataset .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Summarization,Improving Truthfulness of Headline Generation,"Most studies on abstractive summarization report ROUGE scores between system and reference summaries. However, we have a concern about the truthfulness of generated summaries: whether all facts of a generated summary are mentioned in the source text. This paper explores improving the truthfulness in headline generation on two popular datasets. Analyzing headlines generated by the stateof-the-art encoder-decoder model, we show that the model sometimes generates untruthful headlines. We conjecture that one of the reasons lies in untruthful supervision data used for training the model. In order to quantify the truthfulness of article-headline pairs, we consider the textual entailment of whether an article entails its headline. After confirming quite a few untruthful instances in the datasets, this study hypothesizes that removing untruthful instances from the supervision data may remedy the problem of the untruthful behaviors of the model. Building a binary classifier that predicts an entailment relation between an article and its headline, we filter out untruthful instances from the supervision data. Experimental results demonstrate that the headline generation model trained on filtered supervision data shows no clear difference in ROUGE scores but remarkable improvements in automatic and manual evaluations of the generated headlines.","Improving Truthfulness of Headline Generation Most studies on abstractive summarization report ROUGE scores between system and reference summaries. However, we have a concern about the truthfulness of generated summaries: whether all facts of a generated summary are mentioned in the source text. This paper explores improving the truthfulness in headline generation on two popular datasets. Analyzing headlines generated by the stateof-the-art encoder-decoder model, we show that the model sometimes generates untruthful headlines. We conjecture that one of the reasons lies in untruthful supervision data used for training the model. In order to quantify the truthfulness of article-headline pairs, we consider the textual entailment of whether an article entails its headline. After confirming quite a few untruthful instances in the datasets, this study hypothesizes that removing untruthful instances from the supervision data may remedy the problem of the untruthful behaviors of the model. Building a binary classifier that predicts an entailment relation between an article and its headline, we filter out untruthful instances from the supervision data. Experimental results demonstrate that the headline generation model trained on filtered supervision data shows no clear difference in ROUGE scores but remarkable improvements in automatic and manual evaluations of the generated headlines.","improve truthfulness headline generation study abstractive summarization report rouge score system reference summary . , concern truthfulness generate summary : fact generate summary mention source text . paper explore improve truthfulness headline generation popular dataset . analyze headline generate stateof - - art encoder - decoder model , model generate untruthful headline . conjecture reason lie untruthful supervision datum train model . order quantify truthfulness article - headline pair , consider textual entailment article entail headline . confirm untruthful instance dataset , study hypothesize remove untruthful instance supervision datum remedy problem untruthful behavior model . build binary classifier predict entailment relation article headline , filter untruthful instance supervision datum . experimental result demonstrate headline generation model train filter supervision datum show clear difference rouge score remarkable improvement automatic manual evaluation generate headline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 9, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 17, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Asking and Answering Questions to Evaluate the Factual Consistency of Summaries,"Practical applications of abstractive summarization models are limited by frequent factual inconsistencies with respect to their input. Existing automatic evaluation metrics for summarization are largely insensitive to such errors. We propose QAGS, 1 an automatic evaluation protocol that is designed to identify factual inconsistencies in a generated summary. QAGS is based on the intuition that if we ask questions about a summary and its source, we will receive similar answers if the summary is factually consistent with the source. To evaluate QAGS, we collect human judgments of factual consistency on model-generated summaries for the CNN/DailyMail (Hermann et al., 2015) and XSUM (Narayan et al., 2018) summarization datasets. QAGS has substantially higher correlations with these judgments than other automatic evaluation metrics. Also, QAGS offers a natural form of interpretability: The answers and questions generated while computing QAGS indicate which tokens of a summary are inconsistent and why. We believe QAGS is a promising tool in automatically generating usable and factually consistent text. Code for QAGS will be available at https://github. com/W4ngatang/qags.","Asking and Answering Questions to Evaluate the Factual Consistency of Summaries Practical applications of abstractive summarization models are limited by frequent factual inconsistencies with respect to their input. Existing automatic evaluation metrics for summarization are largely insensitive to such errors. We propose QAGS, 1 an automatic evaluation protocol that is designed to identify factual inconsistencies in a generated summary. QAGS is based on the intuition that if we ask questions about a summary and its source, we will receive similar answers if the summary is factually consistent with the source. To evaluate QAGS, we collect human judgments of factual consistency on model-generated summaries for the CNN/DailyMail (Hermann et al., 2015) and XSUM (Narayan et al., 2018) summarization datasets. QAGS has substantially higher correlations with these judgments than other automatic evaluation metrics. Also, QAGS offers a natural form of interpretability: The answers and questions generated while computing QAGS indicate which tokens of a summary are inconsistent and why. We believe QAGS is a promising tool in automatically generating usable and factually consistent text. Code for QAGS will be available at https://github. com/W4ngatang/qags.","ask answer question evaluate factual consistency summary practical application abstractive summarization model limit frequent factual inconsistency respect input . exist automatic evaluation metric summarization largely insensitive error . propose qags , 1 automatic evaluation protocol design identify factual inconsistency generate summary . qags base intuition ask question summary source , receive similar answer summary factually consistent source . evaluate qags , collect human judgment factual consistency model - generate summary cnn / dailymail ( hermann et al . , 2015 ) xsum ( narayan et al . , 2018 ) summarization dataset . qags substantially high correlation judgment automatic evaluation metric . , qags offer natural form interpretability : answer question generate compute qags indicate token summary inconsistent . believe qags promising tool automatically generate usable factually consistent text . code qags available https://github . com / w4ngatang / qags .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 15, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 19, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,"Attend, Translate and Summarize: An Efficient Method for Neural Cross-Lingual Summarization","Cross-lingual summarization aims at summarizing a document in one language (e.g., Chinese) into another language (e.g., English). In this paper, we propose a novel method inspired by the translation pattern in the process of obtaining a cross-lingual summary. We first attend to some words in the source text, then translate them into the target language, and summarize to get the final summary. Specifically, we first employ the encoder-decoder attention distribution to attend to the source words. Second, we present three strategies to acquire the translation probability, which helps obtain the translation candidates for each source word. Finally, each summary word is generated either from the neural distribution or from the translation candidates of source words. Experimental results on Chinese-to-English and English-to-Chinese summarization tasks have shown that our proposed method can significantly outperform the baselines, achieving comparable performance with the state-of-the-art.","Attend, Translate and Summarize: An Efficient Method for Neural Cross-Lingual Summarization Cross-lingual summarization aims at summarizing a document in one language (e.g., Chinese) into another language (e.g., English). In this paper, we propose a novel method inspired by the translation pattern in the process of obtaining a cross-lingual summary. We first attend to some words in the source text, then translate them into the target language, and summarize to get the final summary. Specifically, we first employ the encoder-decoder attention distribution to attend to the source words. Second, we present three strategies to acquire the translation probability, which helps obtain the translation candidates for each source word. Finally, each summary word is generated either from the neural distribution or from the translation candidates of source words. Experimental results on Chinese-to-English and English-to-Chinese summarization tasks have shown that our proposed method can significantly outperform the baselines, achieving comparable performance with the state-of-the-art.","attend , translate summarize : efficient method neural cross - lingual summarization cross - lingual summarization aim summarize document language ( e.g. , chinese ) language ( e.g. , english ) . paper , propose novel method inspire translation pattern process obtain cross - lingual summary . attend word source text , translate target language , summarize final summary . specifically , employ encoder - decoder attention distribution attend source word . second , present strategy acquire translation probability , help obtain translation candidate source word . finally , summary word generate neural distribution translation candidate source word . experimental result chinese - - english english - - chinese summarization task show propose method significantly outperform baseline , achieve comparable performance state - - - art .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Summarization,On Faithfulness and Factuality in Abstractive Summarization,"It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria. 1 * The first two authors contributed equally. 1 Our human annotated summaries for faithfulness and factuality will be released at https://github.com/google-researchdatasets/xsum hallucination annotations.","On Faithfulness and Factuality in Abstractive Summarization It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria. 1 * The first two authors contributed equally. 1 Our human annotated summaries for faithfulness and factuality will be released at https://github.com/google-researchdatasets/xsum hallucination annotations.","faithfulness factuality abstractive summarization known standard likelihood training approximate decoding objective neural text generation model lead human - like response open - ended task language modeling story generation . paper analyze limitation model abstractive document summarization find model highly prone hallucinate content unfaithful input document . conduct large scale human evaluation neural abstractive summarization system well understand type hallucination produce . human annotator find substantial amount hallucinate content model generate summary . , analysis pretrained model well summarizer term raw metric , i.e. , rouge , generate faithful factual summary evaluate human . furthermore , textual entailment measure well correlate faithfulness standard metric , potentially lead way automatic evaluation metric training decoding criterion . 1 * author contribute equally . 1 human annotate summary faithfulness factuality release https://github.com/google-researchdatasets/xsum hallucination annotation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 5, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 17, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,SUPERT: Towards New Frontiers in Unsupervised Evaluation Metrics for Multi-Document Summarization,"We study unsupervised multi-document summarization evaluation metrics, which require neither human-written reference summaries nor human annotations (e.g. preferences, ratings, etc.). We propose SUPERT, which rates the quality of a summary by measuring its semantic similarity with a pseudo reference summary, i.e. selected salient sentences from the source documents, using contextualized embeddings and soft token alignment techniques. Compared to the state-of-theart unsupervised evaluation metrics, SUPERT correlates better with human ratings by 18-39%. Furthermore, we use SUPERT as rewards to guide a neural-based reinforcement learning summarizer, yielding favorable performance compared to the state-of-the-art unsupervised summarizers. All source code is available at https://github.com/yg211/ acl20-ref-free-eval.","SUPERT: Towards New Frontiers in Unsupervised Evaluation Metrics for Multi-Document Summarization We study unsupervised multi-document summarization evaluation metrics, which require neither human-written reference summaries nor human annotations (e.g. preferences, ratings, etc.). We propose SUPERT, which rates the quality of a summary by measuring its semantic similarity with a pseudo reference summary, i.e. selected salient sentences from the source documents, using contextualized embeddings and soft token alignment techniques. Compared to the state-of-theart unsupervised evaluation metrics, SUPERT correlates better with human ratings by 18-39%. Furthermore, we use SUPERT as rewards to guide a neural-based reinforcement learning summarizer, yielding favorable performance compared to the state-of-the-art unsupervised summarizers. All source code is available at https://github.com/yg211/ acl20-ref-free-eval.","supert : new frontier unsupervised evaluation metric multi - document summarization study unsupervised multi - document summarization evaluation metric , require human - write reference summary human annotation ( e.g. preference , rating , etc . ) . propose supert , rate quality summary measure semantic similarity pseudo reference summary , i.e. select salient sentence source document , contextualize embedding soft token alignment technique . compare state - - theart unsupervised evaluation metric , supert correlate well human rating 18 - 39 % . furthermore , use supert reward guide neural - base reinforcement learning summarizer , yield favorable performance compare state - - - art unsupervised summarizer . source code available https://github.com/yg211/ acl20 - ref - free - eval .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Summarization,Unsupervised Opinion Summarization with Noising and Denoising,"The supervised training of high-capacity models on large datasets containing hundreds of thousands of document-summary pairs is critical to the recent success of deep learning techniques for abstractive summarization. Unfortunately, in most domains (other than news) such training data is not available and cannot be easily sourced. In this paper we enable the use of supervised learning for the setting where there are only documents available (e.g., product or business reviews) without ground truth summaries. We create a synthetic dataset from a corpus of user reviews by sampling a review, pretending it is a summary, and generating noisy versions thereof which we treat as pseudo-review input. We introduce several linguistically motivated noise generation functions and a summarization model which learns to denoise the input and generate the original review. At test time, the model accepts genuine reviews and generates a summary containing salient opinions, treating those that do not reach consensus as noise. Extensive automatic and human evaluation shows that our model brings substantial improvements over both abstractive and extractive baselines.","Unsupervised Opinion Summarization with Noising and Denoising The supervised training of high-capacity models on large datasets containing hundreds of thousands of document-summary pairs is critical to the recent success of deep learning techniques for abstractive summarization. Unfortunately, in most domains (other than news) such training data is not available and cannot be easily sourced. In this paper we enable the use of supervised learning for the setting where there are only documents available (e.g., product or business reviews) without ground truth summaries. We create a synthetic dataset from a corpus of user reviews by sampling a review, pretending it is a summary, and generating noisy versions thereof which we treat as pseudo-review input. We introduce several linguistically motivated noise generation functions and a summarization model which learns to denoise the input and generate the original review. At test time, the model accepts genuine reviews and generates a summary containing salient opinions, treating those that do not reach consensus as noise. Extensive automatic and human evaluation shows that our model brings substantial improvements over both abstractive and extractive baselines.","unsupervised opinion summarization noising denoising supervise training high - capacity model large dataset contain hundred thousand document - summary pair critical recent success deep learning technique abstractive summarization . unfortunately , domain ( news ) training data available easily source . paper enable use supervise learning setting document available ( e.g. , product business review ) grind truth summary . create synthetic dataset corpus user review sample review , pretend summary , generate noisy version thereof treat pseudo - review input . introduce linguistically motivated noise generation function summarization model learn denoise input generate original review . test time , model accept genuine review generate summary contain salient opinion , treat reach consensus noise . extensive automatic human evaluation show model bring substantial improvement abstractive extractive baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 20, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,A Transformer-based Approach for Source Code Summarization,"Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens' position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available 1 to facilitate future research.","A Transformer-based Approach for Source Code Summarization Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens' position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available 1 to facilitate future research.","transformer - base approach source code summarization generate readable summary describe functionality program know source code summarization . task , learn code representation model pairwise relationship code token capture long - range dependency crucial . learn code representation summarization , explore transformer model use self - attention mechanism show effective capture long - range dependency . work , despite approach simple , outperform state - - - art technique significant margin . perform extensive analysis ablation study reveal important finding , e.g. , absolute encoding source code token ' position hinder , relative encoding significantly improve summarization performance . code publicly available 1 facilitate future research .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 5, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
Summarization,Unsupervised Opinion Summarization as Copycat-Review Generation,"Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the ""amount of novelty"" going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (""decoder"") has direct access to the text of input reviews through the pointergenerator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review's latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.","Unsupervised Opinion Summarization as Copycat-Review Generation Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the ""amount of novelty"" going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (""decoder"") has direct access to the text of input reviews through the pointergenerator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review's latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.","unsupervised opinion summarization copycat - review generation opinion summarization task automatically create summary reflect subjective information express multiple document , product review . majority previous work focus extractive setting , i.e. , select fragment input review produce summary , let model generate novel sentence produce abstractive summary . recent progress summarization see development supervise model rely large quantity document - summary pair . training data expensive acquire , instead consider unsupervised setting , word , use summary training . define generative model review collection capitalize intuition generate new review give set review product , able control "" novelty "" go new review , equivalently , vary extent deviate input . test time , generate summary , force novelty minimal , produce text reflect consensus opinion . capture intuition define hierarchical variational autoencoder model . individual review product correspond associate stochastic latent code , review generator ( "" decoder "" ) direct access text input review pointergenerator mechanism . experiment amazon yelp dataset , set test time review latent code mean , allow model produce fluent coherent summary reflect common opinion .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 26, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Fact-based Content Weighting for Evaluating Abstractive Summarisation,"Abstractive summarisation is notoriously hard to evaluate since standard word-overlap-based metrics are biased towards specific words in the human reference. We introduce a new evaluation metric which abstracts away from the word-level and instead is based on factlevel content weighting, i.e. relating the facts of the document to the facts of the summary. We follow the assumption that a good summary will reflect all relevant facts, i.e. the ones present in the ground truth (human-generated reference summary). We confirm this hypothesis by showing that our weightings are highly correlated to human perception and compare favourably to the recent manual highlightbased metric of Hardy et al. (2019) .","Fact-based Content Weighting for Evaluating Abstractive Summarisation Abstractive summarisation is notoriously hard to evaluate since standard word-overlap-based metrics are biased towards specific words in the human reference. We introduce a new evaluation metric which abstracts away from the word-level and instead is based on factlevel content weighting, i.e. relating the facts of the document to the facts of the summary. We follow the assumption that a good summary will reflect all relevant facts, i.e. the ones present in the ground truth (human-generated reference summary). We confirm this hypothesis by showing that our weightings are highly correlated to human perception and compare favourably to the recent manual highlightbased metric of Hardy et al. (2019) .","fact - base content weighting evaluate abstractive summarisation abstractive summarisation notoriously hard evaluate standard word - overlap - base metric bias specific word human reference . introduce new evaluation metric abstract away word - level instead base factlevel content weighting , i.e. relate fact document fact summary . follow assumption good summary reflect relevant fact , i.e. one present ground truth ( human - generate reference summary ) . confirm hypothesis show weighting highly correlated human perception compare favourably recent manual highlightbase metric hardy et al . ( 2019 ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 6, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 6, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Summarization,Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization,"Sequence-to-sequence (seq2seq) network is a well-established model for text summarization task. It can learn to produce readable content; however, it falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our model statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements: 2.9% RG-1, 2.5% RG-2, 1.9% RG-L), in the healthcare domain where any range of improvement impacts patients' welfare.","Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization Sequence-to-sequence (seq2seq) network is a well-established model for text summarization task. It can learn to produce readable content; however, it falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our model statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements: 2.9% RG-1, 2.5% RG-2, 1.9% RG-L), in the healthcare domain where any range of improvement impacts patients' welfare.","attend medical ontologies : content selection clinical abstractive summarization sequence - - sequence ( seq2seq ) network - establish model text summarization task . learn produce readable content ; , fall short effectively identify key region source . paper , approach content selection problem clinical abstractive summarization augment salient ontological term summarizer . experiment publicly available clinical data set ( 107,372 report mimic - cxr , 3,366 report openi ) model statistically significantly boost state - - - art result term rouge metric ( improvement : 2.9 % rg-1 , 2.5 % rg-2 , 1.9 % rg - l ) , healthcare domain range improvement impact patient ' welfare .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 7, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,True
Summarization,Automatic Generation of Citation Texts in Scholarly Papers: A Pilot Study,"In this paper, we study the challenging problem of automatic generation of citation texts in scholarly papers. Given the context of a citing paper A and a cited paper B, the task aims to generate a short text to describe B in the given context of A. One big challenge for addressing this task is the lack of training data. Usually, explicit citation texts are easy to extract, but it is not easy to extract implicit citation texts from scholarly papers. We thus first train an implicit citation text extraction model based on BERT and leverage the model to construct a large training dataset for the citation text generation task. Then we propose and train a multi-source pointer-generator network with cross attention mechanism for citation text generation. Empirical evaluation results on a manually labeled test dataset verify the efficacy of our model. This pilot study confirms the feasibility of automatically generating citation texts in scholarly papers and the technique has the great potential to help researchers prepare their scientific papers.","Automatic Generation of Citation Texts in Scholarly Papers: A Pilot Study In this paper, we study the challenging problem of automatic generation of citation texts in scholarly papers. Given the context of a citing paper A and a cited paper B, the task aims to generate a short text to describe B in the given context of A. One big challenge for addressing this task is the lack of training data. Usually, explicit citation texts are easy to extract, but it is not easy to extract implicit citation texts from scholarly papers. We thus first train an implicit citation text extraction model based on BERT and leverage the model to construct a large training dataset for the citation text generation task. Then we propose and train a multi-source pointer-generator network with cross attention mechanism for citation text generation. Empirical evaluation results on a manually labeled test dataset verify the efficacy of our model. This pilot study confirms the feasibility of automatically generating citation texts in scholarly papers and the technique has the great potential to help researchers prepare their scientific papers.","automatic generation citation text scholarly paper : pilot study paper , study challenge problem automatic generation citation text scholarly paper . give context cite paper cite paper b , task aim generate short text describe b give context a. big challenge address task lack training datum . usually , explicit citation text easy extract , easy extract implicit citation text scholarly paper . train implicit citation text extraction model base bert leverage model construct large training dataset citation text generation task . propose train multi - source pointer - generator network cross attention mechanism citation text generation . empirical evaluation result manually label test dataset verify efficacy model . pilot study confirm feasibility automatically generate citation text scholarly paper technique great potential help researcher prepare scientific paper .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 19, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 18, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
"Syntax: Tagging, Chunking and Parsing",A Graph-based Model for Joint Chinese Word Segmentation and Dependency Parsing,"Chinese word segmentation and dependency parsing are two fundamental tasks for Chinese natural language processing. The dependency parsing is defined at the word-level. Therefore word segmentation is the precondition of dependency parsing, which makes dependency parsing suffer from error propagation and unable to directly make use of character-level pre-trained language models (such as BERT). In this paper, we propose a graph-based model to integrate Chinese word segmentation and dependency parsing. Different from previous transition-based joint models, our proposed model is more concise, which results in fewer efforts of feature engineering. Our graph-based joint model achieves better performance than previous joint models and state-of-the-art results in both Chinese word segmentation and dependency parsing. Additionally, when BERT is combined, our model can substantially reduce the performance gap of dependency parsing between joint models and gold-segmented word-based models. Our code is publicly available at https://github. com/fastnlp/JointCwsParser.","A Graph-based Model for Joint Chinese Word Segmentation and Dependency Parsing Chinese word segmentation and dependency parsing are two fundamental tasks for Chinese natural language processing. The dependency parsing is defined at the word-level. Therefore word segmentation is the precondition of dependency parsing, which makes dependency parsing suffer from error propagation and unable to directly make use of character-level pre-trained language models (such as BERT). In this paper, we propose a graph-based model to integrate Chinese word segmentation and dependency parsing. Different from previous transition-based joint models, our proposed model is more concise, which results in fewer efforts of feature engineering. Our graph-based joint model achieves better performance than previous joint models and state-of-the-art results in both Chinese word segmentation and dependency parsing. Additionally, when BERT is combined, our model can substantially reduce the performance gap of dependency parsing between joint models and gold-segmented word-based models. Our code is publicly available at https://github. com/fastnlp/JointCwsParser.","graph - base model joint chinese word segmentation dependency parsing chinese word segmentation dependency parsing fundamental task chinese natural language processing . dependency parsing define word - level . word segmentation precondition dependency parsing , make dependency parsing suffer error propagation unable directly use character - level pre - trained language model ( bert ) . paper , propose graph - base model integrate chinese word segmentation dependency parsing . different previous transition - base joint model , propose model concise , result few effort feature engineering . graph - base joint model achieve well performance previous joint model state - - - art result chinese word segmentation dependency parsing . additionally , bert combine , model substantially reduce performance gap dependency parsing joint model gold - segment word - base model . code publicly available https://github . com / fastnlp / jointcwsparser .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 8, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 13, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 8, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 25, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Abstract Syntax as Interlingua: Scaling Up the Grammatical Framework from Controlled Languages to Robust Pipelines,"syntax is an interlingual representation used in compilers. Grammatical Framework (GF) applies the abstract syntax idea to natural languages. The development of GF started in 1998, first as a tool for controlled language implementations, where it has gained an established position in both academic and commercial projects. GF provides grammar resources for over 40 languages, enabling accurate generation and translation, as well as grammar engineering Submission","Abstract Syntax as Interlingua: Scaling Up the Grammatical Framework from Controlled Languages to Robust Pipelines syntax is an interlingual representation used in compilers. Grammatical Framework (GF) applies the abstract syntax idea to natural languages. The development of GF started in 1998, first as a tool for controlled language implementations, where it has gained an established position in both academic and commercial projects. GF provides grammar resources for over 40 languages, enabling accurate generation and translation, as well as grammar engineering Submission","abstract syntax interlingua : scale grammatical framework control language robust pipelines syntax interlingual representation compiler . grammatical framework ( gf ) apply abstract syntax idea natural language . development gf start 1998 , tool control language implementation , gain establish position academic commercial project . gf provide grammar resource 40 language , enable accurate generation translation , grammar engineering submiss","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}",Theory and Formalism in NLP (Linguistic and Mathematical),False
"Syntax: Tagging, Chunking and Parsing",An Empirical Comparison of Unsupervised Constituency Parsing Methods,"Unsupervised constituency parsing aims to learn a constituency parser from a training corpus without parse tree annotations. While many methods have been proposed to tackle the problem, including statistical and neural methods, their experimental results are often not directly comparable due to discrepancies in datasets, data preprocessing, lexicalization, and evaluation metrics. In this paper, we first examine experimental settings used in previous work and propose to standardize the settings for better comparability between methods. We then empirically compare several existing methods, including decade-old and newly proposed ones, under the standardized settings on English and Japanese, two languages with different branching tendencies. We find that recent models do not show a clear advantage over decade-old models in our experiments. We hope our work can provide new insights into existing methods and facilitate future empirical evaluation of unsupervised constituency parsing.","An Empirical Comparison of Unsupervised Constituency Parsing Methods Unsupervised constituency parsing aims to learn a constituency parser from a training corpus without parse tree annotations. While many methods have been proposed to tackle the problem, including statistical and neural methods, their experimental results are often not directly comparable due to discrepancies in datasets, data preprocessing, lexicalization, and evaluation metrics. In this paper, we first examine experimental settings used in previous work and propose to standardize the settings for better comparability between methods. We then empirically compare several existing methods, including decade-old and newly proposed ones, under the standardized settings on English and Japanese, two languages with different branching tendencies. We find that recent models do not show a clear advantage over decade-old models in our experiments. We hope our work can provide new insights into existing methods and facilitate future empirical evaluation of unsupervised constituency parsing.","empirical comparison unsupervised constituency parsing methods unsupervised constituency parsing aim learn constituency parser training corpus parse tree annotation . method propose tackle problem , include statistical neural method , experimental result directly comparable discrepancy dataset , data preprocessing , lexicalization , evaluation metric . paper , examine experimental setting previous work propose standardize setting well comparability method . empirically compare exist method , include decade - old newly propose one , standardize setting english japanese , language different branch tendency . find recent model clear advantage decade - old model experiment . hope work provide new insight exist method facilitate future empirical evaluation unsupervised constituency parsing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 12, 'System Demonstrations': 0, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing","Exact yet Efficient Graph Parsing, Bi-directional Locality and the Constructivist Hypothesis","A key problem in processing graph-based meaning representations is graph parsing, i.e. computing all possible derivations of a given graph according to a (competence) grammar. We demonstrate, for the first time, that exact graph parsing can be efficient for large graphs and with large Hyperedge Replacement Grammars (HRGs). The advance is achieved by exploiting locality as terminal edge-adjacency in HRG rules. In particular, we highlight the importance of 1) a terminal edge-first parsing strategy, 2) a categorization of a subclass of HRG, i.e. what we call Weakly Regular Graph Grammar, and 3) distributing argumentstructures to both lexical and phrasal rules.","Exact yet Efficient Graph Parsing, Bi-directional Locality and the Constructivist Hypothesis A key problem in processing graph-based meaning representations is graph parsing, i.e. computing all possible derivations of a given graph according to a (competence) grammar. We demonstrate, for the first time, that exact graph parsing can be efficient for large graphs and with large Hyperedge Replacement Grammars (HRGs). The advance is achieved by exploiting locality as terminal edge-adjacency in HRG rules. In particular, we highlight the importance of 1) a terminal edge-first parsing strategy, 2) a categorization of a subclass of HRG, i.e. what we call Weakly Regular Graph Grammar, and 3) distributing argumentstructures to both lexical and phrasal rules.","exact efficient graph parsing , bi - directional locality constructivist hypothesis key problem process graph - base meaning representation graph parsing , i.e. compute possible derivation give graph accord ( competence ) grammar . demonstrate , time , exact graph parsing efficient large graph large hyperedge replacement grammars ( hrgs ) . advance achieve exploit locality terminal edge - adjacency hrg rule . particular , highlight importance 1 ) terminal edge - parsing strategy , 2 ) categorization subclass hrg , i.e. weakly regular graph grammar , 3 ) distribute argumentstructure lexical phrasal rule .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 4, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
"Syntax: Tagging, Chunking and Parsing",Do Neural Language Models Show Preferences for Syntactic Formalisms?,"Recent work on the interpretability of deep neural language models has concluded that many properties of natural language syntax are encoded in their representational spaces. However, such studies often suffer from limited scope by focusing on a single language and a single linguistic formalism. In this study, we aim to investigate the extent to which the semblance of syntactic structure captured by language models adheres to a surface-syntactic or deep syntactic style of analysis, and whether the patterns are consistent across different languages. We apply a probe for extracting directed dependency trees to BERT and ELMo models trained on 13 different languages, probing for two different syntactic annotation styles: Universal Dependencies (UD), prioritizing deep syntactic relations, and Surface-Syntactic Universal Dependencies (SUD), focusing on surface structure. We find that both models exhibit a preference for UD over SUD -with interesting variations across languages and layers -and that the strength of this preference is correlated with differences in tree shape.","Do Neural Language Models Show Preferences for Syntactic Formalisms? Recent work on the interpretability of deep neural language models has concluded that many properties of natural language syntax are encoded in their representational spaces. However, such studies often suffer from limited scope by focusing on a single language and a single linguistic formalism. In this study, we aim to investigate the extent to which the semblance of syntactic structure captured by language models adheres to a surface-syntactic or deep syntactic style of analysis, and whether the patterns are consistent across different languages. We apply a probe for extracting directed dependency trees to BERT and ELMo models trained on 13 different languages, probing for two different syntactic annotation styles: Universal Dependencies (UD), prioritizing deep syntactic relations, and Surface-Syntactic Universal Dependencies (SUD), focusing on surface structure. We find that both models exhibit a preference for UD over SUD -with interesting variations across languages and layers -and that the strength of this preference is correlated with differences in tree shape.","neural language model preference syntactic formalism ? recent work interpretability deep neural language model conclude property natural language syntax encode representational space . , study suffer limit scope focus single language single linguistic formalism . study , aim investigate extent semblance syntactic structure capture language model adhere surface - syntactic deep syntactic style analysis , pattern consistent different language . apply probe extract direct dependency tree bert elmo model train 13 different language , probe different syntactic annotation style : universal dependencies ( ud ) , prioritize deep syntactic relation , surface - syntactic universal dependencies ( sud ) , focus surface structure . find model exhibit preference ud sud -with interesting variation language layer -and strength preference correlate difference tree shape .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 7, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 3}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",False
"Syntax: Tagging, Chunking and Parsing",Enriched In-Order Linearization for Faster Sequence-to-Sequence Constituent Parsing,"Sequence-to-sequence constituent parsing requires a linearization to represent trees as sequences. Top-down tree linearizations, which can be based on brackets or shift-reduce actions, have achieved the best accuracy to date. In this paper, we show that these results can be improved by using an inorder linearization instead. Based on this observation, we implement an enriched inorder shift-reduce linearization inspired by Vinyals et al. ( 2015 )'s approach, achieving the best accuracy to date on the English PTB dataset among fully-supervised single-model sequence-to-sequence constituent parsers. Finally, we apply deterministic attention mechanisms to match the speed of state-of-theart transition-based parsers, thus showing that sequence-to-sequence models can match them, not only in accuracy, but also in speed.","Enriched In-Order Linearization for Faster Sequence-to-Sequence Constituent Parsing Sequence-to-sequence constituent parsing requires a linearization to represent trees as sequences. Top-down tree linearizations, which can be based on brackets or shift-reduce actions, have achieved the best accuracy to date. In this paper, we show that these results can be improved by using an inorder linearization instead. Based on this observation, we implement an enriched inorder shift-reduce linearization inspired by Vinyals et al. ( 2015 )'s approach, achieving the best accuracy to date on the English PTB dataset among fully-supervised single-model sequence-to-sequence constituent parsers. Finally, we apply deterministic attention mechanisms to match the speed of state-of-theart transition-based parsers, thus showing that sequence-to-sequence models can match them, not only in accuracy, but also in speed.","enriched - order linearization fast sequence - - sequence constituent parsing sequence - - sequence constituent parsing require linearization represent tree sequence . - tree linearization , base bracket shift - reduce action , achieve good accuracy date . paper , result improve inorder linearization instead . base observation , implement enriched inorder shift - reduce linearization inspire vinyals et al . ( 2015 ) approach , achieve good accuracy date english ptb dataset fully - supervise single - model sequence - - sequence constituent parser . finally , apply deterministic attention mechanism match speed state - - theart transition - base parser , show sequence - - sequence model match , accuracy , speed .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 11, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Max-Margin Incremental CCG Parsing,"Incremental syntactic parsing has been an active research area both for cognitive scientists trying to model human sentence processing and for NLP researchers attempting to combine incremental parsing with language modelling for ASR and MT. Most effort has been directed at designing the right transition mechanism, but less has been done to answer the question of what a probabilistic model for those transition parsers should look like. A very incremental transition mechanism of a recently proposed CCG parser when trained in straightforward locally normalised discriminative fashion produces very bad results on English CCGbank. We identify three biases as the causes of this problem: label bias, exposure bias and imbalanced probabilities bias. While known techniques for tackling these biases improve results, they still do not make the parser state of the art. Instead, we tackle all of these three biases at the same time using an improved version of beam search optimisation that minimises all beam search violations instead of minimising only the biggest violation. The new incremental parser gives better results than all previously published incremental CCG parsers, and outperforms even some widely used non-incremental CCG parsers.","Max-Margin Incremental CCG Parsing Incremental syntactic parsing has been an active research area both for cognitive scientists trying to model human sentence processing and for NLP researchers attempting to combine incremental parsing with language modelling for ASR and MT. Most effort has been directed at designing the right transition mechanism, but less has been done to answer the question of what a probabilistic model for those transition parsers should look like. A very incremental transition mechanism of a recently proposed CCG parser when trained in straightforward locally normalised discriminative fashion produces very bad results on English CCGbank. We identify three biases as the causes of this problem: label bias, exposure bias and imbalanced probabilities bias. While known techniques for tackling these biases improve results, they still do not make the parser state of the art. Instead, we tackle all of these three biases at the same time using an improved version of beam search optimisation that minimises all beam search violations instead of minimising only the biggest violation. The new incremental parser gives better results than all previously published incremental CCG parsers, and outperforms even some widely used non-incremental CCG parsers.","max - margin incremental ccg parsing incremental syntactic parsing active research area cognitive scientist try model human sentence processing nlp researcher attempt combine incremental parsing language modelling asr mt . effort direct design right transition mechanism , answer question probabilistic model transition parser look like . incremental transition mechanism recently propose ccg parser train straightforward locally normalised discriminative fashion produce bad result english ccgbank . identify bias cause problem : label bias , exposure bias imbalanced probability bias . know technique tackle bias improve result , parser state art . instead , tackle bias time improved version beam search optimisation minimise beam search violation instead minimise big violation . new incremental parser give well result previously publish incremental ccg parser , outperform widely non - incremental ccg parser .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 6, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 2, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 16, 'System Demonstrations': 4, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Efficient Second-Order TreeCRF for Neural Dependency Parsing,"In the deep learning (DL) era, parsing models are extremely simplified with little hurt on performance, thanks to the remarkable capability of multi-layer BiLSTMs in context representation. As the most popular graphbased dependency parser due to its high efficiency and performance, the biaffine parser directly scores single dependencies under the arc-factorization assumption, and adopts a very simple local token-wise cross-entropy training loss. This paper for the first time presents a second-order TreeCRF extension to the biaffine parser. For a long time, the complexity and inefficiency of the inside-outside algorithm hinder the popularity of TreeCRF. To address this issue, we propose an effective way to batchify the inside and Viterbi algorithms for direct large matrix operation on GPUs, and to avoid the complex outside algorithm via efficient back-propagation. Experiments and analysis on 27 datasets from 13 languages clearly show that techniques developed before the DL era, such as structural learning (global TreeCRF loss) and high-order modeling are still useful, and can further boost parsing performance over the state-of-the-art biaffine parser, especially for partially annotated training data. We release our code at https: //github.com/yzhangcs/crfpar.","Efficient Second-Order TreeCRF for Neural Dependency Parsing In the deep learning (DL) era, parsing models are extremely simplified with little hurt on performance, thanks to the remarkable capability of multi-layer BiLSTMs in context representation. As the most popular graphbased dependency parser due to its high efficiency and performance, the biaffine parser directly scores single dependencies under the arc-factorization assumption, and adopts a very simple local token-wise cross-entropy training loss. This paper for the first time presents a second-order TreeCRF extension to the biaffine parser. For a long time, the complexity and inefficiency of the inside-outside algorithm hinder the popularity of TreeCRF. To address this issue, we propose an effective way to batchify the inside and Viterbi algorithms for direct large matrix operation on GPUs, and to avoid the complex outside algorithm via efficient back-propagation. Experiments and analysis on 27 datasets from 13 languages clearly show that techniques developed before the DL era, such as structural learning (global TreeCRF loss) and high-order modeling are still useful, and can further boost parsing performance over the state-of-the-art biaffine parser, especially for partially annotated training data. We release our code at https: //github.com/yzhangcs/crfpar.","efficient second - order treecrf neural dependency parsing deep learning ( dl ) era , parse model extremely simplified little hurt performance , thank remarkable capability multi - layer bilstm context representation . popular graphbased dependency parser high efficiency performance , biaffine parser directly score single dependency arc - factorization assumption , adopt simple local token - wise cross - entropy training loss . paper time present second - order treecrf extension biaffine parser . long time , complexity inefficiency inside - outside algorithm hinder popularity treecrf . address issue , propose effective way batchify inside viterbi algorithm direct large matrix operation gpu , avoid complex outside algorithm efficient - propagation . experiment analysis 27 dataset 13 language clearly technique develop dl era , structural learning ( global treecrf loss ) high - order modeling useful , boost parsing performance state - - - art biaffine parser , especially partially annotate training datum . release code https : //github.com / yzhangcs / crfpar .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 14, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Tetra-Tagging: Word-Synchronous Parsing with Linear-Time Inference,"We present a constituency parsing algorithm that, like a supertagger, works by assigning labels to each word in a sentence. In order to maximally leverage current neural architectures, the model scores each word's tags in parallel, with minimal task-specific structure. After scoring, a left-to-right reconciliation phase extracts a tree in (empirically) linear time. Our parser achieves 95.4 F1 on the WSJ test set while also achieving substantial speedups compared to current state-of-the-art parsers with comparable accuracies.","Tetra-Tagging: Word-Synchronous Parsing with Linear-Time Inference We present a constituency parsing algorithm that, like a supertagger, works by assigning labels to each word in a sentence. In order to maximally leverage current neural architectures, the model scores each word's tags in parallel, with minimal task-specific structure. After scoring, a left-to-right reconciliation phase extracts a tree in (empirically) linear time. Our parser achieves 95.4 F1 on the WSJ test set while also achieving substantial speedups compared to current state-of-the-art parsers with comparable accuracies.","tetra - tagging : word - synchronous parsing linear - time inference present constituency parsing algorithm , like supertagger , work assign label word sentence . order maximally leverage current neural architecture , model score word tag parallel , minimal task - specific structure . score , left - - right reconciliation phase extract tree ( empirically ) linear time . parser achieve 95.4 f1 wsj test set achieve substantial speedup compare current state - - - art parser comparable accuracy .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Neural Reranking for Dependency Parsing: An Evaluation,"Recent work has shown that neural rerankers can improve results for dependency parsing over the top k trees produced by a base parser. However, all neural rerankers so far have been evaluated on English and Chinese only, both languages with a configurational word order and poor morphology. In the paper, we re-assess the potential of successful neural reranking models from the literature on English and on two morphologically rich(er) languages, German and Czech. In addition, we introduce a new variation of a discriminative reranker based on graph convolutional networks (GCNs). We show that the GCN not only outperforms previous models on English but is the only model that is able to improve results over the baselines on German and Czech. We explain the differences in reranking performance based on an analysis of a) the gold tree ratio and b) the variety in the k-best lists.","Neural Reranking for Dependency Parsing: An Evaluation Recent work has shown that neural rerankers can improve results for dependency parsing over the top k trees produced by a base parser. However, all neural rerankers so far have been evaluated on English and Chinese only, both languages with a configurational word order and poor morphology. In the paper, we re-assess the potential of successful neural reranking models from the literature on English and on two morphologically rich(er) languages, German and Czech. In addition, we introduce a new variation of a discriminative reranker based on graph convolutional networks (GCNs). We show that the GCN not only outperforms previous models on English but is the only model that is able to improve results over the baselines on German and Czech. We explain the differences in reranking performance based on an analysis of a) the gold tree ratio and b) the variety in the k-best lists.","neural reranking dependency parsing : evaluation recent work show neural reranker improve result dependency parsing k tree produce base parser . , neural reranker far evaluate english chinese , language configurational word order poor morphology . paper , - assess potential successful neural reranking model literature english morphologically rich(er ) language , german czech . addition , introduce new variation discriminative reranker base graph convolutional network ( gcns ) . gcn outperform previous model english model able improve result baseline german czech . explain difference reranking performance base analysis ) gold tree ratio b ) variety k - good list .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 9, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing","Extracting Headless MWEs from Dependency Parse Trees: Parsing, Tagging, and Joint Modeling Approaches","An interesting and frequent type of multiword expression (MWE) is the headless MWE, for which there are no true internal syntactic dominance relations; examples include many named entities (""Wells Fargo"") and dates (""July 5, 2020"") as well as certain productive constructions (""blow for blow"", ""day after day""). Despite their special status and prevalence, current dependency-annotation schemes require treating such flat structures as if they had internal syntactic heads, and most current parsers handle them in the same fashion as headed constructions. Meanwhile, outside the context of parsing, taggers are typically used for identifying MWEs, but taggers might benefit from structural information. We empirically compare these two common strategies-parsing and tagging-for predicting flat MWEs. Additionally, we propose an efficient joint decoding algorithm that combines scores from both strategies. Experimental results on the MWE-Aware English Dependency Corpus and on six non-English dependency treebanks with frequent flat structures show that: (1) tagging is more accurate than parsing for identifying flat-structure MWEs, (2) our joint decoder reconciles the two different views and, for non-BERT features, leads to higher accuracies, and (3) most of the gains result from feature sharing between the parsers and taggers.","Extracting Headless MWEs from Dependency Parse Trees: Parsing, Tagging, and Joint Modeling Approaches An interesting and frequent type of multiword expression (MWE) is the headless MWE, for which there are no true internal syntactic dominance relations; examples include many named entities (""Wells Fargo"") and dates (""July 5, 2020"") as well as certain productive constructions (""blow for blow"", ""day after day""). Despite their special status and prevalence, current dependency-annotation schemes require treating such flat structures as if they had internal syntactic heads, and most current parsers handle them in the same fashion as headed constructions. Meanwhile, outside the context of parsing, taggers are typically used for identifying MWEs, but taggers might benefit from structural information. We empirically compare these two common strategies-parsing and tagging-for predicting flat MWEs. Additionally, we propose an efficient joint decoding algorithm that combines scores from both strategies. Experimental results on the MWE-Aware English Dependency Corpus and on six non-English dependency treebanks with frequent flat structures show that: (1) tagging is more accurate than parsing for identifying flat-structure MWEs, (2) our joint decoder reconciles the two different views and, for non-BERT features, leads to higher accuracies, and (3) most of the gains result from feature sharing between the parsers and taggers.","extract headless mwe dependency parse tree : parsing , tagging , joint modeling approach interesting frequent type multiword expression ( mwe ) headless mwe , true internal syntactic dominance relation ; example include name entity ( "" wells fargo "" ) date ( "" july 5 , 2020 "" ) certain productive construction ( "" blow blow "" , "" day day "" ) . despite special status prevalence , current dependency - annotation scheme require treat flat structure internal syntactic head , current parser handle fashion head construction . , outside context parsing , tagger typically identify mwe , tagger benefit structural information . empirically compare common strategy - parsing tagging - predict flat mwe . additionally , propose efficient joint decoding algorithm combine score strategy . experimental result mwe - aware english dependency corpus non - english dependency treebank frequent flat structure : ( 1 ) tagging accurate parse identify flat - structure mwe , ( 2 ) joint decoder reconcile different view , non - bert feature , lead high accuracy , ( 3 ) gain result feature sharing parser tagger .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 18, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",SeqVAT: Virtual Adversarial Training for Semi-Supervised Sequence Labeling,"Virtual adversarial training (VAT) is a powerful technique to improve model robustness in both supervised and semi-supervised settings. It is effective and can be easily adopted on lots of image classification and text classification tasks. However, its benefits to sequence labeling tasks such as named entity recognition (NER) have not been shown as significant, mostly, because the previous approach can not combine VAT with the conditional random field (CRF). CRF can significantly boost accuracy for sequence models by putting constraints on label transitions, which makes it an essential component in most state-of-theart sequence labeling model architectures. In this paper, we propose SeqVAT, a method which naturally applies VAT to sequence labeling models with CRF. Empirical studies show that SeqVAT not only significantly improves the sequence labeling performance over baselines under supervised settings, but also outperforms state-of-the-art approaches under semisupervised settings.","SeqVAT: Virtual Adversarial Training for Semi-Supervised Sequence Labeling Virtual adversarial training (VAT) is a powerful technique to improve model robustness in both supervised and semi-supervised settings. It is effective and can be easily adopted on lots of image classification and text classification tasks. However, its benefits to sequence labeling tasks such as named entity recognition (NER) have not been shown as significant, mostly, because the previous approach can not combine VAT with the conditional random field (CRF). CRF can significantly boost accuracy for sequence models by putting constraints on label transitions, which makes it an essential component in most state-of-theart sequence labeling model architectures. In this paper, we propose SeqVAT, a method which naturally applies VAT to sequence labeling models with CRF. Empirical studies show that SeqVAT not only significantly improves the sequence labeling performance over baselines under supervised settings, but also outperforms state-of-the-art approaches under semisupervised settings.","seqvat : virtual adversarial training semi - supervised sequence labeling virtual adversarial training ( vat ) powerful technique improve model robustness supervised semi - supervised setting . effective easily adopt lot image classification text classification task . , benefit sequence labeling task name entity recognition ( ner ) show significant , , previous approach combine vat conditional random field ( crf ) . crf significantly boost accuracy sequence model put constraint label transition , make essential component state - - theart sequence labeling model architecture . paper , propose seqvat , method naturally apply vat sequence labeling model crf . empirical study seqvat significantly improve sequence labeling performance baseline supervise setting , outperform state - - - art approach semisupervised setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
"Syntax: Tagging, Chunking and Parsing",Revisiting Higher-Order Dependency Parsers,"Neural encoders have allowed dependency parsers to shift from higher-order structured models to simpler first-order ones, making decoding faster and still achieving better accuracy than non-neural parsers. This has led to a belief that neural encoders can implicitly encode structural constraints, such as siblings and grandparents in a tree. We tested this hypothesis and found that neural parsers may benefit from higher-order features, even when employing a powerful pre-trained encoder, such as BERT. While the gains of higher-order features are small in the presence of a powerful encoder, they are consistent for long-range dependencies and long sentences. In particular, higher-order models are more accurate on full sentence parses and on the exact match of modifier lists, indicating that they deal better with larger, more complex structures.","Revisiting Higher-Order Dependency Parsers Neural encoders have allowed dependency parsers to shift from higher-order structured models to simpler first-order ones, making decoding faster and still achieving better accuracy than non-neural parsers. This has led to a belief that neural encoders can implicitly encode structural constraints, such as siblings and grandparents in a tree. We tested this hypothesis and found that neural parsers may benefit from higher-order features, even when employing a powerful pre-trained encoder, such as BERT. While the gains of higher-order features are small in the presence of a powerful encoder, they are consistent for long-range dependencies and long sentences. In particular, higher-order models are more accurate on full sentence parses and on the exact match of modifier lists, indicating that they deal better with larger, more complex structures.","revisit high - order dependency parser neural encoder allow dependency parser shift high - order structure model simple - order one , make decoding fast achieve well accuracy non - neural parser . lead belief neural encoder implicitly encode structural constraint , sibling grandparent tree . test hypothesis find neural parser benefit high - order feature , employ powerful pre - trained encoder , bert . gain high - order feature small presence powerful encoder , consistent long - range dependency long sentence . particular , high - order model accurate sentence parse exact match modifier list , indicate deal well large , complex structure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 8, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Structure-Level Knowledge Distillation For Multilingual Sequence Labeling,"Multilingual sequence labeling is a task of predicting label sequences using a single unified model for multiple languages. Compared with relying on multiple monolingual models, using a multilingual model has the benefit of a smaller model size, easier in online serving, and generalizability to low-resource languages. However, current multilingual models still underperform individual monolingual models significantly due to model capacity limitations. In this paper, we propose to reduce the gap between monolingual models and the unified multilingual model by distilling the structural knowledge of several monolingual models (teachers) to the unified multilingual model (student). We propose two novel KD methods based on structure-level information: (1) approximately minimizes the distance between the student's and the teachers' structurelevel probability distributions, (2) aggregates the structure-level knowledge to local distributions and minimizes the distance between two local probability distributions. Our experiments on 4 multilingual tasks with 25 datasets show that our approaches outperform several strong baselines and have stronger zero-shot generalizability than both the baseline model and teacher models.","Structure-Level Knowledge Distillation For Multilingual Sequence Labeling Multilingual sequence labeling is a task of predicting label sequences using a single unified model for multiple languages. Compared with relying on multiple monolingual models, using a multilingual model has the benefit of a smaller model size, easier in online serving, and generalizability to low-resource languages. However, current multilingual models still underperform individual monolingual models significantly due to model capacity limitations. In this paper, we propose to reduce the gap between monolingual models and the unified multilingual model by distilling the structural knowledge of several monolingual models (teachers) to the unified multilingual model (student). We propose two novel KD methods based on structure-level information: (1) approximately minimizes the distance between the student's and the teachers' structurelevel probability distributions, (2) aggregates the structure-level knowledge to local distributions and minimizes the distance between two local probability distributions. Our experiments on 4 multilingual tasks with 25 datasets show that our approaches outperform several strong baselines and have stronger zero-shot generalizability than both the baseline model and teacher models.","structure - level knowledge distillation multilingual sequence labeling multilingual sequence labeling task predict label sequence single unify model multiple language . compare rely multiple monolingual model , multilingual model benefit small model size , easy online serving , generalizability low - resource language . , current multilingual model underperform individual monolingual model significantly model capacity limitation . paper , propose reduce gap monolingual model unify multilingual model distil structural knowledge monolingual model ( teacher ) unify multilingual model ( student ) . propose novel kd method base structure - level information : ( 1 ) approximately minimize distance student teacher ' structurelevel probability distribution , ( 2 ) aggregate structure - level knowledge local distribution minimize distance local probability distribution . experiment 4 multilingual task 25 dataset approach outperform strong baseline strong zero - shot generalizability baseline model teacher model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 3, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,False
"Syntax: Tagging, Chunking and Parsing",Efficient Constituency Parsing by Pointing,"We propose a novel constituency parsing model that casts the parsing problem into a series of pointing tasks. Specifically, our model estimates the likelihood of a span being a legitimate tree constituent via the pointing score corresponding to the boundary words of the span. Our parsing model supports efficient top-down decoding and our learning objective is able to enforce structural consistency without resorting to the expensive CKY inference. The experiments on the standard English Penn Treebank parsing task show that our method achieves 92.78 F1 without using pre-trained models, which is higher than all the existing methods with similar time complexity. Using pre-trained BERT, our model achieves 95.48 F1, which is competitive with the state-of-theart while being faster. Our approach also establishes new state-of-the-art in Basque and Swedish in the SPMRL shared tasks on multilingual constituency parsing.","Efficient Constituency Parsing by Pointing We propose a novel constituency parsing model that casts the parsing problem into a series of pointing tasks. Specifically, our model estimates the likelihood of a span being a legitimate tree constituent via the pointing score corresponding to the boundary words of the span. Our parsing model supports efficient top-down decoding and our learning objective is able to enforce structural consistency without resorting to the expensive CKY inference. The experiments on the standard English Penn Treebank parsing task show that our method achieves 92.78 F1 without using pre-trained models, which is higher than all the existing methods with similar time complexity. Using pre-trained BERT, our model achieves 95.48 F1, which is competitive with the state-of-theart while being faster. Our approach also establishes new state-of-the-art in Basque and Swedish in the SPMRL shared tasks on multilingual constituency parsing.","efficient constituency parsing point propose novel constituency parsing model cast parsing problem series pointing task . specifically , model estimate likelihood span legitimate tree constituent point score correspond boundary word span . parsing model support efficient - decoding learning objective able enforce structural consistency resort expensive cky inference . experiment standard english penn treebank parsing task method achieve 92.78 f1 pre - trained model , high exist method similar time complexity . pre - trained bert , model achieve 95.48 f1 , competitive state - - theart fast . approach establish new state - - - art basque swedish spmrl share task multilingual constituency parsing .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 6, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 14, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",A Span-based Linearization for Constituent Trees,"We propose a novel linearization of a constituent tree, together with a new locally normalized model. For each split point in a sentence, our model computes the normalizer on all spans ending with that split point, and then predicts a tree span from them. Compared with global models, our model is fast and parallelizable. Different from previous local models, our linearization method is tied on the spans directly and considers more local features when performing span prediction, which is more interpretable and effective. Experiments on PTB (95.8 F1) and CTB (92.1 F1) show that our model significantly outperforms existing local models and efficiently achieves competitive results with global models.","A Span-based Linearization for Constituent Trees We propose a novel linearization of a constituent tree, together with a new locally normalized model. For each split point in a sentence, our model computes the normalizer on all spans ending with that split point, and then predicts a tree span from them. Compared with global models, our model is fast and parallelizable. Different from previous local models, our linearization method is tied on the spans directly and considers more local features when performing span prediction, which is more interpretable and effective. Experiments on PTB (95.8 F1) and CTB (92.1 F1) show that our model significantly outperforms existing local models and efficiently achieves competitive results with global models.","span - base linearization constituent tree propose novel linearization constituent tree , new locally normalize model . split point sentence , model compute normalizer span end split point , predict tree span . compare global model , model fast parallelizable . different previous local model , linearization method tie span directly consider local feature perform span prediction , interpretable effective . experiment ptb ( 95.8 f1 ) ctb ( 92.1 f1 ) model significantly outperform existing local model efficiently achieve competitive result global model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",True
"Syntax: Tagging, Chunking and Parsing",Representations of Syntax [MASK] Useful: Effects of Constituency and Dependency Structure in Recursive LSTMs,"Sequence-based neural networks show significant sensitivity to syntactic structure, but they still perform less well on syntactic tasks than tree-based networks. Such tree-based networks can be provided with a constituency parse, a dependency parse, or both. We evaluate which of these two representational schemes more effectively introduces biases for syntactic structure that increase performance on the subject-verb agreement prediction task. We find that a constituency-based network generalizes more robustly than a dependencybased one, and that combining the two types of structure does not yield further improvement. Finally, we show that the syntactic robustness of sequential models can be substantially improved by fine-tuning on a small amount of constructed data, suggesting that data augmentation is a viable alternative to explicit constituency structure for imparting the syntactic biases that sequential models are lacking.","Representations of Syntax [MASK] Useful: Effects of Constituency and Dependency Structure in Recursive LSTMs Sequence-based neural networks show significant sensitivity to syntactic structure, but they still perform less well on syntactic tasks than tree-based networks. Such tree-based networks can be provided with a constituency parse, a dependency parse, or both. We evaluate which of these two representational schemes more effectively introduces biases for syntactic structure that increase performance on the subject-verb agreement prediction task. We find that a constituency-based network generalizes more robustly than a dependencybased one, and that combining the two types of structure does not yield further improvement. Finally, we show that the syntactic robustness of sequential models can be substantially improved by fine-tuning on a small amount of constructed data, suggesting that data augmentation is a viable alternative to explicit constituency structure for imparting the syntactic biases that sequential models are lacking.","representation syntax [ mask ] useful : effect constituency dependency structure recursive lstms sequence - base neural network significant sensitivity syntactic structure , perform syntactic task tree - base network . tree - base network provide constituency parse , dependency parse , . evaluate representational scheme effectively introduce bias syntactic structure increase performance subject - verb agreement prediction task . find constituency - base network generalize robustly dependencybase , combine type structure yield improvement . finally , syntactic robustness sequential model substantially improve fine - tune small construct datum , suggest data augmentation viable alternative explicit constituency structure impart syntactic bias sequential model lack .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 5, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 9, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Syntax: Tagging, Chunking and Parsing",True
Theme,"To Test Machine Comprehension, Start by Defining Comprehension","Many tasks aim to measure MACHINE READ-ING COMPREHENSION (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key contributions. First, we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehension-a TEM-PLATE OF UNDERSTANDING-for a widely useful class of texts, namely short narratives. We then conduct an experiment that strongly suggests existing systems are not up to the task of narrative understanding as we define it.","To Test Machine Comprehension, Start by Defining Comprehension Many tasks aim to measure MACHINE READ-ING COMPREHENSION (MRC), often focusing on question types presumed to be difficult. Rarely, however, do task designers start by considering what systems should in fact comprehend. In this paper we make two key contributions. First, we argue that existing approaches do not adequately define comprehension; they are too unsystematic about what content is tested. Second, we present a detailed definition of comprehension-a TEM-PLATE OF UNDERSTANDING-for a widely useful class of texts, namely short narratives. We then conduct an experiment that strongly suggests existing systems are not up to the task of narrative understanding as we define it.","test machine comprehension , start define comprehension task aim measure machine read - ing comprehension ( mrc ) , focus question type presume difficult . rarely , , task designer start consider system fact comprehend . paper key contribution . , argue exist approach adequately define comprehension ; unsystematic content test . second , present detailed definition comprehension - tem - plate understanding - widely useful class text , short narrative . conduct experiment strongly suggest exist system task narrative understanding define .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 6, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Theme,The State and Fate of Linguistic Diversity and Inclusion in the NLP World,"Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the ""language agnostic"" status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.","The State and Fate of Linguistic Diversity and Inclusion in the NLP World Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the ""language agnostic"" status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.","state fate linguistic diversity inclusion nlp world language technology contribute promote multilingualism linguistic diversity world . , small number 7000 language world represent rapidly evolve language technology application . paper look relation type language , resource , representation nlp conference understand trajectory different language follow time . quantitative investigation underline disparity language , especially term resource , call question "" language agnostic "" status current model system . paper , attempt convince acl community prioritise resolution predicament highlight , language leave .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,"Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly","Building on Petroni et al. ( 2019 ), we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We find that PLMs do not distinguish between negated (""Birds cannot [MASK]"") and non-negated (""Birds can [MASK]"") cloze questions. (2) Mispriming. Inspired by priming methods in human psychology, we add ""misprimes"" to cloze questions (""Talk? Birds can [MASK]""). We find that PLMs are easily distracted by misprimes. These results suggest that PLMs still have a long way to go to adequately learn human-like factual knowledge.","Negated and Misprimed Probes for Pretrained Language Models: Birds Can Talk, But Cannot Fly Building on Petroni et al. ( 2019 ), we propose two new probing tasks analyzing factual knowledge stored in Pretrained Language Models (PLMs). (1) Negation. We find that PLMs do not distinguish between negated (""Birds cannot [MASK]"") and non-negated (""Birds can [MASK]"") cloze questions. (2) Mispriming. Inspired by priming methods in human psychology, we add ""misprimes"" to cloze questions (""Talk? Birds can [MASK]""). We find that PLMs are easily distracted by misprimes. These results suggest that PLMs still have a long way to go to adequately learn human-like factual knowledge.","negate misprime probe pretrained language model : bird talk , fly build petroni et al . ( 2019 ) , propose new probe task analyze factual knowledge store pretrained language models ( plms ) . ( 1 ) negation . find plms distinguish negated ( "" bird [ mask ] "" ) non - negated ( "" bird [ mask ] "" ) cloze question . ( 2 ) mispriming . inspire priming method human psychology , add "" misprime "" cloze question ( "" talk ? bird [ mask ] "" ) . find plms easily distract misprime . result suggest plms long way adequately learn human - like factual knowledge .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 2, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Interpretability and Analysis of Models for NLP,False
Theme,Intermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work?,"While pretrained models such as BERT have shown large gains across natural language understanding tasks, their performance can be improved by further training the model on a data-rich intermediate task, before fine-tuning it on a target task. However, it is still poorly understood when and why intermediate-task training is beneficial for a given target task. To investigate this, we perform a large-scale study on the pretrained RoBERTa model with 110 intermediate-target task combinations. We further evaluate all trained models with 25 probing tasks meant to reveal the specific skills that drive transfer. We observe that intermediate tasks requiring high-level inference and reasoning abilities tend to work best. We also observe that target task performance is strongly correlated with higher-level abilities such as coreference resolution. However, we fail to observe more granular correlations between probing and target task performance, highlighting the need for further work on broad-coverage probing benchmarks. We also observe evidence that the forgetting of knowledge learned during pretraining may limit our analysis, highlighting the need for further work on transfer learning methods in these settings.","Intermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work? While pretrained models such as BERT have shown large gains across natural language understanding tasks, their performance can be improved by further training the model on a data-rich intermediate task, before fine-tuning it on a target task. However, it is still poorly understood when and why intermediate-task training is beneficial for a given target task. To investigate this, we perform a large-scale study on the pretrained RoBERTa model with 110 intermediate-target task combinations. We further evaluate all trained models with 25 probing tasks meant to reveal the specific skills that drive transfer. We observe that intermediate tasks requiring high-level inference and reasoning abilities tend to work best. We also observe that target task performance is strongly correlated with higher-level abilities such as coreference resolution. However, we fail to observe more granular correlations between probing and target task performance, highlighting the need for further work on broad-coverage probing benchmarks. We also observe evidence that the forgetting of knowledge learned during pretraining may limit our analysis, highlighting the need for further work on transfer learning methods in these settings.","intermediate - task transfer learning pretrained language model : work ? pretrained model bert show large gain natural language understanding task , performance improve train model data - rich intermediate task , fine - tune target task . , poorly understand intermediate - task training beneficial give target task . investigate , perform large - scale study pretrained roberta model 110 intermediate - target task combination . evaluate train model 25 probe task mean reveal specific skill drive transfer . observe intermediate task require high - level inference reasoning ability tend work well . observe target task performance strongly correlate high - level ability coreference resolution . , fail observe granular correlation probing target task performance , highlight need work broad - coverage probing benchmark . observe evidence forgetting knowledge learn pretraining limit analysis , highlight need work transfer learning method setting .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Theme,A Call for More Rigor in Unsupervised Cross-lingual Learning,"We review motivations, definition, approaches, and methodology for unsupervised crosslingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.","A Call for More Rigor in Unsupervised Cross-lingual Learning We review motivations, definition, approaches, and methodology for unsupervised crosslingual learning and call for a more rigorous position in each of them. An existing rationale for such research is based on the lack of parallel data for many of the world's languages. However, we argue that a scenario without any parallel data and abundant monolingual data is unrealistic in practice. We also discuss different training signals that have been used in previous work, which depart from the pure unsupervised setting. We then describe common methodological issues in tuning and evaluation of unsupervised cross-lingual models and present best practices. Finally, we provide a unified outlook for different types of research in this area (i.e., cross-lingual word embeddings, deep multilingual pretraining, and unsupervised machine translation) and argue for comparable evaluation of these models.","rigor unsupervised cross - lingual learning review motivation , definition , approach , methodology unsupervised crosslingual learning rigorous position . exist rationale research base lack parallel datum world language . , argue scenario parallel datum abundant monolingual datum unrealistic practice . discuss different training signal previous work , depart pure unsupervised setting . describe common methodological issue tuning evaluation unsupervised cross - lingual model present good practice . finally , provide unified outlook different type research area ( i.e. , cross - lingual word embedding , deep multilingual pretraining , unsupervised machine translation ) argue comparable evaluation model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Theme,The Unstoppable Rise of Computational Linguistics in Deep Learning,"In this paper, we trace the history of neural networks applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures. We focus on the importance of variable binding and its instantiation in attention-based models, and argue that Transformer is not a sequence model but an induced-structure model. This perspective leads to predictions of the challenges facing research in deep learning architectures for natural language understanding.","The Unstoppable Rise of Computational Linguistics in Deep Learning In this paper, we trace the history of neural networks applied to natural language understanding tasks, and identify key contributions which the nature of language has made to the development of neural network architectures. We focus on the importance of variable binding and its instantiation in attention-based models, and argue that Transformer is not a sequence model but an induced-structure model. This perspective leads to predictions of the challenges facing research in deep learning architectures for natural language understanding.","unstoppable rise computational linguistics deep learning paper , trace history neural network apply natural language understanding task , identify key contribution nature language development neural network architecture . focus importance variable binding instantiation attention - base model , argue transformer sequence model induce - structure model . perspective lead prediction challenge face research deep learning architecture natural language understanding .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,Language (Re)modelling: Towards Embodied Language Understanding,"While natural language understanding (NLU) is advancing rapidly, today's technology differs from human-like language understanding in fundamental ways, notably in its inferior efficiency, interpretability, and generalization. This work proposes an approach to representation and learning based on the tenets of embodied cognitive linguistics (ECL). According to ECL, natural language is inherently executable (like programming languages), driven by mental simulation and metaphoric mappings over hierarchical compositions of structures and schemata learned through embodied interaction. This position paper argues that the use of grounding by metaphoric inference and simulation will greatly benefit NLU systems, and proposes a system architecture along with a roadmap towards realizing this vision.","Language (Re)modelling: Towards Embodied Language Understanding While natural language understanding (NLU) is advancing rapidly, today's technology differs from human-like language understanding in fundamental ways, notably in its inferior efficiency, interpretability, and generalization. This work proposes an approach to representation and learning based on the tenets of embodied cognitive linguistics (ECL). According to ECL, natural language is inherently executable (like programming languages), driven by mental simulation and metaphoric mappings over hierarchical compositions of structures and schemata learned through embodied interaction. This position paper argues that the use of grounding by metaphoric inference and simulation will greatly benefit NLU systems, and proposes a system architecture along with a roadmap towards realizing this vision.","language ( re)modelling : embodied language understanding natural language understanding ( nlu ) advance rapidly , today technology differ human - like language understanding fundamental way , notably inferior efficiency , interpretability , generalization . work propose approach representation learning base tenet embodied cognitive linguistics ( ecl ) . accord ecl , natural language inherently executable ( like programming language ) , drive mental simulation metaphoric mapping hierarchical composition structure schema learn embody interaction . position paper argue use grounding metaphoric inference simulation greatly benefit nlu system , propose system architecture roadmap realize vision .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,What Question Answering can Learn from Trivia Nerds,"Question answering (QA)is not just building systems; this NLP subfield also creates and curates challenging question datasets that reveal the best systems. We argue that QA datasets-and QA leaderboards-closely resemble trivia tournaments: the questions agents-humans or machines-answer reveals a ""winner"". However, the research community has ignored the lessons from decades of the trivia community creating vibrant, fair, and effective QA competitions. After detailing problems with existing QA datasets, we outline several lessons that transfer to QA research: removing ambiguity, identifying better QA agents, and adjudicating disputes.","What Question Answering can Learn from Trivia Nerds Question answering (QA)is not just building systems; this NLP subfield also creates and curates challenging question datasets that reveal the best systems. We argue that QA datasets-and QA leaderboards-closely resemble trivia tournaments: the questions agents-humans or machines-answer reveals a ""winner"". However, the research community has ignored the lessons from decades of the trivia community creating vibrant, fair, and effective QA competitions. After detailing problems with existing QA datasets, we outline several lessons that transfer to QA research: removing ambiguity, identifying better QA agents, and adjudicating disputes.","question answering learn trivia nerd question answering ( qa)is build system ; nlp subfield create curate challenge question dataset reveal good system . argue qa dataset - qa leaderboard - closely resemble trivia tournament : question agent - human machine - answer reveal "" winner "" . , research community ignore lesson decade trivia community create vibrant , fair , effective qa competition . detail problem exist qa dataset , outline lesson transfer qa research : remove ambiguity , identify well qa agent , adjudicate dispute .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 20, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Theme,What Does BERT with Vision Look At?,"Pre-trained visually grounded language models such as ViLBERT, LXMERT, and UNITER have achieved significant performance improvement on vision-and-language tasks but what they learn during pre-training remains unclear. In this work, we demonstrate that certain attention heads of a visually grounded language model actively ground elements of language to image regions. Specifically, some heads can map entities to image regions, performing the task known as entity grounding. Some heads can even detect the syntactic relations between non-entity words and image regions, tracking, for example, associations between verbs and regions corresponding to their arguments. We denote this ability as syntactic grounding. We verify grounding both quantitatively and qualitatively, using Flickr30K Entities as a testbed.","What Does BERT with Vision Look At? Pre-trained visually grounded language models such as ViLBERT, LXMERT, and UNITER have achieved significant performance improvement on vision-and-language tasks but what they learn during pre-training remains unclear. In this work, we demonstrate that certain attention heads of a visually grounded language model actively ground elements of language to image regions. Specifically, some heads can map entities to image regions, performing the task known as entity grounding. Some heads can even detect the syntactic relations between non-entity words and image regions, tracking, for example, associations between verbs and regions corresponding to their arguments. We denote this ability as syntactic grounding. We verify grounding both quantitatively and qualitatively, using Flickr30K Entities as a testbed.","bert vision look ? pre - train visually ground language model vilbert , lxmert , uniter achieve significant performance improvement vision - - language task learn pre - training remain unclear . work , demonstrate certain attention head visually ground language model actively ground element language image region . specifically , head map entity image region , perform task know entity grounding . head detect syntactic relation non - entity word image region , track , example , association verb region correspond argument . denote ability syntactic grounding . verify grounding quantitatively qualitatively , flickr30 k entities testbed .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Theme,What are the Goals of Distributional Semantics?,"Distributional semantic models have become a mainstay in NLP, providing useful features for downstream tasks. However, assessing long-term progress requires explicit long-term goals. In this paper, I take a broad linguistic perspective, looking at how well current models can deal with various semantic challenges. Given stark differences between models proposed in different subfields, a broad perspective is needed to see how we could integrate them. I conclude that, while linguistic insights can guide the design of model architectures, future progress will require balancing the often conflicting demands of linguistic expressiveness and computational tractability.","What are the Goals of Distributional Semantics? Distributional semantic models have become a mainstay in NLP, providing useful features for downstream tasks. However, assessing long-term progress requires explicit long-term goals. In this paper, I take a broad linguistic perspective, looking at how well current models can deal with various semantic challenges. Given stark differences between models proposed in different subfields, a broad perspective is needed to see how we could integrate them. I conclude that, while linguistic insights can guide the design of model architectures, future progress will require balancing the often conflicting demands of linguistic expressiveness and computational tractability.","goal distributional semantic ? distributional semantic model mainstay nlp , provide useful feature downstream task . , assess long - term progress require explicit long - term goal . paper , broad linguistic perspective , look current model deal semantic challenge . give stark difference model propose different subfield , broad perspective need integrate . conclude , linguistic insight guide design model architecture , future progress require balance conflict demand linguistic expressiveness computational tractability .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Theme,Returning the N to NLP: Towards Contextually Personalized Classification Models,"Most NLP models today treat language as universal, even though socio-and psycholingustic research shows that the communicated message is influenced by the characteristics of the speaker as well as the target audience. This paper surveys the landscape of personalization in natural language processing and related fields, and offers a path forward to mitigate the decades of deviation of the NLP tools from sociolingustic findings, allowing to flexibly process the ""natural"" language of each user rather than enforcing a uniform NLP treatment. It outlines a possible direction to incorporate these aspects into neural NLP models by means of socially contextual personalization, and proposes to shift the focus of our evaluation strategies accordingly.","Returning the N to NLP: Towards Contextually Personalized Classification Models Most NLP models today treat language as universal, even though socio-and psycholingustic research shows that the communicated message is influenced by the characteristics of the speaker as well as the target audience. This paper surveys the landscape of personalization in natural language processing and related fields, and offers a path forward to mitigate the decades of deviation of the NLP tools from sociolingustic findings, allowing to flexibly process the ""natural"" language of each user rather than enforcing a uniform NLP treatment. It outlines a possible direction to incorporate these aspects into neural NLP models by means of socially contextual personalization, and proposes to shift the focus of our evaluation strategies accordingly.","return n nlp : contextually personalized classification models nlp model today treat language universal , socio - psycholingustic research show communicate message influence characteristic speaker target audience . paper survey landscape personalization natural language processing relate field , offer path forward mitigate decade deviation nlp tool sociolingustic finding , allow flexibly process "" natural "" language user enforce uniform nlp treatment . outline possible direction incorporate aspect neural nlp model mean socially contextual personalization , propose shift focus evaluation strategy accordingly .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 7, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,Are we Estimating or Guesstimating Translation Quality?,"Recent advances in pre-trained multilingual language models lead to state-of-the-art results on the task of quality estimation (QE) for machine translation. A carefully engineered ensemble of such models won the QE shared task at WMT19. Our in-depth analysis, however, shows that the success of using pre-trained language models for QE is overestimated due to three issues we observed in current QE datasets: (i) The distributions of quality scores are imbalanced and skewed towards good quality scores; (ii) QE models can perform well on these datasets while looking at only source or translated sentences; (iii) They contain statistical artifacts that correlate well with human-annotated QE labels. Our findings suggest that although QE models might capture fluency of translated sentences and complexity of source sentences, they cannot model adequacy of translations effectively.","Are we Estimating or Guesstimating Translation Quality? Recent advances in pre-trained multilingual language models lead to state-of-the-art results on the task of quality estimation (QE) for machine translation. A carefully engineered ensemble of such models won the QE shared task at WMT19. Our in-depth analysis, however, shows that the success of using pre-trained language models for QE is overestimated due to three issues we observed in current QE datasets: (i) The distributions of quality scores are imbalanced and skewed towards good quality scores; (ii) QE models can perform well on these datasets while looking at only source or translated sentences; (iii) They contain statistical artifacts that correlate well with human-annotated QE labels. Our findings suggest that although QE models might capture fluency of translated sentences and complexity of source sentences, they cannot model adequacy of translations effectively.","estimate guesstimate translation quality ? recent advance pre - trained multilingual language model lead state - - - art result task quality estimation ( qe ) machine translation . carefully engineer ensemble model win qe share task wmt19 . - depth analysis , , show success pre - trained language model qe overestimate issue observe current qe dataset : ( ) distribution quality score imbalanced skew good quality score ; ( ii ) qe model perform dataset look source translate sentence ; ( iii ) contain statistical artifact correlate human - annotated qe label . finding suggest qe model capture fluency translate sentence complexity source sentence , model adequacy translation effectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 7, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,Speech Translation and the End-to-End Promise: Taking Stock of Where We Are,"Over its three decade history, speech translation has experienced several shifts in its primary research themes; moving from loosely coupled cascades of speech recognition and machine translation, to exploring questions of tight coupling, and finally to end-to-end models that have recently attracted much attention. This paper provides a brief survey of these developments, along with a discussion of the main challenges of traditional approaches which stem from committing to intermediate representations from the speech recognizer, and from training cascaded models separately towards different objectives. Recent end-to-end modeling techniques promise a principled way of overcoming these issues by allowing joint training of all model components and removing the need for explicit intermediate representations. However, a closer look reveals that many end-to-end models fall short of solving these issues, due to compromises made to address data scarcity. This paper provides a unifying categorization and nomenclature that covers both traditional and recent approaches and that may help researchers by highlighting both trade-offs and open research questions.","Speech Translation and the End-to-End Promise: Taking Stock of Where We Are Over its three decade history, speech translation has experienced several shifts in its primary research themes; moving from loosely coupled cascades of speech recognition and machine translation, to exploring questions of tight coupling, and finally to end-to-end models that have recently attracted much attention. This paper provides a brief survey of these developments, along with a discussion of the main challenges of traditional approaches which stem from committing to intermediate representations from the speech recognizer, and from training cascaded models separately towards different objectives. Recent end-to-end modeling techniques promise a principled way of overcoming these issues by allowing joint training of all model components and removing the need for explicit intermediate representations. However, a closer look reveals that many end-to-end models fall short of solving these issues, due to compromises made to address data scarcity. This paper provides a unifying categorization and nomenclature that covers both traditional and recent approaches and that may help researchers by highlighting both trade-offs and open research questions.","speech translation end - - end promise : take stock decade history , speech translation experience shift primary research theme ; move loosely couple cascade speech recognition machine translation , explore question tight coupling , finally end - - end model recently attract attention . paper provide brief survey development , discussion main challenge traditional approach stem commit intermediate representation speech recognizer , train cascade model separately different objective . recent end - - end modeling technique promise principled way overcome issue allow joint training model component remove need explicit intermediate representation . , close look reveal end - - end model fall short solve issue , compromise address datum scarcity . paper provide unify categorization nomenclature cover traditional recent approach help researcher highlight trade - off open research question .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 5, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 2, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 14, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
Theme,How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence,"Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rulebased and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we describe the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an indepth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github. com/thunlp/CLAIM.","How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence Legal Artificial Intelligence (LegalAI) focuses on applying the technology of artificial intelligence, especially natural language processing, to benefit tasks in the legal domain. In recent years, LegalAI has drawn increasing attention rapidly from both AI researchers and legal professionals, as LegalAI is beneficial to the legal system for liberating legal professionals from a maze of paperwork. Legal professionals often think about how to solve tasks from rulebased and symbol-based methods, while NLP researchers concentrate more on data-driven and embedding methods. In this paper, we describe the history, the current state, and the future directions of research in LegalAI. We illustrate the tasks from the perspectives of legal professionals and NLP researchers and show several representative applications in LegalAI. We conduct experiments and provide an indepth analysis of the advantages and disadvantages of existing works to explore possible future directions. You can find the implementation of our work from https://github. com/thunlp/CLAIM.","nlp benefit legal system : summary legal artificial intelligence legal artificial intelligence ( legalai ) focus apply technology artificial intelligence , especially natural language processing , benefit task legal domain . recent year , legalai draw increase attention rapidly ai researcher legal professional , legalai beneficial legal system liberate legal professional maze paperwork . legal professional think solve task rulebased symbol - base method , nlp researcher concentrate data - drive embed method . paper , describe history , current state , future direction research legalai . illustrate task perspective legal professional nlp researcher representative application legalai . conduct experiment provide indepth analysis advantage disadvantage exist work explore possible future direction . find implementation work https://github . com / thunlp / claim .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 20, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,A Tale of a Probe and a Parser,"Measuring what linguistic information is encoded in neural models of language has become popular in NLP. Researchers approach this enterprise by training ""probes""supervised models designed to extract linguistic structure from another model's output. One such probe is the structural probe (Hewitt and Manning, 2019), designed to quantify the extent to which syntactic information is encoded in contextualised word representations. The structural probe has a novel design, unattested in the parsing literature, the precise benefit of which is not immediately obvious. To explore whether syntactic probes would do better to make use of existing techniques, we compare the structural probe to a more traditional parser with an identical lightweight parameterisation. The parser outperforms structural probe on UUAS in seven of nine analysed languages, often by a substantial amount (e.g. by 11.1 points in English). Under a second less common metric, however, there is the opposite trend-the structural probe outperforms the parser. This begs the question: which metric should we prefer?","A Tale of a Probe and a Parser Measuring what linguistic information is encoded in neural models of language has become popular in NLP. Researchers approach this enterprise by training ""probes""supervised models designed to extract linguistic structure from another model's output. One such probe is the structural probe (Hewitt and Manning, 2019), designed to quantify the extent to which syntactic information is encoded in contextualised word representations. The structural probe has a novel design, unattested in the parsing literature, the precise benefit of which is not immediately obvious. To explore whether syntactic probes would do better to make use of existing techniques, we compare the structural probe to a more traditional parser with an identical lightweight parameterisation. The parser outperforms structural probe on UUAS in seven of nine analysed languages, often by a substantial amount (e.g. by 11.1 points in English). Under a second less common metric, however, there is the opposite trend-the structural probe outperforms the parser. This begs the question: which metric should we prefer?","tale probe parser measure linguistic information encode neural model language popular nlp . researcher approach enterprise train "" probes""supervise model design extract linguistic structure model output . probe structural probe ( hewitt manning , 2019 ) , design quantify extent syntactic information encode contextualise word representation . structural probe novel design , unattested parsing literature , precise benefit immediately obvious . explore syntactic probe well use exist technique , compare structural probe traditional parser identical lightweight parameterisation . parser outperform structural probe uuas seven analyse language , substantial ( e.g. 11.1 point english ) . second common metric , , opposite trend - structural probe outperform parser . beg question : metric prefer ?","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 9, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 1, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 1, 'Theme': 10, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,Examining Citations of Natural Language Processing Literature,"We extracted information from the ACL Anthology (AA) and Google Scholar (GS) to examine trends in citations of NLP papers. We explore questions such as: how well cited are papers of different types (journal articles, conference papers, demo papers, etc.)? how well cited are papers from different areas of within NLP? etc. Notably, we show that only about 56% of the papers in AA are cited ten or more times. CL Journal has the most cited papers, but its citation dominance has lessened in recent years. On average, long papers get almost three times as many citations as short papers; and papers on sentiment classification, anaphora resolution, and entity recognition have the highest median citations. The analyses presented here, and the associated dataset of NLP papers mapped to citations, have a number of uses including: understanding how the field is growing and quantifying the impact of different types of papers.","Examining Citations of Natural Language Processing Literature We extracted information from the ACL Anthology (AA) and Google Scholar (GS) to examine trends in citations of NLP papers. We explore questions such as: how well cited are papers of different types (journal articles, conference papers, demo papers, etc.)? how well cited are papers from different areas of within NLP? etc. Notably, we show that only about 56% of the papers in AA are cited ten or more times. CL Journal has the most cited papers, but its citation dominance has lessened in recent years. On average, long papers get almost three times as many citations as short papers; and papers on sentiment classification, anaphora resolution, and entity recognition have the highest median citations. The analyses presented here, and the associated dataset of NLP papers mapped to citations, have a number of uses including: understanding how the field is growing and quantifying the impact of different types of papers.","examine citation natural language processing literature extract information acl anthology ( aa ) google scholar ( gs ) examine trend citation nlp paper . explore question : cite paper different type ( journal article , conference paper , demo paper , etc . ) ? cite paper different area nlp ? etc . notably , 56 % paper aa cite time . cl journal cite paper , citation dominance lessen recent year . average , long paper time citation short paper ; paper sentiment classification , anaphora resolution , entity recognition high median citation . analysis present , associate dataset nlp paper map citation , number use include : understand field grow quantify impact different type paper .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 25, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview,"An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.","Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview An increasing number of natural language processing papers address the effect of bias on predictions, introducing mitigation techniques at different parts of the standard NLP pipeline (data and models). However, these works have been conducted individually, without a unifying framework to organize efforts within the field. This situation leads to repetitive approaches, and focuses overly on bias symptoms/effects, rather than on their origins, which could limit the development of effective countermeasures. In this paper, we propose a unifying predictive bias framework for NLP. We summarize the NLP literature and suggest general mathematical definitions of predictive bias. We differentiate two consequences of bias: outcome disparities and error disparities, as well as four potential origins of biases: label bias, selection bias, model overamplification, and semantic bias. Our framework serves as an overview of predictive bias in NLP, integrating existing work into a single structure, and providing a conceptual baseline for improved frameworks.","predictive biases natural language processing model : conceptual framework overview increase number natural language processing paper address effect bias prediction , introduce mitigation technique different part standard nlp pipeline ( datum model ) . , work conduct individually , unify framework organize effort field . situation lead repetitive approach , focus overly bias symptom / effect , origin , limit development effective countermeasure . paper , propose unify predictive bias framework nlp . summarize nlp literature suggest general mathematical definition predictive bias . differentiate consequence bias : outcome disparity error disparity , potential origin bias : label bias , selection bias , model overamplification , semantic bias . framework serve overview predictive bias nlp , integrate exist work single structure , provide conceptual baseline improve framework .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 12, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 6, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Theme,To Boldly Query What No One Has Annotated Before? The Frontiers of Corpus Querying,"Corpus query systems exist to address the multifarious information needs of any person interested in the content of annotated corpora. In this role they play an important part in making those resources usable for a wider audience. Over the past decades, several such query systems and languages have emerged, varying greatly in their expressiveness and technical details. This paper offers a broad overview of the history of corpora and corpus query tools. It focusses strongly on the query side and hints at exciting directions for future development.","To Boldly Query What No One Has Annotated Before? The Frontiers of Corpus Querying Corpus query systems exist to address the multifarious information needs of any person interested in the content of annotated corpora. In this role they play an important part in making those resources usable for a wider audience. Over the past decades, several such query systems and languages have emerged, varying greatly in their expressiveness and technical details. This paper offers a broad overview of the history of corpora and corpus query tools. It focusses strongly on the query side and hints at exciting directions for future development.","boldly query annotate ? frontiers corpus querying corpus query system exist address multifarious information need person interested content annotate corpus . role play important make resource usable wide audience . past decade , query system language emerge , vary greatly expressiveness technical detail . paper offer broad overview history corpora corpus query tool . focusse strongly query hint exciting direction future development .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Theme,(Re)construing Meaning in NLP,"Human speakers have an extensive toolkit of ways to express themselves. In this paper, we engage with an idea largely absent from discussions of meaning in natural language understanding-namely, that the way something is expressed reflects different ways of conceptualizing or construing the information being conveyed. We first define this phenomenon more precisely, drawing on considerable prior work in theoretical cognitive semantics and psycholinguistics. We then survey some dimensions of construed meaning and show how insights from construal could inform theoretical and practical work in NLP.","(Re)construing Meaning in NLP Human speakers have an extensive toolkit of ways to express themselves. In this paper, we engage with an idea largely absent from discussions of meaning in natural language understanding-namely, that the way something is expressed reflects different ways of conceptualizing or construing the information being conveyed. We first define this phenomenon more precisely, drawing on considerable prior work in theoretical cognitive semantics and psycholinguistics. We then survey some dimensions of construed meaning and show how insights from construal could inform theoretical and practical work in NLP.","( re)construe meaning nlp human speaker extensive toolkit way express . paper , engage idea largely absent discussion meaning natural language understanding - , way express reflect different way conceptualize construe information convey . define phenomenon precisely , draw considerable prior work theoretical cognitive semantic psycholinguistics . survey dimension construe meaning insight construal inform theoretical practical work nlp .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Theme,True
Theme,Gender Gap in Natural Language Processing Research: Disparities in Authorship and Citations,"Disparities in authorship and citations across gender can have substantial adverse consequences not just on the disadvantaged genders, but also on the field of study as a whole. Measuring gender gaps is a crucial step towards addressing them. In this work, we examine female first author percentages and the citations to their papers in Natural Language Processing (1965 to 2019). We determine aggregatelevel statistics using an existing manually curated author-gender list as well as first names strongly associated with a gender. We find that only about 29% of first authors are female and only about 25% of last authors are female. Notably, this percentage has not improved since the mid 2000s. We also show that, on average, female first authors are cited less than male first authors, even when controlling for experience and area of research. Finally, we discuss the ethical considerations involved in automatic demographic analysis.","Gender Gap in Natural Language Processing Research: Disparities in Authorship and Citations Disparities in authorship and citations across gender can have substantial adverse consequences not just on the disadvantaged genders, but also on the field of study as a whole. Measuring gender gaps is a crucial step towards addressing them. In this work, we examine female first author percentages and the citations to their papers in Natural Language Processing (1965 to 2019). We determine aggregatelevel statistics using an existing manually curated author-gender list as well as first names strongly associated with a gender. We find that only about 29% of first authors are female and only about 25% of last authors are female. Notably, this percentage has not improved since the mid 2000s. We also show that, on average, female first authors are cited less than male first authors, even when controlling for experience and area of research. Finally, we discuss the ethical considerations involved in automatic demographic analysis.","gender gap natural language processing research : disparity authorship citation disparity authorship citation gender substantial adverse consequence disadvantaged gender , field study . measure gender gap crucial step address . work , examine female author percentage citation paper natural language processing ( 1965 2019 ) . determine aggregatelevel statistic exist manually curate author - gender list name strongly associate gender . find 29 % author female 25 % author female . notably , percentage improve mid 2000 . , average , female author cite male author , control experience area research . finally , discuss ethical consideration involve automatic demographic analysis .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 6, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 6, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Theme,How Can We Accelerate Progress Towards Human-like Linguistic Generalization?,"This position paper describes and critiques the Pretraining-Agnostic Identically Distributed (PAID) evaluation paradigm, which has become a central tool for measuring progress in natural language understanding. This paradigm consists of three stages: (1) pretraining of a word prediction model on a corpus of arbitrary size; (2) fine-tuning (transfer learning) on a training set representing a classification task; (3) evaluation on a test set drawn from the same distribution as that training set. This paradigm favors simple, low-bias architectures, which, first, can be scaled to process vast amounts of data, and second, can capture the fine-grained statistical properties of a particular data set, regardless of whether those properties are likely to generalize to examples of the task outside the data set. This contrasts with humans, who learn language from several orders of magnitude less data than the systems favored by this evaluation paradigm, and generalize to new tasks in a consistent way. We advocate for supplementing or replacing PAID with paradigms that reward architectures that generalize as quickly and robustly as humans.","How Can We Accelerate Progress Towards Human-like Linguistic Generalization? This position paper describes and critiques the Pretraining-Agnostic Identically Distributed (PAID) evaluation paradigm, which has become a central tool for measuring progress in natural language understanding. This paradigm consists of three stages: (1) pretraining of a word prediction model on a corpus of arbitrary size; (2) fine-tuning (transfer learning) on a training set representing a classification task; (3) evaluation on a test set drawn from the same distribution as that training set. This paradigm favors simple, low-bias architectures, which, first, can be scaled to process vast amounts of data, and second, can capture the fine-grained statistical properties of a particular data set, regardless of whether those properties are likely to generalize to examples of the task outside the data set. This contrasts with humans, who learn language from several orders of magnitude less data than the systems favored by this evaluation paradigm, and generalize to new tasks in a consistent way. We advocate for supplementing or replacing PAID with paradigms that reward architectures that generalize as quickly and robustly as humans.","accelerate progress human - like linguistic generalization ? position paper describe critique pretraine - agnostic identically distribute ( paid ) evaluation paradigm , central tool measure progress natural language understanding . paradigm consist stage : ( 1 ) pretraining word prediction model corpus arbitrary size ; ( 2 ) fine - tuning ( transfer learning ) training set represent classification task ; ( 3 ) evaluation test set draw distribution training set . paradigm favor simple , low - bias architecture , , , scale process vast amount datum , second , capture fine - grained statistical property particular data set , regardless property likely generalize example task outside data set . contrast human , learn language order magnitude datum system favor evaluation paradigm , generalize new task consistent way . advocate supplement replace paid paradigm reward architecture generalize quickly robustly human .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Theme,From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of Parsing Morphologically-Rich Languages (MRLs)?,"It has been exactly a decade since the first establishment of SPMRL, a research initiative unifying multiple research efforts to address the peculiar challenges of Statistical Parsing for Morphologically-Rich Languages (MRLs). Here we reflect on parsing MRLs in that decade, highlight the solutions and lessons learned for the architectural, modeling and lexical challenges in the pre-neural era, and argue that similar challenges re-emerge in neural architectures for MRLs. We then aim to offer a climax, suggesting that incorporating symbolic ideas proposed in SPMRL terms into nowadays neural architectures has the potential to push NLP for MRLs to a new level. We sketch a strategies for designing Neural Models for MRLs (NMRL), and showcase preliminary support for these strategies via investigating the task of multi-tagging in Hebrew, a morphologically-rich, high-fusion, language.","From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of Parsing Morphologically-Rich Languages (MRLs)? It has been exactly a decade since the first establishment of SPMRL, a research initiative unifying multiple research efforts to address the peculiar challenges of Statistical Parsing for Morphologically-Rich Languages (MRLs). Here we reflect on parsing MRLs in that decade, highlight the solutions and lessons learned for the architectural, modeling and lexical challenges in the pre-neural era, and argue that similar challenges re-emerge in neural architectures for MRLs. We then aim to offer a climax, suggesting that incorporating symbolic ideas proposed in SPMRL terms into nowadays neural architectures has the potential to push NLP for MRLs to a new level. We sketch a strategies for designing Neural Models for MRLs (NMRL), and showcase preliminary support for these strategies via investigating the task of multi-tagging in Hebrew, a morphologically-rich, high-fusion, language.","spmrl nmrl : learn ( unlearn ) decade parse morphologically - rich language ( mrls ) ? exactly decade establishment spmrl , research initiative unify multiple research effort address peculiar challenge statistical parsing morphologically - rich languages ( mrls ) . reflect parse mrl decade , highlight solution lesson learn architectural , modeling lexical challenge pre - neural era , argue similar challenge - emerge neural architecture mrl . aim offer climax , suggest incorporate symbolic idea propose spmrl term nowadays neural architecture potential push nlp mrls new level . sketch strategy design neural models mrls ( nmrl ) , showcase preliminary support strategy investigate task multi - tag hebrew , morphologically - rich , high - fusion , language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 5, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,On Forgetting to Cite Older Papers: An Analysis of the ACL Anthology,"The field of natural language processing is experiencing a period of unprecedented growth, and with it a surge of published papers. This represents an opportunity for us to take stock of how we cite the work of other researchers, and whether this growth comes at the expense of ""forgetting"" about older literature. In this paper, we address this question through bibliographic analysis. We analyze the age of outgoing citations in papers published at selected ACL venues between 2010 and 2019, finding that there is indeed a tendency for recent papers to cite more recent work, but the rate at which papers older than 15 years are cited has remained relatively stable.","On Forgetting to Cite Older Papers: An Analysis of the ACL Anthology The field of natural language processing is experiencing a period of unprecedented growth, and with it a surge of published papers. This represents an opportunity for us to take stock of how we cite the work of other researchers, and whether this growth comes at the expense of ""forgetting"" about older literature. In this paper, we address this question through bibliographic analysis. We analyze the age of outgoing citations in papers published at selected ACL venues between 2010 and 2019, finding that there is indeed a tendency for recent papers to cite more recent work, but the rate at which papers older than 15 years are cited has remained relatively stable.","forget cite old paper : analysis acl anthology field natural language processing experience period unprecedented growth , surge publish paper . represent opportunity stock cite work researcher , growth come expense "" forget "" old literature . paper , address question bibliographic analysis . analyze age outgoing citation paper publish select acl venue 2010 2019 , find tendency recent paper cite recent work , rate paper old 15 year cite remain relatively stable .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 11, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theme,"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data","The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as ""understanding"" language or capturing ""meaning"". In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of ""Taking Stock of Where We've Been and Where We're Going"", we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.","Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as ""understanding"" language or capturing ""meaning"". In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of ""Taking Stock of Where We've Been and Where We're Going"", we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding.","climb nlu : meaning , form , understanding age data success large neural language model nlp task exciting . , find success lead hype model describe "" understand "" language capture "" meaning "" . position paper , argue system train form priori way learn meaning . keep acl 2020 theme "" take stock go "" , argue clear understanding distinction form meaning help guide field well science natural language understanding .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 7, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,True
Theory and Formalism in NLP (Linguistic and Mathematical),A Three-Parameter Rank-Frequency Relation in Natural Languages,"We present that, the rank-frequency relation in textual data follows f âˆ r âˆ’Î± (r + Î³) âˆ’Î² , where f is the token frequency and r is the rank by frequency, with (Î±, Î², Î³) as parameters. The formulation is derived based on the empirical observation that d 2 (x+y)/dx 2 is a typical impulse function, where (x, y) = (log r, log f ). The formulation is the power law when Î² = 0 and the Zipf-Mandelbrot law when Î± = 0. We illustrate that Î± is related to the analytic features of syntax and Î² + Î³ to those of morphology in natural languages from an investigation of multilingual corpora.","A Three-Parameter Rank-Frequency Relation in Natural Languages We present that, the rank-frequency relation in textual data follows f âˆ r âˆ’Î± (r + Î³) âˆ’Î² , where f is the token frequency and r is the rank by frequency, with (Î±, Î², Î³) as parameters. The formulation is derived based on the empirical observation that d 2 (x+y)/dx 2 is a typical impulse function, where (x, y) = (log r, log f ). The formulation is the power law when Î² = 0 and the Zipf-Mandelbrot law when Î± = 0. We illustrate that Î± is related to the analytic features of syntax and Î² + Î³ to those of morphology in natural languages from an investigation of multilingual corpora.","- parameter rank - frequency relation natural language present , rank - frequency relation textual datum follow f âˆ r âˆ’Î± ( r + Î³ ) âˆ’Î² , f token frequency r rank frequency , ( Î± , Î² , Î³ ) parameter . formulation derive base empirical observation d 2 ( x+y)/dx 2 typical impulse function , ( x , y ) = ( log r , log f ) . formulation power law Î² = 0 zipf - mandelbrot law Î± = 0 . illustrate Î± relate analytic feature syntax Î² + Î³ morphology natural language investigation multilingual corpus .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 2}",Information Extraction,False
Theory and Formalism in NLP (Linguistic and Mathematical),Dice Loss for Data-imbalanced NLP Tasks,"Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.","Dice Loss for Data-imbalanced NLP Tasks Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.","dice loss data - imbalance nlp task nlp task tagging machine reading comprehension ( mrc ) face severe data imbalance issue : negative example significantly outnumber positive one , huge number easy - negative example overwhelm training . commonly cross entropy criterion actually accuracy - orient , create discrepancy training test . training time , training instance contribute equally objective function , test time f1 score concern positive example .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 4, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
Theory and Formalism in NLP (Linguistic and Mathematical),Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese,"We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.","Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.","language model alternative evaluator word order hypothesis : case study japanese examine methodology neural language model ( lms ) analyze word order language . lm - base method potential overcome difficulty exist method face , propagation preprocessor error count - base method . study , explore lmbase method valid analyze word order . case study , study focus japanese complex flexible word order . validate lm - base method , test ( ) parallel lms human word order preference , ( ii ) consistency result obtain lm - base method previous linguistic study . experiment , tentatively conclude lms display sufficient word order knowledge usage analysis tool . finally , lmbased method , demonstrate relationship canonical word order topicalization , analyze largescale experiment .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 7}",Semantics: Lexical Semantics,False
Theory and Formalism in NLP (Linguistic and Mathematical),A Formal Hierarchy of RNN Architectures,"We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of ""saturated"" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.","A Formal Hierarchy of RNN Architectures We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of ""saturated"" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.","formal hierarchy rnn architecture develop formal hierarchy expressive capacity rnn architecture . hierarchy base formal property : space complexity , measure rnn memory , rational recurrence , define recurrent update describe weight finite - state machine . place rnn variant hierarchy . example , prove lstm rational , formally separate related qrnn ( bradbury et al . , 2016 ) . model ' expressive capacity expand stack multiple layer compose different pool function . result build theory "" saturated "" rnn ( merrill , 2019 ) . formally extend finding unsaturated rnn leave future work , hypothesize practical learnable capacity unsaturated rnn obey similar hierarchy . experimental finding train unsaturated network formal language support conjecture . proof . choose k = 1 . fix controller push 1 x t = , pop .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 23}",Theory and Formalism in NLP (Linguistic and Mathematical),True
Theory and Formalism in NLP (Linguistic and Mathematical),Emergence of Syntax Needs Minimal Supervision,"This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.","Emergence of Syntax Needs Minimal Supervision This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.","emergence syntax need minimal supervision paper theoretical contribution debate learnability syntax corpus explicit syntax - specific guidance . approach originate observable structure corpus , use define isolate grammaticality ( syntactic information ) meaning / pragmatic information . describe formal characteristic autonomous syntax possible search syntax - base lexical category simple optimization process , prior hypothesis form model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 7}",Theory and Formalism in NLP (Linguistic and Mathematical),True
Theory and Formalism in NLP (Linguistic and Mathematical),Theoretical Limitations of Self-Attention in Neural Sequence Models,"Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.","Theoretical Limitations of Self-Attention in Neural Sequence Models Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.","theoretical limitation self - attention neural sequence model transformer emerge new workhorse nlp , show great success task . unlike lstms , transformer process input sequence entirely self - attention . previous work suggest computational capability self - attention process hierarchical structure limited . work , mathematically investigate computational power self - attention model formal language . soft hard attention , strong theoretical limitation computational ability selfattention , find model periodic finite - state language , hierarchical structure , number layer head increase input length . limitation surprising give practical success self - attention prominent role assign hierarchical structure linguistic , suggest natural language approximate model weak formal language typically assume theoretical linguistic .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 3, 'Interpretability and Analysis of Models for NLP': 8, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 7}",Interpretability and Analysis of Models for NLP,False
System Demonstrations,CLIReval: Evaluating Machine Translation as a Cross-Lingual Information Retrieval Task,"We present CLIReval, an easy-to-use toolkit for evaluating machine translation (MT) with the proxy task of cross-lingual information retrieval (CLIR). Contrary to what the project name might suggest, CLIReval does not actually require any annotated CLIR dataset. Instead, it automatically transforms translations and references used in MT evaluations into a synthetic CLIR dataset; it then sets up a standard search engine (Elasticsearch) and computes various information retrieval metrics (e.g., mean average precision) by treating the translations as documents to be retrieved. The idea is to gauge the quality of MT by its impact on the document translation approach to CLIR. As a case study, we run CLIReval on the ""metrics shared task"" of WMT2019; while this extrinsic metric is not intended to replace popular intrinsic metrics such as BLEU, results suggest CLIReval is competitive in many language pairs in terms of correlation to human judgments of quality. CLIReval is publicly available at https: //github.com/ssun32/CLIReval.","CLIReval: Evaluating Machine Translation as a Cross-Lingual Information Retrieval Task We present CLIReval, an easy-to-use toolkit for evaluating machine translation (MT) with the proxy task of cross-lingual information retrieval (CLIR). Contrary to what the project name might suggest, CLIReval does not actually require any annotated CLIR dataset. Instead, it automatically transforms translations and references used in MT evaluations into a synthetic CLIR dataset; it then sets up a standard search engine (Elasticsearch) and computes various information retrieval metrics (e.g., mean average precision) by treating the translations as documents to be retrieved. The idea is to gauge the quality of MT by its impact on the document translation approach to CLIR. As a case study, we run CLIReval on the ""metrics shared task"" of WMT2019; while this extrinsic metric is not intended to replace popular intrinsic metrics such as BLEU, results suggest CLIReval is competitive in many language pairs in terms of correlation to human judgments of quality. CLIReval is publicly available at https: //github.com/ssun32/CLIReval.","clireval : evaluate machine translation cross - lingual information retrieval task present clireval , easy - - use toolkit evaluate machine translation ( mt ) proxy task cross - lingual information retrieval ( clir ) . contrary project suggest , clireval actually require annotate clir dataset . instead , automatically transform translation reference mt evaluation synthetic clir dataset ; set standard search engine ( elasticsearch ) compute information retrieval metric ( e.g. , mean average precision ) treat translation document retrieve . idea gauge quality mt impact document translation approach clir . case study , run clireval "" metric share task "" wmt2019 ; extrinsic metric intend replace popular intrinsic metric bleu , result suggest clireval competitive language pair term correlation human judgment quality . clireval publicly available https : //github.com / ssun32 / clireval .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 10, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
System Demonstrations,OpusFilter: A Configurable Parallel Corpus Filtering Toolbox,"This paper introduces OpusFilter, a flexible and modular toolbox for filtering parallel corpora. It implements a number of components based on heuristic filters, language identification libraries, character-based language models, and word alignment tools, and it can easily be extended with custom filters. Bitext segments can be ranked according to their quality or domain match using single features or a logistic regression model that can be trained without manually labeled training data. We demonstrate the effectiveness of OpusFilter on the example of a Finnish-English news translation task based on noisy web-crawled training data. Applying our tool leads to improved translation quality while significantly reducing the size of the training data, also clearly outperforming an alternative ranking given in the crawled data set. Furthermore, we show the ability of OpusFilter to perform data selection for domain adaptation.","OpusFilter: A Configurable Parallel Corpus Filtering Toolbox This paper introduces OpusFilter, a flexible and modular toolbox for filtering parallel corpora. It implements a number of components based on heuristic filters, language identification libraries, character-based language models, and word alignment tools, and it can easily be extended with custom filters. Bitext segments can be ranked according to their quality or domain match using single features or a logistic regression model that can be trained without manually labeled training data. We demonstrate the effectiveness of OpusFilter on the example of a Finnish-English news translation task based on noisy web-crawled training data. Applying our tool leads to improved translation quality while significantly reducing the size of the training data, also clearly outperforming an alternative ranking given in the crawled data set. Furthermore, we show the ability of OpusFilter to perform data selection for domain adaptation.","opusfilter : configurable parallel corpus filtering toolbox paper introduce opusfilter , flexible modular toolbox filter parallel corpora . implement number component base heuristic filter , language identification library , character - base language model , word alignment tool , easily extend custom filter . bitext segment rank accord quality domain match single feature logistic regression model train manually label training datum . demonstrate effectiveness opusfilter example finnish - english news translation task base noisy web - crawl training datum . apply tool lead improve translation quality significantly reduce size training datum , clearly outperform alternative ranking give crawl data set . furthermore , ability opusfilter perform datum selection domain adaptation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,Interactive Task Learning from GUI-Grounded Natural Language Instructions and Demonstrations,"We show SUGILITE, an intelligent task automation agent that can learn new tasks and relevant associated concepts interactively from the user's natural language instructions and demonstrations, using the graphical user interfaces (GUIs) of third-party mobile apps. This system provides several interesting features: (1) it allows users to teach new task procedures and concepts through verbal instructions together with demonstration of the steps of a script using GUIs; (2) it supports users in clarifying their intents for demonstrated actions using GUI-grounded verbal instructions; (3) it infers parameters of tasks and their possible values in utterances using the hierarchical structures of the underlying app GUIs; and (4) it generalizes taught concepts to different contexts and task domains. We describe the architecture of the SUGILITE system, explain the design and implementation of its key features, and show a prototype in the form of a conversational assistant on Android.","Interactive Task Learning from GUI-Grounded Natural Language Instructions and Demonstrations We show SUGILITE, an intelligent task automation agent that can learn new tasks and relevant associated concepts interactively from the user's natural language instructions and demonstrations, using the graphical user interfaces (GUIs) of third-party mobile apps. This system provides several interesting features: (1) it allows users to teach new task procedures and concepts through verbal instructions together with demonstration of the steps of a script using GUIs; (2) it supports users in clarifying their intents for demonstrated actions using GUI-grounded verbal instructions; (3) it infers parameters of tasks and their possible values in utterances using the hierarchical structures of the underlying app GUIs; and (4) it generalizes taught concepts to different contexts and task domains. We describe the architecture of the SUGILITE system, explain the design and implementation of its key features, and show a prototype in the form of a conversational assistant on Android.","interactive task learn gui - ground natural language instruction demonstration sugilite , intelligent task automation agent learn new task relevant associate concept interactively user natural language instruction demonstration , graphical user interface ( guis ) - party mobile app . system provide interesting feature : ( 1 ) allow user teach new task procedure concept verbal instruction demonstration step script gui ; ( 2 ) support user clarify intent demonstrate action gui - ground verbal instruction ; ( 3 ) infer parameter task possible value utterance hierarchical structure underlie app gui ; ( 4 ) generalize teach concept different context task domain . describe architecture sugilite system , explain design implementation key feature , prototype form conversational assistant android .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 9, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,Embedding-based Scientific Literature Discovery in a Text Editor Application,"Each claim in a research paper requires all relevant prior knowledge to be discovered, assimilated, and appropriately cited. However, despite the availability of powerful search engines and sophisticated text editing software, discovering relevant papers and integrating the knowledge into a manuscript remain complex tasks associated with high cognitive load. To define comprehensive search queries requires strong motivation from authors, irrespective of their familiarity with the research field. Moreover, switching between independent applications for literature discovery, bibliography management, reading papers, and writing text burdens authors further and interrupts their creative process. Here, we present a web application that combines text editing and literature discovery in an interactive user interface. The application is equipped with a search engine that couples Boolean keyword filtering with nearest neighbor search over text embeddings, providing a discovery experience tuned to an author's manuscript and his interests. Our application aims to take a step towards more enjoyable and effortless academic writing. The demo of the application 1 and a short video tutorial 2 are available online.","Embedding-based Scientific Literature Discovery in a Text Editor Application Each claim in a research paper requires all relevant prior knowledge to be discovered, assimilated, and appropriately cited. However, despite the availability of powerful search engines and sophisticated text editing software, discovering relevant papers and integrating the knowledge into a manuscript remain complex tasks associated with high cognitive load. To define comprehensive search queries requires strong motivation from authors, irrespective of their familiarity with the research field. Moreover, switching between independent applications for literature discovery, bibliography management, reading papers, and writing text burdens authors further and interrupts their creative process. Here, we present a web application that combines text editing and literature discovery in an interactive user interface. The application is equipped with a search engine that couples Boolean keyword filtering with nearest neighbor search over text embeddings, providing a discovery experience tuned to an author's manuscript and his interests. Our application aims to take a step towards more enjoyable and effortless academic writing. The demo of the application 1 and a short video tutorial 2 are available online.","embedding - base scientific literature discovery text editor application claim research paper require relevant prior knowledge discover , assimilate , appropriately cite . , despite availability powerful search engine sophisticated text editing software , discover relevant paper integrate knowledge manuscript remain complex task associate high cognitive load . define comprehensive search query require strong motivation author , irrespective familiarity research field . , switch independent application literature discovery , bibliography management , read paper , write text burden author interrupt creative process . , present web application combine text editing literature discovery interactive user interface . application equip search engine couple boolean keyword filtering near neighbor search text embedding , provide discovery experience tune author manuscript interest . application aim step enjoyable effortless academic writing . demo application 1 short video tutorial 2 available online .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 9, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 7, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 9, 'Theme': 4, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
System Demonstrations,pyBART: Evidence-based Syntactic Transformations for IE,"Syntactic dependencies can be predicted with high accuracy, and are useful for both machine-learned and pattern-based information extraction tasks. However, their utility can be improved. These syntactic dependencies are designed to accurately reflect syntactic relations, and they do not make semantic relations explicit. Therefore, these representations lack many explicit connections between content words, that would be useful for downstream applications. Proposals like English Enhanced UD improve the situation by extending universal dependency trees with additional explicit arcs. However, they are not available to Python users, and are also limited in coverage. We introduce a broad-coverage, datadriven and linguistically sound set of transformations, that makes event-structure and many lexical relations explicit. We present pyBART, an easy-to-use open-source Python library for converting English UD trees either to Enhanced UD graphs or to our representation. The library can work as a standalone package or be integrated within a spaCy NLP pipeline. When evaluated in a pattern-based relation extraction scenario, our representation results in higher extraction scores than Enhanced UD, while requiring fewer patterns.","pyBART: Evidence-based Syntactic Transformations for IE Syntactic dependencies can be predicted with high accuracy, and are useful for both machine-learned and pattern-based information extraction tasks. However, their utility can be improved. These syntactic dependencies are designed to accurately reflect syntactic relations, and they do not make semantic relations explicit. Therefore, these representations lack many explicit connections between content words, that would be useful for downstream applications. Proposals like English Enhanced UD improve the situation by extending universal dependency trees with additional explicit arcs. However, they are not available to Python users, and are also limited in coverage. We introduce a broad-coverage, datadriven and linguistically sound set of transformations, that makes event-structure and many lexical relations explicit. We present pyBART, an easy-to-use open-source Python library for converting English UD trees either to Enhanced UD graphs or to our representation. The library can work as a standalone package or be integrated within a spaCy NLP pipeline. When evaluated in a pattern-based relation extraction scenario, our representation results in higher extraction scores than Enhanced UD, while requiring fewer patterns.","pybart : evidence - base syntactic transformations ie syntactic dependency predict high accuracy , useful machine - learn pattern - base information extraction task . , utility improve . syntactic dependency design accurately reflect syntactic relation , semantic relation explicit . , representation lack explicit connection content word , useful downstream application . proposal like english enhanced ud improve situation extend universal dependency tree additional explicit arc . , available python user , limited coverage . introduce broad - coverage , datadriven linguistically sound set transformation , make event - structure lexical relation explicit . present pybart , easy - - use open - source python library convert english ud tree enhanced ud graph representation . library work standalone package integrate spacy nlp pipeline . evaluate pattern - base relation extraction scenario , representation result high extraction score enhanced ud , require few pattern .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 7, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 5, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
System Demonstrations,NSTM: Real-Time Query-Driven News Overview Composition at Bloomberg,"Millions of news articles from hundreds of thousands of sources around the globe appear in news aggregators every day. Consuming such a volume of news presents an almost insurmountable challenge. For example, a reader searching on Bloomberg's system for news about the U.K. would find 10,000 articles on a typical day. Apple Inc., the world's most journalistically covered company, garners around 1,800 news articles a day. We realized that a new kind of summarization engine was needed, one that would condense large volumes of news into short, easy to absorb points. The system would filter out noise and duplicates to identify and summarize key news about companies, countries or markets. When given a user query, Bloomberg's solution, Key News Themes (or NSTM), leverages state-of-the-art semantic clustering techniques and novel summarization methods to produce comprehensive, yet concise, digests to dramatically simplify the news consumption process. NSTM is available to hundreds of thousands of readers around the world and serves thousands of requests daily with sub-second latency. At ACL 2020, we will present a demo of NSTM. * Order reflects writing contributions; M.X., I.C.C., and J.B. designed and developed a prototype of the system; All implemented the production system; A.A. managed the project. I.C.C. worked on the project while employed by Bloomberg.","NSTM: Real-Time Query-Driven News Overview Composition at Bloomberg Millions of news articles from hundreds of thousands of sources around the globe appear in news aggregators every day. Consuming such a volume of news presents an almost insurmountable challenge. For example, a reader searching on Bloomberg's system for news about the U.K. would find 10,000 articles on a typical day. Apple Inc., the world's most journalistically covered company, garners around 1,800 news articles a day. We realized that a new kind of summarization engine was needed, one that would condense large volumes of news into short, easy to absorb points. The system would filter out noise and duplicates to identify and summarize key news about companies, countries or markets. When given a user query, Bloomberg's solution, Key News Themes (or NSTM), leverages state-of-the-art semantic clustering techniques and novel summarization methods to produce comprehensive, yet concise, digests to dramatically simplify the news consumption process. NSTM is available to hundreds of thousands of readers around the world and serves thousands of requests daily with sub-second latency. At ACL 2020, we will present a demo of NSTM. * Order reflects writing contributions; M.X., I.C.C., and J.B. designed and developed a prototype of the system; All implemented the production system; A.A. managed the project. I.C.C. worked on the project while employed by Bloomberg.","nstm : real - time query - drive news overview composition bloomberg million news article hundred thousand source globe appear news aggregator day . consume volume news present insurmountable challenge . example , reader search bloomberg system news u.k. find 10,000 article typical day . apple inc. , world journalistically cover company , garner 1,800 news article day . realize new kind summarization engine need , condense large volume news short , easy absorb point . system filter noise duplicate identify summarize key news company , country market . give user query , bloomberg solution , key news themes ( nstm ) , leverage state - - - art semantic clustering technique novel summarization method produce comprehensive , concise , digest dramatically simplify news consumption process . nstm available hundred thousand reader world serve thousand request daily sub - second latency . acl 2020 , present demo nstm . * order reflect writing contribution ; m.x. , i.c.c. , j.b. design develop prototype system ; implement production system ; a.a. manage project . i.c.c. work project employ bloomberg .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 11, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
System Demonstrations,Multilingual Universal Sentence Encoder for Semantic Retrieval,"We present easy-to-use retrieval focused multilingual sentence embedding models, made available on TensorFlow Hub. The models embed text from 16 languages into a shared semantic space using a multi-task trained dualencoder that learns tied cross-lingual representations via translation bridge tasks (Chidambaram et al., 2018). The models achieve a new state-of-the-art in performance on monolingual and cross-lingual semantic retrieval (SR). Competitive performance is obtained on the related tasks of translation pair bitext retrieval (BR) and retrieval question answering (ReQA). On transfer learning tasks, our multilingual embeddings approach, and in some cases exceed, the performance of English only sentence embeddings. 3 Encoder Architecture 3.1 Multi-task Dual Encoder Training Similar to Cer et al. (2018) and Chidambaram et al. ( 2018 ), we target broad coverage using a 2 https://www.tensorflow.org/hub/, Apache 2.0 license, with models available as saved TF graphs.","Multilingual Universal Sentence Encoder for Semantic Retrieval We present easy-to-use retrieval focused multilingual sentence embedding models, made available on TensorFlow Hub. The models embed text from 16 languages into a shared semantic space using a multi-task trained dualencoder that learns tied cross-lingual representations via translation bridge tasks (Chidambaram et al., 2018). The models achieve a new state-of-the-art in performance on monolingual and cross-lingual semantic retrieval (SR). Competitive performance is obtained on the related tasks of translation pair bitext retrieval (BR) and retrieval question answering (ReQA). On transfer learning tasks, our multilingual embeddings approach, and in some cases exceed, the performance of English only sentence embeddings. 3 Encoder Architecture 3.1 Multi-task Dual Encoder Training Similar to Cer et al. (2018) and Chidambaram et al. ( 2018 ), we target broad coverage using a 2 https://www.tensorflow.org/hub/, Apache 2.0 license, with models available as saved TF graphs.","multilingual universal sentence encoder semantic retrieval present easy - - use retrieval focus multilingual sentence embedding model , available tensorflow hub . model embed text 16 language share semantic space multi - task train dualencoder learn tie cross - lingual representation translation bridge task ( chidambaram et al . , 2018 ) . model achieve new state - - - art performance monolingual cross - lingual semantic retrieval ( sr ) . competitive performance obtain related task translation pair bitext retrieval ( br ) retrieval question answering ( reqa ) . transfer learning task , multilingual embedding approach , case exceed , performance english sentence embedding . 3 encoder architecture 3.1 multi - task dual encoder training similar cer et al . ( 2018 ) chidambaram et al . ( 2018 ) , target broad coverage 2 https://www.tensorflow.org/hub/ , apache 2.0 license , model available save tf graph .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 6, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
System Demonstrations,LinggleWrite: a Coaching System for Essay Writing,"This paper presents LinggleWrite, a writing coach that provides writing suggestions, assesses writing proficiency levels, detects grammatical errors, and offers corrective feedback in response to user's essay. The method involves extracting grammar patterns, training models for automated essay scoring (AES) and grammatical error detection (GED), and finally retrieving plausible corrections from a n-gram search engine. Experiments on public test sets indicate that both AES and GED models achieve state-of-the-art performance. These results show that LinggleWrite is potentially useful in helping learners improve their writing skills.","LinggleWrite: a Coaching System for Essay Writing This paper presents LinggleWrite, a writing coach that provides writing suggestions, assesses writing proficiency levels, detects grammatical errors, and offers corrective feedback in response to user's essay. The method involves extracting grammar patterns, training models for automated essay scoring (AES) and grammatical error detection (GED), and finally retrieving plausible corrections from a n-gram search engine. Experiments on public test sets indicate that both AES and GED models achieve state-of-the-art performance. These results show that LinggleWrite is potentially useful in helping learners improve their writing skills.","lingglewrite : coaching system essay writing paper present lingglewrite , writing coach provide writing suggestion , assess writing proficiency level , detect grammatical error , offer corrective feedback response user essay . method involve extract grammar pattern , train model automate essay scoring ( aes ) grammatical error detection ( ged ) , finally retrieve plausible correction n - gram search engine . experiment public test set indicate aes ged model achieve state - - - art performance . result lingglewrite potentially useful help learner improve writing skill .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,Stimulating Creativity with FunLines: A Case Study of Humor Generation in Headlines,"Building datasets of creative text, such as humor, is quite challenging. We introduce Fun-Lines, a competitive game where players edit news headlines to make them funny, and where they rate the funniness of headlines edited by others. FunLines makes the humor generation process fun, interactive, collaborative, rewarding and educational, keeping players engaged and providing humor data at a very low cost compared to traditional crowdsourcing approaches. FunLines offers useful performance feedback, assisting players in getting better over time at generating and assessing humor, as our analysis shows. This helps to further increase the quality of the generated dataset. We show the effectiveness of this data by training humor classification models that outperform a previous benchmark, and we release this dataset to the public. 1 https://funlines.co FunLines demo video: https://youtu.be/5OXJMxDBaLY","Stimulating Creativity with FunLines: A Case Study of Humor Generation in Headlines Building datasets of creative text, such as humor, is quite challenging. We introduce Fun-Lines, a competitive game where players edit news headlines to make them funny, and where they rate the funniness of headlines edited by others. FunLines makes the humor generation process fun, interactive, collaborative, rewarding and educational, keeping players engaged and providing humor data at a very low cost compared to traditional crowdsourcing approaches. FunLines offers useful performance feedback, assisting players in getting better over time at generating and assessing humor, as our analysis shows. This helps to further increase the quality of the generated dataset. We show the effectiveness of this data by training humor classification models that outperform a previous benchmark, and we release this dataset to the public. 1 https://funlines.co FunLines demo video: https://youtu.be/5OXJMxDBaLY","stimulate creativity funlines : case study humor generation headline build dataset creative text , humor , challenging . introduce fun - lines , competitive game player edit news headline funny , rate funniness headline edit . funlines make humor generation process fun , interactive , collaborative , rewarding educational , keep player engaged provide humor datum low cost compare traditional crowdsourcing approach . funlines offer useful performance feedback , assist player get well time generate assess humor , analysis show . help increase quality generate dataset . effectiveness datum train humor classification model outperform previous benchmark , release dataset public . 1 https://funlines.co funlines demo video : https://youtu.be/5oxjmxdbali","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 7, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 5, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
System Demonstrations,Usnea: An Authorship Tool for Interactive Fiction using Retrieval Based Semantic Parsing,"The reader of a choose your own adventure novel and the user of a modern virtual assistant have a subtle similarity; both may, through the right lens, be viewed as engaging with a work of Interactive Fiction. This literary form emerged in the 1970s and has grown like a vine along the branch of modern technology, one guided by the advances of the other. In this work we weave together threads from the Interactive Fiction community and neural semantic parsing for dialog systems, defining the data model and necessary algorithms for a novel type of Interactive Fiction and open sourcing its accompanying authoring tool. Specifically, our work integrates retrieval based semantic parsing predicates into the branching story structures well known to the Interactive Fiction community, relaxing the relatively strict lexical options of preexisting systems.","Usnea: An Authorship Tool for Interactive Fiction using Retrieval Based Semantic Parsing The reader of a choose your own adventure novel and the user of a modern virtual assistant have a subtle similarity; both may, through the right lens, be viewed as engaging with a work of Interactive Fiction. This literary form emerged in the 1970s and has grown like a vine along the branch of modern technology, one guided by the advances of the other. In this work we weave together threads from the Interactive Fiction community and neural semantic parsing for dialog systems, defining the data model and necessary algorithms for a novel type of Interactive Fiction and open sourcing its accompanying authoring tool. Specifically, our work integrates retrieval based semantic parsing predicates into the branching story structures well known to the Interactive Fiction community, relaxing the relatively strict lexical options of preexisting systems.","usnea : authorship tool interactive fiction retrieval base semantic parsing reader choose adventure novel user modern virtual assistant subtle similarity ; , right lens , view engage work interactive fiction . literary form emerge 1970 grow like vine branch modern technology , guide advance . work weave thread interactive fiction community neural semantic parsing dialog system , define datum model necessary algorithm novel type interactive fiction open source accompany authoring tool . specifically , work integrate retrieval base semantic parsing predicate branch story structure known interactive fiction community , relax relatively strict lexical option preexist system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 3, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 9, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 11, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,"MMPE: A Multi-Modal Interface using Handwriting, Touch Reordering, and Speech Commands for Post-Editing Machine Translation","The shift from traditional translation to postediting (PE) of machine-translated (MT) text can save time and reduce errors, but it also affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than mouse and keyboard, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. Users can directly cross out or hand-write new text, drag and drop words for reordering, or use spoken commands to update the text in place. All text manipulations are logged in an easily interpretable format to simplify subsequent translation process research. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions. Overall, experiment participants were enthusiastic about the new modalities and saw them as useful extensions to mouse & keyboard, but not as a complete substitute.","MMPE: A Multi-Modal Interface using Handwriting, Touch Reordering, and Speech Commands for Post-Editing Machine Translation The shift from traditional translation to postediting (PE) of machine-translated (MT) text can save time and reduce errors, but it also affects the design of translation interfaces, as the task changes from mainly generating text to correcting errors within otherwise helpful translation proposals. Since this paradigm shift offers potential for modalities other than mouse and keyboard, we present MMPE, the first prototype to combine traditional input modes with pen, touch, and speech modalities for PE of MT. Users can directly cross out or hand-write new text, drag and drop words for reordering, or use spoken commands to update the text in place. All text manipulations are logged in an easily interpretable format to simplify subsequent translation process research. The results of an evaluation with professional translators suggest that pen and touch interaction are suitable for deletion and reordering tasks, while speech and multi-modal combinations of select & speech are considered suitable for replacements and insertions. Overall, experiment participants were enthusiastic about the new modalities and saw them as useful extensions to mouse & keyboard, but not as a complete substitute.","mmpe : multi - modal interface handwriting , touch reordering , speech command post - editing machine translation shift traditional translation postediting ( pe ) machine - translate ( mt ) text save time reduce error , affect design translation interface , task change mainly generate text correct error helpful translation proposal . paradigm shift offer potential modality mouse keyboard , present mmpe , prototype combine traditional input mode pen , touch , speech modality pe mt . user directly cross hand - write new text , drag drop word reordering , use speak command update text place . text manipulation log easily interpretable format simplify subsequent translation process research . result evaluation professional translator suggest pen touch interaction suitable deletion reordering task , speech multi - modal combination select & speech consider suitable replacement insertion . overall , experiment participant enthusiastic new modality see useful extension mouse & keyboard , complete substitute .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 8, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 4, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 7, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
System Demonstrations,Penman: An Open-Source Library and Tool for AMR Graphs,"Meaning Representation (AMR) (Banarescu et al., 2013) is a framework for semantic dependencies that encodes its rooted and directed acyclic graphs in a format called PENMAN notation. The format is simple enough that users of AMR data often write small scripts or libraries for parsing it into an internal graph representation, but there is enough complexity that these users could benefit from a more sophisticated and well-tested solution. The open-source Python library Penman provides a robust parser, functions for graph inspection and manipulation, and functions for formatting graphs into PENMAN notation. Many functions are also available in a command-line tool, thus extending its utility to non-Python setups.","Penman: An Open-Source Library and Tool for AMR Graphs Meaning Representation (AMR) (Banarescu et al., 2013) is a framework for semantic dependencies that encodes its rooted and directed acyclic graphs in a format called PENMAN notation. The format is simple enough that users of AMR data often write small scripts or libraries for parsing it into an internal graph representation, but there is enough complexity that these users could benefit from a more sophisticated and well-tested solution. The open-source Python library Penman provides a robust parser, functions for graph inspection and manipulation, and functions for formatting graphs into PENMAN notation. Many functions are also available in a command-line tool, thus extending its utility to non-Python setups.","penman : open - source library tool amr graphs meaning representation ( amr ) ( banarescu et al . , 2013 ) framework semantic dependency encode root direct acyclic graph format call penman notation . format simple user amr datum write small script library parse internal graph representation , complexity user benefit sophisticated - test solution . open - source python library penman provide robust parser , function graph inspection manipulation , function format graph penman notation . function available command - line tool , extend utility non - python setup .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 6, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 7, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,Stanza: A Python Natural Language Processing Toolkit for Many Human Languages,"We introduce Sta n z a , an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Sta n z a features a language-agnostic fully neural pipeline for text analysis, including tokenization, multiword token expansion, lemmatization, part-ofspeech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Sta n z a on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Sta n z a includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https:// stanfordnlp.github.io/stanza/.","Stanza: A Python Natural Language Processing Toolkit for Many Human Languages We introduce Sta n z a , an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Sta n z a features a language-agnostic fully neural pipeline for text analysis, including tokenization, multiword token expansion, lemmatization, part-ofspeech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Sta n z a on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Sta n z a includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https:// stanfordnlp.github.io/stanza/.","stanza : python natural language processing toolkit human language introduce sta n z , open - source python natural language processing toolkit support 66 human language . compare exist widely toolkit , sta n z feature language - agnostic fully neural pipeline text analysis , include tokenization , multiword token expansion , lemmatization , - ofspeech morphological feature tagging , dependency parsing , name entity recognition . train sta n z total 112 dataset , include universal dependencies treebank multilingual corpus , neural architecture generalize achieve competitive performance language test . additionally , sta n z include native python interface widely java stanford corenlp software , extend functionality cover task coreference resolution relation extraction . source code , documentation , pretrained model 66 language available https:// stanfordnlp.github.io/stanza/.","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 5, 'Student Research Workshop': 1, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 4, 'System Demonstrations': 7, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
System Demonstrations,Trialstreamer: Mapping and Browsing Medical Evidence in Real-Time,"We introduce Trialstreamer, a living database of clinical trial reports. Here we mainly describe the evidence extraction component; this extracts from biomedical abstracts key pieces of information that clinicians need when appraising the literature, and also the relations between these. Specifically, the system extracts descriptions of trial participants, the treatments compared in each arm (the interventions), and which outcomes were measured. The system then attempts to infer which interventions were reported to work best by determining their relationship with identified trial outcome measures. In addition to summarizing individual trials, these extracted data elements allow automatic synthesis of results across many trials on the same topic. We apply the system at scale to all reports of randomized controlled trials indexed in MEDLINE, powering the automatic generation of evidence maps, which provide a global view of the efficacy of different interventions combining data from all relevant clinical trials on a topic. We make all code and models freely available 1 alongside a demonstration of the web interface. 2","Trialstreamer: Mapping and Browsing Medical Evidence in Real-Time We introduce Trialstreamer, a living database of clinical trial reports. Here we mainly describe the evidence extraction component; this extracts from biomedical abstracts key pieces of information that clinicians need when appraising the literature, and also the relations between these. Specifically, the system extracts descriptions of trial participants, the treatments compared in each arm (the interventions), and which outcomes were measured. The system then attempts to infer which interventions were reported to work best by determining their relationship with identified trial outcome measures. In addition to summarizing individual trials, these extracted data elements allow automatic synthesis of results across many trials on the same topic. We apply the system at scale to all reports of randomized controlled trials indexed in MEDLINE, powering the automatic generation of evidence maps, which provide a global view of the efficacy of different interventions combining data from all relevant clinical trials on a topic. We make all code and models freely available 1 alongside a demonstration of the web interface. 2","trialstreamer : map browse medical evidence real - time introduce trialstreamer , live database clinical trial report . mainly describe evidence extraction component ; extract biomedical abstract key piece information clinician need appraise literature , relation . specifically , system extract description trial participant , treatment compare arm ( intervention ) , outcome measure . system attempt infer intervention report work well determine relationship identify trial outcome measure . addition summarize individual trial , extract data element allow automatic synthesis result trial topic . apply system scale report randomized controlled trial index medline , power automatic generation evidence map , provide global view efficacy different intervention combine datum relevant clinical trial topic . code model freely available 1 alongside demonstration web interface . 2","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models,"Large Transformer-based language models can route and reshape complex information via their multi-headed attention mechanism. Although the attention never receives explicit supervision, it can exhibit recognizable patterns following linguistic or positional information. Analyzing the learned representations and attentions is paramount to furthering our understanding of the inner workings of these models. However, analyses have to catch up with the rapid release of new models and the growing diversity of investigation techniques. To support analysis for a wide variety of models, we introduce EXBERT, a tool to help humans conduct flexible, interactive investigations and formulate hypotheses for the model-internal reasoning process. EXBERT provides insights into the meaning of the contextual representations and attention by matching a humanspecified input to similar contexts in large annotated datasets. By aggregating the annotations of the matched contexts, EXBERT can quickly replicate findings from literature and extend them to previously not analyzed models.","exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models Large Transformer-based language models can route and reshape complex information via their multi-headed attention mechanism. Although the attention never receives explicit supervision, it can exhibit recognizable patterns following linguistic or positional information. Analyzing the learned representations and attentions is paramount to furthering our understanding of the inner workings of these models. However, analyses have to catch up with the rapid release of new models and the growing diversity of investigation techniques. To support analysis for a wide variety of models, we introduce EXBERT, a tool to help humans conduct flexible, interactive investigations and formulate hypotheses for the model-internal reasoning process. EXBERT provides insights into the meaning of the contextual representations and attention by matching a humanspecified input to similar contexts in large annotated datasets. By aggregating the annotations of the matched contexts, EXBERT can quickly replicate findings from literature and extend them to previously not analyzed models.","exbert : visual analysis tool explore learn representation transformer model large transformer - base language model route reshape complex information multi - headed attention mechanism . attention receive explicit supervision , exhibit recognizable pattern follow linguistic positional information . analyze learn representation attention paramount further understanding inner working model . , analysis catch rapid release new model grow diversity investigation technique . support analysis wide variety model , introduce exbert , tool help human conduct flexible , interactive investigation formulate hypothesis model - internal reasoning process . exbert provide insight meaning contextual representation attention match humanspecifie input similar context large annotate dataset . aggregate annotation match context , exbert quickly replicate finding literature extend previously analyze model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
System Demonstrations,Torch-Struct: Deep Structured Prediction Library,"The literature on structured prediction for NLP describes a rich collection of distributions and algorithms over sequences, segmentations, alignments, and trees; however, these algorithms are difficult to utilize in deep learning frameworks. We introduce Torch-Struct, a library for structured prediction designed to take advantage of and integrate with vectorized, auto-differentiation based frameworks. Torch-Struct includes a broad collection of probabilistic structures accessed through a simple and flexible distribution-based API that connects to any deep learning model. The library utilizes batched, vectorized operations and exploits auto-differentiation to produce readable, fast, and testable code. Internally, we also include a number of general-purpose optimizations to provide cross-algorithm efficiency. Experiments show significant performance gains over fast baselines. Case studies demonstrate the benefits of the library. Torch-Struct is available at https://github.com/ harvardnlp/pytorch-struct.","Torch-Struct: Deep Structured Prediction Library The literature on structured prediction for NLP describes a rich collection of distributions and algorithms over sequences, segmentations, alignments, and trees; however, these algorithms are difficult to utilize in deep learning frameworks. We introduce Torch-Struct, a library for structured prediction designed to take advantage of and integrate with vectorized, auto-differentiation based frameworks. Torch-Struct includes a broad collection of probabilistic structures accessed through a simple and flexible distribution-based API that connects to any deep learning model. The library utilizes batched, vectorized operations and exploits auto-differentiation to produce readable, fast, and testable code. Internally, we also include a number of general-purpose optimizations to provide cross-algorithm efficiency. Experiments show significant performance gains over fast baselines. Case studies demonstrate the benefits of the library. Torch-Struct is available at https://github.com/ harvardnlp/pytorch-struct.","torch - struct : deep structured prediction library literature structured prediction nlp describe rich collection distribution algorithm sequence , segmentation , alignment , tree ; , algorithm difficult utilize deep learning framework . introduce torch - struct , library structured prediction design advantage integrate vectorized , auto - differentiation base framework . torch - struct include broad collection probabilistic structure access simple flexible distribution - base api connect deep learning model . library utilize batched , vectorized operation exploit auto - differentiation produce readable , fast , testable code . internally , include number general - purpose optimization provide cross - algorithm efficiency . experiment significant performance gain fast baseline . case study demonstrate benefit library . torch - struct available https://github.com/ harvardnlp / pytorch - struct .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
System Demonstrations,The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding,"We present MT-DNN 1 , an open-source natural language understanding (NLU) toolkit that makes it easy for researchers and developers to train customized deep learning models. Built upon PyTorch and Transformers, MT-DNN is designed to facilitate rapid customization for a broad spectrum of NLU tasks, using a variety of objectives (classification, regression, structured prediction) and text encoders (e.g., RNNs, BERT, RoBERTa, UniLM). A unique feature of MT-DNN is its built-in support for robust and transferable learning using the adversarial multi-task learning paradigm. To enable efficient production deployment, MT-DNN supports multitask knowledge distillation, which can substantially compress a deep neural model without significant performance drop. We demonstrate the effectiveness of MT-DNN on a wide range of NLU applications across general and biomedical domains. The software and pretrained models will be publicly available at https://github.com/namisan/mt-dnn. * Equal Contribution. 1 The complete name of our toolkit is M T 2 -DNN (The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding), but we use MT-DNN for sake of simplicity.","The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding We present MT-DNN 1 , an open-source natural language understanding (NLU) toolkit that makes it easy for researchers and developers to train customized deep learning models. Built upon PyTorch and Transformers, MT-DNN is designed to facilitate rapid customization for a broad spectrum of NLU tasks, using a variety of objectives (classification, regression, structured prediction) and text encoders (e.g., RNNs, BERT, RoBERTa, UniLM). A unique feature of MT-DNN is its built-in support for robust and transferable learning using the adversarial multi-task learning paradigm. To enable efficient production deployment, MT-DNN supports multitask knowledge distillation, which can substantially compress a deep neural model without significant performance drop. We demonstrate the effectiveness of MT-DNN on a wide range of NLU applications across general and biomedical domains. The software and pretrained models will be publicly available at https://github.com/namisan/mt-dnn. * Equal Contribution. 1 The complete name of our toolkit is M T 2 -DNN (The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding), but we use MT-DNN for sake of simplicity.","microsoft toolkit multi - task deep neural networks natural language understanding present mt - dnn 1 , open - source natural language understanding ( nlu ) toolkit make easy researcher developer train customize deep learning model . build pytorch transformers , mt - dnn design facilitate rapid customization broad spectrum nlu task , variety objective ( classification , regression , structured prediction ) text encoder ( e.g. , rnn , bert , roberta , unilm ) . unique feature mt - dnn build - support robust transferable learning adversarial multi - task learning paradigm . enable efficient production deployment , mt - dnn support multitask knowledge distillation , substantially compress deep neural model significant performance drop . demonstrate effectiveness mt - dnn wide range nlu application general biomedical domain . software pretrained model publicly available https://github.com/namisan/mt-dnn . * equal contribution . 1 complete toolkit m t 2 -dnn ( microsoft toolkit multi - task deep neural networks natural language understanding ) , use mt - dnn sake simplicity .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 9, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",System Demonstrations,True
System Demonstrations,Syntactic Search by Example,"We present a system that allows a user to search a large linguistically annotated corpus using syntactic patterns over dependency graphs. In contrast to previous attempts to this effect, we introduce a light-weight query language that does not require the user to know the details of the underlying syntactic representations, and instead to query the corpus by providing an example sentence coupled with simple markup. Search is performed at an interactive speed due to an efficient linguistic graphindexing and retrieval engine. This allows for rapid exploration, development and refinement of syntax-based queries. We demonstrate the system using queries over two corpora: the English wikipedia, and a collection of English pubmed abstracts. A demo of the wikipedia system is avilable at: https: //allenai.github.io/spike/ .","Syntactic Search by Example We present a system that allows a user to search a large linguistically annotated corpus using syntactic patterns over dependency graphs. In contrast to previous attempts to this effect, we introduce a light-weight query language that does not require the user to know the details of the underlying syntactic representations, and instead to query the corpus by providing an example sentence coupled with simple markup. Search is performed at an interactive speed due to an efficient linguistic graphindexing and retrieval engine. This allows for rapid exploration, development and refinement of syntax-based queries. We demonstrate the system using queries over two corpora: the English wikipedia, and a collection of English pubmed abstracts. A demo of the wikipedia system is avilable at: https: //allenai.github.io/spike/ .","syntactic search example present system allow user search large linguistically annotate corpus syntactic pattern dependency graph . contrast previous attempt effect , introduce light - weight query language require user know detail underlie syntactic representation , instead query corpus provide example sentence couple simple markup . search perform interactive speed efficient linguistic graphindexing retrieval engine . allow rapid exploration , development refinement syntax - base query . demonstrate system query corpora : english wikipedia , collection english pubme abstract . demo wikipedia system avilable : https : //allenai.github.io / spike/ .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 9, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",System Demonstrations,True
System Demonstrations,TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing,"In this paper, we introduce TextBrewer, an open-source knowledge distillation toolkit designed for natural language processing. It works with different neural network models and supports various kinds of supervised learning tasks, such as text classification, reading comprehension, sequence labeling. TextBrewer provides a simple and uniform workflow that enables quick setting up of distillation experiments with highly flexible configurations. It offers a set of predefined distillation methods and can be extended with custom code. As a case study, we use TextBrewer to distill BERT on several typical NLP tasks. With simple configurations, we achieve results that are comparable with or even higher than the public distilled BERT models with similar numbers of parameters. 1","TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing In this paper, we introduce TextBrewer, an open-source knowledge distillation toolkit designed for natural language processing. It works with different neural network models and supports various kinds of supervised learning tasks, such as text classification, reading comprehension, sequence labeling. TextBrewer provides a simple and uniform workflow that enables quick setting up of distillation experiments with highly flexible configurations. It offers a set of predefined distillation methods and can be extended with custom code. As a case study, we use TextBrewer to distill BERT on several typical NLP tasks. With simple configurations, we achieve results that are comparable with or even higher than the public distilled BERT models with similar numbers of parameters. 1","textbrewer : open - source knowledge distillation toolkit natural language processing paper , introduce textbrewer , open - source knowledge distillation toolkit design natural language processing . work different neural network model support kind supervise learning task , text classification , reading comprehension , sequence labeling . textbrewer provide simple uniform workflow enable quick setting distillation experiment highly flexible configuration . offer set predefine distillation method extend custom code . case study , use textbrewer distill bert typical nlp task . simple configuration , achieve result comparable high public distil bert model similar number parameter . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 3, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
System Demonstrations,MixingBoard: a Knowledgeable Stylized Integrated Text Generation Platform,"We present MIXINGBOARD, a platform for quickly building demos with a focus on knowledge grounded stylized text generation. We unify existing text generation algorithms in a shared codebase and further adapt earlier algorithms for constrained generation. To borrow advantages from different models, we implement strategies for cross-model integration, from the token probability level to the latent space level. An interface to external knowledge is provided via a module that retrieves onthe-fly relevant knowledge from passages on the web or any document collection. A user interface for local development, remote webpage access, and a RESTful API are provided to make it simple for users to build their own demos 1 .","MixingBoard: a Knowledgeable Stylized Integrated Text Generation Platform We present MIXINGBOARD, a platform for quickly building demos with a focus on knowledge grounded stylized text generation. We unify existing text generation algorithms in a shared codebase and further adapt earlier algorithms for constrained generation. To borrow advantages from different models, we implement strategies for cross-model integration, from the token probability level to the latent space level. An interface to external knowledge is provided via a module that retrieves onthe-fly relevant knowledge from passages on the web or any document collection. A user interface for local development, remote webpage access, and a RESTful API are provided to make it simple for users to build their own demos 1 .","mixingboard : knowledgeable stylized integrate text generation platform present mixingboard , platform quickly build demo focus knowledge ground stylized text generation . unify exist text generation algorithm share codebase adapt early algorithm constrain generation . borrow advantage different model , implement strategy cross - model integration , token probability level latent space level . interface external knowledge provide module retrieve onthe - fly relevant knowledge passage web document collection . user interface local development , remote webpage access , restful api provide simple user build demo 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 10, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
System Demonstrations,Conversation Learner - A Machine Teaching Tool for Building Dialog Managers for Task-Oriented Dialog Systems,"Traditionally, industry solutions for building a task-oriented dialog system have relied on helping dialog authors define rule-based dialog managers, represented as dialog flows. While dialog flows are intuitively interpretable and good for simple scenarios, they fall short of performance in terms of the flexibility needed to handle complex dialogs. On the other hand, purely machine-learned models can handle complex dialogs, but they are considered to be black boxes and require large amounts of training data. In this demonstration, we showcase Conversation Learner, a machine teaching tool for building dialog managers. It combines the best of both approaches by enabling dialog authors to create a dialog flow using familiar tools, converting the dialog flow into a parametric model (e.g., neural networks), and allowing dialog authors to improve the dialog manager (i.e., the parametric model) over time by leveraging user-system dialog logs as training data through a machine teaching interface.","Conversation Learner - A Machine Teaching Tool for Building Dialog Managers for Task-Oriented Dialog Systems Traditionally, industry solutions for building a task-oriented dialog system have relied on helping dialog authors define rule-based dialog managers, represented as dialog flows. While dialog flows are intuitively interpretable and good for simple scenarios, they fall short of performance in terms of the flexibility needed to handle complex dialogs. On the other hand, purely machine-learned models can handle complex dialogs, but they are considered to be black boxes and require large amounts of training data. In this demonstration, we showcase Conversation Learner, a machine teaching tool for building dialog managers. It combines the best of both approaches by enabling dialog authors to create a dialog flow using familiar tools, converting the dialog flow into a parametric model (e.g., neural networks), and allowing dialog authors to improve the dialog manager (i.e., the parametric model) over time by leveraging user-system dialog logs as training data through a machine teaching interface.","conversation learner - machine teaching tool build dialog manager task - orient dialog system traditionally , industry solution build task - orient dialog system rely help dialog author define rule - base dialog manager , represent dialog flow . dialog flow intuitively interpretable good simple scenario , fall short performance term flexibility need handle complex dialog . hand , purely machine - learn model handle complex dialog , consider black box require large amount training datum . demonstration , showcase conversation learner , machine teaching tool build dialog manager . combine good approach enable dialog author create dialog flow familiar tool , convert dialog flow parametric model ( e.g. , neural network ) , allow dialog author improve dialog manager ( i.e. , parametric model ) time leverage user - system dialog log training datum machine teaching interface .","{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 20, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 8, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
System Demonstrations,jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models,"We introduce jiant, an open source toolkit for conducting multitask and transfer learning experiments on English NLU tasks. jiant enables modular and configuration-driven experimentation with state-of-the-art models and implements a broad set of tasks for probing, transfer learning, and multitask training experiments. jiant implements over 50 NLU tasks, including all GLUE and SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published performance on a variety of tasks and models, including BERT and RoBERTa. jiant is available at https:// jiant.info. * Equal contribution. 1 The name jiant stands for ""jiant is an NLP toolkit"".","jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models We introduce jiant, an open source toolkit for conducting multitask and transfer learning experiments on English NLU tasks. jiant enables modular and configuration-driven experimentation with state-of-the-art models and implements a broad set of tasks for probing, transfer learning, and multitask training experiments. jiant implements over 50 NLU tasks, including all GLUE and SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published performance on a variety of tasks and models, including BERT and RoBERTa. jiant is available at https:// jiant.info. * Equal contribution. 1 The name jiant stands for ""jiant is an NLP toolkit"".","jiant : software toolkit research general - purpose text understanding models introduce jiant , open source toolkit conduct multitask transfer learning experiment english nlu task . jiant enable modular configuration - drive experimentation state - - - art model implement broad set task probe , transfer learning , multitask training experiment . jiant implement 50 nlu task , include glue superglue benchmark task . demonstrate jiant reproduce publish performance variety task model , include bert roberta . jiant available https:// jiant.info . * equal contribution . 1 jiant stand "" jiant nlp toolkit "" .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 8, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,"ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents","We present ADVISER 1 -an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision), sociallyengaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The final Python-based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research.","ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents We present ADVISER 1 -an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision), sociallyengaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The final Python-based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research.","adviser : toolkit develop multi - modal , multi - domain socially - engaged conversational agent present adviser 1 -an open - source , multi - domain dialog system toolkit enable development multi - modal ( incorporate speech , text vision ) , sociallyengaged ( e.g. emotion recognition , engagement level prediction backchanneling ) conversational agent . final python - base implementation toolkit flexible , easy use , easy extend technically experienced user , machine learning researcher , technically experienced user , linguist cognitive scientist , provide flexible platform collaborative research .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 3, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 11, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,"ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems","We present ConvLab-2, an open-source toolkit that enables researchers to build task-oriented dialogue systems with state-of-the-art models, perform an end-to-end evaluation, and diagnose the weakness of systems. As the successor of ConvLab (Lee et al., 2019b), ConvLab-2 inherits ConvLab's framework but integrates more powerful dialogue models and supports more datasets. Besides, we have developed an analysis tool and an interactive tool to assist researchers in diagnosing dialogue systems. The analysis tool presents rich statistics and summarizes common mistakes from simulated dialogues, which facilitates error analysis and system improvement. The interactive tool provides a user interface that allows developers to diagnose an assembled dialogue system by interacting with the system and modifying the output of each system component.","ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems We present ConvLab-2, an open-source toolkit that enables researchers to build task-oriented dialogue systems with state-of-the-art models, perform an end-to-end evaluation, and diagnose the weakness of systems. As the successor of ConvLab (Lee et al., 2019b), ConvLab-2 inherits ConvLab's framework but integrates more powerful dialogue models and supports more datasets. Besides, we have developed an analysis tool and an interactive tool to assist researchers in diagnosing dialogue systems. The analysis tool presents rich statistics and summarizes common mistakes from simulated dialogues, which facilitates error analysis and system improvement. The interactive tool provides a user interface that allows developers to diagnose an assembled dialogue system by interacting with the system and modifying the output of each system component.","convlab-2 : open - source toolkit build , evaluate , diagnose dialogue system present convlab-2 , open - source toolkit enable researcher build task - orient dialogue system state - - - art model , perform end - - end evaluation , diagnose weakness system . successor convlab ( lee et al . , 2019b ) , convlab-2 inherit convlab framework integrate powerful dialogue model support dataset . , develop analysis tool interactive tool assist researcher diagnose dialogue system . analysis tool present rich statistic summarize common mistake simulate dialogue , facilitate error analysis system improvement . interactive tool provide user interface allow developer diagnose assemble dialogue system interact system modify output system component .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 17, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 22, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,Photon: A Robust Cross-Domain Text-to-SQL System,"Natural language interfaces to databases (NLIDB) democratize end user access to relational data. Due to fundamental differences between natural language communication and programming, it is common for end users to issue questions that are ambiguous to the system or fall outside the semantic scope of its underlying query language. We present PHO-TON, a robust, modular, cross-domain NLIDB that can flag natural language input to which a SQL mapping cannot be immediately determined. PHOTON consists of a strong neural semantic parser (63.2% structure accuracy on the Spider dev benchmark), a human-in-theloop question corrector, a SQL executor and a response generator. The question corrector is a discriminative neural sequence editor which detects confusion span(s) in the input question and suggests rephrasing until a translatable input is given by the user or a maximum number of iterations are conducted. Experiments on simulated data show that the proposed method effectively improves the robustness of text-to-SQL system against untranslatable user input. The live demo of our system is available at http://www.naturalsql.com. * Equal contribution. Jichuan implemented the demo interaction flow and the neural question corrector. Victoria designed and implemented the neural semantic parser. â€  Work done during internship at Salesforce Research.","Photon: A Robust Cross-Domain Text-to-SQL System Natural language interfaces to databases (NLIDB) democratize end user access to relational data. Due to fundamental differences between natural language communication and programming, it is common for end users to issue questions that are ambiguous to the system or fall outside the semantic scope of its underlying query language. We present PHO-TON, a robust, modular, cross-domain NLIDB that can flag natural language input to which a SQL mapping cannot be immediately determined. PHOTON consists of a strong neural semantic parser (63.2% structure accuracy on the Spider dev benchmark), a human-in-theloop question corrector, a SQL executor and a response generator. The question corrector is a discriminative neural sequence editor which detects confusion span(s) in the input question and suggests rephrasing until a translatable input is given by the user or a maximum number of iterations are conducted. Experiments on simulated data show that the proposed method effectively improves the robustness of text-to-SQL system against untranslatable user input. The live demo of our system is available at http://www.naturalsql.com. * Equal contribution. Jichuan implemented the demo interaction flow and the neural question corrector. Victoria designed and implemented the neural semantic parser. â€  Work done during internship at Salesforce Research.","photon : robust cross - domain text - - sql system natural language interface database ( nlidb ) democratize end user access relational datum . fundamental difference natural language communication programming , common end user issue question ambiguous system fall outside semantic scope underlie query language . present pho - ton , robust , modular , cross - domain nlidb flag natural language input sql mapping immediately determine . photon consist strong neural semantic parser ( 63.2 % structure accuracy spider dev benchmark ) , human - - theloop question corrector , sql executor response generator . question corrector discriminative neural sequence editor detect confusion span(s ) input question suggest rephrase translatable input give user maximum number iteration conduct . experiment simulated datum propose method effectively improve robustness text - - sql system untranslatable user input . live demo system available http://www.naturalsql.com . * equal contribution . jichuan implement demo interaction flow neural question corrector . victoria design implement neural semantic parser . â€  work internship salesforce research .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 4, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 5, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 7, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'System Demonstrations': 10, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,Tabouid: a Wikipedia-based word guessing game,"We present Tabouid, a word-guessing game automatically generated from Wikipedia. Tabouid contains 10,000 (virtual) cards in English, and as many in French, covering not only words and linguistic expressions but also a variety of topics including artists, historical events or scientific concepts. Each card corresponds to a Wikipedia article, and conversely, any article could be turned into a card. A range of relatively simple NLP and machine-learning techniques are effectively integrated into a two-stage process. First, a large subset of Wikipedia articles are scored -this score estimates the difficulty, or alternatively, the playability of the page. Then, the best articles are turned into cards by selecting, for each of them, a list of banned words based on its content. We believe that the game we present is more than mere entertainment and that, furthermore, this paper has pedagogical potential. 1","Tabouid: a Wikipedia-based word guessing game We present Tabouid, a word-guessing game automatically generated from Wikipedia. Tabouid contains 10,000 (virtual) cards in English, and as many in French, covering not only words and linguistic expressions but also a variety of topics including artists, historical events or scientific concepts. Each card corresponds to a Wikipedia article, and conversely, any article could be turned into a card. A range of relatively simple NLP and machine-learning techniques are effectively integrated into a two-stage process. First, a large subset of Wikipedia articles are scored -this score estimates the difficulty, or alternatively, the playability of the page. Then, the best articles are turned into cards by selecting, for each of them, a list of banned words based on its content. We believe that the game we present is more than mere entertainment and that, furthermore, this paper has pedagogical potential. 1","tabouid : wikipedia - base word guessing game present tabouid , word - guessing game automatically generate wikipedia . tabouid contain 10,000 ( virtual ) card english , french , cover word linguistic expression variety topic include artist , historical event scientific concept . card correspond wikipedia article , conversely , article turn card . range relatively simple nlp machine - learning technique effectively integrate - stage process . , large subset wikipedia article score -this score estimate difficulty , alternatively , playability page . , good article turn card select , , list ban word base content . believe game present mere entertainment , furthermore , paper pedagogical potential . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 2, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 4, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
System Demonstrations,EVIDENCEMINER: Textual Evidence Discovery for Life Sciences,"Traditional search engines for life sciences (e.g., PubMed) are designed for document retrieval and do not allow direct retrieval of specific statements. Some of these statements may serve as textual evidence that is key to tasks such as hypothesis generation and new finding validation. We present EVIDENCEM-INER, a web-based system that lets users query a natural language statement and automatically retrieves textual evidence from a background corpora for life sciences. EVIDENCEMINER is constructed in a completely automated way without any human effort for training data annotation. It is supported by novel data-driven methods for distantly supervised named entity recognition and open information extraction. The entities and patterns are pre-computed and indexed offline to support fast online evidence retrieval. The annotation results are also highlighted in the original document for better visualization. EVIDENCEMINER also includes analytic functionalities such as the most frequent entity and relation summarization. EVIDENCEMINER can help scientists uncover essential research issues, leading to more effective research and more indepth quantitative analysis. The system of EVIDENCEMINER is available at https:// evidenceminer.firebaseapp.com/ 1 .","EVIDENCEMINER: Textual Evidence Discovery for Life Sciences Traditional search engines for life sciences (e.g., PubMed) are designed for document retrieval and do not allow direct retrieval of specific statements. Some of these statements may serve as textual evidence that is key to tasks such as hypothesis generation and new finding validation. We present EVIDENCEM-INER, a web-based system that lets users query a natural language statement and automatically retrieves textual evidence from a background corpora for life sciences. EVIDENCEMINER is constructed in a completely automated way without any human effort for training data annotation. It is supported by novel data-driven methods for distantly supervised named entity recognition and open information extraction. The entities and patterns are pre-computed and indexed offline to support fast online evidence retrieval. The annotation results are also highlighted in the original document for better visualization. EVIDENCEMINER also includes analytic functionalities such as the most frequent entity and relation summarization. EVIDENCEMINER can help scientists uncover essential research issues, leading to more effective research and more indepth quantitative analysis. The system of EVIDENCEMINER is available at https:// evidenceminer.firebaseapp.com/ 1 .","evidenceminer : textual evidence discovery life science traditional search engine life science ( e.g. , pubmed ) design document retrieval allow direct retrieval specific statement . statement serve textual evidence key task hypothesis generation new finding validation . present evidencem - iner , web - base system let user query natural language statement automatically retrieve textual evidence background corpora life science . evidenceminer construct completely automate way human effort training datum annotation . support novel data - drive method distantly supervise name entity recognition open information extraction . entity pattern pre - compute index offline support fast online evidence retrieval . annotation result highlight original document well visualization . evidenceminer include analytic functionality frequent entity relation summarization . evidenceminer help scientist uncover essential research issue , lead effective research indepth quantitative analysis . system evidenceminer available https:// evidenceminer.firebaseapp.com/ 1 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 17, 'Information Retrieval and Text Mining': 5, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 2, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
System Demonstrations,LEAN-LIFE: A Label-Efficient Annotation Framework Towards Learning from Explanation,"Successfully training a deep neural network demands a huge corpus of labeled data. However, each label only provides limited information to learn from and collecting the requisite number of labels involves massive human effort. In this work, we introduce LEAN-LIFE 1 , a web-based, Label-Efficient AnnotatioN framework for sequence labeling and classification tasks, with an easy-to-use UI that not only allows an annotator to provide the needed labels for a task, but also enables LearnIng From Explanations for each labeling decision. Such explanations enable us to generate useful additional labeled data from unlabeled instances, bolstering the pool of available training data. On three popular NLP tasks (named entity recognition, relation extraction, sentiment analysis), we find that using this enhanced supervision allows our models to surpass competitive baseline F1 scores by more than 5-10 percentage points, while using 2X times fewer labeled instances. Our framework is the first to utilize this enhanced supervision technique and does so for three important tasks--thus providing improved annotation recommendations to users and an ability to build datasets of (data, label, explanation) triples instead of the regular (data, label) pair.","LEAN-LIFE: A Label-Efficient Annotation Framework Towards Learning from Explanation Successfully training a deep neural network demands a huge corpus of labeled data. However, each label only provides limited information to learn from and collecting the requisite number of labels involves massive human effort. In this work, we introduce LEAN-LIFE 1 , a web-based, Label-Efficient AnnotatioN framework for sequence labeling and classification tasks, with an easy-to-use UI that not only allows an annotator to provide the needed labels for a task, but also enables LearnIng From Explanations for each labeling decision. Such explanations enable us to generate useful additional labeled data from unlabeled instances, bolstering the pool of available training data. On three popular NLP tasks (named entity recognition, relation extraction, sentiment analysis), we find that using this enhanced supervision allows our models to surpass competitive baseline F1 scores by more than 5-10 percentage points, while using 2X times fewer labeled instances. Our framework is the first to utilize this enhanced supervision technique and does so for three important tasks--thus providing improved annotation recommendations to users and an ability to build datasets of (data, label, explanation) triples instead of the regular (data, label) pair.","lean - life : label - efficient annotation framework learn explanation successfully train deep neural network demand huge corpus label datum . , label provide limited information learn collect requisite number label involve massive human effort . work , introduce lean - life 1 , web - base , label - efficient annotation framework sequence labeling classification task , easy - - use ui allow annotator provide need label task , enable learning explanations labeling decision . explanation enable generate useful additional label datum unlabeled instance , bolster pool available training datum . popular nlp task ( name entity recognition , relation extraction , sentiment analysis ) , find enhance supervision allow model surpass competitive baseline f1 score 5 - 10 percentage point , 2x time few label instance . framework utilize enhance supervision technique important task -- provide improved annotation recommendation user ability build dataset ( data , label , explanation ) triple instead regular ( data , label ) pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 5, 'Speech and Multimodality': 2, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
System Demonstrations,Talk to Papers: Bringing Neural Question Answering to Academic Search,"We introduce Talk to Papers 1 , which exploits the recent open-domain question answering (QA) techniques to improve the current experience of academic search. It's designed to enable researchers to use natural language queries to find precise answers and extract insights from a massive amount of academic papers. We present a large improvement over classic search engine baseline on several standard QA datasets, and provide the community a collaborative data collection tool to curate the first natural language processing research QA dataset via a community effort.","Talk to Papers: Bringing Neural Question Answering to Academic Search We introduce Talk to Papers 1 , which exploits the recent open-domain question answering (QA) techniques to improve the current experience of academic search. It's designed to enable researchers to use natural language queries to find precise answers and extract insights from a massive amount of academic papers. We present a large improvement over classic search engine baseline on several standard QA datasets, and provide the community a collaborative data collection tool to curate the first natural language processing research QA dataset via a community effort.","talk papers : bring neural question answering academic search introduce talk papers 1 , exploit recent open - domain question answering ( qa ) technique improve current experience academic search . design enable researcher use natural language query find precise answer extract insight massive academic paper . present large improvement classic search engine baseline standard qa dataset , provide community collaborative data collection tool curate natural language processing research qa dataset community effort .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 14, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Question Answering,False
System Demonstrations,ESPnet-ST: All-in-One Speech Translation Toolkit,"We present ESPnet-ST, which is designed for the quick development of speech-to-speech translation systems in a single framework. ESPnet-ST is a new project inside end-toend speech processing toolkit, ESPnet, which integrates or newly implements automatic speech recognition, machine translation, and text-to-speech functions for speech translation. We provide all-in-one recipes including data pre-processing, feature extraction, training, and decoding pipelines for a wide range of benchmark datasets. Our reproducible results can match or even outperform the current state-of-the-art performances; these pretrained models are downloadable. The toolkit is publicly available at https://github. com/espnet/espnet.","ESPnet-ST: All-in-One Speech Translation Toolkit We present ESPnet-ST, which is designed for the quick development of speech-to-speech translation systems in a single framework. ESPnet-ST is a new project inside end-toend speech processing toolkit, ESPnet, which integrates or newly implements automatic speech recognition, machine translation, and text-to-speech functions for speech translation. We provide all-in-one recipes including data pre-processing, feature extraction, training, and decoding pipelines for a wide range of benchmark datasets. Our reproducible results can match or even outperform the current state-of-the-art performances; these pretrained models are downloadable. The toolkit is publicly available at https://github. com/espnet/espnet.","espnet - st : - - speech translation toolkit present espnet - st , design quick development speech - - speech translation system single framework . espnet - st new project inside end - toend speech processing toolkit , espnet , integrate newly implement automatic speech recognition , machine translation , text - - speech function speech translation . provide - - recipe include data pre - processing , feature extraction , training , decoding pipeline wide range benchmark dataset . reproducible result match outperform current state - - - art performance ; pretrained model downloadable . toolkit publicly available https://github . com / espnet / espnet .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 7, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 11, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 7, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Speech and Multimodality,False
System Demonstrations,Label Noise in Context,"Label noise-incorrectly or ambiguously labeled training examples-can negatively impact model performance. Although noise detection techniques have been around for decades, practitioners rarely apply them, as manual noise remediation is a tedious process. Examples incorrectly flagged as noise waste reviewers' time, and correcting label noise without guidance can be difficult. We propose LNIC, a noise-detection method that uses an example's neighborhood within the training set to (a) reduce false positives and (b) provide an explanation as to why the example was flagged as noise. We demonstrate on several short-text classification datasets that LNIC outperforms the state of the art on measures of precision and F 0.5 -score. We also show how LNIC's training set context helps a reviewer to understand and correct label noise in a dataset. The LNIC tool lowers the barriers to label noise remediation, increasing its utility for NLP practitioners.","Label Noise in Context Label noise-incorrectly or ambiguously labeled training examples-can negatively impact model performance. Although noise detection techniques have been around for decades, practitioners rarely apply them, as manual noise remediation is a tedious process. Examples incorrectly flagged as noise waste reviewers' time, and correcting label noise without guidance can be difficult. We propose LNIC, a noise-detection method that uses an example's neighborhood within the training set to (a) reduce false positives and (b) provide an explanation as to why the example was flagged as noise. We demonstrate on several short-text classification datasets that LNIC outperforms the state of the art on measures of precision and F 0.5 -score. We also show how LNIC's training set context helps a reviewer to understand and correct label noise in a dataset. The LNIC tool lowers the barriers to label noise remediation, increasing its utility for NLP practitioners.","label noise context label noise - incorrectly ambiguously label training example - negatively impact model performance . noise detection technique decade , practitioner rarely apply , manual noise remediation tedious process . example incorrectly flag noise waste reviewer ' time , correct label noise guidance difficult . propose lnic , noise - detection method use example neighborhood training set ( ) reduce false positive ( b ) provide explanation example flag noise . demonstrate short - text classification dataset lnic outperform state art measure precision f 0.5 -score . lnic training set context help reviewer understand correct label noise dataset . lnic tool lower barrier label noise remediation , increase utility nlp practitioner .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 2, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
System Demonstrations,Personalized PageRank with Syntagmatic Information for Multilingual Word Sense Disambiguation,"Exploiting syntagmatic information is an encouraging research focus to be pursued in an effort to close the gap between knowledge-based and supervised Word Sense Disambiguation (WSD) performance. We follow this direction in our next-generation knowledge-based WSD system, SyntagRank, which we make available via a Web interface and a RESTful API. SyntagRank leverages the disambiguated pairs of cooccurring words included in SyntagNet, a lexical-semantic combination resource, to perform state-of-the-art knowledge-based WSD in a multilingual setting. Our service provides both a user-friendly interface, available at http://syntagnet.org/, and a RESTful endpoint to query the system programmatically (accessible at http://api.syntagnet.org/).","Personalized PageRank with Syntagmatic Information for Multilingual Word Sense Disambiguation Exploiting syntagmatic information is an encouraging research focus to be pursued in an effort to close the gap between knowledge-based and supervised Word Sense Disambiguation (WSD) performance. We follow this direction in our next-generation knowledge-based WSD system, SyntagRank, which we make available via a Web interface and a RESTful API. SyntagRank leverages the disambiguated pairs of cooccurring words included in SyntagNet, a lexical-semantic combination resource, to perform state-of-the-art knowledge-based WSD in a multilingual setting. Our service provides both a user-friendly interface, available at http://syntagnet.org/, and a RESTful endpoint to query the system programmatically (accessible at http://api.syntagnet.org/).","personalized pagerank syntagmatic information multilingual word sense disambiguation exploit syntagmatic information encouraging research focus pursue effort close gap knowledge - base supervised word sense disambiguation ( wsd ) performance . follow direction - generation knowledge - base wsd system , syntagrank , available web interface restful api . syntagrank leverage disambiguated pair cooccurre word include syntagnet , lexical - semantic combination resource , perform state - - - art knowledge - base wsd multilingual setting . service provide user - friendly interface , available http://syntagnet.org/ , restful endpoint query system programmatically ( accessible http://api.syntagnet.org/ ) .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
System Demonstrations,Xiaomingbot: A Multilingual Robot News Reporter,"This paper proposes the building of Xiaomingbot, an intelligent, multilingual and multimodal software robot equipped with four integral capabilities: news generation, news translation, news reading and avatar animation. Its system summarizes Chinese news that it automatically generates from data tables. Next, it translates the summary or the full article into multiple languages, and reads the multilingual rendition through synthesized speech. Notably, Xiaomingbot utilizes a voice cloning technology to synthesize the speech trained from a real person's voice data in one input language. The proposed system enjoys several merits: it has an animated avatar, and is able to generate and read multilingual news. Since it was put into practice, Xiaomingbot has written over 600,000 articles, and gained over 150,000 followers on social media platforms.","Xiaomingbot: A Multilingual Robot News Reporter This paper proposes the building of Xiaomingbot, an intelligent, multilingual and multimodal software robot equipped with four integral capabilities: news generation, news translation, news reading and avatar animation. Its system summarizes Chinese news that it automatically generates from data tables. Next, it translates the summary or the full article into multiple languages, and reads the multilingual rendition through synthesized speech. Notably, Xiaomingbot utilizes a voice cloning technology to synthesize the speech trained from a real person's voice data in one input language. The proposed system enjoys several merits: it has an animated avatar, and is able to generate and read multilingual news. Since it was put into practice, Xiaomingbot has written over 600,000 articles, and gained over 150,000 followers on social media platforms.","xiaomingbot : multilingual robot news reporter paper propose building xiaomingbot , intelligent , multilingual multimodal software robot equip integral capability : news generation , news translation , news reading avatar animation . system summarize chinese news automatically generate datum table . , translate summary article multiple language , read multilingual rendition synthesize speech . notably , xiaomingbot utilize voice clone technology synthesize speech train real person voice datum input language . propose system enjoy merit : animate avatar , able generate read multilingual news . practice , xiaomingbot write 600,000 article , gain 150,000 follower social medium platform .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 3, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 2, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",NLP Applications,False
System Demonstrations,SUPP.AI: finding evidence for supplement-drug interactions,"Dietary supplements are used by a large portion of the population, but information on their pharmacologic interactions is incomplete. To address this challenge, we present SUPP.AI, an application for browsing evidence of supplement-drug interactions (SDIs) extracted from the biomedical literature. We train a model to automatically extract supplement information and identify such interactions from the scientific literature. To address the lack of labeled data for SDI identification, we use labels of the closely related task of identifying drug-drug interactions (DDIs) for supervision. We fine-tune the contextualized word representations of the RoBERTa language model using labeled DDI data, and apply the fine-tuned model to identify supplement interactions. We extract 195k evidence sentences from 22M articles (P=0.82, R=0.58, F1=0.68) for 60k interactions. We create the SUPP.AI application for users to search evidence sentences extracted by our model. SUPP.AI is an attempt to close the information gap on dietary supplements by making upto-date evidence on SDIs more discoverable for researchers, clinicians, and consumers.","SUPP.AI: finding evidence for supplement-drug interactions Dietary supplements are used by a large portion of the population, but information on their pharmacologic interactions is incomplete. To address this challenge, we present SUPP.AI, an application for browsing evidence of supplement-drug interactions (SDIs) extracted from the biomedical literature. We train a model to automatically extract supplement information and identify such interactions from the scientific literature. To address the lack of labeled data for SDI identification, we use labels of the closely related task of identifying drug-drug interactions (DDIs) for supervision. We fine-tune the contextualized word representations of the RoBERTa language model using labeled DDI data, and apply the fine-tuned model to identify supplement interactions. We extract 195k evidence sentences from 22M articles (P=0.82, R=0.58, F1=0.68) for 60k interactions. We create the SUPP.AI application for users to search evidence sentences extracted by our model. SUPP.AI is an attempt to close the information gap on dietary supplements by making upto-date evidence on SDIs more discoverable for researchers, clinicians, and consumers.","supp.ai : find evidence supplement - drug interaction dietary supplement large portion population , information pharmacologic interaction incomplete . address challenge , present supp.ai , application browse evidence supplement - drug interaction ( sdis ) extract biomedical literature . train model automatically extract supplement information identify interaction scientific literature . address lack label datum sdi identification , use label closely related task identify drug - drug interaction ( ddis ) supervision . fine - tune contextualize word representation roberta language model label ddi datum , apply fine - tune model identify supplement interaction . extract 195k evidence sentence 22 m article ( p=0.82 , r=0.58 , f1=0.68 ) 60k interaction . create supp.ai application user search evidence sentence extract model . supp.ai attempt close information gap dietary supplement make upto - date evidence sdi discoverable researcher , clinician , consumer .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 7, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 3, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
System Demonstrations,Clinical-Coder: Assigning Interpretable ICD-10 Codes to Chinese Clinical Notes,"In this paper, we introduce Clinical-Coder, an online system aiming to assign ICD codes to Chinese clinical notes. ICD coding has been a research hotspot of clinical medicine, but the interpretability of prediction hinders its practical application. We exploit a Dilated Convolutional Attention network with N-gram Matching Mechanism (DCANM) to capture semantic features for non-continuous words and continuous n-gram words, concentrating on explaining the reason why each ICD code to be predicted. The experiments demonstrate that our approach is effective and that our system is able to provide supporting information in clinical decision making.","Clinical-Coder: Assigning Interpretable ICD-10 Codes to Chinese Clinical Notes In this paper, we introduce Clinical-Coder, an online system aiming to assign ICD codes to Chinese clinical notes. ICD coding has been a research hotspot of clinical medicine, but the interpretability of prediction hinders its practical application. We exploit a Dilated Convolutional Attention network with N-gram Matching Mechanism (DCANM) to capture semantic features for non-continuous words and continuous n-gram words, concentrating on explaining the reason why each ICD code to be predicted. The experiments demonstrate that our approach is effective and that our system is able to provide supporting information in clinical decision making.","clinical - coder : assign interpretable icd-10 code chinese clinical note paper , introduce clinical - coder , online system aim assign icd code chinese clinical note . icd coding research hotspot clinical medicine , interpretability prediction hinder practical application . exploit dilated convolutional attention network n - gram matching mechanism ( dcanm ) capture semantic feature non - continuous word continuous n - gram word , concentrate explain reason icd code predict . experiment demonstrate approach effective system able provide support information clinical decision making .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 9, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,Nakdan: Professional Hebrew Diacritizer,"We present a system for automatic diacritization of Hebrew text. The system combines modern neural models with carefully curated declarative linguistic knowledge and comprehensive manually constructed tables and dictionaries. Besides providing state of the art diacritization accuracy, the system also supports an interface for manual editing and correction of the automatic output, and has several features which make it particularly useful for preparation of scientific editions of Hebrew texts. The system supports Modern Hebrew, Rabbinic Hebrew and Poetic Hebrew. The system is freely accessible for all use at http://nakdanpro.dicta.org.il.","Nakdan: Professional Hebrew Diacritizer We present a system for automatic diacritization of Hebrew text. The system combines modern neural models with carefully curated declarative linguistic knowledge and comprehensive manually constructed tables and dictionaries. Besides providing state of the art diacritization accuracy, the system also supports an interface for manual editing and correction of the automatic output, and has several features which make it particularly useful for preparation of scientific editions of Hebrew texts. The system supports Modern Hebrew, Rabbinic Hebrew and Poetic Hebrew. The system is freely accessible for all use at http://nakdanpro.dicta.org.il.","nakdan : professional hebrew diacritizer present system automatic diacritization hebrew text . system combine modern neural model carefully curate declarative linguistic knowledge comprehensive manually construct table dictionary . provide state art diacritization accuracy , system support interface manual editing correction automatic output , feature particularly useful preparation scientific edition hebrew text . system support modern hebrew , rabbinic hebrew poetic hebrew . system freely accessible use http://nakdanpro.dicta.org.il .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,GAIA: A Fine-grained Multimedia Knowledge Extraction System,"We present the first comprehensive, open source multimedia knowledge extraction system that takes a massive stream of unstructured, heterogeneous multimedia data from various sources and languages as input, and creates a coherent, structured knowledge base, indexing entities, relations, and events, following a rich, fine-grained ontology. Our system, GAIA 1 , enables seamless search of complex graph queries, and retrieves multimedia evidence including text, images and videos. GAIA achieves top performance at the recent NIST TAC SM-KBP2019 evaluation 2 . The system is publicly available at GitHub 3 and DockerHub 4 , with complete documentation 5 .","GAIA: A Fine-grained Multimedia Knowledge Extraction System We present the first comprehensive, open source multimedia knowledge extraction system that takes a massive stream of unstructured, heterogeneous multimedia data from various sources and languages as input, and creates a coherent, structured knowledge base, indexing entities, relations, and events, following a rich, fine-grained ontology. Our system, GAIA 1 , enables seamless search of complex graph queries, and retrieves multimedia evidence including text, images and videos. GAIA achieves top performance at the recent NIST TAC SM-KBP2019 evaluation 2 . The system is publicly available at GitHub 3 and DockerHub 4 , with complete documentation 5 .","gaia : fine - grained multimedia knowledge extraction system present comprehensive , open source multimedia knowledge extraction system take massive stream unstructured , heterogeneous multimedia datum source language input , create coherent , structured knowledge base , index entity , relation , event , follow rich , fine - grained ontology . system , gaia 1 , enable seamless search complex graph query , retrieve multimedia evidence include text , image video . gaia achieve performance recent nist tac sm - kbp2019 evaluation 2 . system publicly available github 3 dockerhub 4 , complete documentation 5 .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 4, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,NLP Scholar: An Interactive Visual Explorer for Natural Language Processing Literature,"As part of the NLP Scholar project, we created a single unified dataset of NLP papers and their meta-information (including citation numbers), by extracting and aligning information from the ACL Anthology and Google Scholar. In this paper, we describe several interconnected interactive visualizations (dashboards) that present various aspects of the data. Clicking on an item within a visualization or entering query terms in the search boxes filters the data in all visualizations in the dashboard. This allows users to search for papers in the area of their interest, published within specific time periods, published by specified authors, etc. The interactive visualizations presented here, and the associated dataset of papers mapped to citations, have additional uses as well including understanding how the field is growing (both overall and across sub-areas), as well as quantifying the impact of different types of papers on subsequent publications.","NLP Scholar: An Interactive Visual Explorer for Natural Language Processing Literature As part of the NLP Scholar project, we created a single unified dataset of NLP papers and their meta-information (including citation numbers), by extracting and aligning information from the ACL Anthology and Google Scholar. In this paper, we describe several interconnected interactive visualizations (dashboards) that present various aspects of the data. Clicking on an item within a visualization or entering query terms in the search boxes filters the data in all visualizations in the dashboard. This allows users to search for papers in the area of their interest, published within specific time periods, published by specified authors, etc. The interactive visualizations presented here, and the associated dataset of papers mapped to citations, have additional uses as well including understanding how the field is growing (both overall and across sub-areas), as well as quantifying the impact of different types of papers on subsequent publications.","nlp scholar : interactive visual explorer natural language processing literature nlp scholar project , create single unified dataset nlp paper meta - information ( include citation number ) , extract align information acl anthology google scholar . paper , describe interconnected interactive visualization ( dashboard ) present aspect data . click item visualization enter query term search box filter data visualization dashboard . allow user search paper area interest , publish specific time period , publish specified author , etc . interactive visualization present , associate dataset paper map citation , additional use include understand field grow ( overall sub - area ) , quantify impact different type paper subsequent publication .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 10, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Theme,False
System Demonstrations,DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation,"We present a large, tunable neural conversational response generation model, DIALOGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent opendomain dialogue systems.","DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation We present a large, tunable neural conversational response generation model, DIALOGPT (dialogue generative pre-trained transformer). Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017, DialoGPT extends the Hugging Face PyTorch transformer to attain a performance close to human both in terms of automatic and human evaluation in single-turn dialogue settings. We show that conversational systems that leverage DialoGPT generate more relevant, contentful and context-consistent responses than strong baseline systems. The pre-trained model and training pipeline are publicly released to facilitate research into neural response generation and the development of more intelligent opendomain dialogue systems.","dialogpt : large - scale generative pre - training conversational response generation present large , tunable neural conversational response generation model , dialogpt ( dialogue generative pre - trained transformer ) . train 147 m conversation - like exchange extract reddit comment chain period span 2005 2017 , dialogpt extend hugging face pytorch transformer attain performance close human term automatic human evaluation single - turn dialogue setting . conversational system leverage dialogpt generate relevant , contentful context - consistent response strong baseline system . pre - trained model training pipeline publicly release facilitate research neural response generation development intelligent opendomain dialogue system .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 20, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 4, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
System Demonstrations,Prta: A System to Support the Analysis of Propaganda Techniques in the News,"Recent events, such as the 2016 US Presidential Campaign, Brexit and the COVID-19 ""infodemic"", have brought into the spotlight the dangers of online disinformation. There has been a lot of research focusing on factchecking and disinformation detection. However, little attention has been paid to the specific rhetorical and psychological techniques used to convey propaganda messages. Revealing the use of such techniques can help promote media literacy and critical thinking, and eventually contribute to limiting the impact of ""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion Techniques Analyzer) allows users to explore the articles crawled on a regular basis by highlighting the spans in which propaganda techniques occur and to compare them on the basis of their use of propaganda techniques. The system further reports statistics about the use of such techniques, overall and over time, or according to filtering criteria specified by the user based on time interval, keywords, and/or political orientation of the media. Moreover, it allows users to analyze any text or URL through a dedicated interface or via an API. The system is available online: https://www.tanbih.org/prta.","Prta: A System to Support the Analysis of Propaganda Techniques in the News Recent events, such as the 2016 US Presidential Campaign, Brexit and the COVID-19 ""infodemic"", have brought into the spotlight the dangers of online disinformation. There has been a lot of research focusing on factchecking and disinformation detection. However, little attention has been paid to the specific rhetorical and psychological techniques used to convey propaganda messages. Revealing the use of such techniques can help promote media literacy and critical thinking, and eventually contribute to limiting the impact of ""fake news"" and disinformation campaigns. Prta (Propaganda Persuasion Techniques Analyzer) allows users to explore the articles crawled on a regular basis by highlighting the spans in which propaganda techniques occur and to compare them on the basis of their use of propaganda techniques. The system further reports statistics about the use of such techniques, overall and over time, or according to filtering criteria specified by the user based on time interval, keywords, and/or political orientation of the media. Moreover, it allows users to analyze any text or URL through a dedicated interface or via an API. The system is available online: https://www.tanbih.org/prta.","prta : system support analysis propaganda technique news recent event , 2016 presidential campaign , brexit covid-19 "" infodemic "" , bring spotlight danger online disinformation . lot research focus factchecking disinformation detection . , little attention pay specific rhetorical psychological technique convey propaganda message . reveal use technique help promote medium literacy critical thinking , eventually contribute limit impact "" fake news "" disinformation campaign . prta ( propaganda persuasion techniques analyzer ) allow user explore article crawl regular basis highlight span propaganda technique occur compare basis use propaganda technique . system report statistic use technique , overall time , accord filtering criterion specify user base time interval , keyword , and/or political orientation medium . , allow user analyze text url dedicated interface api . system available online : https://www.tanbih.org/prta .","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 8, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
System Demonstrations,SyntaxGym: An Online Platform for Targeted Evaluation of Language Models,"Targeted syntactic evaluations have yielded insights into the generalizations learned by neural network language models. However, this line of research requires an uncommon confluence of skills: both the theoretical knowledge needed to design controlled psycholinguistic experiments, and the technical proficiency needed to train and deploy large-scale language models. We present SyntaxGym, an online platform designed to make targeted evaluations accessible to both experts in NLP and linguistics, reproducible across computing environments, and standardized following the norms of psycholinguistic experimental design. This paper releases two tools of independent value for the computational linguistics community: 1. A website, syntaxgym.org, which centralizes the process of targeted syntactic evaluation and provides easy tools for analysis and visualization; 2. Two command-line tools, syntaxgym and lm-zoo, which allow any user to reproduce targeted syntactic evaluations and general language model inference on their own machine.","SyntaxGym: An Online Platform for Targeted Evaluation of Language Models Targeted syntactic evaluations have yielded insights into the generalizations learned by neural network language models. However, this line of research requires an uncommon confluence of skills: both the theoretical knowledge needed to design controlled psycholinguistic experiments, and the technical proficiency needed to train and deploy large-scale language models. We present SyntaxGym, an online platform designed to make targeted evaluations accessible to both experts in NLP and linguistics, reproducible across computing environments, and standardized following the norms of psycholinguistic experimental design. This paper releases two tools of independent value for the computational linguistics community: 1. A website, syntaxgym.org, which centralizes the process of targeted syntactic evaluation and provides easy tools for analysis and visualization; 2. Two command-line tools, syntaxgym and lm-zoo, which allow any user to reproduce targeted syntactic evaluations and general language model inference on their own machine.","syntaxgym : online platform targeted evaluation language model targeted syntactic evaluation yield insight generalization learn neural network language model . , line research require uncommon confluence skill : theoretical knowledge need design control psycholinguistic experiment , technical proficiency need train deploy large - scale language model . present syntaxgym , online platform design targeted evaluation accessible expert nlp linguistic , reproducible compute environment , standardize follow norm psycholinguistic experimental design . paper release tool independent value computational linguistic community : 1 . website , syntaxgym.org , centralize process target syntactic evaluation provide easy tool analysis visualization ; 2 . command - line tool , syntaxgym lm - zoo , allow user reproduce target syntactic evaluation general language model inference machine .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 5}",Resources and Evaluation,False
System Demonstrations,BENTO: A Visual Platform for Building Clinical NLP Pipelines Based on CodaLab,"CodaLab 1 is an open-source web-based platform for collaborative computational research. Although CodaLab has gained popularity in the research community, its interface has limited support for creating reusable tools that can be easily applied to new datasets and composed into pipelines. In clinical domain, natural language processing (NLP) on medical notes generally involves multiple steps, like tokenization, named entity recognition, etc. Since these steps require different tools which are usually scattered in different publications, it is not easy for researchers to use them to process their own datasets. In this paper, we present BENTO, a workflow management platform with a graphic user interface (GUI) that is built on top of CodaLab, to facilitate the process of building clinical NLP pipelines. BENTO comes with a number of clinical NLP tools that have been pre-trained using medical notes and expert annotations and can be readily used for various clinical NLP tasks. It also allows researchers and developers to create their custom tools (e.g., pretrained NLP models) and use them in a controlled and reproducible way. In addition, the GUI interface enables researchers with limited computer background to compose tools into NLP pipelines and then apply the pipelines on their own datasets in a ""what you see is what you get"" (WYSIWYG) way. Although BENTO is designed for clinical NLP applications, the underlying architecture is flexible to be tailored to any other domains.","BENTO: A Visual Platform for Building Clinical NLP Pipelines Based on CodaLab CodaLab 1 is an open-source web-based platform for collaborative computational research. Although CodaLab has gained popularity in the research community, its interface has limited support for creating reusable tools that can be easily applied to new datasets and composed into pipelines. In clinical domain, natural language processing (NLP) on medical notes generally involves multiple steps, like tokenization, named entity recognition, etc. Since these steps require different tools which are usually scattered in different publications, it is not easy for researchers to use them to process their own datasets. In this paper, we present BENTO, a workflow management platform with a graphic user interface (GUI) that is built on top of CodaLab, to facilitate the process of building clinical NLP pipelines. BENTO comes with a number of clinical NLP tools that have been pre-trained using medical notes and expert annotations and can be readily used for various clinical NLP tasks. It also allows researchers and developers to create their custom tools (e.g., pretrained NLP models) and use them in a controlled and reproducible way. In addition, the GUI interface enables researchers with limited computer background to compose tools into NLP pipelines and then apply the pipelines on their own datasets in a ""what you see is what you get"" (WYSIWYG) way. Although BENTO is designed for clinical NLP applications, the underlying architecture is flexible to be tailored to any other domains.","bento : visual platform build clinical nlp pipeline base codalab codalab 1 open - source web - base platform collaborative computational research . codalab gain popularity research community , interface limited support create reusable tool easily apply new dataset compose pipeline . clinical domain , natural language processing ( nlp ) medical note generally involve multiple step , like tokenization , name entity recognition , etc . step require different tool usually scatter different publication , easy researcher use process dataset . paper , present bento , workflow management platform graphic user interface ( gui ) build codalab , facilitate process build clinical nlp pipeline . bento come number clinical nlp tool pre - train medical note expert annotation readily clinical nlp task . allow researcher developer create custom tool ( e.g. , pretrained nlp model ) use controlled reproducible way . addition , gui interface enable researcher limited computer background compose tool nlp pipeline apply pipeline dataset "" "" ( wysiwyg ) way . bento design clinical nlp application , underlie architecture flexible tailor domain .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 20, 'Theme': 9, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,True
Student Research Workshop,uBLEU: Uncertainty-Aware Automatic Evaluation Method for Open-Domain Dialogue Systems,"Because open-domain dialogues allow diverse responses, basic reference-based metrics such as BLEU do not work well unless we prepare a massive reference set of high-quality responses for input utterances. To reduce this burden, a human-aided, uncertainty-aware metric, âˆ†BLEU, has been proposed; it embeds human judgment on the quality of reference outputs into the computation of multiplereference BLEU. In this study, we instead propose a fully automatic, uncertainty-aware evaluation method for open-domain dialogue systems, Ï…BLEU. This method first collects diverse reference responses from massive dialogue data and then annotates their quality judgments by using a neural network trained on automatically collected training data. Experimental results on massive Twitter data confirmed that Ï…BLEU is comparable to âˆ†BLEU in terms of its correlation with human judgment and that the state of the art automatic evaluation method, RUBER, is improved by integrating Ï…BLEU.","uBLEU: Uncertainty-Aware Automatic Evaluation Method for Open-Domain Dialogue Systems Because open-domain dialogues allow diverse responses, basic reference-based metrics such as BLEU do not work well unless we prepare a massive reference set of high-quality responses for input utterances. To reduce this burden, a human-aided, uncertainty-aware metric, âˆ†BLEU, has been proposed; it embeds human judgment on the quality of reference outputs into the computation of multiplereference BLEU. In this study, we instead propose a fully automatic, uncertainty-aware evaluation method for open-domain dialogue systems, Ï…BLEU. This method first collects diverse reference responses from massive dialogue data and then annotates their quality judgments by using a neural network trained on automatically collected training data. Experimental results on massive Twitter data confirmed that Ï…BLEU is comparable to âˆ†BLEU in terms of its correlation with human judgment and that the state of the art automatic evaluation method, RUBER, is improved by integrating Ï…BLEU.","ubleu : uncertainty - aware automatic evaluation method open - domain dialogue system open - domain dialogue allow diverse response , basic reference - base metric bleu work prepare massive reference set high - quality response input utterance . reduce burden , human - aid , uncertainty - aware metric , âˆ†bleu , propose ; embed human judgment quality reference output computation multiplereference bleu . study , instead propose fully automatic , uncertainty - aware evaluation method open - domain dialogue system , Ï…bleu . method collect diverse reference response massive dialogue datum annotate quality judgment neural network train automatically collect training datum . experimental result massive twitter datum confirm Ï…bleu comparable âˆ†bleu term correlation human judgment state art automatic evaluation method , ruber , improve integrate Ï…bleu .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 13, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 8, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 10, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 8, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Dialogue and Interactive Systems,False
Student Research Workshop,Compositional Generalization by Factorizing Alignment and Translation,"Standard methods in deep learning for natural language processing fail to capture the compositional structure of human language that allows for systematic generalization outside of the training distribution. However, human learners readily generalize in this way, e.g. by applying known grammatical rules to novel words. Inspired by work in cognitive science suggesting a functional distinction between systems for syntactic and semantic processing, we implement a modification to an existing approach in neural machine translation, imposing an analogous separation between alignment and translation. The resulting architecture substantially outperforms standard recurrent networks on the SCAN dataset, a compositional generalization task, without any additional supervision. Our work suggests that learning to align and to translate in separate modules may be a useful heuristic for capturing compositional structure.","Compositional Generalization by Factorizing Alignment and Translation Standard methods in deep learning for natural language processing fail to capture the compositional structure of human language that allows for systematic generalization outside of the training distribution. However, human learners readily generalize in this way, e.g. by applying known grammatical rules to novel words. Inspired by work in cognitive science suggesting a functional distinction between systems for syntactic and semantic processing, we implement a modification to an existing approach in neural machine translation, imposing an analogous separation between alignment and translation. The resulting architecture substantially outperforms standard recurrent networks on the SCAN dataset, a compositional generalization task, without any additional supervision. Our work suggests that learning to align and to translate in separate modules may be a useful heuristic for capturing compositional structure.","compositional generalization factorize alignment translation standard method deep learning natural language processing fail capture compositional structure human language allow systematic generalization outside training distribution . , human learner readily generalize way , e.g. apply know grammatical rule novel word . inspire work cognitive science suggest functional distinction system syntactic semantic processing , implement modification exist approach neural machine translation , impose analogous separation alignment translation . result architecture substantially outperform standard recurrent network scan dataset , compositional generalization task , additional supervision . work suggest learn align translate separate module useful heuristic capture compositional structure .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 5, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 6, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Student Research Workshop,A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples,"Generating adversarial examples for natural language is hard, as natural language consists of discrete symbols, and examples are often of variable lengths. In this paper, we propose a geometryinspired attack for generating natural language adversarial examples. Our attack generates adversarial examples by iteratively approximating the decision boundary of Deep Neural Networks (DNNs). Experiments on two datasets with two different models show that our attack fools natural language models with high success rates, while only replacing a few words. Human evaluation","A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples Generating adversarial examples for natural language is hard, as natural language consists of discrete symbols, and examples are often of variable lengths. In this paper, we propose a geometryinspired attack for generating natural language adversarial examples. Our attack generates adversarial examples by iteratively approximating the decision boundary of Deep Neural Networks (DNNs). Experiments on two datasets with two different models show that our attack fools natural language models with high success rates, while only replacing a few words. Human evaluation","geometry - inspire attack generate natural language adversarial example generate adversarial example natural language hard , natural language consist discrete symbol , example variable length . paper , propose geometryinspired attack generate natural language adversarial example . attack generate adversarial example iteratively approximate decision boundary deep neural networks ( dnns ) . experiment dataset different model attack fool natural language model high success rate , replace word . human evalu","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Student Research Workshop,Adaptive Transformers for Learning Multimodal Representations,"The usage of transformers has grown from learning about language semantics to forming meaningful visiolinguistic representations. These architectures are often over-parametrized, requiring large amounts of computation. In this work, we extend adaptive approaches to learn more about model interpretability and computational efficiency. Specifically, we study attention spans, sparse, and structured dropout methods to help understand how their attention mechanism extends for vision and language tasks. We further show that these approaches can help us learn more about how the network perceives the complexity of input sequences, sparsity preferences for different modalities, and other related phenomena.","Adaptive Transformers for Learning Multimodal Representations The usage of transformers has grown from learning about language semantics to forming meaningful visiolinguistic representations. These architectures are often over-parametrized, requiring large amounts of computation. In this work, we extend adaptive approaches to learn more about model interpretability and computational efficiency. Specifically, we study attention spans, sparse, and structured dropout methods to help understand how their attention mechanism extends for vision and language tasks. We further show that these approaches can help us learn more about how the network perceives the complexity of input sequences, sparsity preferences for different modalities, and other related phenomena.","adaptive transformer learn multimodal representation usage transformer grow learn language semantic form meaningful visiolinguistic representation . architecture - parametrize , require large amount computation . work , extend adaptive approach learn model interpretability computational efficiency . specifically , study attention span , sparse , structured dropout method help understand attention mechanism extend vision language task . approach help learn network perceive complexity input sequence , sparsity preference different modality , related phenomenon .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 4, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Student Research Workshop,Enhancing Word Embeddings with Knowledge Extracted from Lexical Resources,"In this work, we present an effective method for semantic specialization of word vector representations. To this end, we use traditional word embeddings and apply specialization methods to better capture semantic relations between words. In our approach, we leverage external knowledge from rich lexical resources such as BabelNet. We also show that our proposed post-specialization method based on an adversarial neural network with the Wasserstein distance allows to gain improvements over state-of-the-art methods on two tasks: word similarity and dialog state tracking.","Enhancing Word Embeddings with Knowledge Extracted from Lexical Resources In this work, we present an effective method for semantic specialization of word vector representations. To this end, we use traditional word embeddings and apply specialization methods to better capture semantic relations between words. In our approach, we leverage external knowledge from rich lexical resources such as BabelNet. We also show that our proposed post-specialization method based on an adversarial neural network with the Wasserstein distance allows to gain improvements over state-of-the-art methods on two tasks: word similarity and dialog state tracking.","enhance word embedding knowledge extract lexical resource work , present effective method semantic specialization word vector representation . end , use traditional word embedding apply specialization method well capture semantic relation word . approach , leverage external knowledge rich lexical resource babelnet . propose post - specialization method base adversarial neural network wasserstein distance allow gain improvement state - - - art method task : word similarity dialog state tracking .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 8, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Student Research Workshop,Grammatical Error Correction Using Pseudo Learner Corpus Considering Learner's Error Tendency,"Recently, several studies have focused on improving the performance of grammatical error correction (GEC) tasks using pseudo data. However, a large amount of pseudo data are required to train an accurate GEC model. To address the limitations of language and computational resources, we assume that introducing pseudo errors into sentences similar to those written by the language learners is more efficient, rather than incorporating random pseudo errors into monolingual data. In this regard, we study the effect of pseudo data on GEC task performance using two approaches. First, we extract sentences that are similar to the learners' sentences from monolingual data. Second, we generate realistic pseudo errors by considering error types that learners often make. Based on our comparative results, we observe that F 0.5 scores for the Russian GEC task are significantly improved.","Grammatical Error Correction Using Pseudo Learner Corpus Considering Learner's Error Tendency Recently, several studies have focused on improving the performance of grammatical error correction (GEC) tasks using pseudo data. However, a large amount of pseudo data are required to train an accurate GEC model. To address the limitations of language and computational resources, we assume that introducing pseudo errors into sentences similar to those written by the language learners is more efficient, rather than incorporating random pseudo errors into monolingual data. In this regard, we study the effect of pseudo data on GEC task performance using two approaches. First, we extract sentences that are similar to the learners' sentences from monolingual data. Second, we generate realistic pseudo errors by considering error types that learners often make. Based on our comparative results, we observe that F 0.5 scores for the Russian GEC task are significantly improved.","grammatical error correction pseudo learner corpus consider learner error tendency recently , study focus improve performance grammatical error correction ( gec ) task pseudo datum . , large pseudo datum require train accurate gec model . address limitation language computational resource , assume introduce pseudo error sentence similar write language learner efficient , incorporate random pseudo error monolingual datum . regard , study effect pseudo datum gec task performance approach . , extract sentence similar learner ' sentence monolingual datum . second , generate realistic pseudo error consider error type learner . base comparative result , observe f 0.5 score russian gec task significantly improve .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 6, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Student Research Workshop,Cross-Lingual Disaster-related Multi-label Tweet Classification with Manifold Mixup,"Distinguishing informative and actionable messages from a social media platform like Twitter is critical for facilitating disaster management. For this purpose, we compile a multilingual dataset of over 130K samples for multilabel classification of disaster-related tweets. We present a masking-based loss function for partially labeled samples and demonstrate the effectiveness of Manifold Mixup in the text domain. Our main model is based on Multilingual BERT, which we further improve with Manifold Mixup. We show that our model generalizes to unseen disasters in the test set. Furthermore, we analyze the capability of our model for zero-shot generalization to new languages. Our code, dataset, and other resources are available on Github. 1","Cross-Lingual Disaster-related Multi-label Tweet Classification with Manifold Mixup Distinguishing informative and actionable messages from a social media platform like Twitter is critical for facilitating disaster management. For this purpose, we compile a multilingual dataset of over 130K samples for multilabel classification of disaster-related tweets. We present a masking-based loss function for partially labeled samples and demonstrate the effectiveness of Manifold Mixup in the text domain. Our main model is based on Multilingual BERT, which we further improve with Manifold Mixup. We show that our model generalizes to unseen disasters in the test set. Furthermore, we analyze the capability of our model for zero-shot generalization to new languages. Our code, dataset, and other resources are available on Github. 1","cross - lingual disaster - related multi - label tweet classification manifold mixup distinguish informative actionable message social media platform like twitter critical facilitate disaster management . purpose , compile multilingual dataset 130 k sample multilabel classification disaster - relate tweet . present masking - base loss function partially label sample demonstrate effectiveness manifold mixup text domain . main model base multilingual bert , improve manifold mixup . model generalize unseen disaster test set . furthermore , analyze capability model zero - shot generalization new language . code , dataset , resource available github . 1","{'Computational Social Science and Social Media': 3, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Student Research Workshop,AraDIC: Arabic Document Classification Using Image-Based Character Embeddings and Class-Balanced Loss,"Classical and some deep learning techniques for Arabic text classification often depend on complex morphological analysis, word segmentation, and hand-crafted feature engineering. These could be eliminated by using character-level features. We propose a novel end-to-end Arabic document classification framework, Arabic document imagebased classifier (AraDIC), inspired by the work on image-based character embeddings. AraDIC consists of an image-based character encoder and a classifier. They are trained in an end-to-end fashion using the class balanced loss to deal with the long-tailed data distribution problem. To evaluate the effectiveness of AraDIC, we created and published two datasets, the Arabic Wikipedia title (AWT) dataset and the Arabic poetry (AraP) dataset. To the best of our knowledge, this is the first image-based character embedding framework addressing the problem of Arabic text classification. We also present the first deep learningbased text classifier widely evaluated on modern standard Arabic, colloquial Arabic and classical Arabic. AraDIC shows performance improvement over classical and deep learning baselines by 12.29% and 23.05% for the micro and macro F-score, respectively.","AraDIC: Arabic Document Classification Using Image-Based Character Embeddings and Class-Balanced Loss Classical and some deep learning techniques for Arabic text classification often depend on complex morphological analysis, word segmentation, and hand-crafted feature engineering. These could be eliminated by using character-level features. We propose a novel end-to-end Arabic document classification framework, Arabic document imagebased classifier (AraDIC), inspired by the work on image-based character embeddings. AraDIC consists of an image-based character encoder and a classifier. They are trained in an end-to-end fashion using the class balanced loss to deal with the long-tailed data distribution problem. To evaluate the effectiveness of AraDIC, we created and published two datasets, the Arabic Wikipedia title (AWT) dataset and the Arabic poetry (AraP) dataset. To the best of our knowledge, this is the first image-based character embedding framework addressing the problem of Arabic text classification. We also present the first deep learningbased text classifier widely evaluated on modern standard Arabic, colloquial Arabic and classical Arabic. AraDIC shows performance improvement over classical and deep learning baselines by 12.29% and 23.05% for the micro and macro F-score, respectively.","aradic : arabic document classification image - base character embedding class - balance loss classical deep learning technique arabic text classification depend complex morphological analysis , word segmentation , hand - craft feature engineering . eliminate character - level feature . propose novel end - - end arabic document classification framework , arabic document imagebased classifier ( aradic ) , inspire work image - base character embedding . aradic consist image - base character encoder classifier . train end - - end fashion class balance loss deal long - tail datum distribution problem . evaluate effectiveness aradic , create publish dataset , arabic wikipedia title ( awt ) dataset arabic poetry ( arap ) dataset . good knowledge , image - base character embedding framework address problem arabic text classification . present deep learningbase text classifier widely evaluate modern standard arabic , colloquial arabic classical arabic . aradic show performance improvement classical deep learning baseline 12.29 % 23.05 % micro macro f - score , respectively .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 9, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 5, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 8, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 5, 'Student Research Workshop': 10, 'Summarization': 3, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,True
Student Research Workshop,Topic Balancing with Additive Regularization of Topic Models,"This article proposes a new approach for building topic models on unbalanced collections in topic modelling, based on the existing methods and our experiments with such methods. Real-world data collections contain topics in various proportions, and often documents of the relatively small theme become distributed all over the larger topics instead of being grouped into one topic. To address this issue, we design a new regularizer for Î˜ and Î¦ matrices in probabilistic Latent Semantic Analysis (pLSA) model. We make sure this regularizer increases the quality of topic models, trained on unbalanced collections. Besides, we conceptually support this regularizer by our experiments.","Topic Balancing with Additive Regularization of Topic Models This article proposes a new approach for building topic models on unbalanced collections in topic modelling, based on the existing methods and our experiments with such methods. Real-world data collections contain topics in various proportions, and often documents of the relatively small theme become distributed all over the larger topics instead of being grouped into one topic. To address this issue, we design a new regularizer for Î˜ and Î¦ matrices in probabilistic Latent Semantic Analysis (pLSA) model. We make sure this regularizer increases the quality of topic models, trained on unbalanced collections. Besides, we conceptually support this regularizer by our experiments.","topic balancing additive regularization topic model article propose new approach build topic model unbalanced collection topic modelling , base exist method experiment method . real - world data collection contain topic proportion , document relatively small theme distribute large topic instead group topic . address issue , design new regularizer Î¸ Ï† matrix probabilistic latent semantic analysis ( plsa ) model . sure regularizer increase quality topic model , train unbalanced collection . , conceptually support regularizer experiment .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 13, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 1, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Retrieval and Text Mining,False
Student Research Workshop,Exploring the Role of Context to Distinguish Rhetorical and Information-Seeking Questions,"Social media posts often contain questions, but many of the questions are rhetorical and do not seek information. Our work studies the problem of distinguishing rhetorical and information-seeking questions on Twitter. Most work has focused on features of the question itself, but we hypothesize that the prior context plays a role too. This paper introduces a new dataset containing questions in tweets paired with their prior tweets to provide context. We create classification models to assess the difficulty of distinguishing rhetorical and information-seeking questions, and experiment with different properties of the prior context. Our results show that the prior tweet and topic features can improve performance on this task.","Exploring the Role of Context to Distinguish Rhetorical and Information-Seeking Questions Social media posts often contain questions, but many of the questions are rhetorical and do not seek information. Our work studies the problem of distinguishing rhetorical and information-seeking questions on Twitter. Most work has focused on features of the question itself, but we hypothesize that the prior context plays a role too. This paper introduces a new dataset containing questions in tweets paired with their prior tweets to provide context. We create classification models to assess the difficulty of distinguishing rhetorical and information-seeking questions, and experiment with different properties of the prior context. Our results show that the prior tweet and topic features can improve performance on this task.","explore role context distinguish rhetorical information - seeking question social medium post contain question , question rhetorical seek information . work study problem distinguish rhetorical information - seeking question twitter . work focus feature question , hypothesize prior context play role . paper introduce new dataset contain question tweet pair prior tweet provide context . create classification model assess difficulty distinguish rhetorical information - seek question , experiment different property prior context . result prior tweet topic feature improve performance task .","{'Computational Social Science and Social Media': 7, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 4, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 5, 'Question Answering': 7, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Computational Social Science and Social Media,False
Student Research Workshop,To compress or not to compress? A Finite-State approach to Nen verbal morphology,"This paper describes the development of a verbal morphological parser for an underresourced Papuan language, Nen. Nen verbal morphology is particularly complex, with a transitive verb taking up to 1, 740 unique features. The structural properties exhibited by Nen verbs raises interesting choices for analysis. Here we compare two possible methods of analysis: 'Chunking' and decomposition. 'Chunking' refers to the concept of collating morphological segments into one, whereas the decomposition model follows a more classical linguistic approach. Both models are built using the Finite-State Transducer toolkit foma. The resultant architecture shows differences in size and structural clarity. While the 'Chunking' model is under half the size of the full decomposed counterpart, the decomposition displays higher structural order. In this paper, we describe the challenges encountered when modelling a language exhibiting distributed exponence and present the first morphological analyser for Nen, with an overall accuracy of 80.3%.","To compress or not to compress? A Finite-State approach to Nen verbal morphology This paper describes the development of a verbal morphological parser for an underresourced Papuan language, Nen. Nen verbal morphology is particularly complex, with a transitive verb taking up to 1, 740 unique features. The structural properties exhibited by Nen verbs raises interesting choices for analysis. Here we compare two possible methods of analysis: 'Chunking' and decomposition. 'Chunking' refers to the concept of collating morphological segments into one, whereas the decomposition model follows a more classical linguistic approach. Both models are built using the Finite-State Transducer toolkit foma. The resultant architecture shows differences in size and structural clarity. While the 'Chunking' model is under half the size of the full decomposed counterpart, the decomposition displays higher structural order. In this paper, we describe the challenges encountered when modelling a language exhibiting distributed exponence and present the first morphological analyser for Nen, with an overall accuracy of 80.3%.","compress compress ? finite - state approach nen verbal morphology paper describe development verbal morphological parser underresourced papuan language , nen . nen verbal morphology particularly complex , transitive verb take 1 , 740 unique feature . structural property exhibit nen verb raise interesting choice analysis . compare possible method analysis : ' chunking ' decomposition . ' chunking ' refer concept collate morphological segment , decomposition model follow classical linguistic approach . model build finite - state transducer toolkit foma . resultant architecture show difference size structural clarity . ' chunk ' model half size decompose counterpart , decomposition display high structural order . paper , describe challenge encounter model language exhibit distribute exponence present morphological analyser nen , overall accuracy 80.3 % .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Student Research Workshop,Reflection-based Word Attribute Transfer,"Word embeddings, which often represent such analogic relations as âˆ’âˆ’â†’ king âˆ’ âˆ’âˆ’â†’ man+ âˆ’ âˆ’âˆ’âˆ’âˆ’ â†’ woman â‰ˆ âˆ’âˆ’âˆ’â†’ queen, can be used to change a word's attribute, including its gender. For transferring king into queen in this analogy-based manner, we subtract a difference vector âˆ’âˆ’â†’ manâˆ’ âˆ’ âˆ’âˆ’âˆ’âˆ’ â†’ woman based on the knowledge that king is male. However, developing such knowledge is very costly for words and attributes. In this work, we propose a novel method for word attribute transfer based on reflection mappings without such an analogy operation. Experimental results show that our proposed method can transfer the word attributes of the given words without changing the words that do not have the target attributes.","Reflection-based Word Attribute Transfer Word embeddings, which often represent such analogic relations as âˆ’âˆ’â†’ king âˆ’ âˆ’âˆ’â†’ man+ âˆ’ âˆ’âˆ’âˆ’âˆ’ â†’ woman â‰ˆ âˆ’âˆ’âˆ’â†’ queen, can be used to change a word's attribute, including its gender. For transferring king into queen in this analogy-based manner, we subtract a difference vector âˆ’âˆ’â†’ manâˆ’ âˆ’ âˆ’âˆ’âˆ’âˆ’ â†’ woman based on the knowledge that king is male. However, developing such knowledge is very costly for words and attributes. In this work, we propose a novel method for word attribute transfer based on reflection mappings without such an analogy operation. Experimental results show that our proposed method can transfer the word attributes of the given words without changing the words that do not have the target attributes.","reflection - base word attribute transfer word embedding , represent analogic relation âˆ’âˆ’â†’ king âˆ’ âˆ’âˆ’â†’ man+ âˆ’ âˆ’âˆ’âˆ’âˆ’ â†’ woman â‰ˆ âˆ’âˆ’âˆ’â†’ queen , change word attribute , include gender . transfer king queen analogy - base manner , subtract difference vector âˆ’âˆ’â†’ manâˆ’ âˆ’ âˆ’âˆ’âˆ’âˆ’ â†’ woman base knowledge king male . , develop knowledge costly word attribute . work , propose novel method word attribute transfer base reflection mapping analogy operation . experimental result propose method transfer word attribute give word change word target attribute .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 10, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Student Research Workshop,Non-Topical Coherence in Social Talk: A Call for Dialogue Model Enrichment,"Current models of dialogue mainly focus on utterances within a topically coherent discourse segment, rather than new-topic utterances (NTUs), which begin a new topic not correlating with the content of prior discourse. As a result, these models may sufficiently account for discourse context of task-oriented but not social conversations. We conduct a pilot annotation study of NTUs as a first step towards a model capable of rationalizing conversational coherence in social talk. We start with the naturally occurring social dialogues in the Disco-SPICE corpus, annotated with discourse relations in the Penn Discourse Treebank (PDTB) and Cognitive approach to Coherence Relations (CCR) frameworks. We first annotate content-based coherence relations that are not available in Disco-SPICE, and then heuristically identify NTUs, which lack a coherence relation to prior discourse. Based on the interaction between NTUs and their discourse context, we construct a classification for NTUs that actually convey certain non-topical coherence in social talk. This classification introduces new sequence-based social intents that traditional taxonomies of speech acts do not capture. The new findings advocates the development of a Bayesian game-theoretic model for social talk. 1","Non-Topical Coherence in Social Talk: A Call for Dialogue Model Enrichment Current models of dialogue mainly focus on utterances within a topically coherent discourse segment, rather than new-topic utterances (NTUs), which begin a new topic not correlating with the content of prior discourse. As a result, these models may sufficiently account for discourse context of task-oriented but not social conversations. We conduct a pilot annotation study of NTUs as a first step towards a model capable of rationalizing conversational coherence in social talk. We start with the naturally occurring social dialogues in the Disco-SPICE corpus, annotated with discourse relations in the Penn Discourse Treebank (PDTB) and Cognitive approach to Coherence Relations (CCR) frameworks. We first annotate content-based coherence relations that are not available in Disco-SPICE, and then heuristically identify NTUs, which lack a coherence relation to prior discourse. Based on the interaction between NTUs and their discourse context, we construct a classification for NTUs that actually convey certain non-topical coherence in social talk. This classification introduces new sequence-based social intents that traditional taxonomies of speech acts do not capture. The new findings advocates the development of a Bayesian game-theoretic model for social talk. 1","non - topical coherence social talk : dialogue model enrichment current model dialogue mainly focus utterance topically coherent discourse segment , new - topic utterance ( ntus ) , begin new topic correlate content prior discourse . result , model sufficiently account discourse context task - orient social conversation . conduct pilot annotation study ntus step model capable rationalize conversational coherence social talk . start naturally occurring social dialogue disco - spice corpus , annotate discourse relation penn discourse treebank ( pdtb ) cognitive approach coherence relations ( ccr ) framework . annotate content - base coherence relation available disco - spice , heuristically identify ntu , lack coherence relation prior discourse . base interaction ntus discourse context , construct classification ntus actually convey certain non - topical coherence social talk . classification introduce new sequence - base social intent traditional taxonomy speech act capture . new finding advocate development bayesian game - theoretic model social talk . 1","{'Computational Social Science and Social Media': 9, 'Dialogue and Interactive Systems': 9, 'Discourse and Pragmatics': 14, 'Ethics and NLP': 7, 'Generation': 2, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 7, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Discourse and Pragmatics,False
Student Research Workshop,RPD: A Distance Function Between Word Embeddings,"It is well-understood that different algorithms, training processes, and corpora produce different word embeddings. However, less is known about the relation between different embedding spaces, i.e. how far different sets of embeddings deviate from each other. In this paper, we propose a novel metric called Relative pairwise inner Product Distance (RPD) to quantify the distance between different sets of word embeddings. This metric has a unified scale for comparing different sets of word embeddings. Based on the properties of RPD, we study the relations of word embeddings of different algorithms systematically, and investigate the influence of different training processes and corpora. The results shed light on the poorly understood word embeddings and justify RPD as a measure of the distance of embedding spaces.","RPD: A Distance Function Between Word Embeddings It is well-understood that different algorithms, training processes, and corpora produce different word embeddings. However, less is known about the relation between different embedding spaces, i.e. how far different sets of embeddings deviate from each other. In this paper, we propose a novel metric called Relative pairwise inner Product Distance (RPD) to quantify the distance between different sets of word embeddings. This metric has a unified scale for comparing different sets of word embeddings. Based on the properties of RPD, we study the relations of word embeddings of different algorithms systematically, and investigate the influence of different training processes and corpora. The results shed light on the poorly understood word embeddings and justify RPD as a measure of the distance of embedding spaces.","rpd : distance function word embedding - understand different algorithm , training process , corpus produce different word embedding . , know relation different embedding space , i.e. far different set embedding deviate . paper , propose novel metric call relative pairwise inner product distance ( rpd ) quantify distance different set word embedding . metric unified scale compare different set word embedding . base property rpd , study relation word embedding different algorithm systematically , investigate influence different training process corpus . result shed light poorly understand word embedding justify rpd measure distance embed space .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 10, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 12, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 4, 'Speech and Multimodality': 0, 'Student Research Workshop': 2, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Student Research Workshop,Crossing the Line: Where do Demographic Variables Fit into Humor Detection?,"Recent shared tasks in humor classification have struggled with two issues: scope and subjectivity. Regarding scope, many task datasets either comprise a highly constrained genre of humor which does not broadly represent the genre, or the data collection is so indiscriminate that the inter-annotator agreement on its comic content is drastically low. In terms of subjectivity, these tasks typically average over all annotators' judgments, in spite of the fact that humor is highly subjective and varies both between and within cultures. We propose a dataset which maintains a broad scope but which addresses subjectivity. We will collect demographic information about the data's humor annotators in order to bin ratings more sensibly. We also suggest the addition of an 'offensive' label to reflect the fact a text may be humorous to one group, but offensive to another. This would allow for more meaningful shared tasks and could lead to better performance on downstream applications, such as content moderation.","Crossing the Line: Where do Demographic Variables Fit into Humor Detection? Recent shared tasks in humor classification have struggled with two issues: scope and subjectivity. Regarding scope, many task datasets either comprise a highly constrained genre of humor which does not broadly represent the genre, or the data collection is so indiscriminate that the inter-annotator agreement on its comic content is drastically low. In terms of subjectivity, these tasks typically average over all annotators' judgments, in spite of the fact that humor is highly subjective and varies both between and within cultures. We propose a dataset which maintains a broad scope but which addresses subjectivity. We will collect demographic information about the data's humor annotators in order to bin ratings more sensibly. We also suggest the addition of an 'offensive' label to reflect the fact a text may be humorous to one group, but offensive to another. This would allow for more meaningful shared tasks and could lead to better performance on downstream applications, such as content moderation.","cross line : demographic variable fit humor detection ? recent share task humor classification struggle issue : scope subjectivity . scope , task dataset comprise highly constrained genre humor broadly represent genre , data collection indiscriminate inter - annotator agreement comic content drastically low . term subjectivity , task typically average annotator ' judgment , spite fact humor highly subjective vary culture . propose dataset maintain broad scope address subjectivity . collect demographic information data humor annotator order bin rating sensibly . suggest addition ' offensive ' label reflect fact text humorous group , offensive . allow meaningful share task lead well performance downstream application , content moderation .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 2, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Student Research Workshop,Zero-shot North Korean to English Neural Machine Translation by Character Tokenization and Phoneme Decomposition,"The primary limitation of North Korean to English translation is the lack of a parallel corpus; therefore, high translation accuracy cannot be achieved. To address this problem, we propose a zero-shot approach using South Korean data, which are remarkably similar to North Korean data. We train a neural machine translation model after tokenizing a South Korean text at the character level and decomposing characters into phonemes. We demonstrate that our method can effectively learn North Korean to English translation and improve the BLEU scores by +1.01 points in comparison with the baseline.","Zero-shot North Korean to English Neural Machine Translation by Character Tokenization and Phoneme Decomposition The primary limitation of North Korean to English translation is the lack of a parallel corpus; therefore, high translation accuracy cannot be achieved. To address this problem, we propose a zero-shot approach using South Korean data, which are remarkably similar to North Korean data. We train a neural machine translation model after tokenizing a South Korean text at the character level and decomposing characters into phonemes. We demonstrate that our method can effectively learn North Korean to English translation and improve the BLEU scores by +1.01 points in comparison with the baseline.","zero - shot north korean english neural machine translation character tokenization phoneme decomposition primary limitation north korean english translation lack parallel corpus ; , high translation accuracy achieve . address problem , propose zero - shot approach south korean datum , remarkably similar north korean datum . train neural machine translation model tokenize south korean text character level decompose character phoneme . demonstrate method effectively learn north korean english translation improve bleu score +1.01 point comparison baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Student Research Workshop,HGCN4MeSH: Hybrid Graph Convolution Network for MeSH Indexing,"Recently, deep learning has been used in Medical Subject Headings (MeSH) indexing to reduce the labor costs associated with manual annotation, including DeepMeSH, TextCNN, etc. However, these models fail to capture the complex correlations between MeSH terms. To this end, we use a Graph Convolution Network (GCN) to learn the relationship between these terms and present a novel Hybrid Graph Convolution Net for MeSH index (HGCN4MeSH). We utilize two bidirectional GRUs to learn the embedding representation of the abstract and the title of the MeSH index text respectively. We construct the adjacency matrix of MeSH terms, based on the co-occurence relationships in corpus, and use the matrix to learn representations using the GCN. On the basis of learning the joint representation, the prediction problem of the MeSH index keywords is an extreme multi-label classification problem after the attention layer operation. Experimental results on two datasets show that HGCN4MeSH is competitive with the state-of-the-art methods.","HGCN4MeSH: Hybrid Graph Convolution Network for MeSH Indexing Recently, deep learning has been used in Medical Subject Headings (MeSH) indexing to reduce the labor costs associated with manual annotation, including DeepMeSH, TextCNN, etc. However, these models fail to capture the complex correlations between MeSH terms. To this end, we use a Graph Convolution Network (GCN) to learn the relationship between these terms and present a novel Hybrid Graph Convolution Net for MeSH index (HGCN4MeSH). We utilize two bidirectional GRUs to learn the embedding representation of the abstract and the title of the MeSH index text respectively. We construct the adjacency matrix of MeSH terms, based on the co-occurence relationships in corpus, and use the matrix to learn representations using the GCN. On the basis of learning the joint representation, the prediction problem of the MeSH index keywords is an extreme multi-label classification problem after the attention layer operation. Experimental results on two datasets show that HGCN4MeSH is competitive with the state-of-the-art methods.","hgcn4mesh : hybrid graph convolution network mesh indexing recently , deep learning medical subject headings ( mesh ) indexing reduce labor cost associate manual annotation , include deepmesh , textcnn , etc . , model fail capture complex correlation mesh term . end , use graph convolution network ( gcn ) learn relationship term present novel hybrid graph convolution net mesh index ( hgcn4mesh ) . utilize bidirectional gru learn embedding representation abstract title mesh index text respectively . construct adjacency matrix mesh term , base co - occurence relationship corpus , use matrix learn representation gcn . basis learn joint representation , prediction problem mesh index keyword extreme multi - label classification problem attention layer operation . experimental result dataset hgcn4mesh competitive state - - - art method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 5, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 12, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,True
Student Research Workshop,Logical Inferences with Comparatives and Generalized Quantifiers,"Comparative constructions pose a challenge in Natural Language Inference (NLI), which is the task of determining whether a text entails a hypothesis. Comparatives are structurally complex in that they interact with other linguistic phenomena such as quantifiers, numerals, and lexical antonyms. In formal semantics, there is a rich body of work on comparatives and gradable expressions using the notion of degree. However, a logical inference system for comparatives has not been sufficiently developed for use in the NLI task. In this paper, we present a compositional semantics that maps various comparative constructions in English to semantic representations via Combinatory Categorial Grammar (CCG) parsers and combine it with an inference system based on automated theorem proving. We evaluate our system on three NLI datasets that contain complex logical inferences with comparatives, generalized quantifiers, and numerals. We show that the system outperforms previous logic-based systems as well as recent deep learning-based models.","Logical Inferences with Comparatives and Generalized Quantifiers Comparative constructions pose a challenge in Natural Language Inference (NLI), which is the task of determining whether a text entails a hypothesis. Comparatives are structurally complex in that they interact with other linguistic phenomena such as quantifiers, numerals, and lexical antonyms. In formal semantics, there is a rich body of work on comparatives and gradable expressions using the notion of degree. However, a logical inference system for comparatives has not been sufficiently developed for use in the NLI task. In this paper, we present a compositional semantics that maps various comparative constructions in English to semantic representations via Combinatory Categorial Grammar (CCG) parsers and combine it with an inference system based on automated theorem proving. We evaluate our system on three NLI datasets that contain complex logical inferences with comparatives, generalized quantifiers, and numerals. We show that the system outperforms previous logic-based systems as well as recent deep learning-based models.","logical inference comparatives generalized quantifier comparative construction pose challenge natural language inference ( nli ) , task determine text entail hypothesis . comparative structurally complex interact linguistic phenomenon quantifier , numeral , lexical antonym . formal semantic , rich body work comparative gradable expression notion degree . , logical inference system comparative sufficiently develop use nli task . paper , present compositional semantics map comparative construction english semantic representation combinatory categorial grammar ( ccg ) parser combine inference system base automate theorem proving . evaluate system nli dataset contain complex logical inference comparative , generalize quantifier , numeral . system outperform previous logic - base system recent deep learning - base model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 11, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}","Semantics: Sentence-level Semantics, Textual Inference and Other areas",False
Student Research Workshop,Research on Task Discovery for Transfer Learning in Deep Neural Networks,"Deep neural network based machine learning models are shown to perform poorly on unseen or out-of-domain examples by numerous recent studies. Transfer learning aims to avoid overfitting and to improve generalizability by leveraging the information obtained from multiple tasks. Yet, the benefits of transfer learning depend largely on task selection and finding the right method of sharing. In this thesis, we hypothesize that current deep neural network based transfer learning models do not achieve their fullest potential for various tasks and there are still many task combinations that will benefit from transfer learning that are not considered by the current models. To this end, we started our research by implementing a novel multi-task learner with relaxed annotated data requirements and obtained a performance improvement on two NLP tasks. We will further devise models to tackle tasks from multiple areas of machine learning, such as Bioinformatics and Computer Vision, in addition to NLP.","Research on Task Discovery for Transfer Learning in Deep Neural Networks Deep neural network based machine learning models are shown to perform poorly on unseen or out-of-domain examples by numerous recent studies. Transfer learning aims to avoid overfitting and to improve generalizability by leveraging the information obtained from multiple tasks. Yet, the benefits of transfer learning depend largely on task selection and finding the right method of sharing. In this thesis, we hypothesize that current deep neural network based transfer learning models do not achieve their fullest potential for various tasks and there are still many task combinations that will benefit from transfer learning that are not considered by the current models. To this end, we started our research by implementing a novel multi-task learner with relaxed annotated data requirements and obtained a performance improvement on two NLP tasks. We will further devise models to tackle tasks from multiple areas of machine learning, such as Bioinformatics and Computer Vision, in addition to NLP.","research task discovery transfer learning deep neural networks deep neural network base machine learning model show perform poorly unseen - - domain example numerous recent study . transfer learning aim avoid overfitting improve generalizability leverage information obtain multiple task . , benefit transfer learning depend largely task selection find right method sharing . thesis , hypothesize current deep neural network base transfer learning model achieve full potential task task combination benefit transfer learning consider current model . end , start research implement novel multi - task learner relaxed annotate datum requirement obtain performance improvement nlp task . devise model tackle task multiple area machine learning , bioinformatics computer vision , addition nlp .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 2, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Phonology, Morphology and Word Segmentation",False
Student Research Workshop,Why is penguin more similar to polar bear than to sea gull? Analyzing conceptual knowledge in distributional models,"What do powerful models of word meaning created from distributional data (e.g. Word2vec (Mikolov et al., 2013)  BERT (Devlin et al., 2019) and ELMO (Peters et al.,  2018)) represent? What causes words to be similar in the semantic space? What type of information is lacking? This thesis proposal presents a framework for investigating the information encoded in distributional semantic models. Several analysis methods have been suggested, but they have been shown to be limited and are not well understood. This approach pairs observations made on actual corpora with insights obtained from data manipulation experiments. The expected outcome is a better understanding of (1) the semantic information we can infer purely based on linguistic co-occurrence patterns and (2) the potential of distributional semantic models to pick up linguistic evidence.","Why is penguin more similar to polar bear than to sea gull? Analyzing conceptual knowledge in distributional models What do powerful models of word meaning created from distributional data (e.g. Word2vec (Mikolov et al., 2013)  BERT (Devlin et al., 2019) and ELMO (Peters et al.,  2018)) represent? What causes words to be similar in the semantic space? What type of information is lacking? This thesis proposal presents a framework for investigating the information encoded in distributional semantic models. Several analysis methods have been suggested, but they have been shown to be limited and are not well understood. This approach pairs observations made on actual corpora with insights obtained from data manipulation experiments. The expected outcome is a better understanding of (1) the semantic information we can infer purely based on linguistic co-occurrence patterns and (2) the potential of distributional semantic models to pick up linguistic evidence.","penguin similar polar bear sea gull ? analyze conceptual knowledge distributional model powerful model word meaning create distributional datum ( e.g. word2vec ( mikolov et al . , 2013 )   bert ( devlin et al . , 2019 ) elmo ( peters et al . ,   2018 ) ) represent ? cause word similar semantic space ? type information lack ? thesis proposal present framework investigate information encode distributional semantic model . analysis method suggest , show limited understand . approach pair observation actual corpus insight obtain datum manipulation experiment . expect outcome well understanding ( 1 ) semantic information infer purely base linguistic co - occurrence pattern ( 2 ) potential distributional semantic model pick linguistic evidence .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 7, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 4, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Student Research Workshop,Feature Difference Makes Sense: A medical image captioning model exploiting feature difference and tag information,"Medical image captioning can reduce the workload of physicians and save time and expense by automatically generating reports. However, current datasets are small and limited, creating additional challenges for researchers. In this study, we propose a feature difference and tag information combined long short-term memory (LSTM) model for chest x-ray report generation. A feature vector extracted from the image conveys visual information, but its ability to describe the image is limited. Other image captioning studies exhibited improved performance by exploiting feature differences, so the proposed model also utilizes them. First, we propose a difference and tag (DiTag) model containing the difference between the patient and normal images. Then, we propose a multi-difference and tag (mDiTag) model that also contains information about low-level differences, such as contrast, texture, and localized area. Evaluation of the proposed models demonstrates that the mDiTag model provides more information to generate captions and outperforms all other models.","Feature Difference Makes Sense: A medical image captioning model exploiting feature difference and tag information Medical image captioning can reduce the workload of physicians and save time and expense by automatically generating reports. However, current datasets are small and limited, creating additional challenges for researchers. In this study, we propose a feature difference and tag information combined long short-term memory (LSTM) model for chest x-ray report generation. A feature vector extracted from the image conveys visual information, but its ability to describe the image is limited. Other image captioning studies exhibited improved performance by exploiting feature differences, so the proposed model also utilizes them. First, we propose a difference and tag (DiTag) model containing the difference between the patient and normal images. Then, we propose a multi-difference and tag (mDiTag) model that also contains information about low-level differences, such as contrast, texture, and localized area. Evaluation of the proposed models demonstrates that the mDiTag model provides more information to generate captions and outperforms all other models.","feature difference make sense : medical image captioning model exploit feature difference tag information medical image captioning reduce workload physician save time expense automatically generate report . , current dataset small limited , create additional challenge researcher . study , propose feature difference tag information combine long short - term memory ( lstm ) model chest x - ray report generation . feature vector extract image convey visual information , ability describe image limited . image captioning study exhibit improve performance exploit feature difference , propose model utilize . , propose difference tag ( ditag ) model contain difference patient normal image . , propose multi - difference tag ( mditag ) model contain information low - level difference , contrast , texture , localize area . evaluation propose model demonstrate mditag model provide information generate caption outperform model .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 11, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 8, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Language Grounding to Vision, Robotics and Beyond",False
Student Research Workshop,Preventing Critical Scoring Errors in Short Answer Scoring with Confidence Estimation,"Many recent Short Answer Scoring (SAS) systems have employed Quadratic Weighted Kappa (QWK) as the evaluation measure of their systems. However, we hypothesize that QWK is unsatisfactory for the evaluation of the SAS systems when we consider measuring their effectiveness in actual usage. We introduce a new task formulation of SAS that matches the actual usage. In our formulation, the SAS systems should extract as many scoring predictions that are not critical scoring errors (CSEs). We conduct the experiments in our new task formulation and demonstrate that a typical SAS system can predict scores with zero CSE for approximately 50% of test data at maximum by filtering out low-reliablility predictions on the basis of a certain confidence estimation. This result directly indicates the possibility of reducing half the scoring cost of human raters, which is more preferable for the evaluation of SAS systems.","Preventing Critical Scoring Errors in Short Answer Scoring with Confidence Estimation Many recent Short Answer Scoring (SAS) systems have employed Quadratic Weighted Kappa (QWK) as the evaluation measure of their systems. However, we hypothesize that QWK is unsatisfactory for the evaluation of the SAS systems when we consider measuring their effectiveness in actual usage. We introduce a new task formulation of SAS that matches the actual usage. In our formulation, the SAS systems should extract as many scoring predictions that are not critical scoring errors (CSEs). We conduct the experiments in our new task formulation and demonstrate that a typical SAS system can predict scores with zero CSE for approximately 50% of test data at maximum by filtering out low-reliablility predictions on the basis of a certain confidence estimation. This result directly indicates the possibility of reducing half the scoring cost of human raters, which is more preferable for the evaluation of SAS systems.","prevent critical scoring error short answer scoring confidence estimation recent short answer scoring ( sas ) system employ quadratic weighted kappa ( qwk ) evaluation measure system . , hypothesize qwk unsatisfactory evaluation sas system consider measure effectiveness actual usage . introduce new task formulation sas match actual usage . formulation , sas system extract scoring prediction critical scoring error ( cse ) . conduct experiment new task formulation demonstrate typical sas system predict score zero cse approximately 50 % test datum maximum filter low - reliablility prediction basis certain confidence estimation . result directly indicate possibility reduce half scoring cost human rater , preferable evaluation sas system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 2, 'Resources and Evaluation': 3, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 6, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",System Demonstrations,False
Student Research Workshop,Efficient Neural Machine Translation for Low-Resource Languages via Exploiting Related Languages,"A large percentage of the world's population speaks a language of the Indian subcontinent, comprising languages from both Indo-Aryan (e.g. Hindi, Punjabi, Gujarati, etc.) and Dravidian (e.g. Tamil, Telugu, Malayalam, etc.) families. A universal characteristic of Indian languages is their complex morphology, which, when combined with the general lack of sufficient quantities of high-quality parallel data, can make developing machine translation (MT) systems for these languages difficult. Neural Machine Translation (NMT) is a rapidly advancing MT paradigm and has shown promising results for many language pairs, especially in large training data scenarios. Since the condition of large parallel corpora is not met for Indian-English language pairs, we present our efforts towards building efficient NMT systems between Indian languages (specifically Indo-Aryan languages) and English via efficiently exploiting parallel data from the related languages. We propose a technique called Unified Transliteration and Subword Segmentation to leverage language similarity while exploiting parallel data from related language pairs. We also propose a Multilingual Transfer Learning technique to leverage parallel data from multiple related languages to assist translation for lowresource language pair of interest. Our experiments demonstrate an overall average improvement of 5 BLEU points over the standard Transformer-based NMT baselines.","Efficient Neural Machine Translation for Low-Resource Languages via Exploiting Related Languages A large percentage of the world's population speaks a language of the Indian subcontinent, comprising languages from both Indo-Aryan (e.g. Hindi, Punjabi, Gujarati, etc.) and Dravidian (e.g. Tamil, Telugu, Malayalam, etc.) families. A universal characteristic of Indian languages is their complex morphology, which, when combined with the general lack of sufficient quantities of high-quality parallel data, can make developing machine translation (MT) systems for these languages difficult. Neural Machine Translation (NMT) is a rapidly advancing MT paradigm and has shown promising results for many language pairs, especially in large training data scenarios. Since the condition of large parallel corpora is not met for Indian-English language pairs, we present our efforts towards building efficient NMT systems between Indian languages (specifically Indo-Aryan languages) and English via efficiently exploiting parallel data from the related languages. We propose a technique called Unified Transliteration and Subword Segmentation to leverage language similarity while exploiting parallel data from related language pairs. We also propose a Multilingual Transfer Learning technique to leverage parallel data from multiple related languages to assist translation for lowresource language pair of interest. Our experiments demonstrate an overall average improvement of 5 BLEU points over the standard Transformer-based NMT baselines.","efficient neural machine translation low - resource language exploit related language large percentage world population speak language indian subcontinent , comprise language indo - aryan ( e.g. hindi , punjabi , gujarati , etc . ) dravidian ( e.g. tamil , telugu , malayalam , etc . ) family . universal characteristic indian language complex morphology , , combine general lack sufficient quantity high - quality parallel datum , develop machine translation ( mt ) system language difficult . neural machine translation ( nmt ) rapidly advance mt paradigm show promising result language pair , especially large training datum scenario . condition large parallel corpora meet indian - english language pair , present effort build efficient nmt system indian language ( specifically indo - aryan language ) english efficiently exploit parallel datum related language . propose technique call unified transliteration subword segmentation leverage language similarity exploit parallel datum related language pair . propose multilingual transfer learning technique leverage parallel datum multiple related language assist translation lowresource language pair interest . experiment demonstrate overall average improvement 5 bleu point standard transformer - base nmt baseline .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 16, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 7, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 2, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Student Research Workshop,Pointwise Paraphrase Appraisal is Potentially Problematic,"The prevailing approach for training and evaluating paraphrase identification models is constructed as a binary classification problem: the model is given a pair of sentences, and is judged by how accurately it classifies pairs as either paraphrases or non-paraphrases. This pointwise-based evaluation method does not match well the objective of most real world applications, so the goal of our work is to understand how models which perform well under pointwise evaluation may fail in practice and find better methods for evaluating paraphrase identification models. As a first step towards that goal, we show that although the standard way of fine-tuning BERT for paraphrase identification by pairing two sentences as one sequence results in a model with state-of-the-art performance, that model may perform poorly on simple tasks like identifying pairs with two identical sentences. Moreover, we show that these models may even predict a pair of randomly-selected sentences with higher paraphrase score than a pair of identical ones.","Pointwise Paraphrase Appraisal is Potentially Problematic The prevailing approach for training and evaluating paraphrase identification models is constructed as a binary classification problem: the model is given a pair of sentences, and is judged by how accurately it classifies pairs as either paraphrases or non-paraphrases. This pointwise-based evaluation method does not match well the objective of most real world applications, so the goal of our work is to understand how models which perform well under pointwise evaluation may fail in practice and find better methods for evaluating paraphrase identification models. As a first step towards that goal, we show that although the standard way of fine-tuning BERT for paraphrase identification by pairing two sentences as one sequence results in a model with state-of-the-art performance, that model may perform poorly on simple tasks like identifying pairs with two identical sentences. Moreover, we show that these models may even predict a pair of randomly-selected sentences with higher paraphrase score than a pair of identical ones.","pointwise paraphrase appraisal potentially problematic prevailing approach train evaluate paraphrase identification model construct binary classification problem : model give pair sentence , judge accurately classify pair paraphrase non - paraphrase . pointwise - base evaluation method match objective real world application , goal work understand model perform pointwise evaluation fail practice find well method evaluate paraphrase identification model . step goal , standard way fine - tune bert paraphrase identification pair sentence sequence result model state - - - art performance , model perform poorly simple task like identify pair identical sentence . , model predict pair randomly - select sentence high paraphrase score pair identical one .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 0, 'Resources and Evaluation': 2, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Learning for NLP,False
Student Research Workshop,Understanding Points of Correspondence between Sentences for Abstractive Summarization,"Fusing sentences containing disparate content is a remarkable human ability that helps create informative and succinct summaries. Such a simple task for humans has remained challenging for modern abstractive summarizers, substantially restricting their applicability in realworld scenarios. In this paper, we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text. The types of points of correspondence are delineated by text cohesion theory, covering pronominal and nominal referencing, repetition and beyond. We create a dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences. Our dataset bridges the gap between coreference resolution and summarization. It is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems. 1","Understanding Points of Correspondence between Sentences for Abstractive Summarization Fusing sentences containing disparate content is a remarkable human ability that helps create informative and succinct summaries. Such a simple task for humans has remained challenging for modern abstractive summarizers, substantially restricting their applicability in realworld scenarios. In this paper, we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text. The types of points of correspondence are delineated by text cohesion theory, covering pronominal and nominal referencing, repetition and beyond. We create a dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences. Our dataset bridges the gap between coreference resolution and summarization. It is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems. 1","understand point correspondence sentence abstractive summarization fuse sentence contain disparate content remarkable human ability help create informative succinct summary . simple task human remain challenging modern abstractive summarizer , substantially restrict applicability realworld scenario . paper , present investigation fuse sentence draw document introduce notion point correspondence , cohesive device tie sentence coherent text . type point correspondence delineate text cohesion theory , cover pronominal nominal referencing , repetition . create dataset contain document , source fusion sentence , human annotation point correspondence sentence . dataset bridge gap coreference resolution summarization . publicly share serve basis future work measure success sentence fusion system . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 2, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 4, 'Summarization': 8, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Summarization,False
Student Research Workshop,Exploring Interpretability in Event Extraction: Multitask Learning of a Neural Event Classifier and an Explanation Decoder,"We propose an interpretable approach for event extraction that mitigates the tension between generalization and interpretability by jointly training for the two goals. Our approach uses an encoder-decoder architecture, which jointly trains a classifier for event extraction, and a rule decoder that generates syntactico-semantic rules that explain the decisions of the event classifier. We evaluate the proposed approach on three biomedical events and show that the decoder generates interpretable rules that serve as accurate explanations for the event classifier's decisions, and, importantly, that the joint training generally improves the performance of the event classifier. Lastly, we show that our approach can be used for semi-supervised learning, and that its performance improves when trained on automatically-labeled data generated by a rulebased system.","Exploring Interpretability in Event Extraction: Multitask Learning of a Neural Event Classifier and an Explanation Decoder We propose an interpretable approach for event extraction that mitigates the tension between generalization and interpretability by jointly training for the two goals. Our approach uses an encoder-decoder architecture, which jointly trains a classifier for event extraction, and a rule decoder that generates syntactico-semantic rules that explain the decisions of the event classifier. We evaluate the proposed approach on three biomedical events and show that the decoder generates interpretable rules that serve as accurate explanations for the event classifier's decisions, and, importantly, that the joint training generally improves the performance of the event classifier. Lastly, we show that our approach can be used for semi-supervised learning, and that its performance improves when trained on automatically-labeled data generated by a rulebased system.","explore interpretability event extraction : multitask learning neural event classifier explanation decoder propose interpretable approach event extraction mitigate tension generalization interpretability jointly train goal . approach use encoder - decoder architecture , jointly train classifier event extraction , rule decoder generate syntactico - semantic rule explain decision event classifier . evaluate propose approach biomedical event decoder generate interpretable rule serve accurate explanation event classifier decision , , importantly , joint training generally improve performance event classifier . lastly , approach semi - supervised learning , performance improve train automatically - label datum generate rulebase system .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 8, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 2, 'Language Grounding to Vision, Robotics and Beyond': 3, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 4, 'Machine Translation and Multilinguality': 1, 'NLP Applications': 5, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 3, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 3, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 1, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Student Research Workshop,Research Replication Prediction Using Weakly Supervised Learning,"Knowing whether a published research result can be replicated is important. Carrying out direct replication of published research incurs a high cost. There are efforts tried to use machine learning aided methods to predict scientific claims' replicability. However, existing machine learning aided approaches use only hand-extracted statistics features such as p-value, sample size, etc. without utilizing research papers' text information and train only on a very small size of annotated data without making the most use of a large number of unlabeled articles. Therefore, it is desirable to develop effective machine learning aided automatic methods which can automatically extract text information as features so that we can benefit from Natural Language Processing techniques. Besides, we aim for an approach that benefits from both labeled and the large number of unlabeled data. In this paper, we propose two weakly supervised learning approaches that use automatically extracted text information of research papers to improve the prediction accuracy of research replication using both labeled and unlabeled datasets. Our experiments over real-world datasets show that our approaches obtain much better prediction performance compared to the supervised models utilizing only statistic features and a small size of labeled dataset. Further, we are able to achieve an accuracy of 75.76% for predicting the replicability of research.","Research Replication Prediction Using Weakly Supervised Learning Knowing whether a published research result can be replicated is important. Carrying out direct replication of published research incurs a high cost. There are efforts tried to use machine learning aided methods to predict scientific claims' replicability. However, existing machine learning aided approaches use only hand-extracted statistics features such as p-value, sample size, etc. without utilizing research papers' text information and train only on a very small size of annotated data without making the most use of a large number of unlabeled articles. Therefore, it is desirable to develop effective machine learning aided automatic methods which can automatically extract text information as features so that we can benefit from Natural Language Processing techniques. Besides, we aim for an approach that benefits from both labeled and the large number of unlabeled data. In this paper, we propose two weakly supervised learning approaches that use automatically extracted text information of research papers to improve the prediction accuracy of research replication using both labeled and unlabeled datasets. Our experiments over real-world datasets show that our approaches obtain much better prediction performance compared to the supervised models utilizing only statistic features and a small size of labeled dataset. Further, we are able to achieve an accuracy of 75.76% for predicting the replicability of research.","research replication prediction weakly supervise learn know publish research result replicate important . carry direct replication publish research incur high cost . effort try use machine learning aid method predict scientific claim ' replicability . , exist machine learning aid approach use hand - extract statistic feature p - value , sample size , etc . utilize research paper ' text information train small size annotate datum make use large number unlabeled article . , desirable develop effective machine learning aid automatic method automatically extract text information feature benefit natural language processing technique . , aim approach benefit label large number unlabeled datum . paper , propose weakly supervise learning approach use automatically extract text information research paper improve prediction accuracy research replication label unlabeled dataset . experiment real - world dataset approach obtain well prediction performance compare supervise model utilize statistic feature small size label dataset . , able achieve accuracy 75.76 % predict replicability research .","{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 3, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 3, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 5, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 7, 'Theme': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Resources and Evaluation,False
Student Research Workshop,How much complexity does an RNN architecture need to learn syntax-sensitive dependencies?,"Long short-term memory (LSTM) networks and their variants are capable of encapsulating long-range dependencies, which is evident from their performance on a variety of linguistic tasks. On the other hand, simple recurrent networks (SRNs), which appear more biologically grounded in terms of synaptic connections, have generally been less successful at capturing long-range dependencies as well as the loci of grammatical errors in an unsupervised setting. In this paper, we seek to develop models that bridge the gap between biological plausibility and linguistic competence. We propose a new architecture, the Decay RNN, which incorporates the decaying nature of neuronal activations and models the excitatory and inhibitory connections in a population of neurons. Besides its biological inspiration, our model also shows competitive performance relative to LSTMs on subject-verb agreement, sentence grammaticality, and language modeling tasks. These results provide some pointers towards probing the nature of the inductive biases required for RNN architectures to model linguistic phenomena successfully.","How much complexity does an RNN architecture need to learn syntax-sensitive dependencies? Long short-term memory (LSTM) networks and their variants are capable of encapsulating long-range dependencies, which is evident from their performance on a variety of linguistic tasks. On the other hand, simple recurrent networks (SRNs), which appear more biologically grounded in terms of synaptic connections, have generally been less successful at capturing long-range dependencies as well as the loci of grammatical errors in an unsupervised setting. In this paper, we seek to develop models that bridge the gap between biological plausibility and linguistic competence. We propose a new architecture, the Decay RNN, which incorporates the decaying nature of neuronal activations and models the excitatory and inhibitory connections in a population of neurons. Besides its biological inspiration, our model also shows competitive performance relative to LSTMs on subject-verb agreement, sentence grammaticality, and language modeling tasks. These results provide some pointers towards probing the nature of the inductive biases required for RNN architectures to model linguistic phenomena successfully.","complexity rnn architecture need learn syntax - sensitive dependency ? long short - term memory ( lstm ) network variant capable encapsulate long - range dependency , evident performance variety linguistic task . hand , simple recurrent network ( srns ) , appear biologically grounded term synaptic connection , generally successful capture long - range dependency loci grammatical error unsupervised setting . paper , seek develop model bridge gap biological plausibility linguistic competence . propose new architecture , decay rnn , incorporate decay nature neuronal activation model excitatory inhibitory connection population neuron . biological inspiration , model show competitive performance relative lstm subject - verb agreement , sentence grammaticality , language modeling task . result provide pointer probe nature inductive bias require rnn architecture model linguistic phenomenon successfully .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 4, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'System Demonstrations': 0, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 4}",Interpretability and Analysis of Models for NLP,False
Student Research Workshop,Multi-Task Neural Model for Agglutinative Language Translation,"Neural machine translation (NMT) has achieved impressive performance recently by using large-scale parallel corpora. However, it struggles in the low-resource and morphologically-rich scenarios of agglutinative language translation task. Inspired by the finding that monolingual data can greatly improve the NMT performance, we propose a multi-task neural model that jointly learns to perform bi-directional translation and agglutinative language stemming. Our approach employs the shared encoder and decoder to train a single model without changing the standard NMT architecture but instead adding a token before each source-side sentence to specify the desired target outputs of the two different tasks. Experimental results on Turkish-English and Uyghur-Chinese show that our proposed approach can significantly improve the translation performance on agglutinative languages by using a small amount of monolingual data.","Multi-Task Neural Model for Agglutinative Language Translation Neural machine translation (NMT) has achieved impressive performance recently by using large-scale parallel corpora. However, it struggles in the low-resource and morphologically-rich scenarios of agglutinative language translation task. Inspired by the finding that monolingual data can greatly improve the NMT performance, we propose a multi-task neural model that jointly learns to perform bi-directional translation and agglutinative language stemming. Our approach employs the shared encoder and decoder to train a single model without changing the standard NMT architecture but instead adding a token before each source-side sentence to specify the desired target outputs of the two different tasks. Experimental results on Turkish-English and Uyghur-Chinese show that our proposed approach can significantly improve the translation performance on agglutinative languages by using a small amount of monolingual data.","multi - task neural model agglutinative language translation neural machine translation ( nmt ) achieve impressive performance recently large - scale parallel corpora . , struggle low - resource morphologically - rich scenario agglutinative language translation task . inspire finding monolingual datum greatly improve nmt performance , propose multi - task neural model jointly learn perform bi - directional translation agglutinative language stemming . approach employ share encoder decoder train single model change standard nmt architecture instead add token source - sentence specify desire target output different task . experimental result turkish - english uyghur - chinese propose approach significantly improve translation performance agglutinative language small monolingual datum .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 2, 'Phonology, Morphology and Word Segmentation': 6, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 3, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Student Research Workshop,Unsupervised Paraphasia Classification in Aphasic Speech,"Aphasia is a speech and language disorder that results from brain damage, often characterized by word retrieval deficit (anomia) resulting in naming errors (paraphasia). Automatic paraphasia detection has many benefits for both treatment and diagnosis of Aphasia and its type. But supervised learning methods cant be utilized adequately as there is a lack of aphasic speech data. In this paper, we describe our novel unsupervised method, which can be implemented without the need for labeled paraphasia data. Our evaluations show that our method outperforms previous work based on supervised learning and transfer learning approaches for English. We demonstrate the utility of our method as an essential first step in developing augmentative and alternative communication (AAC) devices for patients suffering from aphasia in any language.","Unsupervised Paraphasia Classification in Aphasic Speech Aphasia is a speech and language disorder that results from brain damage, often characterized by word retrieval deficit (anomia) resulting in naming errors (paraphasia). Automatic paraphasia detection has many benefits for both treatment and diagnosis of Aphasia and its type. But supervised learning methods cant be utilized adequately as there is a lack of aphasic speech data. In this paper, we describe our novel unsupervised method, which can be implemented without the need for labeled paraphasia data. Our evaluations show that our method outperforms previous work based on supervised learning and transfer learning approaches for English. We demonstrate the utility of our method as an essential first step in developing augmentative and alternative communication (AAC) devices for patients suffering from aphasia in any language.","unsupervised paraphasia classification aphasic speech aphasia speech language disorder result brain damage , characterize word retrieval deficit ( anomia ) result naming error ( paraphasia ) . automatic paraphasia detection benefit treatment diagnosis aphasia type . supervise learning method nt utilize adequately lack aphasic speech datum . paper , describe novel unsupervised method , implement need label paraphasia datum . evaluation method outperform previous work base supervise learning transfer learning approach english . demonstrate utility method essential step develop augmentative alternative communication ( aac ) device patient suffer aphasia language .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 2, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 3, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 2, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 3, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Linguistic Theories, Cognitive Modeling and Psycholinguistics",False
Student Research Workshop,Story-level Text Style Transfer: A Proposal,"Text style transfer aims to change the style of the input text to the target style while preserving the content to some extent. Previous works on this task are on the sentence level. We aim to work on story-level text style transfer to generate stories that preserve the plot of the input story while exhibiting a strong target style. The challenge in this task compared to previous work is that the structure of the input story, consisting of leading roles and their relations with each other, needs to be preserved, and that the generated story needs to be consistent after adding flavors. We plan to explore three methods including the BERT-based method, the Story Realization method, and the Graph-based method.","Story-level Text Style Transfer: A Proposal Text style transfer aims to change the style of the input text to the target style while preserving the content to some extent. Previous works on this task are on the sentence level. We aim to work on story-level text style transfer to generate stories that preserve the plot of the input story while exhibiting a strong target style. The challenge in this task compared to previous work is that the structure of the input story, consisting of leading roles and their relations with each other, needs to be preserved, and that the generated story needs to be consistent after adding flavors. We plan to explore three methods including the BERT-based method, the Story Realization method, and the Graph-based method.","story - level text style transfer : proposal text style transfer aim change style input text target style preserve content extent . previous work task sentence level . aim work story - level text style transfer generate story preserve plot input story exhibit strong target style . challenge task compare previous work structure input story , consist leading role relation , need preserve , generate story need consistent add flavor . plan explore method include bert - base method , story realization method , graph - base method .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 14, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Generation,False
Student Research Workshop,Embeddings of Label Components for Sequence Labeling: A Case Study of Fine-grained Named Entity Recognition,"In general, the labels used in sequence labeling consist of different types of elements. For example, IOB-format entity labels, such as B-Person and I-Person, can be decomposed into span (B and I) and type information (Person). However, while most sequence labeling models do not consider such label components, the shared components across labels, such as Person, can be beneficial for label prediction. In this work, we propose to integrate label component information as embeddings into models. Through experiments on English and Japanese fine-grained named entity recognition, we demonstrate that the proposed method improves performance, especially for instances with low-frequency labels.","Embeddings of Label Components for Sequence Labeling: A Case Study of Fine-grained Named Entity Recognition In general, the labels used in sequence labeling consist of different types of elements. For example, IOB-format entity labels, such as B-Person and I-Person, can be decomposed into span (B and I) and type information (Person). However, while most sequence labeling models do not consider such label components, the shared components across labels, such as Person, can be beneficial for label prediction. In this work, we propose to integrate label component information as embeddings into models. Through experiments on English and Japanese fine-grained named entity recognition, we demonstrate that the proposed method improves performance, especially for instances with low-frequency labels.","embedding label component sequence labeling : case study fine - grained name entity recognition general , label sequence labeling consist different type element . example , iob - format entity label , b - person - person , decompose span ( b ) type information ( person ) . , sequence labeling model consider label component , share component label , person , beneficial label prediction . work , propose integrate label component information embedding model . experiment english japanese fine - grained name entity recognition , demonstrate propose method improve performance , especially instance low - frequency label .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 12, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 2, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Information Extraction,False
Student Research Workshop,Unsupervised Multilingual Sentence Embeddings for Parallel Corpus Mining,"Existing models of multilingual sentence embeddings require large parallel data resources which are not available for low-resource languages. We propose a novel unsupervised method to derive multilingual sentence embeddings relying only on monolingual data. We first produce a synthetic parallel corpus using unsupervised machine translation, and use it to fine-tune a pretrained cross-lingual masked language model (XLM) to derive the multilingual sentence representations. The quality of the representations is evaluated on two parallel corpus mining tasks with improvements of up to 22 F1 points over vanilla XLM. In addition, we observe that a single synthetic bilingual corpus is able to improve results for other language pairs.","Unsupervised Multilingual Sentence Embeddings for Parallel Corpus Mining Existing models of multilingual sentence embeddings require large parallel data resources which are not available for low-resource languages. We propose a novel unsupervised method to derive multilingual sentence embeddings relying only on monolingual data. We first produce a synthetic parallel corpus using unsupervised machine translation, and use it to fine-tune a pretrained cross-lingual masked language model (XLM) to derive the multilingual sentence representations. The quality of the representations is evaluated on two parallel corpus mining tasks with improvements of up to 22 F1 points over vanilla XLM. In addition, we observe that a single synthetic bilingual corpus is able to improve results for other language pairs.","unsupervised multilingual sentence embedding parallel corpus mining exist model multilingual sentence embedding require large parallel datum resource available low - resource language . propose novel unsupervised method derive multilingual sentence embedding rely monolingual datum . produce synthetic parallel corpus unsupervised machine translation , use fine - tune pretrained cross - lingual mask language model ( xlm ) derive multilingual sentence representation . quality representation evaluate parallel corpus mining task improvement 22 f1 point vanilla xlm . addition , observe single synthetic bilingual corpus able improve result language pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 6, 'Machine Translation and Multilinguality': 3, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 10, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,True
Student Research Workshop,Combining Subword Representations into Word-level Representations in the Transformer Architecture,"In Neural Machine Translation, using wordlevel tokens leads to degradation in translation quality. The dominant approaches use subword-level tokens, but this increases the length of the sequences and makes it difficult to profit from word-level information such as POS tags or semantic dependencies. We propose a modification to the Transformer model to combine subword-level representations into word-level ones in the first layers of the encoder, reducing the effective length of the sequences in the following layers and providing a natural point to incorporate extra word-level information. Our experiments show that this approach maintains the translation quality with respect to the normal Transformer model when no extra word-level information is injected and that it is superior to the currently dominant method for incorporating word-level source language information to models based on subword-level vocabularies.","Combining Subword Representations into Word-level Representations in the Transformer Architecture In Neural Machine Translation, using wordlevel tokens leads to degradation in translation quality. The dominant approaches use subword-level tokens, but this increases the length of the sequences and makes it difficult to profit from word-level information such as POS tags or semantic dependencies. We propose a modification to the Transformer model to combine subword-level representations into word-level ones in the first layers of the encoder, reducing the effective length of the sequences in the following layers and providing a natural point to incorporate extra word-level information. Our experiments show that this approach maintains the translation quality with respect to the normal Transformer model when no extra word-level information is injected and that it is superior to the currently dominant method for incorporating word-level source language information to models based on subword-level vocabularies.","combine subword representation word - level representation transformer architecture neural machine translation , wordlevel token lead degradation translation quality . dominant approach use subword - level token , increase length sequence make difficult profit word - level information pos tag semantic dependency . propose modification transformer model combine subword - level representation word - level one layer encoder , reduce effective length sequence follow layer provide natural point incorporate extra word - level information . experiment approach maintain translation quality respect normal transformer model extra word - level information inject superior currently dominant method incorporate word - level source language information model base subword - level vocabulary .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 9, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 7, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 11, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 1, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Semantics: Lexical Semantics,False
Student Research Workshop,Effectively Aligning and Filtering Parallel Corpora under Sparse Data Conditions,"Parallel corpora are key to developing good machine translation systems. However, abundant parallel data are hard to come by, especially for languages with a low number of speakers. When rich morphology exacerbates the data sparsity problem, it is imperative to have accurate alignment and filtering methods that can help make the most of what is available by maximising the number of correctly translated segments in a corpus and minimising noise by removing incorrect translations and segments containing extraneous data. This paper sets out a research plan for improving alignment and filtering methods for parallel texts in low-resource settings. We propose an effective unsupervised alignment method to tackle the alignment problem. Moreover, we propose a strategy to supplement state-of-theart models with automatically extracted information using basic NLP tools to effectively handle rich morphology.","Effectively Aligning and Filtering Parallel Corpora under Sparse Data Conditions Parallel corpora are key to developing good machine translation systems. However, abundant parallel data are hard to come by, especially for languages with a low number of speakers. When rich morphology exacerbates the data sparsity problem, it is imperative to have accurate alignment and filtering methods that can help make the most of what is available by maximising the number of correctly translated segments in a corpus and minimising noise by removing incorrect translations and segments containing extraneous data. This paper sets out a research plan for improving alignment and filtering methods for parallel texts in low-resource settings. We propose an effective unsupervised alignment method to tackle the alignment problem. Moreover, we propose a strategy to supplement state-of-theart models with automatically extracted information using basic NLP tools to effectively handle rich morphology.","effectively align filter parallel corpus sparse datum condition parallel corpus key develop good machine translation system . , abundant parallel datum hard come , especially language low number speaker . rich morphology exacerbate datum sparsity problem , imperative accurate alignment filtering method help available maximise number correctly translate segment corpus minimise noise remove incorrect translation segment contain extraneous datum . paper set research plan improve alignment filtering method parallel text low - resource setting . propose effective unsupervised alignment method tackle alignment problem . , propose strategy supplement state - - theart model automatically extract information basic nlp tool effectively handle rich morphology .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 4, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 5, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 7, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,True
Student Research Workshop,Pre-training via Leveraging Assisting Languages for Neural Machine Translation,"Sequence-to-sequence (S2S) pre-training using large monolingual data is known to improve performance for various S2S NLP tasks. However, large monolingual corpora might not always be available for the languages of interest (LOI). Thus, we propose to exploit monolingual corpora of other languages to complement the scarcity of monolingual corpora for the LOI. We utilize script mapping (Chinese to Japanese) to increase the similarity (number of cognates) between the monolingual corpora of helping languages and LOI. An empirical case study of low-resource Japanese-English neural machine translation (NMT) reveals that leveraging large Chinese and French monolingual corpora can help overcome the shortage of Japanese and English monolingual corpora, respectively, for S2S pre-training. Using only Chinese and French monolingual corpora, we were able to improve Japanese-English translation quality by up to 8.5 BLEU in lowresource scenarios.","Pre-training via Leveraging Assisting Languages for Neural Machine Translation Sequence-to-sequence (S2S) pre-training using large monolingual data is known to improve performance for various S2S NLP tasks. However, large monolingual corpora might not always be available for the languages of interest (LOI). Thus, we propose to exploit monolingual corpora of other languages to complement the scarcity of monolingual corpora for the LOI. We utilize script mapping (Chinese to Japanese) to increase the similarity (number of cognates) between the monolingual corpora of helping languages and LOI. An empirical case study of low-resource Japanese-English neural machine translation (NMT) reveals that leveraging large Chinese and French monolingual corpora can help overcome the shortage of Japanese and English monolingual corpora, respectively, for S2S pre-training. Using only Chinese and French monolingual corpora, we were able to improve Japanese-English translation quality by up to 8.5 BLEU in lowresource scenarios.","pre - training leverage assist language neural machine translation sequence - - sequence ( s2s ) pre - training large monolingual datum know improve performance s2s nlp task . , large monolingual corpus available language interest ( loi ) . , propose exploit monolingual corpus language complement scarcity monolingual corpus loi . utilize script mapping ( chinese japanese ) increase similarity ( number cognate ) monolingual corpora help language loi . empirical case study low - resource japanese - english neural machine translation ( nmt ) reveal leverage large chinese french monolingual corpus help overcome shortage japanese english monolingual corpus , respectively , s2s pre - training . chinese french monolingual corpus , able improve japanese - english translation quality 8.5 bleu lowresource scenario .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 3, 'Machine Translation and Multilinguality': 12, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 4, 'Question Answering': 0, 'Resources and Evaluation': 7, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 19, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 0, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,True
Student Research Workshop,"Media Bias, the Social Sciences, and NLP: Automating Frame Analyses to Identify Bias by Word Choice and Labeling","Media bias can strongly impact the public perception of topics reported in the news. A difficult to detect, yet powerful form of slanted news coverage is called bias by word choice and labeling (WCL). WCL bias can occur, for example, when journalists refer to the same semantic concept by using different terms that frame the concept differently and consequently may lead to different assessments by readers, such as the terms ""freedom fighters"" and ""terrorists,"" or ""gun rights"" and ""gun control."" In this research project, I aim to devise methods that identify instances of WCL bias and estimate the frames they induce, e.g., not only is ""terrorists"" of negative polarity but also ascribes to aggression and fear. To achieve this, I plan to research methods using natural language processing and deep learning while employing models and using analysis concepts from the social sciences, where researchers have studied media bias for decades. The first results indicate the effectiveness of this interdisciplinary research approach. My vision is to devise a system that helps news readers to become aware of the differences in media coverage caused by bias.","Media Bias, the Social Sciences, and NLP: Automating Frame Analyses to Identify Bias by Word Choice and Labeling Media bias can strongly impact the public perception of topics reported in the news. A difficult to detect, yet powerful form of slanted news coverage is called bias by word choice and labeling (WCL). WCL bias can occur, for example, when journalists refer to the same semantic concept by using different terms that frame the concept differently and consequently may lead to different assessments by readers, such as the terms ""freedom fighters"" and ""terrorists,"" or ""gun rights"" and ""gun control."" In this research project, I aim to devise methods that identify instances of WCL bias and estimate the frames they induce, e.g., not only is ""terrorists"" of negative polarity but also ascribes to aggression and fear. To achieve this, I plan to research methods using natural language processing and deep learning while employing models and using analysis concepts from the social sciences, where researchers have studied media bias for decades. The first results indicate the effectiveness of this interdisciplinary research approach. My vision is to devise a system that helps news readers to become aware of the differences in media coverage caused by bias.","media bias , social science , nlp : automate frame analysis identify bias word choice label media bias strongly impact public perception topic report news . difficult detect , powerful form slant news coverage call bias word choice labeling ( wcl ) . wcl bias occur , example , journalist refer semantic concept different term frame concept differently consequently lead different assessment reader , term "" freedom fighter "" "" terrorist , "" "" gun right "" "" gun control . "" research project , aim devise method identify instance wcl bias estimate frame induce , e.g. , "" terrorist "" negative polarity ascribe aggression fear . achieve , plan research method natural language processing deep learning employ model analysis concept social science , researcher study medium bias decade . result indicate effectiveness interdisciplinary research approach . vision devise system help news reader aware difference medium coverage cause bias .","{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 10, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 1, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 6, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 4, 'Semantics: Lexical Semantics': 2, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Ethics and NLP,False
Student Research Workshop,Checkpoint Reranking: An Approach to Select Better Hypothesis for Neural Machine Translation Systems,"In this paper, we propose a method of reranking the outputs of Neural Machine Translation (NMT) systems. After the decoding process, we select a few last iteration outputs in the training process as the N -best list. After training a Neural Machine Translation (NMT) baseline system, it has been observed that these iteration outputs have an oracle score higher than baseline up to 1.01 BLEU points compared to the last iteration of the trained system.We come up with a ranking mechanism by solely focusing on the decoder's ability to generate distinct tokens and without the usage of any language model or data. With this method, we achieved a translation improvement up to +0.16 BLEU points over baseline.We also evaluate our approach by applying the coverage penalty to the training process.In cases of moderate coverage penalty, the oracle scores are higher than the final iteration up to +0.99 BLEU points, and our algorithm gives an improvement up to +0.17 BLEU points.With excessive penalty, there is a decrease in translation quality compared to the baseline system. Still, an increase in oracle scores up to +1.30 is observed with the re-ranking algorithm giving an improvement up to +0.15 BLEU points is found in case of excessive penalty.The proposed re-ranking method is a generic one and can be extended to other language pairs as well.","Checkpoint Reranking: An Approach to Select Better Hypothesis for Neural Machine Translation Systems In this paper, we propose a method of reranking the outputs of Neural Machine Translation (NMT) systems. After the decoding process, we select a few last iteration outputs in the training process as the N -best list. After training a Neural Machine Translation (NMT) baseline system, it has been observed that these iteration outputs have an oracle score higher than baseline up to 1.01 BLEU points compared to the last iteration of the trained system.We come up with a ranking mechanism by solely focusing on the decoder's ability to generate distinct tokens and without the usage of any language model or data. With this method, we achieved a translation improvement up to +0.16 BLEU points over baseline.We also evaluate our approach by applying the coverage penalty to the training process.In cases of moderate coverage penalty, the oracle scores are higher than the final iteration up to +0.99 BLEU points, and our algorithm gives an improvement up to +0.17 BLEU points.With excessive penalty, there is a decrease in translation quality compared to the baseline system. Still, an increase in oracle scores up to +1.30 is observed with the re-ranking algorithm giving an improvement up to +0.15 BLEU points is found in case of excessive penalty.The proposed re-ranking method is a generic one and can be extended to other language pairs as well.","checkpoint reranking : approach select well hypothesis neural machine translation system paper , propose method reranke output neural machine translation ( nmt ) system . decoding process , select iteration output training process n -b list . train neural machine translation ( nmt ) baseline system , observe iteration output oracle score high baseline 1.01 bleu point compare iteration train system . come ranking mechanism solely focus decoder ability generate distinct token usage language model datum . method , achieve translation improvement +0.16 bleu point baseline . evaluate approach apply coverage penalty training process . case moderate coverage penalty , oracle score high final iteration +0.99 bleu point , algorithm give improvement +0.17 bleu point . excessive penalty , decrease translation quality compare baseline system . , increase oracle score +1.30 observe - ranking algorithm give improvement +0.15 bleu point find case excessive penalty . propose - ranking method generic extend language pair .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 1, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 22, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 1, 'Student Research Workshop': 11, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 5, 'Theme': 1, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Machine Translation and Multilinguality,False
Student Research Workshop,Building a Japanese Typo Dataset from Wikipedia's Revision History,"User generated texts contain many typos for which correction is necessary for NLP systems to work. Although a large number of typo-correction pairs are needed to develop a data-driven typo correction system, no such dataset is available for Japanese. In this paper, we extract over half a million Japanese typo-correction pairs from Wikipedia's revision history. Unlike other languages, Japanese poses unique challenges: (1) Japanese texts are unsegmented so that we cannot simply apply a spelling checker, and (2) the way people inputting kanji logographs results in typos with drastically different surface forms from correct ones. We address them by combining character-based extraction rules, morphological analyzers to guess readings, and various filtering methods. We evaluate the dataset using crowdsourcing and run a baseline seq2seq model for typo correction.","Building a Japanese Typo Dataset from Wikipedia's Revision History User generated texts contain many typos for which correction is necessary for NLP systems to work. Although a large number of typo-correction pairs are needed to develop a data-driven typo correction system, no such dataset is available for Japanese. In this paper, we extract over half a million Japanese typo-correction pairs from Wikipedia's revision history. Unlike other languages, Japanese poses unique challenges: (1) Japanese texts are unsegmented so that we cannot simply apply a spelling checker, and (2) the way people inputting kanji logographs results in typos with drastically different surface forms from correct ones. We address them by combining character-based extraction rules, morphological analyzers to guess readings, and various filtering methods. We evaluate the dataset using crowdsourcing and run a baseline seq2seq model for typo correction.","build japanese typo dataset wikipedia revision history user generate text contain typo correction necessary nlp system work . large number typo - correction pair need develop data - drive typo correction system , dataset available japanese . paper , extract half million japanese typo - correction pair wikipedia revision history . unlike language , japanese pose unique challenge : ( 1 ) japanese text unsegmente simply apply spelling checker , ( 2 ) way people inputte kanji logograph result typo drastically different surface form correct one . address combine character - base extraction rule , morphological analyzer guess reading , filtering method . evaluate dataset crowdsourcing run baseline seq2seq model typo correction .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 6, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 1, 'Phonology, Morphology and Word Segmentation': 3, 'Question Answering': 1, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 2, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Student Research Workshop': 12, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'System Demonstrations': 3, 'Theme': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}",Student Research Workshop,True
Student Research Workshop,A Simple and Effective Dependency Parser for Telugu,"We present a simple and effective dependency parser for Telugu, a morphologically rich, free word order language. We propose to replace the rich linguistic feature templates used in the past approaches with a minimal feature function using contextual vector representations. We train a BERT model on the Telugu Wikipedia data and use vector representations from this model to train the parser. Each sentence token is associated with a vector representing the token in the context of that sentence and the feature vectors are constructed by concatenating two token representations from the stack and one from the buffer. We put the feature representations through a feed forward network and train with a greedy transition based approach. The resulting parser has a very simple architecture with minimal feature engineering and achieves state-of-the-art results for Telugu.","A Simple and Effective Dependency Parser for Telugu We present a simple and effective dependency parser for Telugu, a morphologically rich, free word order language. We propose to replace the rich linguistic feature templates used in the past approaches with a minimal feature function using contextual vector representations. We train a BERT model on the Telugu Wikipedia data and use vector representations from this model to train the parser. Each sentence token is associated with a vector representing the token in the context of that sentence and the feature vectors are constructed by concatenating two token representations from the stack and one from the buffer. We put the feature representations through a feed forward network and train with a greedy transition based approach. The resulting parser has a very simple architecture with minimal feature engineering and achieves state-of-the-art results for Telugu.","simple effective dependency parser telugu present simple effective dependency parser telugu , morphologically rich , free word order language . propose replace rich linguistic feature template past approach minimal feature function contextual vector representation . train bert model telugu wikipedia datum use vector representation model train parser . sentence token associate vector represent token context sentence feature vector construct concatenate token representation stack buffer . feature representation feed forward network train greedy transition base approach . result parser simple architecture minimal feature engineering achieve state - - - art result telugu .","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 7, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 5, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 2, 'Student Research Workshop': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 6, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 1}",Machine Learning for NLP,False
Student Research Workshop,Inducing Grammar from Long Short-Term Memory Networks by Shapley Decomposition,"The principle of compositionality has deep roots in linguistics: the meaning of an expression is determined by its structure and the meanings of its constituents. However, modern neural network models such as long shortterm memory network process expressions in a linear fashion and do not seem to incorporate more complex compositional patterns. In this work, we show that we can explicitly induce grammar by tracing the computational process of a long short-term memory network. We show: (i) the multiplicative nature of long short-term memory network allows complex interaction beyond sequential linear combination; (ii) we can generate compositional trees from the network without external linguistic knowledge; (iii) we evaluate the syntactic difference between the generated trees, randomly generated trees and gold reference trees produced by constituency parsers; (iv) we evaluate whether the generated trees contain the rich semantic information. 1","Inducing Grammar from Long Short-Term Memory Networks by Shapley Decomposition The principle of compositionality has deep roots in linguistics: the meaning of an expression is determined by its structure and the meanings of its constituents. However, modern neural network models such as long shortterm memory network process expressions in a linear fashion and do not seem to incorporate more complex compositional patterns. In this work, we show that we can explicitly induce grammar by tracing the computational process of a long short-term memory network. We show: (i) the multiplicative nature of long short-term memory network allows complex interaction beyond sequential linear combination; (ii) we can generate compositional trees from the network without external linguistic knowledge; (iii) we evaluate the syntactic difference between the generated trees, randomly generated trees and gold reference trees produced by constituency parsers; (iv) we evaluate whether the generated trees contain the rich semantic information. 1","induce grammar long short - term memory network shapley decomposition principle compositionality deep root linguistic : meaning expression determine structure meaning constituent . , modern neural network model long shortterm memory network process expression linear fashion incorporate complex compositional pattern . work , explicitly induce grammar trace computational process long short - term memory network . : ( ) multiplicative nature long short - term memory network allow complex interaction sequential linear combination ; ( ii ) generate compositional tree network external linguistic knowledge ; ( iii ) evaluate syntactic difference generate tree , randomly generate tree gold reference tree produce constituency parser ; ( iv ) evaluate generate tree contain rich semantic information . 1","{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 4, 'Information Extraction': 4, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 1, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'NLP Applications': 0, 'Phonology, Morphology and Word Segmentation': 1, 'Question Answering': 0, 'Resources and Evaluation': 1, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Student Research Workshop': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 7, 'System Demonstrations': 0, 'Theme': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}","Syntax: Tagging, Chunking and Parsing",False
