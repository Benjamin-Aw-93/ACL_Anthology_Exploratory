{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benjamin Aw\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keybert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeybert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KeyBERT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerDocumentEmbeddings\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myake\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keybert'"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "\n",
    "# Reading in files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import scipy.sparse as sp\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keybert import KeyBERT\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "\n",
    "import yake\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ACL_2020 = pd.read_csv(\"./Data/Pred/BART/ACL_2022_bart_pred_231122.csv\")\n",
    "df_EMNLP_2020 = pd.read_csv(\"./Data/Pred/BART/EMNLP_2020_bart_pred_231122.csv\")\n",
    "\n",
    "df_ACL_2020 = df_ACL_2020[[\"Labels\", \"Paper Name\", \"abstract\"]]\n",
    "df_EMNLP_2020 = df_EMNLP_2020[[\"Labels\", \"Paper Name\", \"abstract\"]]\n",
    "\n",
    "df_ACL_2020.columns = [\"Label\", \"Title\", \"Abstract\"]\n",
    "df_EMNLP_2020.columns = [\"Label\", \"Title\", \"Abstract\"]\n",
    "\n",
    "df_ACL_2020 = df_ACL_2020.loc[lambda df_ACL_2020: ~df_ACL_2020[\"Label\"].isin([\"Student Research Workshop\", \"Theme\", \"NLP Applications\", \"System Demonstrations\"]), :]\n",
    "df_ACL_2020[\"Label\"].unique()\n",
    "\n",
    "\n",
    "df_ACL_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EMNLP_2020 = df_EMNLP_2020.loc[lambda df_EMNLP_2020: ~df_EMNLP_2020[\"Label\"].isin([\"Student Research Workshop\", \"Theme\", \"NLP Applications\", \"System Demonstrations\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ACL_2020['Text'] = df_ACL_2020['Title'] + \" \" +df_ACL_2020['Abstract']\n",
    "df_EMNLP_2020['Text'] = df_EMNLP_2020['Title'] + \" \" +df_EMNLP_2020['Abstract']\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf', disable=['parser', 'ner'])\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatiser_stemmer_stopword(text, nlp, stemmer):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    lemmatised_sentence_lst = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    lemmatised_sentence = \" \".join(lemmatised_sentence_lst)\n",
    "    stemmed_lemmatised_sentence = stemmer.stem(lemmatised_sentence)\n",
    "    \n",
    "    return stemmed_lemmatised_sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ACL_2020['Lemm Stemmed Text'] = df_ACL_2020['Text'].progress_apply(lemmatiser_stemmer_stopword, args=(nlp, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EMNLP_2020['Lemm Stemmed Text'] = df_EMNLP_2020['Text'].progress_apply(lemmatiser_stemmer_stopword, args=(nlp, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P20 = pd.read_csv(\"./Data/ACL_2020.csv\")\n",
    "df_D20 = pd.read_csv(\"./Data/EMNLP_2020.csv\")\n",
    "df_E21 = pd.read_csv(\"./Data/EACL_2021.csv\")\n",
    "df_P21 = pd.read_csv(\"./Data/ACL_JCNLP_2021.csv\")\n",
    "df_N21 = pd.read_csv(\"./Data/NAACL_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2894\n",
      "791 791 23\n",
      "781 781 20\n",
      "320 320 21\n",
      "528 528 22\n",
      "474 474 22\n"
     ]
    }
   ],
   "source": [
    "print(len(df_P20) + len(df_D20) + len(df_E21) + len(df_P21) + len(df_N21))\n",
    "print(len(df_P20), len(df_P20.Labels), len(df_P20.Labels.unique()))\n",
    "print(len(df_D20), len(df_D20.Labels), len(df_D20.Labels.unique()))\n",
    "print(len(df_E21), len(df_E21.Labels), len(df_E21.Labels.unique()))\n",
    "print(len(df_P21), len(df_P21.Labels), len(df_P21.Labels.unique()))\n",
    "print(len(df_N21), len(df_N21.Labels), len(df_N21.Labels.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P20 = df_P20[df_P20[\"Labels\"] != \"NLP Applications\"]\n",
    "df_D20 = df_D20[df_D20[\"Labels\"] != \"NLP Applications\"]\n",
    "df_E21 = df_E21[df_E21[\"Labels\"] != \"NLP Applications\"]\n",
    "df_P21 = df_P21[df_P21[\"Labels\"] != \"NLP Applications\"]\n",
    "df_N21 = df_N21[df_N21[\"Labels\"] != \"NLP Applications\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2705\n",
      "742 742 22\n",
      "715 715 19\n",
      "317 317 20\n",
      "502 502 21\n",
      "429 429 21\n"
     ]
    }
   ],
   "source": [
    "print(len(df_P20) + len(df_D20) + len(df_E21) + len(df_P21) + len(df_N21))\n",
    "print(len(df_P20), len(df_P20.Labels), len(df_P20.Labels.unique()))\n",
    "print(len(df_D20), len(df_D20.Labels), len(df_D20.Labels.unique()))\n",
    "print(len(df_E21), len(df_E21.Labels), len(df_E21.Labels.unique()))\n",
    "print(len(df_P21), len(df_P21.Labels), len(df_P21.Labels.unique()))\n",
    "print(len(df_N21), len(df_N21.Labels), len(df_N21.Labels.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Paper Name</th>\n",
       "      <th>Author Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals</td>\n",
       "      <td>Kate McCurdy, Sharon Goldwater, Adam Lopez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Learning to Understand Child-directed and Adult-directed Speech</td>\n",
       "      <td>Lieke Gelderloos, Grzegorz Chrupa≈Ça, Afra Alishahi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment</td>\n",
       "      <td>Forrest Davis, Marten van Schijndel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction</td>\n",
       "      <td>Orion Weller, Jordan Hildebrandt, Ilya Reznik, Christopher Challis, E. Shannon Tass, Quinn Snell, Kevin Seppi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts</td>\n",
       "      <td>Alex Rinaldi, Jean Fox Tree, Snigdha Chaturvedi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Emergence of Syntax Needs Minimal Supervision</td>\n",
       "      <td>Rapha√´l Bailly, Kata G√°bor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>A Three-Parameter Rank-Frequency Relation in Natural Languages</td>\n",
       "      <td>Chenchen Ding, Masao Utiyama, Eiichiro Sumita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese</td>\n",
       "      <td>Tatsuki Kuribayashi, Takumi Ito, Jun Suzuki, Kentaro Inui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Dice Loss for Data-imbalanced NLP Tasks</td>\n",
       "      <td>Xiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun Liang, Fei Wu, Jiwei Li</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Theoretical Limitations of Self-Attention in Neural Sequence Models</td>\n",
       "      <td>Michael Hahn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Labels  \\\n",
       "0    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "1    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "2    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "3    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "4    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "..                                                             ...   \n",
       "786      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "787      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "788      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "789      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "790      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "\n",
       "                                                                                                                     Paper Name  \\\n",
       "0    Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals   \n",
       "1                                                               Learning to Understand Child-directed and Adult-directed Speech   \n",
       "2                                 Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment   \n",
       "3                                          You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction   \n",
       "4                                 Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts   \n",
       "..                                                                                                                          ...   \n",
       "786                                                                               Emergence of Syntax Needs Minimal Supervision   \n",
       "787                                                              A Three-Parameter Rank-Frequency Relation in Natural Languages   \n",
       "788                              Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese   \n",
       "789                                                                                     Dice Loss for Data-imbalanced NLP Tasks   \n",
       "790                                                         Theoretical Limitations of Self-Attention in Neural Sequence Models   \n",
       "\n",
       "                                                                                                      Author Names  \n",
       "0                                                                       Kate McCurdy, Sharon Goldwater, Adam Lopez  \n",
       "1                                                               Lieke Gelderloos, Grzegorz Chrupa≈Ça, Afra Alishahi  \n",
       "2                                                                              Forrest Davis, Marten van Schijndel  \n",
       "3    Orion Weller, Jordan Hildebrandt, Ilya Reznik, Christopher Challis, E. Shannon Tass, Quinn Snell, Kevin Seppi  \n",
       "4                                                                  Alex Rinaldi, Jean Fox Tree, Snigdha Chaturvedi  \n",
       "..                                                                                                             ...  \n",
       "786                                                                                     Rapha√´l Bailly, Kata G√°bor  \n",
       "787                                                                  Chenchen Ding, Masao Utiyama, Eiichiro Sumita  \n",
       "788                                                      Tatsuki Kuribayashi, Takumi Ito, Jun Suzuki, Kentaro Inui  \n",
       "789                                            Xiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun Liang, Fei Wu, Jiwei Li  \n",
       "790                                                                                                   Michael Hahn  \n",
       "\n",
       "[742 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Paper Name</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals</td>\n",
       "      <td>Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Learning to Understand Child-directed and Adult-directed Speech</td>\n",
       "      <td>Speech directed to children differs from adultdirected speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment</td>\n",
       "      <td>A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction</td>\n",
       "      <td>Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only predictions (i.e. predicting the time to read a single word). We seek to extend these works by examining whether or not document level predictions are effective, given additional information such as subject matter, font characteristics, and readability metrics. We perform a novel experiment to examine how different features of text contribute to the time it takes to read, distributing and collecting data from over a thousand participants. We then employ a large number of machine learning methods to predict a user's reading time. We find that despite extensive research showing that word level reading time can be most effectively predicted by neural networks, larger scale text can be easily and most accurately predicted by one factor, the number of words.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts</td>\n",
       "      <td>Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization</td>\n",
       "      <td>Meetings are a key component of human collaboration. As increasing numbers of meetings are recorded and transcribed, meeting summaries have become essential to remind those who may or may not have attended the meetings about the key decisions made and the tasks to be completed. However, it is hard to create a single short summary that covers all the content of a long meeting involving multiple people and topics. In order to satisfy the needs of different types of users, we define a new query-based multi-domain meeting summarization task, where models have to select and summarize relevant spans of meetings in response to a query, and we introduce QMSum, a new benchmark for this task. QMSum consists of 1,808 query-summary pairs over 232 meetings in multiple domains. Besides, we investigate a locate-then-summarize method and evaluate a set of strong summarization baselines on the task. Experimental results and manual analysis reveal that QMSum presents significant challenges in long meeting summarization for future research. Dataset is available at https://github.com/Yale-LILY/ QMSum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>MM-AVS: A Full-Scale Dataset for Multi-modal Summarization</td>\n",
       "      <td>Multimodal summarization becomes increasingly significant as it is the basis for question answering, Web search, and many other downstream tasks. However, its learning materials have been lacking a holistic organization by integrating resources from various modalities, thereby lagging behind the research progress of this field. In this study, we present a full-scale multimodal dataset comprehensively gathering documents, summaries, images, captions, videos, audios, transcripts, and titles in English from CNN and Daily Mail. To our best knowledge, this is the first collection that spans all modalities and nearly comprises all types of materials available in this community. In addition, we devise a baseline model based on the novel dataset, which employs a newly proposed Jump-Attention mechanism based on transcripts. The experimental results validate the important assistance role of the external information for multimodal summarization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization</td>\n",
       "      <td>This paper introduces MEDIASUM 1 , a largescale media interview dataset consisting of 463.6K transcripts with abstractive summaries. To create this dataset, we collect interview transcripts from NPR and CNN and employ the overview and topic descriptions as summaries. Compared with existing public corpora for dialogue summarization, our dataset is an order of magnitude larger and contains complex multi-party conversations from multiple domains. We conduct statistical analysis to demonstrate the unique positional bias exhibited in the transcripts of televised and radioed interviews. We also show that MEDIASUM can be used in transfer learning to improve a model's performance on other dialogue summarization tasks. * Equal contribution 1 https://github.com/zcgzcgzcg1/ MediaSum/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection</td>\n",
       "      <td>Despite significant progress in neural abstractive summarization, recent studies have shown that the current models are prone to generating summaries that are unfaithful to the original context. To address the issue, we study contrast candidate generation and selection as a model-agnostic post-processing technique to correct the extrinsic hallucinations (i.e. information not present in the source text) in unfaithful summaries. We learn a discriminative correction model by generating alternative candidate summaries where named entities and quantities in the generated summary are replaced with ones with compatible semantic types from the source document. This model is then used to select the best candidate as the final output summary. Our experiments and analysis across a number of neural summarization systems show that our proposed method is effective in identifying and correcting extrinsic hallucinations. We analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>Inference Time Style Control for Summarization</td>\n",
       "      <td>How to generate summaries of different styles without requiring corpora in the target styles, or training separate models? We present two novel methods that can be deployed during summary decoding on any pre-trained Transformer-based summarization model. ( 1 ) Decoder state adjustment instantly modifies decoder final states with externally trained style scorers, to iteratively refine the output against a target style. (2) Word unit prediction constrains the word usage to impose strong lexical control during generation. In experiments of summarizing with simplicity control, automatic evaluation and human judges both find our models producing outputs in simpler languages while still informative. We also generate news headlines with various ideological leanings, which can be distinguished by humans with a reasonable probability.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2534 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Labels  \\\n",
       "0     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "1     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "2     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "3     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "4     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "...                                                             ...   \n",
       "2710                                                  Summarization   \n",
       "2711                                                  Summarization   \n",
       "2712                                                  Summarization   \n",
       "2713                                                  Summarization   \n",
       "2714                                                  Summarization   \n",
       "\n",
       "                                                                                                                      Paper Name  \\\n",
       "0     Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals   \n",
       "1                                                                Learning to Understand Child-directed and Adult-directed Speech   \n",
       "2                                  Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment   \n",
       "3                                           You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction   \n",
       "4                                  Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts   \n",
       "...                                                                                                                          ...   \n",
       "2710                                                   QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization   \n",
       "2711                                                                  MM-AVS: A Full-Scale Dataset for Multi-modal Summarization   \n",
       "2712                                                  MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization   \n",
       "2713                        Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection   \n",
       "2714                                                                              Inference Time Style Control for Summarization   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      abstract  \n",
       "0     Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.  \n",
       "1                                                                                                                                                                                                                                                                                                                               Speech directed to children differs from adultdirected speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.  \n",
       "2                                                                                                                                                                                                                                          A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.  \n",
       "3                                                                                                                                                                                                                                                                           Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only predictions (i.e. predicting the time to read a single word). We seek to extend these works by examining whether or not document level predictions are effective, given additional information such as subject matter, font characteristics, and readability metrics. We perform a novel experiment to examine how different features of text contribute to the time it takes to read, distributing and collecting data from over a thousand participants. We then employ a large number of machine learning methods to predict a user's reading time. We find that despite extensive research showing that word level reading time can be most effectively predicted by neural networks, larger scale text can be easily and most accurately predicted by one factor, the number of words.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                            Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...  \n",
       "2710                                                                                                                                                                                Meetings are a key component of human collaboration. As increasing numbers of meetings are recorded and transcribed, meeting summaries have become essential to remind those who may or may not have attended the meetings about the key decisions made and the tasks to be completed. However, it is hard to create a single short summary that covers all the content of a long meeting involving multiple people and topics. In order to satisfy the needs of different types of users, we define a new query-based multi-domain meeting summarization task, where models have to select and summarize relevant spans of meetings in response to a query, and we introduce QMSum, a new benchmark for this task. QMSum consists of 1,808 query-summary pairs over 232 meetings in multiple domains. Besides, we investigate a locate-then-summarize method and evaluate a set of strong summarization baselines on the task. Experimental results and manual analysis reveal that QMSum presents significant challenges in long meeting summarization for future research. Dataset is available at https://github.com/Yale-LILY/ QMSum.  \n",
       "2711                                                                                                                                                                                                                                                                                                                                      Multimodal summarization becomes increasingly significant as it is the basis for question answering, Web search, and many other downstream tasks. However, its learning materials have been lacking a holistic organization by integrating resources from various modalities, thereby lagging behind the research progress of this field. In this study, we present a full-scale multimodal dataset comprehensively gathering documents, summaries, images, captions, videos, audios, transcripts, and titles in English from CNN and Daily Mail. To our best knowledge, this is the first collection that spans all modalities and nearly comprises all types of materials available in this community. In addition, we devise a baseline model based on the novel dataset, which employs a newly proposed Jump-Attention mechanism based on transcripts. The experimental results validate the important assistance role of the external information for multimodal summarization.  \n",
       "2712                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           This paper introduces MEDIASUM 1 , a largescale media interview dataset consisting of 463.6K transcripts with abstractive summaries. To create this dataset, we collect interview transcripts from NPR and CNN and employ the overview and topic descriptions as summaries. Compared with existing public corpora for dialogue summarization, our dataset is an order of magnitude larger and contains complex multi-party conversations from multiple domains. We conduct statistical analysis to demonstrate the unique positional bias exhibited in the transcripts of televised and radioed interviews. We also show that MEDIASUM can be used in transfer learning to improve a model's performance on other dialogue summarization tasks. * Equal contribution 1 https://github.com/zcgzcgzcg1/ MediaSum/  \n",
       "2713                                                                                                                                                                                                  Despite significant progress in neural abstractive summarization, recent studies have shown that the current models are prone to generating summaries that are unfaithful to the original context. To address the issue, we study contrast candidate generation and selection as a model-agnostic post-processing technique to correct the extrinsic hallucinations (i.e. information not present in the source text) in unfaithful summaries. We learn a discriminative correction model by generating alternative candidate summaries where named entities and quantities in the generated summary are replaced with ones with compatible semantic types from the source document. This model is then used to select the best candidate as the final output summary. Our experiments and analysis across a number of neural summarization systems show that our proposed method is effective in identifying and correcting extrinsic hallucinations. We analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.  \n",
       "2714                                                                                                                                                                                                                                                                                                                                                                                                                                                     How to generate summaries of different styles without requiring corpora in the target styles, or training separate models? We present two novel methods that can be deployed during summary decoding on any pre-trained Transformer-based summarization model. ( 1 ) Decoder state adjustment instantly modifies decoder final states with externally trained style scorers, to iteratively refine the output against a target style. (2) Word unit prediction constrains the word usage to impose strong lexical control during generation. In experiments of summarizing with simplicity control, automatic evaluation and human judges both find our models producing outputs in simpler languages while still informative. We also generate news headlines with various ideological leanings, which can be distinguished by humans with a reasonable probability.  \n",
       "\n",
       "[2534 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole = pd.read_csv(\"./Data/Collated_dataset_for_scientific_papers.csv\")\n",
    "df_whole = df_whole[df_whole['Labels'] != 'NLP Applications']\n",
    "df_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Linguistic Theories, Cognitive Modeling and Psycholinguistics',\n",
       "       'Computational Social Science and Social Media',\n",
       "       'Dialogue and Interactive Systems', 'Discourse and Pragmatics',\n",
       "       'Ethics and NLP', 'Generation', 'Information Extraction',\n",
       "       'Information Retrieval and Text Mining',\n",
       "       'Interpretability and Analysis of Models for NLP',\n",
       "       'Language Grounding to Vision, Robotics and Beyond',\n",
       "       'Machine Learning for NLP',\n",
       "       'Machine Translation and Multilinguality',\n",
       "       'Phonology, Morphology and Word Segmentation',\n",
       "       'Question Answering', 'Resources and Evaluation',\n",
       "       'Semantics: Lexical Semantics',\n",
       "       'Semantics: Sentence-level Semantics, Textual Inference and Other areas',\n",
       "       'Sentiment Analysis, Stylistic Analysis, and Argument Mining',\n",
       "       'Speech and Multimodality', 'Summarization',\n",
       "       'Syntax: Tagging, Chunking and Parsing',\n",
       "       'Theory and Formalism in NLP (Linguistic and Mathematical)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole.Labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keybert_keyword_extraction(input_text, kw_model, use_maxsum=True, use_mmr=False, ngram=3, topn=10, nr_cand=20, div=0.5):\n",
    "    if use_maxsum:\n",
    "        keywords_res = kw_model.extract_keywords(input_text, keyphrase_ngram_range=(1, ngram), stop_words='english',\n",
    "                                        top_n=topn, use_maxsum=True, nr_candidates=nr_cand)\n",
    "    elif use_mmr:\n",
    "        keywords_res = kw_model.extract_keywords(input_text, keyphrase_ngram_range=(1, ngram), stop_words='english',\n",
    "                                        top_n=topn, use_mmr=True, diversity=div)\n",
    "    keyword_str = \"#\".join([kw[0] for kw in keywords_res])\n",
    "    return keyword_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_keyword_extraction(input_text, kw_model, useless):\n",
    "    keywords_res = kw_model.extract_keywords(input_text)\n",
    "    keyword_str = \"#\".join([kw[0] for kw in keywords_res])\n",
    "    return keyword_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_str(keyword_str):\n",
    "    keyword_str = keyword_str.replace(\" \", \"_\")\n",
    "    keyword_str = keyword_str.replace(\"#\", \" \")\n",
    "    return keyword_str\n",
    "\n",
    "#format_str(df_ACL_2020[\"Keyword\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different setting of keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plm_name: roberta-base, allenai/scibert_scivocab_uncased, allenai/specter\n",
    "plm_name = \"allenai/scibert_scivocab_uncased\"\n",
    "plm = TransformerDocumentEmbeddings(plm_name)\n",
    "kw_model = KeyBERT(model=plm)\n",
    "    \n",
    "use_maxsum = False\n",
    "topn = 10\n",
    "nr_cand = 20\n",
    "use_mmr = True\n",
    "ngram = 1\n",
    "df_ACL_2020['Keyword'] = df_ACL_2020['Text'].progress_apply(keybert_keyword_extraction, args=(kw_model, use_maxsum, use_mmr, ngram, topn, nr_cand))\n",
    "\n",
    "df_ACL_2020.to_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_nostem_261222.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plm_name: roberta-base, allenai/scibert_scivocab_uncased, allenai/specter\n",
    "plm_name = \"allenai/specter\"\n",
    "plm = TransformerDocumentEmbeddings(plm_name)\n",
    "kw_model = KeyBERT(model=plm)\n",
    "    \n",
    "use_maxsum = False\n",
    "topn = 10\n",
    "nr_cand = 20\n",
    "use_mmr = True\n",
    "ngram = 1\n",
    "df_ACL_2020['Keyword'] = df_ACL_2020['Lemm Stemmed Text'].progress_apply(keybert_keyword_extraction, args=(kw_model, use_maxsum, use_mmr, ngram, topn, nr_cand))\n",
    "\n",
    "df_ACL_2020.to_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_specter_261222.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dedup_func='seqm'\n",
    "dedup_thred=0.7\n",
    "ngram=2\n",
    "wind_size=1\n",
    "top_n=20\n",
    "kw_model = yake.KeywordExtractor(n=ngram, dedupLim=dedup_thred, dedupFunc=dedup_func, windowsSize=wind_size, top=top_n)\n",
    "useless=True\n",
    "\n",
    "df_ACL_2020['Keyword'] = df_ACL_2020['Lemm Stemmed Text'].progress_apply(yake_keyword_extraction, args=(kw_model, useless))\n",
    "\n",
    "df_ACL_2020.to_csv(\"./Data/ACL_2020_keywords_yake_030123.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EMNLP_2020['Keyword'] = df_EMNLP_2020['Lemm Stemmed Text'].progress_apply(yake_keyword_extraction, args=(kw_model, useless))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword matching based topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_mmr_161222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_mmr_bigram_161222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_maxsum_231222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_maxsum_bigram_231222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_maxsum_unigram_251222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_maxsum_unigram_251222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_maxsum_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_maxsum_bigram_specter_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_bigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords20_mmr_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords20_mmr_bigram_specter_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords30_mmr_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords40_mmr_unigram_specter_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords20_mmr_unigram_specter_div7_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_roberta_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_specter_nostem_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_nostem_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_roberta_nostem_261222.csv\")\n",
    "df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_yake_030123.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ACL_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on ACL2020\n",
    "\n",
    "Obtain topic_keywords{topic: \\[keywords\\]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_ACL_load\n",
    "text_label = \"Keyword\" # Extract keyword from which column, \"Keyword\" or \"Lemm Stemmed Text\", or \"Text\"\n",
    "topk = 10 # 10, 20, 30, 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for keyword only, convert from 'kc kc#kw2#kc kc3' to \"kc_kc kw2 kc_kc3\"\n",
    "df_train[\"Keyword\"] = df_train[\"Keyword\"].apply(format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_docs = df_train.groupby(['Label'], as_index=False).agg({text_label: ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_vals = tfidf_model.fit_transform(topic_docs[text_label])\n",
    "keyword_feas = tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if text_label == \"Keyword\": \n",
    "    ngram_range=1\n",
    "elif text_label == \"Lemm Stemmed Text\": \n",
    "    ngram_range=(1, 2)\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range).fit(topic_docs[text_label])\n",
    "count = count_vectorizer.transform(topic_docs[text_label])\n",
    "words = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTFIDFVectorizer(TfidfTransformer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CTFIDFVectorizer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X: sp.csr_matrix, n_samples: int):\n",
    "        \"\"\"Learn the idf vector (global term weights) \"\"\"\n",
    "        _, n_features = X.shape\n",
    "        df = np.squeeze(np.asarray(X.sum(axis=0)))\n",
    "        idf = np.log(n_samples / df)\n",
    "        self._idf_diag = sp.diags(idf, offsets=0,\n",
    "                                  shape=(n_features, n_features),\n",
    "                                  format='csr',\n",
    "                                  dtype=np.float64)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: sp.csr_matrix) -> sp.csr_matrix:\n",
    "        \"\"\"Transform a count-based matrix to c-TF-IDF \"\"\"\n",
    "        X = X * self._idf_diag\n",
    "        X = normalize(X, axis=1, norm='l1', copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top _topk_ words per class\n",
    "ctfidf = CTFIDFVectorizer().fit_transform(count, n_samples=len(df_train)).toarray()\n",
    "\n",
    "topic_keywords = {topic_docs['Label'].iloc[label]: [words[index].replace(\"_\", \" \") for index in ctfidf[label].argsort()[-topk:]  if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "topic_keywords_val = {topic_docs['Label'].iloc[label]: [(words[index].replace(\"_\", \" \"), ctfidf[label][index]) for index in ctfidf[label].argsort()[-topk:] if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "\n",
    "#topic_keywords = {topic_docs['Label'].iloc[label]: [lemmatiser_stemmer_stopword(words[index].replace(\"_\", \" \"), nlp, stemmer) for index in ctfidf[label].argsort()[-topk:]  if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "#topic_keywords_val = {topic_docs['Label'].iloc[label]: [(lemmatiser_stemmer_stopword(words[index].replace(\"_\", \" \"), nlp, stemmer), ctfidf[label][index]) for index in ctfidf[label].argsort()[-topk:] if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_keywords_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on ACL2020/EMNLP2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_EMNLP_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_count(text): \n",
    "\n",
    "    keyword_count_dict = {}\n",
    "    keyword_list_dict = {}\n",
    "\n",
    "    for label in topic_keywords.keys():\n",
    "\n",
    "        count = 0\n",
    "        keywords = []\n",
    "\n",
    "        list_of_key_words = topic_keywords[label]\n",
    "\n",
    "        for keyword in list_of_key_words:\n",
    "\n",
    "            count += text.count(keyword)\n",
    "            if keyword in text: keywords.append(keyword)\n",
    "\n",
    "        keyword_count_dict[label] = count\n",
    "        keyword_list_dict[label] = keywords\n",
    "    \n",
    "    return keyword_list_dict, keyword_count_dict, max(keyword_count_dict, key=keyword_count_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count keywords from \"Text\" or \"Lemm Stemmed Text\" or \"Keyword\", according to which column to extract keyword\n",
    "df_pred = df_test.apply(lambda row: keyword_count(row['Lemm Stemmed Text']), axis='columns', result_type='expand')\n",
    "df_pred.columns = [\"Matched Keywords\", \"Dictionary Output\", \"Predicted Label\"]\n",
    "\n",
    "df_test = pd.concat([df_test, df_pred], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Label Outcome\"] = df_test.apply(lambda x: x[\"Label\"] == x[\"Predicted Label\"], axis = 1)\n",
    "df_test_outcome = df_test[['Label', 'Label Outcome']].groupby(['Label', 'Label Outcome']).size().reset_index(name='Counts')\n",
    "df_test_outcome = df_test_outcome.sort_values(by = ['Label','Label Outcome'], ascending = [True, False])\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(df_test_outcome, x=\"Label\", y=\"Counts\", color=\"Label Outcome\", title=\"Predictions for ACL Dataset\",\n",
    "             width=900, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_labels = list(df_test[\"Label\"].unique())\n",
    "\n",
    "cm = confusion_matrix(df_test['Label'], df_test['Predicted Label'], labels = idx_labels)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = idx_labels, \n",
    "                     columns = idx_labels)\n",
    "\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cm_df, annot=True, cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(df_test['Label'], df_test['Predicted Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_accuracy = df_test_outcome.pivot(index=\"Label\", columns=\"Label Outcome\", values=\"Counts\").reset_index().fillna(0)\n",
    "df_test_accuracy[\"Accuracy\"] = df_test_accuracy[True] / (df_test_accuracy[False] + df_test_accuracy[True]) * 100\n",
    "df_test_accuracy = df_test_accuracy.sort_values(by = 'Accuracy', axis=0, ascending=False)\n",
    "df_test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b110531817a2bf0b8e1fa59ad47ae74cf2e8602bdaf1b8cf6b96ebd8cf78ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
