{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "# Reading in files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import scipy.sparse as sp\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keybert import KeyBERT\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "\n",
    "import yake\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Overestimation of Syntactic Representation in Neural Language Models</td>\n",
       "      <td>With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals</td>\n",
       "      <td>Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>A Systematic Assessment of Syntactic Generalization in Neural Language Models</td>\n",
       "      <td>While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts</td>\n",
       "      <td>Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Probing Linguistic Systematicity</td>\n",
       "      <td>Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Dice Loss for Data-imbalanced NLP Tasks</td>\n",
       "      <td>Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese</td>\n",
       "      <td>We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>A Formal Hierarchy of RNN Architectures</td>\n",
       "      <td>We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of \"saturated\" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Emergence of Syntax Needs Minimal Supervision</td>\n",
       "      <td>This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Theoretical Limitations of Self-Attention in Neural Sequence Models</td>\n",
       "      <td>Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Label  \\\n",
       "0    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "1    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "2    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "3    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "4    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "..                                                             ...   \n",
       "771      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "772      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "773      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "774      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "775      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "\n",
       "                                                                                                                          Title  \\\n",
       "0                                                          Overestimation of Syntactic Representation in Neural Language Models   \n",
       "1    Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals   \n",
       "2                                                 A Systematic Assessment of Syntactic Generalization in Neural Language Models   \n",
       "3                                 Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts   \n",
       "4                                                                                              Probing Linguistic Systematicity   \n",
       "..                                                                                                                          ...   \n",
       "771                                                                                     Dice Loss for Data-imbalanced NLP Tasks   \n",
       "772                              Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese   \n",
       "773                                                                                     A Formal Hierarchy of RNN Architectures   \n",
       "774                                                                               Emergence of Syntax Needs Minimal Supervision   \n",
       "775                                                         Theoretical Limitations of Self-Attention in Neural Sequence Models   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Abstract  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.  \n",
       "1    Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.  \n",
       "2                                                                                                                                                                                        While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                           Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                         Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...  \n",
       "771                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.  \n",
       "772                                                                                                                                                                                                                                                                                                                             We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.  \n",
       "773                                                                                                                                                                                                                             We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of \"saturated\" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.  \n",
       "774                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.  \n",
       "775                                                                                                                                                                                                                                                                       Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.  \n",
       "\n",
       "[705 rows x 3 columns]"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ACL_2020 = pd.read_csv(\"./Data/Pred/BART/ACL_2022_bart_pred_231122.csv\")\n",
    "df_EMNLP_2020 = pd.read_csv(\"./Data/Pred/BART/EMNLP_2020_bart_pred_231122.csv\")\n",
    "\n",
    "df_ACL_2020 = df_ACL_2020[[\"Labels\", \"Paper Name\", \"abstract\"]]\n",
    "df_EMNLP_2020 = df_EMNLP_2020[[\"Labels\", \"Paper Name\", \"abstract\"]]\n",
    "\n",
    "df_ACL_2020.columns = [\"Label\", \"Title\", \"Abstract\"]\n",
    "df_EMNLP_2020.columns = [\"Label\", \"Title\", \"Abstract\"]\n",
    "\n",
    "df_ACL_2020 = df_ACL_2020.loc[lambda df_ACL_2020: ~df_ACL_2020[\"Label\"].isin([\"Student Research Workshop\", \"Theme\", \"NLP Applications\", \"System Demonstrations\"]), :]\n",
    "df_ACL_2020[\"Label\"].unique()\n",
    "\n",
    "\n",
    "df_ACL_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_EMNLP_2020 = df_EMNLP_2020.loc[lambda df_EMNLP_2020: ~df_EMNLP_2020[\"Label\"].isin([\"Student Research Workshop\", \"Theme\", \"NLP Applications\", \"System Demonstrations\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ACL_2020['Text'] = df_ACL_2020['Title'] + \" \" +df_ACL_2020['Abstract']\n",
    "df_EMNLP_2020['Text'] = df_EMNLP_2020['Title'] + \" \" +df_EMNLP_2020['Abstract']\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf', disable=['parser', 'ner'])\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatiser_stemmer_stopword(text, nlp, stemmer):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    lemmatised_sentence_lst = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    lemmatised_sentence = \" \".join(lemmatised_sentence_lst)\n",
    "    stemmed_lemmatised_sentence = stemmer.stem(lemmatised_sentence)\n",
    "    \n",
    "    return stemmed_lemmatised_sentence.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 705/705 [02:05<00:00,  5.64it/s]\n"
     ]
    }
   ],
   "source": [
    "df_ACL_2020['Lemm Stemmed Text'] = df_ACL_2020['Text'].progress_apply(lemmatiser_stemmer_stopword, args=(nlp, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 713/713 [02:06<00:00,  5.65it/s]\n"
     ]
    }
   ],
   "source": [
    "df_EMNLP_2020['Lemm Stemmed Text'] = df_EMNLP_2020['Text'].progress_apply(lemmatiser_stemmer_stopword, args=(nlp, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P20 = pd.read_csv(\"./Data/ACL_2020.csv\")\n",
    "df_D20 = pd.read_csv(\"./Data/EMNLP_2020.csv\")\n",
    "df_E21 = pd.read_csv(\"./Data/EACL_2021.csv\")\n",
    "df_P21 = pd.read_csv(\"./Data/ACL_JCNLP_2021.csv\")\n",
    "df_N21 = pd.read_csv(\"./Data/NAACL_2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2894\n",
      "791 791 23\n",
      "781 781 20\n",
      "320 320 21\n",
      "528 528 22\n",
      "474 474 22\n"
     ]
    }
   ],
   "source": [
    "print(len(df_P20) + len(df_D20) + len(df_E21) + len(df_P21) + len(df_N21))\n",
    "print(len(df_P20), len(df_P20.Labels), len(df_P20.Labels.unique()))\n",
    "print(len(df_D20), len(df_D20.Labels), len(df_D20.Labels.unique()))\n",
    "print(len(df_E21), len(df_E21.Labels), len(df_E21.Labels.unique()))\n",
    "print(len(df_P21), len(df_P21.Labels), len(df_P21.Labels.unique()))\n",
    "print(len(df_N21), len(df_N21.Labels), len(df_N21.Labels.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P20 = df_P20[df_P20[\"Labels\"] != \"NLP Applications\"]\n",
    "df_D20 = df_D20[df_D20[\"Labels\"] != \"NLP Applications\"]\n",
    "df_E21 = df_E21[df_E21[\"Labels\"] != \"NLP Applications\"]\n",
    "df_P21 = df_P21[df_P21[\"Labels\"] != \"NLP Applications\"]\n",
    "df_N21 = df_N21[df_N21[\"Labels\"] != \"NLP Applications\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2705\n",
      "742 742 22\n",
      "715 715 19\n",
      "317 317 20\n",
      "502 502 21\n",
      "429 429 21\n"
     ]
    }
   ],
   "source": [
    "print(len(df_P20) + len(df_D20) + len(df_E21) + len(df_P21) + len(df_N21))\n",
    "print(len(df_P20), len(df_P20.Labels), len(df_P20.Labels.unique()))\n",
    "print(len(df_D20), len(df_D20.Labels), len(df_D20.Labels.unique()))\n",
    "print(len(df_E21), len(df_E21.Labels), len(df_E21.Labels.unique()))\n",
    "print(len(df_P21), len(df_P21.Labels), len(df_P21.Labels.unique()))\n",
    "print(len(df_N21), len(df_N21.Labels), len(df_N21.Labels.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Paper Name</th>\n",
       "      <th>Author Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals</td>\n",
       "      <td>Kate McCurdy, Sharon Goldwater, Adam Lopez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Learning to Understand Child-directed and Adult-directed Speech</td>\n",
       "      <td>Lieke Gelderloos, Grzegorz Chrupała, Afra Alishahi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment</td>\n",
       "      <td>Forrest Davis, Marten van Schijndel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction</td>\n",
       "      <td>Orion Weller, Jordan Hildebrandt, Ilya Reznik, Christopher Challis, E. Shannon Tass, Quinn Snell, Kevin Seppi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts</td>\n",
       "      <td>Alex Rinaldi, Jean Fox Tree, Snigdha Chaturvedi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Emergence of Syntax Needs Minimal Supervision</td>\n",
       "      <td>Raphaël Bailly, Kata Gábor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>A Three-Parameter Rank-Frequency Relation in Natural Languages</td>\n",
       "      <td>Chenchen Ding, Masao Utiyama, Eiichiro Sumita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese</td>\n",
       "      <td>Tatsuki Kuribayashi, Takumi Ito, Jun Suzuki, Kentaro Inui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Dice Loss for Data-imbalanced NLP Tasks</td>\n",
       "      <td>Xiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun Liang, Fei Wu, Jiwei Li</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Theoretical Limitations of Self-Attention in Neural Sequence Models</td>\n",
       "      <td>Michael Hahn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Labels  \\\n",
       "0    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "1    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "2    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "3    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "4    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "..                                                             ...   \n",
       "786      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "787      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "788      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "789      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "790      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "\n",
       "                                                                                                                     Paper Name  \\\n",
       "0    Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals   \n",
       "1                                                               Learning to Understand Child-directed and Adult-directed Speech   \n",
       "2                                 Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment   \n",
       "3                                          You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction   \n",
       "4                                 Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts   \n",
       "..                                                                                                                          ...   \n",
       "786                                                                               Emergence of Syntax Needs Minimal Supervision   \n",
       "787                                                              A Three-Parameter Rank-Frequency Relation in Natural Languages   \n",
       "788                              Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese   \n",
       "789                                                                                     Dice Loss for Data-imbalanced NLP Tasks   \n",
       "790                                                         Theoretical Limitations of Self-Attention in Neural Sequence Models   \n",
       "\n",
       "                                                                                                      Author Names  \n",
       "0                                                                       Kate McCurdy, Sharon Goldwater, Adam Lopez  \n",
       "1                                                               Lieke Gelderloos, Grzegorz Chrupała, Afra Alishahi  \n",
       "2                                                                              Forrest Davis, Marten van Schijndel  \n",
       "3    Orion Weller, Jordan Hildebrandt, Ilya Reznik, Christopher Challis, E. Shannon Tass, Quinn Snell, Kevin Seppi  \n",
       "4                                                                  Alex Rinaldi, Jean Fox Tree, Snigdha Chaturvedi  \n",
       "..                                                                                                             ...  \n",
       "786                                                                                     Raphaël Bailly, Kata Gábor  \n",
       "787                                                                  Chenchen Ding, Masao Utiyama, Eiichiro Sumita  \n",
       "788                                                      Tatsuki Kuribayashi, Takumi Ito, Jun Suzuki, Kentaro Inui  \n",
       "789                                            Xiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun Liang, Fei Wu, Jiwei Li  \n",
       "790                                                                                                   Michael Hahn  \n",
       "\n",
       "[742 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_P20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Paper Name</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals</td>\n",
       "      <td>Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Learning to Understand Child-directed and Adult-directed Speech</td>\n",
       "      <td>Speech directed to children differs from adultdirected speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment</td>\n",
       "      <td>A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction</td>\n",
       "      <td>Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only predictions (i.e. predicting the time to read a single word). We seek to extend these works by examining whether or not document level predictions are effective, given additional information such as subject matter, font characteristics, and readability metrics. We perform a novel experiment to examine how different features of text contribute to the time it takes to read, distributing and collecting data from over a thousand participants. We then employ a large number of machine learning methods to predict a user's reading time. We find that despite extensive research showing that word level reading time can be most effectively predicted by neural networks, larger scale text can be easily and most accurately predicted by one factor, the number of words.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts</td>\n",
       "      <td>Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization</td>\n",
       "      <td>Meetings are a key component of human collaboration. As increasing numbers of meetings are recorded and transcribed, meeting summaries have become essential to remind those who may or may not have attended the meetings about the key decisions made and the tasks to be completed. However, it is hard to create a single short summary that covers all the content of a long meeting involving multiple people and topics. In order to satisfy the needs of different types of users, we define a new query-based multi-domain meeting summarization task, where models have to select and summarize relevant spans of meetings in response to a query, and we introduce QMSum, a new benchmark for this task. QMSum consists of 1,808 query-summary pairs over 232 meetings in multiple domains. Besides, we investigate a locate-then-summarize method and evaluate a set of strong summarization baselines on the task. Experimental results and manual analysis reveal that QMSum presents significant challenges in long meeting summarization for future research. Dataset is available at https://github.com/Yale-LILY/ QMSum.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>MM-AVS: A Full-Scale Dataset for Multi-modal Summarization</td>\n",
       "      <td>Multimodal summarization becomes increasingly significant as it is the basis for question answering, Web search, and many other downstream tasks. However, its learning materials have been lacking a holistic organization by integrating resources from various modalities, thereby lagging behind the research progress of this field. In this study, we present a full-scale multimodal dataset comprehensively gathering documents, summaries, images, captions, videos, audios, transcripts, and titles in English from CNN and Daily Mail. To our best knowledge, this is the first collection that spans all modalities and nearly comprises all types of materials available in this community. In addition, we devise a baseline model based on the novel dataset, which employs a newly proposed Jump-Attention mechanism based on transcripts. The experimental results validate the important assistance role of the external information for multimodal summarization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization</td>\n",
       "      <td>This paper introduces MEDIASUM 1 , a largescale media interview dataset consisting of 463.6K transcripts with abstractive summaries. To create this dataset, we collect interview transcripts from NPR and CNN and employ the overview and topic descriptions as summaries. Compared with existing public corpora for dialogue summarization, our dataset is an order of magnitude larger and contains complex multi-party conversations from multiple domains. We conduct statistical analysis to demonstrate the unique positional bias exhibited in the transcripts of televised and radioed interviews. We also show that MEDIASUM can be used in transfer learning to improve a model's performance on other dialogue summarization tasks. * Equal contribution 1 https://github.com/zcgzcgzcg1/ MediaSum/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection</td>\n",
       "      <td>Despite significant progress in neural abstractive summarization, recent studies have shown that the current models are prone to generating summaries that are unfaithful to the original context. To address the issue, we study contrast candidate generation and selection as a model-agnostic post-processing technique to correct the extrinsic hallucinations (i.e. information not present in the source text) in unfaithful summaries. We learn a discriminative correction model by generating alternative candidate summaries where named entities and quantities in the generated summary are replaced with ones with compatible semantic types from the source document. This model is then used to select the best candidate as the final output summary. Our experiments and analysis across a number of neural summarization systems show that our proposed method is effective in identifying and correcting extrinsic hallucinations. We analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>Inference Time Style Control for Summarization</td>\n",
       "      <td>How to generate summaries of different styles without requiring corpora in the target styles, or training separate models? We present two novel methods that can be deployed during summary decoding on any pre-trained Transformer-based summarization model. ( 1 ) Decoder state adjustment instantly modifies decoder final states with externally trained style scorers, to iteratively refine the output against a target style. (2) Word unit prediction constrains the word usage to impose strong lexical control during generation. In experiments of summarizing with simplicity control, automatic evaluation and human judges both find our models producing outputs in simpler languages while still informative. We also generate news headlines with various ideological leanings, which can be distinguished by humans with a reasonable probability.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2534 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Labels  \\\n",
       "0     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "1     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "2     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "3     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "4     Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "...                                                             ...   \n",
       "2710                                                  Summarization   \n",
       "2711                                                  Summarization   \n",
       "2712                                                  Summarization   \n",
       "2713                                                  Summarization   \n",
       "2714                                                  Summarization   \n",
       "\n",
       "                                                                                                                      Paper Name  \\\n",
       "0     Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals   \n",
       "1                                                                Learning to Understand Child-directed and Adult-directed Speech   \n",
       "2                                  Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment   \n",
       "3                                           You Don't Have Time to Read This: An Exploration of Document Reading Time Prediction   \n",
       "4                                  Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts   \n",
       "...                                                                                                                          ...   \n",
       "2710                                                   QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization   \n",
       "2711                                                                  MM-AVS: A Full-Scale Dataset for Multi-modal Summarization   \n",
       "2712                                                  MediaSum: A Large-scale Media Interview Dataset for Dialogue Summarization   \n",
       "2713                        Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection   \n",
       "2714                                                                              Inference Time Style Control for Summarization   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      abstract  \n",
       "0     Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.  \n",
       "1                                                                                                                                                                                                                                                                                                                               Speech directed to children differs from adultdirected speech in linguistic aspects such as repetition, word choice, and sentence length, as well as in aspects of the speech signal itself, such as prosodic and phonemic variation. Human language acquisition research indicates that child-directed speech helps language learners. This study explores the effect of child-directed speech when learning to extract semantic information from speech directly. We compare the task performance of models trained on adult-directed speech (ADS) and child-directed speech (CDS). We find indications that CDS helps in the initial stages of learning, but eventually, models trained on ADS reach comparable task performance, and generalize better. The results suggest that this is at least partially due to linguistic rather than acoustic properties of the two registers, as we see the same pattern when looking at models trained on acoustically comparable synthetic speech.  \n",
       "2                                                                                                                                                                                                                                          A standard approach to evaluating language models analyzes how models assign probabilities to valid versus invalid syntactic constructions (i.e. is a grammatical sentence more probable than an ungrammatical sentence). Our work uses ambiguous relative clause attachment to extend such evaluations to cases of multiple simultaneous valid interpretations, where stark grammaticality differences are absent. We compare model performance in English and Spanish to show that non-linguistic biases in RNN LMs advantageously overlap with syntactic structure in English but not Spanish. Thus, English models may appear to acquire human-like syntactic preferences, while models trained on Spanish fail to acquire comparable human-like preferences. We conclude by relating these results to broader concerns about the relationship between comprehension (i.e. typical language model use cases) and production (which generates the training data for language models), suggesting that necessary linguistic biases are not present in the training signal at all.  \n",
       "3                                                                                                                                                                                                                                                                           Predicting reading time has been a subject of much previous work, focusing on how different words affect human processing, measured by reading time. However, previous work has dealt with a limited number of participants as well as word level only predictions (i.e. predicting the time to read a single word). We seek to extend these works by examining whether or not document level predictions are effective, given additional information such as subject matter, font characteristics, and readability metrics. We perform a novel experiment to examine how different features of text contribute to the time it takes to read, distributing and collecting data from over a thousand participants. We then employ a large number of machine learning methods to predict a user's reading time. We find that despite extensive research showing that word level reading time can be most effectively predicted by neural networks, larger scale text can be easily and most accurately predicted by one factor, the number of words.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                            Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...  \n",
       "2710                                                                                                                                                                                Meetings are a key component of human collaboration. As increasing numbers of meetings are recorded and transcribed, meeting summaries have become essential to remind those who may or may not have attended the meetings about the key decisions made and the tasks to be completed. However, it is hard to create a single short summary that covers all the content of a long meeting involving multiple people and topics. In order to satisfy the needs of different types of users, we define a new query-based multi-domain meeting summarization task, where models have to select and summarize relevant spans of meetings in response to a query, and we introduce QMSum, a new benchmark for this task. QMSum consists of 1,808 query-summary pairs over 232 meetings in multiple domains. Besides, we investigate a locate-then-summarize method and evaluate a set of strong summarization baselines on the task. Experimental results and manual analysis reveal that QMSum presents significant challenges in long meeting summarization for future research. Dataset is available at https://github.com/Yale-LILY/ QMSum.  \n",
       "2711                                                                                                                                                                                                                                                                                                                                      Multimodal summarization becomes increasingly significant as it is the basis for question answering, Web search, and many other downstream tasks. However, its learning materials have been lacking a holistic organization by integrating resources from various modalities, thereby lagging behind the research progress of this field. In this study, we present a full-scale multimodal dataset comprehensively gathering documents, summaries, images, captions, videos, audios, transcripts, and titles in English from CNN and Daily Mail. To our best knowledge, this is the first collection that spans all modalities and nearly comprises all types of materials available in this community. In addition, we devise a baseline model based on the novel dataset, which employs a newly proposed Jump-Attention mechanism based on transcripts. The experimental results validate the important assistance role of the external information for multimodal summarization.  \n",
       "2712                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           This paper introduces MEDIASUM 1 , a largescale media interview dataset consisting of 463.6K transcripts with abstractive summaries. To create this dataset, we collect interview transcripts from NPR and CNN and employ the overview and topic descriptions as summaries. Compared with existing public corpora for dialogue summarization, our dataset is an order of magnitude larger and contains complex multi-party conversations from multiple domains. We conduct statistical analysis to demonstrate the unique positional bias exhibited in the transcripts of televised and radioed interviews. We also show that MEDIASUM can be used in transfer learning to improve a model's performance on other dialogue summarization tasks. * Equal contribution 1 https://github.com/zcgzcgzcg1/ MediaSum/  \n",
       "2713                                                                                                                                                                                                  Despite significant progress in neural abstractive summarization, recent studies have shown that the current models are prone to generating summaries that are unfaithful to the original context. To address the issue, we study contrast candidate generation and selection as a model-agnostic post-processing technique to correct the extrinsic hallucinations (i.e. information not present in the source text) in unfaithful summaries. We learn a discriminative correction model by generating alternative candidate summaries where named entities and quantities in the generated summary are replaced with ones with compatible semantic types from the source document. This model is then used to select the best candidate as the final output summary. Our experiments and analysis across a number of neural summarization systems show that our proposed method is effective in identifying and correcting extrinsic hallucinations. We analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.  \n",
       "2714                                                                                                                                                                                                                                                                                                                                                                                                                                                     How to generate summaries of different styles without requiring corpora in the target styles, or training separate models? We present two novel methods that can be deployed during summary decoding on any pre-trained Transformer-based summarization model. ( 1 ) Decoder state adjustment instantly modifies decoder final states with externally trained style scorers, to iteratively refine the output against a target style. (2) Word unit prediction constrains the word usage to impose strong lexical control during generation. In experiments of summarizing with simplicity control, automatic evaluation and human judges both find our models producing outputs in simpler languages while still informative. We also generate news headlines with various ideological leanings, which can be distinguished by humans with a reasonable probability.  \n",
       "\n",
       "[2534 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole = pd.read_csv(\"./Data/Collated_dataset_for_scientific_papers.csv\")\n",
    "df_whole = df_whole[df_whole['Labels'] != 'NLP Applications']\n",
    "df_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Linguistic Theories, Cognitive Modeling and Psycholinguistics',\n",
       "       'Computational Social Science and Social Media',\n",
       "       'Dialogue and Interactive Systems', 'Discourse and Pragmatics',\n",
       "       'Ethics and NLP', 'Generation', 'Information Extraction',\n",
       "       'Information Retrieval and Text Mining',\n",
       "       'Interpretability and Analysis of Models for NLP',\n",
       "       'Language Grounding to Vision, Robotics and Beyond',\n",
       "       'Machine Learning for NLP',\n",
       "       'Machine Translation and Multilinguality',\n",
       "       'Phonology, Morphology and Word Segmentation',\n",
       "       'Question Answering', 'Resources and Evaluation',\n",
       "       'Semantics: Lexical Semantics',\n",
       "       'Semantics: Sentence-level Semantics, Textual Inference and Other areas',\n",
       "       'Sentiment Analysis, Stylistic Analysis, and Argument Mining',\n",
       "       'Speech and Multimodality', 'Summarization',\n",
       "       'Syntax: Tagging, Chunking and Parsing',\n",
       "       'Theory and Formalism in NLP (Linguistic and Mathematical)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole.Labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keybert_keyword_extraction(input_text, kw_model, use_maxsum=True, use_mmr=False, ngram=3, topn=10, nr_cand=20, div=0.5):\n",
    "    if use_maxsum:\n",
    "        keywords_res = kw_model.extract_keywords(input_text, keyphrase_ngram_range=(1, ngram), stop_words='english',\n",
    "                                        top_n=topn, use_maxsum=True, nr_candidates=nr_cand)\n",
    "    elif use_mmr:\n",
    "        keywords_res = kw_model.extract_keywords(input_text, keyphrase_ngram_range=(1, ngram), stop_words='english',\n",
    "                                        top_n=topn, use_mmr=True, diversity=div)\n",
    "    keyword_str = \"#\".join([kw[0] for kw in keywords_res])\n",
    "    return keyword_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_keyword_extraction(input_text, kw_model, useless):\n",
    "    keywords_res = kw_model.extract_keywords(input_text)\n",
    "    keyword_str = \"#\".join([kw[0] for kw in keywords_res])\n",
    "    return keyword_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_str(keyword_str):\n",
    "    keyword_str = keyword_str.replace(\" \", \"_\")\n",
    "    keyword_str = keyword_str.replace(\"#\", \" \")\n",
    "    return keyword_str\n",
    "\n",
    "#format_str(df_ACL_2020[\"Keyword\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different setting of keyword extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plm_name: roberta-base, allenai/scibert_scivocab_uncased, allenai/specter\n",
    "plm_name = \"allenai/scibert_scivocab_uncased\"\n",
    "plm = TransformerDocumentEmbeddings(plm_name)\n",
    "kw_model = KeyBERT(model=plm)\n",
    "    \n",
    "use_maxsum = False\n",
    "topn = 10\n",
    "nr_cand = 20\n",
    "use_mmr = True\n",
    "ngram = 1\n",
    "df_ACL_2020['Keyword'] = df_ACL_2020['Text'].progress_apply(keybert_keyword_extraction, args=(kw_model, use_maxsum, use_mmr, ngram, topn, nr_cand))\n",
    "\n",
    "df_ACL_2020.to_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_nostem_261222.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plm_name: roberta-base, allenai/scibert_scivocab_uncased, allenai/specter\n",
    "plm_name = \"allenai/specter\"\n",
    "plm = TransformerDocumentEmbeddings(plm_name)\n",
    "kw_model = KeyBERT(model=plm)\n",
    "    \n",
    "use_maxsum = False\n",
    "topn = 10\n",
    "nr_cand = 20\n",
    "use_mmr = True\n",
    "ngram = 1\n",
    "df_ACL_2020['Keyword'] = df_ACL_2020['Lemm Stemmed Text'].progress_apply(keybert_keyword_extraction, args=(kw_model, use_maxsum, use_mmr, ngram, topn, nr_cand))\n",
    "\n",
    "df_ACL_2020.to_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_specter_261222.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 705/705 [00:45<00:00, 15.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dedup_func='seqm'\n",
    "dedup_thred=0.7\n",
    "ngram=2\n",
    "wind_size=1\n",
    "top_n=20\n",
    "kw_model = yake.KeywordExtractor(n=ngram, dedupLim=dedup_thred, dedupFunc=dedup_func, windowsSize=wind_size, top=top_n)\n",
    "useless=True\n",
    "\n",
    "df_ACL_2020['Keyword'] = df_ACL_2020['Lemm Stemmed Text'].progress_apply(yake_keyword_extraction, args=(kw_model, useless))\n",
    "\n",
    "df_ACL_2020.to_csv(\"./Data/ACL_2020_keywords_yake_030123.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1523,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 651/651 [00:42<00:00, 15.42it/s]\n"
     ]
    }
   ],
   "source": [
    "df_EMNLP_2020['Keyword'] = df_EMNLP_2020['Lemm Stemmed Text'].progress_apply(yake_keyword_extraction, args=(kw_model, useless))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword matching based topic classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_mmr_161222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_mmr_bigram_161222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_maxsum_231222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_maxsum_bigram_231222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_maxsum_unigram_251222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_maxsum_unigram_251222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_maxsum_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_maxsum_bigram_specter_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_bigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords20_mmr_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords20_mmr_bigram_specter_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords30_mmr_unigram_specter_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords40_mmr_unigram_specter_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords20_mmr_unigram_specter_div7_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_roberta_261222.csv\")\n",
    "\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_specter_nostem_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_nostem_261222.csv\")\n",
    "#df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords10_mmr_unigram_roberta_nostem_261222.csv\")\n",
    "df_ACL_load = pd.read_csv(\"./Data/ACL_2020_keywords_yake_030123.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1546,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemm Stemmed Text</th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Overestimation of Syntactic Representation in Neural Language Models</td>\n",
       "      <td>With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.</td>\n",
       "      <td>Overestimation of Syntactic Representation in Neural Language Models With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.</td>\n",
       "      <td>overestimation syntactic representation neural language model advent powerful neural language model year , research attention increasingly focus aspect language represent successful . testing methodology develop probe model ' syntactic representation . popular method determine model ability induce syntactic structure train model string generate accord template test model ability distinguish string superficially similar one different syntax . illustrate fundamental problem approach reproduce positive result recent paper non - syntactic baseline language model : n - gram model lstm model train scrambled input .</td>\n",
       "      <td>language model#neural language#syntactic representation#model ability#research attention#represent successful#testing methodology#popular method#illustrate fundamental#scrambled input#representation neural#aspect language#language represent#baseline language#powerful neural#ability induce#ability distinguish#overestimation syntactic#advent powerful#attention increasingly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals</td>\n",
       "      <td>Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.</td>\n",
       "      <td>Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.</td>\n",
       "      <td>inflect majority : limitation encoder - decoder neural network cognitive model german plural artificial neural network learn represent inflectional morphology generalize new word human speaker ? kirov cotterell ( 2018 ) argue answer yes : modern encoder - decoder ( ed ) architecture learn human - like behavior inflect english verb , extend regular past tense form /-(e)d/ novel word . , work address criticism raise marcus et al . ( 1995 ) : neural model learn extend regular , frequent class -and fail task like german number inflection , infrequent suffix like /-s/ productively generalize . investigate question , collect new dataset german speaker ( production rating plural form novel noun ) design avoid source information unavailable ed model . speaker datum high variability , suffix evince ' regular ' behavior , appear phonologically atypical input . encoder - decoder model generalize frequently produce plural class , human - like variability ' regular ' extension plural marker . conclude modern neural model struggle minority - class generalization .</td>\n",
       "      <td>kirov cotterell#investigate question#limitation encoder#neural network#extend regular#argue answer#english verb#work address#number inflection#production rating#design avoid#atypical input#struggle minority#high variability#inflect majority#infrequent suffix#suffix evince#conclude modern#represent inflectional#inflectional morphology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>A Systematic Assessment of Syntactic Generalization in Neural Language Models</td>\n",
       "      <td>While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.</td>\n",
       "      <td>A Systematic Assessment of Syntactic Generalization in Neural Language Models While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.</td>\n",
       "      <td>systematic assessment syntactic generalization neural language model state - - - art neural network model continue achieve low perplexity score language modeling benchmark , remain unknown optimize broad - coverage predictive performance lead human - like syntactic knowledge . furthermore , exist work provide clear picture model property require produce proper syntactic generalization . present systematic evaluation syntactic knowledge neural language model , test 20 combination model type data size set 34 english - language syntactic test suite . find substantial difference syntactic generalization performance model architecture , sequential model underperform architecture . factorially manipulate model architecture training dataset size ( 1m-40 m word ) , find variability syntactic generalization performance substantially great architecture dataset size corpus test experiment . result reveal dissociation perplexity syntactic generalization performance .</td>\n",
       "      <td>syntactic generalization#generalization performance#dataset size#neural language#syntactic knowledge#generalization neural#find substantial#find variability#modeling benchmark#remain unknown#optimize broad#coverage predictive#lead human#exist work#factorially manipulate#result reveal#language model#art neural#size set#present systematic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts</td>\n",
       "      <td>Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.</td>\n",
       "      <td>Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.</td>\n",
       "      <td>predict depression screening interview latent categorization interview prompt despite pervasiveness clinical depression modern society , professional help remain highly stigmatized , inaccessible , expensive . accurately diagnose depression difficult - require time - intensive interview , assessment , analysis . , automate method assess linguistic pattern interview help psychiatric professional fast , informed decision diagnosis . propose jlpc , method analyze interview transcript identify depression jointly categorize interview prompt latent category . latent categorization allow model identify high - level conversational context influence pattern language depressed individual . propose model outperform competitive baseline , latent prompt category provide psycholinguistic insight depression .</td>\n",
       "      <td>require time#propose jlpc#latent categorization#modern society#highly stigmatized#accurately diagnose#informed decision#decision diagnosis#level conversational#depressed individual#competitive baseline#automate method#professional fast#identify high#propose model#interview prompt#pervasiveness clinical#remain highly#assess linguistic#jointly categorize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>Probing Linguistic Systematicity</td>\n",
       "      <td>Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.</td>\n",
       "      <td>Probing Linguistic Systematicity Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.</td>\n",
       "      <td>probe linguistic systematicity recently , interest question deep natural language understanding model exhibit systematicitygeneralizing unit like word consistent contribution meaning sentence appear . accumulate evidence neural model generalize non - systematically . examine notion systematicity linguistic perspective , define set probe set metric measure systematic behaviour . identify way network architecture generalize non - systematically , discuss form generalization unsatisfying . case study , perform series experiment setting natural language inference ( nli ) , demonstrate nlu system achieve high overall performance despite non - systematic .</td>\n",
       "      <td>case study#natural language#interest question#accumulate evidence#examine notion#discuss form#generalization unsatisfying#perform series#demonstrate nlu#language inference#systematicity recently#linguistic perspective#define set#systematic behaviour#question deep#exhibit systematicitygeneralizing#systematicitygeneralizing unit#word consistent#consistent contribution#contribution meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Dice Loss for Data-imbalanced NLP Tasks</td>\n",
       "      <td>Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.</td>\n",
       "      <td>Dice Loss for Data-imbalanced NLP Tasks Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.</td>\n",
       "      <td>dice loss data - imbalance nlp task nlp task tagging machine reading comprehension ( mrc ) face severe data imbalance issue : negative example significantly outnumber positive one , huge number easy - negative example overwhelm training . commonly cross entropy criterion actually accuracy - orient , create discrepancy training test . training time , training instance contribute equally objective function , test time f1 score concern positive example .</td>\n",
       "      <td>nlp task#dice loss#reading comprehension#face severe#huge number#number easy#commonly cross#create discrepancy#objective function#score concern#imbalance issue#test time#tagging machine#machine reading#significantly outnumber#cross entropy#entropy criterion#instance contribute#contribute equally#equally objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese</td>\n",
       "      <td>We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.</td>\n",
       "      <td>Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.</td>\n",
       "      <td>language model alternative evaluator word order hypothesis : case study japanese examine methodology neural language model ( lms ) analyze word order language . lm - base method potential overcome difficulty exist method face , propagation preprocessor error count - base method . study , explore lmbase method valid analyze word order . case study , study focus japanese complex flexible word order . validate lm - base method , test ( ) parallel lms human word order preference , ( ii ) consistency result obtain lm - base method previous linguistic study . experiment , tentatively conclude lms display sufficient word order knowledge usage analysis tool . finally , lmbased method , demonstrate relationship canonical word order topicalization , analyze largescale experiment .</td>\n",
       "      <td>word order#base method#case study#language model#analyze word#propagation preprocessor#error count#explore lmbase#consistency result#tentatively conclude#analysis tool#demonstrate relationship#largescale experiment#order hypothesis#order preference#order topicalization#evaluator word#flexible word#human word#sufficient word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>A Formal Hierarchy of RNN Architectures</td>\n",
       "      <td>We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of \"saturated\" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.</td>\n",
       "      <td>A Formal Hierarchy of RNN Architectures We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of \"saturated\" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.</td>\n",
       "      <td>formal hierarchy rnn architecture develop formal hierarchy expressive capacity rnn architecture . hierarchy base formal property : space complexity , measure rnn memory , rational recurrence , define recurrent update describe weight finite - state machine . place rnn variant hierarchy . example , prove lstm rational , formally separate related qrnn ( bradbury et al . , 2016 ) . model ' expressive capacity expand stack multiple layer compose different pool function . result build theory \" saturated \" rnn ( merrill , 2019 ) . formally extend finding unsaturated rnn leave future work , hypothesize practical learnable capacity unsaturated rnn obey similar hierarchy . experimental finding train unsaturated network formal language support conjecture . proof . choose k = 1 . fix controller push 1 x t = , pop .</td>\n",
       "      <td>expressive capacity#space complexity#state machine#rnn architecture#formally separate#formally extend#unsaturated rnn#define recurrent#weight finite#prove lstm#related qrnn#pool function#result build#build theory#future work#hypothesize practical#support conjecture#fix controller#controller push#formal hierarchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Emergence of Syntax Needs Minimal Supervision</td>\n",
       "      <td>This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.</td>\n",
       "      <td>Emergence of Syntax Needs Minimal Supervision This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.</td>\n",
       "      <td>emergence syntax need minimal supervision paper theoretical contribution debate learnability syntax corpus explicit syntax - specific guidance . approach originate observable structure corpus , use define isolate grammaticality ( syntactic information ) meaning / pragmatic information . describe formal characteristic autonomous syntax possible search syntax - base lexical category simple optimization process , prior hypothesis form model .</td>\n",
       "      <td>specific guidance#syntactic information#approach originate#isolate grammaticality#describe formal#base lexical#optimization process#prior hypothesis#form model#minimal supervision#supervision paper#paper theoretical#theoretical contribution#contribution debate#debate learnability#originate observable#observable structure#define isolate#formal characteristic#characteristic autonomous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Theory and Formalism in NLP (Linguistic and Mathematical)</td>\n",
       "      <td>Theoretical Limitations of Self-Attention in Neural Sequence Models</td>\n",
       "      <td>Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.</td>\n",
       "      <td>Theoretical Limitations of Self-Attention in Neural Sequence Models Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.</td>\n",
       "      <td>theoretical limitation self - attention neural sequence model transformer emerge new workhorse nlp , show great success task . unlike lstms , transformer process input sequence entirely self - attention . previous work suggest computational capability self - attention process hierarchical structure limited . work , mathematically investigate computational power self - attention model formal language . soft hard attention , strong theoretical limitation computational ability selfattention , find model periodic finite - state language , hierarchical structure , number layer head increase input length . limitation surprising give practical success self - attention prominent role assign hierarchical structure linguistic , suggest natural language approximate model weak formal language typically assume theoretical linguistic .</td>\n",
       "      <td>hierarchical structure#unlike lstms#theoretical limitation#formal language#structure limited#workhorse nlp#show great#mathematically investigate#soft hard#ability selfattention#periodic finite#number layer#structure linguistic#strong theoretical#success task#previous work#input length#theoretical linguistic#weak formal#assign hierarchical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Label  \\\n",
       "0    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "1    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "2    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "3    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "4    Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "..                                                             ...   \n",
       "700      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "701      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "702      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "703      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "704      Theory and Formalism in NLP (Linguistic and Mathematical)   \n",
       "\n",
       "                                                                                                                          Title  \\\n",
       "0                                                          Overestimation of Syntactic Representation in Neural Language Models   \n",
       "1    Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals   \n",
       "2                                                 A Systematic Assessment of Syntactic Generalization in Neural Language Models   \n",
       "3                                 Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts   \n",
       "4                                                                                              Probing Linguistic Systematicity   \n",
       "..                                                                                                                          ...   \n",
       "700                                                                                     Dice Loss for Data-imbalanced NLP Tasks   \n",
       "701                              Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese   \n",
       "702                                                                                     A Formal Hierarchy of RNN Architectures   \n",
       "703                                                                               Emergence of Syntax Needs Minimal Supervision   \n",
       "704                                                         Theoretical Limitations of Self-Attention in Neural Sequence Models   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.   \n",
       "1    Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.   \n",
       "2                                                                                                                                                                                        While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                           Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                         Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...   \n",
       "700                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.   \n",
       "701                                                                                                                                                                                                                                                                                                                             We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.   \n",
       "702                                                                                                                                                                                                                             We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of \"saturated\" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.   \n",
       "703                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.   \n",
       "704                                                                                                                                                                                                                                                                       Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Overestimation of Syntactic Representation in Neural Language Models With the advent of powerful neural language models over the last few years, research attention has increasingly focused on what aspects of language they represent that make them so successful. Several testing methodologies have been developed to probe models' syntactic representations. One popular method for determining a model's ability to induce syntactic structure trains a model on strings generated according to a template then tests the model's ability to distinguish such strings from superficially similar ones with different syntax. We illustrate a fundamental problem with this approach by reproducing positive results from a recent paper with two non-syntactic baseline language models: an n-gram model and an LSTM model trained on scrambled inputs.   \n",
       "1    Inflecting When There's No Majority: Limitations of Encoder-Decoder Neural Networks as Cognitive Models for German Plurals Can artificial neural networks learn to represent inflectional morphology and generalize to new words as human speakers do? Kirov and Cotterell (2018) argue that the answer is yes: modern Encoder-Decoder (ED) architectures learn human-like behavior when inflecting English verbs, such as extending the regular past tense form /-(e)d/ to novel words. However, their work does not address the criticism raised by Marcus et al. (1995) : that neural models may learn to extend not the regular, but the most frequent class -and thus fail on tasks like German number inflection, where infrequent suffixes like /-s/ can still be productively generalized. To investigate this question, we first collect a new dataset from German speakers (production and ratings of plural forms for novel nouns) that is designed to avoid sources of information unavailable to the ED model. The speaker data show high variability, and two suffixes evince 'regular' behavior, appearing more often with phonologically atypical inputs. Encoder-decoder models do generalize the most frequently produced plural class, but do not show human-like variability or 'regular' extension of these other plural markers. We conclude that modern neural models may still struggle with minority-class generalization.   \n",
       "2                                                                                                                                                                                                                                     A Systematic Assessment of Syntactic Generalization in Neural Language Models While state-of-the-art neural network models continue to achieve lower perplexity scores on language modeling benchmarks, it remains unknown whether optimizing for broad-coverage predictive performance leads to human-like syntactic knowledge. Furthermore, existing work has not provided a clear picture about the model properties required to produce proper syntactic generalizations. We present a systematic evaluation of the syntactic knowledge of neural language models, testing 20 combinations of model types and data sizes on a set of 34 English-language syntactic test suites. We find substantial differences in syntactic generalization performance by model architecture, with sequential models underperforming other architectures. Factorially manipulating model architecture and training dataset size (1M-40M words), we find that variability in syntactic generalization performance is substantially greater by architecture than by dataset size for the corpora tested in our experiments. Our results also reveal a dissociation between perplexity and syntactic generalization performance.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                        Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts Despite the pervasiveness of clinical depression in modern society, professional help remains highly stigmatized, inaccessible, and expensive. Accurately diagnosing depression is difficult-requiring time-intensive interviews, assessments, and analysis. Hence, automated methods that can assess linguistic patterns in these interviews could help psychiatric professionals make faster, more informed decisions about diagnosis. We propose JLPC, a method that analyzes interview transcripts to identify depression while jointly categorizing interview prompts into latent categories. This latent categorization allows the model to identify high-level conversational contexts that influence patterns of language in depressed individuals. We show that the proposed model not only outperforms competitive baselines, but that its latent prompt categories provide psycholinguistic insights about depression.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Probing Linguistic Systematicity Recently, there has been much interest in the question of whether deep natural language understanding models exhibit systematicitygeneralizing such that units like words make consistent contributions to the meaning of the sentences in which they appear. There is accumulating evidence that neural models often generalize non-systematically. We examined the notion of systematicity from a linguistic perspective, defining a set of probes and a set of metrics to measure systematic behaviour. We also identified ways in which network architectures can generalize non-systematically, and discuss why such forms of generalization may be unsatisfying. As a case study, we performed a series of experiments in the setting of natural language inference (NLI), demonstrating that some NLU systems achieve high overall performance despite being non-systematic.   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "700                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Dice Loss for Data-imbalanced NLP Tasks Many NLP tasks such as tagging and machine reading comprehension (MRC) are faced with the severe data imbalance issue: negative examples significantly outnumber positive ones, and the huge number of easy-negative examples overwhelms training. The most commonly used cross entropy criteria is actually accuracy-oriented, which creates a discrepancy between training and test. At training time, each training instance contributes equally to the objective function, while at test time F1 score concerns more about positive examples.   \n",
       "701                                                                                                                                                                                                                                                                                                                                                         Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese We examine a methodology using neural language models (LMs) for analyzing the word order of language. This LM-based method has the potential to overcome the difficulties existing methods face, such as the propagation of preprocessor errors in count-based methods. In this study, we explore whether the LMbased method is valid for analyzing the word order. As a case study, this study focuses on Japanese due to its complex and flexible word order. To validate the LM-based method, we test (i) parallels between LMs and human word order preference, and (ii) consistency of the results obtained using the LM-based method with previous linguistic studies. Through our experiments, we tentatively conclude that LMs display sufficient word order knowledge for usage as an analysis tool. Finally, using the LMbased method, we demonstrate the relationship between the canonical word order and topicalization, which had yet to be analyzed by largescale experiments.   \n",
       "702                                                                                                                                                                                                                                                                                                                A Formal Hierarchy of RNN Architectures We develop a formal hierarchy of the expressive capacity of RNN architectures. The hierarchy is based on two formal properties: space complexity, which measures the RNN's memory, and rational recurrence, defined as whether the recurrent update can be described by a weighted finite-state machine. We place several RNN variants within this hierarchy. For example, we prove the LSTM is not rational, which formally separates it from the related QRNN (Bradbury et al., 2016). We also show how these models' expressive capacity is expanded by stacking multiple layers or composing them with different pooling functions. Our results build on the theory of \"saturated\" RNNs (Merrill, 2019) . While formally extending these findings to unsaturated RNNs is left to future work, we hypothesize that the practical learnable capacity of unsaturated RNNs obeys a similar hierarchy. Experimental findings from training unsaturated networks on formal languages support this conjecture. Proof. Choose k = 1. Fix the controller to push 1 for x t = a, and pop otherwise.   \n",
       "703                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Emergence of Syntax Needs Minimal Supervision This paper is a theoretical contribution to the debate on the learnability of syntax from a corpus without explicit syntax-specific guidance. Our approach originates in the observable structure of a corpus, which we use to define and isolate grammaticality (syntactic information) and meaning/pragmatics information. We describe the formal characteristics of an autonomous syntax and show that it becomes possible to search for syntax-based lexical categories with a simple optimization process, without any prior hypothesis on the form of the model.   \n",
       "704                                                                                                                                                                                                                                                                                                                              Theoretical Limitations of Self-Attention in Neural Sequence Models Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Lemm Stemmed Text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                      overestimation syntactic representation neural language model advent powerful neural language model year , research attention increasingly focus aspect language represent successful . testing methodology develop probe model ' syntactic representation . popular method determine model ability induce syntactic structure train model string generate accord template test model ability distinguish string superficially similar one different syntax . illustrate fundamental problem approach reproduce positive result recent paper non - syntactic baseline language model : n - gram model lstm model train scrambled input .   \n",
       "1    inflect majority : limitation encoder - decoder neural network cognitive model german plural artificial neural network learn represent inflectional morphology generalize new word human speaker ? kirov cotterell ( 2018 ) argue answer yes : modern encoder - decoder ( ed ) architecture learn human - like behavior inflect english verb , extend regular past tense form /-(e)d/ novel word . , work address criticism raise marcus et al . ( 1995 ) : neural model learn extend regular , frequent class -and fail task like german number inflection , infrequent suffix like /-s/ productively generalize . investigate question , collect new dataset german speaker ( production rating plural form novel noun ) design avoid source information unavailable ed model . speaker datum high variability , suffix evince ' regular ' behavior , appear phonologically atypical input . encoder - decoder model generalize frequently produce plural class , human - like variability ' regular ' extension plural marker . conclude modern neural model struggle minority - class generalization .   \n",
       "2                                                                                                     systematic assessment syntactic generalization neural language model state - - - art neural network model continue achieve low perplexity score language modeling benchmark , remain unknown optimize broad - coverage predictive performance lead human - like syntactic knowledge . furthermore , exist work provide clear picture model property require produce proper syntactic generalization . present systematic evaluation syntactic knowledge neural language model , test 20 combination model type data size set 34 english - language syntactic test suite . find substantial difference syntactic generalization performance model architecture , sequential model underperform architecture . factorially manipulate model architecture training dataset size ( 1m-40 m word ) , find variability syntactic generalization performance substantially great architecture dataset size corpus test experiment . result reveal dissociation perplexity syntactic generalization performance .   \n",
       "3                                                                                                                                                                                                                                                                         predict depression screening interview latent categorization interview prompt despite pervasiveness clinical depression modern society , professional help remain highly stigmatized , inaccessible , expensive . accurately diagnose depression difficult - require time - intensive interview , assessment , analysis . , automate method assess linguistic pattern interview help psychiatric professional fast , informed decision diagnosis . propose jlpc , method analyze interview transcript identify depression jointly categorize interview prompt latent category . latent categorization allow model identify high - level conversational context influence pattern language depressed individual . propose model outperform competitive baseline , latent prompt category provide psycholinguistic insight depression .   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                            probe linguistic systematicity recently , interest question deep natural language understanding model exhibit systematicitygeneralizing unit like word consistent contribution meaning sentence appear . accumulate evidence neural model generalize non - systematically . examine notion systematicity linguistic perspective , define set probe set metric measure systematic behaviour . identify way network architecture generalize non - systematically , discuss form generalization unsatisfying . case study , perform series experiment setting natural language inference ( nli ) , demonstrate nlu system achieve high overall performance despite non - systematic .   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "700                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     dice loss data - imbalance nlp task nlp task tagging machine reading comprehension ( mrc ) face severe data imbalance issue : negative example significantly outnumber positive one , huge number easy - negative example overwhelm training . commonly cross entropy criterion actually accuracy - orient , create discrepancy training test . training time , training instance contribute equally objective function , test time f1 score concern positive example .   \n",
       "701                                                                                                                                                                                                                                                                                               language model alternative evaluator word order hypothesis : case study japanese examine methodology neural language model ( lms ) analyze word order language . lm - base method potential overcome difficulty exist method face , propagation preprocessor error count - base method . study , explore lmbase method valid analyze word order . case study , study focus japanese complex flexible word order . validate lm - base method , test ( ) parallel lms human word order preference , ( ii ) consistency result obtain lm - base method previous linguistic study . experiment , tentatively conclude lms display sufficient word order knowledge usage analysis tool . finally , lmbased method , demonstrate relationship canonical word order topicalization , analyze largescale experiment .   \n",
       "702                                                                                                                                                                                                                                                              formal hierarchy rnn architecture develop formal hierarchy expressive capacity rnn architecture . hierarchy base formal property : space complexity , measure rnn memory , rational recurrence , define recurrent update describe weight finite - state machine . place rnn variant hierarchy . example , prove lstm rational , formally separate related qrnn ( bradbury et al . , 2016 ) . model ' expressive capacity expand stack multiple layer compose different pool function . result build theory \" saturated \" rnn ( merrill , 2019 ) . formally extend finding unsaturated rnn leave future work , hypothesize practical learnable capacity unsaturated rnn obey similar hierarchy . experimental finding train unsaturated network formal language support conjecture . proof . choose k = 1 . fix controller push 1 x t = , pop .   \n",
       "703                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 emergence syntax need minimal supervision paper theoretical contribution debate learnability syntax corpus explicit syntax - specific guidance . approach originate observable structure corpus , use define isolate grammaticality ( syntactic information ) meaning / pragmatic information . describe formal characteristic autonomous syntax possible search syntax - base lexical category simple optimization process , prior hypothesis form model .   \n",
       "704                                                                                                                                                                                                                                           theoretical limitation self - attention neural sequence model transformer emerge new workhorse nlp , show great success task . unlike lstms , transformer process input sequence entirely self - attention . previous work suggest computational capability self - attention process hierarchical structure limited . work , mathematically investigate computational power self - attention model formal language . soft hard attention , strong theoretical limitation computational ability selfattention , find model periodic finite - state language , hierarchical structure , number layer head increase input length . limitation surprising give practical success self - attention prominent role assign hierarchical structure linguistic , suggest natural language approximate model weak formal language typically assume theoretical linguistic .   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                   Keyword  \n",
       "0                    language model#neural language#syntactic representation#model ability#research attention#represent successful#testing methodology#popular method#illustrate fundamental#scrambled input#representation neural#aspect language#language represent#baseline language#powerful neural#ability induce#ability distinguish#overestimation syntactic#advent powerful#attention increasingly  \n",
       "1                                                          kirov cotterell#investigate question#limitation encoder#neural network#extend regular#argue answer#english verb#work address#number inflection#production rating#design avoid#atypical input#struggle minority#high variability#inflect majority#infrequent suffix#suffix evince#conclude modern#represent inflectional#inflectional morphology  \n",
       "2                                                       syntactic generalization#generalization performance#dataset size#neural language#syntactic knowledge#generalization neural#find substantial#find variability#modeling benchmark#remain unknown#optimize broad#coverage predictive#lead human#exist work#factorially manipulate#result reveal#language model#art neural#size set#present systematic  \n",
       "3                                       require time#propose jlpc#latent categorization#modern society#highly stigmatized#accurately diagnose#informed decision#decision diagnosis#level conversational#depressed individual#competitive baseline#automate method#professional fast#identify high#propose model#interview prompt#pervasiveness clinical#remain highly#assess linguistic#jointly categorize  \n",
       "4    case study#natural language#interest question#accumulate evidence#examine notion#discuss form#generalization unsatisfying#perform series#demonstrate nlu#language inference#systematicity recently#linguistic perspective#define set#systematic behaviour#question deep#exhibit systematicitygeneralizing#systematicitygeneralizing unit#word consistent#consistent contribution#contribution meaning  \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                     ...  \n",
       "700                                                                             nlp task#dice loss#reading comprehension#face severe#huge number#number easy#commonly cross#create discrepancy#objective function#score concern#imbalance issue#test time#tagging machine#machine reading#significantly outnumber#cross entropy#entropy criterion#instance contribute#contribute equally#equally objective  \n",
       "701                                                                  word order#base method#case study#language model#analyze word#propagation preprocessor#error count#explore lmbase#consistency result#tentatively conclude#analysis tool#demonstrate relationship#largescale experiment#order hypothesis#order preference#order topicalization#evaluator word#flexible word#human word#sufficient word  \n",
       "702                                                                              expressive capacity#space complexity#state machine#rnn architecture#formally separate#formally extend#unsaturated rnn#define recurrent#weight finite#prove lstm#related qrnn#pool function#result build#build theory#future work#hypothesize practical#support conjecture#fix controller#controller push#formal hierarchy  \n",
       "703      specific guidance#syntactic information#approach originate#isolate grammaticality#describe formal#base lexical#optimization process#prior hypothesis#form model#minimal supervision#supervision paper#paper theoretical#theoretical contribution#contribution debate#debate learnability#originate observable#observable structure#define isolate#formal characteristic#characteristic autonomous  \n",
       "704                                                   hierarchical structure#unlike lstms#theoretical limitation#formal language#structure limited#workhorse nlp#show great#mathematically investigate#soft hard#ability selfattention#periodic finite#number layer#structure linguistic#strong theoretical#success task#previous work#input length#theoretical linguistic#weak formal#assign hierarchical  \n",
       "\n",
       "[705 rows x 6 columns]"
      ]
     },
     "execution_count": 1546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ACL_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on ACL2020\n",
    "\n",
    "Obtain topic_keywords{topic: \\[keywords\\]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_ACL_load\n",
    "text_label = \"Keyword\" # Extract keyword from which column, \"Keyword\" or \"Lemm Stemmed Text\", or \"Text\"\n",
    "topk = 10 # 10, 20, 30, 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for keyword only, convert from 'kc kc#kw2#kc kc3' to \"kc_kc kw2 kc_kc3\"\n",
    "df_train[\"Keyword\"] = df_train[\"Keyword\"].apply(format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1549,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_docs = df_train.groupby(['Label'], as_index=False).agg({text_label: ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = TfidfVectorizer()\n",
    "tfidf_vals = tfidf_model.fit_transform(topic_docs[text_label])\n",
    "keyword_feas = tfidf_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "metadata": {},
   "outputs": [],
   "source": [
    "if text_label == \"Keyword\": \n",
    "    ngram_range=1\n",
    "elif text_label == \"Lemm Stemmed Text\": \n",
    "    ngram_range=(1, 2)\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range).fit(topic_docs[text_label])\n",
    "count = count_vectorizer.transform(topic_docs[text_label])\n",
    "words = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTFIDFVectorizer(TfidfTransformer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CTFIDFVectorizer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X: sp.csr_matrix, n_samples: int):\n",
    "        \"\"\"Learn the idf vector (global term weights) \"\"\"\n",
    "        _, n_features = X.shape\n",
    "        df = np.squeeze(np.asarray(X.sum(axis=0)))\n",
    "        idf = np.log(n_samples / df)\n",
    "        self._idf_diag = sp.diags(idf, offsets=0,\n",
    "                                  shape=(n_features, n_features),\n",
    "                                  format='csr',\n",
    "                                  dtype=np.float64)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: sp.csr_matrix) -> sp.csr_matrix:\n",
    "        \"\"\"Transform a count-based matrix to c-TF-IDF \"\"\"\n",
    "        X = X * self._idf_diag\n",
    "        X = normalize(X, axis=1, norm='l1', copy=False)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top _topk_ words per class\n",
    "ctfidf = CTFIDFVectorizer().fit_transform(count, n_samples=len(df_train)).toarray()\n",
    "\n",
    "topic_keywords = {topic_docs['Label'].iloc[label]: [words[index].replace(\"_\", \" \") for index in ctfidf[label].argsort()[-topk:]  if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "topic_keywords_val = {topic_docs['Label'].iloc[label]: [(words[index].replace(\"_\", \" \"), ctfidf[label][index]) for index in ctfidf[label].argsort()[-topk:] if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "\n",
    "#topic_keywords = {topic_docs['Label'].iloc[label]: [lemmatiser_stemmer_stopword(words[index].replace(\"_\", \" \"), nlp, stemmer) for index in ctfidf[label].argsort()[-topk:]  if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "#topic_keywords_val = {topic_docs['Label'].iloc[label]: [(lemmatiser_stemmer_stopword(words[index].replace(\"_\", \" \"), nlp, stemmer), ctfidf[label][index]) for index in ctfidf[label].argsort()[-topk:] if ctfidf[label][index]>0] for label in range(0,len(topic_docs['Label']))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Computational Social Science and Social Media': [('live heart',\n",
       "   0.002280860792029811),\n",
       "  ('listen trust', 0.002280860792029811),\n",
       "  ('share sentiment', 0.002280860792029811),\n",
       "  ('outperform state', 0.0022954695210204113),\n",
       "  ('base model', 0.0026331768529845832),\n",
       "  ('case study', 0.0028332814485927766),\n",
       "  ('current state', 0.003115313035753343),\n",
       "  ('unseen training', 0.0035974492185221023),\n",
       "  ('medium post', 0.004079585401290862),\n",
       "  ('social medium', 0.006230626071506686)],\n",
       " 'Dialogue and Interactive Systems': [('state tracking',\n",
       "   0.0028417408794451527),\n",
       "  ('human evaluation', 0.003230101398991199),\n",
       "  ('orient dialog', 0.0033989162407980764),\n",
       "  ('dialog system', 0.0033989162407980764),\n",
       "  ('domain dialogue', 0.0038013837229970773),\n",
       "  ('dialogue state', 0.003928432582299458),\n",
       "  ('orient dialogue', 0.003928432582299458),\n",
       "  ('response generation', 0.003928432582299458),\n",
       "  ('dialogue generation', 0.0041932961530030495),\n",
       "  ('dialogue system', 0.004306550494355493)],\n",
       " 'Discourse and Pragmatics': [('art system', 0.004531926746860623),\n",
       "  ('criterion train', 0.004531926746860623),\n",
       "  ('treat tree', 0.004531926746860623),\n",
       "  ('latent geometric', 0.004531926746860623),\n",
       "  ('experimental result', 0.0046730357751328016),\n",
       "  ('address issue', 0.005148169423324707),\n",
       "  ('relation recognition', 0.00810587926313503),\n",
       "  ('discourse relation', 0.00810587926313503),\n",
       "  ('assume gold', 0.00810587926313503),\n",
       "  ('sentence encoder', 0.00810587926313503)],\n",
       " 'Ethics and NLP': [('level give', 0.004403421044153317),\n",
       "  ('spouse hypernym', 0.004403421044153317),\n",
       "  ('slow expensive', 0.004403421044153317),\n",
       "  ('base posterior', 0.004403421044153317),\n",
       "  ('word embedding', 0.004852827600202315),\n",
       "  ('sentiment analysis', 0.005170268260343232),\n",
       "  ('resolution system', 0.007876031834226051),\n",
       "  ('bias mitigation', 0.007876031834226051),\n",
       "  ('social bias', 0.010417832370218203),\n",
       "  ('gender bias', 0.012801464972443196)],\n",
       " 'Generation': [('style transfer', 0.002453972110213823),\n",
       "  ('question generation', 0.002453972110213823),\n",
       "  ('generation model', 0.002564623680229133),\n",
       "  ('human evaluation', 0.0025912111667773085),\n",
       "  ('evaluation metric', 0.0026402090034982),\n",
       "  ('art performance', 0.002666155341011188),\n",
       "  ('generate question', 0.002707278365047805),\n",
       "  ('natural language', 0.0032580429683397917),\n",
       "  ('language generation', 0.0038118725759320824),\n",
       "  ('text generation', 0.008004234480172222)],\n",
       " 'Information Extraction': [('task learning', 0.002084795219743417),\n",
       "  ('experimental result', 0.0020985312991647453),\n",
       "  ('label datum', 0.002146952120632437),\n",
       "  ('information extraction', 0.0024074450458012923),\n",
       "  ('art method', 0.0024324030594327483),\n",
       "  ('entity linking', 0.002541356822751107),\n",
       "  ('flat ner', 0.002541356822751107),\n",
       "  ('extensive experiment', 0.002908548240228298),\n",
       "  ('relation extraction', 0.004622158743824688),\n",
       "  ('entity recognition', 0.008290161632258345)],\n",
       " 'Information Retrieval and Text Mining': [('european language',\n",
       "   0.0026876883396151747),\n",
       "  ('exist method', 0.0031557440400702937),\n",
       "  ('previous work', 0.004105574585669997),\n",
       "  ('neural topic', 0.00447490751779547),\n",
       "  ('significant progress', 0.00447490751779547),\n",
       "  ('keyphrase generation', 0.00447490751779547),\n",
       "  ('document retrieval', 0.004807243893107544),\n",
       "  ('topic distribution', 0.004807243893107544),\n",
       "  ('topic modeling', 0.004807243893107544),\n",
       "  ('text classification', 0.007889360100175734)],\n",
       " 'Interpretability and Analysis of Models for NLP': [('tuning downstream',\n",
       "   0.0027262351891226963),\n",
       "  ('multilingual bert', 0.0027262351891226963),\n",
       "  ('explanation model', 0.0027262351891226963),\n",
       "  ('downstream task', 0.0027325847696711494),\n",
       "  ('neural network', 0.0028185610007021734),\n",
       "  ('natural language', 0.002863165144664769),\n",
       "  ('attention mechanism', 0.002900732803146159),\n",
       "  ('language processing', 0.003181931601781763),\n",
       "  ('language model', 0.0035232012508777167),\n",
       "  ('attention weight', 0.0048080830211391645)],\n",
       " 'Language Grounding to Vision, Robotics and Beyond': [('unified framework',\n",
       "   0.002310058333490589),\n",
       "  ('achieve state', 0.0025458194268579183),\n",
       "  ('case study', 0.002869550585602108),\n",
       "  ('improve state', 0.0036435005483875112),\n",
       "  ('language learning', 0.0041318086076843445),\n",
       "  ('action sequence', 0.0041318086076843445),\n",
       "  ('source supervision', 0.0041318086076843445),\n",
       "  ('art method', 0.004141431860905475),\n",
       "  ('natural language', 0.004339335959402167),\n",
       "  ('question answering', 0.00544644092624253)],\n",
       " 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [('high variability',\n",
       "   0.004734082158597289),\n",
       "  ('question deep', 0.004734082158597289),\n",
       "  ('represent successful', 0.004734082158597289),\n",
       "  ('collocational preference', 0.004734082158597289),\n",
       "  ('find indication', 0.004734082158597289),\n",
       "  ('represent inflectional', 0.004734082158597289),\n",
       "  ('advent powerful', 0.004734082158597289),\n",
       "  ('testing methodology', 0.004734082158597289),\n",
       "  ('language model', 0.00656566050523372),\n",
       "  ('neural language', 0.007144595697975105)],\n",
       " 'Machine Learning for NLP': [('train model', 0.0017376256207727858),\n",
       "  ('processing task', 0.0018854396720349063),\n",
       "  ('language model', 0.0022105386722358214),\n",
       "  ('experimental result', 0.0024652613595600686),\n",
       "  ('language processing', 0.0024955226643651037),\n",
       "  ('language modeling', 0.002585669899669051),\n",
       "  ('knowledge graph', 0.0029115118346804618),\n",
       "  ('natural language', 0.00299402769744438),\n",
       "  ('text classification', 0.003275038406591723),\n",
       "  ('neural network', 0.003315808008353732)],\n",
       " 'Machine Translation and Multilinguality': [('monolingual corpora',\n",
       "   0.001923805974069588),\n",
       "  ('transfer learning', 0.0019437500952485304),\n",
       "  ('german english', 0.002030815800500987),\n",
       "  ('translation task', 0.002565074632092784),\n",
       "  ('nmt model', 0.003068004507005434),\n",
       "  ('translation quality', 0.0034312885545757666),\n",
       "  ('bleu score', 0.0035459681892990036),\n",
       "  ('language pair', 0.004221255995604734),\n",
       "  ('machine translation', 0.013774502303419337),\n",
       "  ('neural machine', 0.01387499862643446)],\n",
       " 'Phonology, Morphology and Word Segmentation': [('supervised contextual',\n",
       "   0.0029067526622988268),\n",
       "  ('task map', 0.0029067526622988268),\n",
       "  ('graph auto', 0.0029067526622988268),\n",
       "  ('error analysis', 0.004584626615514763),\n",
       "  ('correspond author', 0.004839641988682152),\n",
       "  ('paradigm completion', 0.005199065970056208),\n",
       "  ('morphological paradigm', 0.005199065970056208),\n",
       "  ('model morphological', 0.005199065970056208),\n",
       "  ('word segmentation', 0.006580231987025123),\n",
       "  ('chinese word', 0.006876939923272145)],\n",
       " 'Question Answering': [('address problem', 0.0018884923279779504),\n",
       "  ('art baseline', 0.001987515644578732),\n",
       "  ('extensive experiment', 0.002079623363863458),\n",
       "  ('question generation', 0.002196086844186385),\n",
       "  ('base question', 0.0024227734195862017),\n",
       "  ('clarification question', 0.002602704676995602),\n",
       "  ('comprehension benchmark', 0.002602704676995602),\n",
       "  ('machine reading', 0.007553969311911802),\n",
       "  ('question answering', 0.008920122979052102),\n",
       "  ('reading comprehension', 0.009765918778559587)],\n",
       " 'Resources and Evaluation': [('lingual word', 0.001954207224231181),\n",
       "  ('scale dataset', 0.002062908090479973),\n",
       "  ('create large', 0.002062908090479973),\n",
       "  ('alternative approach', 0.002062908090479973),\n",
       "  ('nlp research', 0.002062908090479973),\n",
       "  ('gold standard', 0.0022161133566593757),\n",
       "  ('million user', 0.0022161133566593757),\n",
       "  ('machine translation', 0.0022813330547075297),\n",
       "  ('natural language', 0.00232742154628817),\n",
       "  ('large publicly', 0.0030943621357199594)],\n",
       " 'Semantics: Lexical Semantics': [('previous state', 0.004414413127899185),\n",
       "  ('embedding space', 0.005009402602906738),\n",
       "  ('unlike prior', 0.00523528058275147),\n",
       "  ('specific word', 0.005526487946711784),\n",
       "  ('word sense', 0.005526487946711784),\n",
       "  ('sense disambiguation', 0.005526487946711784),\n",
       "  ('hypernymy detection', 0.0059369216741379256),\n",
       "  ('lowresource scenario', 0.0059369216741379256),\n",
       "  ('prior work', 0.005950749154074434),\n",
       "  ('word embedding', 0.007316084537722541)],\n",
       " 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [('semantic dependency',\n",
       "   0.0018151686356780055),\n",
       "  ('language model', 0.0018766405578772467),\n",
       "  ('art performance', 0.0019968188583012357),\n",
       "  ('role labeling', 0.0022973801038735486),\n",
       "  ('language understanding', 0.0024258617099647667),\n",
       "  ('experimental result', 0.0027905170875167744),\n",
       "  ('logical form', 0.003063173471831398),\n",
       "  ('language inference', 0.0034653144600361864),\n",
       "  ('natural language', 0.0041939450778917175),\n",
       "  ('semantic parsing', 0.004412235780055799)],\n",
       " 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [('sentiment classification',\n",
       "   0.0037148418814143287),\n",
       "  ('experimental result', 0.00409923315685693),\n",
       "  ('aspect extraction', 0.004255063320593649),\n",
       "  ('pair extraction', 0.004255063320593649),\n",
       "  ('term extraction', 0.004255063320593649),\n",
       "  ('graph attention', 0.0046541729683207),\n",
       "  ('extensive experiment', 0.00486986196600882),\n",
       "  ('base sentiment', 0.00514258494225005),\n",
       "  ('aspect term', 0.005374468220559794),\n",
       "  ('sentiment analysis', 0.008001887956007201)],\n",
       " 'Speech and Multimodality': [('net accept', 0.00298465584883148),\n",
       "  ('sentiment analysis', 0.0035044278638197606),\n",
       "  ('experimental result', 0.004103450721104609),\n",
       "  ('model achieve', 0.004198132394352541),\n",
       "  ('learning framework', 0.004504391479301235),\n",
       "  ('propose multi', 0.004504391479301235),\n",
       "  ('speech translation', 0.0047074981026706585),\n",
       "  ('recognition system', 0.005338404900166809),\n",
       "  ('multimodal sentiment', 0.005338404900166809),\n",
       "  ('speech recognition', 0.011260978698253089)],\n",
       " 'Summarization': [('discourse unit', 0.0031856587834838542),\n",
       "  ('collect human', 0.0031856587834838542),\n",
       "  ('source word', 0.0031856587834838542),\n",
       "  ('lingual summarization', 0.0031856587834838542),\n",
       "  ('summarization paper', 0.0031856587834838542),\n",
       "  ('write reference', 0.0031856587834838542),\n",
       "  ('summarization model', 0.0031856587834838542),\n",
       "  ('document summarization', 0.005618338421103189),\n",
       "  ('generate summary', 0.00671991659898139),\n",
       "  ('abstractive summarization', 0.007766810785421102)],\n",
       " 'Syntax: Tagging, Chunking and Parsing': [('linearization constituent',\n",
       "   0.003090785747097921),\n",
       "  ('apply abstract', 0.003090785747097921),\n",
       "  ('define word', 0.003090785747097921),\n",
       "  ('deep syntactic', 0.003090785747097921),\n",
       "  ('annotation scheme', 0.003090785747097921),\n",
       "  ('recent work', 0.004011220004079356),\n",
       "  ('dependency parsing', 0.004221548795218599),\n",
       "  ('sequence labeling', 0.004221548795218599),\n",
       "  ('empirically compare', 0.004874889694877679),\n",
       "  ('constituency parsing', 0.005146050668048775)],\n",
       " 'Theory and Formalism in NLP (Linguistic and Mathematical)': [('analysis tool',\n",
       "   0.008700559729752574),\n",
       "  ('largescale experiment', 0.008700559729752574),\n",
       "  ('formulation power', 0.008700559729752574),\n",
       "  ('flexible word', 0.008700559729752574),\n",
       "  ('formulation derive', 0.008700559729752574),\n",
       "  ('space complexity', 0.008700559729752574),\n",
       "  ('human word', 0.008700559729752574),\n",
       "  ('base empirical', 0.008700559729752574),\n",
       "  ('typical impulse', 0.008700559729752574),\n",
       "  ('tentatively conclude', 0.008700559729752574)]}"
      ]
     },
     "execution_count": 1554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_keywords_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on ACL2020/EMNLP2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_EMNLP_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_count(text): \n",
    "\n",
    "    keyword_count_dict = {}\n",
    "    keyword_list_dict = {}\n",
    "\n",
    "    for label in topic_keywords.keys():\n",
    "\n",
    "        count = 0\n",
    "        keywords = []\n",
    "\n",
    "        list_of_key_words = topic_keywords[label]\n",
    "\n",
    "        for keyword in list_of_key_words:\n",
    "\n",
    "            count += text.count(keyword)\n",
    "            if keyword in text: keywords.append(keyword)\n",
    "\n",
    "        keyword_count_dict[label] = count\n",
    "        keyword_list_dict[label] = keywords\n",
    "    \n",
    "    return keyword_list_dict, keyword_count_dict, max(keyword_count_dict, key=keyword_count_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count keywords from \"Text\" or \"Lemm Stemmed Text\" or \"Keyword\", according to which column to extract keyword\n",
    "df_pred = df_test.apply(lambda row: keyword_count(row['Lemm Stemmed Text']), axis='columns', result_type='expand')\n",
    "df_pred.columns = [\"Matched Keywords\", \"Dictionary Output\", \"Predicted Label\"]\n",
    "\n",
    "df_test = pd.concat([df_test, df_pred], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemm Stemmed Text</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Matched Keywords</th>\n",
       "      <th>Dictionary Output</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "      <td>Named Entity Recognition for Social Media Texts with Semantic Augmentation</td>\n",
       "      <td>Existing approaches for named entity recognition suffer from data sparsity problems when conducted on short and informal texts, especially user-generated social media content. Semantic augmentation is a potential way to alleviate this problem. Given that rich semantic information is implicitly preserved in pre-trained word embeddings, they are potential ideal resources for semantic augmentation. In this paper, we propose a neural-based approach to NER for social media texts where both local (from running text) and augmented semantics are taken into account. In particular, we obtain the augmented semantic information from a large-scale corpus, and propose an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively. Extensive experiments are performed on three benchmark datasets collected from English and Chinese social media platforms, where the results demonstrate the superiority of our approach to previous studies across all three datasets. 1 * Equal contribution.</td>\n",
       "      <td>Named Entity Recognition for Social Media Texts with Semantic Augmentation Existing approaches for named entity recognition suffer from data sparsity problems when conducted on short and informal texts, especially user-generated social media content. Semantic augmentation is a potential way to alleviate this problem. Given that rich semantic information is implicitly preserved in pre-trained word embeddings, they are potential ideal resources for semantic augmentation. In this paper, we propose a neural-based approach to NER for social media texts where both local (from running text) and augmented semantics are taken into account. In particular, we obtain the augmented semantic information from a large-scale corpus, and propose an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively. Extensive experiments are performed on three benchmark datasets collected from English and Chinese social media platforms, where the results demonstrate the superiority of our approach to previous studies across all three datasets. 1 * Equal contribution.</td>\n",
       "      <td>name entity recognition social medium text semantic augmentation exist approach name entity recognition suffer datum sparsity problem conduct short informal text , especially user - generate social medium content . semantic augmentation potential way alleviate problem . give rich semantic information implicitly preserve pre - trained word embedding , potential ideal resource semantic augmentation . paper , propose neural - base approach ner social medium text local ( run text ) augment semantic take account . particular , obtain augment semantic information large - scale corpus , propose attentive semantic augmentation module gate module encode aggregate information , respectively . extensive experiment perform benchmark dataset collect english chinese social medium platform , result demonstrate superiority approach previous study dataset . 1 * equal contribution .</td>\n",
       "      <td>social medium#semantic augmentation#entity recognition#medium text#augment semantic#semantic information#propose neural#scale corpus#equal contribution#medium platform#generate social#obtain augment#propose attentive#give rich#preserve pre#trained word#word embedding#extensive experiment#result demonstrate#information large</td>\n",
       "      <td>{'Computational Social Science and Social Media': ['social medium'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': ['word embedding'], 'Generation': [], 'Information Extraction': ['extensive experiment', 'entity recognition'], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': ['extensive experiment'], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': ['word embedding'], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': ['extensive experiment'], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "      <td>Suicidal Risk Detection for Military Personnel</td>\n",
       "      <td>We analyze social media for detecting the suicidal risk of military personnel, which is especially crucial for countries with compulsory military service such as the Republic of Korea. From a widely-used Korean social Q&amp;A site, we collect posts containing military-relevant content written by active-duty military personnel. We then annotate the posts with two groups of experts: military experts and mental health experts. Our dataset includes 2,791 posts with 13,955 corresponding expert annotations of suicidal risk levels, and this dataset is available to researchers who consent to research ethics agreement. Using various finetuned state-of-the-art language models, we predict the level of suicide risk, reaching .88 F1 score for classifying the risks.</td>\n",
       "      <td>Suicidal Risk Detection for Military Personnel We analyze social media for detecting the suicidal risk of military personnel, which is especially crucial for countries with compulsory military service such as the Republic of Korea. From a widely-used Korean social Q&amp;A site, we collect posts containing military-relevant content written by active-duty military personnel. We then annotate the posts with two groups of experts: military experts and mental health experts. Our dataset includes 2,791 posts with 13,955 corresponding expert annotations of suicidal risk levels, and this dataset is available to researchers who consent to research ethics agreement. Using various finetuned state-of-the-art language models, we predict the level of suicide risk, reaching .88 F1 score for classifying the risks.</td>\n",
       "      <td>suicidal risk detection military personnel analyze social medium detect suicidal risk military personnel , especially crucial country compulsory military service republic korea . widely - korean social q&amp;a site , collect post contain military - relevant content write active - duty military personnel . annotate post group expert : military expert mental health expert . dataset include 2,791 post 13,955 correspond expert annotation suicidal risk level , dataset available researcher consent research ethic agreement . finetune state - - - art language model , predict level suicide risk , reach .88 f1 score classify risk .</td>\n",
       "      <td>suicidal risk#military personnel#finetune state#dataset include#republic korea#relevant content#write active#ethic agreement#art language#language model#score classify#korean social#predict level#personnel analyze#detect suicidal#annotation suicidal#medium detect#crucial country#country compulsory#service republic</td>\n",
       "      <td>{'Computational Social Science and Social Media': ['social medium'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': ['language model'], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': ['language model'], 'Machine Learning for NLP': ['language model'], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': ['language model'], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "      <td>Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media</td>\n",
       "      <td>In this paper, we suggest a minimallysupervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control, and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.</td>\n",
       "      <td>Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media In this paper, we suggest a minimallysupervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control, and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.</td>\n",
       "      <td>weakly supervised learning nuanced frame analyze polarization news medium paper , suggest minimallysupervised approach identify nuanced frame news article coverage politically divisive topic . suggest break broad policy frame suggest boydstun et al . , 2014 fine - grained subframe capture difference political ideology well way . evaluate suggest subframe embedding , learn minimal supervision , topic , , immigration , gun - control , abortion . demonstrate ability subframe capture ideological difference analyze political discourse news medium .</td>\n",
       "      <td>nuanced frame#subframe capture#weakly supervised#learn minimal#minimal supervision#demonstrate ability#medium paper#divisive topic#grained subframe#subframe embedding#supervised learning#minimallysupervised approach#approach identify#article coverage#coverage politically#politically divisive#break broad#broad policy#learning nuanced#identify nuanced</td>\n",
       "      <td>{'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "      <td>Modeling Protagonist Emotions for Emotion-Aware Storytelling</td>\n",
       "      <td>Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (Emo-Sup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.</td>\n",
       "      <td>Modeling Protagonist Emotions for Emotion-Aware Storytelling Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (Emo-Sup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.</td>\n",
       "      <td>model protagonist emotion emotion - aware storytelling emotion evolution play central role create captivating story . paper , present study model emotional trajectory protagonist neural storytelling . design method generate story adhere give story title desire emotion arc protagonist . model include emotion supervision ( emo - sup ) emotion - reinforced ( emorl ) model . emorl model use special reward design regularize story generation process reinforcement learning . automatic manual evaluation demonstrate model significantly well generate story follow desire emotion arc compare baseline method , sacrifice story quality .</td>\n",
       "      <td>desire emotion#emotion arc#generate story#present study#reinforcement learning#automatic manual#aware storytelling#title desire#follow desire#arc compare#evolution play#play central#central role#role create#create captivating#emotional trajectory#adhere give#special reward#generation process#process reinforcement</td>\n",
       "      <td>{'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "      <td>Investigating African-American Vernacular English in Transformer-Based Text Generation</td>\n",
       "      <td>The growth of social media has encouraged the written use of African American Vernacular English (AAVE), which has traditionally been used only in oral contexts. However, NLP models have historically been developed using dominant English varieties, such as Standard American English (SAE), due to text corpora availability. We investigate the performance of GPT-2 on AAVE text by creating a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating syntactic structure and AAVE-or SAE-specific language for each pair. We evaluate each sample and its GPT-2 generated text with pretrained sentiment classifiers and find that while AAVE text results in more classifications of negative sentiment than SAE, the use of GPT-2 generally increases occurrences of positive sentiment for both. Additionally, we conduct human evaluation of AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall quality.</td>\n",
       "      <td>Investigating African-American Vernacular English in Transformer-Based Text Generation The growth of social media has encouraged the written use of African American Vernacular English (AAVE), which has traditionally been used only in oral contexts. However, NLP models have historically been developed using dominant English varieties, such as Standard American English (SAE), due to text corpora availability. We investigate the performance of GPT-2 on AAVE text by creating a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating syntactic structure and AAVE-or SAE-specific language for each pair. We evaluate each sample and its GPT-2 generated text with pretrained sentiment classifiers and find that while AAVE text results in more classifications of negative sentiment than SAE, the use of GPT-2 generally increases occurrences of positive sentiment for both. Additionally, we conduct human evaluation of AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall quality.</td>\n",
       "      <td>investigate african - american vernacular english transformer - base text generation growth social medium encourage write use african american vernacular english ( aave ) , traditionally oral context . , nlp model historically develop dominant english variety , standard american english ( sae ) , text corpora availability . investigate performance gpt-2 aave text create dataset intent - equivalent parallel aave / sae tweet pair , isolate syntactic structure aave - sae - specific language pair . evaluate sample gpt-2 generate text pretrained sentiment classifier find aave text result classification negative sentiment sae , use gpt-2 generally increase occurrence positive sentiment . additionally , conduct human evaluation aave sae text generate gpt-2 compare contextual rigor overall quality .</td>\n",
       "      <td>american vernacular#vernacular english#evaluate sample#investigate performance#traditionally oral#oral context#nlp model#corpora availability#dataset intent#equivalent parallel#isolate syntactic#specific language#generally increase#conduct human#compare contextual#tweet pair#language pair#standard american#investigate african#generation growth</td>\n",
       "      <td>{'Computational Social Science and Social Media': ['social medium'], 'Dialogue and Interactive Systems': ['human evaluation'], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': ['human evaluation', 'text generation'], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': ['language pair'], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "      <td>Uncertainty-Aware Label Refinement for Sequence Labeling</td>\n",
       "      <td>Conditional random fields (CRF) for label decoding has become ubiquitous in sequence labeling tasks. However, the local label dependencies and inefficient Viterbi decoding have always been a problem to be solved. In this work, we introduce a novel two-stage label decoding framework to model long-term label dependencies, while being much more computationally efficient. A base model first predicts draft labels, and then a novel twostream self-attention model makes refinements on these draft predictions based on longrange label dependencies, which can achieve parallel decoding for a faster prediction. In addition, in order to mitigate the side effects of incorrect draft labels, Bayesian neural networks are used to indicate the labels with a high probability of being wrong, which can greatly assist in preventing error propagation. The experimental results on three sequence labeling benchmarks demonstrated that the proposed method not only outperformed the CRF-based methods but also greatly accelerated the inference process.</td>\n",
       "      <td>Uncertainty-Aware Label Refinement for Sequence Labeling Conditional random fields (CRF) for label decoding has become ubiquitous in sequence labeling tasks. However, the local label dependencies and inefficient Viterbi decoding have always been a problem to be solved. In this work, we introduce a novel two-stage label decoding framework to model long-term label dependencies, while being much more computationally efficient. A base model first predicts draft labels, and then a novel twostream self-attention model makes refinements on these draft predictions based on longrange label dependencies, which can achieve parallel decoding for a faster prediction. In addition, in order to mitigate the side effects of incorrect draft labels, Bayesian neural networks are used to indicate the labels with a high probability of being wrong, which can greatly assist in preventing error propagation. The experimental results on three sequence labeling benchmarks demonstrated that the proposed method not only outperformed the CRF-based methods but also greatly accelerated the inference process.</td>\n",
       "      <td>uncertainty - aware label refinement sequence labeling conditional random field ( crf ) label decoding ubiquitous sequence labeling task . , local label dependency inefficient viterbi decoding problem solve . work , introduce novel - stage label decoding framework model long - term label dependency , computationally efficient . base model predict draft label , novel twostream self - attention model make refinement draft prediction base longrange label dependency , achieve parallel decoding fast prediction . addition , order mitigate effect incorrect draft label , bayesian neural network indicate label high probability wrong , greatly assist prevent error propagation . experimental result sequence labeling benchmark demonstrate propose method outperform crf - base method greatly accelerate inference process .</td>\n",
       "      <td>sequence labeling#label dependency#draft label#label decoding#computationally efficient#labeling task#outperform crf#random field#problem solve#achieve parallel#order mitigate#bayesian neural#probability wrong#error propagation#experimental result#inference process#labeling conditional#ubiquitous sequence#dependency inefficient#result sequence</td>\n",
       "      <td>{'Computational Social Science and Social Media': ['base model'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': ['experimental result'], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': ['experimental result'], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': ['neural network'], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': ['experimental result', 'neural network'], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': ['experimental result'], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': ['experimental result'], 'Speech and Multimodality': ['experimental result'], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['sequence labeling'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "      <td>AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network</td>\n",
       "      <td>The linear-chain Conditional Random Field (CRF) model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.</td>\n",
       "      <td>AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network The linear-chain Conditional Random Field (CRF) model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.</td>\n",
       "      <td>ain : fast accurate sequence labeling approximate inference network linear - chain conditional random field ( crf ) model widely - neural sequence labeling approach . exact probabilistic inference algorithm forward - backward viterbi algorithm typically apply training prediction stage crf model . , algorithm require sequential computation make parallelization impossible . paper , propose employ parallelizable approximate variational inference algorithm crf model . base algorithm , design approximate inference network connect encoder neural crf model form end - - end network , amenable parallelization fast training prediction . empirical result propose approach achieve 12.7 - fold improvement decode speed long sentence competitive accuracy compare traditional crf approach .</td>\n",
       "      <td>sequence labeling#training prediction#crf model#approximate inference#inference network#chain conditional#random field#exact probabilistic#backward viterbi#empirical result#fold improvement#model widely#inference algorithm#parallelization impossible#amenable parallelization#network linear#design approximate#conditional random#typically apply#require sequential</td>\n",
       "      <td>{'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['sequence labeling'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "      <td>Position-Aware Tagging for Aspect Sentiment Triplet Extraction</td>\n",
       "      <td>Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first end-to-end model with a novel positionaware tagging scheme that is capable of jointly extracting the triplets. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness 1 .</td>\n",
       "      <td>Position-Aware Tagging for Aspect Sentiment Triplet Extraction Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first end-to-end model with a novel positionaware tagging scheme that is capable of jointly extracting the triplets. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness 1 .</td>\n",
       "      <td>position - aware tagging aspect sentiment triplet extraction aspect sentiment triplet extraction ( aste ) task extract triplet target entity , associate sentiment , opinion span explain reason sentiment . exist research effort solve problem pipeline approach , break triplet extraction process stage . observation element triplet highly related , motivate build joint model extract triplet sequence tagging approach . , effectively design tagging approach extract triplet capture rich interaction element challenging research question . work , propose end - - end model novel positionaware tagging scheme capable jointly extract triplet . experimental result exist dataset jointly capture element triplet approach lead improve performance exist approach . conduct extensive experiment investigate model effectiveness robustness 1 .</td>\n",
       "      <td>extract triplet#triplet extraction#aspect sentiment#sentiment triplet#tagging approach#task extract#target entity#opinion span#process stage#highly related#motivate build#effectively design#experimental result#conduct extensive#effectiveness robustness#break triplet#extraction aspect#observation element#reason sentiment#research question</td>\n",
       "      <td>{'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': ['experimental result'], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': ['experimental result', 'extensive experiment'], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': ['experimental result'], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': ['extensive experiment'], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': ['experimental result'], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': ['experimental result', 'extensive experiment'], 'Speech and Multimodality': ['experimental result'], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Information Extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "      <td>Keep it Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in Sanskrit</td>\n",
       "      <td>Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020) , proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework's default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.</td>\n",
       "      <td>Keep it Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in Sanskrit Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020) , proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework's default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.</td>\n",
       "      <td>surprisingly simple : simple order graph base parsing model joint morphosyntactic parsing sanskrit morphologically rich language benefit joint processing morphology syntax , compare pipeline architecture . propose graph - base model joint morphological parsing dependency parsing sanskrit . , extend energy base model framework ( krishna et al . , 2020 ) , propose structured prediction task sanskrit , 2 simple significant way . , framework default input graph generation method modify generate multigraph , enable use exact search inference . second , prune input search space linguistically motivate approach , root traditional grammatical analysis sanskrit . experiment morphological parsing joint model outperform standalone morphological parser . report state art result morphological parsing , dependency parsing , standalone ( gold morphological tag ) joint morphosyntactic parsing setting .</td>\n",
       "      <td>joint morphosyntactic#morphosyntactic parsing#morphological parsing#dependency parsing#base model#model joint#parsing sanskrit#propose structured#morphology syntax#compare pipeline#pipeline architecture#extend energy#generate multigraph#motivate approach#root traditional#report state#search inference#prune input#parsing setting#rich language</td>\n",
       "      <td>{'Computational Social Science and Social Media': ['base model'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['dependency parsing'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "      <td>Please Mind the Root: Decoding Arborescences for Dependency Parsing</td>\n",
       "      <td>The connection between dependency trees and spanning trees is exploited by the NLP community to train and to decode graph-based dependency parsers. However, the NLP literature has missed an important difference between the two structures: only one edge may emanate from the root in a dependency tree. We analyzed the output of state-of-the-art parsers on many languages from the Universal Dependency Treebank: although these parsers are often able to learn that trees which violate the constraint should be assigned lower probabilities, their ability to do so unsurprisingly degrades as the size of the training set decreases. In fact, the worst constraint-violation rate we observe is 24%. Prior work has proposed an inefficient algorithm to enforce the constraint, which adds a factor of n to the decoding runtime. We adapt an algorithm due to Gabow and Tarjan (1984) to dependency parsing, which satisfies the constraint without compromising the original runtime. 1</td>\n",
       "      <td>Please Mind the Root: Decoding Arborescences for Dependency Parsing The connection between dependency trees and spanning trees is exploited by the NLP community to train and to decode graph-based dependency parsers. However, the NLP literature has missed an important difference between the two structures: only one edge may emanate from the root in a dependency tree. We analyzed the output of state-of-the-art parsers on many languages from the Universal Dependency Treebank: although these parsers are often able to learn that trees which violate the constraint should be assigned lower probabilities, their ability to do so unsurprisingly degrades as the size of the training set decreases. In fact, the worst constraint-violation rate we observe is 24%. Prior work has proposed an inefficient algorithm to enforce the constraint, which adds a factor of n to the decoding runtime. We adapt an algorithm due to Gabow and Tarjan (1984) to dependency parsing, which satisfies the constraint without compromising the original runtime. 1</td>\n",
       "      <td>mind root : decode arborescence dependency parsing connection dependency tree span tree exploit nlp community train decode graph - base dependency parser . , nlp literature miss important difference structure : edge emanate root dependency tree . analyze output state - - - art parser language universal dependency treebank : parser able learn tree violate constraint assign low probability , ability unsurprisingly degrade size training set decrease . fact , bad constraint - violation rate observe 24 % . prior work propose inefficient algorithm enforce constraint , add factor n decoding runtime . adapt algorithm gabow tarjan ( 1984 ) dependency parsing , satisfy constraint compromise original runtime . 1</td>\n",
       "      <td>dependency parsing#decoding runtime#original runtime#difference structure#edge emanate#analyze output#output state#low probability#ability unsurprisingly#set decrease#violation rate#rate observe#prior work#add factor#gabow tarjan#mind root#decode graph#adapt algorithm#parsing connection#dependency tree</td>\n",
       "      <td>{'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': ['prior work'], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['dependency parsing'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}</td>\n",
       "      <td>{'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}</td>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Label  \\\n",
       "0    Computational Social Science and Social Media   \n",
       "1    Computational Social Science and Social Media   \n",
       "2    Computational Social Science and Social Media   \n",
       "3    Computational Social Science and Social Media   \n",
       "4    Computational Social Science and Social Media   \n",
       "..                                             ...   \n",
       "708          Syntax: Tagging, Chunking and Parsing   \n",
       "709          Syntax: Tagging, Chunking and Parsing   \n",
       "710          Syntax: Tagging, Chunking and Parsing   \n",
       "711          Syntax: Tagging, Chunking and Parsing   \n",
       "712          Syntax: Tagging, Chunking and Parsing   \n",
       "\n",
       "                                                                                                                         Title  \\\n",
       "0                                                   Named Entity Recognition for Social Media Texts with Semantic Augmentation   \n",
       "1                                                                               Suicidal Risk Detection for Military Personnel   \n",
       "2                                        Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media   \n",
       "3                                                                 Modeling Protagonist Emotions for Emotion-Aware Storytelling   \n",
       "4                                       Investigating African-American Vernacular English in Transformer-Based Text Generation   \n",
       "..                                                                                                                         ...   \n",
       "708                                                                   Uncertainty-Aware Label Refinement for Sequence Labeling   \n",
       "709                                                AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network   \n",
       "710                                                             Position-Aware Tagging for Aspect Sentiment Triplet Extraction   \n",
       "711  Keep it Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in Sanskrit   \n",
       "712                                                        Please Mind the Root: Decoding Arborescences for Dependency Parsing   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Abstract  \\\n",
       "0                                                                                                     Existing approaches for named entity recognition suffer from data sparsity problems when conducted on short and informal texts, especially user-generated social media content. Semantic augmentation is a potential way to alleviate this problem. Given that rich semantic information is implicitly preserved in pre-trained word embeddings, they are potential ideal resources for semantic augmentation. In this paper, we propose a neural-based approach to NER for social media texts where both local (from running text) and augmented semantics are taken into account. In particular, we obtain the augmented semantic information from a large-scale corpus, and propose an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively. Extensive experiments are performed on three benchmark datasets collected from English and Chinese social media platforms, where the results demonstrate the superiority of our approach to previous studies across all three datasets. 1 * Equal contribution.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                         We analyze social media for detecting the suicidal risk of military personnel, which is especially crucial for countries with compulsory military service such as the Republic of Korea. From a widely-used Korean social Q&A site, we collect posts containing military-relevant content written by active-duty military personnel. We then annotate the posts with two groups of experts: military experts and mental health experts. Our dataset includes 2,791 posts with 13,955 corresponding expert annotations of suicidal risk levels, and this dataset is available to researchers who consent to research ethics agreement. Using various finetuned state-of-the-art language models, we predict the level of suicide risk, reaching .88 F1 score for classifying the risks.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  In this paper, we suggest a minimallysupervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control, and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                               Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (Emo-Sup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.   \n",
       "4                                                                                                                                                                                                       The growth of social media has encouraged the written use of African American Vernacular English (AAVE), which has traditionally been used only in oral contexts. However, NLP models have historically been developed using dominant English varieties, such as Standard American English (SAE), due to text corpora availability. We investigate the performance of GPT-2 on AAVE text by creating a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating syntactic structure and AAVE-or SAE-specific language for each pair. We evaluate each sample and its GPT-2 generated text with pretrained sentiment classifiers and find that while AAVE text results in more classifications of negative sentiment than SAE, the use of GPT-2 generally increases occurrences of positive sentiment for both. Additionally, we conduct human evaluation of AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall quality.   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ...   \n",
       "708                                                                                                  Conditional random fields (CRF) for label decoding has become ubiquitous in sequence labeling tasks. However, the local label dependencies and inefficient Viterbi decoding have always been a problem to be solved. In this work, we introduce a novel two-stage label decoding framework to model long-term label dependencies, while being much more computationally efficient. A base model first predicts draft labels, and then a novel twostream self-attention model makes refinements on these draft predictions based on longrange label dependencies, which can achieve parallel decoding for a faster prediction. In addition, in order to mitigate the side effects of incorrect draft labels, Bayesian neural networks are used to indicate the labels with a high probability of being wrong, which can greatly assist in preventing error propagation. The experimental results on three sequence labeling benchmarks demonstrated that the proposed method not only outperformed the CRF-based methods but also greatly accelerated the inference process.   \n",
       "709                                                                                                                                                                                                         The linear-chain Conditional Random Field (CRF) model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.   \n",
       "710  Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first end-to-end model with a novel positionaware tagging scheme that is capable of jointly extracting the triplets. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness 1 .   \n",
       "711                                                                                                                                         Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020) , proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework's default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.   \n",
       "712                                                                                                                                                                     The connection between dependency trees and spanning trees is exploited by the NLP community to train and to decode graph-based dependency parsers. However, the NLP literature has missed an important difference between the two structures: only one edge may emanate from the root in a dependency tree. We analyzed the output of state-of-the-art parsers on many languages from the Universal Dependency Treebank: although these parsers are often able to learn that trees which violate the constraint should be assigned lower probabilities, their ability to do so unsurprisingly degrades as the size of the training set decreases. In fact, the worst constraint-violation rate we observe is 24%. Prior work has proposed an inefficient algorithm to enforce the constraint, which adds a factor of n to the decoding runtime. We adapt an algorithm due to Gabow and Tarjan (1984) to dependency parsing, which satisfies the constraint without compromising the original runtime. 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Text  \\\n",
       "0                                                                                         Named Entity Recognition for Social Media Texts with Semantic Augmentation Existing approaches for named entity recognition suffer from data sparsity problems when conducted on short and informal texts, especially user-generated social media content. Semantic augmentation is a potential way to alleviate this problem. Given that rich semantic information is implicitly preserved in pre-trained word embeddings, they are potential ideal resources for semantic augmentation. In this paper, we propose a neural-based approach to NER for social media texts where both local (from running text) and augmented semantics are taken into account. In particular, we obtain the augmented semantic information from a large-scale corpus, and propose an attentive semantic augmentation module and a gate module to encode and aggregate such information, respectively. Extensive experiments are performed on three benchmark datasets collected from English and Chinese social media platforms, where the results demonstrate the superiority of our approach to previous studies across all three datasets. 1 * Equal contribution.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                         Suicidal Risk Detection for Military Personnel We analyze social media for detecting the suicidal risk of military personnel, which is especially crucial for countries with compulsory military service such as the Republic of Korea. From a widely-used Korean social Q&A site, we collect posts containing military-relevant content written by active-duty military personnel. We then annotate the posts with two groups of experts: military experts and mental health experts. Our dataset includes 2,791 posts with 13,955 corresponding expert annotations of suicidal risk levels, and this dataset is available to researchers who consent to research ethics agreement. Using various finetuned state-of-the-art language models, we predict the level of suicide risk, reaching .88 F1 score for classifying the risks.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in News Media In this paper, we suggest a minimallysupervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in political ideology in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, immigration, gun-control, and abortion. We demonstrate the ability of the subframes to capture ideological differences and analyze political discourse in news media.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                 Modeling Protagonist Emotions for Emotion-Aware Storytelling Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our models include Emotion Supervision (Emo-Sup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through reinforcement learning. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.   \n",
       "4                                                                                                                                                                               Investigating African-American Vernacular English in Transformer-Based Text Generation The growth of social media has encouraged the written use of African American Vernacular English (AAVE), which has traditionally been used only in oral contexts. However, NLP models have historically been developed using dominant English varieties, such as Standard American English (SAE), due to text corpora availability. We investigate the performance of GPT-2 on AAVE text by creating a dataset of intent-equivalent parallel AAVE/SAE tweet pairs, thereby isolating syntactic structure and AAVE-or SAE-specific language for each pair. We evaluate each sample and its GPT-2 generated text with pretrained sentiment classifiers and find that while AAVE text results in more classifications of negative sentiment than SAE, the use of GPT-2 generally increases occurrences of positive sentiment for both. Additionally, we conduct human evaluation of AAVE and SAE text generated with GPT-2 to compare contextual rigor and overall quality.   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "708                                                                                                        Uncertainty-Aware Label Refinement for Sequence Labeling Conditional random fields (CRF) for label decoding has become ubiquitous in sequence labeling tasks. However, the local label dependencies and inefficient Viterbi decoding have always been a problem to be solved. In this work, we introduce a novel two-stage label decoding framework to model long-term label dependencies, while being much more computationally efficient. A base model first predicts draft labels, and then a novel twostream self-attention model makes refinements on these draft predictions based on longrange label dependencies, which can achieve parallel decoding for a faster prediction. In addition, in order to mitigate the side effects of incorrect draft labels, Bayesian neural networks are used to indicate the labels with a high probability of being wrong, which can greatly assist in preventing error propagation. The experimental results on three sequence labeling benchmarks demonstrated that the proposed method not only outperformed the CRF-based methods but also greatly accelerated the inference process.   \n",
       "709                                                                                                                                                                                            AIN: Fast and Accurate Sequence Labeling with Approximate Inference Network The linear-chain Conditional Random Field (CRF) model is one of the most widely-used neural sequence labeling approaches. Exact probabilistic inference algorithms such as the forward-backward and Viterbi algorithms are typically applied in training and prediction stages of the CRF model. However, these algorithms require sequential computation that makes parallelization impossible. In this paper, we propose to employ a parallelizable approximate variational inference algorithm for the CRF model. Based on this algorithm, we design an approximate inference network that can be connected with the encoder of the neural CRF model to form an end-to-end network, which is amenable to parallelization for faster training and prediction. The empirical results show that our proposed approaches achieve a 12.7-fold improvement in decoding speed with long sentences and a competitive accuracy compared with the traditional CRF approach.   \n",
       "710  Position-Aware Tagging for Aspect Sentiment Triplet Extraction Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first end-to-end model with a novel positionaware tagging scheme that is capable of jointly extracting the triplets. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness 1 .   \n",
       "711                                                                              Keep it Surprisingly Simple: A Simple First Order Graph Based Parsing Model for Joint Morphosyntactic Parsing in Sanskrit Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020) , proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework's default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.   \n",
       "712                                                                                                                                                                Please Mind the Root: Decoding Arborescences for Dependency Parsing The connection between dependency trees and spanning trees is exploited by the NLP community to train and to decode graph-based dependency parsers. However, the NLP literature has missed an important difference between the two structures: only one edge may emanate from the root in a dependency tree. We analyzed the output of state-of-the-art parsers on many languages from the Universal Dependency Treebank: although these parsers are often able to learn that trees which violate the constraint should be assigned lower probabilities, their ability to do so unsurprisingly degrades as the size of the training set decreases. In fact, the worst constraint-violation rate we observe is 24%. Prior work has proposed an inefficient algorithm to enforce the constraint, which adds a factor of n to the decoding runtime. We adapt an algorithm due to Gabow and Tarjan (1984) to dependency parsing, which satisfies the constraint without compromising the original runtime. 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Lemm Stemmed Text  \\\n",
       "0                          name entity recognition social medium text semantic augmentation exist approach name entity recognition suffer datum sparsity problem conduct short informal text , especially user - generate social medium content . semantic augmentation potential way alleviate problem . give rich semantic information implicitly preserve pre - trained word embedding , potential ideal resource semantic augmentation . paper , propose neural - base approach ner social medium text local ( run text ) augment semantic take account . particular , obtain augment semantic information large - scale corpus , propose attentive semantic augmentation module gate module encode aggregate information , respectively . extensive experiment perform benchmark dataset collect english chinese social medium platform , result demonstrate superiority approach previous study dataset . 1 * equal contribution .   \n",
       "1                                                                                                                                                                                                                                                                                      suicidal risk detection military personnel analyze social medium detect suicidal risk military personnel , especially crucial country compulsory military service republic korea . widely - korean social q&a site , collect post contain military - relevant content write active - duty military personnel . annotate post group expert : military expert mental health expert . dataset include 2,791 post 13,955 correspond expert annotation suicidal risk level , dataset available researcher consent research ethic agreement . finetune state - - - art language model , predict level suicide risk , reach .88 f1 score classify risk .   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                  weakly supervised learning nuanced frame analyze polarization news medium paper , suggest minimallysupervised approach identify nuanced frame news article coverage politically divisive topic . suggest break broad policy frame suggest boydstun et al . , 2014 fine - grained subframe capture difference political ideology well way . evaluate suggest subframe embedding , learn minimal supervision , topic , , immigration , gun - control , abortion . demonstrate ability subframe capture ideological difference analyze political discourse news medium .   \n",
       "3                                                                                                                                                                                                                                                                                 model protagonist emotion emotion - aware storytelling emotion evolution play central role create captivating story . paper , present study model emotional trajectory protagonist neural storytelling . design method generate story adhere give story title desire emotion arc protagonist . model include emotion supervision ( emo - sup ) emotion - reinforced ( emorl ) model . emorl model use special reward design regularize story generation process reinforcement learning . automatic manual evaluation demonstrate model significantly well generate story follow desire emotion arc compare baseline method , sacrifice story quality .   \n",
       "4                                                                                                     investigate african - american vernacular english transformer - base text generation growth social medium encourage write use african american vernacular english ( aave ) , traditionally oral context . , nlp model historically develop dominant english variety , standard american english ( sae ) , text corpora availability . investigate performance gpt-2 aave text create dataset intent - equivalent parallel aave / sae tweet pair , isolate syntactic structure aave - sae - specific language pair . evaluate sample gpt-2 generate text pretrained sentiment classifier find aave text result classification negative sentiment sae , use gpt-2 generally increase occurrence positive sentiment . additionally , conduct human evaluation aave sae text generate gpt-2 compare contextual rigor overall quality .   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "708                                                                                  uncertainty - aware label refinement sequence labeling conditional random field ( crf ) label decoding ubiquitous sequence labeling task . , local label dependency inefficient viterbi decoding problem solve . work , introduce novel - stage label decoding framework model long - term label dependency , computationally efficient . base model predict draft label , novel twostream self - attention model make refinement draft prediction base longrange label dependency , achieve parallel decoding fast prediction . addition , order mitigate effect incorrect draft label , bayesian neural network indicate label high probability wrong , greatly assist prevent error propagation . experimental result sequence labeling benchmark demonstrate propose method outperform crf - base method greatly accelerate inference process .   \n",
       "709                                                                                                                      ain : fast accurate sequence labeling approximate inference network linear - chain conditional random field ( crf ) model widely - neural sequence labeling approach . exact probabilistic inference algorithm forward - backward viterbi algorithm typically apply training prediction stage crf model . , algorithm require sequential computation make parallelization impossible . paper , propose employ parallelizable approximate variational inference algorithm crf model . base algorithm , design approximate inference network connect encoder neural crf model form end - - end network , amenable parallelization fast training prediction . empirical result propose approach achieve 12.7 - fold improvement decode speed long sentence competitive accuracy compare traditional crf approach .   \n",
       "710                                                                      position - aware tagging aspect sentiment triplet extraction aspect sentiment triplet extraction ( aste ) task extract triplet target entity , associate sentiment , opinion span explain reason sentiment . exist research effort solve problem pipeline approach , break triplet extraction process stage . observation element triplet highly related , motivate build joint model extract triplet sequence tagging approach . , effectively design tagging approach extract triplet capture rich interaction element challenging research question . work , propose end - - end model novel positionaware tagging scheme capable jointly extract triplet . experimental result exist dataset jointly capture element triplet approach lead improve performance exist approach . conduct extensive experiment investigate model effectiveness robustness 1 .   \n",
       "711  surprisingly simple : simple order graph base parsing model joint morphosyntactic parsing sanskrit morphologically rich language benefit joint processing morphology syntax , compare pipeline architecture . propose graph - base model joint morphological parsing dependency parsing sanskrit . , extend energy base model framework ( krishna et al . , 2020 ) , propose structured prediction task sanskrit , 2 simple significant way . , framework default input graph generation method modify generate multigraph , enable use exact search inference . second , prune input search space linguistically motivate approach , root traditional grammatical analysis sanskrit . experiment morphological parsing joint model outperform standalone morphological parser . report state art result morphological parsing , dependency parsing , standalone ( gold morphological tag ) joint morphosyntactic parsing setting .   \n",
       "712                                                                                                                                                                                               mind root : decode arborescence dependency parsing connection dependency tree span tree exploit nlp community train decode graph - base dependency parser . , nlp literature miss important difference structure : edge emanate root dependency tree . analyze output state - - - art parser language universal dependency treebank : parser able learn tree violate constraint assign low probability , ability unsurprisingly degrade size training set decrease . fact , bad constraint - violation rate observe 24 % . prior work propose inefficient algorithm enforce constraint , add factor n decoding runtime . adapt algorithm gabow tarjan ( 1984 ) dependency parsing , satisfy constraint compromise original runtime . 1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                        Keyword  \\\n",
       "0                                         social medium#semantic augmentation#entity recognition#medium text#augment semantic#semantic information#propose neural#scale corpus#equal contribution#medium platform#generate social#obtain augment#propose attentive#give rich#preserve pre#trained word#word embedding#extensive experiment#result demonstrate#information large   \n",
       "1                                                   suicidal risk#military personnel#finetune state#dataset include#republic korea#relevant content#write active#ethic agreement#art language#language model#score classify#korean social#predict level#personnel analyze#detect suicidal#annotation suicidal#medium detect#crucial country#country compulsory#service republic   \n",
       "2               nuanced frame#subframe capture#weakly supervised#learn minimal#minimal supervision#demonstrate ability#medium paper#divisive topic#grained subframe#subframe embedding#supervised learning#minimallysupervised approach#approach identify#article coverage#coverage politically#politically divisive#break broad#broad policy#learning nuanced#identify nuanced   \n",
       "3                                                    desire emotion#emotion arc#generate story#present study#reinforcement learning#automatic manual#aware storytelling#title desire#follow desire#arc compare#evolution play#play central#central role#role create#create captivating#emotional trajectory#adhere give#special reward#generation process#process reinforcement   \n",
       "4                     american vernacular#vernacular english#evaluate sample#investigate performance#traditionally oral#oral context#nlp model#corpora availability#dataset intent#equivalent parallel#isolate syntactic#specific language#generally increase#conduct human#compare contextual#tweet pair#language pair#standard american#investigate african#generation growth   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                          ...   \n",
       "708                   sequence labeling#label dependency#draft label#label decoding#computationally efficient#labeling task#outperform crf#random field#problem solve#achieve parallel#order mitigate#bayesian neural#probability wrong#error propagation#experimental result#inference process#labeling conditional#ubiquitous sequence#dependency inefficient#result sequence   \n",
       "709  sequence labeling#training prediction#crf model#approximate inference#inference network#chain conditional#random field#exact probabilistic#backward viterbi#empirical result#fold improvement#model widely#inference algorithm#parallelization impossible#amenable parallelization#network linear#design approximate#conditional random#typically apply#require sequential   \n",
       "710                         extract triplet#triplet extraction#aspect sentiment#sentiment triplet#tagging approach#task extract#target entity#opinion span#process stage#highly related#motivate build#effectively design#experimental result#conduct extensive#effectiveness robustness#break triplet#extraction aspect#observation element#reason sentiment#research question   \n",
       "711                     joint morphosyntactic#morphosyntactic parsing#morphological parsing#dependency parsing#base model#model joint#parsing sanskrit#propose structured#morphology syntax#compare pipeline#pipeline architecture#extend energy#generate multigraph#motivate approach#root traditional#report state#search inference#prune input#parsing setting#rich language   \n",
       "712                                                             dependency parsing#decoding runtime#original runtime#difference structure#edge emanate#analyze output#output state#low probability#ability unsurprisingly#set decrease#violation rate#rate observe#prior work#add factor#gabow tarjan#mind root#decode graph#adapt algorithm#parsing connection#dependency tree   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Matched Keywords  \\\n",
       "0                                                                 {'Computational Social Science and Social Media': ['social medium'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': ['word embedding'], 'Generation': [], 'Information Extraction': ['extensive experiment', 'entity recognition'], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': ['extensive experiment'], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': ['word embedding'], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': ['extensive experiment'], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "1                                                                                                                         {'Computational Social Science and Social Media': ['social medium'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': ['language model'], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': ['language model'], 'Machine Learning for NLP': ['language model'], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': ['language model'], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "2                                                                                                                                                                                                        {'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "3                                                                                                                                                                                                        {'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "4                                                                                                                   {'Computational Social Science and Social Media': ['social medium'], 'Dialogue and Interactive Systems': ['human evaluation'], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': ['human evaluation', 'text generation'], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': ['language pair'], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ...   \n",
       "708       {'Computational Social Science and Social Media': ['base model'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': ['experimental result'], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': ['experimental result'], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': ['neural network'], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': ['experimental result', 'neural network'], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': ['experimental result'], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': ['experimental result'], 'Speech and Multimodality': ['experimental result'], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['sequence labeling'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "709                                                                                                                                                                                   {'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['sequence labeling'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "710  {'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': ['experimental result'], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': ['experimental result', 'extensive experiment'], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': ['experimental result'], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': ['extensive experiment'], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': ['experimental result'], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': ['experimental result', 'extensive experiment'], 'Speech and Multimodality': ['experimental result'], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': [], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "711                                                                                                                                                                      {'Computational Social Science and Social Media': ['base model'], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': [], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['dependency parsing'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "712                                                                                                                                                                      {'Computational Social Science and Social Media': [], 'Dialogue and Interactive Systems': [], 'Discourse and Pragmatics': [], 'Ethics and NLP': [], 'Generation': [], 'Information Extraction': [], 'Information Retrieval and Text Mining': [], 'Interpretability and Analysis of Models for NLP': [], 'Language Grounding to Vision, Robotics and Beyond': [], 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': [], 'Machine Learning for NLP': [], 'Machine Translation and Multilinguality': [], 'Phonology, Morphology and Word Segmentation': [], 'Question Answering': [], 'Resources and Evaluation': [], 'Semantics: Lexical Semantics': ['prior work'], 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': [], 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': [], 'Speech and Multimodality': [], 'Summarization': [], 'Syntax: Tagging, Chunking and Parsing': ['dependency parsing'], 'Theory and Formalism in NLP (Linguistic and Mathematical)': []}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Dictionary Output  \\\n",
       "0    {'Computational Social Science and Social Media': 4, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 1, 'Generation': 0, 'Information Extraction': 3, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "1    {'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 1, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "2    {'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "3    {'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "4    {'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 1, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 2, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 1, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "708  {'Computational Social Science and Social Media': 1, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 1, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 1, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 2, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 1, 'Speech and Multimodality': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 3, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "709  {'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "710  {'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 1, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 2, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 1, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 1, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 1, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 2, 'Speech and Multimodality': 1, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 0, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "711  {'Computational Social Science and Social Media': 2, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 0, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "712  {'Computational Social Science and Social Media': 0, 'Dialogue and Interactive Systems': 0, 'Discourse and Pragmatics': 0, 'Ethics and NLP': 0, 'Generation': 0, 'Information Extraction': 0, 'Information Retrieval and Text Mining': 0, 'Interpretability and Analysis of Models for NLP': 0, 'Language Grounding to Vision, Robotics and Beyond': 0, 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': 0, 'Machine Learning for NLP': 0, 'Machine Translation and Multilinguality': 0, 'Phonology, Morphology and Word Segmentation': 0, 'Question Answering': 0, 'Resources and Evaluation': 0, 'Semantics: Lexical Semantics': 1, 'Semantics: Sentence-level Semantics, Textual Inference and Other areas': 0, 'Sentiment Analysis, Stylistic Analysis, and Argument Mining': 0, 'Speech and Multimodality': 0, 'Summarization': 0, 'Syntax: Tagging, Chunking and Parsing': 2, 'Theory and Formalism in NLP (Linguistic and Mathematical)': 0}   \n",
       "\n",
       "                                   Predicted Label  \n",
       "0    Computational Social Science and Social Media  \n",
       "1    Computational Social Science and Social Media  \n",
       "2    Computational Social Science and Social Media  \n",
       "3    Computational Social Science and Social Media  \n",
       "4                                       Generation  \n",
       "..                                             ...  \n",
       "708          Syntax: Tagging, Chunking and Parsing  \n",
       "709          Syntax: Tagging, Chunking and Parsing  \n",
       "710                         Information Extraction  \n",
       "711  Computational Social Science and Social Media  \n",
       "712          Syntax: Tagging, Chunking and Parsing  \n",
       "\n",
       "[651 rows x 9 columns]"
      ]
     },
     "execution_count": 1558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Label Outcome=True<br>Label=%{x}<br>Counts=%{y}<extra></extra>",
         "legendgroup": "True",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "True",
         "offsetgroup": "True",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Computational Social Science and Social Media",
          "Dialogue and Interactive Systems",
          "Discourse and Pragmatics",
          "Generation",
          "Information Extraction",
          "Information Retrieval and Text Mining",
          "Interpretability and Analysis of Models for NLP",
          "Language Grounding to Vision, Robotics and Beyond",
          "Linguistic Theories, Cognitive Modeling and Psycholinguistics",
          "Machine Learning for NLP",
          "Machine Translation and Multilinguality",
          "Phonology, Morphology and Word Segmentation",
          "Question Answering",
          "Semantics: Lexical Semantics",
          "Semantics: Sentence-level Semantics, Textual Inference and Other areas",
          "Sentiment Analysis, Stylistic Analysis, and Argument Mining",
          "Summarization",
          "Syntax: Tagging, Chunking and Parsing"
         ],
         "xaxis": "x",
         "y": [
          17,
          32,
          3,
          22,
          24,
          4,
          15,
          6,
          3,
          19,
          42,
          2,
          12,
          6,
          15,
          10,
          11,
          7
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Label Outcome=False<br>Label=%{x}<br>Counts=%{y}<extra></extra>",
         "legendgroup": "False",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "False",
         "offsetgroup": "False",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Computational Social Science and Social Media",
          "Dialogue and Interactive Systems",
          "Discourse and Pragmatics",
          "Generation",
          "Information Extraction",
          "Information Retrieval and Text Mining",
          "Interpretability and Analysis of Models for NLP",
          "Language Grounding to Vision, Robotics and Beyond",
          "Linguistic Theories, Cognitive Modeling and Psycholinguistics",
          "Machine Learning for NLP",
          "Machine Translation and Multilinguality",
          "Phonology, Morphology and Word Segmentation",
          "Question Answering",
          "Semantics: Lexical Semantics",
          "Semantics: Sentence-level Semantics, Textual Inference and Other areas",
          "Sentiment Analysis, Stylistic Analysis, and Argument Mining",
          "Speech and Multimodality",
          "Summarization",
          "Syntax: Tagging, Chunking and Parsing"
         ],
         "xaxis": "x",
         "y": [
          11,
          26,
          8,
          20,
          30,
          18,
          37,
          23,
          6,
          51,
          27,
          10,
          28,
          10,
          39,
          18,
          9,
          20,
          10
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 800,
        "legend": {
         "title": {
          "text": "Label Outcome"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Predictions for ACL Dataset"
        },
        "width": 900,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Label"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Counts"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"f428bae3-56f5-4fb8-9284-b4edc31c87e6\" class=\"plotly-graph-div\" style=\"height:800px; width:900px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f428bae3-56f5-4fb8-9284-b4edc31c87e6\")) {                    Plotly.newPlot(                        \"f428bae3-56f5-4fb8-9284-b4edc31c87e6\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Label Outcome=True<br>Label=%{x}<br>Counts=%{y}<extra></extra>\",\"legendgroup\":\"True\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"True\",\"offsetgroup\":\"True\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Computational Social Science and Social Media\",\"Dialogue and Interactive Systems\",\"Discourse and Pragmatics\",\"Generation\",\"Information Extraction\",\"Information Retrieval and Text Mining\",\"Interpretability and Analysis of Models for NLP\",\"Language Grounding to Vision, Robotics and Beyond\",\"Linguistic Theories, Cognitive Modeling and Psycholinguistics\",\"Machine Learning for NLP\",\"Machine Translation and Multilinguality\",\"Phonology, Morphology and Word Segmentation\",\"Question Answering\",\"Semantics: Lexical Semantics\",\"Semantics: Sentence-level Semantics, Textual Inference and Other areas\",\"Sentiment Analysis, Stylistic Analysis, and Argument Mining\",\"Summarization\",\"Syntax: Tagging, Chunking and Parsing\"],\"xaxis\":\"x\",\"y\":[17,32,3,22,24,4,15,6,3,19,42,2,12,6,15,10,11,7],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Label Outcome=False<br>Label=%{x}<br>Counts=%{y}<extra></extra>\",\"legendgroup\":\"False\",\"marker\":{\"color\":\"#EF553B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"False\",\"offsetgroup\":\"False\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"x\":[\"Computational Social Science and Social Media\",\"Dialogue and Interactive Systems\",\"Discourse and Pragmatics\",\"Generation\",\"Information Extraction\",\"Information Retrieval and Text Mining\",\"Interpretability and Analysis of Models for NLP\",\"Language Grounding to Vision, Robotics and Beyond\",\"Linguistic Theories, Cognitive Modeling and Psycholinguistics\",\"Machine Learning for NLP\",\"Machine Translation and Multilinguality\",\"Phonology, Morphology and Word Segmentation\",\"Question Answering\",\"Semantics: Lexical Semantics\",\"Semantics: Sentence-level Semantics, Textual Inference and Other areas\",\"Sentiment Analysis, Stylistic Analysis, and Argument Mining\",\"Speech and Multimodality\",\"Summarization\",\"Syntax: Tagging, Chunking and Parsing\"],\"xaxis\":\"x\",\"y\":[11,26,8,20,30,18,37,23,6,51,27,10,28,10,39,18,9,20,10],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Counts\"}},\"legend\":{\"title\":{\"text\":\"Label Outcome\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Predictions for ACL Dataset\"},\"barmode\":\"relative\",\"height\":800,\"width\":900},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f428bae3-56f5-4fb8-9284-b4edc31c87e6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[\"Label Outcome\"] = df_test.apply(lambda x: x[\"Label\"] == x[\"Predicted Label\"], axis = 1)\n",
    "df_test_outcome = df_test[['Label', 'Label Outcome']].groupby(['Label', 'Label Outcome']).size().reset_index(name='Counts')\n",
    "df_test_outcome = df_test_outcome.sort_values(by = ['Label','Label Outcome'], ascending = [True, False])\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(df_test_outcome, x=\"Label\", y=\"Counts\", color=\"Label Outcome\", title=\"Predictions for ACL Dataset\",\n",
    "             width=900, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/wAAAQrCAYAAAAxPafiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd5xU1d3H8c+XBQQEQZFiFMUaCyoq2LCgkdgVxW5QjBG7QYPGiiXRx5InJvbeG/bHFk1iVBALItLsDQ2KYEOlw/J7/rh3cVi2ws4ddub7fr32tTN37j2/c849M7vnnnPPKCIwMzMzMzMzs+LSpNAZMDMzMzMzM7OG5w6/mZmZmZmZWRFyh9/MzMzMzMysCLnDb2ZmZmZmZlaE3OE3MzMzMzMzK0Lu8JuZmZmZmZkVIXf4zczMzIqQpJaSnpT0g6SHliKdwyX9syHzVgiS/iHpyELnw8wsS+7wm5mZmRWQpMMkjZI0XdLktGO6XQMkfQDQCWgfEQcuaSIRcW9E/LoB8rMISb0lhaRHK23fNN3+Yh3TuUDSPbXtFxG7R8SdS5hdM7NGyR1+MzMzswKRdBrwN+ASks756sB1wL4NkPwawAcRMb8B0sqXr4FtJbXP2XYk8EFDBVDC//OaWUnyh5+ZmZlZAUhqC1wEnBgRj0bEjIiYFxFPRsTp6T7LSfqbpC/Tn79JWi59rbekSZL+IGlqOjvgqPS1C4EhwMHpzIGjK4+ES+qajqQ3TZ8PkPSJpJ8kfSrp8JztL+cct62kN9JbBd6QtG3Oay9K+pOkEWk6/5S0cg3VMBd4HDgkPb4MOAi4t1Jd/V3SfyX9KOlNSdun23cDzs4p59icfFwsaQQwE1gr3fa79PXrJT2ck/5lkp6XpLqePzOzxsAdfjMzM7PC2AZoATxWwz7nAFsD3YFNgS2Bc3Ne7wy0BVYFjgaulbRiRJxPMmtgaES0johba8qIpOWBq4DdI6INsC0wpor9VgKeTvdtD/wVeLrSCP1hwFFAR6A5MLim2MBdwBHp412Bt4EvK+3zBkkdrATcBzwkqUVEPFupnJvmHNMfGAi0AT6rlN4fgE3Sixnbk9TdkRERteTVzKxRcYffzMzMrDDaA9/UMuX+cOCiiJgaEV8DF5J0ZCvMS1+fFxHPANOBXy5hfhYA3SS1jIjJEfF2FfvsCXwYEXdHxPyIuB94D9g7Z5/bI+KDiJgFPEjSUa9WRLwCrCTplyQd/7uq2OeeiPg2jfm/wHLUXs47IuLt9Jh5ldKbCfyG5ILFPcDJETGplvTMzBodd/jNzMzMCuNbYOWKKfXV+AWLjk5/lm5bmEalCwYzgdb1zUhEzAAOBo4DJkt6WtL6dchPRZ5WzXn+1RLk527gJGAnqpjxkN628G56G8E0klkNNd0qAPDfml6MiJHAJ4BILkyYmRUdd/jNzMzMCuNVYDbQt4Z9viRZfK/C6iw+3b2uZgCtcp53zn0xIp6LiD7AKiSj9jfXIT8VefpiCfNU4W7gBOCZdPR9oXTK/R9J7u1fMSLaAT+QdNQBqpuGX+P0fEknkswU+BI4Y4lzbma2DHOH38zMzKwAIuIHkoX1rpXUV1IrSc0k7S7p8nS3+4FzJXVIF78bQjIFfUmMAXaQtHq6YOBZFS9I6iRpn/Re/jkktwaUV5HGM8B66VcJNpV0MLAh8NQS5gmAiPgU2JFkzYLK2gDzSVb0byppCLBCzutTgK71WYlf0nrAn0mm9fcHzpDUfclyb2a27HKH38zMzKxAIuKvwGkkC/F9TTIN/SSSlesh6ZSOAsYB44HR6bYlifUvYGia1pss2klvQrKQ3ZfAdySd7xOqSONbYK90329JRsb3iohvliRPldJ+OSKqmr3wHPAPkq/q+4xkVkTudP2H0t/fShpdW5z0Fop7gMsiYmxEfEiy0v/dFd+AYGZWLOTFSM3MzMzMzMyKj0f4zczMzMzMzIqQO/xmZmZmZmZmRcgdfjMzMzMzM7Mi5A6/mZmZmZmZWRFyh9/MzMzMzMysCDUtdAbMzGzZdPWITzP9Gpdjtlozy3CZm1e+INN4zcqK/5r+t9PnZhqvfevmmcbLus2UglJ4X5jVR9afM22Wa6JMA1aj5WYnFfSr6ma9dU1m9eBPPTMzMzMzM7Mi5A6/mZmZmZmZWRHylH4zMzMzMzMrHSqdce/SKamZmZmZmZlZCfEIv5mZmZmZmZUOLRNrB2bCI/xmZmZmZmZmRcgdfjMzMzMzM7Mi5Cn9ZmZmZmZmVjq8aJ+ZmZmZmZmZNWYe4TczMzMzM7PS4UX7zMzMzMzMzKwxc4ff8kJSZ0kPSPpY0juSnpG0XoHycvaS7CfplTzk5Q5JB1SxfWtJr0saI+ldSRcsYfrPSGpXyz4TJa1cxfbfShovaZykCZL2rSGNX0h6eEnyWGiSplez/RxJb6flHyNpqyVIu4ekq2rZp7ekp6rZHpKOztm2WbptcD3zMT39nffz9Pxtf+XW3x/Mfecdu3Dbs9dfwgPnn8AD55/AnacfwQPnn5CX2COGD2OfPXdlr936cOvNN+UlRiFjXjjkHPrs2IuD9ts7r3FyZV2nhTiH5eXlDOx/IGefdmIm8Yq5zRSijWYds9g/Zxyv8cfLOmYh3ve2dNzhtwYnScBjwIsRsXZEbAicDXQqUJbq1OGvvF9EbJuHvFTnTmBgRHQHugEPLkkiEbFHREyr73GSVgPOAbaLiE2ArYFxNcT5MiIWu3DRWEnaBtgL2Dwt/y7Af+ubTkSMiohTliIr44GDc54fAoxd0sSyOE/r9+rD3qf9eZFtux1/NodceB2HXHgda2+xHWtt0avB45aXl3PJxRdx3Q238NgTT/PsM0/x8UcfNXicQsbce5++XH19Nv8sQvblK8Q5BHh06D2s3nXNvMeB4m8zWcfLOmYpfM44XuOOV4iYhXjf54WaFPYnQ+7wWz7sBMyLiBsqNkTEmIgYrsQV6QjyeEkHw8LRzZckPSjpA0mXSjpc0sh0v7XT/e6QdIOk4el+e6XbB0i6piKepKfSNC8FWqYjtvemrz0u6c10NHdguq2q/SpGSWvK84uSHpb0nqR704sdSBoi6Y30mJsqttegIzA5ravyiHgnTWelNL/jJL0maZN0e2tJt+eMyPdLty8cva+qnLXE/wmYnuZhekR8mqazjqR/SxorabSktSV1lTQhfb0srZ830rwcW4f66SnplTTNkZLaVJdOZdWVS9J0SRenab4mqVO6fU1Jr6bp/qma8q8CfBMRc9LyfxMRX6bH/0rSW2ld3yZpuRrKsHD0XtKW6etvpb9/Wcs5APgcaCGpU1pXuwH/yCnj2pKeTcs/XNL6NZWx0nnqmh4zOv1pkAtaq/5yY1os36bK1yKCj94Yxnpb9W6IUIuYMH4cXbqswWpdutCseXN222NPXnzh+QaPU8iYm/foyQpt2+Ut/cqyLl8hzuHXU77itRHD2WPffnmNU6HY20zW8bKOWQqfM47XuOMVImYh3ve2dNzht3zoBrxZzWv7A92BTUlGUa+QtEr62qbA74GNgf7AehGxJXALcHJOGl2BHYE9gRsktaguIxFxJjArIrpHxOHp5t9GxBZAD+AUSe2r2a8ued4MGARsCKwFVAxlXhMRPSOiG9CSZPS4JlcC70t6TNKxOWW6EHgrHXU+G7gr3X4e8ENEbJy+9p8q0lysnDXEHwtMAT5NLyTkztO6F7g2IjYFtiW9MJHj6DQvPYGewDGSKobPFqsfSc2BocDv0zR3AWbVkk5dyrU88Fqa5jDgmHT734Hr03S/qqb8/wS6KLmIdJ2kHQHS83AHcHBEbEyy0OnxNZQh13vADhGxGTAEuKSa2JU9DBxIUtejgTk5r90EnJyWfzBwXT3KOBXoExGbk8wiqPHWg4bw5QcTaLnCirTrtGqDpz11yhQ6r9J54fOOnToxZcqUBo9T6JhZyrp8hajPa6+8nGNPOpUmGY2uFHubKXal8DnjeI07XqFiFgWpsD8ZcoffsrYdcH86ij0FeImkcwfwRkRMTkdZPybphEEyzblrThoPRsSCiPgQ+ARYv555OEXSWOA1oAuw7lLkeWRETIqIBcCYnHzupOSe/PHAzsBGNQWIiItIOrD/BA4Dns2JfXe6z3+A9pLaknQwr805/vulKWdElJOMJh8AfABcKekCSW2AVSPisXS/2RExs9LhvwaOkDQGeB1onxOrqvr5JTA5It5I0/wxIubXkk5dyjUXqLg3/k1+Phe9gPvTx3dXU/7pwBbAQOBrYKikAWleP42ID9Jd7wR2qKEMudoCD6Uj7FdSSxvI8SBJh//QnHwjqTXJRYCH0jq6kWRmQp3KCDQDbk7b5EMkF2Hy6sPXX8zL6D5AEIttU57/gBYiZpayLl/W8V59+SXarbQS621Q17fi0iv2NlPsSuFzxvEad7xCxbTGxR1+y4e3STpPVanpEyh3JHNBzvMFLPoVkpU/2QKYz6LtucpRf0m9STrL26Qjs29Vt+8S5LkcaJqOCl8HHJCOCt9chxhExMcRcT3wK2DTdOS6qtiRbl/8E74iw0tQzkiMjIj/Ibl3vF818RcLRzLq3D39WTMiKi7WLFY/NeS9pnTqUq55EVGRbkWshcWrrRDpBZ0XI+J84CRqLn+N9Z/6E/BCOstjb+rQBtJ8fAXMA/oAuXPymgDTcuqne0RskHtoLUmfSjKLY1OSi0vNq9pJ0kBJoySNGvF/91e1S50sKC/n49EjWHfLHZY4jZp06tSZryb/PJlh6pQpdOzYMS+xChkzS1mXL+t4E8a+xSvDXuDQvrvyp3NP561RI7nk/DPzFg+Kv80Uu1L4nHG8xh2vUDGtcXGH3/LhP8BykiqmVFfc77wjyVTrg9P7tTuQjJaOrGf6B0pqouS+/rWA94GJQPd0exdgy5z950lqlj5uC3wfETPT+5+3rma/XPXNc0XH7pt0VLbWRdMk7amfL8euS9JhnZbGPjzdpzfJfeY/kswEOCnn+BUrJVlTOauK/wtJm+ds6g58lsaaJKlvut9yklpVOvw5kmnuzdJ91pO0fA3h3gN+Ialnun8bSU3rmE69ypUaQXIBA9K6rEzSLyXlziboDnyW5rWrpHXS7f1JZnhUV4bKef0ifTygDvnMNQT4YzrzAkhmEZDccnFgGlOSNq1rGdP8TE5nW/QHyqraKSJuiogeEdGj176H1jPbP/vvO2+xYucutF6pwxKnUZONum3M559PZNKk/zJv7lyefeZpdtxp57zEKmTMLGVdvqzjHXPiIB586nnuf/w5zvvzFWzWY0vOvvDSvMWD4m8zxa4UPmccr3HHK1TMolBCi/ZV/gfVbKlFREjaD/ibpDOB2SQd8kEkHdhtSO4ZD+CMiPiqYvGxOnqfpNPVCTguImZLGgF8SjL9fwLJvc8VbgLGSRoN/BY4TtK4NJ3Xqtqv0n38j9UnzxExTdLNaV4mAm/UoUz9SabRzySZrXB4RJQr+Xq+29P8zgSOTPf/M3BtOl28nORe/0dz0nu2hnJWpRnwF0m/IDlfXwPH5eTtRkkXkYw8H0gy66LCLSTT50enFy2+BvpWFygi5ipZ+PBqSS1J7n3fpY7p1LdckKwLcZ+k3wOPVLNP6zQ/7Ujq/yOSb02YLekokmn0TUnO5Q01lCHX5cCdkk6j6jUWqhUR1X0l5OHA9ZLOJTlnD5C0y7qU8TrgkfSCwQvAjPrkqTrP3fA/fPH+OGZP/5Hb//Abttr3N2y4w258ODJ/0/kBmjZtylnnDOH4gb9jwYJy+u7Xj3XWqe3unMYV8+wz/sCbo0Yybdo09tilNwNPOIm+++fvSxeyLl8hzmHWir3NZB0v65il8DnjeI07XiFiFuJ9b0tHP8+ANVv2SboDeCoiGuV3wJs1JleP+DTTPxDHbJXNV6UVyrzyBbXv1ICalRX/JL5vp8/NNF771lXeCZM3WbeZUlAK7wuz+sj6c6bNck2WiQUGWm5zZkE7wbNevTSzevCnnpmZmZmZmVkR8pR+a1QiYkCh82BmZmZmZtYYuMNvZmZmZmZmpSPjhfMKqXRKamZmZmZmZlZCPMJvZmZmZmZmpUPLxNqBmfAIv5mZmZmZmVkRcoffzMzMzMzMbBkjqUzSW5KeSp+vJOlfkj5Mf69YWxru8JuZmZmZmVnpUJPC/tTd74F3c56fCTwfEesCz6fPa+QOv5mZmZmZmdkyRNJqwJ7ALTmb9wXuTB/fCfStLR13+M3MzMzMzMyWLX8DzgAW5GzrFBGTAdLfHWtLxB1+MzMzMzMzKx1SQX8kDZQ0Kudn4KLZ017A1Ih4c2mL6q/lMzMzMzMzM8tIRNwE3FTDLr2AfSTtAbQAVpB0DzBF0ioRMVnSKsDU2mJ5hN/MzMzMzMxKxzK+aF9EnBURq0VEV+AQ4D8R8RvgCeDIdLcjgf+rLS2P8JuZWZV2X7dzpvF+edqTmcZ7/697ZxqvFMyaW55pvFbNyzKNZ43fvPIFte/UgJqVZTu2lvV7cNJ3szKNB7Bu59aZxyxmWbdRW2qXAg9KOhr4HDiwtgPc4TczMzMzMzNbBkXEi8CL6eNvgV/V53h3+M3MzMzMzKx01GFafbEonZKamZmZmZmZlRCP8JuZmZmZmVnpaKJC5yAzHuE3MzMzMzMzK0Lu8JuZmZmZmZkVIU/pNzMzMzMzs9LhRfvMzMzMzMzMrDHzCL+ZmZmZmZmVDnnRPjMzMzMzMzNrxNzhNzMzMzMzMytCntJvZmZmZmZmpcOL9plZQ5FULmmMpLcljZV0mpR8ykjqIemqWo7vLempbHLbsCQNkHRNXbdX2qerpMPyl7uFcXpL2jbn+XGSjmiAdH8p6cX03L8r6aYlSCOTOmgo03/6kUvOHcyxh/fl2N/sx7sTxjZo+ss1bcL//WE7/vHHHfjXWb05dff1ADh73w14/pydePaPO3Lj0T1YoWX+rmWPGD6Mffbclb1268OtN9f7lNbLhUPOoc+OvThov73zGidXluWb8tVkTjhmAAfvvxeH9tuboffdndd4hYpZzG2mEG20FMpY7O/DJx++l0G/PZBTjz6IK/98NnPnzslrvCzrsxDxChGzEGW0JecOv1n+zYqI7hGxEdAH2AM4HyAiRkXEKQXN3bKrK1Cvzq6ksiWI0xtY2OGPiBsi4q4lSKeyq4Ar03O/AXD1EqTRlXrWQSHddNXlbLHVttx47+Ncc/uDdFljzQZNf878BRx69avsftkwdr/sJXbcoCObdW3H8Pe/4df/8yK7XfYSn349gxP6rNugcSuUl5dzycUXcd0Nt/DYE0/z7DNP8fFHH+UlFsDe+/Tl6uuz+0cq6/KVlTXllNPOYOijT3HLXQ/w8ND7+PTj/MUrRMxibzNZxytETL8PG9a3X0/lH489wGXX382Vtz7IggXljPjPc3mLl3V9Zh2vEDELUca8kAr7kyF3+M0yFBFTgYHASUosHL2XtKWkVyS9lf7+ZeXjJa0k6XFJ4yS9JmmTdHsHSf+SNFrSjZI+k7RyOkI8Ief4wZIuSB+vLelZSW9KGi5p/SriVZmndIT+0fT4DyVdnnPMUZI+kPQS0Ku2OpF0h6Sr0vQ/kXRA+tKlwPbpCPmpksokXSHpjbT8x6bH95b0gqT7gPHptsfTcr0taWBOrN3SOhor6XlJXYHjgFPTONtLuiCtpw0kjcw5tqukcenjLSS9lMZ4TtIqVRRtFWBSxZOIqMjbcEndc9IdIWkTSTumeRiT1nebetbBS5IeTOv+UkmHSxopabyktdP9DpQ0IS3/sNrOTX3MnDGdCWNH8+u99gOgWbNmtG6zQkOGSOLMLQegaVkTmpU1IQKGv/c15QsCgLcmfs8q7Vo0eFyACePH0aXLGqzWpQvNmjdntz325MUXns9LLIDNe/Rkhbbt8pZ+ZVmXb+UOHVh/gw0BWH755em65lpM/Xpq3uIVImaxt5ms4xUipt+HDa+8vJy5c+ZQXj6fObNns+LKHfIWK+v6zDpeIWIWooy2dHwPv1nGIuITJVP6O1Z66T1gh4iYL2kX4BKgX6V9LgTeioi+knYG7gK6k8wY+E9E/I+k3UguKtTmJuC4iPhQ0lbAdcDO9chTd2AzYA7wvqSrgflpHrcAfgBeAN6qQ15WAbYD1geeAB4GzgQGR8ReAGnH/YeI6ClpOWCEpH+mx28JdIuIT9Pnv42I7yS1BN6Q9AjJBc6b0/J8KmmldJ8bgOkR8Zc0zq8AIuJdSc0lrRURnwAHAw9KakYyWr9vRHwt6WDgYuC3lcp0JfAfSa8A/wRuj4hpwC3AAGCQpPWA5SJinKQngRMjYoSk1sDsetbBpsAGwHfAJ8AtEbGlpN8DJwODgCHArhHxhaR2dTgvdTb5y0m0bbciV14yhE8//oB11tuQY39/Bi1atmzIMDQRPHX6DnTtsDx3DZ/ImM+mLfL6QVt34anRXzZozApTp0yh8yqdFz7v2KkT48eNy0usQihk+b788gs+eP9dunXbJJN4WcUs9jZjDa/Y34ftO3RknwN/w/GH7knz5ZZjkx5b073HNnmLl3V9FuL8lUIZbel4hN+sMKqay9MWeCgdkb8S2KiKfbYD7gaIiP8A7SW1Tbc/kG5/Fvi+xuBJh3LbNN4Y4EaSTnd98vR8RPwQEbOBd4A1gK2AFyPi64iYCwytKR85Ho+IBRHxDtCpmn1+DRyR5vd1oD1QMXd7ZE5nH+AUSWOB14Au6X5bA8Mq9ouI7+qQrweBg9LHB6fl+SXQDfhXmpdzgdUqHxgRt5N0wB8iuW3gtbST/hCwV3rh4LfAHekhI4C/SjoFaBcR8+tZB29ExOSImAN8THKRAZJZD11zYtwh6RigytsfJA2UNErSqAfuurXaiqlsQXk5H33wHnv0PYirbxtKi5YteOje2+p8fJ3jBOxx+TC2HvIvuq/RjvVWabPwtZN+vS7zy4PHRn3R4HEBglhsm4roe3wLVb6ZM2dw1uDfM2jwWSzfunXe42UZs9jbjDW8Yn8fTv/pR9545SWuvfdJbnrwWebMmsWwfz2Tt3hZ12chzl8plDEv1KSwPxlyh98sY5LWAsqBynPm/gS8EBHdgL2BquYlV/WJGtVsh2TEPfd9XpFmE2Baen95xc8GVRxfU55yV9kp5+cZQ4v/JahdblrVlUXAyTn5XTMiKjq1MxbuJPUGdgG2iYhNSWYYtEiPr2/ehgIHpSPxEREfpum8nZOPjSPi11UdHBFfRsRtEbEvybnoFhEzgX8B+5JcTLgv3fdS4HdAS5KLA4vdYlFLHeTW4YKc5wtIz01EHEdygaILMEZS+yryfFNE9IiIHocccXQdqwnad+jEyh06sv5GGwPQq3cfPnr/3TofX18/zprPqx9+S+8Nkqmg/bZcjV9t1JHf31WXCSVLplOnznw1+auFz6dOmULHjpUn6jRehSjf/HnzOGvwIHbdfS92+lWfvMYqRMxibzPW8Ir9fThu9Ot07LwqbdutSNOmzdhq+515/52GXeA1V9b1WYjzVwpltKXjDr9ZhiR1AG4AromIyp3PtkDF0OSAapIYBhyeptUb+CYifgReJh2JlvRrYMV0/ylAR0nt09HlvQDSYz6VdGB6jCRtWkW8uuQp1+tA7zReM+DAOhxTnZ+ANjnPnwOOT9NF0nqSlq/iuLbA9xExM+00b51ufxXYUdKa6fErVRNnoYj4mORixnn8PFvhfaCDpG3SdJpJWmw2hpL1Airy2plkNL6iLm8hWdTvjYqZBpLWjojxEXEZMIrk9oYlrYMqpTFej4ghwDckHf8GsVL7lenQsTOTPp8IwNg3X2f1rms1VPJJjNbNF67Av1yzJmz3y5X5aMp0dtygA8fvsg5H3/wGs+eVN2jMXBt125jPP5/IpEn/Zd7cuTz7zNPsuFPlu2Aar6zLFxFcfOF5dF1zLQ7rPyBvcQoZs9jbjDW8Yn8frtyxMx+8O545s2cREYwfPZJVV2/YBV5zZV2fhXjPl0IZ86KEFu3zPfxm+dcynYLdjGSU927gr1Xsdzlwp6TTgP9Uk9YFwO1KFo+bCRyZbr8QuD+9n/wlYDLwU0TMk3QRSUf8U5J78iscDlwv6dw0bw8AlS+z1yVPC0XEZCWLAr6a5mE01Uwdr4NxwPx0av4dwN9JpqaPVjJ37GugbxXHPQscl9bR+yTT+knvtx8IPJquoTCV5FsTngQelrQvyb3ulQ0FrgDWTNOZq2RhwavS2ymaAn8D3q503K+Bv0uanT4/PSK+StN4U9KPwO05+w+StBPJBYZ3gH+QjM4vSR1U5wpJ65LMFHiexc/3Ujl20B+54qKzmT9vHp1/sSqDzr6oIZOn4wrL8dffbEYTKbmXf8yX/Oftqbx03s40b9qEe05Iru28NfF7znlwfIPGBmjatClnnTOE4wf+jgULyum7Xz/WWSc/3wgAcPYZf+DNUSOZNm0ae+zSm4EnnETf/Q+o/cAllHX5xo4ZzT+efoK1112P/gcniz0ef9Igtt1+x6KJWextJut4hYjp92HDWm+Djdlmh19x+nGHU1bWlDXX+SV99tw/L7Eg+/rMOl4hYhaijLZ0tPggo5k1NunofXm6uN42wPUR0b3A2bJqSPoF8CKwfkQsKHB2qvXR1FmZ/oH41Z//nWU43v9rdt+rDTCvPNtT3aws+0l8s+bmb4bFsqBl8yW9frlksm4z1vCyfh9m/R6c9N2sTOMBrNs5m7U+LD9aNK321s1Mtdz1LwXtBM96bnBm9eARfrPisDrJCvJNgLnAMQXOj1VD0hEkq/qftix39s3MzMyKVsYL5xWSO/xmRSBdTG6zQufDahcRd5F8naKZmZmZWV6VzqUNMzMzMzMzsxLiEX4zMzMzMzMrHRmvlF9IHuE3MzMzMzMzK0Ie4TczMzMzM7PSUUKL9pVOSc3MzMzMzMxKiDv8ZmZmZmZmZkXIU/rNzMzMzMysdHjRPjMzMzMzMzNrzDzCb2ZmZmZmZqXDi/aZmZmZmZmZWWPmDr+ZmZmZmZlZEfKUfjMzq1LL5mWZxnv/r3tnGu/HWfMyjbdCy2aZxiuEpmXZLoI0vzwyjZe1ZmUel7H6yfpze93OrTONZ9ZgPKXfzMzMzMzMzBozj/CbmZmZmZlZ6fDX8pmZmZmZmZlZY+YOv5mZmZmZmVkR8pR+MzMzMzMzKx1etM/MzMzMzMzMGjOP8JuZmZmZmVnp8KJ9ZmZmZmZmZtaYucNvZmZmZmZmVoQ8pd/MzMzMzMxKhxftMzMzMzMzM7PGzB1+sxImqVzSGElvSxor6TQpueQpqYekqwqdxyxJukPSAdVs/zStq9GStilE/iqT1FvStjnPj5N0RCHzVF5ezsD+B3L2aSfmPdaI4cPYZ89d2Wu3Ptx68015jzdnzhwGHnEIAw7dn/4H7cutN16T95hZlzHreBcOOYc+O/bioP32znssgClfTeaEYwZw8P57cWi/vRl63915j1ns59DxGn9Mx2vc8QoRsxBltCXnDr9ZaZsVEd0jYiOgD7AHcD5ARIyKiFOyzIykZfk2o9MjojtwJnBj5RcllWWeI+gNLOzwR8QNEXFXAfKx0KND72H1rmvmPU55eTmXXHwR191wC4898TTPPvMUH3/0UV5jNm/enL/dcBt33P8ot9/3MK+/MoK3x4/NW7ysy1iIOt17n75cfX12/yyWlTXllNPOYOijT3HLXQ/w8ND7+PTj4qlTx2vc8QoR0/Ead7xCxCxEGfNCKuxPhtzhNzMAImIqMBA4SYnekp4CkLRjOro9RtJbktqk28+QND6dHXBpuq27pNckjZP0mKQV0+0vSuqRPl5Z0sT08QBJD0l6EvinpFUkDUtjTZC0fbrfryW9mo6wPySpdeUySDpG0htpfh6R1CrdfoekqyS9IumTilH8tJzXSHpH0tNAxzpU1TBgnfT4iZKGSHoZOLCG+GundfKGpIskTU+395b0kqQHJX0g6VJJh0samdbr2ul+e0t6Pa37f0vqJKkrcBxwalpX20u6QNLg9Jh10n3HpnW2dnV121C+nvIVr40Yzh779mvIZKs0Yfw4unRZg9W6dKFZ8+bstseevPjC83mNKYlWrVoBMH/+fObPn5/XP9pZl7EQdbp5j56s0LZdXmPkWrlDB9bfYEMAll9+ebquuRZTv56at3jFfg4dr/HHdLzGHa8QMQtRRls67vCb2UIR8QnJ50Llju9g4MR0hHt7YJak3YG+wFYRsSlwebrvXcAfI2ITYDzpjIFabAMcGRE7A4cBz6WxNgXGSFoZOBfYJSI2B0YBp1WRzqMR0TPNz7vA0TmvrQJsB+wFXJpu2w/4JbAxcAw5o+U12DstV4XZEbFdRDxQQ/y/A3+PiJ7Al5XS2xT4fZqH/sB6EbElcAtwcrrPy8DWEbEZ8ABwRkRMBG4ArkxnaQyvlO69wLVpXrYFJlNF3dahvHV27ZWXc+xJp9Ikg4Vwpk6ZQudVOi983rFTJ6ZMmZL3uOXl5Rx1WD/26bMDPbfaho26bZK3WFmXsVB1WihffvkFH7z/Lt18Dh1vGYlXiJiO17jjFSJmsfytkFTQnyy5w29mlVX1KTQC+KukU4B2ETEf2AW4PSJmAkTEd5Lapq+/lB53J7BDHWL+KyK+Sx+/ARwl6QJg44j4Cdga2BAYIWkMcCSwRhXpdJM0XNJ44HBgo5zXHo+IBRHxDtAp3bYDcH9ElEfEl8B/asjjFWnsgSx6IWFoHeJvAzyUPr6vUrpvRMTkiJgDfAz8M90+HuiaPl4NeC5N9/RK5VqMkhkYq0bEYwARMTs9T1XVbYN49eWXaLfSSqy3QY1ZazBBLLYtiz+gZWVl3H7fIzzyzPO8+/Z4Pvnow7zFyrqMharTQpg5cwZnDf49gwafxfKtF5ss1GCK/Rw6XuOP6XiNO14hYpbS34pi4Q6/mS0kaS2gHFhkjmtEXAr8DmgJvCZpfZILA4t/6ldvPj9/5rSo9NqMnFjDSDriXwB3K1mETiQXBbqnPxtGxNEs7g7gpIjYGLiwUpw5uUXNLV4d8396GrtPREyoKu+1xK9Obr4W5DxfwM9fnXo1cE2a7rF1SLfKv7zV1O2iB0oDJY2SNOqeO26pQ/YTE8a+xSvDXuDQvrvyp3NP561RI7nk/DPrfHx9derUma8mf7Xw+dQpU+jYsS53ZDSMNm1WYLMtevL6qy/nLUbWZSx0nWZl/rx5nDV4ELvuvhc7/apPXmMV+zl0vMYf0/Ead7xCxCyVvxXFxB1+MwNAUgeSKeLXRERUem3tiBgfEZeRTKdfn2Qk+rc596mvFBE/AN/n3BveH6gY7Z8IbJE+Xmwl/JxYawBTI+Jm4FZgc+A1oJekinvnW0lar4rD2wCTJTUjGWGvzTDgEEllklYBdqrDMTWpLv5rQMWN7YcsQbptSTrpkMxuqPBTGnMREfEjMElSXwBJy6V1VlXdVj72pojoERE9fjPgd3XO4DEnDuLBp57n/sef47w/X8FmPbbk7Asvrf3AJbRRt435/POJTJr0X+bNncuzzzzNjjvtnLd4AN9//x0//fQjAHNmz2bUyNfyukBh1mUsRJ1mLSK4+MLz6LrmWhzWf0De4xX7OXS8xh/T8Rp3vELELJa/FaU0pX9ZXhHbzPKvZTpNvRnJCPzdwF+r2G+QpJ1IRv/fAf4REXMkdQdGSZoLPAOcTdIhvSG9EPAJcFSaxl+AByX1p+ap872B0yXNA6YDR0TE15IGAPdLWi7d71zgg0rHnge8DnxGMiV+sc5wJY8BO6f7fsDPFyeWVHXxBwH3SPoD8DTwQz3TvQB4SNIXJBcPKnqZTwIPS9qXn+/3r9AfuFHSRcA84ECS9RcWqdt65mOZ0bRpU846ZwjHD/wdCxaU03e/fqyzzrp5jfntN19zyfnnUL6gnFgQ7NRnV3pt3ztv8bIuYyHq9Owz/sCbo0Yybdo09tilNwNPOIm++1d7PXCpjR0zmn88/QRrr7se/Q/eD4DjTxrEttvvmJd4xX4OHa/xx3S8xh2vEDELUUZbOqo0kGdmZg0svfgxKyJC0iHAoRGxb6HzVZsvps3N9A9E+9bNswzHj7PmZRpvhZbNMo1XCPPKF2Qab355tv/DtGxeiG/fNDMrHi2aVn3bYdaWP/D2gnaCZzx0VGb14BF+M7P82wK4RskcrmnAbwubHTMzMzMrBe7wm5nlWfqVeZsWOh9mZmZmVlrc4TczMzMzM7OSUUpfJehV+s3MzMzMzMyKkEf4zczMzMzMrGR4hN/MzMzMzMzMGjV3+M3MzMzMzMyKkKf0m5mZmZmZWcnwlH4zMzMzMzMza9Q8wm9mZmZmZmYlwyP8ZmZmZmZmZtaoucNvZmZmZmZmVoQ8pd/MzMzMzMxKR+nM6HeH38zMqjblh9mZxmvfunmm8bL2m7tHZxrv9sO6ZxoPoFlZthMHZ82dl2m8lpRlGm9e+YJM4038emam8QDW7dw685hZyvocZv0eLISs6zRr2X+Olmcar0XTbD9HzR1+MzMzMzMzKyFetM/MzMzMzMzMMiephaSRksZKelvShen2CyR9IWlM+rNHbWl5hN/MzMzMzMxs2TEH2DkipktqBrws6R/pa1dGxF/qmpA7/GZmZmZmZlYylvUp/RERwPT0abP0J5YkLU/pNzMzMzMzM1uGSCqTNAaYCvwrIl5PXzpJ0jhJt0lasbZ03OE3MzMzMzMzy4ikgZJG5fwMrLxPRJRHRHdgNWBLSd2A64G1ge7AZOB/a4vlKf1mZmZmZmZWMgo9pT8ibgJuquO+0yS9COyWe+++pJuBp2o73iP8ZmZmZmZmZssISR0ktUsftwR2Ad6TtErObvsBE2pLyyP8ZmZmZmZmVjIKPcJfB6sAd0oqIxmkfzAinpJ0t6TuJAv4TQSOrS0hd/jNzMzMzMzMlhERMQ7YrIrt/eublqf0m5mZmZmZmRUhd/jNbKlJml6HfbaX9LakMem9SFnkq7ekbXOeHyfpiAZIt6ukWWlZKn6qTVdSO0knLG3cnPTyUq6l9Y/H7uf0Yw5m8DEH8cyj9+U93ojhw9hnz13Za7c+3Hpznda9WSpz5sxh4BGHMODQ/el/0L7ceuM1DR6j/fLNuGC3dfnbfhtyZd8N2GPDDou8vk+3jjx81Oa0Wa6swWMDXDjkHPrs2IuD9ts7L+lXVoznsLIsy5j1+QN48uF7GfTbAzn16IO48s9nM3funLzGy7rNZB2vEOfQddq440G2dTrlq8mccMwADt5/Lw7ttzdD77s7r/HyRgX+yZA7/GaWlcOBv0RE94iYVdvO6T1LS6s3sLBjHBE3RMRdDZAuwMdpWSp+akq3HVBlh38Jy9mb/JVrifz304/4zzOP8+er7+SyG+7jrddfZvIXn+ctXnl5OZdcfBHX3XALjz3xNM8+8xQff/RR3uIBNG/enL/dcBt33P8ot9/3MK+/MoK3x49t0BjlC4I735jEoMfe4ayn3me39TuwWtsWQHIxYJNfrMDX0/PXodp7n75cfX3+/wGH4j2HubIuY5bnD+Dbr6fyj8ce4LLr7+bKWx9kwYJyRvznubzFy7o+C9FGsz6HrtPGHy/rOi0ra8opp53B0Eef4pa7HuDhoffx6cf5PYe2dNzhN7MGk448vyjpYUnvSbpXid8BBwFDcrZdIWmCpPGSDs45/gVJ9wHj0+cvSXpQ0geSLpV0uKSR6XFrp8ftLel1SW9J+rekTpK6AscBp6Yj8NtLukDS4PSY7pJekzRO0mOSVky3vyjpsjTGB5K2r0f515D0oaSVJTWRNFzSr4FLgbXTfFxRuZzpsY9LejOdBTEwJ83dJI2WNFbS84UoV1188d+JrLvBxizXogVlZU3ZYOPNeWPEiw0ZYhETxo+jS5c1WK1LF5o1b85ue+zJiy88n7d4kCzw06pVKwDmz5/P/PnzoYEX/Zk2az6ffptcD5s9fwFf/DCblZZvBsCALVfj7je+IKJBQy5i8x49WaFtu/wFyFGs5zBX1mXM8vxVKC8vZ+6cOZSXz2fO7NmsuHKH2g9aQlnXZyHaaNbn0HXa+ONlXacrd+jA+htsCMDyyy9P1zXXYurXU/MWL18kFfQnS+7wm1lD2wwYBGwIrAX0iohbgCeA0yPicGB/oDuwKcnXjFyhn79mZEvgnIjYMH2+KfB7YGOgP7BeRGwJ3AKcnO7zMrB1RGwGPACcERETgRuAK9MR+OGV8nkX8MeI2ISk031+zmtN0xiDKm3PVdGBr/jZPiI+Ay5L4/4BeCci/gmcyc8zAk6vppy/jYgtgB7AKZLaS+oA3Az0i4hNgQMzKNcS6dJ1bd4d/xY//TiNObNnM+aNV/j26ykNGWIRU6dMofMqnRc+79ipE1Om5C9ehfLyco46rB/79NmBnlttw0bdNslbrA6tm9N1pVZ8+PUMenRpy3cz5/HZ97VOjmk0SuEcFqqMWWnfoSP7HPgbjj90T445cFdatW5N9x7b5C1e1vVZ7OcPXKfFoJB1+uWXX/DB++/SLY+fo7b03OE3s4Y2MiImRcQCYAzQtYp9tgPuj4jyiJgCvAT0zDn+05x934iIyRExB/gY+Ge6fXxO2qsBz0kaD5wObFRTBiW1BdpFxEvppjuBHXJ2eTT9/WY1+YfFp/QPB0gvbrQhGYUfXEM2KpfzFEljgdeALsC6wNbAsIr9IuK7DMq1RFZdfU32OegILjnzJC49+xRWX2tdyprk5z5zgGDxYe4srpiXlZVx+32P8Mgzz/Pu2+P55KMP8xKnRdMmDN5pLe4YOYnyBUG/TTszdPSXeYlVKMV+DqFwZczK9J9+5I1XXuLae5/kpgefZc6sWQz71zN5i5d1fRb7+QPXaTEoVJ3OnDmDswb/nkGDz2L51q3zHs+WnDv8ZtbQcm8wLqfqr/+s6S/RjBrSW5DzfEFO2lcD10TExiTfR9qizrmtWkWM6vJfLUmtSC5AANT0F3BhOSX1JpnpsE06kv8WSRkEVfwlX3K1lkvSQEmjJI169L7b65X4Trvvy/9cdw/n//UmWrdZgc6rdlnK7FavU6fOfDX5q4XPp06ZQseOHfMWr7I2bVZgsy168vqrLzd42mWCwTuvxfBPvuP1z6bReYXl6Ni6OX/ZdwOuO2Aj2i/fnMv32YB2LRv3N+sW8zmsUOgy5tu40a/TsfOqtG23Ik2bNmOr7Xfm/XfytyZC1vVZ7OcPXKfFoBB1On/ePM4aPIhdd9+LnX7VJ6+x8sVT+s3M8msYcLCksnTa+g7AyKVIry3wRfr4yJztP5GMti8iIn4Avs+5j70/ySyDhnAZcC8whGQ6frX5yNEW+D4iZkpan2RkH+BVYEdJawJIWqmm9BqiXBFxU0T0iIge+x92VH0O5YfvkwkI30z9ijdefoFtd9q1XsfXx0bdNubzzycyadJ/mTd3Ls8+8zQ77rRz3uIBfP/9d/z0048AzJk9m1EjX2P1rms2eJwTtluDSdNm89TbyT2Rn38/m6MfGM8JD7/NCQ+/zbcz5nLGE+8ybdb8Bo+dpWI+hxUKUcYsrdyxMx+8O545s2cREYwfPZJVVy+e+iz28weu02KQdZ1GBBdfeB5d11yLw/oPyFscaziNe3jAzBqrx4BtgLEkI9hnRMRXaWd3SVwAPCTpC5Ip8RX/cT4JPCxpX36+37/CkcAN6Yj8J0D9erfpPfw5z28jKU9PknULyiX1k3RURNwuaYSkCcA/gKcrpfUscJykccD7aRmIiK+VLOD3qKQmwFSgT57LtcSu/NMfmf7jD5Q1bcpRJ59B6zYr5C1W06ZNOeucIRw/8HcsWFBO3/36sc466+YtHsC333zNJeefQ/mCcmJBsFOfXem1fe8GjbF+x+XZcZ32fPbdLK7YJ3k73Df6S96a9GODxqnO2Wf8gTdHjWTatGnssUtvBp5wEn33PyAvsYr1HObKuoxZnj+A9TbYmG12+BWnH3c4ZWVNWXOdX9Jnz/3zFi/r+ixEG836HLpOG3+8rOt07JjR/OPpJ1h73fXof/B+ABx/0iC23X7HvMXMh1K6lUSRz+V+zcys0Rr92Y+Z/oHYcNX8XSCoyo+z5mUa74SHx2ca7/bDumcaD6BZWbYTB7M+hyu0bJZpvHnlCzKNN/HrmZnGA1i3c3Hf+5v1Ocz6PVgIWddp1rI+h7Pmlmcab8VWZctET7vjbx8saCd46m0HZVYPxf+pYGZmZmZmZlaCPKXfzMzMzMzMSscyMc8gGx7hNzMzMzMzMytCHuE3MzMzMzOzklFKi/Z5hN/MzMzMzMysCLnDb2ZmZmZmZlaEPKXfzMzMzMzMSoan9JuZmZmZmZlZo+YRfjMzMzMzMysZHuE3MzMzMzMzs0bNHX4zMzMzMzOzIuQp/WZmZmZmZlYyPKXfzMzMzMzMzBo1j/CbmVmV1uywfKGzkFctm5dlGu+6AzbONN6Ps+ZnGg9ghZbZ/luxQstmmcYrdm0yPn8A88oXZBqvWVm2Y11ZxysFWddp1m0063hZ/y207LnDb2ZmZmZmZqWjdGb0e0q/mZmZmZmZWTHyCL+ZmZmZmZmVDC/aZ2ZmZmZmZmaNmjv8ZmZmZmZmZkXIU/rNzMzMzMysZHhKv5mZmZmZmZk1ah7hNzMzMzMzs5LhEX4zMzMzMzMza9Tc4TczMzMzMzMrQp7Sb2ZmZmZmZqWjdGb0e4TfzMzMzMzMrBi5w29WDUnT67DP9pLeljRGUsuM8tVb0rY5z4+TdEQDpNtV0qy0LO9IuktSs1qOGSDpFzW8fpGkXZY2b5XSvEPSAQ2ZZnXpSro2pz4q6mZMfeJL6itpw2peu0BSSFonZ9up6bYe6fNnJLWrJUaD13N9TflqMiccM4CD99+LQ/vtzdD77s57zBHDh7HPnruy1259uPXmm/Ie78Ih59Bnx14ctN/eeY8FMGfOHAYecQgDDt2f/gfty603XpNJ3PLycgb2P5CzTzsx77GyrtOs20zWMbOuT4Aj9t+dY3/Tj+OPPIiTfnto3uO5zTjesh4v6zZaiPd9Id4XDU1SQX+y5A6/2dI5HPhLRHSPiFm17SyprAFi9gYWdvgj4oaIuKsB0gX4OCK6AxsDqwEH1bL/AKDKDr+ksogYEhH/bqC8ZS4iTkzrYw/Sukl/Hq5HMn2BKjv8qfHAITnPDwDeycnDHhExrZZ8Fryey8qacsppZzD00ae45a4HeHjofXz68Ud5i1deXs4lF1/EdTfcwmNPPM2zzzzFxx/lLx7A3vv05errs/vHpnnz5vzthtu44/5Huf2+h3n9lRG8PX5s3uM+OvQeVu+6Zt7jQLZ1Wog2k3XMrNtohcuvuYXr73yQa267P++x3GYcb1mOB9m/D7OOV4g6taXjDr9ZLdIR9RclPSzpPUn3KvE7kg7xkJxtV0iaIGm8pINzjn9B0n3A+PT5S5IelPSBpEslHS5pZHrc2ulxe0t6XdJbkv4tqZOkrsBxwKnpSPP26Sjx4PSY7pJekzRO0mOSVky3vyjpsjTGB5K2r6nMEVEOjARWTY/fIs3zm5Kek7RKOsrdA7g3zUtLSRMlDZH0MnBg7qh5NWlsIGlkTl13lTQufTxE0htpfd6kWi6HSjom3X+spEcktUq33yHpKkmvSPokJz+SdI2S0fungY51bA/LS7otjfWWpH3T7VdJGpI+3lXSMCUzMfYBrkjraO0qknwcqEhjLeAH4OuceBMlrZzWzbuSblYyq+SfSmeVVKrniZIulDQ6bU/rp9s7SPpXuv1GSZ9JWrkuZa6LlTt0YP0Nkusayy+/PF3XXIupX09tqOQXM2H8OLp0WYPVunShWfPm7LbHnrz4wvN5iweweY+erNC2XV5j5JJEq1atAJg/fz7z58+HPI8KfD3lK14bMZw99u2X1zgVsqzTQrSZrGNm3UYLwW3G8ZbleJD9+zDreIWoU1s67vCb1c1mwCCSkdq1gF4RcQvwBHB6RBwO7A90BzYFdiHp5K2SHr8lcE5EVIz0bgr8nmQkvT+wXkRsCdwCnJzu8zKwdURsBjwAnBERE4EbgCvTkebhlfJ5F/DHiNiEZOT4/JzXmqYxBlXavhhJLYCtgGeVTOu/GjggIrYAbgMuTke5RwGHV5rhMDsitouIB3LSqy6Nd4HmaUcX4GDgwfTxNRHRMyK6AS2BvWrKM/Bouv+mwLvA0TmvrQJsl6ZxabptP+CXJOfgGHJmTdTiHOA/EdET2InkPC8PnAkcLGkn4CrgqIh4hZ/bSPeI+LiK9H4E/iupG3AoMLSG2OsC10bERsA0oLpe2TcRsTlwPTA43XZ+mu/NgceA1etY3nr78ssv+OD9d+nWbZN8hWDqlCl0XqXzwucdO3ViypQpeYtXKOXl5Rx1WD/26bMDPbfaho3yWKcA1155OceedCpNVHz/HhSizZREOxWcPeg4TjzqEJ55vD6Tn5Z9pdBmHM/qq1jqVJ7Sb2aVjIyISRGxABgDdK1in+2A+yOiPCKmAC8BPXOO/zRn3zciYnJEzAE+Bv6Zbh+fk/ZqwHOSxgOnAxvVlEFJbYF2EfFSuulOYIecXR5Nf79ZTf4B1pY0BvgW+DwixpF0irsB/0pfOzfNW3Wq6rDWlMaD/HzrwME5x++kZIbDeGBnaik/0E3S8HT/wyvt/3hELIiId4BO6bYd+Pl8fQn8p5b0K/waODMtx4tAC2D1iJhJcuHgXyQXK6rq3FfnAZJp/X1JOuPV+TQixqSPazqPVZ3r7dI4RMSzwPdVHShpoKRRkkbdcdvNdct9jpkzZ3DW4N8zaPBZLN+6db2Pr6sgFtuW9R/QLJSVlXH7fY/wyDPP8+7b4/nkow/zFuvVl1+i3Uorsd4Gtb3VGqdCtJlSaKdX3nAn194xlIv/91qeeHQo4996s9BZajCl0GYcz+rLddr4+Gv5zOpmTs7jcqp+79T0aTejhvQW5DxfkJP21cBfI+IJSb2BC+qY1+pUxKgu/5Dep57OTHhR0j7Ap8DbEbFNHeNULiskdVNdGkOBhyQ9CkREfJjOMLgO6BER/5V0AUnHuiZ3AH0jYqykASRrHVTIre/c87T4X63aCegXEe9X8drGJBdLql3IsBpPAlcAoyLixxr+cFZuh9UtFFnVua7TX+OIuAm4CeD7meX1qp/58+Zx1uBB7Lr7Xuz0qz71ObTeOnXqzFeTv1r4fOqUKXTsWKe7MhqlNm1WYLMtevL6qy+z1jrr5iXGhLFv8cqwF3j9leHMnTOHmTNmcMn5Z3L2hZfWfnAjUIg2UwrttH2HpDztVmpPrx125r13J7DxZlsUOFcNoxTajONZfRVLnZbSRQqP8Js1nGEkU7rLJHUgGUEeWcsxNWkLfJE+PjJn+09Am8o7R8QPwPf6+f78/iSzDOotIiaTTFE/C3gf6CBpG0im50uqGAKsMi9VqDaNdCS8HDiPn0f3Kzr330hqTbKQXW3aAJPT2wcOr8P+w4BD0vO1Csn0/Lp4DjhZ6V8KSZulv9cA/kBy+8fukrZK96+1jtLbIf4IXFzHPCyJl0lnUkj6NbBiQyYeEVx84Xl0XXMtDus/oCGTrtJG3Tbm888nMmnSf5k3dy7PPvM0O+60c97jZun777/jp59+BGDO7NmMGvlaXhfTO+bEQTz41PPc//hznPfnK9isx5ZF09mHwrSZYm+ns2fNZOaMGQsfvznyVbqutU4tRzUepdBmHM/qy3Xa+HiE36zhPAZsA4wlGTk+IyK+qlg0bQlcQDLy/QXwGlDxn/6TwMPpYnEnVzrmSOAGJQvWfQIctYSxIVlM7gKSe/kPAK5KbxtoCvwNeJtkVP0GSbNIyl6liJibLipXVRqQdPSvqChjREyTdDPJLQ4TgTfqkN/zgNeBz9LjarsQ8RjJrQLjgQ+o+8WRP6V5H5d2+idK2hu4FRgcEV9KOhq4Q1JPkmn0N0s6hWQNgyqn+ueueZAnFwL3K1lM8iVgMsnFiAYxdsxo/vH0E6y97nr0P3g/AI4/aRDbbr9jQ4VYRNOmTTnrnCEcP/B3LFhQTt/9+rFOnka+K5x9xh94c9RIpk2bxh679GbgCSfRd/8G/4bIhb795msuOf8cyheUEwuCnfrsSq/te+ctXiFkWaeFaDNZx8y6jX7/3XdceNapAJSXz2enPnvQc+teeYsHbjOOt2zHg+zfh1nHK0Sd2tJRxJLMaDUzs8ZE0nJAeUTMT2daXJ9+5WC16julf2m1bN4Q31pZd/PKF2Qab9bc8kzjzcv29AGwQstsxxGalRX3RMWs2+i30+dmGg+gfevmmcYr9jZjDS/r92HWsn5PtGhat1sM823NQU8XtBP86d/2zKwePMJvZlYaVgcelNQEmEuywKCZmZmZFTF3+M3MSkBEfEiyvoCZmZmZlQh3+M3MzMzMzKx0LBM3FmTDNzKZmZmZmZmZFSGP8JuZmZmZmVnJSL9duSR4hN/MzMzMzMysCLnDb2ZmZmZmZlaEPKXfzMzMzMzMSoan9JuZmZmZmZlZo+YRfjMzMzMzMysZJTTA7xF+MzMzMzMzs2LkDr+ZmZmZmZlZEfKUfjMzMzMzMysZpbRonzv8ZmZWpQ+/mp5pvE1Wb5tpvGZl2U5ya9Yy23hf/TA703gAT0z4MtN4/TZdLdN4P86al2m8FVo2yzTe/PLINB7ArLnlmcbL+n04r3xBpvGy9uOs+ZnHbN+6eeYxs5T136as22iLpp5gnjV3+M3MzMzMzKxklNAAv+/hNzMzMzMzMytG7vCbmZmZmZmZFSFP6TczMzMzM7OSUUqL9nmE38zMzMzMzKwIeYTfzMzMzMzMSkYJDfB7hN/MzMzMzMysGLnDb2ZmZmZmZlaEPKXfzMzMzMzMSkaTJqUzp98j/GZmZmZmZmZFyCP8ZmZmZmZmVjKW9UX7JLUAhgHLkfTZH46I8yWtBAwFugITgYMi4vua0vIIv2VG0vQ67DNIUqss8lMpbm9J29ZhvwskDa5i+y8kPZyT1lPp430knZk+7itpw4bOey35vUPSAdW81lTSN5L+ZyljLCxvPY/rIemqpYmdpnOKpHcl3VtFvkLS0TnbNku3LXYOa0i/q6QJS7tPpf0PTPP8Ql2PqSKNkPS/Oc8HS7ogfVxdOy2XNEbSBEkPNcR77ea//okTDtmVM487ZOG26T/9wKVnn8Tgo/tx6dknMeOnH5c2TJVGDB/GPnvuyl679eHWm2/KS4xCx8w63hH7786xv+nH8UcexEm/PTQvMZ648Qr+clw/rj9j4VuTFx++kytPPIgbzxrIjWcN5MO3Xs9L7Kzrc86cOQw84hAGHLo//Q/al1tvvCbvMbMu4/SffuSScwdz7OF9OfY3+/HuhLF5i1UK9XnhkHPos2MvDtpv77zHKkS8CuXl5QzsfyBnn3Zi3mMV+zmEbMtYqDZTguYAO0fEpkB3YDdJWwNnAs9HxLrA8+nzGrnDb8uaQUC9OiGSyuq4X00zWnoDtXb4qxMRX0bEYh3riHgiIi5Nn/YFMu3w1+LXwPvAQVL21zkjYlREnNIASZ0A7BERh1fx2njg4JznhwD5+2+07o4GToiIneqyczVtdw6wv6SV6xF3VkR0j4huwFzguHocW6Xt++zJGX/++yLbnnzwTjbq3pO/3PoIG3XvyZMP3rm0YRZTXl7OJRdfxHU33MJjTzzNs888xccffdTgcQoZsxBlBLj8mlu4/s4Huea2+/OS/qY77Mrhf1z8OuNWux/Asf9zE8f+z02su9lWDR63EPXZvHlz/nbDbdxx/6Pcft/DvP7KCN4en7+PoEKU8aarLmeLrbblxnsf55rbH6TLGmvmLVYp1Ofe+/Tl6uuzuYBZiHgVHh16D6t3zV9bqVAK5zDrMhaqzZSaSFQMljZLfwLYF6j4x+pOkv5Fjdzht8ylI68vSnpY0nuS7lXiFOAXwAsVI5+Sfi3pVUmj0xHJ1un2iZKGSHoZODBN72+SXklHL7dM97tA0k2S/gncJamDpEckvZH+9JLUlaTjc2o6+rm9pL0lvS7pLUn/ltQppwibSvqPpA8lHZPGqXKEV9IASdekswf2Aa5IY6wtaXTOfutKerOK449J8zk2zXerdPsdkq5Ky/tJxSh+Wo/XSHpH0tNAxxpOxaHA34HPga1zYk6UdGFa5+MlrZ9u3zKN91b6+5eV8tokrZMOOc8/krRyOqI9IS3HsJx2UDETYse0Xsak6bepoi5OS9OYIGlQuu0GYC3gCUmnVlHGz4EWkjqlFzV2A/6Rk2Z3Sa9JGifpMUkrptu3SPP6KnBizv5lkq5Iz8k4ScdWkc+NJI1MyzJO0rqVXh8CbAfckKbVQtLtaV2/JWmndL8BaZt/EvhnFWWbD9wEVFXuuhgOrLOExy60/sabs3ybFRbZNvrVYWy/y54AbL/Lnrz56ktLG2YxE8aPo0uXNVitSxeaNW/ObnvsyYsvPN/gcQoZsxBlzMIaG2xCy9Yr1L5jAytEfUqiVavkGvb8+fOZP39+XueRZl3GmTOmM2HsaH69134ANGvWjNZt8ndui70+ATbv0ZMV2rbLa4xCxgP4espXvDZiOHvs2y/vsUrhHGZdxkK0mXyQVOifgZJG5fwMrCKPZZLGAFOBf0XE60CniJgMkP6u6X99wB1+K5zNSEbzNyTpsPWKiKuAL4GdImInJSOX5wK7RMTmwCjgtJw0ZkfEdhHxQPp8+YjYlmTE97ac/bYA9o2Iw0g6uFdGRE+gH3BLREwEbki3d4+I4cDLwNYRsRnwAHBGTnqbAHsC2wBDJP2itsJGxCvAE8DpaYyPgR8kdU93OQq4o4pDH42Inul0nndJRoYrrELScdwLqJhFsB/wS2Bj4BiqmbUgqSXwK+Ap4H6Szn+ub9I6vx6omBr+HrBDWidDgEsqlXEBcA9QMdK+CzA2Ir5J9981Lcc+VWRpMHBiRHQHtgdmVcrvFiR1tBXJxYljJG0WEcfxc5u5sqqyAg8DB6Z1MZpkZLzCXcAfI2ITktkA56fbbwdOiYhtKqV1NPBD2n56pvmoPERxHPD3tCw9gEm5L0bERSRt+fCIOJ30gkJEbExyHu5Uct8WJG3syIjYuZqyXQscLqltNa9XScmMgd1Jytzgfpz2He1WSiYetFtpZX78ocZby5bI1ClT6LxK54XPO3bqxJQpUxo8TiFjFqKMCM4edBwnHnUIzzz+cH5jVfLGPx/nhj/+jiduvIJZ039q8PQLUp8ko29HHdaPffrsQM+ttmGjbpvkLVbWZZz85STatluRKy8Zwsm/PZi/X3ohs2fNqv3ApVDM9Vkqrr3yco496VSaKP/dkFI4h6VQxmIUETdFRI+cn8WmTUREefr/5GrAlpK6LUksd/itUEZGxKS0kziGZOGJyrYmuSAwIr26dSSwRs7rQyvtfz9ARAwDVpDULt3+RERU/AeyC3BNmt4T6X6LjSaTvLGekzQeOB3YKOe1/4uIWWlH9gVgy1pLW7VbgKOU3JJwMHBfFft0kzQ8zcfhlfLxeEQsiIh3gIoZCDsA96cfEF8C/6km9l7ACxExE3gE2E+L3hrxaPr7TX4+N22Bh5TMZLiyUl4q3AYckT7+LUnHGWAEcIeSGRFV3YIxAvirklke7SJifqXXtwMei4gZ6fSmR0kuDNTFgyQd/kNJ2whA2kluFxEVw893AjtUsf3unLR+DRyRtp/XgfbAIiP4wKvA2ZL+CKyR0/aqs11FjIh4D/gMWC997V8R8V11B0bEjyQXLep6a0TLNO+jSGY/3FrH45Y5QSy2TXm+MyXrmIUo45U33Mm1dwzl4v+9liceHcr4txabeJQXPfrszcl/u5tj/+cmWrdbiX/de0ODxyhEfQKUlZVx+32P8Mgzz/Pu2+P55KMP8xYr6zIuKC/now/eY4++B3H1bUNp0bIFD917W+0HLoVirs9S8OrLL9FupZVYb4Oq/oVoeKVwDkuhjKUuIqYBL5LMVJ0iaRWA9PfU2o53h98KJXeUtZyqvzFCJB2e7unPhhGRO8I9o9L+lT/xoor9mgDb5KS5akRUNZR0NXBNOup6LNAi57Xq4tTXIySjrHsBb0bEt1XscwdwUpqPCyvlI7cOcz/Z65KfQ4FdJE0k6dS3B3LvJ69IO/fc/InkIkE3YO9KeUkCR/yX5INoZ5LR+H+k248jma3RBRgjqX2l4y4Ffge0BF5TehtBNeWrl4j4CpgH9CFZ3KQ2ovo6FHByTvtZMyIWmW4fEfeRzGKYRXLRqLrR+dw0q1O5jVflbyQzD5avw76zcvJ+ckTMXSwzOVPMHrv/jjokubgV2q3EtO++AWDad9+wQtsVlyidmnTq1JmvJn+18PnUKVPo2LHWWW2NKmYhyti+Q5J+u5Xa02uHnXnv3TqvRblUWrddiSZNylCTJmy+85588fF7DR6jEPWZq02bFdhsi568/urLeYuRdRnbd+jEyh06sv5GGwPQq3cfPnr/3bzFy1WM9VkKJox9i1eGvcChfXflT+eezlujRnLJ+bWuObbESuEclkIZ80Eq7E/t+VOHisHLdGbuLiSzbZ8gGQQl/f1/taXlDr8ta34CKkbcXwN6SVoHQFIrSetVe2S6OJuk7UimXf9QxT7/BE6qeJIzpT43LiSj2V+kj49kUfum9123J1ns741aylRhkRgRMRt4jmTa/O3VHNMGmCypGT9Pla/JMOCQ9J6fVVi0Ew+ApBVIRpVXj4iuEdGVZFp5bUty59bJgBr2u4Vkav+DEVGexlw7Il6PiCHANyQd/9w8rR0R4yPiMpLR58od/mFA37QNLE9y68LwWvKbawjJ1P3yig1p+/heUsVMgf7AS+lV1B/SdgSL1vtzwPHp+UDSeml+csuyFvBJeovKEyS3gNRkWEWMtH2vTrKYYp2kMwAeZNHbPZZY7hSz/Q4dsERpbL71Dgz/99MADP/302y+zQ4NkbVFbNRtYz7/fCKTJv2XeXPn8uwzT7PjTrVdW2lcMbOON3vWTGbOmLHw8ZsjX6XrWku9zEOd/PT9z9c733vjZTqu1rXBYxSizXz//Xf8lH5LxZzZsxk18rW8LlSWdRlXar8yHTp2ZtLnEwEY++brrN51rbzFK/b6LAXHnDiIB596nvsff47z/nwFm/XYkrMvvLT2A5dQKZzDUihjiVqFZF2zcSR9jX9FxFMkt/H2kfQhyWBWrW+gmlYtNyuEm4B/SJqc3sc/ALhf0nLp6+cCH1Rz7PeSXgFWIJlOXpVTgGvTN09Tks7WccCTwMOS9gVOBi4gmb7+BcmFh9z/KEYCT5N0zP4UEV8qWfivNg8AN6fT1g9I7+O/F9ifqhdlAziPZOr4ZyT3W1d1+0Gux4Cd030/AKpaLW1/4D8RkTtD4P+Ay3PquSqXk9xffhrV3yoASSf3dha9iHGFksXrRDLKPhbYMef1QUoWqysH3iFnYT2AiBgt6Q6Suodk7YW3asjDItI1FKpyJMniea2AT0jWCSD9fZukmSSd/Aq3kNziMFrJfLmvWXx11IOB30iaB3wFXFRL9q5L8zCeZCG+ARExp57T8f6XnAtZqXOVLm4IEBGr1SfBurr20nN5d9ybTP9xGqf8Zi/2738Mex10BNdccjYvPfcE7Tt04uRzluqbH6vUtGlTzjpnCMcP/B0LFpTTd79+rLNO5bsrGnfMrON9/913XHhWsgZkefl8duqzBz237tXgcR65+s989u5YZv70A1eedDC9+x3JxHfHMuWzjwFo16Ezex69pGtRVq8Qbebbb77mkvPPoXxBObEg2KnPrvTavnfe4hWijMcO+iNXXHQ28+fNo/MvVmXQ2bV95C25UqjPs8/4A2+OGsm0adPYY5feDDzhJPruX+W36zbKeFkrhXOYdRmLpc0s67c9RMQ4kjXPKm//lmQdrjpTxJLORjZbdkh6ERgcEaMKnZf6UPJd6W0j4rxC56WhSOpBsgBiXe+xt2XUyE9+yPQPxCar12vtQavFVz/MzjzmiInfZBqv36Z5uY5VrR9nzcs03gotm2Uab9J3+V1wryortMx27CnrOp1XviDTeFn7cVblJXfyr33r5pnGy/ocNivLdgJ21uVrs1yTZaKnvcmQfxe0Ezzuol0yqweP8JsViKTHgLVJRuSLgqQzgeOp2+0HZmZmZmaWR+7wW1GIiN6FzkN9RcR+hc5DQ0sX38vfzXhmZmZmZktpWZ/S35C8aJ+ZmZmZmZlZEfIIv5mZmZmZmZWMEhrg9wi/mZmZmZmZWTFyh9/MzMzMzMysCHlKv5mZmZmZmZUML9pnZmZmZmZmZo2aR/jNzMzMzMysZJTQAL9H+M3MzMzMzMyKkTv8ZmZmZmZmZkXIU/rNzMzMzMysZHjRPjMzMzMzMzNr1DzCb2ZmVeraoVWm8b76YXam8Tq3bZFpvKwVonyb/2LFTOOd9MiETONd069bpvHmlS/INF771s0zjQfQsnlZ5jGLWbOybMfyCtFmspZ1nVo2SmiA3yP8ZmZmZmZmZsXIHX4zMzMzMzOzIuQp/WZmZmZmZlYyvGifmZmZmZmZmTVqHuE3MzMzMzOzklFCA/we4TczMzMzMzMrRu7wm5mZmZmZmRUhT+k3MzMzMzOzkuFF+8zMzMzMzMysUXOH38zMzMzMzKwIeUq/mZmZmZmZlYwSmtHvEX4zs9pI6iTpPkmfSHpT0quS9itQXnpL2jbn+XGSjihEXnLNmTOHgUccwoBD96f/Qfty643XZBL3iP1359jf9OP4Iw/ipN8emvd4I4YPY589d2Wv3fpw6803Od5S+OLziQw6+pCFP4fusT1PPHRvg8ZYsWUzBvfuyp92X4cLd1uHX63bHoADNu3En3Zflwt2XYcTeq1Oy2b5+3coyzq9cMg59NmxFwftt3de41SY8tVkTjhmAAfvvxeH9tuboffdnfeYxfyegOzPIRR/nRZ7vKxjFqKN2tLxCL+ZWQ2UrOryOHBnRByWblsD2CePMZtGxPxqXu4NTAdeAYiIG/KVj/po3rw5f7vhNlq1asX8+fM44egj2Hrb7dlo403zHvvya26hbbsV8x6nvLycSy6+iBtvvp1OnTpx2MEH0HunnVl7nXUcbwmsunpX/nbrAwtjH33Abmy9/U4NGmNBBA+O/YrPv5/Nck2bcN6v1+adKdN556sZPDpuCgsC+m3SiT026MAj46Y0aGzIvk733qcvBx9yGEPOOTMv6VdWVtaUU047g/U32JAZM2Yw4LAD2HKrbVhz7eJoo1nHg+zPYbHXabHHK0TMrNtovnjRPjMzq7AzMDe3Yx0Rn0XE1ZLKJF0h6Q1J4yQdCwtH4V+U9LCk9yTdm144QNIWkl5KZwo8J2mVdPuLki6R9BLwe0l7S3pd0luS/p3OMugKHAecKmmMpO0lXSBpcJpGd0mvpXl5TNKKOWlfJmmkpA8kbd/QlSSJVq1aATB//nzmz59fdPPlJowfR5cua7Baly40a96c3fbYkxdfeN7xGsC40SPpvOpqdOz8iwZN94fZ8/n8+9kAzJm/gMk/zmHFlk15Z8p0FkSyzyffzmTFVs0aNG6FrOt08x49WaFtu7ylX9nKHTqw/gYbArD88svTdc21mPr11LzFK4X3RNbnsNjrtNjjFSJm1m3Ulp47/GZmNdsIGF3Na0cDP0RET6AncIykNdPXNgMGARsCawG9JDUDrgYOiIgtgNuAi3PSaxcRO0bE/wIvA1tHxGbAA8AZETERuAG4MiK6R8TwSvm5C/hjRGwCjAfOz3mtaURsmebpfPKgvLycow7rxz59dqDnVtuwUbdN8hFmUYKzBx3HiUcdwjOPP5zXUFOnTKHzKp0XPu/YqRNTpjT8qHCpxMv18n+eY/udd81rjPatmrF6uxZ88u2sRbZvt+aKTJj8U15iFrJOs/bll1/wwfvv0i2P7/tSek9kpdjrtNjjFSqmNS6e0m9mVg+SrgW2A+YCnwGbSDogfbktsG762siImJQeMwboCkwDugH/Sgf8y4DJOckPzXm8GjA0nQHQHPi0lny1Jblg8FK66U7goZxdHk1/v5nmpcGVlZVx+32P8NNPP3LO4N/zyUcfstY66+Yj1EJX3nAn7Tt0ZNp333LmoOPossaabLzZFnmJFcRi2/I5JbDY41WYN28eI0cMo/8xJ+ctxnJNm3BCr9UZ+tZXzJ6/YOH2PTfoQHnAa5/9kJe4harTrM2cOYOzBv+eQYPPYvnWrfMWp1TeE1kq9jot9niFilkMSqmKPMJvZlazt4HNK55ExInAr4AOgICT09H27hGxZkT8M911Tk4a5SQXWAW8nbP/xhHx65z9ZuQ8vhq4JiI2Bo4FWixlOSryU5GXKkkaKGmUpFF33X7LEgVq02YFNtuiJ6+/+vISHV8f7Tt0BKDdSu3ptcPOvPfuhLzF6tSpM19N/mrh86lTptCxY0fHW0qjXx/BWuutT7uV2ucl/TLB8dt24bXPpjH6ix8Xbt+2azs2+UUbbnntv3mJC4Wr0yzNnzePswYPYtfd92KnX/XJa6xSeU9kqdjrtNjjFSqmNS7u8JuZ1ew/QAtJx+dsa5X+fg44Pp2qj6T1JC1fQ1rvAx0kbZPu30zSRtXs2xb4In18ZM72n4A2lXeOiB+A73Puz+8PvFR5v9pExE0R0SMiehxx1O/qfNz333/HTz8lnak5s2czauRrrN51zVqOWjqzZ81k5owZCx+/OfJVuq6Vv4WRNuq2MZ9/PpFJk/7LvLlzefaZp9lxp50dbykNf/5ZdvhV/qbzH7nlqkz+aQ7/+uDbhds26tya3dZfmatf/oy55YuPjjWUQtVpViKCiy88j65rrsVh/QfkPV6pvCeyVOx1WuzxChWzGEgq6E+WPKXfzKwGERGS+gJXSjoD+JpkJP6PJFPmuwKj00X5vgb61pDW3HT6/1XpFPymwN9IZhFUdgHwkKQvgNeAit7zk8DDkvYFKs+BPhK4QVIr4BPgqHoWd4l9+83XXHL+OZQvKCcWBDv12ZVe2/fOa8zvv/uOC886FYDy8vns1GcPem7dK2/xmjZtylnnDOH4gb9jwYJy+u7Xj3XyeMtCsccDmDN7FmPffJ3j/3BOXtJfZ+VWbNt1RSZNm82QX68NwGPjp3DoZqvQtKwJp+3YFYBPvp3FPW9+2eDxs67Ts8/4A2+OGsm0adPYY5feDDzhJPruf0DtBy6hsWNG84+nn2Dtddej/8HJN5Uef9Igtt1+x7zEK4X3RNbnsNjrtNjjFSJm1m3Ulp4i8ndl28zMGq+pP83L9A/EzLnlWYajc9ulvUvCKvv06xm179SA/ndYjUtbNLhr+nXLNN688gW179SA5udxtkN1WjYvyzxmlrI+h83KPHnX6ifrNtpmuSbLxN3zva4YXtBO8IjTt8+sHjzCb2ZmZmZmZiXDi/aZmZmZmZmZWaPmEX4zMzMzMzMrGaX01YUe4TczMzMzMzMrQu7wm5mZmZmZmRUhT+k3MzMzMzOzkuEp/WZmZmZmZmbWqHmE38zMzMzMzEpGCQ3we4TfzMzMzMzMrBi5w29mZmZmZmZWhDyl38zMzMzMzEqGF+0zMzMzMzMzs0bNHX4zMzMzMzOzIuQp/WZmVqWZc8szjde5bYtM42VtXvmCQmch71o2L8s03oW7rpdpvEnfzco03mortcw03qy58zKNB9CSbNtM1pqVFffYWiE+17Ku01kZ/y3M+nO02NtodUpoRr9H+M3MzMzMzMyKkUf4zczMzMzMrGR40T4zMzMzMzMza9Tc4TczMzMzMzMrQp7Sb2ZmZmZmZiWjhGb0e4TfzMzMzMzMrBh5hN/MzMzMzMxKRpMSGuL3CL+ZmZmZmZlZEXKH38zMzMzMzKwIeUq/mZmZmZmZlYwSmtHvEX4zMzMzMzOzYuQRfjMzMzMzMysZKqEhfo/wlxhJ0wudh4Ym6TeSxkl6W9JYSbdIapdxHu6QdED6+BZJGzZAmu0knVDPY16UtGulbYMkXSdpH0ln1nBsD0lXLWl+a8nT++m5eUNS91r2v0DS4Hqk31XSYTnP81KO+qiuDOn2LySNkfSepOslFeRzOD0vPRoyzSP2351jf9OP4488iJN+e2hDJl2lEcOHsc+eu7LXbn249eab8h4v65gXDjmHPjv24qD99s5rnELGzLrNAJSXlzOw/4GcfdqJmcSb/tOPXHLuYI49vC/H/mY/3p0wNq/xsmyjc+bMYeARhzDg0P3pf9C+3HrjNXmNB9m/74v9cybreIX4XMuyfFO+mswJxwzg4P334tB+ezP0vrvzGq9CMbcZW3ru8FujJmk34FRg94jYCNgceAXoVMW+ZVnkKSJ+FxHvNEBS7YB6dfiB+4FDKm07BLg/Ip6IiEurOzAiRkXEKfWMV1eHR8SmwHXAFQ2cdldgYYc/z+VoCFdGRHdgQ2BjYMfCZqdhXX7NLVx/54Ncc9v9eY1TXl7OJRdfxHU33MJjTzzNs888xccffVRUMffepy9XX5/tP1KFiJlVm6nw6NB7WL3rmpnEArjpqsvZYqttufHex7nm9gfpskb+YmfdRps3b87fbriNO+5/lNvve5jXXxnB2+Pzd0Ej6/KVwudMsX+uZV2+srKmnHLaGQx99CluuesBHh56H59+7DZjheUOvyFpb0mvS3pL0r8ldUq3XyDptnQk8BNJp+Qcc146QvkvSfdXjGbmjhpKWlnSxPRxV0nDJY1Of7ZNtzdJR5/flvSUpGdyRsq3kPSSpDclPSdplSqyfw4wOCK+AIiI8oi4LSLeT9OYKGmIpJeBAyUdKmm8pAmSLsspz/ScxwdIuiN9fIekqyS9ktZBRd4k6RpJ70h6GuiYc3xuHUyXdHE6uv1aTt2unT5/Q9JF1cy8uBRYOx0NviKNeUWa9/GSDq7imIeBvSQtV1HvwC+AlyUNkHRNuv3ANJ2xkoal23pLeip9vJKkx5XMnHhN0ia1tYk6ehVYtaYYqU0l/UfSh5KOyanzqsp/KbB9Wk+nVipHa0m3p/uPk9RPUll6XivSObVyJrVk74lzlMxk+DfwyzrURXOgBfB9evzakp5N2/twSetLaiPpU0nN0n1WSNt0M0nd03obJ+kxSSum+7wo6TJJIyV9IGn7dHtLSQ+k+w8FWtb5rC2DJowfR5cua7Baly40a96c3fbYkxdfeL6oYm7eoycrtG2Xt/SXlZhZ+nrKV7w2Yjh77Nsvk3gzZ0xnwtjR/Hqv/QBo1qwZrduskLd4WbdRSbRq1QqA+fPnM3/+/LyuhJV1+Urhc6bYP9eyLt/KHTqw/gbJJM/ll1+ermuuxdSvp+YtHhR/m8mXJirsT6ZlzTacLaNeBraOiM2AB4Azcl5bH9gV2BI4P+1o9AD6AZsB+wN1mRY8FegTEZsDBwMVU673Jxmh3Rj4HbANQNrBuRo4ICK2AG4DLq4i3Y2A0bXEnh0R2wHDgMuAnYHuQE9JfeuQ91WA7YC9SDqXAPuRdOo2Bo4Btq3m2OWB19LR7WHpvgB/B/4eET2BL6s59kzg44joHhGnk9RVd2BTYBfgClW6CBIR3wIjgd3STYcAQyMiKqU9BNg1zdc+VcS+EHgrIjYBzgbuynltsTZRTf6rshvweB1ibALsSdIehkj6BdWX/0xgeFpPV1aKdx7wQ0RsnMb5T5rGqhHRLSI2Bm6vIp/1fU9sQVLXFe+JnjXUwamSxgCTgQ8iYky6/Sbg5LS9Dwaui4ifgBfTuiCN8UhEzEvr649pucYD5+fEaBoRWwKDcrYfD8xM978Y2KKGPC4ZwdmDjuPEow7hmccfbvDkc02dMoXOq3Re+Lxjp05MmTKl6GIWvQzbDMC1V17OsSedSpOM7qSZ/OUk2rZbkSsvGcLJvz2Yv196IbNnzcpbvEK00fLyco46rB/79NmBnlttw0bdNqn9oCWUdflK4XOm2D/XClm+L7/8gg/ef5dueXxPgNuM1c4dfgNYDXhO0njgdJJOdIWnI2JORHxD0mnvRNL5/b+ImJV2SJ6sQ4xmwM1pjIdIpjOTpvVQRCyIiK+AF9LtvwS6Af9KO0fnpvmslqSN01HejyuNfg9Nf/cEXoyIryNiPnAvsEMd8v54mr93+PlWgR1IpsmXR8SXJB3JqswFnkofv0lycQOSjuxD6eP76pAHSOqqIuYU4CWq7ljmTus/JH1e2QjgjnT0vKpbHbYD7gaIiP8A7SW1TV+rqk3U5l5Jk4A/klzIqS1GRfv6hqRNbFmP8ufaBbi24klEfA98Aqwl6Wolt4T8WMVx9X1PbA88FhEzI+JH4Ika8lQxpb8jsLykQyS1Jrlo9FDa3m8kudAEcAtwVPr4KOD2tJ7aRcRL6fY7WbQtP5r+zm1zOwD3pPUwDhhXVeYkDZQ0StKo++68tYZiVFGwG+7k2juGcvH/XssTjw5l/Ftv1uv4+ggqX8PK/wI8hYhZ7LJsM6++/BLtVlqJ9TbYqPadG8iC8nI++uA99uh7EFffNpQWLVvw0L235S1eIdpoWVkZt9/3CI888zzvvj2eTz76MG+xsi5fKXzOFPvnWqHKN3PmDM4a/HsGDT6L5Vu3zmsst5klI6mgP1lyh98g6YBdk452HksyzbjCnJzH5STf7FBTK53Pz+0qN51TgSkko7M9SKYzU0NaAt5OR227pyO0v65iv7dJ7tsnIsanHal/sOh05Rm1xAIW+fRqUem13DrITWPxT7zFzcsZXa+ovyVV10+Hx4FfSdocaBkRi82AiIjjSC6idAHGSGpfh1gV5aiqTdTmcGBNkosbFR3wmmJUrtuoZv/aqHJaaad/U5KR8xNJOtSV1fc9UVWea5SO0j9L0hFvAkzLae/dI2KDdL8RQFdJOwJlETGhDslX5LHy+ak1jxFxU0T0iIgehx15dH2KRPsOyZ0t7VZqT68ddua9d+uS1SXTqVNnvpr81cLnU6dMoWPHjjUc0ThjFrss28yEsW/xyrAXOLTvrvzp3NN5a9RILjm/2nVMG0T7Dp1YuUNH1t9oYwB69e7DR++/m7d4hWyjbdqswGZb9OT1V1/OW4ysy1cKnzPF/rlWiPLNnzePswYPYtfd92KnX/XJayxwm7HaucNvAG2BL9LHR9Zh/5eBvSW1SEcm98x5bSI/TxU+oFKMyRGxAOjPz6PKLwP9lNzL3wnonW5/H+ggaeEUf0lVDcv8D/AXSbmj/9Xdm/w6sKOStQXKgENJRokBpkjaQMmK6fvVUPYKw4BDlNwPvgqwUx2OyfUayW0RsPgiexV+AtpUinlwGrMDSUdxZOWDImI6SWf2Nqoe3UfS2hHxekQMAb4h6fjnGkbSSUdSb+CbdOS6WpKel7Rqda+nHdxzga0lbVBLjH3T9tWepE28UUP5K9dTrn8CJ+XkcUVJKwNNIuIRkin/m1dxXH3fE8OA/dL75NsAtS4/rOTy7rYkt238CHwq6cCK1yRtmrP7XSTn8naAiPgB+L7i/nyS99RL1Cy3vruR3DbRYGbPmsnMGTMWPn5z5Kt0XWudhgyxiI26bcznn09k0qT/Mm/uXJ595ml23GnnvMUrVMxilnWbOebEQTz41PPc//hznPfnK9isx5acfWG165g2iJXar0yHjp2Z9PlEAMa++Tqrd10rb/GybqPff/8dP/2UfGzPmT2bUSNfy+uCiFmXrxQ+Z4r9cy3r8kUEF194Hl3XXIvD+g/IW5xcbjNWm6UZbbTGqVU6tbrCX4ELSKYSf0HSEa3xr3VEvCHpCWAs8BkwCvghffkvwIOS+rPoNPfrgEfSDs0L/Dzq/gjwK2AC8AFJp/yHiJirZIG8q9Lpy02Bv5GM6Ofm5Zm08/ePtBM/LU3ruSryPVnSWWl8Ac9ExP+lL59JMvX+v+nxtc2/eoxkLYDxab5r62xVNgi4R9IfgKf5uf5y8/utpBGSJpDMWjiD5FaAsSQjtWekt0FU5X6Sad3VXUy4QtK6JPXwfJpm7mrxF5BMHR8HzKSWTm96oWQd4Lua9ouIWZL+l+Qe9dNriDGSpF5WB/4UEV9Keowqyi/pW2C+pLHAHcBbOen8Gbg2rcNyknUDPk7jVlzwPKuKrF5A/d4To5UshDeG5D0xvIbdT5X0G5LbXMaRvDcg6YxfL+nc9LUH0rJCcvvJn1n0As6RwA2SWpHcpnAUNbuen+t7DFVcLFoa33/3HReelax/WF4+n5367EHPrXs1ZIhFNG3alLPOGcLxA3/HggXl9N2vH+uss27e4hUi5tln/IE3R41k2rRp7LFLbwaecBJ99z+g9gMbScys20yhHDvoj1xx0dnMnzePzr9YlUFnX5S3WFm30W+/+ZpLzj+H8gXlxIJgpz670mv73nmLl3X5SuFzptg/17Iu39gxo/nH00+w9rrr0f/gZPzo+JMGse32+ftCnmJvM/myrN+FIKkLyYBPZ2ABcFNE/F3SBSRrgn2d7np2RDxTY1qLr+VlVjtJrSNietrZGAYMrGrqeD3Tak/SCelVQ0e2KKT1NisiQtIhwKERsW+h87Wk0hHj30bEaYXOSzFKL37tGxH9s4w78dvZmf6B6Ny28t00xWVe+YJCZyHvvp0+N9N4zcqynag4a255pvFWWynbL9P4cda8TOMBrNCyPuu+2rKmEJ9rxf6+b9k8k2+RLpgWTZfoFs0Gt+eNIwvaCX762C1rrId0BvEq6aBSG5J1mfoCBwHTI+IvdY3lEX5bUjdJ2pDk3uY7l7Szn3pKUjuS+/r/VOyd/dQWwDXptO5pwG8Lm52lk95X7s5+Hki6Gtgd2KPQeTEzMzMrBlo2rjtUKyImk3yjExHxk6R3Sb/aur7c4bclEhGHNWBavRsqrcYiIoaTLBxnVqOIOLnQeTAzMzOzwpDUleSrn18HegEnSTqC5LbqP6QLUlfLi/aZmZmZmZmZZUQ5X4Oc/gysZr/WJGueDUoXeb4eWBvoTjID4H9ri+URfjMzMzMzMysZTQo8oz8ibgJuqmkfSc1IOvv3RsSj6XFTcl6/mWTR8Rp5hN/MzMzMzMxsGZGu83Ur8G5E/DVn+yo5u+1H8u1iNfIIv5mZmZmZmdmyoxfQHxgvaUy67WzgUEndSb6ieiJwbG0JucNvZmZmZmZmJSMZQF92RcTLUOVXCTxT37Q8pd/MzMzMzMysCHmE38zMzMzMzErGMj7A36A8wm9mZmZmZmZWhNzhNzMzMzMzMytCntJvZmZmZmZmJaNJCc3p9wi/mZmZmZmZWRHyCL+ZmVWpWZmvCTekUqjPzm1bFDoLReXHWfMyjbdCy2aZxgOYV74g03il8D7MUinUZ8vmZYXOguVBCQ3we4TfzMzMzMzMrBi5w29mZmZmZmZWhDyl38zMzMzMzEqGSmhOv0f4zczMzMzMzIqQR/jNzMzMzMysZJTQAL9H+M3MzMzMzMyKkTv8ZmZmZmZmZkXIU/rNzMzMzMysZDQpoTn9HuE3MzMzMzMzK0Ie4TczMzMzM7OSUTrj+x7hNzMzMzMzMytK7vAvBUnTq9h2nKQj8hCrxnQl9Za0bX3zIam9pDHpz1eSvsh5vp6kCQ1Vhkpx95F0ZgOn2VrSjZI+lvS2pGGStmrgGD0kXZU+XqI6r0OMCySFpHVytp2abutRj3QGSLqmrvvkq+0uCUkvVlXWdPv7ksZKGiHplw0Ur9a6quKYiZJWTh+/0hD5qCJGjelKOrs++2ehvLycgf0P5OzTTsx7rBHDh7HPnruy1259uPXmm/IerxAxHa9xx8s65pw5cxh4xCEMOHR/+h+0L7feWK+PtSWSdZ1eOOQc+uzYi4P22zvvsaD424zjNf54hYhZiDLaknOHv4FFxA0RcVcB0u0NLOx81jUfEfFtRHSPiO7ADcCVOc/nLl2uqyapaUQ8ERGXNnDStwDfAetGxEbAAGDlhgwQEaMi4pT0aW+WoM7raDxwSM7zA4B3GijtKuWr7ebB4RGxKXAncEWhMwMQEdvWvlde0l2kw5+vfNTHo0PvYfWua+Y9Tnl5OZdcfBHX3XALjz3xNM8+8xQff/RRUcV0vMYdrxAxmzdvzt9uuI077n+U2+97mNdfGcHb48fmLV4h6nTvffpy9fXZdDBKoc04XuOOV4iYhShjPkgq6E+W3OFvYOno7OD08YuSLpM0UtIHkrZPt7eS9KCkcZKGSnq9YjQzd9aApAMk3VFFuqdIeic9/gFJXYHjgFPTkfntK+2/jqR/p6OioyWtXY8ilUm6OR0x/6eklmmaa0t6VtKbkoZLWj/dvoak59O8PS9p9XT7HZL+KukF4LJKI8sdJD0i6Y30p1e6fUf9PNvgLUltaqj3tYGtgHMjYgFARHwSEU+nr58maUL6MyjnuPMkvSfpX5Lur8O56y3pqZrqXNIGkkbmxOgqaVz6eAtJL6X19pykVaop0uPAvukxawE/AF/npHmopPFpeS7L2X5Umt+XgF4526us40p1uFRtt1JaQ9I4EyTdJCWfbDWk2zJty+MkDQVaVlMvuYYB60gqS9vXhLROTk3b5+ic/Kwr6c30cU9Jr6Tvh5E57eoXaZv+UNLltdV1pfJOT3/3Tsv4cNqu7s0p+x7ptpclXSXpqcr1nj6fkLav3HRXUTJjZUz6+vaSLgVaptvuzd0/fXxGmu+x6b6LfXbUoY7r5espX/HaiOHssW+/hk56MRPGj6NLlzVYrUsXmjVvzm577MmLLzxfVDEdr3HHK0RMSbRq1QqA+fPnM3/+fMjjP5aFqNPNe/Rkhbbt8hqjQim0Gcdr3PEKEbMQZbSl4w5//jWNiC2BQcD56bYTgO8jYhPgT8AW9UzzTGCz9PjjImIii47OD6+0/73Atemo6LbA5HrEWjc9diNgGlDxn/xNwMkRsQUwGLgu3X4NcFeat3uBq3LSWg/YJSL+UCnG39O890zTvyXdPhg4MZ1tsD0wq4Z8bgSMiYjyyi9I2gI4iuSCwNbAMZI2Szuq/YDNgP2Byh3Xqs4dADXVeUS8CzRPO+oABwMPSmoGXA0ckNbbbcDF1ZTnR+C/kroBhwJDc8rzC+AyYGegO9BTUt/04sGFJB39PsCGOelVV8c1WZq2e01E9IyIbiSd971qSfd4YGaa7sU1pJtrb5KZEN2BVSOiW0RsDNweER8DP0jqnu57FHCHpOYkdfn79P2wCz+3q+4k52pj4GBJXaqr61rytVlatg2BtYBekloANwK7R8R2QIc6lC/XYcBz6XthU5K2fiYwK21/h+fuLGl3oC+wVVrOigsYi3x21DMPtbr2yss59qRTaaL8/2mZOmUKnVfpvPB5x06dmDJlSlHFdLzGHa9QMcvLyznqsH7s02cHem61DRt12yRvsQpRviyVQptxvMYdrxAxi+V930SF/cm0rNmGK0mPpr/fBLqmj7cDHgCIiAnAuHqmOQ64V9JvgPk17ZiOXq4aEY+l8WZHxMx6xPo0Isakj98EukpqTXLh4CFJY0g6MhUj1dsA96WP7yYpa4WHquqQk3S6rknTegJYIc33COCvkk4B2kVEjWWtwXbAYxExIyKmk5yT7dPt/xcRsyLiJ+DJSsdVde7q6kHgoPTxwSSdzF8C3YB/pWU9F1ithjQeIJnW3xd4LGd7T+DFiPg6rZN7gR1ILmhUbJ9LzkUCqq/jmixN290pHf0fT9JZ3qiWdHcA7knTHVdDupC0/TEkFzYGA58Aa0m6WtJuJBdLILmocZSkMpJzcB/JOZgcEW+ksX7MaVfPR8QPETGb5PaJNai+rmsyMiImpTNNxqRlXB/4JCI+Tfe5v5Y0KnsjLcsFwMZpe63JLiQXPmYCRMR36fY6f3bU16svv0S7lVZivQ02qn3nBhDEYtuU5ylyWcd0vMYdr1Axy8rKuP2+R3jkmed59+3xfPLRh3mLVYjyZakU2ozjNe54hYhZ7O/7YuQOf/7NSX+X8/PXINb0rsh9F7WoZp89gWtJRkHflFTT1ysu7TtwTs7jijI0AaZV3Ouf/mxQzfG55ZlRzT5NgG1y0lo1In5K7/H/HckI8WtKbxuoxtvAplKVQ4vV1UFtdVPVuaurocBBktYDIiI+TOO9nVPOjSPi1zWk8STQH/g8In7M2V7X9pOryjqupQz1bbvJDslo9nUkMxk2Bm5m0bZcXb1Wl/fKDk/L0Dci/hsR35OMer8InMjPsxceAXYnmV3wZkR8m+a/ujhVtfUlef/UN535LPpZvNj7PiKGkVxo+AK4W7UvrlhdOWv97JA0UNIoSaPuuaMuE0ESE8a+xSvDXuDQvrvyp3NP561RI7nk/AZdl3MRnTp15qvJXy18PnXKFDp27Ji3eIWI6XiNO16hYlZo02YFNtuiJ6+/+nLeYhSyfFkohTbjeI07XiFiFvv7vhi5w18YL5OO/krakGQKcYUpSu4BbwLsV/nAdHuXiHgBOANoB7QGfgIWG7FNO4qTKqYhS1pOUqulyXya5qeSDkzTlKRN05df4efF5g5Py1qbfwInVTypmIYtae2IGB8RlwGjSEZJkfReFXn6ON3nwpx7pteVtC/Jvd59ldx/vjxJvQ5P87a3pBbprIU961ENUE2d5+SnHDiPn0fa3wc6SNomzV8zSdUOh0bELOCPLD7t/3VgR0krp6PXhwIvpdt7K/nmhWbAgTnHVFnHS6CmtluhosP6TVqvB9Qh3WEk7YX0NoY6z0FVslJ+k4h4hKS+N4dkNgvwHHA9cHu6+3sk9+r3TI9tU8sFs+rqur7eI5mF0DV9fnDOaxMr8ixpc2CxFe8krQFMjYibgVsr9gfmpee6sn8Cv614r0taqYbPjkVExE0R0SMievxmwO/qXMBjThzEg089z/2PP8d5f76CzXpsydkXNvS6nD/bqNvGfP75RCZN+i/z5s7l2WeeZsedds5bvELEdLzGHa8QMb///jt++im5Pjxn9mxGjXwtr4toFqJOs1QKbcbxGne8QsQslve9SmjRvlpHLZUsXvVnkvtcnyUZSRsUEffkOW+NQStJk3Ke/7WOx10H3KlkIbe3SKbZ/pC+dibwFPBfYAKL/0NeBtwjqS3JKN6VETFN0pPAw2kH9+RKx/QHbpR0ETCPpCP4SR3zWp3DgeslnQs0I5nmPRY4BbhN0ukki8wdVYe0TgGuTeujKUnn7zhgkKSdSDrO7wD/SDt31b1Lfgf8L/CRpJnAt8DpETFayeKHFQvp3RIRbwFIeiLN92ckFwx+WCzV6tVU55B09K8g7cBFxFxJBwBXpeevKfA3ktkJVYqIxRZWi4jJks4CXiCpi2ci4v/S8lwAvEqyTsNokvYC1ddxfdXUdivyN03SzST3108kmY5em+uB29N0x/DzuaqLVdNjKy5gnpXz2r0k6zP8M83bXEkHA1crWYByFsn09yrVVNf1ERGzJJ0APCvpGxYt3yPAEUpuU3gD+KCKJHoDp0uaB0wHKkb4bwLGSRqdex9/RDybXtQZJWku8AzJegmLfXbUtyzLiqZNm3LWOUM4fuDvWLCgnL779WOdddYtqpiO17jjFSLmt998zSXnn0P5gnJiQbBTn13ptX3vvMUrRJ2efcYfeHPUSKZNm8Yeu/Rm4Akn0Xf/ulxXrr9SaDOO17jjFSJmIcpoS0cRNc+ilTQmIrpL2o/kXuJTgRfShaBsCaQjhc0iYraS1eWfB9ZL77u2GkjaC1grIq6qdee6pdc6IqanI6HDgIERMbq240pVY2u7Sla/bxsR5y0DealoayKZVv9hRFxZ6HzV5Itpc+t6m0WDaN+6eZbhzJZ5P86al2m8FVpWNWEov+aVL8g0XrMyT241K6QWTZf6duMG8Zt7xmb6P05l9/xm08zqoS73JVd8+u8B3B8R32U9DaEItQJeSKfiCjh+We0wLWsi4qkGTvKmdGp6C+BOd/Zr1WjarqTHgLVJFg1cFhwj6UigOcnsiBsLnB8zMzOzklRK3dm6dPifTO+ZngWcIKkDMDu/2Spu6WJpi313uWUvIg4rdB4ak8bUdiNisTUwCikdzV+mR/TNzMzMrLjU2uGPiDMlXQb8GBHl6b3R++Y/a2ZmZmZmZmYNq5RmrNd6I1N6b/OJJItqAfyCRjLCZ2ZmZmZmZlaq6rJyye3AXGDb9PkkklX7zczMzMzMzGwZVZd7+NeOiIMlHQoLv16qdOZAmJmZmZmZWdFoUkK92bqM8M9Nv686ANKv4pqT11yZmZmZmZmZ2VKpywj/+cCzQBdJ9wK9gAH5zJSZmZmZmZlZPpTShPW6rNL/L0mjga1Jvnf79xHxTd5zZmZmZmZmZmZLrNYOv6Qd0oc/pb83lEREDMtftszMzMzMzMxsadRlSv/pOY9bAFsCbwI75yVHZmZmZmZmZnlSOhP66zalf+/c55K6AJfnLUdmZmZmZmZmttTqMsJf2SSgW0NnxMzMzMzMzCzfmnjRvp9Jupr0K/lIvsavOzA2j3kyM7NlwLzyBZnGmzW3PNN4P8yal2m8ti2bZRqvEP7nhY8yjff7XmtmGq996+aZxlsh4zZz6X8+zDQewO+3WyvTeM3KMg2X+eday+YZF7AAsv7b1KysLt9i3nhl3UZbNC3+NrqsqcsI/6icx/OB+yNiRJ7yY2ZmZmZmZmYNoC738N+ZRUbMzMzMzMzM8q2EZvRX3+GXNJ6fp/Iv8hIQEbFJ3nJlZmZmZmZmZkulphH+vTLLhZmZmZmZmVkGVEJD/NV2+CPisywzYmZmZmZmZmYNp9ZlJyVtLekNSdMlzZVULunHLDJnZmZmZmZmZkumLqv0XwMcAjwE9ACOANbJZ6bMzMzMzMzM8qGEZvTXqcNPRHwkqSwiyoHbJb2S53yZmZmZmZmZ2VKoS4d/pqTmwBhJlwOTgeXzmy0zMzMzMzOzhtekhIb4q72HX1KP9GH/dL+TgBlAF6Bf/rNmZmZmZmZmZkuqphH+myW1Bu4HHoiId4ALs8mWmZmZmZmZmS2Nmr6WbzNJvyRZsO9hSXP5ufPvr+wzKyKSArgnIvqnz5uS3L7zekTstQTpTQR6RMQ3lbbvA2wYEZc2QJ6rjJEvkp4BDouIaQ2Q1hXAHsAzEXH6EhzfG3gB2Ccinky3PQX8JSJelPQiMDgiRlU65v+AT4AWJJ/lDXoR94j9d6dlq1Y0KSujrKyMa267vyGTX8yUryZz4Xln8e2339BEom+/gzj4sP55jZllGbMuXxbxZn3/NaPv+xuzf/oeSayxza6svcM+zJ3xE6PuvpyZ302l1Uod6XHEH2neqnWDxq5QXl7O8QMOYeUOHbnkr9fmJUauEcOHcdmlF7OgfAH79TuQo48Z2KjjvXbv3/hywhu0aNOWPc6+DoDvJ33CG0OvZf6c2SzfviPbHnE6zVq2atC4UJj3fNbnrxTKmHW8C4ecw8svvciKK63Eg489mddYkH35so5ZiDaaDyU0o7/me/gj4n2SUf0LJW1K0vn/j6SvIqJXFhk0s0zMALpJahkRs4A+wBcNHSQingCeaOh0G4KkphExv7rXI2KPBgx3LNAhIubUZedq8jYJOAeoz38vwyNiL0nLk6zL8lREvFmP42t1+TW30Lbdig2ZZLXKyppyymlnsP4GGzJjxgwGHHYAW261DWuund8vksmqjFmXL4t4Kitjo31/S7vV1mbe7Jm8dOVpdFivO/9943lWXndT1vvVAXzw/MN8+PzDbLT3gAaLm+vRofewetc1mTljRl7Sz1VeXs4lF1/EjTffTqdOnTjs4APovdPOrL1Ofs5hFvHW2moX1tthL167+68Lt428/2o26/tbOq67MR+/+k/eff4RNtmr4TsAWb8nsj5/UPxlLESd7r1PXw4+5DCGnHNm3mJUKET5so5ZqL+9tuSqvYc/l6QmQEegE8mCfV/nM1NmVhD/APZMHx9KMqMHAElbSnpF0lvp71+m28sk/UXSeEnjJJ2ck97Jkkanr62f7j9A0jXp4zskXZWm94mkA3LinS7pjTTNOo9CS+og6ZH02Dck9aol/wMkPSTpSeCf6fNHJT0r6cN0odKKtCdKWllSV0nvSrpZ0tuS/imp5f+zd99xVlT3G8c/jwsI0owFsKDYC6ioYEdBJRorqBFLNBgVNTGKiUksiYkmGhOTGEssWFPsLT+jRk2MxN5AEOxGUVEEG4pKXb6/P+ZcuK677MLuncve+7x57Yt7586c7zlnzszumXNmblqnf8rz45LOkzSxnjzeSXYefVLSMElrSnogbfeApDWK6ucPkh4EflNPcccDn0ga3NT6KYiIz4ExwDqLu+3SZKWVV2bDjTYGoGPHjvRaa22mvT+tzLlqOXmXL4947buswPKrZ82ubfvl6NxtdWZ98iFTJj7FGv13BmCN/jszZeKTLRq34P2p7/HEow+zx775PIpo4oTn6NlzTVbv2ZO27dqx+x57MvrBB1p1vG7r9qHdcp2/tOzTaZNZed0+APTYcHPeHl+aL3PK+5jIe/9B5ZexHHW6Rb/+dOm6fEljFJSjfHnHrPTfvZVokR1+SQMkXUI2kvQj4BFgg4gYkkPezCxfNwIHSWoPbAoU/8X9ErBjRGwOnAGck5aPANYCNo+ITYHrirb5ICK2AC4FTm4g5irADsBewLkAkr4OrAdsBfQFtpS0YxPLcAFwfkT0J3u46JWN5B9gW+DbEbFzet8XGAZsAgyT1LOeOOsBf4qI3sB0Fj7I9Brg2IjYFqitL4MRsQ8wMyL6RsRNwMXAX4rq78Ki1dcHdo2IHzZQ3l8BP23gswZJWhHYBnh+cbdddMJw2shj+d4RB3HP329t0aQb8+677/DKyy/Sp8+mpQ1UpjLmVr4c433x0VQ+eed1vrbmBsyeMZ32XVYAsosCcz6bXpKYfzr/txxz/EksoyaNdzTbtKlT6bFKjwXvu3XvztSpUysmXsHyq6zJOxOyXxlvP/sIX3xc+jut8mij5arPgkosY7nrtNTKUb5y1mnev5takqSy/uSpwSn9kt4G3iLrBJwZEZVzNJrZV0TEc5J6kY3u31Pn467AnyWtBwTQNi3fFbisMN08Ij4q2ub29P8YYL8Gwv49IuYDL0jqnpZ9Pf08m953IutgP9SEYuwKbFx0Iu0iqfMi8g/wrzr5fiAiPgGQ9AKwJvB2nThvRMS4ovL1krQ80DkiCkNb15NdyGjMtiysn78Cvy367JaIqPfCAUBEPJx+cQxoQhyAAZKeBeYD50ZEi3b4z7/sz6y4cjemf/Qhp4w8lp5rrsUmm2/ZkiHq9cUXn3PqyScy8uRT6dipNPd9F5SjjHmWL69482bP5Klrz6XPkKNo277l7/Wuz+OP/JflV1iB9TfqzbgxT+cSM4ivLCvlH3p5xyvY+pATGXPbKCbeewOr9dmaZWqa8q3PSy6vY6Jc9QmVW8Zy1mkeylG+ctVp3r+bbMkt6oy8gx/OZ1Z17gR+BwwEVixa/kvgwYgYmi4KjE7LBfX8pskU7k+vpeFzTfE97Cr6/9cRcfniZDxZBtg2PYdgYcLSRdSff8ieX9BQnhrKe911OrAw/81VXJ9Nucn4bLJ7+Rt8/kCRhxt7CKOkEWQzNzj79xdzyLePbEKymRVX7gbA8iusyPY77sxLL04seWd43ty5nHrySHb7xl4M2mWx725YbHmXMe/y5RFvfu08nrr2XFbfYidW3XQ7AJbtvDyzPv2I9l1WYNanH9Gu0/ItHnfi+Gd57KEHefKxh5kzezZffP455/z8FE47s9nPEG1Q9+49eG/KewveT5s6lW7dulVMvIIuPXoy6Hu/BODTae/w7vOlu6CS5zFRrvqs5DKWq07zUo7ylSNm3r+bSiGfeV5LhwbL6s6+WVW6GjgrIibUWd6VhQ/xG160/H7gWGVP9UfSCi2Qh/uA7yj7WlAkrSapqb+57geOL7yR1De9bCj/LSYiPgZmSNomLTqoiZs+VrTuoWS3Ti1O3PuBrwGbLc52i0hvVET0i4h+i9PZnzXziwUPQZs18wvGPPU4vdYu7QN8IoKzz/wZvdZam0MOG17SWJB/GfMuXx7xIoJnb7qIzt1WZ92BQxYsX6X3Vrz19H8AeOvp/7BKn61aPPbR3xvJzXc9wA1/v4+f/eo8Nu+3VUk7+wC9+2zCW29NYvLkt5k7Zw733nM3Ow3aufENW0m8glkzpgMQ8+fz/L03su4O3yhJnLyPiXLUZ6WXsVxtNC/lKF/eMfNuo9Z8pZ1zZWatSkRMJrsPvq7fkk2J/wHwn6LlV5LdZ/6cpLnAFWT3pDcnD/dL2gh4PE1J+wz4FlDfE2GekzQ/vb4ZOAH4k6TnyM5vDwHHLiL/Le1I4ApJn5PNIvikCducAFwt6UdkD0Q9Ygnink32lXvF7k77BOBxoKTfP/bxRx9x5qknAVBbO49Bg/eg/zal/TKX8ePG8s+772Sd9dbnsGFDATju+JFsN2CnksTLu4x5ly+PeB+98SKTn3mQLqusyYO/OxGAjfc4jPV22Z+n//Jb3nryX3T42sr0P/wnLRaznNq0acOpp5/BcSOOYv78WoYM3Z91112vVcd79JrfMu21Ccz+7FP+/rNvs8kehzJv9kxefehuAFbfbDvW3qY0I355HxN57z+o/DKWo05P+/EPGfPMU0yfPp09dh3IiO8ez5D9Dmh8wyVQjvLlHTPvNmrNp4iGZuOamdnikNQpIj5Lr08BVomIE8ucrSU26cNZuf6C6NqhbeMrtaBPZs5tfKUWlHf5yuHXD76Wa7wTt18r13grdmqXa7y8nfufV3OPeeIOa+car0O7mlzjzZzT4GNYSiLv8pXD3Nr5ja/UgtrWVPbk77zb6NeWq1kqHtpwwt9fKmsn+MIhG+ZWD4t6aN9FNHxvLhFxQklyZGbWeu0p6VSyc+ublOj2ATMzMzOzpljUlP5ncsuFmVkFSF+zd1O582FmZmZmDVtmqZhnkI8GO/wR8ec8M2JmZmZmZmZmLafRh/ZJWhn4CbAx0L6wPCIq55GaZmZmZmZmZhWmKU+huA54EVgLOBOYBJTuC1bNzMzMzMzMSmQZlfcn17I2YZ0VI+IqYG5E/DcivgNs09hGZmZmZmZmZlY+jU7pBwrfWzRF0p7Au8DqpcuSmZmZmZmZWWlI1fPUvqZ0+H8lqSvwQ+AioAtwUklzZWZmZmZmZmbN0miHPyLuSi8/AQaVNjtmZmZmZmZm1UtST+AvQA9gPjAqIi6QtALZV0D3Inu23oER8fGi0mrKU/qvAaLu8nQvv5mZmZmZmVmrkfeD85bAPOCHETFWUmdgjKR/AcOBByLiXEmnAKeQfaNeg5oypf+uotftgaFk9/GbmZmZmZmZWQuKiCnAlPR6hqQXgdWAfYGBabU/A6Npboc/Im4rfi/pBuDfi5tpMzMzMzMzs3JrTc/sk9QL2Bx4EuieLgYQEVMkdWts+6Z8LV9d6wFrLMF2ZmZmZmZmZlVN0ghJzxT9jGhgvU7AbcDIiPh0SWI15R7+GXz5Hv73aGTagJmZtX7LtavJNV6HCo83c05trvHK4bDNVss1Xt5ttNJ9d9teucdcdfsTc4338dMX5xrP55mWl3edzq2dn2u8tjVLMh675PKuT8tExChg1KLWkdSWrLN/XUTcnhZPlbRKGt1fBZjWWKymTOnv3IQ8m5mZmZmZmS31llnK5/RLEnAV8GJE/KHoozuBbwPnpv//r7G0Gr2EJOmBpiwzMzMzMzMzs2bbHjgM2FnSuPSzB1lHf7CkV4HB6f0iNTjCL6k9sBywkqSvAYXLIF2AVZtZADMzMzMzMzOrIyIeYWH/u65dFietRU3pPwYYSda5H1MU8FPgT4sTxMzMzMzMzGxpkO+TEsqrwQ5/RFwAXCDp+xFxUY55MjMzMzMzM7NmasrFjfmSli+8kfQ1Sd8tXZbMzMzMzMzMSkMq70+emtLhPzoiphfeRMTHwNEly5GZmZmZmZmZNVtTOvzLpK8FAEBSDdCudFkyMzMzMzMzs+Za1EP7Cu4DbpZ0GRDAscC9Jc2VmZmZmZmZWQksk/e8+jJqSof/J8AI4DiyJ/XfD1xRykyZmZmZmZmZWfM02uGPiPnAZekHSTsAFwHfK23WzMzMzMzMzFpWFQ3wN2mEH0l9gYOBYcAbwO0lzJOZmZmZmZmZNVODD+2TtL6kMyS9CFwMTAYUEYMi4qLccmhWApJC0l+L3reR9L6ku5YwvUmSVqpn+T6STmlOXlM6T0oaJ+mtlM9x6adXc9OuJ9YvJJ3cyDpDJG1c9P4sSbu2dF4Wl6SB9e3DtDwkHVm0bPO0rLGyLkgzvd6u6LNjJR2eXl8r6YD0+sri+im1hmJLOi2vPMyePZsRhx/E8IP347AD9+Wqyy8uecxHH36Iffbcjb12H8xVV4wqeby8Y059bwrfPXo4w/bbi4P335ubrv9r4xu1ongA/7j1OkZ+55ucdOSBnP+r05gzZ3ZJ45WjjHm30zzj5XncL7OMePyGn3DbBccCcM7IIYy7/ac8ddOp3PT7o+naqUNJ4vo807rjQf778MwzTmfwTttz4NC9Sx6roJLPM9Z8ixrhfwl4GNg7Il4DkHRSLrkyK73PgT6SOkTETGAw8E5LB4mIO4E7WyCdrQEkDQf6RcTxxZ9LahMR85obZzEMAe4CXkj5OyPH2EtqAtkspavS+4OA8YuZxkDgM+AxgIi4rL6VIuKoJcti89WJfRpwTh5x27Vrxx8vu5rllluOefPm8t0jD2eb7QbQe5PNShKvtraWc84+i8uvuIbu3btzyLADGDhoZ9ZZd92SxCtHzJqaNpzwgx+z4UYb8/nnnzP8kAPYauttWWudyoj34fvT+OcdN3L+1bew7LLt+f1ZP+HR/9zHoN33KUk8yL+MebeZvOPledwff8ggXn5jKp07tgfggSde4mcX3Ult7Xx+dcK+/Og7X+enF/5fi8b0eab1xyvHPtx7nyEMO+gQzji92eM9TVLp55lSWaaKpvQv6mv59gfeAx6UdIWkXcge2mdWKf4J7JleHwzcUPhA0laSHpP0bPp/g7S8RtLvJE2Q9Jyk7xel931JY9NnG6b1h0u6OL2+VtKFKb3XCyOy6bMfSXo6pXlmUzKfRuJHSbof+IukXpIeTnkYWxiJTqPSoyXdKuklSdcVvmpT0rmSXkhxf1dPjKNTvsZLuk3ScindfYDz0iyDdeqMMO+S6m2CpKslLZuWT5J0Zt06qhNvScqwe1r2CLDfIqrsLaC9pO5p293J2kAh9mhJ/dLrlSRNqps3sm8pOSmVe4AamA1RJ63PJJ2d6vAJSd3T8nXS+6eVzZD4rKisdxWldXG60IOyWVdPS5qY9v1XzsmF2JLOBTqkvF4n6ZeSTixa72xJJyyivhaLJJZbbjkA5s2bx7x580p6g9zECc/Rs+earN6zJ23btWP3PfZk9IMPlCxeOWKutPLKbLhRNlGkY8eO9Fprbaa9P61i4kH2h+Oc2bOprZ3H7Fmz+NpKK5c0Xt5lzLvN5B0vr+N+tW7Ls/sOvbnmjscWLHvgiZeorZ0PwFMT3mC17su3eFyfZ1p/vHLswy369adL1+VLGqNYpZ9nrPka7PBHxB0RMQzYEBgNnAR0l3SppK/nlD+zUroROEhSe2BT4Mmiz14CdoyIzYEzWDhKOgJYC9g8IjYFriva5oOI2AK4FGhomvgqwA7AXsC5AOl4Wg/YCugLbClpxyaWYUtg34g4BJgGDE55GAZcWLTe5sBIYGNgbWB7SSsAQ4HeqSy/qif92yOif0RsBrwIHBkRj5HNWvhRRPSNiP8VVk51eS0wLCI2IZtFdFxReo3V0eKWoT3Zt4bsDQwAeiyirgBuBb4JbAeMBZo8fzgiJpE9vPT8VO6Hm7hpR+CJVIcPAUen5RcAF0REf+DdJqZ1cdoffYAOZO2oofyeAsxMeT2UbGbDtwEkLUM2w+G6hrZfErW1tRxxyP7sM3hH+m+9Lb37bNqSyX/JtKlT6bHKwt3drXt3pk6dWrJ45YpZ8O677/DKyy/Sp4R1mne8FVfuxj7f/BbHHbwnR39zN5br1Im+/bYtWby68ihj3m2mHG00j+P+vB/tz+kX/J3586Pezw/fd1vue/SFFo/r80zrj1fO+sxLNZxnSmEZqaw/uZa1sRUi4vOIuC4i9gJWB8YB+cxRMSuhiHgO6EU2un9PnY+7ArdImgicD/ROy3cFLitMn4+Ij4q2KTzMckxKtz5/j4j5EfEC0D0t+3r6eZasE7oh2QWAprgz3ZIA0Ba4QtIE4BayjnHBUxExOX3rxriUv0+BWcCVkvYDvqgn/T5pxH0CcCgL66EhGwBvRMQr6f2fgeKLF43V0eKWYcMU79WICOBvjeTvZrIO/5dmdJTYHLLbH+DL5d6WrIwA1zcxrUHKnucwAdiZxvfHAumCxYeSNie1t4j4sO56kkZIekbSM3+55sqmJg9ATU0N11x/G7fd8wAvPj+B1197dbG2XxzBV//wr2fCQ6uPCfDFF59z6sknMvLkU+nYqVPFxPtsxqc8/dh/+dN1/2DUzfcye+ZMHvpX3VNxaeRVxrzbTDnaaKmP+28M6MO0j2bw7Itv1/v5j4/cjdra+dx4z9MtGhd8nqmEeOWqzzxVw3nGmqdJT+kvSJ2by9OPWSW4E/gd2b3ZKxYt/yXwYEQMTVO5R6flgnrOdJnCaHEtDR9bxSPKKvr/1xGxJMfV50WvTwKmApuRXcyb1UDcWqBNRMyTtBWwC9lo7/Fknchi1wJDImJ8mlY+sJH8NHbGb6yOFqsM6XVD++MrIuI9SXPJntlwItlIf8E8Fl4Ebd/UNJtgbroYAYtuG/XlY0Fe0myGS8ie4fC2pF8sQT6vBIaTzYS4ur4VImIUMApg2oy5Ta7bYp07d2HzLfvz5OOPsPa6Tb12tXi6d+/Be1PeW/B+2tSpdOvWrSSxyhlz3ty5nHrySHb7xl4M2mVwSWPlHe+5sU/SrcdqdF3+awBsPWBnXn5hPDsO3qOkcfMsY95tphxttKBUx/22fddmr502YfcderNsu7Z06dieq391ON/56V84dO+t2WPHPnzjmAsbT2gJ+DzT+uOV85jISzWdZ2zJNDrCb1bhrgbOiogJdZZ3ZeFD/IYXLb8fOFZSG4A0Lb657gO+I6lTSnM1SUty5uwKTEkj4IcBNYtaOcXrGhH3kE2V71vPap2BKZLako3wF8xIn9X1EtBLUuHJLYcB/y1VGVK8tSStk94f3IQYZwA/iYjaOssnkd0iAXAA9Wuo3EviCbJnpUB2waXgTWBjSctK6kp2QQYWdu4/SPuuoTwWm5v2XcEdZM8u6E/W7lrMxx9/xIwZnwIwe9YsnnnqCdbotVZLhviS3n024a23JjF58tvMnTOHe++5m50G1b1e1bpjRgRnn/kzeq21NoccNrxkccoVb6VuPXjlxQnMnjWTiGDC2KdYbY3StRnIv4x5t5m84+Vx3J9x0Z2su/vP2HDPn3P4Kdcw+ulX+M5P/8Lg7Tbih8N35YCRlzNz1twWjVng80zrj1eOfZi3Sj/PlIpU3p88LdYIv1mliYjJZPdS1/Vb4M+SfgD8p2j5lcD6wHNppPgKsq+tbE4e7pe0EfB4mhL1GfAtsvvZF8clwG2Svgk8yJdH/+vTGfi/NHIsstH1un5G9myDN8mecl/o7N5INvX+BIo6nhExS9IRZLdDtAGeJrvvvSRlSPFGAHdL+gB4BOjTyDaPNfDR74CbJR3Gl/d5sX8At0raF/h+A+s01Ujgb5J+CNwNfJLy97akm4HngFfJbvUgIqZLuoJsP0wiq9vGjCJrq2Mj4tCImCPpQWB6PRc8muXDD97nnJ+fTu38WmJ+MGjwbmw/YGBLhviSNm3acOrpZ3DciKOYP7+WIUP3Z90SzSYoV8zx48byz7vvZJ311uewYUMBOO74kWw3YKeKiLf+Rpuw7Y678KNjD6Wmpg1rrbsBg/dc1HM3my/vMubdZvKOl/dxX+z8nxzIsu3acNel2ZfWPDVhEiecfWOLxvB5pvXHK8c+PO3HP2TMM08xffp09th1ICO+ezxD9mvKNfolU+nnGWs+LZxpamZmeZG0HNlD9ULSQcDBEbFviWMuQ/aciG9GRKM32i7plP4l1aVD28ZXasVmzmnRayxLpckfzWx8pRa0+gql+e71hnRo19iko9bt05mlGSlflDV3zPcbnz9+ulnX6Jd61XCeyfs4nJu+DSIvbWsqewJ2+zZLx7e+nf3Aa2XtBJ++y7q51YNH+M3MymNL4OL01XrTge+UMpikjckeHnhHUzr7ZmZmZtb6ucNvZlYG6Wv9Nssx3gtkX2doZmZmZlXCHX4zMzMzMzOrGlo67izIRWXfJGJmZmZmZmZWpTzCb2ZmZmZmZlVjmeoZ4PcIv5mZmZmZmVklcoffzMzMzMzMrAJ5Sr+ZmZmZmZlVDU/pNzMzMzMzM7NWzR1+MzMzMzMzswrkKf1mZmZmZmZWNaTqmdPvEX4zMzMzMzOzCuQRfjMzMzMzM6sa1fTQPnf4zcysXh3a1ZQ7CxUl7/qcWzs/13gA3bsum2s8t9GW1bYm/4mfHz99ca7xZs6pzTVe3m20TU2+vZhytJm8VUMZrbK5BZuZmZmZmZlVII/wm5mZmZmZWdWoomf2eYTfzMzMzMzMrBJ5hN/MzMzMzMyqxjJVNMTvEX4zMzMzMzOzCuQOv5mZmZmZmVkF8pR+MzMzMzMzqxrLVM+Mfo/wm5mZmZmZmVUij/CbmZmZmZlZ1aiiZ/Z5hN/MzMzMzMysErnDb2ZmZmZmZlaB3OG3ZpNUK2mcpImSbpG0nKRekiaWOO5ASXeVMkadeJMkPVxn2biWLKekzxZz/V9IOrml4re0hvaRpGcl9U2v20j6XNK3ij4fI2mLJYxZb51I2kDS6LTPXpQ0aknSLyVJwyWturjrSbpS0salzV3jzjzjdAbvtD0HDt07l3iPPvwQ++y5G3vtPpirrshnd+YdM+94ee7D2bNnM+Lwgxh+8H4cduC+XHX5xSWP6TbTsqa+N4XvHj2cYfvtxcH7781N1/+1pPGg8ssH+ZYx7/M2VPYxUY545YhZjjK2tGVQWX/yLatZ882MiL4R0QeYAxxb7gyVUGdJPQEkbbS4G0vyczMyjwHbpdebAS8X3kvqCKwNjG8sEWWaeh67EDg/tdWNgIsWO9elNxxotMNfd72IOCoiXihRnpps732GcNGl+fzir62t5Zyzz+KSy67kjjvv5t577uJ/r71WUTHLUcY892G7du3442VXc+0Nt3PN9bfy5GOP8vyERg/7JeY20/Jqatpwwg9+zE2338WVf7mRW2+6njf+5/I1R95lzPOYh8o/JnyesaWRO/zW0h4G1k2vayRdIel5SfdL6gAgqa+kJyQ9J+kOSV9Ly0dL+o2kpyS9ImlAWt5e0jWSJqSR4UF1g0paQdLfU5pPSNo0LV9Z0r8kjZV0uaQ3Ja0k6ZeSTiza/mxJJzShfDcDw9Lrg4EbitKoN59pNPYWSf8A7k+j3g+lsr8g6bLiTmvKy/hUju5p2ZqSHkjle0DSGvXUQUP12j8te1zSeYUZCZIeLoyyp/ePFuqtaFmvtN7Y9FPolA9M++tWSS9Juk7KHn8iafe07BFgvwbq8VEWdvi3Ay4DCnnZChgbEbWSfqBs5shESSOL8vSipEuAsUBPSadLelnSv4ENGoi5CjC58CYiJqT0alK9PJ3q6Zi0fBlJl6T2e5ekeyQdkD6bJOmcVKfPSNpC0n2S/idpwQUvST8qSvfMOvn/0rGR0u4HXKdsFkIHSWek7SdKGqVMfeuNltQvpX9waoMTJf2mKC+f1de2WtIW/frTpevyLZ1svSZOeI6ePddk9Z49aduuHbvvsSejH3ygomKWo4x57kNJLLfccgDMmzePefPmlfQpSm4zLW+llVdmw42yyUUdO3ak11prM+39aSWLV+nlg/zLmOcxD5V/TPg803pI5f3Jkzv81mKUjV5/A5iQFq0H/CkiegPTgf3T8r8AP4mITdO6Py9Kpk1EbAWMLFr+PYCI2ISsk/1nSe3rhD8TeDaleVqKQUrjPxGxBXAHUOgoXwV8O+V7GeAg4LomFPNWFnZi9wb+UfTZovK5LfDtiNg5vd8K+CGwCbBOUZodgSciYjPgIeDotPxi4C+pfNeRjVbX1VC9XgMcGxHbArVF619JNlKMpPWBZSPiuTppTgMGp/obVifu5mT7aWOyEfntU3mvSHUzAOhRTz7hyyP826WyzpbUOb1/VNKWwBHA1sA2wNGSNk/bbJDqY3NgJbL9tzlZPfZvIOb5wH8k/VPSSZKWT8uPBD6JiP5p26MlrZXS6kW2j44i24fF3k51+jBwLXBAyudZAJK+TnYMbEV2MWNLSTumbb9ybETErcAzwKFpFsJM4OKI6J9mz3QA9mpgPVLMVYHfADunmP0lDUkfN9S2WqVpU6fSY5WFzatb9+5MnTq1omKWo4x5q62t5YhD9mefwTvSf+tt6d1n08Y3WkJuM6X17rvv8MrLL9KnwvZhQR7lg8o/7iv9mPB5xpZG7vBbS+ggaRxZJ+Qtss40wBsRMS69HgP0ktQVWD4i/puW/xnYsSit24vXT693AP4KEBEvAW8C69fJQ/E6/wFWTLF2AG5My+8FPk6vJwEfpg7k18kuFnzYhLJ+BHws6SDgReCLBvJQN5//ioiPitZ9KiJej4haslkCO6Tlc4DCPe/FdbAtcH16/dei9QFoqF5Tp7ZzRDyWll9ftNktwF6S2gLfIeu01tUWuELShLR+8X3iT0XE5IiYD4xLed2QbL+/GhEB/K2eNAv1305Sj7TNy8DTZJ377cguCOwA3BERn0fEZ2RtY0BK4s2IeCK9HpDW+yIiPgXubCDmNcBGqRwDgSckLUu2/w9PbfhJYEWyDvkOwC0RMT8i3gMerJNkIc4E4MmImBER7wOzUr1/Pf08SzYTYcOULtRzbNSXZ2CQpCdT/e8M9G5gvYL+wOiIeD8i5pFdHCocXw21rVYpiK8sU4kvmecdsxxlzFtNTQ3XXH8bt93zAC8+P4HXX3u1ZLHcZkrniy8+59STT2TkyafSsVOnksWp9PJB5R/3lX5M+DxjSyPfT2wtYWZE9C1ekA782UWLaslGKBtT2KaWhe2zKWeR+taJRrYtjHD3AK5uQoyCm4A/pW0by0PB5/Xkrb73c1NHGb5cB3V99WxbvwbzFBFfSPoXsC9wINk08bpOAqaS3We/DDCr6LO6+7eQ16bm7XGyUfEpERGSngC2JxsRf4Ksg9yQxuqzXhHxLtm+vlrZrQ19yOro+xFxX/G6kvZsJLlC+efz5bqYT1YXAn4dEZfXSbcXTTg20myJS4B+EfG2pF8AdWe2fGWzRXzWpLYlaQQwAuCCiy/liKNGNBKyPLp378F7U95b8H7a1Kl069atomKWo4zl0rlzFzbfsj9PPv4Ia6+7XuMbLAG3mdKYN3cup548kt2+sReDdhlc0liVXj6o/OO+0o8Jn2daj2Wq6BqFR/gtVxHxCdkIeWGk9jDgv4vYBLLpx4fCgqnna5CNCDe0zkDggzTa+whZZ7YwxfprRdvcAexONiq6oLMn6aVG8nMH8NvibRYjnwVbSVor3U4wLOVzUR4jm7ZOivGl9Ruq14j4GJghaZu0/CC+7EqyafpP15mBUNCVrEM+P6VZ00g+XwLWkrROen/wItZ9lOyCwuPp/ePA4cB7ETGdrD6HKPvWh47AULLp83U9BAxN97J3Jrud4CuUPVugbXrdg2wk/x2y/Xhc0Wfrp3iPAPsru5e/O9msgMVxH/AdSZ1SuqtJauw34gygc3pd6Nx/kNI4oIH1ij0J7KTsORU1ZPXf2PH1JRExKiL6RUS/pbWzD9C7zya89dYkJk9+m7lz5nDvPXez06CdG9+wFcUsRxnz9PHHHzFjxqcAzJ41i2eeeoI1eq1VsnhuMy0vIjj7zJ/Ra621OeSw4SWLU1Dp5YPKP+4r/ZjwecaWRh7ht3L4NnCZpOWA18nu016US9L6E4B5wPCImF1n+tAvgGskPUc2zf7bafmZwA2ShpF1fKaQdZaIiDmSHgSmp6n1SFqJRmYURMQMsvuk605hako+Cx4HziW7P/whsosIi3IC2aj0j4D3qb/OGqrXI8mm5X8OjAY+KSrLGEmfkt3nX59LgNskfZNsSnvdkfUviYhZaYT4bkkfkHWa+zSw+qNk99U/nradkjqpj6X3YyVdCzyV1r8yIp5NI+TFMcdKuonstoI3qf+iAGTT6y+QVJil8KOIeE/SlWTT28cq21nvA0OA24BdgInAK2Sd6U/qJtqQiLhf2Tc5PJ7awGfAt/jycxTqupZsH84ku43jCrJbBiaR3fLQ0HqFmFMknUq2rwTcExH/19Q8N9dpP/4hY555iunTp7PHrgMZ8d3jGbLfAY1vuATatGnDqaefwXEjjmL+/FqGDN2fdUs0MlyumOUoY5778MMP3uecn59O7fxaYn4waPBubD9gYEligdtMKYwfN5Z/3n0n66y3PocNGwrAccePZLsBO5UkXqWXD/IvY57HPFT+MeHzTOuxTBXdhqCFMzzNKk+6R7s2IuZJ2ha4tHD7QRpdHwt8MyJeTcv2AtaOiPoeitdSeRoInBwRe5UqRp14ndI98Eg6BVglIk5M71cluwiwYRrFtyKFupO0ItmFh+3T/fxVYcbs+bn+gmhb40lnLWlubf6H9Mw5i7qe1fK6dGiba7xKl/f+A+jQrrGJYy0r7zLmXb68j3uft21xtW+T85fQN2DUE2+WtRM8Yps1c6sHj/BbpVsDuDl17ueQnkwuaWOyB5jdUejsA0TEXfWm0rrtmUZ925CNgA8HkHQ4cDbwA3f2G3RXegBfO+CX1dTZNzMzM7PWzyP8ZmZWL4/wt24e4bfF5RH+lucRfrMvW1pG+K94srwj/Edvnd8Iv49SMzMzMzMzswrkDr+ZmZmZmZlZBfI9/GZmZmZmZlY1qukp/R7hNzMzMzMzM6tAHuE3MzMzMzOzqlFFA/we4TczMzMzMzOrRO7wm5mZmZmZmVUgT+k3MzMzMzOzqlFNo97VVFYzMzMzMzOzquERfjMzMzMzM6saqqKn9nmE38zMzMzMzKwCeYTfzMyq0sw5teXOQkl1aFeTe8x5NZFrvLz34QOvTss13l69V8k1XjXI+7h4+NUPco23zdor5Bpvbu38XOMBtK3xeKXZ4nCH38zMzMzMzKpG9Uzo95R+MzMzMzMzs4rkEX4zMzMzMzOrGsv4oX1mZmZmZmZmVg6SrpY0TdLEomW/kPSOpHHpZ4/G0nGH38zMzMzMzGzpci2wez3Lz4+IvunnnsYS8ZR+MzMzMzMzqxqtYUJ/RDwkqVdz0/EIv5mZmZmZmVlOJI2Q9EzRz4jF2Px4Sc+lKf9fa2xld/jNzMzMzMysakjl/YmIURHRr+hnVBOzfimwDtAXmAL8vrEN3OE3MzMzMzMzW8pFxNSIqI2I+cAVwFaNbeMOv5mZmZmZmdlSTtIqRW+HAhMbWrfAD+0zMzMzMzOzqiEt/Y/tk3QDMBBYSdJk4OfAQEl9gQAmAcc0lo5H+M0sV5JWl/R/kl6V9LqkiyUt28IxhkjauOj9WZJ2bcH0L0jfgVr2c6ikfSSdUu58AJx5xukM3ml7Dhy6dy7xHn34IfbZczf22n0wV13R1FvfltzU96bw3aOHM2y/vTh4/7256fq/VlQ8yLdOy1G+PGLedslvOOeoIVzww+Ff+ezhO2/k9AMH8vmn01s8bkGl78O8j/s84v3tonM45dt7cvYJ31qw7I5rL+aX3zuYc048nFG/PpUvPptRkth5n7fzjgeV2WbKHbMcZaxGEXFwRKwSEW0jYvWIuCoiDouITSJi04jYJyKmNJZO2f9YNbPqoexy6u3A3yNiPWA9oAPw2xYONQRY0OGPiDMi4t8tkXDq5A8F3gZ2bIk0m5GXNhFxZ0ScW858FOy9zxAuujSfX/y1tbWcc/ZZXHLZldxx593ce89d/O+110oas6amDSf84MfcdPtdXPmXG7n1put543+li5l3vLzrNO/y5RVzi4G78+3TvnpKm/7BNF6bMIblV+reovGKVfo+zLt8ecXbZuc9+N4Zf/jSsg03689pF/6V0y74C91W7cn9t5XmYkqe5+1yxKvUNlPOmOUoozWPO/xmlqedgVkRcQ1ARNQCJwGHS+okabikiwsrS7pL0sD0+uuSHpc0VtItkjql5edKeiF9PcnvJG0H7AOcJ2mcpHUkXSvpgLT+LpKelTQhfZ3Jsmn5JElnpvQnSNqwgTIMIrtf6lLg4KK8/iKlNzrNXDghLe8o6W5J4yVNlDRM0laSbk+f7ytppqR2ktpLej0tX0fSvZLGSHq4kJ9Ulj9IehD4TXGdpc8ulPRYykOhzMtIukTS86lO7yl81pK26NefLl2Xb+lk6zVxwnP07Lkmq/fsSdt27dh9jz0Z/eADJY250sors+FG2XWkjh070muttZn2/rSKiZd3neZdvrxirrXxZizXqfNXlt/z54vZ/dBjSvrlz5W+D/MuX17x1u3dl+U6dfnSso0235qamuzO27U26M30D0tTr3met8sRr1LbTDljlqOMpbBMmX/y5A6/meWpNzCmeEFEfEp2D9K6DW0kaSXgp8CuEbEF8AzwA0krkI22946ITYFfRcRjwJ3AjyKib0T8ryid9sC1wLCI2ITsOSbHFYX6IKV/KXByA9k5GLgBuAPYS1Lbos82BHYje2Lqz9NnuwPvRsRmEdEHuBcYC2yethlAdgGhP7A18GRaPgr4fkRsmfJySVGc9VNd/LCe/K0C7ADsBRRG/vcDegGbAEcB2zZQtlZj2tSp9Filx4L33bp3Z+rUqbnFf/fdd3jl5Rfp02fTiolXzjrNuz7zjvniM4/SZYWVWaVXg6e5FlHp+zDv8pX7PFPw+L/vZuMtWv1puyyqoc1UQxmtedzhN7M8iewhI/UtX5RtyKboPyppHPBtYE3gU2AWcKWk/YAvGklnA+CNiHglvf8zX56Wf3v6fwxZB/nLmZTaAXuQ3ZLwKVnn/OtFq9wdEbMj4gNgGtAdmADsKuk3kgZExCcRMQ94TdJGZBcH/pDyMQB4OM1e2A64JZX3crKOfMEtaXZEff4eEfMj4oUUH7ILALek5e8BDy6ijlqFqKcZ5fUAni+++JxTTz6RkSefSsdOnSomXrnqNO/6zDvmnNmzGH3739h12BEljQOVvw/zLl85zzMF997yZ5apqaH/Tl9vfGX7impoM9VQxlKQVNafPLnDb2Z5eh7oV7xAUheyjunLwDy+fF5qX1gN+Fcase8bERtHxJGp47wVcBvZffv3NhK/sTPs7PR/LfV/i8nuQFdggqRJZB3pg4s+n130uhZoky4ubEnW8f+1pDPS5w8D3wDmAv9Oae0APERWB9OLyts3IjYqSvvzJpQBFpa3yb9ZJI2Q9IykZ665cul9EE/37j14b8p7C95PmzqVbt26lTzuvLlzOfXkkez2jb0YtMvgiopXjjrNuz7LEfOjqe/y8bQpXPSjIznve8P49MP3+dNPRjBj+octHqvS92He5SvXeabgif/cw8RnHmX4D37eKjtUS4NqaDPVUEZrHnf4zSxPDwDLSTocQFIN8Hvg4oiYSTa1v2+657wnWWce4Alge0nrpu2Wk7R+GgnvGhH3ACOBvmn9GcBXb6KFl4BehXSAw4D/Lkb+DwaOioheEdELWAv4uqTlGtpA0qrAFxHxN+B3wBbpo4dSnh+PiPeBFcluCXg+zR54Q9I3UxqStNli5LOuR4D9U712J/uKl3pFxKiI6BcR/Y44akQzQpZW7z6b8NZbk5g8+W3mzpnDvffczU6Ddi5pzIjg7DN/Rq+11uaQw4aXNFY54uVdp3mXr1wxe6yxNqdd+Xd+9Keb+NGfbqLLiivzvd+MovPyK7Z4rErfh3mXrxznmYIXxj7Bv2+/jmNO+w3tlm3f+AZWr2poM9VQRmue+kawzMxKIiJC0lDgT5J+BqwM3BQRZ6dVHgXeIBsNn0h2rzsR8b6k4cANWvgVfj8l69j/X7o3X2QPAAS4EbgiPThvwcPpImKWpCPIpsq3AZ4GLmtK3lOnfjeKvu80Ij6X9AiwqO8X2oTsAYLzyUbzC88MeJJsZsND6f1zwLSIKMyVOxS4VNJPgbapTOObktd63AbsQlanr6TYnyxhWg067cc/ZMwzTzF9+nT22HUgI757PEP2a/FnAwLQpk0bTj39DI4bcRTz59cyZOj+rLvueiWJVTB+3Fj+efedrLPe+hw2bCgAxx0/ku0G7FQR8fKu07zLl1fMm/54Fq+/MI4vZnzCb449gF0OPIJ+O+/ZYukvSqXvw7zLl1e8a37/c16d+CyffTqdnx45hD0OOpL7b/sr8+bO5eKfjwSg1wa9Ofi4H7d47DzP2+WIV6ltppwxy1HGUqimOTNa+LelmVm+lD1R/wZgv4gY09j6tuQkdYqIzyStCDwFbJ/u52/QjNnzc/0F0bYm30lnM+c09BiEytChXU3uMSu9Th94tbTfIlDXXr1XaXylFlSO/VeOdpqnh1/9INd426y9Qq7xyiHv3xXWstq3WTr62reMe7esneBv9l01t3rwCL+ZlU16ov6a5c5HlbhL0vJAO+CXjXX2zczMzCpVNT0Xwx1+M7MqEBEDy50HMzMzM8uX58SYmZmZmZmZVSCP8JuZmZmZmVnVqKZR72oqq5mZmZmZmVnV8Ai/mZmZmZmZVY1qemifR/jNzMzMzMzMKpA7/GZmZmZmZmYVyFP6zczMzMzMrGpUz4R+j/CbmZmZmZmZVSSP8JuZmZmZmVnVqKJn9nmE38zMzMzMzKwSucNvZmZmZmZmVoE8pd/MzOo1c05trvHadsj3GnSbmnzn87Wt8TX2ltahXU2u8XbbsHuu8az1G7DeSrnGm/zRzFzjrb5Ch1zjmbWUZarosX3+68PMzMzMzMysAnmE38zMzMzMzKqGH9pnZmZmZmZmZq2aO/xmZmZmZmZmFchT+s3MzMzMzKxqyA/tMzMzMzMzM7PWzB1+MzMzMzMzswrkKf1mZmZmZmZWNfyUfjMzMzMzMzNr1TzCb2ZmZmZmZlVjGT+0z8zMzMzMzMxaM3f4zczMzMzMzCqQO/xmrZCk0yU9L+k5SeMkbV2mfAyRtHHR+7Mk7dqC6V8r6YBmprGPpFOWcNtJklaqZ/l3JE1I9T9R0r7NyeOSkjRQ0nZF74+VdHg58jJ79mxGHH4Qww/ej8MO3JerLr+45DEfffgh9tlzN/bafTBXXTGq5PHOPON0Bu+0PQcO3bvksQryLmOe8aa+N4XvHj2cYfvtxcH7781N1/+1pPHAbaalVcM+zDteOWJ+NuNTzvnpyRxz6BCO+dZQXpw4vqTxKn0fVkObKUcZW5pU3p88ucNv1spI2hbYC9giIjYFdgXeLlN2hgALOvwRcUZE/LtMealXRNwZEee2VHqSVgdOB3ZI9b8N8FxLpb+YBgILOvwRcVlE/KUcGWnXrh1/vOxqrr3hdq65/laefOxRnp9Quj8aa2trOefss7jksiu54867ufeeu/jfa6+VLB7A3vsM4aJL8/vDJu8y5h2vpqYNJ/zgx9x0+11c+ZcbufWm63njf5VTPqj8NlPp+7AcbaYcMUdd+Fu23Ho7Lr/u71x8zc30XHOtksWq9H1YDW2mHGW05nGH36z1WQX4ICJmA0TEBxHxLoCkLSX9V9IYSfdJWiUtHy3pfEkPSXpRUn9Jt0t6VdKvCglL+nva9nlJI4qWfybpbEnjJT0hqXsaWd4HOC/NMlineEQ+xXgsbfOUpM6SeqfX49Lo+HqLW3hJNZLOk/R0SuOYtPwHkq5OrzdJI+/LSRou6eK0vLukO1KexhdGxxsqdwO6ATOAz1L9fxYRb6R01pF0b0rrYUkbpuXXSrpU0oOSXpe0k6Sr0764tqhsl0p6JuXjzKLlkySdKWlsmlmwoaRewLHASak+B0j6haST0zbrSvp3KufYlLdVUhsYl+pnwOLWf0MksdxyywEwb9485s2bV9JL2BMnPEfPnmuyes+etG3Xjt332JPRDz5QsngAW/TrT5euy5c0RrG8y5h3vJVWXpkNN8quF3bs2JFea63NtPenlSye20zLq/R9WI42k3fMLz7/jInjx/L1vYYC0LZtWzp17lKyeJW+D6uhzZSjjKXgEX4zW5rdD/SU9IqkSyTtBCCpLXARcEBEbAlcDZxdtN2ciNgRuAz4P+B7QB9guKQV0zrfSdv2A04oWt4ReCIiNgMeAo6OiMeAO4EfRUTfiPhfIZCkdsBNwIlpm12BmWQd1Asiom+KMTmtf4+kVZtY/iOBTyKiP9AfOFrSWsAfgXUlDQWuAY6JiC/qbHsh8N+Upy2A5xspd33GA1OBNyRdI6l4ru4o4PsprZOBS4o++xqwM3AS8A/gfKA3sImkvmmd0yOiH7ApsJOkTYu2/yAitgAuBU6OiElk+/L8VP8P18nndcCfUlm3A6YAhwD3pfrfDBi3iHIuttraWo44ZH/2Gbwj/bfelt59Nm18oyU0bepUeqzSY8H7bt27M3Xq1JLFK4e8y1jOOn333Xd45eUX6eM20yzeh607XjliTnl3Ml2X/xrnn3MG3//OMC4490xmzZxZsniVvg+roc1Uw7m00rjDb9bKRMRnwJbACOB94CZJw4ENyDrw/5I0DvgpsHrRpnem/ycAz0fElDRL4HWgZ/rsBEnjgSfSssII/BzgrvR6DNCrkWxuAEyJiKdTnj+NiHnA48Bpkn4CrBkRM9PnexRmKTTB14HDUxmfBFYE1ouI+cBw4K9knfpH69l2Z7IOMxFRGxGfNFLur4iIWmB34ADgFeD8NLLeiaxjfUvK2+VkszEK/hERQVb/UyNiQsrz8yyszwMljQWeJbsYsHHR9ren/xutf0mdgdUi4o6U51np4sfTwBGSfgFsEhEz6tl2RJpl8MxfrrlyUWG+oqamhmuuv43b7nmAF5+fwOuvvbpY2y+OIL6yTHlfMi+xvMtYrjr94ovPOfXkExl58ql07NSpZHHcZkqnUvdhOeoz75jza2t57ZWX2GPIgVx09U2079CeW667umTxKn0fVkObqYZzaaVpU+4MmNniS53O0cBoSROAb5N1BJ+PiG0b2Gx2+n9+0evC+zaSBpKNxG8bEV9IGg20T+vMTZ1VgFoaP3cIvvobISKul/QksCdwn6SjIuI/jaRVX9rfj4j76vlsPbKp9k2dLUAj5a5XqoungKck/YtsRsEfgOlp9Lw+jdX/WmSzAvpHxMdpqn/7erZvav3Xl++HJO1IVv9/lXRe3Xv+I2IU2UwFps2Y+9Xf6k3QuXMXNt+yP08+/ghrr7vYd200SffuPXhvynsL3k+bOpVu3bqVJFa55F3GctTpvLlzOfXkkez2jb0YtMvgksZymymNSt6H5ajPvGOuuHJ3Vlq5Gxv23gSA7QcO5pa/la7DX+n7sBraTKWcS1X/n0oVySP8Zq2MpA3q3PveF3gTeBlYWdlD/ZDUVlLvxUi6K/Bx6vRuSPYwusbMADrXs/wlYFVJ/VNeOktqI2lt4PWIuJBsxsGSzP28Dzgu3cKApPUldZTUFbgA2BFYUfU/3f8B4Li0XY2kLixmuSWtKmmLokV9gTcj4lOyaf7fTOtJ0maLUa4uwOfAJ5K6A99owjb11n/Ky2RJQ1JellX2PIM1gWkRcQVwFdltDS3i448/YsaMTwGYPWsWzzz1BGv0Kt2Dn3r32YS33prE5MlvM3fOHO695252GrRzyeKVQ95lzDteRHD2mT+j11prc8hhw0sWp8BtpuVV+j4sR5vJO+YKK67Eyt16MPmtSQCMH/Mka/Rau2TxKn0fVkObqYZzaaXxCL9Z69MJuEjS8sA84DVgRETMSZ3cC1Pntw3Zfe3PN5RQHfcCx0p6juziwRNN2OZG4ApJJ5BNcQcg5WVYymcHsvv3dwWGAd+SNBd4DzgLsnv4gaMamNZ/uaQ/ptdvA9uTTWkfq2wO2ftk3xZwPnBJRLwi6UjgQUkP1UnrRGBU+ryWrPO/uOVuC/wuPXNgVop/bPrsUOBSST9N691Ids9/oyJivKRnyfbX60B9tyTU9Q/gVmVfC/j9Op8dRlZ3ZwFzgW8CA4Afpfr/DGixr/D78IP3Oefnp1M7v5aYHwwavBvbDxjYUsl/RZs2bTj19DM4bsRRzJ9fy5Ch+7NuiWYTFJz24x8y5pmnmD59OnvsOpAR3z2eIfs161sjFynvMuYdb/y4sfzz7jtZZ731OWxY9sCw444fyXYDdipJPLeZllfp+7AcbaYcMY8Z+RPOO+s05s2dS49VV2PkaWeVLFal78NqaDPlKGMpLFM9A/xo4SxdMzOzhZZ0Sv+S6tKhbZ7hmFs7P9d4bWsqf1LdzDm1ucbr0K4m13iV3mby3n+Q/z6sdJM/Kt0D9+qz+godco1nrV/7NkvHXPoHXvqgrJ3gXTZcKbd6qPy/PszMzMzMzMyqkKf0m5mZmZmZWdXwQ/vMzMzMzMzMrFXzCL+ZmZmZmZlVDVXPAL9H+M3MzMzMzMwqkTv8ZmZmZmZmZhXIU/rNzMzMzMysavihfWZmZmZmZmbWqnmE38zMzMzMzKrGMtUzwO8RfjMzMzMzM7NK5A6/mZmZmZmZWQXylH4zMzMzMzOrGn5on5mZmZmZmZm1ah7hNzOzeo2f/Emu8Qast1Ku8fI2+aOZucbr3nXZXOMBvPfJrFzjrb5Ch1zjzauNXOO1rck1HHNr5+cbEGBOvuE6tMu5UnO2Yqd2uca7bfzkXOMB7NNn1Vzjta3x+Ki1bu7wm5mZmZmZWdVQ9czo95R+MzMzMzMzs0rkEX4zMzMzMzOrGlU0wO8RfjMzMzMzM7NK5A6/mZmZmZmZWQXylH4zMzMzMzOrGstU0VP7PMJvZmZmZmZmVoE8wm9mZmZmZmZVo3rG9z3Cb2ZmZmZmZlaR3OE3MzMzMzMzq0Ce0m9mZmZmZmbVo4rm9JdshF/S6ZKel/ScpHGSti5VrEbyMUTSxkXvz5K0awumv42kJ1MZX5T0i2akdVpL5WsJYg+UdFceaUpaTtJ1kiZImijpEUmdWjL2YuRxpKTlit7fI2n5Fkh3xdQmxkl6T9I7Re/bLUY6zWoTkn4h6eSmLq9nvRvSMXxSc/KxtJI0XNLFDXw2JJX9pdRWh9TZbtWi95MkrZRDlpc6f7voHE759p6cfcK3Fiy749qL+eX3DuacEw9n1K9P5YvPZpQk9qMPP8Q+e+7GXrsP5qorRpUkRrEzzzidwTttz4FD9y55rILPZnzKOT89mWMOHcIx3xrKixPHlzRenmV8561JjDzyoAU/B+8xgDtvua6kMfPeh1Pfm8J3jx7OsP324uD99+am6/9a8ph5HhezZ89mxOEHMfzg/TjswH256vJ6T6ctptLrsxwx86jTOy8/j98duz+X/vjIBctG3/pnzv/egVx+6gguP3UErz77ZIvHLcj7uK/0NlOOeNVK0tWSpkmaWLRsBUn/kvRq+v9rjaVTkg6/pG2BvYAtImJTYFfg7VLEaoIhwIIOf0ScERH/bsH0/wyMiIi+QB/g5makVbYOf85OBKZGxCYR0Qc4EphbpryMBBZ0+CNij4iY3txEI+LDiOib2sVlwPmF9xExZzGSKudFoB7AdhGxaUSc38RtKmLWkKTNgN8B+0bEhsA+wO8kbZpWGQ6s2sDmixtriepMUk1LxG+ubXbeg++d8YcvLdtws/6cduFfOe2Cv9Bt1Z7cf1vL/wFZW1vLOWefxSWXXckdd97Nvffcxf9ee63F4xTbe58hXHRpvn/YjLrwt2y59XZcft3fufiam+m55loljZdnGVdboxd/vOpG/njVjfx+1HUsu2x7thkwqKQx896HNTVtOOEHP+am2+/iyr/cyK03Xc8b/ytdO837uGjXrh1/vOxqrr3hdq65/laefOxRnp9QuotSlV6f5YiZR51utuNuHPqTX39l+dbfOIBjfj2KY349ivU2L924YJ7HfTW0mXKUsRRU5n9NdC2we51lpwAPRMR6wAPp/SKVaoR/FeCDiJgNEBEfRMS7AJK2lPRfSWMk3SdplbR8tKTzJT2URsr7S7o9Xb34VSFhSX9P2z4vaUTR8s8knS1pvKQnJHWXtB3ZH+rnpZHVdSRdK+mAtE1/SY+lbZ6S1FlS7/R6XBrdW6+RsnYDpqRy1kbECyntjumqzNOSnpW0b1o+PJXr3lS236bl5wIdUtzr0rJvFeXl8sIf+PWVNS3vLumOtHx8Kn+D6TRkEXl/UlLvovVGp/1Z7/qLsArwTuFNRLxcaCuNlPk3ad//W9JWKf7rkvZJ6/SS9LCksemnUP6Bad1blY3WXqfMCWSdtgclPZjWXTBSK+nw1AbGS/prWvZNZbMSxkt6qJFy1le3X2n/krpKelnSBmmdGyQdXbdNpPIVX+E7WWlGSVr/6ZSv21Q0a6EJeRqd6vYpSa9IGpA+uh/oluIPUHb83Jvy/rCkDdP210r6Q6rD3zSy3oXKjrnXlY7D9NmPlY2ij0/lpqF06uR9q5Tes+n/Qh3We5ylz45I5fwvsH0D1XIycE5EvAGQ/v818KOU737AdaluOqRtvp/a3YSiMi/qPHCLpH+keq5brkWd586S9CSwrRo+Xi6V9Eza/syi7c+V9EJq179roOyLZd3efVmuU5cvLdto862pqcmuY6y1QW+mfzitJUJ9ycQJz9Gz55qs3rMnbdu1Y/c99mT0gw+0eJxiW/TrT5euy5c0RrEvPv+MiePH8vW9hgLQtm1bOnXu0shWzZN3GQueG/sUPVZbnW49WuQ6WoPyLt9KK6/MhhtlYw4dO3ak11prM+39lj8eCvI+LiSx3HLZr5t58+Yxb948KOF3W1d6fZYjZh51uuZGm9KhU2nPXYuS53FfDW2mHGWsVhHxEPBRncX7kg04k/4f0lg6perw3w/0TH9UXyJpJwBJbYGLgAMiYkvgauDsou3mRMSOZCOi/wd8j2zUfLikFdM630nb9gNOKFreEXgiIjYDHgKOjojHgDuBH6WR1f8VAimbVn0TcGLaZldgJnAscEEame0HTE7r36OiKbxFzgdeVtbRPkZS+7T8dOA/EdEfGER20aFj+qwvMAzYBBgmqWdEnALMTPk8VNJGaZ3tU15qgUMbKmtafiHw37R8C+D5RtJpSEN5vxE4MNXHKsCqETGmkbLW52rgJ5Iel/QrpYsqTSjz6LTvZwC/AgYDQ4Gz0jrTgMERsUVK58KimJuTjeZvDKydYlwIvAsMiogvDSspu7BxOrBzqs8T00dnALulZfssuhq/rKH2HxGfAMcD10o6CPhaRFxRt000kvztEdE/5etFslkTi6NNRGxFVkc/T8v2Af6X4j8MjAK+n/J+MnBJ0fbrA7tGxA8bWW8VYAeyGUCFjv03yE5WW6f8Fzrni0qn4CVgx4jYnGzfnFP0WV/qHGep3Z5J1tEfTNHsnzp6A2PqLHsG6B0Rt6bXh6a6mZk+/yC1vUtTfmHRx8a2wLcjYud64i/qPDcxIrYGPqTh4+X0iOgHbArsJGlTSSuQHS+908yrX5GDx/99NxtvsW2Lpztt6lR6rNJjwftu3bszderUFo9TTlPenUzX5b/G+eecwfe/M4wLzj2TWTNnNr5hK/TIf+5jwM67lTsbJfXuu+/wyssv0qfPpo2vvITKcVzU1tZyxCH7s8/gHem/9bb0LmH5ilVqfZbz3JZHnRZ7+v6/c9lPjuLOy89jZolu/cpbNbSZavj9u5TrHhGFweYpZIPPi1SS6bcR8ZmkLYEBZH/k3iTpFLI/kvsA/1J2BbiGNDqe3Jn+nwA8XyiMpNeBnmR/4J4gaWharyewXlo+ByjcLz6G7I/5RdkAmBIRT6c8f5piPQ6cLml1sk7Uq+nzPRoo61nKRuS/DhwCHAwMTO/30cL7pNsDa6TXD6ROHpJeANbkq7c87AJsCTyd6qoDWYeWRZR1Z+DwlK9a4BNJhy0inYY0lPebgX+RdQgPBG5pZP16RcQ4SWun7XZNedu2CWW+N72eAMyOiLmSJgC90vK2wMWS+pJ1ftYvCvtURBQu3oxL2zyyiDrYGbg1Ij5IeS5cXXuUrGN+M3D7IravzwY00P4j4l+Svgn8CdhsMdMF6KNsJszyQCfgvsXcvlCWMSyszwWUPWNhO+AWLRy9WbZolVsiorYJ6/09IuYDLyjNTCFrA9dExBeQ1XUT0inoCvw5XTQKsjZQUN9xthLZhaP30/Kb+HI7WVDklF5jy4oV1+F+6fWijo1/FbWruho6z9UCt6XlizpeDkwzA9qQXWTZGHgBmAVcKeluFp5DSubeW/7MMjU19N/p6y2edtSzK1TCkcVymF9by2uvvMQxJ57Chr034fILfsMt113NYUd9r9xZa1Fz587lqUcf4rCjv1/urJTMF198zqknn8jIk0+lY6fSPbKmHMdFTU0N11x/GzNmfMrpJ5/I66+9ytrrNjY5snkquT7LdW7Lq04L+g3emx33+xZCPHjLNfzrusvY55gflTxuqVVDm6mU37/lznL6O21E0aJREVGSe09Kdr9t6nCOBkanTtm3yf4Qfj4iGhrumZ3+n1/0uvC+jaSBZJ2DbSPiC0mjyf6ABpgbEYUWWEvjZav3j/eIuD5Nl90TuE/SURHxn0UllGYOXCrpCuD9NBonYP+IePlLQbOHFxaXraG8CvhzRJxaz2eLU9Z600mdicJI7lH1bPOVvKftPlR2H/Mw4JhFrV/UofuKiPiMrIN0u6T5wB5knfqmlHlB+4iI+Vp4D/RJwFSyDvMyZJ2bgqbU+ZeyT/3t49i0D/cExknqGxEfNpJWcZr1tn9JywAbkc0yWYE0s6SOeXx5Vk77otfXAkMiYryk4WQXnRZHoX4aqptlgOlpJLk+nzdxveL9oKL/69Z1Y+kU/BJ4MCKGSupFds6pL1ZxuRbVaS94nmx0/bmiZVuQdZobUl8dLuo88Dn1aOQ8NyudWwtp13dsr0U2w6B/RHws6VqgfUTMk7QV2YWCg8hmlXxldkHxL6ATf/F79jzw8EUUuWFP/OceJj7zKCecdWFJ/hDo3r0H7015b8H7aVOn0q1boxe5W5UVV+7OSit3Y8PemwCw/cDB3PK3q8ucq5Y39slHWXv9DVl+hRUbX7kVmjd3LqeePJLdvrEXg3ZpbCyiecp5XHTu3IXNt+zPk48/UtIOf6XXZzli5lmnBZ26rrDg9RY778kN552eS9xSq4Y2Uw2/f/OQOvdL0sGfKmmViJiSZq42eg9OqR7at4G+fO97X+BN4GVg5TSai6S2KronvAm6Ah+nP4I3BLZpwjYzgM71LH8JWFVS/5SXzpLapJHn19N07zvJpsQ2SNKeWvjX7Hpkf+xPJxth/X7hM0mbNyGvc9O0b8gewnCApG5p+xUkrdnI9g8Ax6X1ayR1aSidiLgjFj5E7pk66Swq7zcCPwa6RsSEJqz/FZK2V3qipLJbKzYmax9LUuZiXclmbcwHDiMbQW9MQ+3jAbJR0hULeUn/rxMRT0bEGcAHZLeurCapKTcvLar9n0Q2Ff9g4OqidlDcJqaS3VO/oqRlyabFF3QGpqR1G5v+v9jSDJg30iwElPnKTISmrlfH/cB3lJ47IGmFxUinKwufBzG8CUV5EhiY6rAt8M0G1vsdcGq6iED6/zTg9+nzhtpNXUtyHmjqea6h46UL2cWET9JFt2+kzzuRHbf3kN260be+RCNiVET0i4h+S9rZf2HsE/z79us45rTf0G7Z9o1vsAR699mEt96axOTJbzN3zhzuvedudhpU390RrdcKK67Eyt16MPmtSQCMH/Mka/Rau7yZKoGHH7iXHXepzOn8EcHZZ/6MXmutzSGHDS95vLyPi48//ogZMz4FYPasWTzz1BOs0at0D5as9PosR8y867RgxscLx0peevoRuq3eK7fYpVQNbaZSfv+qzD/NcCfZQDrp//9rbINSjfB3Ai5S9vVm84DXyJ5kP0fZA68ulNQ1xf8j2WhaU9wLHCvpObLO0xNN2OZG4AplD2hb8JCwlJdhKZ8dyEZWdyUbuf6WpLnAe6T7wyXdAxwV6eGDRQ4Dzpf0RSrroWlq8y9T2Z5Lf+xP4ssdtPqMSuuPjew+/p8C96fR37lkzzR4cxHbnwiMknQk2YWH4yLi8SVIZ1F5vxW4IK3TlPXrsw7ZjAiRXXS6G7gtImIJ8lrsEuC21El8kAZGUOsYBfxT0pQouo8/Ip6XdDbwX0m1wLNkHcrz0sUskXW4xpNNq57XWKCG2n9qa0cBW0XEDGUPA/wp2QyMum3iLLJO6xtkF60KfpaWv0l2y0NTOqOL61Cy/fZTsqnzN5KVf0nXAyAi7lV2G8YzkuYA95B1rpuSzm/JpvT/AFjkTJwUa4qyBx0+TnY7xVjquTCUbjv5CfCPdGFgLvDjiBiXVrkWuEzSTLJ78RuyJOeBJp3nIuKF+o6XiHhC0rNk59XXyW5DgaxN/J+y54yI7CJTs13z+5/z6sRn+ezT6fz0yCHscdCR3H/bX5k3dy4X/3wkAL026M3Bx/24JcIt0KZNG049/QyOG3EU8+fXMmTo/qxb4mnEp/34h4x55immT5/OHrsOZMR3j2fIfgc0vmEzHDPyJ5x31mnMmzuXHquuxsjTzmp8o2bIu4yzZ81k/JgnOe6H+Yzu5V2+8ePG8s+772Sd9dbnsGHZXTrHHT+S7QbsVJJ4eR8XH37wPuf8/HRq59cS84NBg3dj+wEDSxav0uuzHDHzqNPbLvoVb744ni9mfML5xw9j4P7fZtKL45n6ZvZoreVX7sGeR7bIr6R65XncV0ObKUcZq5WkG8hm7a4kaTJZ3+Bc4ObU33uLhgevFqazcJa0mS0JSccDb0XEnY2ubNaK/OvFD3L9BTFgvZXyDMfc2vm5xpv6yezGV2pB3bvW99iL0pr8Ub4PFVx9hQ6Nr9SC5tXm+zdTh3b5fvvmpzPz/4bctjWlen50/fKu07zNnFPb+Eot6J4XpzS+Ugvbp09pv82jrrzbaKVr36a5A9wt4+nXPylrJ7j/2l1zq4eK+M5ss3KKiIvLnQczMzMzM2uipeKyQz58ycrMzMzMzMysArnDb2ZmZmZmZlaBPKXfzMzMzMzMqoaqaE6/R/jNzMzMzMzMKpBH+M3MzMzMzKxqqHoG+D3Cb2ZmZmZmZlaJ3OE3MzMzMzMzq0Ce0m9mZmZmZmZVo4pm9HuE38zMzMzMzKwSeYTfzMzMzMzMqkcVDfF7hN/MzMzMzMysArnDb2ZmZmZmZlaBPKXfzMzqtV63TrnGm1s7P9d4bWvyvebdveuyucbLu3zliJl/vFzD5a5Du/wLWI52Wsny3of7b7Z6rvEAnnvrk1zj9Vp5uVzj5b0Pq/UYVBXN6a/OPWxmZmZmZmZW4TzCb2ZmZmZmZlVD1TPA7xF+MzMzMzMzs0rkDr+ZmZmZmZlZBfKUfjMzMzMzM6saVTSj3yP8ZmZmZmZmZpXII/xmZmZmZmZWPapoiN8j/GZmZmZmZmYVyB1+MzMzMzMzswrkKf1mZmZmZmZWNVRFc/o9wm9mZmZmZmZWgdzhLwFJp0t6XtJzksZJ2noJ0+kraY+i9/tIOqXlclpvzIGStmtknf+T9HgLxPpsCbd7bAm320bSk2mfvCjpF2l5o2VO610r6YD0+kpJGy9i3eGSVi16v8j1G0jjAknvSGrWcSppkqSVlmC7eyQt35zYS0LSLySdvIjPx0u6Ic88NYekkZKWa+Cz0ZLekqSiZX8vHBuSVpV0axNilGVf1XX4ft/gmG/tz3HfPpDjv3NwyeOdecbpDN5pew4cunfJYxU8+vBD7LPnbuy1+2CuumJUSWNVevkAPpvxKef89GSOOXQIx3xrKC9OHF/SeHmXrxwx3UZbd7xyxKy0eFf84Zd896DdOOXYgxYs+2zGJ5x72vGcfOT+nHva8Xw+49MWjwswe/ZsRhx+EMMP3o/DDtyXqy6/uCRxilXDcVgKUnl/8uQOfwuTtC2wF7BFRGwK7Aq8vYTJ9QUWdPgj4s6IOLfZmVy0gUCDnd/UqdgCWF7SWiXOS70iotHOeQP+DIyIiL5AH+DmtHwgiyhzA3k4KiJeWMQqw4EFHf4mrP8lqZM/lKzt7Lg4eWspEbFHREwvR+yGSNqI7Ly1o6SODayztN2qNBKot8OfTAe2hwXH1yqFDyLi3Yg4oLEAS9O++u3FV3Lpn2/m4qtLf01m732GcNGl+f2hUVtbyzlnn8Ull13JHXfezb333MX/XnutZPEqvXwAoy78LVtuvR2XX/d3Lr7mZnquWbpfK+UoX94x3UZbd7xyxKzEeAMG78mPf3XBl5b94+Y/07tvf3531W307tuff9z85xaNWdCuXTv+eNnVXHvD7Vxz/a08+dijPD+htBcyK/04tOZzh7/lrQJ8EBGzASLig4h4F0DSlpL+K2mMpPskrZKWj5b0G0lPSXpF0gBJ7YCzgGFpRHpYGjW+OG1zraRLJT0o6XVJO0m6Oo1cX1vIjKSvS3pc0lhJt0jqlJZPknRmWj5B0oaSegHHAielmAPqKd/+wD+AG4GDiuJcK+lCSY+l/BRGwjtJeqAozr51E5T01+Llkq5Lsxl6pzoZl2ZLrJc+L4x+riLpofT5xAbyW6wbMCXtl9qIeKG+Mkt6Q1LbFKNLqqu2dfI8WlI/STWp7BNT+U5KZe8HXJfS7FBYP227e6qP8ZIeaCCvg4CJwKXAgqHSNPp9dUrvdUknFH3299S2npc0op56/qWkE4veny3phIbqMZV7JUkdJd2d8jtR0rBFVbKkvZXNpHhW0r8ldW9C3k+X9LKkfwMbLCL5Q4C/AvcD+xRtP1rSOZL+C5woqX9qM49LOk/SxLTegmMovb9L0sD0+jNlx+GYlO+tivK6T1qnJqX3dEr/mLR8YFr3VkkvpTasVMZVgQclPdhAmYqPpf2A24vy16tO3m+XdK+kVyX9tmi9wr7qpewccEVqB/dL6pDWqbdOWrMt+vWnS9flc4s3ccJz9Oy5Jqv37Enbdu3YfY89Gf1gQ4dw81V6+b74/DMmjh/L1/caCkDbtm3p1LlLyeLlXb5yxHQbbd3xyhGzEuNtuMkWdKxzLhn7+EMM2HVPAAbsuidjHv9vi8YskMRyy2XX+OfNm8e8efNKPpxb6cehNZ87/C3vfqCnso77JZJ2AkgdxouAAyJiS+Bq4Oyi7dpExFZko4E/j4g5wBnATRHRNyJuqifW14CdgZPIOuHnA72BTZTdDrAS8FNg14jYAngG+EHR9h+k5ZcCJ0fEJOAy4PwU8+F6Yh4M3JB+6s7ZXQXYgWyGQ2EmwixgaIozCPi99JUz35XAEameupKNtt9D1hG/II3I9wMm19nuEOC+9PlmwLh68lvsfOBlSXdIOkZS+wbKPBrYM21zEHBbRMxtIM2+wGoR0SciNgGuiYhbyer60JTmzMLKklYGrgD2j4jNgG82kG6hnu8A9qpzwWFDYDdgK+DnRZ99J7WtfsAJklask+ZVwLdTPpZJZbuOxutxd+DdiNgsIvoA9zaQ54JHgG0iYnOyzuyPF5V3SVumvGxO1uHtv4i0hwE3UX/7Wz4idoqI3wPXAMdGxLZAbSP5LegIjE51OAP4FTCYbKbFWWmdI4FPIqJ/yufRWjjTZXOy43djYG1g+4i4EHgXGBQRgxqI+wDZjIUasnqo71gv6EtWB5uQXQzsWc866wF/iojeZLMH9k/Ll6ROFo/gtJHH8r0jDuKevzd6J0KrM23qVHqs0mPB+27duzN16tQy5qhl5V2+Ke9OpuvyX+P8c87g+98ZxgXnnsmsmTMb33AJlWP/5R3TbbR1xytHzEqPV/Dp9I9YfoXs7sblV1iJTz/5uGSxamtrOeKQ/dln8I7033pbevfZtGSxyqFSzjMq80+e3OFvYRHxGbAlMAJ4H7hJ0nCyUcs+wL8kjSPriK9etGlhVG8M0KuJ4f4REQFMAKZGxISImA88n9LYhqzz8WiK+W1gzSWNmUZq1wUeiYhXgHmS+hSt8veImJ+mrncvbAacI+k54N/AakWfARAR/wXWldSNrBN3W0TMAx4HTpP0E2DN4o5z8jRwhLJ78TeJiBmLyn9EnEXWGb6frJPbUMd1wQWI9P81i0j2dWBtSRdJ2h1o7KawbYCHIuKNlKeP6q6gbHbHHmT1+SnwJPD1olXujojZEfEBMI2F9XmCpPHAE0BPso7fAunixoeSNk/pPRsRH9J4PU4Adk2j3wMi4pNGyrg6cJ+kCcCPyC5CLSrvA4A7IuKLVN4760tUUn/g/Yh4k6yTvIWkrxWtclNab3mgc0QUnvVwfSP5LZjDwjYxAfhvutAzgYXHx9eBw9Px9CSwIgvr+amImJyOwXE0/TiuJbtIMgzokPZTQx6IiE8iYhbwAl8+ngveiIhx6fUYoFcz6mSxnH/Zn/nTtTdx9u//xJ2338SEZ8eUIkzZBPGVZV+9ftl65V2++bW1vPbKS+wx5EAuuvom2ndozy3XXV2yeOXYf3nHdBtt3fHKEbPS45VDTU0N11x/G7fd8wAvPj+B1197tdxZalHVsA8rjTv8JZCmi4+OiJ8Dx5ONsAl4Po349o2ITSKiuBM3O/1fS9O/LrGwzfyi14X3bVLMfxXF3DgijmxGzGFkswrekDSJrENzUNHnxXkoHPmHAisDW6YR5KlA+3rS/mtad0EHOyKuJ5u2PZOsA7lz8QYR8RDZ/e3vAH+VdHhjBYiI/0XEpcAuwGb1jIITEY+SdZJ2AmoiosGpzxHxMdmo+Gjge2QXCxZFUM+Z8st2B7oCE1I978CXR7OL67kWaJOmpe8KbJtmDjxL/fV8JdnzBY4gm2XSaD2miztbknV8fy3pjEbyfxFwcZrxcEydfHwl74UwjaQJWR1smOrkf0AXFo5eA3ye/l/Ub515fPm8V5y3uekCGhQdU6kDX8ingO8XHVNrRcT96bOGytYUN5LV282NrNeUGPWt0+TfxJJGSHpG0jPX//mqpm4GwIordwNg+RVWZPsdd+alF1v9XQNf0r17D96b8t6C99OmTqVbt25lzFHLyrt8K67cnZVW7saGvTcBYPuBg3nt5RdLFq8c+y/vmG6jrTteOWJWeryCLsuvwPSPPgBg+kcf0KXr1xrZovk6d+7C5lv258nHHyl5rDxV+nmmErnD38IkbaB0r3nSF3gTeBlYWdlD/UhTmXvXk0SxGUDnZmTnCWB7SeummMtJWr8ZMQ8Gdo+IXhHRi6wTeFAD6xZ0BaZFxFxJg6h/RBLgWrLp0ETE8ym/awOvp2nRdwJfmhMlac2U9hVk09W3SMv/ImmrugEk7Vl0O8F6ZJ2h6Q2U+S9k08YXNbpPum1imYi4DfhZIQ8NpAnZrIWdCtPAJa1QzzoHA0cV1fNawNfVwJPek67AxxHxhaQNyWYS1OcOsgsK/YH7Uh7qrceiMq4KfBERfwN+x8J6/rWkoQ3k5Z30+tuLyHPBQ8BQZc866Ax85TGz6RaEbwKbFtXLvnx1Wn/hIswMSYU6KG6jk4C+kpZJ0+G/0k4acR9wnBY+42F9NfDwwCJNOY4fBn5N1uZaXCN1UnfdURHRLyL6HfLtIxta7StmzfyCLz7/fMHrMU89Tq+1121Otpc6vftswltvTWLy5LeZO2cO995zNzsN2rnxDVuJvMu3woorsXK3Hkx+axIA48c8yRq91i5ZvHLsv7xjuo227njliFnp8Qq22GZHHv733QA8/O+72WLb0jwP+eOPP2JG+gaA2bNm8cxTT7BGr7I847pkKuY8U0Vz+pe2p1lXgk7ARWkK7TzgNbInw89R9jC3C9N96m2AP5JNv2/Ig8Apafrwrxc3IxHxfrqd4AZJy6bFPwVeWcRm/wBuVfYQve8X7uNX9nC7NcguIhTSf0PSp1r01w5eB/xD0jNk05xfaiCvUyW9CPy9aPEw4FuS5gLvsfA+6oKBwI/S558BhZHpTUkP56vjMOB8SV+Q7ZtDI6JWUn1lvo7sHu7GOmCrAddo4VfnnZr+vxa4TNJMYNuicr6v7IF6t6dtppHdJw5kF2XI7nE/pmibzyU9Qj0d4SL3AsemWydepmg/FUvt8EFgekQU7uMeSP31WLAJcJ6k+cBc4Lii5fVNv/8FcIukd1I+FvmbLiLGSrqJrH28Sdb5rWtH4J2IeKdo2UPAxkoPv6zjSOAKSZ+Tzb4o3IbwKPAG2WyFicDYReWtHleSzWwZmy4evQ8MaWSbUcA/JU1p6D7+NLPgd4uZl8XVUJ20iI8/+ogzTz0JgNraeQwavAf9t9m+JUN8xWk//iFjnnmK6dOns8euAxnx3eMZsl+jX2qwxNq0acOpp5/BcSOOYv78WoYM3Z91112v8Q2XUKWXD+CYkT/hvLNOY97cufRYdTVGnlb3NN9yylG+vGO6jbbueOWIWYnx/nTuT3nxuTF89ul0TvjWXux32NHsdeDhXHzOafz3vjtZceXufP/0xf6zukk+/OB9zvn56dTOryXmB4MG78b2AwaWJFZBpR+H1nxaOIPVrHxSR3cC2dcZLnFHRFIX4KqIaOhheE1N5wBg34g4rDnpLG3SRYaxwDcjolk3lUm6LyJ2a5mctSxJndLzNJB0CrBKRJzYyGYVbUnqZNKHs3L9BbFip3Z5hqNtTb6T3ObWzs81Xt7lA5j8Uekeulef1VfokGu8Spd3G4XytFNr3Z57q0WvVzeq18qLmmDZ8jq0q8k1Xt7HYPs2uT+zrl7Pv/N5WTvBvVfrmFs9eITfyk7SrmT3k/+hOZ19gPTQt+Z29i8CvkH24LyKIWlj4C6yB+Q1+wkyS2tnP9lT0qlk57g3yZ5bUO1cJ2ZmZmZVxiP8ZmZWL4/wtyyP8Lc8j/C3LI/wW2vgEf6W5RH+8vAIv5mZmZmZmVkJVNM3CfqyqpmZmZmZmVkF8gi/mZmZmZmZVY0qGuD3CL+ZmZmZmZlZJXKH38zMzMzMzKwCeUq/mZmZmZmZVY8qmtPvEX4zMzMzMzOzCuQRfjMzMzMzM6saqqIhfo/wm5mZmZmZmVUgd/jNzMzMzMzMKpCn9JuZmZmZmVnVUPXM6HeH38zM6teja/tyZ6GitK2p/El1XTr4z4rWrBxtdOac2lzjdWhXk2u8vOVdn21q8u81bbpG19xjmrVm/s1sZmZmZmZmVaOKBvh9D7+ZmZmZmZlZJXKH38zMzMzMzKwCeUq/mZmZmZmZVY8qmtPvEX4zMzMzMzOzCuQRfjMzMzMzM6saqqIhfo/wm5mZmZmZmVUgd/jNzMzMzMzMKpCn9JuZmZmZmVnVUPXM6PcIv5mZmZmZmVklcoffzMzMzMzMrAJ5Sr+ZmZmZmZlVjSqa0e8RfrNqJul0Sc9Lek7SOElb5xR3kqSVShxjoKS7Glgeko4sWrZ5WnZyU9NMr7cr+uxYSYe3ZBlSur9oQr4WrCPpLEm7ptcjJS3X0nlqyKMPP8Q+e+7GXrsP5qorRlVcvHLErOR4s2fPZsThBzH84P047MB9ueryi0saD9xmWnu8qe9N4btHD2fYfntx8P57c9P1fy1pPKj8NpN3nZ55xukM3ml7Dhy6d0njFKvkY6JcMctRRlty7vCbVSlJ2wJ7AVtExKbArsDb5c1VbiYAw4reHwSMX8w0BgILOvwRcVlE/KX5WWueiDgjIv6d3o4Ecunw19bWcs7ZZ3HJZVdyx513c+89d/G/116rmHjliFnp8dq1a8cfL7uaa2+4nWuuv5UnH3uU5ycs7mHYdG4zrT9eTU0bTvjBj7np9ru48i83cutN1/PG/yqnfOWImXed7r3PEC66NL8OYqUfE+WIWY4yloTK/JMjd/jNqtcqwAcRMRsgIj6IiHdhwQj8byQ9lX7WTctXlnSbpKfTz/ZpeUdJV6dlz0raNy2vkfQ7SRPSLILvF8X/vqSx6bMN62ZOUi9JD6d1xhZG09PI+mhJt0p6SdJ1UvasVUm7p2WPAPstouxvAe0ldU/b7g78syj2aEn90uuVJE2qmzfgWOCkNDNiQJ1R9tGSzpf0kKQXJfWXdLukVyX9qiidH0iamH5GFi0/XdLLkv4NbFC0/OhUx+PTfvhKZ17StZIOkHQCsCrwoKQHJR0p6fw6af1hEXW0WCZOeI6ePddk9Z49aduuHbvvsSejH3ygpZIve7xyxKz0eJJYbrmsCc+bN4958+aV9LHJbjOtP95KK6/MhhttDEDHjh3ptdbaTHt/WsniVUObybtOt+jXny5dly9Z+nVV+jFRjpjlKKM1jzv8ZtXrfqCnpFckXSJppzqffxoRWwEXA39Myy4Azo+I/sD+wJVp+enAf9LyQcB5kjoCI4C1gM3TLILritL/ICK2AC4F6puyPg0YnNYZBlxY9NnmZKPXGwNrA9tLag9cAewNDAB6NFL+W4Fvko3SjwVmN7L+AhExCbiMrC76RsTD9aw2JyJ2TOv9H/A9oA8wXNKKkrYEjgC2BrYBjk63FmxJNuNgc7KLFv2L0rw9IvpHxGbAi8CRNCAiLgTeBQZFxCDgRmAfSW3TKkcA1zS1zI2ZNnUqPVZZWOXdundn6tSpLZV82eOVI2alx4NspOiIQ/Znn8E70n/rbendZ9OSxXKbaf3xir377ju88vKL9HGbaTF51GnequGYqIYyWvO4w29WpSLiM2BLsk75+8BNkoYXrXJD0f/bpte7AhdLGgfcCXSR1Bn4OnBKWj4aaA+skda/LCLmpZgfFaV/e/p/DNCrniy2Ba6QNAG4haxzX/BUREyOiPnAuLT9hsAbEfFqRATwt0aq4GayDv/BRWVtSXem/ycAz0fElDSb4nWgJ7ADcEdEfJ72xe1kFyoGpOVfRMSnRekA9EmzHiYAhwK9m5qZiPgc+A+wV5pR0TYiJtRdT9IISc9IemZx7ssL4ivLVMLR2rzjlSNmpccDqKmp4Zrrb+O2ex7gxecn8Pprr5YslttM649X8MUXn3PqyScy8uRT6dipU8niVEObKcirTvNWDcdENZSxFFTmf3nyU/rNqlhE1JJ10EenTuS3gWsLHxevmv5fBtg2ImYWp5Omxe8fES/Xs/yrvxkyhRH1Wuo/F50ETAU2S3Fn1bNt3e0bivUVEfGepLnAYOBEiu7HB+ax8IJo+6amWUchj/P5cn7nk+V3UWf7hspxLTAkIsanizMDFzNPVwKnAS/RwOh+RIwCRgHMmtf0+uzevQfvTXlvwftpU6fSrVu3xcxe0+UdrxwxKz1esc6du7D5lv158vFHWHvd9UoSw22m9ccDmDd3LqeePJLdvrEXg3YZXNJY1dBmIN86zVs1HBPVUEZrHo/wm1UpSRtIKv7Lui/wZtH7YUX/P55e3w8cX5RG3/TyPrJ78gv30m9etP6xktqk5SssRha7AlPSKP5hQE0j678ErCVpnfT+4CbEOAP4SbrwUWwS2ewHgAMa2HYG0LkJMRryEDBE0nLp9oehwMNp+VBJHdLsieJHGXcGpqRp+Yc2IcaX8hgRT5LNLjiEFp7V0LvPJrz11iQmT36buXPmcO89d7PToJ1bMkRZ45UjZqXH+/jjj5gx41MAZs+axTNPPcEavdYqWTy3mdYfLyI4+8yf0WuttTnksOEli1NQDW0m7zrNW6UfE+WIWY4yloJU3p88eYTfrHp1Ai6StDzZiPZrZNP7C5aV9CTZhcFC5/kE4E+SniM7fzxE9vC6X5Ld5/9c6vRPIvsGgCuB9dPyuWT32Df1u7cuAW6T9E3gQeDzRa0cEbMkjQDulvQB8AjZPfOL2uaxBj76HXCzpMPIpsHX5x/ArcoeUPj9BtZZVOyxkq4FnkqLroyIZwEk3UR2q8KbZBcBCn4GPJmWT6DxCw6jgH9KmpLu44fsVoa+EfHx4uZ5Udq0acOpp5/BcSOOYv78WoYM3Z91SzRSW4545YhZ6fE+/OB9zvn56dTOryXmB4MG78b2AwaWLJ7bTOuPN37cWP55952ss976HDZsKADHHT+S7QbUfQRNy6iGNpN3nZ724x8y5pmnmD59OnvsOpAR3z2eIfs1dF29+Sr9mChHzHKU0ZpH2a2uZmYLpafS94uID8qdF2tZku4ie9hgo4/UXZwp/WYAn86cm2u8Lh3aNr6SLdVmzqk7waq0OrRrbLJY65Z3fbapyf/e7bY1nqDcmrVvk/eX0tXvjQ9mlfVvnLVWap9bPXiE38ysCqSZHE8B45vS2TczMzOrVEvFVYdGpAG4GWTPq5oXEf2WJB13+M3sKyKiV7nzYC0rIqaT3V5hZmZmZq3DoObOuHWH38zMzMzMzKpHaxjibyG+CcbMzMzMzMxs6RLA/ZLGpAdTLxGP8JuZmZmZmZnlJHXgizvxoyJiVJ3Vto+IdyV1A/4l6aWIeGhxY7nDb2ZmZmZmZlVDZZ7Tnzr3dTv4ddd5N/0/TdIdwFZkX4m9WDyl38zMzMzMzGwpIamjpM6F18DXgYlLkpZH+M3MzMzMzKxqaOl/aF934A5lGW0DXB8R9y5JQu7wm5mZmZmZmS0lIuJ1YLOWSMtT+s3MzMzMzMwqkEf4zczMzMzMrGos/TP6W45H+M3MzMzMzMwqkDv8ZmZmZmZmZhXIU/rNzKxeM+fUljsLJdWmJt8JfZ/OnJdrvC4d8v8V36FdTa7xPvxsTq7xVuzULtd4eSvHMZ93m5lbOz/XeG1r8h1by/u8lnf5yiHvNjPuzU9yjdd/7a/lGm9p0Qqe0t9iKv8oNTMzMzMzM6tCHuE3MzMzMzOzKlI9Q/we4TczMzMzMzOrQO7wm5mZmZmZmVUgT+k3MzMzMzOzquGH9pmZmZmZmZlZq+YRfjMzMzMzM6saVTTA7xF+MzMzMzMzs0rkDr+ZmZmZmZlZBfKUfjMzMzMzM6safmifmZmZmZmZmbVq7vCbWUWSdLqk5yU9J2mcpK3Lnae6JN0jafkl2G6kpOWam05LmvreFL579HCG7bcXB++/Nzdd/9eKi3nmGaczeKftOXDo3iWNU1dtbS0jDvsmp/3geyWPlXcZy1GnedYnwKMPP8Q+e+7GXrsP5qorRlVUvHIc93nXZznaaJ5lrPTylSNeHnV6zQW/4qRvfYMzvnfIgmXPPPIAZ3z3YI7eZ1smvfpiyWJD/nVaCirzvzy5w29mFUfStsBewBYRsSmwK/B2eXO1kDLLRMQeETF9CZIYCSzo8DcjnRZTU9OGE37wY266/S6u/MuN3HrT9bzxv9cqKube+wzhokvz/8Pm9pv+xhq91solVt5lLEed5lmftbW1nHP2WVxy2ZXccefd3HvPXfzvtdK10bzj5X0M5l0+yL+N5l3GSi9fpbaZ7XfZk5G/OP9Ly1Zdc22+e9q5rNe7b0ljl6NOrXnc4TezSrQK8EFEzAaIiA8i4l1JkyStBCCpn6TR6fUvJP1Z0v1pnf0k/VbSBEn3Smqb1psk6RxJj0t6RtIWku6T9D9Jx6Z1Okl6QNLYtP2+aXkvSS9KugQYC/Qs5EfSsWkWwjhJb0h6MG1zaYrzvKQz07ITgFWBB4vWKy7XDyRNTD8j68S+IqV1v6QOLVnhK628MhtutDEAHTt2pNdaazPt/WktGaLsMbfo158uXZcvWfr1eX/qezzx6MPsse/+ucTLu4x5x8u7PidOeI6ePddk9Z49aduuHbvvsSejH3ygYuLlfQzmXT7Iv43mXcZKL1+ltpn1+2xOx85dvrRs1Z5r0WP1NUsaF8pTp9Y87vCbWSW6n6xD/YqkSyTt1IRt1gH2BPYF/gY8GBGbADPT8oK3I2Jb4GHgWuAAYBvgrPT5LGBoRGwBDAJ+Ly14NMwGwF8iYvOIeLOQYERcFhF9gf7AZOAP6aPTI6IfsCmwk6RNI+JC4F1gUEQMKi6ApC2BI4CtU56OlrR5+ng94E8R0RuYDpSsx/Puu+/wyssv0qfPpqUKsVTEzMOfzv8txxx/EsvIv65bQt71OW3qVHqs0mPB+27duzN16tSKiVcsj2OwnOXLS6WXsZqOiUpVMXWqMv/kyH9BmFnFiYjPgC2BEcD7wE2Shjey2T8jYi4wAagB7k3LJwC9ita7s2j5kxExIyLeB2al++gFnCPpOeDfwGpA97TNmxHxxCLycAHwn4j4R3p/oKSxwLNAb2DjRsqwA3BHRHye6uB2YED67I2IGJdej6lTphbzxRefc+rJJzLy5FPp2KlTKUIsFTHz8Pgj/2X5FVZg/Y16lzsrFaEc9RnEV5aphI+GzjteQV7HYLnKl6dKL2O1HBOVzHXa+vhr+cysIkVELTAaGC1pAvBtYB4LL3S2r7NJYfr/fElzI6LwG20+Xz5Xzi5aPrtoeWG9Q4GVgS0jYq6kSUWxPm8ov+mCxJrA8en9WsDJQP+I+FjStfXk+SvJLOKz4rzWAvVO6Zc0guxCCX+46FKGf+foRkIuNG/uXE49eSS7fWMvBu0yuMnbNUc5YuZl4vhneeyhB3nysYeZM3s2X3z+Oef8/BROO/PccmetVSpHfXbv3oP3pry34P20qVPp1q1bxcSDfI/BcpQvb5Vexmo4JipdpdRpNV2i8Ai/mVUcSRtIWq9oUV/gTWAS2cg/lG5Ke1dgWursDyLrxC9Smop/MvCtiJifFnchu0DwiaTuwDeKNpkBdK4nqYeAIZKWk9QRGEp260GTRcSoiOgXEf0Wp7MfEZx95s/otdbaHHLY8MUJucTKETNPR39vJDff9QA3/P0+fvar89i831bu7DdDOeqzd59NeOutSUye/DZz58zh3nvuZqdBO1dMvLyPwbzLVw6VXsZKPyaqgeu09fEIv5lVok7ARWmK/TzgNbJR642AqySdBjxZotjXAf+Q9AwwDnipCdscD6xA9iA+gGci4ihJzwLPA68DjxatPwr4p6QpxffxR8TYNBPgqbToyoh4VlKv5hWpcePHjeWfd9/JOuutz2HDhgJw3PEj2W5AUx6f0DpinvbjHzLmmaeYPn06e+w6kBHfPZ4h+x1QkljlkncZK71O27Rpw6mnn8FxI45i/vxahgzdn3XXXa/xDVtJvLyPwbzLB/m30bzLWOnlq9Q2M+q8n/HyhLF89ul0fjR8b/Y55Gg6du7CDZf/nhmfTOeCs37AGmutz0lnXdCicaE8dWrNo4WzVs3MzBb6+Ivaiv4F0aYm3wl9n86cl2u8Lh0q/5p+3nW6Yqd2ucbL28w5tbnH7NCuJtd4c2vnN75SC2pbk+9k2kovXznkXafj3vwk13j91/5arvHat1k6ZtNPmzG3rH/jdOvcNrd6qPyj1MzMzMzMzKwKVf7lfzMzMzMzM7NES8dEg1x4hN/MzMzMzMysArnDb2ZmZmZmZlaBPKXfzMzMzMzMqkf1zOj3CL+ZmZmZmZlZJXKH38zMzMzMzKwCeUq/mZmZmZmZVY0qmtHvEX4zMzMzMzOzSuQRfjMzMzMzM6saqqIhfo/wm5mZmZmZmVUgd/jNzMzMzMzMKpCn9JuZmZmZmVnVUBU9tk8RUe48mJnZUuid6XNy/QWxYqd2eYbL3dza+bnGa1uT/yS+vMtY6fLeh+XYf+Vop2aLo9LP3W+8/3mu8TZapeNS0dP+6PPasnaCV+hYk1s9eITfzMzMzMzMqoYf2mdmZmZmZmZmrZo7/GZmZmZmZmYVyB1+MzMzMzMzswrkDr+ZmZmZmZlZBfJD+8zMzMzMzKxq+KF9ZmZmZmZmZtaqucNvZmZmZmZmVoE8pd/MzMzMzMyqhqieOf0e4TczMzMzMzOrQB7hNzMzMzMzs6rhh/aZVQFJp0t6XtJzksZJ2noJ0xkiaeMWzttuKU/jJH0m6eX0+i8tGOOxlkqrTrrrS7pH0muSXpR0s6TukoZLuriFYgyUdFc9y/eRdEpLxGguSddKOqCB5W+k/TlW0rYtEOssSbs2N52WUFtby4jDvslpP/heyWM9+vBD7LPnbuy1+2CuumJUyePlHfPMM05n8E7bc+DQvUsap1jedZp3GSs9HriNtvZ45YjpeC2r0o+Ld96axMgjD1rwc/AeA7jzlutKGtOaxx1+q0qpk7UXsEVEbArsCry9hMkNAVq0wx8R90VE34joCzwDHJreH96CMbZrqbQKJLUH7gYujYh1I2Ij4FJg5ZaOVZ+IuDMizs0jVjP9KO3bU4DLm7KBMvWesyPijIj4dwvmb4ndftPfWKPXWiWPU1tbyzlnn8Ull13JHXfezb333MX/XnutomLuvc8QLro0nw4GlKdO8y5jpcdzG23d8coR0/FaXqUfF6ut0Ys/XnUjf7zqRn4/6jqWXbY92wwYVLJ41nzu8Fu1WgX4ICJmA0TEBxHxrqRdJN1RWEnSYEm3p9efSTpb0nhJT6RR6+2AfYDz0ojtOpKOlvR0Wu82Scul7f9P0uHp9TGSFvtyqKRLJT2TZiacWbR8D0kvSXpE0oWF0W9JK0v6VxpJvlzSm5JWKpQn/T9Q0mhJt6Y0rpOyiU4NpbsIhwCPR8Q/Cgsi4sGImJjerirpXkmvSvptUf4/K3p9gKRr0+trU9zHJL3ewIh5f0nPSlq7eBZBQ9tKWkbSJakO70qzEepLt6H92FC6knSxpBck3Q10a6SuAB4C1pXUSdIDaT9NkLRvSrOXslkSlwBjgZ4p/sS03klFeSrkY5KkM4vS2jAtb7AttJT3p77HE48+zB777t+SydZr4oTn6NlzTVbv2ZO27dqx+x57MvrBByoq5hb9+tOl6/IlS7+uctRp3mWs9Hhuo607XjliOl7Lq/TjothzY5+ix2qr063HqrnEa0kq80+e3OG3anU/WefpldT52ykt/w+wkaTCiPQRwDXpdUfgiYjYjKyjdnREPAbcSRqxjYj/AbdHRP+03ovAkWn7EcAZkgYAPwS+DyDpWEnHNjHfp0dEP2BTYCdJmyobVb8c+EZE7MCXR9N/DvwnIrYA7gDWaCDdzYGRZDMV1ga2byTdhvQBxizi877AMGATYJiknk1IcxVgB7IZGV8avU8XXC4D9o2I15u47X5Ar5SHo4CGptQ3tB8bSncosEFK92igKTMo9gYmALOAoWk/DQJ+X7joktL8S0RsDqwErBYRfSJiExa2zbo+SGldCpycljW1LSyxP53/W445/iSWqX8iQouaNnUqPVbpseB9t+7dmTp1asXFzFOll68aVPo+zLt81XCecbzWr5xlfOQ/9zFg591yiWVLzh1+q0oR8RmwJVkn/H3gJknDIyKAvwLfkrQ8WWfwn2mzOUBhhHsMWaexPn0kPSxpAnAo0DvFnAqcATwI/DAiPkrLL4uIy5qY9QMljQWeTeluDGwIvB4Rb6R1bihafwfgxhTnXuDjBtJ9KiImR8R8YFwq26LSXVIPRMQnETELeAFYswnb/D0i5kfEC0D3ouUbAaOAvSPircXYdgfglrT8PbL9UZ969+Mi0t0RuCEiaiPiXbKLRw05T9I4svZ3JNnF3nMkPQf8G1itKN03I+KJ9Pp1YG1JF0naHfi0gfRvT/8Xt9OmtoUl8vgj/2X5FVZg/Y16N75yCwjiK8tU4ifwlCNmniq9fNWg0vdh3uWrhvOM47V+5Srj3LlzeerRh9h+4OCSxyqJKhrid4ffqlbqmI2OiJ8DxwOFecjXAN8CDibrGM5Ly+emCwIAtTT8LRfXAsenEdgzgfZFn20CfAgs9twnSWuRjdbukp47cHdKe1GnjaaeUmYXvS6UbUlOR8+TXUhZnDjAl35bFddX3W2K8zSFbGR88ybGU53/G3MtDe/HhvL01d+69SvMCBmcbnc4lGwGxZbp3v6pRfE+X5B4xMfAZsBo4HvAlQ2kX8hfcR03qdySRii7beSZv13bUPJfNXH8szz20IMcPGQ3fvnTH/HsM09xzs9L9/zE7t178N6U9xa8nzZ1Kt26NeUuitYVM0+VXr5qUOn7MO/yVcN5xvFav3KVceyTj7L2+huy/AorljyWNY87/FaVJG0gab2iRX2BNwHS6Oy7wE/JOn2NmQF0LnrfGZgiqS1ZR64QcyvgG2Qd1JNTB35xdCHr/H0iqXtKC+AlslHfXun9sKJtHgEOTPG/DnxtMeI1mK6krVT/NwZcD2wnac+idXeXtEkjsaZK2kjZQ+mGNjF/04E9yUbGBzZxG8jqZP90L393oKFt692Pi/AQcJCkGkmrkE3Nb6quwLSImCtpEA3MfEj33C8TEbcBPwO2WIwYTWoLETEqIvpFRL9vDT+qyYkf/b2R3HzXA9zw9/v42a/OY/N+W3HamaV7fmLvPpvw1luTmDz5bebOmcO999zNToN2Llm8csXMU6WXrxpU+j7Mu3zVcJ5xvNavXGV8+IF72XEXT+dvDRoaoTSrdJ2Ai9K0/XnAa2TTqwuuA1ZOU7YbcyNwhaQTgAPIOmJPkl1AmAB0lrQscAVwRHo44A+BqyXtDBwD2dT+RQWJiPGSniUbRX8deDQtnynpu8C9kj4Anira7EzgBknDgP+SjYrPaEKZGkt3DWBmA9vsBfxR0h+BucBzwImNhDuF7HaJt4GJZPunKXmcKmlv4J+SvtOUbYDbgF1SnFfI9tUn9az3lf3YSLp3ADundV8hq++mug74h6RnyG6peKmB9VYDrtHCp/WfuhgxlrgtLI3atGnDqaefwXEjjmL+/FqGDN2fddddr/ENW1HM0378Q8Y88xTTp09nj10HMuK7xzNkv688X7LFlKNO8y5jpcdzG23d8coR0/FaXqUfFwCzZ81k/JgnOe6Hp5c0Tikp90fnlY8WzlA2swJlT3p/NiKuKndemkJSp4j4LD3o7U/AqxFxfrrQUBsR85R9FeGlacp4c9M9D/hrRDxXivKUWlG5ViS7kLF9up+/Yi1JW3hn+pxcf0Gs2KldnuFyN7d2fq7x2tbkP4kv7zJWurz3YTn2XznaqdniqPRz9xvvf974Si1oo1U6LhU97c9ml7cT3GnZ/B4m4RF+szokjSGbOv/DcudlMRwt6dtAO7IH+hW+230N4OY0IjyH7OnxzU43In7UIrkun7vS7I52wC8rvbOfNLctmJmZmVkr4xF+MzOrl0f4W1aljxKBR/hbmkf4zcqv0s/d1TrC//mc8naCO7bLb4TfZ1kzMzMzMzOzCuQp/WZmZmZmZlY1loppBjnxCL+ZmZmZmZlZBXKH38zMzMzMzKwCeUq/mZmZmZmZVY8qmtPvEX4zMzMzMzOzCuQRfjMzMzMzM6saqqIhfo/wm5mZmZmZmVUgd/jNzMzMzMzMliKSdpf0sqTXJJ2ypOl4Sr+ZmZmZmZlVDS3lM/ol1QB/AgYDk4GnJd0ZES8sbloe4TczMzMzMzNbemwFvBYRr0fEHOBGYN8lScgj/GZmVq/Vlm+3RNe/JY2IiFEtnZ/WHq99myW7xp53+ZoTs7WU0fHqt6T7rzkxHa8645Ujps9r9dtolY65xltatG9T3qf2SRoBjChaNKpOfa4GvF30fjKw9ZLE8gi/mZm1tBGNr+J4S3G8csR0vNYdrxwxHa91xytHTMdr3fEqSkSMioh+RT91L57Ud0EiliSWO/xmZmZmZmZmS4/JQM+i96sD7y5JQu7wm5mZmZmZmS09ngbWk7SWpHbAQcCdS5KQ7+E3M7OWlvc9fY7X+mM6XuuOV46Yjte645UjpuO17nhVJSLmSToeuA+oAa6OiOeXJC1FLNGtAGZmZmZmZma2FPOUfjMzMzMzM7MK5A6/mZmZmZmZWQVyh9/MzFotSV+TtGm582G2tJC0jKQuJY6xuaQDJG1Uyjh1Yh4v6Wt5xTMzqxR+aJ+ZmTWLpG2Ai4CNgHZkD5f5PCJK0umQNBrYh+x32DjgfUn/jYgflCje9sC4iPhc0reALYALIuLNEsb7BbAmWRkFRESsXYp4KeYK9SyeERFzWzhOe+BYYF1gAnBVRMxryRjlJGmLRX0eEWNLFPd6snqtBcYAXSX9ISLOK0GsM4BvpTi/lfTriLiipePUowfwtKSxwNXAfVHCB1FJWhk4GuhF0d/LBs3NwwAAq1xJREFUEfGdEsXbr57FnwATImJaCeLlel5LMX8L/AqYCdwLbAaMjIi/lSjeBL76veWfAM8Av4qID1s43u+Aa5b0wWpLu7x+T1jL80P7zMysWSQ9Q/Z1MbcA/YDDgXUj4vQSxXs2IjaXdBTQMyJ+Lum5iCjJSL+k58j+MN0U+CtwFbBfROxUongvASeRdahqC8tb+o/TOjEnkX3f78dkFxiWB6YA04CjI2JMC8W5CZgLPAx8A3gzIk5sibQbiZvLRRRJD6aX7cmOhfEp1qbAkxGxQ0vGK4o7LiL6SjoU2BL4CTCmFMeEpOeB/hHxhaQVgXsjon9Lx2kgtoCvA0eQ1e/NZBeN/leCWI+RtdO6x+FtLR0rxbsb2BYotKGBwBPA+sBZEfHXFo6X63ktxSy006HAELLz3IMRsVmJ4v2WbN9dnxYdlP7/FNghIvZu4XhHkbXNNsA1wA0R8UlLxqgn5rLA/nz1wtRZJYg1iRx+T1jL8wi/mZk1W0S8JqkmImqBa9Ify6XSRtIqwIHw/+ydd5hdVfWG3y+hl1AEEVCqFBFC70hRBKWJ0kRBmlhAqqICKk2lqiAogmBAlI4g8JMOCb0FQgdBQAEBRSmRTvL9/tj7Mndu7kxg5uxzMzfrfZ48M+fczPn2zNx756y91voWRTYVWnjHtiV9jpQBO1XSDgX1XrZ9WcHrt+Ny4ELbVwBI2gD4DCmg+jWwakU6S9leJmucCtxe0XUnx6m02USpGtvrAUg6G/ia7fvy8dLAd0rpAtNKmpYURJ1g+21JpTI6b9h+DdImlKTa2kPz6/A54DngHWAO4HxJV9n+bsVyM9n+XsXX7I+JwMdsPw8gaR7gRNJr73pSUF4ldb+vAUybP25ECob/m/ZwirGm7TWbju+TdJPtNXNVQ6XYPgU4RdISpMD/Xkk3Ab+1fV3/Xz1g/kyqWhgLvFlIo0FdfyeCiomAPwiCIBgsr0maDhiXMyrPAjMX1DuUNJf2Rtt3SFoEeLSg3nhJ+5PKmNeWNJyeG9cSXCfpaOBPNN3AlSoHz6xk+xtNWldK+qntfXMGqSreLf3MM4YrvHS/1L2JsmQj2Aewfb+k5QrqnQQ8SaoouF7SgqQsZgkWlXRx/lwtx9jerISopD2BHYAXgFOA/fLGxjDS67/qgP9SSRvZ/kvF1+2LhRrBfuZfwOI5KC5RMl33+xrAJbmC6XVgt9w28UZBvVkkrWr7NgBJqwCz5MeKtBLln+OS+d8LpNfkvpK+bvuL/X7xwPiw7c8UuG476vo7EVRMlPQHQRAEgyIHF/8i3SzuA8wG/Nr2Yx1dWEVI+hDwJeAO2zdIWgBY1/bvC+m1ywTZ9idL6GXNK4FrgLPzqW2AT5OyN3fY7rc3/X3oTABebRwCMwKv0VNiX8r34QiSt0QtmyiSziJ9n38g9RBvB8xie9sSem30BQwv4Y8gqd+Sb9tjqtbMuoeSyvcn6TGX9DHbD1WsN560cfkWPRtVJZ+jvwYWILVGQSrTfhrYD7i0UT1SoV6t72tNunMAr9ieIGkmYITt5wpprUzye5iF9B7zCvBV4AFgY9vnVqz3c2BT4FrSc/X2pscesb1ElXr5uicDxzdvMJairr8TQfVEwB8EQRAMKSQtDOzBpD2LpTKLCwPP2X49H88IzGP7yRJ6nUDSXMBBwFqkG+MbgUNIpaILDPXNm7o3UbI54TeBtfOp64ETbRfJZkr6KXCU7Zfy8RzAt23/oIReP+s4x/Y2ha59hu3tJ3duqJI3abYA1qTnNXhBKWPCTr2v5faWpUg+FwDUsMkwGynmeamwzs7A2Y2Wl9Y1lOjnl/QgyQT1CdJmZmPztIR/R1f/nehmIuAPgiAIBoSkc21v3YcTMgVN9O4h9WTfR+p7beiVyizeCaxh+618PB1wUymjsnxzehA9weIYkmlXUfOnTiPpH7YX6PQ6hiINI8uWc3fVnXEr+Tts/X5y6fR9tpcqoZc1NqPndTja9qWltOqm7ve1rHEQyYxwKeAvJOPOG21vWUivNkO7rHeN7U9N7lzFmgu2O9+uEiaYeoke/iAIgmCgNNzVN6lZ9w3bv6xRb5rGTTGA7bfyzXEpfgfcTzIlBNie5PjcbmxXJUhanGQqtxC9b4yLtRG0W0axC9e8iaJJpwIA4HKjFYdLmt72m1l/RqArempzn/kBwIySGr4EIpXan1xQ9whgZeCP+dRektay/f1Cel8AjgQ+SPr+ira5UP/7GsCWpMkAd9veKRsTnlJQrxZDu1zRMxMwV66uabyXjQDmK6ULKbCXtCzwiXzqBtv3lNCaQv5OBAMgAv4gCIJgQNh+Nn+sO5NwXM4UXUk9pnb/lrSZ7YsBsqv1C4W0ABa1vUXT8SGSxhXUg9Q3/BvSzXcxF/vJULLksO5NlFqmAjTxB+AaSaNIP8edgdNLCEnqq2pAFDB9s304cLikw23vX/X1+2EjYDnbEwEknQ7cDRQJ+IGjgE2r9iLoh7rf1wBetz1R0juSRpC8X0ptgkF9hnZfB/YmBffNf4deAX5VUljSXsCuJH8SgD9IOtn28QXkpoS/E8EAiIA/CIIgGBDZ1KrPIK1gZmoZUsD2SXpK+p2PS/AN4I+STiAFNU8BXymkBfB6ziTeCO9mi18vqAdpRNeJhTWQtG9fD9Hjnl2CujdRap0KYPuo3FrzKdLP8jDn0VkF+Fk/jz1ctZikJW0/DJzXbrOh4EYfpDnj/82fz1ZQB+D5GoN9qP99DeBOSbMDvyVthv2PsqM5b5a0TGlDO9vHkTai9ygUaPfHLsCqtl8FkHQkcAtQYh21/J0Iqid6+IMgCIJBkd2znyPNiRbwZWBW20cV0nsYGNlcjloHkmYh/d0cX1hnOVJ2djbSz/O/wI6lyjSz5sGkbNuF9K6a+G9fXzNAnYP6e9z2IVXqNeneQhrj1ryJcozt1Qvp1ToVoJuR9Fvbu3bAeHFb4AjgOtLrcG1gf9tn9/uFA9c7DvgQcBG9nzN/6utrKtKt5X2tje5CJIf+ewtq1GJoJ+mTtq/NbRmTUPJ3mDf6Vm4Ygub2gjtsL1NA62Bq+DsRVE8E/EEQBMGgkHSb7VUnd65CvXOAPWz/q8T1m3S2s/2HvrLStn9eWH9E1ik1T71Z64k2p12w57xW6t5EqSs4lXSj7bXaVNsU6/+WtHZ/j9u+vmrNTiFpXlIfv4DbXGh8XNYa1ea0be9csU7H3tfyJIIvA4vYPlRpFOCH3DS+rmK9WgztJB1i+6C6foct2vsCO5CCcIDNgdNsH1tAq6v/TnQzUdIfBEEQDJYJkr5Mms1rYFvK9vfNAzws6Q56ZxmqHss3c/44a5vHKt8t7+tGPN0jl70Rt71wqWs3I+lH/S/Dh5XQtT0OWLauTRRXPDO9H5218sd2z9FS7NduKSQztg+TKhsqo6+s6bvCFWdPGy0ETe0DT+eP80mar1SVhu2dSly3DbW+r7Xwa1Ib1ieBQ4HxwAWkTZXKkDQiv8ZrqVqwfVD+WNfvsFn755JG0zMqbyfbdxfSquXvRFA9EfAHQRAEg+VLwHH5n4Gb8rlS9FsWXhW2T8qfXm37pubHckl41dR+I96BUtRX25ybmdSH+gGg0oC/U5soHZgKUNuMetubtuisBRwIPAt8q2o9YNN+HjM9ZmVVsS/wNdp7FVTuFSLpu9mD4Xjajzfds0q9DryvNbOq7RUk3Z3X8mKhyQBnkqbHjCX9TJsngJiKjQL78SZJggXeZxqbGpLmBJ7M/xqPzVllmX0nWxaCaoiAPwiCIBgUtp8EPlej3phcqrmY7aslzUTFWcUWjgdazcLanRsUHboRXwe4lvZBVeXBlO13gyhJs5JGO+5Eqg7pzwxuoHQqm1n3VICPNx9ImgZYsZBWQ+NTwA9JP8ef2r6qhE7dWVPbX8uffrbRF90g90dXTcOo784C1+6PWt7XWnhb0nDya0/S3PQYr1aG7U3yx7oy0nVW2DRo3dRoIKrf1Kj170RQPdHDHwRBEAyKPJv3RGAe20tLGglsZvvHhfR2JWXg5rS9qKTFgN/Y/lTFOqsDa5DGLf2i6aERwOdtL1ulXpPuXbZXmNy5oUrOSO1L6uU9HTjO9ouFNddst4nSeq5CvXG2l5vcuQp03p1RD7zWOE2eUe8CY+wkbUzK6L8M/LjUz7Af7Y8D7wbetg8tpFXb6zAHwUfYbtcuUbVWR97XsvaXgW1ImwqnA1sCP7B9XkHN+YEF6T03vmt8JoLgvRAZ/iAIgmCw/JbU13sSgO17JZ0JFAn4gd2BVYDbst6jkj5YQGc60qi4aeidwXmFdKNaKU034nO3lIiOoGwFA5KmB7YAFqL3jXGlwZSko0lZ7pOBZWz/r8rr90Pd2cxaRiu6MzPqLyH1tf8H+F6jPaJpTVV7aQAg6TfATMB6pDngW1JgpJukDwHzAzNKWp6ecvARWb9ybE+QVLQio4la39caSBpGcsv/Lj3jIzd3wVGEeUTdNsCD9PjKGCgS8OcKkF2YdFOqpGnfNa2b3e3OVaS1F6lSaTzp7/4KwPdtX1m1VlAtEfAHQRAEg2Um27e33Pi/U1DvTdtvNfRy+XLl5Wq2xwBjJJ1WtatzH3TkRjzzZ1LGdixNRogF+Ha+/g+AA5ueM0Vc5Tu4ifJN4PTcyw/wIslJuxSXSprZ9quStiPdiB9X6HlbiyFhG9awPVLSvbYPkfQzypQSbwjsSDIgbO69Hk+qpijF3ZIuBs6jyeui6v7oDryvNXQnSvqZ0yjMh2uS3RxYwnbJ97RmziB9bxuSTAm/TE/LRqXkzYWZgLkkzUHvjan5SmgCO9s+TtKGwAdJ7VijgAj4p3Ai4A+CIAgGywuSFqWnL3NLkoFXKcZIOoCUgfs0sBsp61iK13JmujVrU6l5V6duxDMftv2Z0iK2h5XWaKFTmyj32a5tKgCppWZZScuSMqinAr8n9d5WSn6edoJGhcRrkuYjVRhU3qNt+3TSZs0Wti+o+vr9MCfpe2p+XynZHz29pJOZtKqn0ve1Fq6UtAXwJ9fTU/w4MC1lNzGb+ajtrSR9zvbpudLtikJaXye1ZcxH2qhtBPyvAL8qpNnQ2AgYZfsetZb4BFMk0cMfBEEQDApJi5BKtNcgZTKfALbLZn4l9IaRyiY3IN2AXGH7tyW0st6VwDnAd4BvkDK1/7b9vUJ6VwFb2X4pH88BnG17wxJ6WeNk4Hjb95XS6CSSFqxzE0VpXvX5wO9Kliw36d2V3c9/BDxj+9Ru8n0AkPRDUhvGp0gBjYFTbP+woGZtngF1I+ke4DekYPHdMaq2xxbUHE8y0nwHeINClT1NeheQxkVeQ+8RrpVOPmjSu932KpKuJ21EPwfc7oJz6iXtYfv4Utdv0RpFandZmPRzHQ6Mtl1XO0owQCLgD4IgCCpB0szAMNtFZx9L2sv2cZM7V6HeWNsr5lLikfncGNuVZ0/zte+2vfzkzlWs+SDwUdJmzZv03IiPLKVZJ9kN/LsUrtJo0psV+CKp5HUYybX/7FKZfkljgMuz3trAv4FxtpcpoddpsufEDC405jBrtPUMsL1LIb26zU/HdnugJqltG02u4iih91XgAmAkqdR9FuBHtn9TQq9Jd2lgKXq/t/2+Yg2R2lzmBh63/ZKkDwDz2763Sq2geiLgD4IgCAaEOjB7OOu2c88uFhBLutX2apKuAH4J/BM43/aihfTGktyy/5GPFwQuLJmtzRqT0IHWgiLUXaXRor02cBYwOynrf5jtxyrW+BDwJeAO2zdIWgBYt+qb/ia92lzlmzS/0u58we/x3ibPgJGSZiGVom9QSG8M2fy08V4m6X7bSxfSOxj4F3AhvbPflc1v70N3DmAxegen4Zo/QCQdBKxLCvj/AnwWuNF2CWPZrt8k6laihz8IgiAYKMcA44DL6MkKF0PStqSgZuFsbtVgBKn3tRQ/zuZr3yaVFI8A9imodyBwYw4AIGVsv9bP/x8wkkbkrHPRqowWzeGkNoz169IEPpDL3Pdq8koo1ouev8eNSRn3hYCfAX8EPkG6KV+8Sj3bz9FkMJc3i4oEwvn6EyStKEk19WIDrNz0+Qyk0v67KPd91uIZ0ETd5qeN7Hfzpk3V89t7kTPge5EyxeOA1YBb6O1bUIXOuba3lnQfbQxdq65c6tTmd2ZLUnn93bZ3kjQPqSKlBLdKWtn2HYWuHxQiAv4gCIJgoKxAKlvemNQHehZwTcEA4GaSGeBcpACqwXigWEmh7Uvzpy9Tg0O57cslrUC6GRawj+0XCsmdCWxC+v2Z3ps2RW7+c7D4mqTZSpZkt/B2/vhs7sv+JynoKMWjwHXA0bZvbjp/fs74V4KkG22vlXujm193RXujM3cDf5ZU1FW+6bp7NB/nTbgzSmhlLpU0O3A0aWPBlAukoGbzU9slNy/6Yi/Sxs2ttteTtCRwSCEdSO9tddAwBF2C9P01NqQ3pdAIwCZed5qA8E42Cf0X5TZt1gO+LunvpNd8V7V+dTNR0h8EQRAMGklrANsC6wPfs33xZL5kMFoz03OTsziwJHCZ7bcn86UD1VsY2INJ3ayLzBvPml1d9irpXNKGxlX0DhZLmWltAtwAfISeKo1DSj1PJc1i+38lrj2lkA28WrELzhxv0Z8WuNf2xwpdf3rncW4NzwDgDRca8daH+emXS7bV1NH73aJ3h+2VJY0DVrX9pqRxtpcrpVknuXVoi4aPTfbyOM8FJ6BI+jVpXOQXSVVo/yP5d+xUQKurW7+6mcjwB0EQBIMiG6ItDywDPE3KMJTkeuATOSi+BrgT2IY087gEF5HGnF0CTCyk8S51lb1mrX59AWzfVbVm5v/yv+Lk8vrFcqVGLVUawHyS6jRgW6Dd+YYPRAlKBBT9IekSeqoYhpEC1XMLSt5CqmIiB/lvSrqrca5qbD8OrF+j+Wnb3m8KtoIAT+eqiYuAqyS9SKq2qZS+Kl4oX/myAPBW0/FbpI3iYtjeLX/6G0mXAyNKmeg1AntJH6RpkyiY8okMfxAEQTAgJO1ECrRnIJmRnWu7dLDfPIJsD2BG20cVNu27zfaqJa7dh9599JS9Ltcoe7W9TQGticADJFd3aCnpL+Vin7Wno6eX/ZFSFRpZ6zrbdQT6Db26DdiaxynOQOo1f8T2x0voZc0Pk6ol1iQFUzcCe9l+upBe81SMd4C/l9DKBojzA38geYY0XhMjgN/YXrJqzaz7N+BWUiXK9bYfLKHTpHcfPb3fyzZ6v21vWlK3SX8dYDbgcttvTe7/v89rXwR8CPgTaTpGsY2vFt0Dga1JRogAmwPn2D68oOY1wM9s/6Xp3Mm2K/d9kbQZqZ1uPtLG/oLAQyXfZ4JqiAx/EARBMFBOBe4D/gFsCGzQbDhVsORdklYnZfQbI7JK/j07LmfDrqS3m3Wp7Pcbtt+Q1CgrfljSEoW0vg1sQTIoO5s0DaB4KbqkdYHTgSdJAdVHJO1QsG3hZkknkJz6m1sISv0OazVgc8v4vVy58fVSeplRJA+IrfLxdvncp0uIZbPFOtgQ2JFUYdNstjaeVDpdiqWAVUnGjsfkjb57bH++kF6dvd+TUPL3aXvz7PHwBeC3kmYgvfbPLjmFwPZPJF1G+h0a2Mn23aX0MgsD38tmeg0/hJUKaR1Gqji72vbyktYjtfIFUzgR8AdBEAQDpbaMaQt7AfuTgtMHcu/rdQX1lgG2J5XUN0r6TYES+0wtZa8Atn8B/CL7FGwLXJMNmX5qe1wJzczPgA1sPwLvziA/Cyg18mmN/PHQpnMlf4e1GrC1YvsuSStP/n8OirltN/fxnyZp71Jibcq0IbVo3Al8O5fEDxqnGe2nS9rC9gVVXPM9MoFkLjmB9D7zPGXbo+7M7zO/JZl2/g+4vaBerWRD0FGSTidVoh1Pqn4p6ZgPPb8/U0MLGPASaWLFL3Pby3YFtd62/R9JwyQNs32dpCML6gUVESX9QRAEwZBC0tK2769R72FgZNVlp+9Ru1jZaxutj5OMn7YHvmu7WH+08mzzyZ0bqtRtwKbeY8GGkfrMP2B7wxJ6WfNq4DTSRg2kDaOdbH+qkN4hpI2vM0lVIV8klW0/AnzT9roV601Pqn5ZiN5mnYf29TWD1HuNVDH1c1IGteSo0VbthSjY+90JmoxkP0FqNznH9g2FNfcCdgUuID1HPw+cbPv4gprvtrNJ2pFUtTWH7cqnkOTX/ObA4aRpOf8CVra9Rn9fF3SeCPiDIAiCIYWkG4HpSMHGmbZfKqx3DrBHTf4Ew0jO40V6vdvoLUIKnD4HPEUq67/U9huFdX9HyoA1xqp9GZimlBFc7k/+KTCf7c9KWgpY3fapJfSadOs0YGvwDqlV4oKSv8dsFHgCsDrpd3kzqYe/1KbGJF4akm61vZqke2wvW7He5aQKgrGkrC0Atn/W5xcNTu9zwFrAKiSzt5tJvfzXlNDLmiOZdEOjyFjFbJ55he31S1y/RetJUub7bOBaWtppSrXySLqX9L7yaj6eGbil5EampK/bPqnpeEVgdxeYliFpJuAN0qbil0mb0X+sc3MqGBgR8AdBEARDjlwCvhOpf/h24DTbVxbSGg2MBO6gdw9/EY8CSX8E9q/DaCqb9t0L/Bl4hZaSadtFyl9z9nR3UoAj0uSFX7vcyLPLSP3lB2aDsmlIZmXLTOZLB6K1DvCi7XslbQ2sDTwGnFjq+6sTSUfa/p6krWyfV6PuLcAvSAahAFsC++aAv/LRbiVNFiejuyTJMX9v4IO2Zyyk8zvS+9oDNLUqlQgUmzQvBrbP5fbFyO/Zjfeyhjt/g2JmpA3D1cZGW/YOuKPQ+8wI269ImrPd41V6FUhalVSxtCipCmWX0qaSQbVEwB8EQRAMSXLGaHPgl6RgVcABVWeoWtzB36WU6ZSka0ku/bfT22Cu8g0GSQczaV/0uzSZQFWld43tTzWCxiqvPRndxvzv5vLXEkHir0hB1PTAX4FZgMtJpf3DbRcZHZkDqVYa/e0nVZnpz0HNCsBttouMqOtDdxHgOHoqCm4F9gGeAVa0fWPFeicDx9u+b7L/uRq9C4DlSJtDN5I2wW4rVaUh6UHbS5W4dj+a55JM366i93vbnnWuoxS5tWYHerv0n2b72AJal9reRNITtN/UqMyAUdKdJN+c64HNgK+WbBcKqicC/iAIgmBAqPdc7EkomAEfScrub0y6cTw1m5TNRyqfXLCEbl3UvcFQJ5IeBL4J/IbeI8+AoqW2o0n92Fc5jXRcDTjSdtuf9SB0HrS9VM7sPUPK0E5Qsuu/t0SmL+seB8xNTz/9NsBzwIyk3uztK9Q6GvgaMDPwGtQ247xW8nP1oyT/hTfp+f6KlGdnk8W7bE+Y7H+uRu9U0ji32jK1knZodz4bJXYFShMy3q1cckGX/vy+8pHS1WDKo3D7Og6mfMKlPwiCIBgox3RI9wSSs/QBtl9vnLT9T0k/qFqsLnfwJjZqzX5nJ+QhH/ADPwK+z6Qjz6Csa/6+wMXAopJuIgXHWxbQeQPAaazi3xvBm21LeruAXoPlba/ddHyJpOttry3pgSqFbO8H7Cfpz7Y/V+W1+0PS3CRDtIXo3XNeqgT9s4Wu2xcLAQ8D4/P72ArAj0ttgpHGYt4i6Tlq2NAgXfx0STMCCzhP6OhCniB5BkxDislXKPU7zO8rF1JuukmD2SV9oa/jUr4PQXVEhj8IgiAYkkiaFlgaeKakoV4H3MEnyZ50k4M9gKQf2j6sZs1pgCVIv8NHbFcegEt6mrSRIVK5eWNTQ8Detj9StWbWfQjYsJHpy4Z6l+dqg3fbGIYykm4GbmBSE71io/MkrQUsZntU3nCYxfYThbTutT0yax5O2lA9oNWosEK9x0gbYffRND6ulOli1tyU9H1NZ3thScsBh5aqBqsbSYcBOwJ/o8lDoJRnQNb8Falt4I6CGqP6ebio70NQDRHwB0EQBINC0mKkG9SlSHOOAaiyhzDr/IbUU/uApNmAW0g3/nMC37F9Vr8XGLhuLe7gkr4J7EYyRnqs6aFZgZtL9X9n7YVbA5l254YySmO6FqJ3dvj3FWsc1N/jVXsiNOluRGqT+Btpc2Fh0nNpNLBriR7iuinhuTAZvYOAlYAlbC+eW4bOs71mIb27bS8v6XDgPttnltyskXRtyUC0D82xpCqe0U1eGvcVbHW5xi1jItudq1DvEWAZ1zjCNbeeLA78neSLULxSIxh6REl/EARBMFhGAQeRHLTXI/XXq9+vGBifsP2N/PlOwF9tby7pQ8Bl9PQvV83E7Lbe7A7eoMpd8zNJ38fhpLL3BuOrdFzugwtIJcTNnE/5UtFakHQGaSNlHD3ZYQOVBvylAvr3oPuXvPG2JOm193CT2duxnVhTAS6VtJHtv9Sk93lgeeAueLdlaNaCes9IOglYHzhSaZLFsIJ6D0s6E7iE3tNHSpZnv2P75dR6/i6VZx6zh8ZMwFyS5qDn79EIYL6q9Zq4H5idNJ++LupuPQmGIBHwB0EQBINlRtvXSFIuBz1Y0g2kTYAqac6afBo4D8D2cy03kFXzZZI7+K/pcQffLveifqsqEadRVS9LOrW1rFbSDiWMrZRGgH0cmK2lR3METdUaXcBKwFLu7rLGFempYBgpqfIKhg6zF3CApDeBtylvEvhW7pE2vDtTvSRbA58BjrH9kqR5gf0K6s1ICvQ3aDpnoGTAf7+kLwHD8wbVnsDNBXS+ThprOB+pBaTxB+IV4FcF9BocDtwt6X5qGOGar/13AEkfpLves4MKiZL+IAiCYFBkE7RPkDLC15LcyY+wvUTFOtcBP8vXvw5YMgf70wD3216ySr1OIel60mzs75DGup0CvGm7cpM5SZ8jjY7ajGRq12A8cLbtEjfjSFoUeNr2m5LWJY2y+73tlwrpnQfsafvZEtfvNH1VMLjguDOl8Xx9mVn+2PZ/SmnXgaTvAIuRNhcPB3YGzrR9fEHN4cA89G47KerAXieSZgIOJG0yCLgCOMzlRg/uUfL31UbvAeAkJvVFKGa4Kmkz0t/F+UiVBQsCD9n+eCnNYOgRAX8QBEEwKPI4qYdIpYyHAbMBR9m+tWKdxYFfkgzzjrV9Wj6/IbCB7W9XqdekOwOwCykT3uxRUMSoKI9a+jYpSwXwo1L+BE2aq9u+peXcdKV6USWNI2XdFyLd9F9M6pXeqJDedaQZ57dTU+atTrJpX60VDJKOIm0unJlPfTF/fAVYy/amFeksafthpXFnk1DQxR5Jn6YpOLV9VUGtPUhVUc/TEywW68XO76cnAvPYXlpp3Olmtn9cQq9T1OHd0aQ1xhWP+nwPmveQfBGuzh4Q6wHb2v5ahRpf6O/xcOmf8omAPwiCIAj6IWeHHybNjT+UVOL/kO29CunNScoSzUoaX/cH0sz4Yn+wlebU72j7yXy8MnBKVYaEbfTusr2CpP2AN2wfX9igrO1NeNWZN0n79ve47dZRhFXp1l7BIOmmVgO7xrkqjdgk/db2rnnTppWiDuhZfwS9g8UifhrZNX/VuiojJI0htQyc1GSgd7/tpQtqLk6qXFqI3j/TIr/DuitfJP2ctKF4Mb03FktuSt1pe6Uc+C9ve6Kk222vUqFGw6X/g8AapEo+SJ49o233uyEQdJ7o4Q+CIAgGhKRjbe8t6RLaGC91S/YU+KjtrSR9zmmO9JmkrHQpbiW1RPwu+wQcCdxEutEqxeHA5ZJ+CcwPbEQyRizF25K2BXYAGpngaUuJ2R4jaUHSiLWrc2nx8AJSDVO3JYCV6WmT2BS4voBeg7mAByXVWcEwi6RVbd8GIGkVUgsKpDnklWB71/xxvaqu+V6Q9HXSBt/rpIy7SO9zlU4faeIpUktEXcxk+/YW/5PKfm99cB5pmsQpNI1WLEjd3h2NDcvVms6ZlIEvxUuSZiG9v/xR0r+o+PdoeycASZeSfp7P5uN5KeuJEFREBPxBEATBQDkjfzymo6soT2Ne+0uSlgaeI2WoSrF+o2/X9uvAnpLWLqiH7SskfQO4CniBlCl6rqDkTsA3gJ/YfkLSwqRKhiJI2hX4GmmE46KkTY3fAJWO52q49Eu6EljB9vh8fDDZZLIQBxe8dl98FfhdDjZEKuX/aja3O7wqkQ6WE38H+LjtFwpdv5XHgdGS/o/emzZFqkKAF7KXRsOUcEugdIXIO7ZPLKzRzP2kFrBaKl/q3pTKfA54A9iHVH02G2mjqgQLtVQRPU8aCRhM4UTAHwRBEAwI22Pzp3cCr9ueCO8aT03fsYVVz8l5tNMPSBnbWYAfVi0iaTvbf7D9D0lr2r6p6eGRFMwQS/ohySV87aw1WtK3bf9fCT3bD5IcuhvHTwBHlNDK7A6sAtyW9R7NrtalWIDeUyXeouAmUUlTsH407wCWkTQbqUX0paaHz61Qqj8vgJKu8n8DXit07Xb8I/+bLv+DAiPrmtgdOBlYUtIzwBOkgLFycpsSwCWSdgMupPemRqmxo7VUvjTeu/tq6Sm4aYPtV/MaRpBGLJZktKQrSCNwTfLtaNdqE0xhRMAfBEEQDJZrSLOj/5ePZwSupFAJuqR5gJ8C89n+rKSlgNVtn1pAaxjwiu0XSQF3qXJegH3pyXIfDzSblO0MnFBQey5glVxRcIuky0llt5UG/H04u0PPiLUiBmWkKQdvNcqX82SHksHUGcDtki7MOp8HKjcKk3Sj7bUkjaf391N6ZB1Kc+K3IPdjN362tivNLjbKiTvA/sDNkm6jd7BYpP+7UR3SIJuFVmJ82Ife48D6uSJjWKMapRBjSc/PRv9A87jBkm0SBxe6biuNkY2ztnmsaDtBna0ntr+VK24+kU+dbPvCqnWC6gnTviAIgmBQSBpne7nJnatQ7zJgFHCg7WVz8HZ3VSZhbfSut120pD7rvGta12pgV9LQrkljRmAB248U1Fiwv8edZ0oX0D0KeAn4CrAHsBvwoO0DS+hlzRWBtfLh9bbvLqXVCfKm0MukYO7dfmzbP6tYpyPZ05wVvpFJR6ydXkIvaw4nTQXYNn+80RWP45S0KXCve+a3/4i0cfN3YK9cbVMESTO4ZQRfu3MVa07i3VFqc6NNZVbbcxVrPkra8K6r9SQYgkSGPwiCIBgsr0paoeFEnAOd1wvqzWX7XEn7A9h+R1JJA6irlGZynwO82jhZoAzVfXze7rhSchBwDKmUeGFJywGHVl362hzQt9yIz0jZe5Lvk0Yr3kfq5f8/26cU1IPkDP4s+fuStIArnqneVCrdloKl0gAftv2Zgtdv0Kns6Tu2+526UBXZo+NLwMak0ZFrAovYLtFS8BOyqZykTYDtSBsMy5N8LTYsoNngZnpXLvV1rhLq8u5oorUyq69zVVJb60nO7h9JcusXNVQSBdUQAX8QBEEwWPYGzpP0z3w8L7BNQb1XJX2AHrOp1Sjrbr1z/rh707kSJZNLSrqXdBO1aP6cfFyylQBS6esqwGgA2+OykV4R2tyIf5gCN+KSPkcKTH8F/Dbrzg2sKOkl2+dXqdek2zxTfQI9ZbZVtyy0lko3U7JUGlK5+zK27yuoge2T8qdXt8ueFpS+TtLXSH3RxfrNJT1N6t0/EdjP9nhJTxQK9iEFaI1rfwE4NfuxjM399ZUj6UOkYHtGScvT83wdAcxUQjNTi3eHpNVJLWxzt1SijKDMNJBm6mw9OQrY1PZDBa4dFCQC/iAIgmBQ2L5D0pKkUWQCHrb99mS+bDB8m2Set6ikm0gBXKVlr83YLhb4tvCxmnTa8Y7tl1tGdJU2DKvDRO+7JGOpBtMBK5KMF0cBRQJ+YC9gCReeqV7jc7MdawE7SnqCFGiU9mGoO3v6pfxx/6ZzJTZRLgA2J22STpD0Z8q+9pQnK7xG2mD7ddNjMxTS3BDYkbSx19yC8QpwQCFNqM+7YzrSe8o09K5EeYWCf5syJwHX0tJ6UojnI9gfmkTAHwRBEAwKSdMC3yQ5vENy8j2pVNBve6ykdejZYHikhJakVUku1ouSbqZ2LnmzU6p/vT8kfSGPNbtf0peA4ZIWIzno31xQurYbcdtPNR3fmDO0/81mZaWoe6Y6kjaj6TVo+9LCkp8tfH2gc9nTujZTbO8laW9gPVJp/dHACElbA3+x/b/+vn4AHEtqN3kFeMj2nQA5815kfF32PThd0ha2Lyih0QdjJB1Aqiz4NMm7o3In+zwlY4yk0zrwPl5b6wlwp6RzgIvoXU1QalJGUBFh2hcEQRAMCkmnANMCDTOr7YEJtr9aSO8eUj/9Obb/VkIj69xJyu5dD2wGfNV2yf7W2pF0l+0VspnVgSSjMAFXAIeVMtOqy0RP0mO2P9rHY3+zvWiVek3XPpW0IVXLTHVJRwArA3/Mp7YF7rS9f99fNWCtEbZf6cs/oEDJ+zrAusA3SG0fDcYDl9h+tEq9Jt0vtDn9MnCf7X+V0My60wKfIRv32Z6rgMb8pD7se9wzTnVeYNqqfSaaNJcmVdwsRdrcexA4pmRLiNKUlV3o/b52iisOfiRdQj8bllV7obRo/4RkuFi09SRrjWpz2rZ3bnM+mIKIgD8IgiAYFJLusb3s5M5VqLcgqfx1G1IJ4znAuQUM0e6yvUJfx91Ap76nGm/E/0jKdv+25fzXgXVtb1ulXtP1D2p33i2j1yrUuxdYril4G06aXFF5eb2kS21vkkv5W/0DbLuIb4CkBevMnkr6P2B1euaMrwvcCixOMrQ8o4Y1zOg0KnNIk700jiGNUx1Les6sSNpQ/Y7tP3dweYMmb0r1Sa4AKKXdbqpCsddhMDSJgD8IgiAYFJLuArZqZNslLQKcX0cgmcvPfwh82Xal5b2SHge+03TqmObjbihjlPQa8Fhfjxfsx66F7AtwESnzdVc+vSIwPbC57ec7tLRKyQH/uo2sXs6+jx7qvz/oXPY063618RyRNA/JWO+rpDGLS5fQ7UZyVdbnbD/Zcn4h4M8FN4c3AQ4DFiS1MYer/CCQNANpo/bjNPk9RIZ/yid6+IMgCILBsh/J0fpx0g3VgsBOJQXzjeLWZKMrUqlo1YwBNu3j2ECRgD87jx/MpDepJTI2T9D7eyyKpPvoP3irNEDNpddrSPok6SYV0ki+a6vUaUXS3KTnZOuN8ScLSR4O3C3pOtLzZW16m80VIZeGN56nANi+vmKZYyq+3ntloZYNoX8Bi9v+r6SSpqTdyLStwT6A7SdzC0MpjiVNIriv6uqhdjRVvfSiZLY9V/NsDCxE79dhifahM4CHSSaMhwJfBsLEbwgQAX8QBEEwKGxfkzPtzS79b07mywZMHj80LXAeqbLg8RI6totuWvTDqcA+pNLXCYW13qrZZGqT/LEx4rBRFv1lCs6SzgF+0SC/hT+SWk02IfWe7wD8u5SY7bMkjSb18Qv4nu3nSukBSDqStOH2ID3PU5M8LyqjZDn0ZLhB0qWk9xlIbuvXZ7PHlzq0pkHTl/dCgxK938DbkhZobbvK7VnvFNBr8BRwfx3Bfmalps9nALYijR4tySXAG9Tj0v9R21tJ+pzt0yWdSWrHCqZwoqQ/CIIgGBCSVgaeagQWkr4CbEEyEDq40I0jkpa0/XCJa08JSLrN9qo1aZ1g+1t1aLXo3mR7zcmdG6pIGmt7RUn3NqoWJI2x3W+v7yA168i2N+s9AowsubnXoldr9lRphMQXSOMHBdwIXFAqeJS0OKlaqvV3WGlVSB/eC01y1f88JW1OmuHe6OE3aXPq+6TNqYuq1sy6K5NK+sdQg3lmH2u40fZaBa//7ntMaSTdbnsVSdeTjFafA24Pv4Apn8jwB0EQBAPlJGB9AElrA0eQHNeXI42zq3T+sKTtbP8B2EjSRq2P13kTV5jrJB1Nahlovkm9q+8vGRidCPYzM0tay/aNAJLWAEqOyaubRsn3s5I2Bv5JmkFehKZs+wP0ZPkqz7a38Dip0qaWgJ+as6e2nSd1vGz76jzJYhbSdIASnEeaQvBbClb2uKZxgy2aF+WNhm+T/kYIuB/Y2vY9BaV/AvyP9HyZrqAOAJKafWuGkZ6zsxaWvUzSBravLKwDcLKkOYAfABeTXg8/rEE3GCQR8AdBEAQDZXhTFn8b4GSnGcsXSBpXQK8RELa7geqmcrVGdr85wDFQqv+7E+wC/E7SbPn4JaCbjJ9+nL+3bwPHk2bG71NQb3Ngibqy7ZnXgHGSrqH3xtSeJcRs/6fl1LGSbgR+VEJP0q7A10ibCosC85MC8k+V0CPNUz+x0LXbkoO3xejtM1FkkygH9l8pce1+mNP2BjXq/azp83eAJ0leMyW5FbgwTz55m4LGhLZPyZ9eD0RWfwgRAX8QBEEwUIZLmsb2O6Sb4K81PVb53xfbJ+VPr7Z9U/Nj2eiuUvqYw928niKmfbbXK3HdKQnbY4FlJY0gtRe+3Ok1VYntS/OnLwN1/D7rzrZDyvBdXJdYB7KnuwOrALcB2H40T30oxSWSdgMupPA8dQBJXwX2IlWejANWA26huzYWr64x+92p9+6fkcZH1mJMGAxNIuAPgiAIBspZwBhJLwCvAzcASPooKdApxfFA68i/ducGS8O9/oPAGvSYvq0HjKacS/9swEEkp3VI/aeHlgiKO7Wp0fo9Sir2PXYzko4nVX/Umm3PzuDb216/xPX7oO7s6Zu230qt/CBpGspWEu2QP+7XdM6Uy6TuReqjv9X2epKWBA4ppNUpdge+K+lNCma/Je3b3+OF280epV5jwmAIEgF/EARBMCBs/yQHGPMCVzbdcAwj9WlWiqTVSYH33C03WCOA4VXrNVz6s1P3UrafzcfzAr+qWq+J35H7W/Px9sAokoFY1XRkU4N6v8du5s78cSw1ZtttT5D0mqTZ6tqk6UD2dIykA4AZJX2aZFJ2SSmxDvTWv2H7DUlImt72w5KWqHkNRbFdun++wTGkKonLSBtu7QwRS/EsMFpSQxvoKk+boAIi4A+CIAgGjO1b25z7ayG56UgmQdPQu5T3FSo2CGxhoUawn3keWLyg3qK2t2g6PqSQJ0InNzVq+x67GdunA+RRcW/YnpCPhwPTF5Z/A7hP0lXAq01rqrSqoIPZ0++TvCbuA74O/AU4pd+vGAR5Hv036ansGQ2cZPvtPr9ocDwtaXbgIuAqSS+SzCUrp6kSpS0FK1HWbne+gE/BCsAXgY1Jm29nAdfUlHV/Iv+bjsLGhH1UhL1Maif4V0ntYHDEWL4gCIJgSCFpwTpnx0s6gWRsdRbppvWLwGO2K69iyHq3APs1OdivCRxje/USelnjfttLNx0PA+5tPlexXu3fY51I2otUsTCeFCQuD3y/VC+xpFuB9W3/Lx/PQqq6WaOEXtbYod35xiZEhToT6Sd7artoGbqk6YCPA8+UDGoknULyYWj8/LYHJtj+ainNJu11gNmAy22/VeD6jefKmsBSwDn5eCtgrO0ihpaSmisyZiB5MoytetRhi+YawLakCTbfs11b5U1pJP0fyS/gunxqXZJp4OKklqwzOrS0YDJEhj8IgiAYapwiaSvbL8G7TtNn296whJjtb+XMxifyqZNtX1hCK/NN4PTc5y7gv8COBfUglYReQe9Njev6/5JB0YnvsU52tn2cpA2BuYGdSBsApczDZmgE+wC2/5fHyBWj6sC+H2rNnkr6DXC87Qfy8/MW0pi8OSV9x/ZZJXSBlW0v23R8raRiI+skrQY8YHu87TGSZiVtTN1WtVZTJcqOwHqNqoX8sy5mqGd70+ZjSR8BjiqlJ2lu0s9wGeBpoHjWW9J1tKmeKLSpMRH4mO3ns/Y8wImkyTLXAxHwT6FEwB8EQRAMNeZqBPsAtl8s7J7dMK8r1c/eqjWOHgd7bL9Sg2atmxqd+B5rppGF3ggYZfseNdzfyvCqpBVs3wUgaUWSkWYxJC0GHE7K2DaPdavUZC4/V8YB32/Knh4vqVT29BO2v5E/3wn4q+3NJX2IVGVQKuCfIGlR238DkLQIaaOhFCfS2+j01TbnqmY+UjtWY/LALPlcXTwNVF61JGkn0mjaGYDzga1rLHH/TtPnMwBbkEwtS7BQI9jP/AtY3PZ/JZVqPQkqIAL+IAiCYEBIGk//fZmVzwHOTJS0gO1/5HUs2N86BksOhI8kGduJck7P29n+Q2vPciNOLG3CVMemRl/92HV9jzUyVtKVwMLA/jl7OrGg3t7AeZIaPdjzkgKQkowiTVr4BcnkcScKmpXVmD1tLmn/NHAegO3nyu7ZsB9wnaTHST/HBUk/01KouUrC9sQ8iaAkRwB356w0wDrAwaXEWrwDhgHLASWqJk4leT38A9gQ2KD5uWJ7swKajWuPbTl1U556UoIbst/Lefl4C+D67CHyUiHNoAIi4A+CIAgGRMMBWdKhwHOkcj4BX6bsfOwDgRubbmrWBr5WUO8oYFPbDxXUAJg5f2z3sytquFPXpgaddbOuk11IwcXjtl+T9AEKBm+278hj1ZYg/UwfLmj21mBG29dIUvbUOFjSDaRNgMroQPb0JUmbAM+Qes53yeuYBpixlGj+WS5G79/hm5P5ssHwuKQ9SVl9SFMIHi+oh+1R2U1+1Xzq+7afKyh5Z9Pn7wBn2b6pgE7dEyTeRdKcTYfDgJWADxWS250U5K9Jeo7+Hrggbxx17GcQTJ4w7QuCIAgGhaTbbK86uXMVa84FrEa66bjF9gsFtW6yvWap67fRW7P1prTduYo1H6OGTQ1Jy5H6sT9D/W7WtSHp88C1jZF12Q19XdsXFdK7kzTq8CzbL5bQaKN5E6kF5HzSOMdngCNsVzraLZv2NbKn0LL5VXX2VNLiwC9JQdOxtk/L5zcENrD97Yr1Pmn72j4c0BuVN5WT26B+CXyS9DO9Bti7dCm6pPlJ1QvvJh0LuOZPNUh6gp7XxDvAkyQDvRs7tqhgiiMC/iAIgmBQSLqZNMLtbNKNx7bA7oUdwucgOec39w4XuWmUdBzp5v8ies85LnUjfpftFSZ3rmLNWjc1smY3u1mPs71cy7m7bS9fSO+jpAqCbUhZzVEkl/6SrS4rAw8BswOHASOAo91mVOcgddbp73HbpcqXa0HSIbYPkjSqzcO2vXPtiyqEpCNJz9EH6GlxcamSd0n3MWl11Muk18iPbf+nhG4d5NffU40KiTwJYQtSwH+w7f/28+UD1ayrEiyomAj4gyAIgkEhaSHgOFKZn4GbSJmiJwvpfRXYC/gwqTx8NVKWv8iopbpuxCWtDqxB6sf+RdNDI4DPtzh4V0oHNjXmBrYmjeV6G/hh1YFiJ5F0r+2RLefus71MYd1hwCakMu2JpKz/cSVu/ps0Z7b9aqnrTy1IWtj2E5M7V4HOd20f1dLf/i6296xSr0X7EWBk4VaFZr2jSMaHZ+ZTX8wfXwHWanXxH0pIuos0ivO/ktYmbbjvQWol+pjtLQto1lIJFlRP9PAHQRAEgyIH9p+rUXIvYGXgVtvr5d7lYrO4bZc0zmpmOpJr9TT07uN/Baj85q2FEcBrwAZN50zFJn4ddrOukzsl/ZxU+WLSjXiruValSBpJyvJvBFwA/BFYi1Ruv1wBvdVJZmWzAAtIWhb4uu3dqtaaSriASR3yzwdWrFinEazd2e//KsPjwLQ0bSoWZs2WyqX7GtVMkraraQ2lGN60kbcNabLKBcAFksYV0nw+gv2hSQT8QRAEwaDI2dpdgYXo3ZdZqhT1DdtvSELS9LYfllRp33AzkmYgGXd9nN4tBJV+f7k0eYyk07IJWm3UuKnRMTfrmtkD+CFwDqns9UqS4VURJI0luWSfSjJCawRUt0kq1apxLOl3eDGA0+jBtQtpdS15w/LjwGwtffwjaHq/qQrbl+RPz7H9Rsta5qpar4XXgHGSrqF3JVGpqoJZJK1q+zYASauQNqigwtF1ki6h/4k1Jd7XhkuaxvY7wKfobVxbKr67U9I51FQJFlRHBPxBEATBYPkzcANwNWXnRjd4OpugXQRcJelF4J/9fsXgOAN4mBTcHEqaQlAyy/GapKOZdIOhSMsC1LepwVTi5JxL3L9fo+RWtts6rNtuawZXBbafahlVV8frvyh9jY5sUGB05BKkNozZgeYS8/GkjdRS3C7pa41WGklbAIcDixfUvDj/q4tdgFGSGkH+eGCXPEbu8Ap1jskfv0BqjfpDPt6W1FNfgrNIG8QvAK+T/gY3/DxeLqRZSyVYUD3Rwx8EQRAMinYGZTVqrwPMBlxu+63J/f8Batxte/lGX7akaYErCnoGXEnKDH8H+AawA/Bv298roZc1zyNtanyJpk0N23uV0uxGJB1re+++Mn4Fzcn2Ihn1jQdOIc2r/77tK0voZc3zgZ8DJ5B8NPYEVrL9xX6/8P3r1Jo9ldQYK7gEqXWoEaBuClxv+6tV6jXprm77lhLX7kNvGZLHw2hgPuADwFdtP13XGkoiaTiwp+1fSJqNFPO8VFjzettrT+5chXqrAfOSDDpfzecWB2axfVcJzWBoEgF/EARBMCgk/Ri42fZfatAaBtxre+nSWk2at9teRdL1pFnVzwG3216kkN5Y2ys2G79JGmO7X7fyQWrWuqnRrUha0fbYvpzlSznKS7rH9rJ5dNzupHaCUYUnO8xFMutcn562hT2rNghs+lm2zZ7aPqBKvSbdK4EtbI/Px7MC59n+TCG9o4Afk7K1lwPLksxP/9DvFw5Oc3NSBdN4YG3bj5XSynqLkTLrS9G7kqjUe+lo2+uWuHYfeg8BGzeqbSQtDPzF9sfqWkMJOmn0GFRDlPQHQRAEg2Uv4ABJb5Ic14uN6rE9UdI9khaw/Y/Jf0UlnKw0BvAHpGzfLKSAqhRv54/PStqY1K7w4YJ6zZovSVqatKmxUGHNrsN2w5hvOdvHNT+Ws/ClRsg16uo3IgX696il1r5qbL9AqgTpWYR0DKkypUqdMfnah7VkSi/Jm3ClWABorhp6i7KviQ1sf1fS54GnSRMsrqNng6NSJJ0KLAqMJJXxXyLpBNu/KqGXGQUcRJpCsh7JZLLk8/QmSSeQKqbenSRRMPu9DzBaUqO9ZiHg64W06qSTRo9BBUSGPwiCIBhSSLqWVGp7O71v4rrC8E3SJqR+zI8Ax5P6Jg9xwTn1SqMOLwCWAU4jb2rYPqlinTNsby9pr9aAuJuQdFdrdr1RRVFIbxQwP7AwKTM8HBhtu2qH98mt4x+2Fyh07Vqzp5IOJI2OvJCU1fw8yeiuyt7vZr0HbH9c0m+BC2xf3qjcKKS3D3CscyCQy95/bnuXEnpZo1G99O6ISkk32P5EIb3r2px2YT+U6YEl8+HDrmkEYR1IWsgt43YlrWz7jg4tKXiPRMAfBEEQDJqcAV+M3mWaRbJvdZdLB9Uh6UHgs6RKiXVpye5VXQ5eN5K2JfkgrEU20crMCkywvX4hXZH69h+3/ZKkDwDz2763hF4/63jK9kcKXfszwMmk0W6Qs6e2ryigJVJVzdxAIxi93vbdVWs1aR4BbE4q6V+FZOJ3qe1VC2ouCCxm+2pJMwLTNFoYCundRPp5nk8aF/kMcITtYlNW2qxhHtvPF7z+Gkw6seb3pfTqRGkayGa2n8nH6wAnNDZvgimXCPiDIAiCQZGzw3uRbpDHkQy8bimcRWm+UZ2JNJO42I1qneTM5R5MetM45CsYJO0JfBNYhHSz3xzwu1Qvb13k5+XCpD7lZpf+8STvicpGgWW9xUgO4YuSxh1+p3EzXgpJc/b1EHCP7WLtJ3VmTxvZ6FLX70NzDuAV2xOyk/ystp8rpLUraZTbnLYXzc+l39j+VAm9rLkyqTx8duAwUvXS0c6TAgrqzgZsQdqM+5jt+QvpnEF6LY6jZ2KFu6XHPf/+fk0ysFwB+Cmwqe2nOrqwYLJEwB8EQRAMCkn3kUrsb7W9nNJc6UNsb1NIr/Yb1TqRdA898+onNs53UwWDpBNtf7PT6yiJpHlIrwtIJo//KqBxA/B74HpgM2B1FxzDlzWfIJW4t+u9LrppU2f2VNKvgNPqKlfOG5f7AgvY/lp+X1vC9qWF9MaRKglua7SaNJfaD3VyxcJmpCB/BVKVzeakSo2J/XzpYDQfApZyFwdXklYHTgLeILXY/LvDSwreA2HaFwRBEAyWN2y/IQlJ09t+WFLJEs3dyTeqALYflfTBUmL5RvzbpBvxXUvfiJN+nr8sdO0pAtvflLQsvculay0/L4mkrUiZ99GkwPh4SfvZPr9iqVlt/zZ/frSk4qO4bC9cWqMdfWVPSRseJVgP+IakJ0leIQ0z0pGF9EYBY4E18vHTwHlAqfeZN22/1fB2lDQN/Yw/HEpI+iOwNmlyxAmk9oHHbI8uLH0/aZLEs4V1akWTjsacCXgZOFVSV1SfdTsR8AdBEASD5WlJswMXAVdJepHkLF+Kum9UGzfiq+fj0jfixynNAr8SeLdkuYSztKR+s8G2/1S1Ztbdk1Sl0bj+HyWdbPv4Enod4AfAyo2svqS5gatJvctVMoOk5enJts/YfFzQjbwTrES92dPP1qTTYFHb22QfCGy/XnjSwhhJB5CeM58mjRy9pKBenSwNvEhqH3g4t0jU8byZC3hQ0u30fu8e6gHxMZ1eQDA4IuAPgiAIBoXtz+dPD86uyLOR5kiXou4b1bpvxJcBtgc+SU9Jv/Nx1Wzaz2OmJyCvmq8Cq9p+FUDSkcAtpKkE3cCwlhL+/wDDCug8C/y86fi5puNSz5lOUWv21PbfW6pQbrB9T0HJt3IZesM1f1GagsYCfB/YhdQ69HXSxIPf9v8lQwPby+bWsi8BV0v6FzCrpA+V8kTIHFzw2h2jm9rJplaihz8IgiAYUkgaRrpR3YCUybyi5I2qpJuBTwE32V4h34ifZXuVQnoPAyNtvzXZ/zxEafg+2H4jH88A3NFF/cNHk+abn5VPbUMy7fte51Y1tMmbicuRxnEWz55K2gvYlZ5Nr88DxapQ8ublD4ClSNU9awI71lCG3ryGm2yvWfD6iwMnAvPYXlrSSJLr+49LaWbdlYBtga2Ap22vMZkvCdqQK8KOBD5I+tvbaHMZ0dGFBZMlAv4gCIJgSKE2M9zbnatQr9YbcUnnAHuUMHmbjO7GwMfpPVrx0EJa+wI7kGacQzLTOs32sSX0OkG+OV6LdFN8ve0LJ/MlQw5Ja5GmZYzKbQuz2H6ikFat4zgl3UsyQWxUocxMmj5SqoefPE5xNdJz5lbbL5TS6kO/2FjFfP0xwH7ASU1GgffbXrqUZou+gLULPmdWI1UpfQyYDhgOvNotAbGkx0iu/A91ei3B+yNK+oMgCIKhxg5Aa3C/Y5tzlWD7qmyG1rgR36vwjfg8wMOS7qCmPlBJvyEZMa0HnAJsScqkFsH2zyWNpicg3skFZ5x3iJtJ5nITgVqc3usk+0ysBCxB8rmYFvgDaUOscjpQVix6zAHJnxdr5ZG0dv60MV50qWyIdn0pzTaUzgLOZPv2lo6oSkdV9kf2fyj5PDoB+CLJ42Ul4CvAYgX16ub5CPaHJhHwB0EQBIMmzx9fzPbVuQ91GtvjJ/d171NjW1JP5sKSLm56aFZSj3QRJK0JjLP9f5K2Aw6QdJztvxeSPKjQdftjDdsjJd1r+xBJP6Nc/z7wrqFcN5nKvYukrwI/IrmDN1z6D7X9u86urFI+DyxP/h3a/qekWUuJdSB7Ogq4TVJzFcqphbQgZb4bzECaRDKWin0Y+jHqFDBjlVpteCG3RDV8CrakyxztbT8mabjtCcCo3BLWLdyZK9AuovdmdNG/FcHgiYA/CIIgGBSSdiU5rs9JGpv1YeA3pL73KrmZdHM4F/CzpvPjgZIj3U4Els0GXvsBvyONAmtbYjwYsj/Br+oqcW3i9fzxNUnzkTZQOjJ+rUvYD1je9n/g3VLtm0nPncqQtEJ/jxd26X/Lthvu57nkvSS1ZE8lLQfcU3cViu1eBpqSPgIcVUCqP6POUpNHGuwOnAwsKekZ4Algu8KadfKapOmAcZKOIv29Kv26qJMRwGsk/5wGJc1dg4qIgD8IgiAYLLuTslG3Adh+VNIHqxbJGfW/0zMery7eyYHN54Bf2j5V0g4lhGxPlHSPpAVs/6OERh9cmkcrHk3K2BroCsfuDvE0PaXZ5M+fKqDT2PiagRQE30MKTkeSXo9rFdBscK6kk4DZ86bfzhR+ztSUPT2FVEV0F3ATaaPmVtuvFNDqj6dJ4+UqxfZOVV/zfWg/DqyfN4eGVV0F1iB7hPS3jp/39/gg2J40jeNbwD7AR4AtCmnVTiefO8HgiIA/CIIgGCxv2n6r0ZcpaRoK9oJ2wCl4vKT9SZmotSUNJ/Url2Je4IE8y/nVxsmSPfy2D8ufXiDpUmAG2y+X0ss3/K/nDY7FgSWBy2y/XUqzDpoCjWdI5eB/Jr0WPkcBTwTb62Xds4Gv2b4vHy8NfKdqvRbtY7Kh5SukPv4f2b6qoGQt2VPbK0maibSJuQawJ3CGpOdIkzp2q1oTQNLx9LxvDiNNJCg5BrB2JP0UOMr2S/l4DuDbtn9QsVSjtWQJYGWg0QK2KVDME6GpzesN4JBSOp1C0ija/G23vXMHlhO8D8KlPwiCIBgU+eb7JVKJ7R7AbsCDtg8spFerU7CkD5G8A+6wfYOkBYB1bf++kF6tbuRZ8x7gHOAc238rpdOkN5Y033wO4FbgTuA1218urV2SbGTXJ7aLBAGSxtlebnLnhjLZJ+R5Uv/+PsBswK9tP1ZQc2aSWeeapPe3YbYXKaTVXDX0DvCk7ZtKaHUKSXc33Pmbzt1lu9/WlEHoXQls0agkyB4T59n+TAm9bkdSc7XCDCQfj3/a3rNDSwreIxHwB0EQBIMi953vQurrE3AFcIoL/YEpPSu6RWs4cIXt9evQa9Kdh5SZAri99Ii+HExtk/9NJAX/55ZqK2jc5EvaA5jR9lHtgoGhTg4wbPt/hXXOIlWD/IGUgduONCJv24KaXTmTW9KXSJn95UjGZHeQ2iNusf1cQd2ZgI/mw0dsv9nf/x+K5FGHKze+t2zweqftjxfSexhYtklvepI/w5Il9KY28t/+q21XaiwZVE8E/EEQBMGgyFmwN3JfbSNInt72a4X0jgM+RE1OwXkiwPYlS9xb9LYm9dKPJgVRnwD2s31+TfqLAT8Evmx7eCGNu0mVIL8AdrH9gKT7bC9TQq9uckn9GSQjS4AXgK/YfqCQ3gzAN4HGaLfrgRNtv1FCL2t25UxuSf8DHiYZj15v+6+F9aYlvd63B54klfN/EDje9hGSli9lFijpQ82bGK3HBfS+C2xGmoBgku/DxbZLmBMi6UBga+DCrPd50kbmT0voTW1IWgL4P9sfnex/DjpKBPxBEATBoJB0K7B+I4spaRbgSttrFNIb1ea0S/URSjqXVNZ7Fb176ouUMeby+k83svqS5iZlUZYtodekuxDp5ngb0szxc2z/rN8vGrjWOsC3ST3RR0paBNi7W0pDs5ncgbavy8frAj8t9ZroBHVW2tRJ3rBclpTlX4PUB/4scAspy39txXq/BGYC9mkqPR8BHEN6HX7GdpGJGZL+z/bGfR0X0vwsaYKLSH8nriistyI95pXXl5y0kP1I9gMWpMknrVsy4JLGkzZOlD8+B+xv+4KOLiyYLBHwB0EQBIOi2/uH+3Lkt316Ib1eme5cNnlPyey3pNtIRoTnkQL9x0tpTQ1Iuqd1g6bduQr11gQOZtJAo0i/edastdKmU+T2mi1JvgELV131kislFmttgcobDy8An7V9a5WaUxP55zgPvV8XpVqV7iFVhowlbdY09MaW0AuC90q49AdBEASD5VVJKzjP/M4Zldcn8zXvmxYX60kolR0uFdj3w+WSrgDOysfbAH8prLmD7YcLayDpWNt7S7qE9m7PxSYR1Mzjkn5IKuuH1FP/REG9U0kBaa9AozC1zuSuK3sqaSQ92f01SCaBtwDHk8b0Vc3Edn4ntidI+nepYF/SosDTtt/MFSgjgd83HPQLadbq+5A9Qg4imT1OoCczPbKEHmmE64mFrj1FIGl+Jn0NFpt8EFRDZPiDIAiCQSFpZeBs4J/51LzANlVnNfrKtDcomHF/gvbBaaXZU0nTN5lLfYFUhipSGeqFVWq10Z4H+Ckwn+3PSloKWN32qRXrrGh7bCcmEdRJHjd2CD2/wzHAwaWCKUm32V61xLWnFOrKnkq6ixTY3wzc7J5Ra0WQdBHwJ7dM/ZC0HbCV7c8V0h0HrAQsRDJavRhYwvZGJfSyZt0TVh4DVrX9n8I6Da+OPYF/kTwDmqte/ltSvy4kHUnagH6Qntegu2ijtmuJgD8IgiAYNNl4aglScPOwh/g89WYkfaDpcAZgK2BO2z+qWKfhXH+G7e2rvPZ70L6MZKR1oO1lJU0D3F2HiV4Ojj9i+97SWp1C0pKkeeO7Frr+EcBwUna9OdC4q4DWd/NUhbYVNwW9LcbaXrHEtTtJzpj+iVQVNZb0M10ZmBH4vO1nCuk23m/2I5muHl96Ukbdvg+SriP5obxTWKexKaw2D7tka02dSHoEGOkunCDR7URJfxAEQVAFK5MyRdMAy0uiNWM1VGmTHTpW0o1ApQE/MF2uYlgjZ/hb11GyN3ou2+dK2j9rvSOpWGm4pNEkt+5pgHHAvyWNsb1vKc06yOXgxwDzkbJ8JwC/BlYFihggZhrZ/ZWazhkoYRbWyM7eWeDa/XGJpN3osuxpDuhXlfRJ4OOkoPEy29cUln5b0rbADsCm+dy0hTXvlHQO9fk+PA6MlvR/LXo/r1KklKniFMjjpOdIBPxDjAj4gyAIgkEh6QxgUVLg9m6ZH9AVAb+kFZoOh5GCqlkLSH0D+DIwOz034A2K9UZnXs2VDAaQtBpQcgzhbLZfkfRVYJTtg5RmdA91fgucSOr5/gxwF3AmacRhsRF5ttcrde02Wpfkj3V7WzRaevZrXg7QFdnT7P5f6QSAybAT6T3nJ7afkLQw8IfCmrX6PgD/yP+my/+KIml34I+N1p1cvbSt7V+X1i5JUzXPa8A4SdfQewOlK6ardDNR0h8EQRAMCkkPAUu1M57qBnJZaIN3SLOyj7H9SCG9XarunX8PmiuQTMmWBu4H5ga2LFVmL+k+0k3/6aQ2gjsk3Wu7lJlWLbROp5D0FLCQ7eJGepI2JmWIZ2ics31oQb3Fge/QU9nT0OyKEWTdjqSZSaX8E/LxcGB62691dmVDlz4m1hRtk6iDTvnnBNURGf4gCIJgsNxPGs/1bEmRDrr015Y9zXqnSlqDSQOpYhUTtu/KRnoNH4ZHCvswHEoyCrsxB/uLAI8W1KuLGSQtT08v7/+AkZIEZXrqAST9hjTLfT3gFNIYudtLaDVxHslE7xRqmAyQfUK+CaydT40GTqr6edrXBIkGXWRQdg2wPuk5Cskz4ErSZIIi5E2iE4F5bC+dW2A2s/3jQnpzA99l0o2wUptSwySpsfmdN1GKVxbUwF+AuW0/2HxS0tKkCQjBFE5k+IMgCIJBkTPgy5ECjOYyv0pvjJuyDGsCSwHn5OOtgLG296lSr0l3NtJop0agMQY41HaRkve+WiRKbGhI+qTta9t5BmTRUiPW5hzqvdftaKkGacWlAo1GdUTTx1lIzu8bTPaLB65Zq4mepFNI/cONbOL2wATbX61YpzFB4gukjcxGmfu2wJO2D6hSr1P0kY2e5FzFmmNILRknNbLeku63vXQhvStJfye+Q2pf2AH4t+3vFdI7mrRR+xvSptE3gKdsf7uEXl1IOhs4sXWKiqQNSSNdv9SZlQXvlcjwB0EQBIPl4DpEGmWDknYE1mtk9nJ288qC0r8jVTFsnY+3Jznatw2SK2Al6muRWIfUN9zqGQBle2tvy2PBRpEMyroi+1B3NUgTr+ePr0maD/gPUMRIrGkEWd0meivbXrbp+No8qq9SGkGNpMNsr9300CWSumne+KuSVmhUnUhakZ7nUSlmsn17LnhpUNJB/wO5Ymqv/HsdkzcdSvE94OukShSR/i6dUlCvLpZpDfYBbF8hqaQZaVAREfAHQRAEg8L2GEkLAovZvlrSTKQRYaWYj2Sa1wgsZsnnSrGo7S2ajg/JwWopammRAMhmecNIQfe5pfWaWJxUTrwzcHx27j7N9l9rXEM3camk2YGjSUaBJhkIlqAxOq4RtdVlojdB0qK2/waQ20BKthLMLWkR249nvYVJ3hbdwt7AeZL+mY/nJc1YL8kLkhalxxx0S8q+zzXaPZ7NHhf/BD5cSsz2REmnAdeW8njpEP1Nbyg92SGogAj4gyAIgkEhaVfga8CcpFL0+UkljZ8qJHkEcHdT+fQ6lK0yeF3SWrZvBJC0JmUzYXMBD0oq2iLRdN2Jkr4F1Bbw54z+VcBVktYjlU3vljO237d9S11r6QZsH5Y/vUDSpcAMpVpOOjiCbD/gOkmPkzYbFiQ5zZdiH9JIt8fz8UKk7G1XkL0zlqTHt+Phwr4dALsDJwNLSnoGeII0maQUP84tWd8mmZKOIP1eiyBpM9Km23TAwpKWI7V/DXXfh0clbWT7L80nJX2WNKovmMKJHv4gCIJgUORs9yrAbU19mffZXqag5ofomT1+m+3nCmotR+obni2fehHY0Xbl5cRZb51259uVVFao+UPSJsY5wKtNmkXKs/MIwO1I7RHPA6cCF5O8IM6biuZaD1k6MYJM0vT0DlCLzgPPekvmw+J6ddBB347hwBG298sTAobZHl9Cq1NIGgt8Ehjd9LewG6aPLA5cCtxMqvCB1Hq2OrBJVGZN+USGPwiCIBgsb9p+q9GXKWka+nG5rojhwL9Jf8cWl7S47SL9tbbHActKGpGPXymh06RXsse0L3bOH3dvXgrlyrNvAc4ANrf9dNP5O7MnQ1chaV7gv90QMDaxq+1fNQ5sv5irfSoN+PsJUBeVVCxAzaxIz7SMZbNesWkZNdER3w7bE7JPALZfndz/H6K8Y/vlFo+CIY/tv0paBvgSaXQrJPPar9t+o3MrC94rEfAHQRAEg2WMpAOAGSV9GtgNuKSUmKQjSb2mDwAT82kDRQJ+ST8FjmrJZH7b9g8q1hlP+40SkargR1Sp18LHWm/cJM3Q13+ugCX6MuqzfWRB3U5xBilAvcD2dzq9mIqoawRZRwLUvqZlAEM64Ld9UP70UNtPND+WfQpKcreki0kjHZsriUpu2tTJ/ZK+BAyXtBiwJykrPuTJm5WjOr2OYGBESX8QBEEwKLLp2y7ABqTg9ArglFLO65IeAUbWlS2VdHejPLPp3F22V6hDvw7afT8lvkdNPTPOJ0Ep7beU7QcKXLvd7+ll4O+2i7ig1z2CTNLC7QLU1nMV6j1EfdMyaqeP13zRUYuS2gWMtr1zm/NDjmxYeyDpbyGkv4U/jix40Gkiwx8EQRAMCtsTSY7gpVzBW3mc5AxcV3n0cEnTNzYYJM0ITF+TdlGyF8L8pOqM5elxXh8BzFRA8pgC15wiyRnveWi61yoR7Gd+DawA3Ev6HS6dP/+ApG/YLjG2su4RZBeQvsdmzieV3ZegtmkZdZKN+j4OzNbSJjECKFnVg+2SJouTRdLngOds31bi+rZfAw6U9NMublsIhiAR8AdBEAQDQtK5treWdB9tsrYFjYpeA8ZJuobeLvZ7FtL7A3BNzk6Z1O9+eiGtutkQ2JE0qurnTedfAQ6oWqxD/gS1I2kP4CCSIWFz20mp18STwC6NDQVJS5Fc7Q8jlbxXHvDnjb4T879idDBArXVaRo0sAWwCzE7vNonxwK4lhbP524nAPLaXljQS2Mz2j0vqNrEqsIykaWx/tuqLS1qDtOk1C7CApGVJfe67Va0VBO+HKOkPgiAIBoSkeW0/K2nBdo/b/nsh3R360CsWhEv6DGluvIArbV9RSqsTSNrC9gU16i0GHA4sRVPQZruUSWCtSHoMWNX2f2rSG2d7uXbn2j1WkWYtv8Ocld0c2Iw0yaHBeOBs20V6pDsxLaNOJK1e9/hLSWNIG1EnNbnY32976f6/cmgg6TZgS+Dibvz+WpF0OmkD/le27+/0eoK+iQx/EARBMCBsN0pdhwHPNvoUc8n7PAV1a82u5xFSV9q+XNISwBKSpq1hZnWd3CTpVGA+25/NGeLVbZ9aSG8UKQP+C2A90jz1brK2forUQ18Xj0g6ETg7H28D/DWPlSv1PK3ld2j7z8Cf6w5QuyWw74fHstnqQvRuOynZTz+T7dtbXOyLeEwASNoKuNz2eEk/ILWEHGb77lKatp9q+f4m9PV/u4ATgAVI41W/1+G1BP0wrNMLCIIgCIY859FTtgzpBue8UmKSFpN0vqQHJT3e+FdKj+T+P4Ok+YGrSYHNaQX1OsEoksHUfPn4r8DeBfVmtH0NqdLw77YPJs2v7hYeB0ZL2l/Svo1/BfV2BB4j/c72yfo7koL99Qpp1v07vFvS7pJ+Lel3jX+lxCStJukOSf+T9JakCZKKjuSsmT8Ds5He0/6v6V9JXpC0KLkFTNKWlPVI+GEO9tcitS+dTjKZLMVTuazfkqaT9B3goYJ6HcX2HbYvsB3B/hROZPiDIAiCwTKN7bcaB7bfklRiPFeDurPDsv2apF2A420fJalYhqhDzGX7XEn7A9h+R1LJzNQbebrDo5K+BTwDfLCgXt38I/+bjjKj6nph+3XgZ/lfK/8rJFv37/AM4GFS4HYo8GXKBlMnAF8kbV6uBHwFWKygXt3M1IFAbXfgZGBJSc8AT5B+j6VovIdtDJxo+8+SDi6o9w3gOJIR6jOkTdTdC+rVSh9TVl4G7iS1acQ0gimUCPiDIAiCwfJvSZvZvhje7bl9oaDejLavyTPA/w4cLOkG0iZACSRpddKN6S75XLf9/XxV0gfoybytRtmS9L1JUwD2JBnLfRJo680wFLF9CICkWdOhSwXdZJ01gYOBBeldnl3SE2Fv6v0dftT2VpI+Z/t0SWeSAqpi2H5M0nDbE4BRkrpipnrmUkkb2f5LaSFJe9k+DpjX9vq5TWqY7fGFpZ+RdBLJf+XI3OJSrLrZ9guU3cDoNI8DcwNn5eNtSMaki5Om9GzfoXUFkyFM+4IgCIJBkUs0/0gqBxepf/krth8rpHcT8AnSSK5rSZmUI2wvUUhvHeDbwE22j5S0CLB3wakAtaM0x/140ji3+0k3dVvavrejCxuiSFqalJGeM596gfSaKDKWT9LDpFL+sTT1DNdlGlgHkm63vYqk64HdgOeA20ttamSd9Umu68+RSs93tL1sCb26kTQemJk0geBt0nu3bY8ooNUwkLzLdutoxWJImgn4DHCf7UclzQssU2hMJflvw3HAaqTN01uAfWyXbDmrDUnX21673TlJD9j+eKfWFvRPBPxBEARBJUiahfR3pWjWRtLKpFLe2UmZxRHA0bZvLanb7UiahjSyS8AjwCq2byqktTjJrbs1I90Vffw5E3yg7evy8brAT22vUUjvNturlrh2G62L+3u81Ng6SV8FLiCNNhxFGn32I9tFerLz9JHnSS0Z+5D63X9daiOzm5F0FrA6aSPxb80PkTYZKh1XKWmE7Vckzdnucdv/rVKvSfdW4Ff0ZMC/COxR12uzNJIeAja0/Y98vADJFHEpSXc3JhMEUx4R8AdBEAQDQtKmwL2N8XuSfgRsAfwd2Mv2E51c32CRdKztvfvoW+yGedxIGg5sTeo5vcz2A5I2AQ4gtU4UuYGTdA/JPKs1Iz22hF7dSLqnNRPc7lyFekcAw4E/0Xtm/F0FtP5NquI5C7iNFv+MqcDdvmuQNAfJl6B5rOL1hbQ+RGrBmOR9s+oRrpIutb2JpCdI793Nz1EXrAqZZONN0q22VyuhVzeSNiK9b/+N9DNdmFRtMxrY1faxHVtc0C8R8AdBEAQDQtK9wGrZ0G4T4OfAtsDywFa2N+zoAgeJpBVtj1UXz+OWdBrwEeB2YFXSZs1qwP62LyqoO9b2iqWu32kkXQjcRSrrB9gOWMn25oX0rmtz2iUqJvIm0adJr/WRJGf3swq2K/Q73cD2z0vodju5YmIv4MPAONLr/pZuqbLpBHnj7SXSeEyTetynJ2X9i1UW1En2QViSFPA/HEZ9Q4MI+IMgCIIB0ZyxzOOxHrF9ZD6utVezNJLmBrD9706vpUok3Q+MtD1R0gykXvOP2n6usO7BwL+AC+mdkR7yN8Twbub0EGAt0o3x9cDBtl/s6MIqJt/8bwscDRxq+/gCGv2acTYMEoP3h6T7gJWBW3N//ZLAIba3KajZai7ZKOkvlXFfExhn+1VJ2wErAMc2StIL6PVX1Vbs+6yTPHZwIXq3Yv2+YwsK3hMR8AdBEAQDImf41wBeI41X2sL2nfmxB20v1cn1DRZJIjn/f4t0YzoMeIc0mu/QTq6tKlo3ZuraqOnjxrgrbojrRNJ2tv/QVxa8VPY7B/obk4L9hYCLgd/ZfqaEXieQtLTt+zu9jlJIusP2ypLGAavafrNhrldQs1Zzyfw3allSJcoZwKnAF2y3rdoK+kfSGcCipIqQxu/P3WRg261021ihIAiCoD6OJf3hfwV4qCnYX57kaF2EbPh2IjCP7aUljQQ2s/3jiqX2BtYEVm74EWQX5hMl7WP7FxXrdYIl800xpE2NRfNxETOtBrYXbj0nqfi8+tJ0wPdh5vxx1oqv2yeSTidNc7iMlBGuJSiWdBTwY+B14HJSILe37T8UkvxNfk6eBpxp+6VCOp3iaUmzAxcBV0l6EfhnYc2XbV9WWKOZd2xbaVTscbZPlVT56MhsJPtUozJK0lfo8bM5uFsql4CVgKUc2eIhR2T4gyAIggEjaX7gg8A9tifmc/MC0xYsmxxDcng/qWEqJ+l+20tXrHM38Gmn2crN5+cGruwGR+LsRN4nVZtptdEXsB7wJWBT2/OU1CvNVOL7MBF4NR8230QWG+uWdRuj3T4PbE7KFF9Xyggxay4G7AxsRfK5GGX7qlJ6nSI/X2cjOa6/VVCnNnPJrDeGtDm0E7A28G9Sif8yFevcBaxv+7+S1ib18O8BLAd8zPaWVep1CknnAXvaLrahH5QhMvxBEATBgMklvM+0nCt9MzCT7dtTrPgu7xTQmbY12IfUxy9p2gJ6tVM6oO8LSauSgvzPk2bV707axBnSNKYMNAf2uZ//I7bv7fMLB4ikX05mPZWX2toeVvU13yON19xGJJPA/7a8B1SO0+z2HwB3Ar8Els+bVAfY/lNR8RpoPDeB8fnf0iSzyVI0HOxXajpnoJRR4Dak95ldbD+Xx8gdXUBneFMWfxvgZNsXABfkloluYS7gQUm303vDZshPrOl2IuAPgiAIhhovSFqUnF2UtCVlWgj6y3QVy4J1M5J+QhoD+A/SWLdDgTttn97RhVWMpNGk8WPTkNpe/i1pjO1+HecHQFeMMXyPXJJ7wF8HdsuVNsUcwnOr0E4kr4KrSBUod0maD7iFlKUeskg6DNgReByYmE+XDL6xvV6pa/fBlqSqjBez/j+AEgZzwyVNY/sd4FPA15oe66ZY6+BOLyAYGFHSHwRBEAwpch/9ySTDwBdJhoHb2X6yYp0J9JQu93oImMF2V2T56yTPcH+E5P9wqe03JD3ebWZ9ku62vXweffYR2wdJureUJ0KT7sy22z1nu4KckX7F9gRJMwEjSk2UkHQ9cApwnu3XWx7b3vYZ7b9yaCDpEWCZkiX8TVodGa0o6cfAF0lVC78DrijRfy7pQFLlyQvAAsAK2Tvgo8DpttesWjMI3g8R8AdBEAQDQtKc/T1e2qhI0szAMNvjS+oE1ZFnuG9Acnf/JHAdsD4pKC7RltER8sizDYDTgQNt31Ey4Je0OsmBfBbbC0haFvi67d1K6HWKGAlWHZIuAL5p+181aHVstGJuwdiAVK2xEnAucKrtv1WssxowL8nf5dV8bnHSa7Jkm0RxJN1oey1J46nRtyOojm4qMwmCIAjqZSzpj3+7RloDpWYr/6jlOAl2yai8TlDXfGzbE0ju7pdJmgHYBJgJeEbSNba/VKVeBzkUuAK4MQf7iwCPFtQ7FtiQNB4P2/dk87Cuoa+RYJQp0W5s2rRmxV4m9fP/uNQouRo5HLhb0v0U7scuGdC/B21Leg54juT1MgdwvqSrbH+3Qp1b25z7a1XX7yS218ofa5sGElRLZPiDIAiCIYWkbzcdNoLGh2zv3KElDXnqno/dRn8E8Plu6+WvC0m32V610UqQz91T0sG+biQ9RI0jwfIYwAnAmfnUF/PHV4C1bG9axzpKIekB4CTgPnp6+LtikkQDSXsCO5BK7U8BLrL9tqRhwKO2F+3oAocYfVT1jbf9du2LCd4XkeEPgiAIBk3urV2MFIADYPv6Elq2f9aifQw5sxkMmLrnY/fC9iuk8vchjaTv2j5K0vFMmh0u4pqfeSqXuzvPjt8TeKiQVqe4H/gQZQw627FmS+/1fZJusr2mpO1qWkNJXrDd75SHLmAu4Aut00hsT5S0SYfWNJS5izTV4UVSFdjswLOS/gXs2phSEkx5RMAfBEEQDIpsTLYX8GFSue1qJBfrYm7PLcxEofaBqYjrJB1NTfOxu5gH88c7a9b9BnAcMD/wNHAladRhN1H3SLBZJK1q+zYASasAs+THusFvYqykw0mbpV31mm/KRB/bcgwkfxnb3bYhVgeXAxfavgJA0gbAZ0i+CL+mZ+xiMIURJf1BEATBoMi9risDt9peTtKSwCG2tymo1/jjNRyYGzjU9gkl9KYGJF3X5rRt17Vp0xVIOgE40/bNnV5LtyFpnXbnS5WgS1qZ5Ow+Cymb+QqwC2lTZ2Pb55bQrYs6X/N1u/RLeoKevxGtHjOVe5NMLUi60/ZK7c5JGmd7uQ4tLZgMkeEPgiAIBssbebwakqa3/bCkJQrqNZdivgM8300O752grvnYkr4wmXUM6dnmJGO+n0maFzgHOMv2uFJifbUONCjYQlA7dfeW274DWEbSbKQE2UtNDw/pYB/qe81najV7s71wnXpTEf+V9D3g7Hy8DfBinr4yse8vCzpNZPiDIAiCQSHpQtLIo71JZfwvAtPa3qiQXhgHVUwOag4CGs7uY0hVEy9XrDMqf/pBYA3g2ny8HjDadr8bAkMFSQuSTN6+SPK1OAs4u2rXbkk75E/XBJYibTIAbAWMtb1PlXqdJI89Ox74GDAdqbrn1VIjwep6TXQKSfMAPwXms/1ZSUsBq9s+tcNLq5Q6/WW6HUlzkV4Ta5EqJ24EDiFNr1jA9mMdXF7QDxHwB0EQBJWRy25nAy63/VYhjSdpYxwEhHHQAMkzue+nxzhve2DZUgG4pEtJv6tn8/G8wK+6JeBvRtLypNLwkbaHF9K4DtigseklaVrSPPA6s7hFkXQnaQPlPNI89a8Ai9k+oJBera+JupF0GTAKOND2spKmAe62vUxBzRlIbREfp3cAXmTCSl/+MtGqFExtREl/EARBMCAkjbD9SkvG/b78cRbgv4Wkwzioeha1vUXT8SGSxhXUW6gR7GeeBxYvqFcrOeD+DClA/RQpO1xyFvl8pLLpxmtulnyuq7D9mKThticAoySV9Eqo+zVRN3PZPlfS/gC235E0YXJfNEjOAB4GNgQOBb5M2WkSe9HjL7New1+moF5XI+kSJm0heplkUnqS7TfqX1XwXoiAPwiCIBgoZ5L66ceSbgLU8rGUMdJKtr/ROLB9paSf2t5X0vSFNLud1yWtZftGAElrAq8X1Bst6QpSqbtJgXE7E7EhhaRPA9sCGwO3k3pdv2b71cLSRwB3NxmxrQMcXFizbl7LIwfHSTqKVNUzc0G9ul8TdfOqpA+QA7jcMlG6XeGjtreS9Dnbp0s6E7iioF7d/jLdzuMkk9yz8vE29GzW/pZUBRNMgUTAHwRBEAwI25vkj3UbJIVxUPV8Ezi9YVBGyhTvWErM9reygd8n8qmTbV9YSq9GDiBthH3HdqkKl0mwPSqXaK9KCuC+b/u5uvRrYntgGPAtYB9SW88W/X7F4Kj1NdEB9iWN5FtU0k2kQG7LwpoNn5WXJC0NPAcsVFDvaUmzAxcBV0l6EfhnQb1uZ3nbazcdXyLpettrS3qgY6sKJkv08AdBEASDQtLngWsbZlb5Bmtd2xcV0gvjoEJIGgFg+5VOryV4f0jajCaDOduXdHI9VZI38063vV0HtLv2NZH79pcgvY8+Utr4NPfUXwCMJPkHzAL8yPZvSupm7eL+Mt2OpIeADW3/Ix8vQPp5LiXpbtvLd3aFQV9EwB8EQRAMinbzd+v4459vxCfa/l9JnW5G0na2/9DXnOyq52M36X4BOJLk1q/8z6Uc17sdSUeQepX/mE9tC9xpe//OrapacgvIpqWDtbpnxteNpJWBpxoVIJK+QqqU+DtwcJ2VKXWQN4vmoamquRGwBu8PSRsBvwH+RnrPXhjYDRhNMmE9tmOLC/olSvqDIAiCwTKszblif18kLQP8HpgzH78A7GD7/lKaXUyjB7rdnOySGYGjSMFbScOuqYmNgOVsTwSQdDpwNzDkA35JC+QA7UngJkkXA+96IhQIwGudGd8BTgLWB5C0Nsn/YQ9gOeBkCpb1S/pRu/O2Dy2ktwepGux5etq9TKowCN4ntv8iaTFgSVLA/3CTUd+xHVtYMFki4A+CIAgGy52Sfg78inQztQfJyK8UJwH72r4OQNK6pBvVNQpqdiW2T8qfXm37pubHsklZKZ7v9mA/zzlfOR/ebvtfhSVnp8elf7bCWnVyEbACqff6n6QNxmJBue1ud3Ef3pTF34bkn3EBcEENUwiazStnIJm+lnbpX8L2fwpqTG0sRmoDmQEYKQnbv+/wmoLJEAF/EARBMFj2AH4InEPa9b8S2L2g3syNYB/A9mhJJd26pwaOJwVVkztXFXdKOocUzL3ZOGn7T4X0akXS1sDRpFJXAcdL2s/2+YUkD6fHpV+kXv4hn93PCOoPxCV9mPQaWJO0kXkjsJftp+tcRwGGS5rG9jukkZFfa3qsaFxg+2fNx5KOIRkHluIpyk8emGqQdBCwLrAU8Bfgs6TXRQT8UzgR8AdBEASDIo8c+36NPfWPS/ohaaYzwHbAE4U1uxJJq5MqI+Zu6V0eAQwvKD0CeA3YoOmcga4I+IEDgZUbWX1JcwNXA0UCfttnSRpNqigQ8L0ucumfX9Iv+3rQ9p6FdEeRJi5slY+3y+c+XUivLs4CxuRWqNeBGwAkfZT6g+OZKDe+FdIYudGS/o/eG4tD2oehg2wJLAvcbXunXMV0SofXFLwHIuAPgiAIBkUHeup3Jrny/4kU3FwP7FRIq9uZjuSUPQ29y6RfoWAvr+1u/30Naynh/w/tvS4GhaTWCoxG9nk+SfPZvqtqzQ7wOmVbhPpibtujmo5Pk7R3B9ZRKbZ/IukaYF7gSve4dw8jVWsVQ9J99HiDDCeNAjysoOQ/8r/p8j8o603S7bxue6Kkd/IG/78ou2ETVEQE/EEQBMFgqbWn3vaLQKms3lSF7TGkbN9ptv9el66kGYBdgI+TekEb69m5rjUU5vLsKn9WPt4GuKyAzp3AA8C/87GaHjPwyQKadfMf26d3QPcFSdvR8zvclrRxM+SxfWubc3+tQXqTps/fIXl5vFNKrLUNJL/vbFpKr1vJfx92JLVizQ78lrQJ9z/g9g4uLXiPxFi+IAiCYFBIusf2spM7V4HOJfSTnbG9WZV6UxO55Py7TBqAFwkYJZ0HPAx8CTgU+DLwkO29Suh1gjx6cC1yFYrtCwto7EMaqfYycDZwYbeNqZR0q+3VOqC7AHACsDrpfedmUg9/bRtj3YakM2xvP7lzFWsOJ7UObZs/3mi7WPVSNyLpLtsrtJxbCBhh+97OrCp4P0TAHwRBEAwKSRcCd9G7p34l25tXrLNOf4/nbHUwACRdSTJd/A7wDWAH4N+2v1dI727by0u61/ZISdMCV5TaYKgbSUe2/uzanatQb2FSQPM50jz1n9oeV0IrCAZKa+AoaRrgXttLFdBam7ShuDEpC70msIjt16rW6nYkPUx6f1G7x7ukdairiZL+IAiCYLDU0lMfAX1RPmD7VEl7NZX5l/x5v50/viRpaeA5YKGCenXzaaA1uP9sm3OVYPsJSX8GZgS2BxYHxpXQmlrIVS+7kp6X794vd1HbSW1I2h84AJhR0iuN08BbpPLwqvWeJvXunwjsZ3u8pCci2B8w8wM/o33A3y2tQ11NBPxBEATBoGjuqZc0B/CSC5aPSVqMNIZsKXqXn4d50MBpBODPStqYNO/8wwX1Ts7PlR+QxnLNQhrtOKSR9E1gN2ARSc2lrrMCNxXQWwT4Iimz/xSprP8ntt+oWmsq5M8kB/urgQkdXsuQxvbhwOGSDrddx7jIC4DNSd4ZE/JmWJQ0D5zHuqX6amolSvqDIAiCASHpR8C5th+WND3JlGxZ0s3xl2xfXUj3RuAg4BckA6adSH/PDiqhNzUgaRNScPMR0uzxEcAhtkvOyO46JM0GzEHakPp+00Pjbf+3gN5E4F5ScPoKLUFNt40fk7QWsJjtUTkDP4vtIiM5JY2zvVyJa0+tSNrF9qlNx8OBH7Sa61WkJWA9Uin6RqT3tF2Av3Sbz0VpGi1YnV5HMHAi4A+CIAgGhKQHgKVtW9LXSP2SnyKVE59ue5VCumNtryjpPtvL5HM32P5ECb0gmFKRdDD9G1lWHkh1CkkHASsBS9heXNJ8wHm21yyk92PgZtt/KXH9qRFJZwKzkwLvuYDfAWNsf6ew7rTAZ8jGfbbnKqnXbUjawPaVnV5HMHCipD8IgiAYKG81le5vCJxlewLwUDZjKsUbkoYBj0r6FvAM8MGCel1PNn3bg0n7lWPywRSM7YM7vYYa+TywPMkgFNv/lDRr1SKSxpM2UQQcIOktelpebHtE1ZpTC7a/JGkb4D7gNWBb25W3urTRfRu4BLhE0oyl9bqNCPaHPhHwB0EQBAPlzWy49jypdLI5SzNTQd298/X3BA4jGQbtUFBvauAi4FTSTfHEzi4lCNryVq4mMoCkmUuI2K58EyFIZP+VvUg99h8Dts/l4rWZ6dl+vS6tIJhSiIA/CIIgGCh7AecDcwO/aPTSStoIuLuUqO078qf/o8A0gKmUN2z/si4xSXcCo4Azs+ljEEyOcyWdBMwuaVfSdJDKHd6bkfQFYC1Sxv8G2xeV1JsKuAT4lu2rc4/9vsAdwMc7u6wg6G6ihz8IgiAYEkg61vbeki6hTd9ylJ8PHElfAhYDrgTebJwvNV9Z0kdJmzXbAI3g/8qS0x3qpKksvJmXSd/rt20/Xv+qhj6SPg1sQCq3v8L2VQW1fg18FDgrn9oG+Jvt3UtpdjuSRth+peXcYrYf7dSagveHpK/ZPrmv42DKJDL8QRAEwVDhjPzxmI6uojtZhjS//ZP0lPQXm69s+zHgQEk/BDYhmXdNlPQ74LgSjvY183PSaMMzScHpF4EPAY+Qvtd1qxSTNA/wU2A+25+VtBSwerMjejeQA/xiQX4L65BNSQEknU7qPQ8GzoySfgHMb/szjecpUCTgl3QVsJXtl/LxHMDZtjcsoTeVoMkcB1MgkeEPgiAIhhx5JBe2/93ptXQDkh4GRtp+q0bNkaQs/0bAFcAfSeXT2w/1cWiSbrO9asu5W22vJuke28tWrHcZqUriQNvLZtPMuxtTLLqBXF5/JMmgU/lfMRM9SX8C9rH993y8IHCE7W1L6E0N1P08bTdOLkbMBVMjwzq9gCAIgiB4LyhxsKQXgIeBv0r6t6QfdXptXcA9pHFZtSBpLPALUv/uSNt72r7N9s+Abih3nyhpa0nD8r+tmx4rkWmZy/a55OoM2+8AEwrodJKjgM1sz2Z7hO1ZCzvmf4A0cWS0pNHAg8Dcki6WdHFB3W6m7ufpREkLNA7ypk1kOgeIpDMkzdZ0vKCkazq5puC9ESX9QRAEwYDIGbc+sf2niiX3BtYEVm4yCFwEOFHSPrZ/UbHe1MQ8wMOS7qB3D38pX4StWvvYJS1s+wnb/T6vhghfBo4Dfk0KMG4Ftssjwb5VQO9VSR/IWkhajeQZ0E08b/uhGvViI7EiJE2Tg/u6n6cHAjdKGpOP1wa+VlCv27kRuE3SvsD8wH7Atzu7pOC9ECX9QRAEwYCQNKqfh21754r17gY+bfuFlvNzkwzfokxzgEhap91522Pana9A7y7bK7ScG2t7xRJ63Y6kFYFfAksD95MmZ2xp+96OLqxCJB1H8kG4iN6bUlVvLCJpOMkUcP2qrz010ni9d+J5KmkuYDVSC8gtrX8/gveHpLWA64AXgOVtP9fhJQXvgcjwB0EQBAPCdt0j8aZtd7Nm+9+Spq15LV2DpGHAr2wvXYPWkqQRXLO1VIiMAGYorV8XeRNqV2Ahmu61qt4Ea7ru2LxpswQpsHnE9tsltDrICOA1kkt/AwOVB/y2J0h6TdJstrutUqITCOp7nkpa0vbDkhqbiv/MHxeQtECp6SPdjqTtgR8CXwFGAn+RtJPtezq7smByRMAfBEEQDBpJG5MCuXeDNtuHVizTn6FcbWZz3YbtiZLuyTfC/ygstwTJlX92YNOm8+NJAXK38GfgBuBqauill3QPcA5wju2/ldbrBB3YYHwDuC87vb/atI49a15HNzB3LgNvZQNJ2P55xXr7kkr3f9bmsWLTR6YCtgDWsv0v4CxJFwKnA8t1dFXBZImS/iAIgmBQSPoNMBOwHnAKsCVwu+1dKtaZQNONd/NDwAy2I8s/QCRdC6wM3E7v4KZID7+k1W3fUuLaUwKSxtU5aSCbkW2T/00kBf/n1rCBUxxJ37V9lKTjaWO4VioAl7RDu/O2Ty+h181IehY4kT5GuNk+pJDuDLbfmNy5YOBImq7O6S7BwIiAPwiCIBgUku61PbLp4yzAn2xvMNkvDqYI6urh71TwVjeSfgzcbPsvHdBejFR2+2Xbw+vWrxpJm9q+pBMBuKTpgMXzYTe2SdRCO8+OTul2ai3dgKQZgF2YtJqvSKtSUB1R0h8EQRAMltfzx9ckzQf8B1i4g+sJ3ie2x0iah5Tlh1Sh8a8CUg2X9TsLXHtKYi/gAElvAm9TeGY8gKSFgK1JWf4JwHdLadWJ7Uvyx1oz65LWJZUrP0n6/X1E0g62r69zHV1C28x+MTHpQyQX+RklLd+kP4JUjRYMjDNII3E3BA4lTSOpc3JGMEAiwx8EQRAMCkk/BI4HPgX8ipS5PcX2Dzu6sOA9k+fEHw2MJt0cfwLYz/b5nVxX8N6QdBswLXAeqY//8cl8yZBD0uLAd5jUCLFIP7akscCXbD/SpH9WTJJ4/0ia0/Z/a9TbAdgRWAm4g56AfzxwWonJDlMDku62vXxTNd+0pGkW4YkwhRMBfxAEQVAZkqYn9dOHs/UQIpu+fbqR1c8u81fbXrZinUtoU8rfoJRnQF20cQfvRSl38IZuiWtPKeTn6G+AsTQZIdoeW0jvXtsjJ3cumHKRtIXtCzq9jm5B0u22V5F0PbAb8BypGmyRDi8tmAxR0h8EQRAMGklr0JR5y87Lv+/oooL3w7CWEv7/AMMK6BxT4JpTEt8mTRuoxR1c0na2/wBsJGmjSQSrdz/vJO/YPrFGvTslnUoqY4ZUvlxkcyEoxocljSBl9n8LrAB83/aVnV3WkOVkSXMAPwAuBmYh+YUEUzgR8AdBEASDQtIZwKLAOHoybwYi4B86XC7pCuCsfLwNULnhXNUmgFMatnfNH9erSXLm/HHWdsupaQ1FkTRn/vQSSbsBFwJvNh4vWCr+TWB3YE9SSfj1wK8LaQVl2Nn2cZI2BD4I7ASMAiLgHxjX2H6R9FpYBEBS+PUMAaKkPwiCIBgUkh4ClnL8QRlySJre9pv58y8Aa5GDG9sXFtA71/bWku6jd0DaMLUb0uXS+WfYJ6V6hyWtafumyZ0bikh6gvRcaWf85ignHrpIuppkavkr25cWuH6j1/w4YLTtCxt96FVrTQ30MfVgbPhaTPlEhj8IgiAYLPcDHwKe7fRCgvfNLcAKks6wvT1Q2sxqr/xxk8I6nWLT/PGDwBrAtfl4PZIhYqmf7/GkcuXJnRty2K41gyjp3v4eH+qbUlMYXwHmBVYrdP2xkq4kTY3ZX9KswMRCWl2LpCVJo/hma9nUHEHTeL5gyiUC/iAIgmCwzAU8KOl2epfaDmkDtqmE6bKj9RrtstNVZ6RtP5s//j2PzlqFlL29w/ZzVWp1Ats7AUi6lFT18mw+npc0waJSJK1O2liYW9K+TQ+NAIZXrddJJO0O/NH2S/l4DmBb21WX2U8kPSfPBC6hZ+xoUCH59zdXNl0s5Y2wC7Ac8Ljt1yR9gFTWH7w/liBt0s5Oz6YmJG+EXTuxoOD9ESX9QRAEwaCQtE67893er90NSFqLZEa2NcmEqRnb3rmQ7leBH5Ey4ALWAQ61/bsSenUj6X7bSzcdDwPubT5Xkc46wLrAN0gO9g3GA5fYfrRKvU4iaZzt5VrOFSnPzhnNbUnBzYOk4P9K2+9UrTU1IWk0sBkp4TgO+Dcwxva+/XzZQHQ6Mi2j25G0uu1bOr2O4P0TAX8QBEEwaCTNA6ycD29vcXwPpnAk7WL71Br1HgHWsP2ffPwB4GbbS9S1hpJIOgFYjGSCaOCLwGO29yikt6Dtv5e49pRCLrVftuEVImk4aRPl44V1tyFVZxxp++iSWt1O0xz3rwIfsX1QiVGHkn5re1dJ17V52DE3fmDkca270jSRB6DUxnBQHVHSHwRBEAwKSVsDR5N6lAUcL2k/2+d3dGHBe8b2qa2jFfP5UpMWniZloRuMB54qpFU7tr+VWyQ+kU+dXMgE8VjbewMnSJokg9NlbTVXAOdK+g1pE+UbwOUlhCTNT9qk+TzwIrAPaTpAMDimye0tWwMHlhLpwLSMqYU/AzcAV9MzkScYAkSGPwiCIBgUku4BPt3I6ucswNW2l+3syoL3Sl+jFW3vWbFOo3R3OWAZ0g2kgc+RKkO+UaVetyNpRdtjp4a2mtwW8XXgU6SNxSuBU2xXGnhIGkMac3gucD7Qa+xfwTGAXY+krUhz22+0vZukRYCjbW9RsU5HpmV0O+3aaoKhQQT8QRAEwaCQdJ/tZZqOhwH3NJ8LpmzqGq0o6aD+Hrd9SEn9usgBx5Ekt37RM3ZwREcXFkwWSU/SMzKy3ejIGAM4hSNpVD8PF/Mm6XYk/ZjUevWXTq8leH9EwB8EQRAMCklHAyNJ/coA25B6a7/XuVUF7wdJ5wF7Nlzlg8Eh6TFgU9sP1aS3JnAwsCCpJaPrglNJiwGHA0vRNAqsm77HbkfS6cBeLZMWflbQHHR41RUgUzOSxgMzk6bxvE1sZA4Zooc/CIIgGBS295O0BbAm6QagSL9yUJRaRyvmto/vkmY7Nwdv3WKm9XxdwX7mVFKf+Vi6t7d2FHAQ8AtgPdJ4NXV0RcH7ZWQj2Aew/aKkyqcsNPGYpPOBUbYfLKgzVWB71k6vIRgYEfAHQRAEg8b2BcAFnV5HMGAOrlnvj8A5pNnO3wB2II3o6hbulHQOcBG9N1BK9Q6/bPuyQteeUpjR9jWSlCcSHCzpBtImQDA0GCZpDtsvAkiak7KxyEiS+eIpudXsd8DZtl8pqNm15M2T3wGX257Y6fUE750o6Q+CIAgGhKQbba+Vy/za9bpGmV/QFkljba/YPJJL0hjbbc3nhhp99BAX6x2WdAQwHPgTvTcYumbeuKSbSFMPzgeuBZ4BjuiWUY5TA5K+AuxP+h0CbAX8xPYZNWivTWo7mz3rH2b7sdK63YSk9UmVNasB5wGn2X64s6sK3gsR8AdBEATBVEqbzZp3H6Lgpo2kW22vJukK4JfAP4HzbS9aQq/bmRrmjUtaGXiIFLAdBswGHGX71k6uK3h/SFoK+CTpPeaakqX2koYDG5OC1IWAM0jVRZ8Afmp78VLa3Yyk2YBtSaMVnwJ+C/zB9tsdXVjQJxHwB0EQBINC0hm2t5/cuSBoIGkT0jznjwDHAyOAg21f0tGFVUTO8E9ygxXu4EOXPMkC4Fe2T+joYoYYkkbYfiWX8E9CqVGHkh4HrgNOtX1zy2O/rHrs6NSApA8A2wHbkzZq/wisBSxje90OLi3oh+jhD4IgCAbLx5sPJE0DrNihtQRDgxdtvwy8TDJgazjNdwuXNn0+A/B50s1xESTt2+b0y8BY2+NK6daBpIv7e7yUsWQbnY/lYGe1OvS6jDNJfh1jadP+BZSatPAV2zc2n5C0pu2bIth//0j6E7AkqVJi06apLudIurNzKwsmR2T4gyAIggEhaX/gAGBG4LXGaeAtklP//p1aWzBlI+ku2ytM7ly3kA3Dri5VYi/pTGAloFEhsTFwB+nm/DzbR5XQrQNJ/yaVDZ8F3EaLM7/tMYV0vwX8sWEwFww9prb3mdJI+qTtazu9juD9Exn+IAiCYEDYPhw4XNLhEdwH7wVJqwNrAHO3ZKVHkEznupXFgAUKXv8DwAq2/wcg6SCSMdnapKzqkA34gQ8Bnyb1DH8J+D/gLNsP1KB7h6S7SM7kVziyZINC0jW2PzW5cxXoTK3vM0XI/hlPNYL9bL64BfB3UitWkZaMoDqGdXoBQRAEwdDG9v6S5pC0iqS1G/86va5gimQ6YBZSwmHWpn+vAFt2cF2VImm8pFcaH0mZ9+8VlFyAVFnT4G1gQduv0+TaPxSxPcH25bZ3IJXTPwaMlrRHYd0fkDZqTgV2BB6V9FNJYSz5PpE0Q+7fnyv/rZgz/1sImK+A5FTxPlMjJ5HfX/Lf9iOA35Pahk7u4LqC90hk+IMgCIJBIemrwF7Ah4FxpJvyW0hOzEHwLrn8eoyk02z/XdLMtl/t9LqqxvasNUueCdwq6c+kkvdNgLMkzQwUc0GvC0nTk9oUtiW5rf+SNIKwKLYt6TngOeAdYA7gfElX2f5uaf0u4uvA3qTgfiw9bRmvAL+qWqz1fQZA0hzAS1GlMSCGN2XxtyG17F0AXCBpXOeWFbxXooc/CIIgGBSS7gNWBm61vZykJYFDbG/T4aUFUyi55PZUYBbbC0haFvi67d06vLTKkLQZqaQeYLTtS/v7/xXorUhyyxZwo+2uMNGSdDqwNHAZcLbt+2vS3RPYAXgBOAW4yPbb2Y/h0Rgh+f6RtIft42vQ+RFwru2H82bRZcBypE2bL9m+uvQauglJ9wPL2X5H0sPA12xf33jM9tKdXWEwOSLDHwRBEAyWN2y/IQlJ0+ebrCU6vahgiuZYYEPgYgDb93RTG4ikI0ibYH/Mp/bK7uAlvS7eASaSXM+7aR729sCrwOLAntK7nn0iJeFHFNKdC/hCI0PcwPbEPFYyeJ/YPl7SGqQqjWmazv++YqltgMPy5zuQWpjnJj2HTgci4H9/nEWqmHgBeJ00UhVJHyWV9QdTOBHwB0EQBIPlaUmzAxcBV0l6kYIjyILuwPZTTcEbwIROraUAG5EyYhPh3Sz13UCRgF/SXsCuwAWkQPgPkk6uI5taGtud8ps6FqBldvx422/bfqgzSxraSDoDWJTU+tV4vZvUD14lbzWV7m9IMnmcADyUx8YG7wPbP5F0DTAvcGXTz3YYUNRLI6iGeNIHQRAEg8L25/OnB0u6DpiNVEIZBH3xVM70WdJ0wJ5AtwVRswONvtfZCmvtAqza8EOQdCTJR2PIB/wd5C7gI8CLpE2U2YFnJf0L2NX22A6ubaiyErBUDX30b0paGngeWA/4TtNjMxXW7kps39rm3F87sZbg/RMu/UEQBMGgyFkbIJkl2b6YNMYqCPriG8DuwPzA06T+2t07uaCK+Slwt6TTcnZ/bD5XCtG7QmICLfPqg/fN5cBGtuey/QHgs8C5wG7Arzu6sqHL/aRxh6XZizSW8mHgF7afAJC0EanSJgimKsK0LwiCIBgUku6yvULT8XDgPttLdXBZwRRKfn6cbnu7Tq+lBNnUbUtSn+vKpMD7NtvPFdTcl9SrfGE+tTlwmu1jS2l2O5LutL1Su3OSxtlerkNLG7LkCrDlgNtpGhdpe7NOrSkIpgaipD8IgiAYEJL2Bw4AZsyzxiEFN28Rs3mDPrA9QdLckqaz/dbkv2JokU3dvmX7XLIpYQ2aP5c0mh6X/p1sRyZzcPxX0veAs/PxNsCLecNqYueWNaQ5uNMLCIKpkcjwB0EQBINC0uGF3ceDLkPSScAKpID41cZ52z/v2KIqRNIPSW7W59D7+/tvn180MJ2VgblsX9ZyfjPgmegzHziS5gIOomnUIXAIyZV8AduPdXB5QRAE75kI+IMgCIJB0dc4tcac3iBoRdJB7c7bPqTutZRA0hNtTtv2IhXrjAZ2tP1ky/mPAifb/mSVelMjkkYAE23/r9NrGepIWo1kJPkxYDpgOPBqwdGKQRAQAX8QBEEwSCRd0nQ4A7AKMDaCjWBy5GDKtsd3ei1DEUn32V6mj8fusb1s3WvqFiQtQxoX1xjL9wKwg+37O7eqoY2kO4EvAueRHPu/Aixm+4Ca9FcCnrX9TB16QTClED38QRAEwaCwvWnzsaSPAEd1aDnBECDfeI8CZs3HLwM7D/US9LyBMY/tR/PxVsCM+eErbD9fseSM/Tw2c8VaUxsnAfvavg5A0rokb5I1OrimIY/txyQNtz0BGCXp5hrl9wBGSvqr7W1q1A2CjhIBfxAEQVA1TwNLd3oRwRTN74DdbN8AIGkt0gbAyI6uavAcA9wMPJqPDwcuIwXma5DGEVbJ1ZJ+Avygeba5pEOAayvWmtqYuRHsA9geLSk2UQbHa5KmA8ZJOgp4lho3pmzvACBp1ro0g2BKIAL+IAiCYFBIOh5oBBvDSGOX7unYgoKhwPhGsA9g+0ZJ3VDW///t3Xm4ZFV19/HvjwZkdkREBZlBRGYMiIKo0YhCHDCCaIwzMQHURH0MvooSEyNKFBQjkThLFMEBJwjzoIaxmUEN4hA1ztgyNrjeP865UFxvN9Bd554avp/nqefW2XWr1uq2r9x19t5r7wS8euB6UVUdCJDk3A7i/R3wEeB7SRa2Y9sAFwKv6CDeNLmubb74yfb6RcBcvRl0772YZt/+3wKvA9YDntdVsCS7Agur6sYkL6JpFPr+qvpBVzGlUeQefknScknykoHL24Hrq+q8vvLR6Evyr8BqwHE0N4teAPwGOAGgqi7uL7tlN3tPfZKtZvZ8J7miqjpZ+ZJkI+Ax7eWVVXVdF3GmSZIH0nTln+nSfzZwaFX9ptfEdK8luYzmBtjWNDdujgWeW1W795qYNM8s+CVJy61dprkFTfF27SSer67hSXLGUl6ucW34mORS4OlV9bNZ448Avl5V475lQVpmSZ4FHAY8imaVcWh+3jvp0p/k4qraPslbaY6pPHZmrIt40qhySb8kabkk2ZOmwdX/0PwCt2GSV88+G1wCSLIC8KGq+lzfuXTgcOCkJH8HXNKObU+zt//w3rLSvdaeOrLE2bCq2nse05k07wOeC1xe8zPjuCjJm2m2Y+yWZAGw0jzElUaKM/ySpOWS5BrgWVX1vfZ6Y+CrVbVFv5lpVCU5u6p26zuPLiT5M+AfaJbYF3Al8C5vgI2HJEtd7l1VZ81XLpOmXdnzlKr6wzzFexjwQuCCqjonyfrAk6rqE/MRXxoVFvySpOUyu3hLEuCsSS3otPzaZmg3A58FbpwZr6pf95aUNEu7VWmz9vLaqlrcZz7jLslONEv6zwJunRmvqiN6S0qaAhb8kqTlkuRDNHsyP0czo/l84FrgPICqOrG/7DSKkszV7byqaqN5T2YCJbm6ffrBqvpAr8mMqSRPAj4OXE+zVWk94CVVdXZ/WY23JKcAvwcuB+6c5a+qtw85zrlV9YT25I/BQqfTngHSqLLglyQtlyQfXcrLVVUvm7dkJAGQ5MHAzlX11b5zGUdJLgJeWFXXttebAcdV1Q79Zja+klxYVTv2nYc0bSz4JUnSvEqyGvB6YP2qelWSTYHNq+orPac2lpKsDtxcVX9oC9MtaE4FcAn6Mkpy2exTFeYa072X5F3A6VV1yjzF2xj4cVXd2q7Y2Br4RFX9dj7iS6PCgl+StFySbAgcCGzAwOkvdrPWkiT5LHAR8JdVtVWSVYFvVdW2/WY2HEnWAf4JeHhVPSPJlsAuVXVsR/EuAp4IPBD4NnAhcFNV7d9FvGmQ5D9oloN/sh3aH1ixql7aX1bjrV1ivzpwW/vo+li+hcCONP9tOhn4Ms2NxT27iCeNKgt+SdJyac8eP5Y/3pdpN2vNaWZpb5JLqmq7duzSqtqm79yGIcnXgY8Ch1TVNklWBC6pqsd2FG/mvPEDgVWr6t2Df7e675LcD/gb4Ak0henZwNFVdetS36iRMfBz8Qbglqo6yp8LTaMV7/lbJElaqluq6si+k9BYua2d1S+4c+ntJBVSD6mqz7VngFNVtye5o8N4SbILzSz0y9sxf8dbDm1hf0T70BC0J7jsD2xYVYclWQ9Yt6rO7yjk4iT7AS8B9mrHVuooljSyVug7AUnS2Ht/krcl2SXJ9jOPvpPSSDsU+AawXpJPA6cBb+o1o+G6sW2aN3NDY2fghg7jvRZ4M/CFqroyyUbAGR3Gm3hJdk3yX0m+k+S6mUffeY25o4FdgBe2178HPthhvJe28d5ZVd9vt599qsN40khySb8kabkk+WfgxcD/cNeS/qqqJ/eXlUbdTBd5muXS366qX/ac0tC0N7yOArYCrgDWBvapqss6jrt6Vd3YZYxpkeQa4HU0vSbuXJ1RVb/qLakxN7DEfl628iR5FvC1qvrDPX6zNMFc7iVJWl7PATaqqtv6TkTjIclpVfUU4KtzjI29qro4ye7A5jQ3NK7tsmN+u5z/WGANYP0k2wCvrqrXdBVzCtxQVV/vO4kJszjJAu5a+bI2A31fOrAvzQq0E4CPVtXVHcaSRpYFvyRpeV0KPAD4ec95aMQlWQVYDXhIkgfSFMMAawEP7y2xIUvy3FlDmyW5Abi8qrr4OXkf8HSaLuRU1aVJdusgzjQ5I8nhwIkM9Jeoqov7S2nsHQl8AXhokncC+wBv6SpYVb0oyVrAfsBHkxRNM83jqmpRV3GlUWPBL0laXusA1yS5gLv/YuyxfJrt1TT7zR9Os1R6puD/Hd3u5Z1vL6fZOzyzj/5JNMflbZbkHVX1ySW9cVlV1Y+anmh36rJJ4DT4k/brjgNjBbhVaRlV1afbIyRnVvI8u+tZ96r6XTvDvyrN//c8B3hDkiOr6qguY0ujwoJfkrS83tZ3AhoPVfV+miW2B074L9t/AB5dVf8HkGQd4EM0ReTZ3HW2+7D8KMnjgUqyMnAQ4PLl5VBVe/Sdw6RIshqwuKoWV9U17Uz7nsCj6fDfaZK9gJcBG9P8zD2uqn7e5nM1TZ8NaeLZtE+StNzagman9vL8jpYta4K0BeoGDEw+VNUnektoiJJcXlWPHbgOzXL+rbo4BzzJQ4D3A0+lWTVxCnCwDeaWXZL709zMnNkacRbwjqrq8rSFiZTkbODlVfXdJJsA5wOfBrak+e/FmzuK+wngI1V19hyvPaWqTusirjRqLPglScslyV8AhwNn0hQbTwTeUFWf7zMvja4kn6SZdVvIXUvPq6oO6i2pIUpyNLA+cHw79Dzgx8AbgK84ezz62mXgVwAfb4deDGxTVbP7M+geDN4AS3IY8KCq+pt2NcpFgzfHJA2fBb8kabkkuRT405lZ/bbz8qldHbWk8ZfkamDLmtBfQtoZ/ecBu9LcBDsXOGHYf94kb6yqdyc5irbz+aBJuYHShyQLq2rbexrTPUtyWVVt3T4/Dzi8qr7YXg/9WL4ki7j7z0Pa69DcWFxrmPGkUecefknS8lph1hL+XwEr9JWMxsIVwMOAn/adSBfawv7z7aNLM/ufL+w4zjS6OckTqupcgCS7Ajf3nNO4uizJe4D/BTah2XJCkgd0Eayq1uzic6VxZcEvSVpe30hyMnBce/0CwPOrtTQPAa5Kcj4TeLJDkp1pGoI9GlgZWADcOOyZxao6qT3XfKuqesMwP1scAHyi3csf4NfAX/Wa0fh6JXAwTc+Op1XVTe34lsB7ug6e5KHAKjPXVfXDrmNKo8Ql/ZKk5daeO/4Eml+Mz66qL/SckkZYkt3nGq+qs+Y7ly4kuRDYl2YP/47AXwKbVNUhHcU7vao8Lq4D7TnuVNXv+s5F902SvYH30hwD+nPgUcDVVfWYXhOT5pkFvyRpmbTdltepqvNmje8G/G9V/U8/mUn9SnJhVe04a+/yN6vq8R3Fey+wKc0NhhtnxqvqxC7iTYMk96Ppw7ABdz9J4h195aT7pu0v82SanjLbJdkD2K+qXtVzatK8ckm/JGlZvQ/4hznGb2pf22s+k9Hom6OZ1p0vMVnNtG5qO5AvTPJuml4Fq3cY70E0vTMGZ/kLsOBfdl8CbgAuYmDbicbK4qr6VZIVkqxQVWck+Ze+k5LmmwW/JGlZbVBVl80erKoLk2zQQz4acVPUTOvFNPv2/xZ4HbAezWxxJ6rqpV199hR7ZFX9Wd9JaLn8NskawNnAp5P8HLi955ykeeeSfknSMknyvara5L6+Jmm4kjySpkngrjQz++cCB1fVj3tNbIwlOQY4qqou7zuXcZfkJOZe2QN016wzyerALTQriPYH7g98uqp+1UU8aVRZ8EuSlkmS44DTq+rfZ42/nKYT8wv6yUzqV5LvM0eBU1UbdRTvv4DPAJ9sh14E7F9Vf9pFvEmW5HKa/+1WpOmLcB3Nkv6ZbSdb95jeWFpSk84Zk9KsUxpVFvySpGWSZB3gC8BtNPtcoelIvjLwnKr6WV+5SX1K8uCBy1WA5wMPqqq3dhRvYVVte09jumdJHrW016vqB/OVyyRKsiqwflVdOw+xngv8C/BQmhs2k9YrRLpXLPglScul7Xy8VXt5ZVWd3mc+0ihKcm5VPaGjzz4V+BhwXDu0H/DSqnpKF/EmWZJVgAOATYDLgWOryn3fQ5BkL+A9wMpVtWGSbYF3dLik/3vAXlV1dRefL40LC35JkqQhSrL9wOUKNCtf/rqqtuko3vrAB4BdaJajf5NmD7+z0fdRks8Ci4FzgGcAP6iqg/vNajIkuYjmJIkzq2q7duyyrrZJJDmvqnbt4rOlcWKXfkmSpOF678Dz24Hrgb/oKlhV/RDoZJZ0Cm1ZVY8FSHIscH7P+UyS26vqhiTzFe/C9gbOFxk4WrGqPK5SU8WCX5IkaYiqao/5jJdkM+BDwDpVtVWSrYG9q+of5zOPCbF45klV3T6Pxek0uCLJC4EFSTYFDqJZjdKVtYCbgKcNjBVgwa+p4pJ+SZKkIUry+jmGbwAuqqqFHcQ7C3gD8OGBpdJXVNVWS3+nZktyB3DjzCWwKk3RaMO35ZRkNeAQ7irATwb+sapumcccdqqqC+YrnjQKnOGXJEkarh3bx0nt9TOBC4ADkhxfVe8ecrzVqur8WbPRNppbBlW1oO8cJtjmVXUITdE/b5JsCexL08zyBpqfTWlqWPBLkiQN14OB7avq9wBJ3gZ8HtiN5gjLYRf8v0yyMc1yZZLsA/x0yDGk5XVEknWB44H/rKoruwrUHq+4X/u4HXgUsGNVXd9VTGlUrdB3ApIkSRNmfeC2gevFwKOq6mYGmocN0d8AHwa2SPK/wGuBv+4gjrTM2t4WTwJ+ARyT5PIkbxl2nCTfBL4GrATsU1U7AIss9jWtnOGXJEkars8A307ypfZ6L+C4JKsDVw07WFVdBzy1/fwVqmrRsGNIw1BVPwOOTHIG8EbgrcCwm0v+AngksA6wNvBd2tUv0jSyaZ8kSdKQJdkR2JWm2du5VXVhh7HuBzwP2ICByZyqekdXMaX7KsmjgRcAzwd+CfwncEJV/byDWPen+ZnYD9gEeADw9KrymEVNHQt+SZKkIUuygGaGcbAA/2FHsb5BewoAcMdAvPd2EU9aFkm+DRwHHF9VP5nHuA+ludGwH7BeVa03X7GlUWDBL0mSNERJDgTeBvwfTQE+c6Tb1h3F8wg+jYUkqwLrV9W1PcV/VFX9oI/YUl9s2idJkjRcB9McQfaYqtq6qh7bVbHf+maSx3b4+dJyS7IXsBD4Rnu9bZIvz2cOFvuaRjbtkyRJGq4f0Syx71SSy2maka0IvDTJdTSnAHS6okBaRocCjwPOBKiqhUk26DEfaSpY8EuSJA3XdcCZSb7KwDF8VXXEkOM8l7sf/yeNstur6oYk8xIsya5Vdd49jUmTzoJfkiRpuH7YPlZuH135bFVt3+HnS8N0RZIXAguSbAocBHyzw3hHAbN/PuYakyaaBb8kSdIQVdXb5ynU/EyVSsNxIHAIzaqX44CTgcOGHSTJLsDjgbWTvH7gpbWABcOOJ406C35JkqQhSrI28EbgMcAqM+NV9eQhh5pd0NxNB1sIpGVWVTfRFPyHdBxqZWANmjpnzYHx3wH7dBxbGjkW/JIkScP1aeCzwLOAA4CXAL/oIM4CmsLGmX6NrCQn0TSXnFNV7T3MeFV1FnBWko/ZlV+CVC3x50+SJEn3UZKLqmqHJJfNdMpPclZV7T7kOBe7h1+jLslS/923BXoXcTcD/h7YgIFJzg5W2kgjzRl+SZKk4Vrcfv1pkmcCPwEe2UEcZ/Y18uYq6JNsX1UXdxz6eODfgI8Ad3QcSxpZzvBLkiQNUZJnAecA69F0BV8LOLSqThpynAdV1a+H+ZnSfJiP1SkzK226jCGNA2f4JUmShqiqvtI+vQHYAyDJazuIY7GvcTUfq1NOSvIa4As0JwMA/txo+jjDL0mS1LEkP6yq9fvOQxoFSZ5dVV/sOMb35xiuqtqoy7jSqHGGX5IkqXudzWgm2RD4aVXd0l6vCqxTVdd3FVO6r5IE2B/YqKrekWR94GFVdX4X8apqwy4+Vxo3K/SdgCRJ0hTocknl8cAfBq7vaMekUXI0sAuwX3u9CPhgV8GSrJbkLUmOaa83bftrSFPFGX5JkqQhSLKIuQv7AKt2GHrFqrpt5qKqbkuycofxpGXxJ1W1fZJLAKrqNx3/O/0ocBHw+Pb6xzQ3wr6yxHdIE8gZfkmSpCGoqjWraq05HmtWVZeTLL9IsvfMRZI/B37ZYTxpWSxOsoD2pliStbn7ypRh27iq3k17TGZV3YxHWWoKOcMvSZI03g4APp3kAzQFzY+Av+w3JemPHEnTMf+hSd4J7AO8pcN4t7X9LGZuMGzMQLd+aVrYpV+SJGkCJFmD5ne7RX3nIs0lyRbAU2huTJ1WVVd3GOtPaW4obAmcAuwK/FVVndlVTGkUWfBLkiSNoSQvqqpPJXn9XK9X1RHznZO0JEl2Bq6cuSGVZE1gy6r67w5jPhjYmeYGw7eryq0umjru4ZckSRpPq7df15zjsUZfSUlL8CHg9wPXN7ZjXXoEsABYGdgtyXM7jieNHPfwS5IkjaGq+nD79NSqOm/wtSS79pCStDSpgaXFVfWHJJ3VIkn+A9gauJK7mgMWcGJXMaVRZMEvSZI03o4Ctr8XY1KfrktyEHfN6r8GuK7DeDtX1ZYdfr40Fiz4JUmSxlCSXWjOGF971j7+tWiWMUuj5ACaTv1voZlpPw14VYfxvpVky6q6qsMY0siz4JckSRpPK9Ps1V+RZt/+jN/RHHkmjYyq+jmw7zyG/DhN0f8zmuP40qRRW89jDlLv7NIvSZI0xpI8qqp+0D5fAVijqn7Xc1rS3SRZG3glsAEDk45V9bKO4n0PeD1wOXft4WfmZ0WaFs7wS5Ikjbd/TnIAcAdwEXD/JEdU1eE95yUN+hJwDnAqzb/Vrv2wqr48D3GkkeYMvyRJ0hhLsrCqtk2yP7AD8CbgIpcua5TM/Dudx3hHAw8ATqJZ0g9AVdmlX1PFGX5JkqTxtlKSlYBnAx+oqsVJnNHRqPlKkj2r6mvzFG9VmkL/aQNjHsunqeMMvyRJ0hhrjzp7E3Ap8ExgfeBTVfXEXhOTBiRZBKwO3NY+ZprordVrYtKEs+CXJEmaMElWrKrb+85Dmm9J3lhV705yFM2M/t1U1UE9pCX1xiX9kiRJYyjJi6rqU0lev4RvOWJeE5KWIkmA/YENq+qwJOsB61bV+UMOdXX79cIhf640liz4JUmSxtPq7dc1e81CuneOpjke78nAYcDvgQ8COw0zSFWd1D69qaqOH3wtyfOHGUsaBy7plyRJktSpJBdX1fZJLqmq7dqxS6tqmy7j3dOYNOmc4ZckSRpjST7K3HuVX9ZDOtKSLE6ygPbfapK1aWb8hyrJM4A9gUckOXLgpbUA+1po6ljwS5IkjbevDDxfBXgO8JOecpGW5EjgC8BDk7wT2Af4fx3E+QnN/v29gYsGxhcBr+sgnjTSXNIvSZI0QZKsAJxaVU/uOxdpUJItgKfQHMl3WlVdfQ9vWZ5YK1XV4q4+XxoXzvBLkiRNlk2B9ftOQhqU5JNV9WLgmjnGuvC4JIcCj6KpeQJUVW3UUTxpJFnwS5IkjbEki2j2Raf9+jPgTb0mJf2xxwxetPv5d+gw3rE0S/gvAu7oMI400iz4JUmSxlhVeSyfRlaSNwP/AKya5Hc0N6YAbgOO6TD0DVX19Q4/XxoL7uGXJEkaY0nmOmbsBuAHVWVXco2EJP9cVW+ex3jvAhYAJwK3zoxX1cXzlYM0Ciz4JUmSxliSbwPbA5fRzJ4+FrgUeDBwQFWd0mN60p2SPIK79tQDUFVndxTrjDmGy2aWmjYu6ZckSRpv1wMvr6orAZJsCbwBOIxmdtOCX71rZ9z3Ba7irj31BXRS8FfVHl18rjRuLPglSZLG2xYzxT5AVV2VZLuqui7J0t4nzafnAJtX1a33+J1DkGQd4J+Ah1fVM9obYbtU1bHzEV8aFSv0nYAkSZKWy7VJPpRk9/ZxNPCdJPcDPIdco+I6YKV5jPcx4GTg4e31d4DXzmN8aSS4h1+SJGmMJVkVeA3wBJo9/OcCRwO3AKtV1e97TE8CIMkJwDbAady9id5BHcW7oKp2SnJJVW3Xji2sqm27iCeNKpf0S5IkjbGquhl4b/uYzWJfo+LL7WO+3JjkwTR9AkiyM83pFdJUcYZfkiRpjCXZFTiUP+5+vlFfOUlzaVejrF9V185DrO2Bo4CtgCuAtYF9quqyrmNLo8SCX5IkaYwluQZ4HXARd3U/p6p+1VtS0ixJ9gLeA6xcVRsm2RZ4R1Xt3WHMFYHNaba6XFtV9rTQ1HFJvyRJ0ni7oaq+3ncS0j04FHgccCZAVS1MsuGwgyTZCfhRVf2sqm5PsgPwPOAHSQ6tql8PO6Y0yuzSL0mSNN7OSHJ4kl2SbD/z6DspaZbbq2r2Hvoulhp/GLgNIMluwLuAT9Ds3z+mg3jSSHOGX5Ikabz9Sft1x4GxAp7cQy7SklyR5IXAgiSbAgcB3+wgzoKBWfwXAMdU1QnACUkWdhBPGmkW/JIkSWOsqvboOwfpXjgQOITmSL7jgJOBwzqIsyDJilV1O/AU4FUDr1n7aOrYtE+SJGkMJXlRVX0qyevner2qjpjvnKR7I8kDgd9WB4VIkkOAPYFfAusD21dVJdkE+HhV7TrsmNIocw+/JEnSeFq9/brmHI81+kpKGpTkrUm2aJ/fL8npwPeA/0vy1GHHq6p3An8HfAx4wsBNhRVoVhlIU8UZfkmSpAmT5LVV9b6+85CSXAls1c6yvwp4Ic1S+81oZtwf12uC0oRzhl+SJGnyzLnMX+rBbQOz7E8HjquqO6rqatxTL3XOgl+SJGnypO8EpNatSbZKsjawB3DKwGur9ZSTNDW8qyZJkjR53LOpUXEw8HlgbeBfq+r7AEn2BC7pMzFpGriHX5IkaQwlWcTchX2AVavKiR1JmnIW/JIkSZIkTSD38EuSJEmSNIEs+CVJkiRJmkAW/JIkSZI6l+RhS7uWNHwW/JIkSZLmw7H3cC1pyGzaJ0mSJEnSBHKGX5IkSVKnkmyc5H7t8yclOSjJA3pOS5p4FvySJEmSunYCcEeSTWiW8m8IfKbflKTJZ8EvSZIkqWt/qKrbgecA76uq1wHr9pyTNPEs+CVJkiR1bXGS/YCXAF9px1bqMR9pKljwS5IkSeraS4FdgHdW1feTbAh8quecpIlnl35JkiRJnUqyOnBLVd3RXi8A7ldVN/WbmTTZnOGXJEmS1LXTgFUHrlcFTu0pF2lqWPBLkiRJ6toqVfX7mYv2+Wo95iNNBQt+SZIkSV27Mcn2MxdJdgBu7jEfaSqs2HcCkiRJkibea4Hjk/ykvV4XeEF/6UjTwaZ9kiRJkjqXZCVgcyDANVW1uOeUpIlnwS9JkiSpE0meXFWnJ3nuXK9X1YnznZM0TVzSL0mSJKkruwOnA3vN8VoBFvxSh5zhlyRJktSpJBtW1ffvaUzScNmlX5IkSVLXTphj7PPznoU0ZVzSL0mSJKkTSbYAHgPcf9Y+/rWAVfrJSpoeFvySJEmSurI58CzgAdx9H/8i4JV9JCRNE/fwS5IkSepUkl2q6lt95yFNGwt+SZIkSZ1KsjbNjP4GDKwyrqqX9ZWTNA1c0i9JkiSpa18CzgFOBe7oORdpajjDL0mSJKlTSRZW1bZ95yFNG4/lkyRJktS1ryTZs+8kpGnjDL8kSZKkTiVZBKwO3AosBgJUVa3Va2LShLPglyRJkiRpAtm0T5IkSVLnkjwQ2BRYZWasqs7uLyNp8lnwS5IkSepUklcABwOPBBYCOwPfAp7cY1rSxLNpnyRJkqSuHQzsBPygqvYAtgN+0W9K0uSz4JckSZLUtVuq6haAJPerqmuAzXvOSZp4LumXJEmS1LUfJ3kA8EXgv5L8BvhJrxlJU8Au/ZIkSZLmTZLdgfsD36iq2/rOR5pkFvySJEmSOtd26V+PgVXGVXVxfxlJk88l/ZIkSZI6leQw4K+A64A/tMOFXfqlTjnDL0mSJKlTSa4FHusSfml+2aVfkiRJUteuAB7QdxLStHGGX5IkSVKnkuwIfImm8L91Zryq9u4tKWkKuIdfkiRJUtc+DvwLcDl37eGX1DELfkmSJEld+2VVHdl3EtK0cUm/JEmSpE4lOYJmKf+XufuSfo/lkzpkwS9JkiSpU0nOmGO4qspj+aQOWfBLkiRJkjSBPJZPkiRJUqeSrJPk2CRfb6+3TPLyvvOSJp0FvyRJkqSufQw4GXh4e/0d4LV9JSNNCwt+SZIkSV17SFV9jvZIvqq6Hbij35SkyWfBL0mSJKlrNyZ5MFAASXYGbug3JWnyrdh3ApIkSZIm3utpjuTbOMl5wNrAPv2mJE0+u/RLkiRJ6lySFYHNgQDXVtXinlOSJp5L+iVJkiR1IslOSR4Gd+7b3wF4J/DeJA/qNTlpCljwS5IkSerKh4HbAJLsBrwL+ATN/v1jesxLmgru4ZckSZLUlQVV9ev2+QuAY6rqBOCEJAv7S0uaDs7wS5IkSerKgnbvPsBTgNMHXnPyUeqYP2SSJEmSunIccFaSXwI3A+cAJNkEj+WTOmeXfkmSJEmdSbIzsC5wSlXd2I5tBqxRVRf3mpw04Sz4JUmSJEmaQO7hlyRJkiRpAlnwS5IkSZI0gSz4JUmSRliSO5IsTHJFkuOTrLYcn/WxJPu0zz+SZMulfO+Tkjx+GWJcn+Qhc8R99ayxZyf52r3JVZK0bCz4JUmSRtvNVbVtVW0F3AYcMPhikgXL8qFV9Yqqumop3/Ik4D4X/EtwHLDvrLF923FJUkcs+CVJksbHOcAm7ez7GUk+A1yeZEGSw5NckOSymdn0ND6Q5KokXwUeOvNBSc5MsmP7/M+SXJzk0iSnJdmA5sbC69rVBU9MsnaSE9oYFyTZtX3vg5OckuSSJB8GMkfepwJbJFm3fc9qwFOBLyZ5a/t5VyQ5JskfvX9w1UCSHZOc2T5fPcl/tO+/JMmft+OPSXJ+m/tlSTYdxl++JI0bC35JkqQxkGRF4BnA5e3Q44BDqmpL4OXADVW1E7AT8MokGwLPATYHHgu8kjlm7JOsDfw78Lyq2gZ4flVdD/wb8K/t6oJzgPe31zsBzwM+0n7E24Bzq2o74MvA+rNjVNUdwInAX7RDewNnVNUi4ANVtVO7gmFV4Fn34a/lEOD0Nqc9gMOTrE5zs+L9VbUtsCPw4/vwmZI0MVbsOwFJkiQt1apJFrbPzwGOpSncz6+q77fjTwO2Htjzfn9gU2A34Li24P5JktPn+PydgbNnPquqfr2EPJ4KbDkwAb9WkjXbGM9t3/vVJL9ZwvuPAw6nuXGwL/CJdnyPJG8EVgMeBFwJnLSEz5jtacDeSf6+vV6F5obDt4BDkjwSOLGqvnsvP0+SJooFvyRJ0mi7uZ2pvlNbdN84OAQcWFUnz/q+PYG6h8/PvfgeaFaG7lJVN8+Ry715/3nAukm2oblhsW+SVYCjgR2r6kdJDqUp2me7nbtWpg6+HpqVCdfO+v6rk/w38Ezg5CSvqKq5bnZI0kRzSb8kSdL4Oxn46yQrASTZrF3afjZNYb2g3T+/xxzv/Rawe7sFgCQPascXAWsOfN8pwN/OXCTZtn16NrB/O/YM4IFzJVhVBXwO+Djwtaq6hbuK918mWQNYUlf+64Ed2ufPm/XnPnBm33+S7dqvGwHXVdWRNNsMtl7C50rSRLPglyRJGn8fAa4CLk5yBfBhmpWcXwC+S7Pv/0PAWbPfWFW/AF4FnJjkUuCz7UsnAc+ZadoHHATs2DbBu4q7Tgt4O7Bbkotpltj/cCl5HgdsA/xnG/u3NP0DLge+CFywhPe9HXh/knOAOwbGDwNWAi5r/9yHteMvAK5ot0JswV3bByRpqqS52SpJkiRJkiaJM/ySJEmSJE0gC35JkiRJkiaQBb8kSZIkSRPIgl+SJEmSpAlkwS9JkiRJ0gSy4JckSZIkaQJZ8EuSJEmSNIEs+CVJkiRJmkD/H2WWjRCZNgwmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx_labels = list(df_test[\"Label\"].unique())\n",
    "\n",
    "cm = confusion_matrix(df_test['Label'], df_test['Predicted Label'], labels = idx_labels)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = idx_labels, \n",
    "                     columns = idx_labels)\n",
    "\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(cm_df, annot=True, cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1561,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        precision    recall  f1-score   support\n",
      "\n",
      "                         Computational Social Science and Social Media       0.18      0.61      0.27        28\n",
      "                                      Dialogue and Interactive Systems       0.76      0.55      0.64        58\n",
      "                                              Discourse and Pragmatics       0.18      0.27      0.21        11\n",
      "                                                        Ethics and NLP       0.00      0.00      0.00         0\n",
      "                                                            Generation       0.43      0.52      0.47        42\n",
      "                                                Information Extraction       0.50      0.44      0.47        54\n",
      "                                 Information Retrieval and Text Mining       0.22      0.18      0.20        22\n",
      "                       Interpretability and Analysis of Models for NLP       0.18      0.29      0.22        52\n",
      "                     Language Grounding to Vision, Robotics and Beyond       0.22      0.21      0.21        29\n",
      "         Linguistic Theories, Cognitive Modeling and Psycholinguistics       0.38      0.33      0.35         9\n",
      "                                              Machine Learning for NLP       0.31      0.27      0.29        70\n",
      "                               Machine Translation and Multilinguality       0.76      0.61      0.68        69\n",
      "                           Phonology, Morphology and Word Segmentation       0.50      0.17      0.25        12\n",
      "                                                    Question Answering       0.71      0.30      0.42        40\n",
      "                                              Resources and Evaluation       0.00      0.00      0.00         0\n",
      "                                          Semantics: Lexical Semantics       0.33      0.38      0.35        16\n",
      "Semantics: Sentence-level Semantics, Textual Inference and Other areas       0.47      0.28      0.35        54\n",
      "           Sentiment Analysis, Stylistic Analysis, and Argument Mining       0.77      0.36      0.49        28\n",
      "                                              Speech and Multimodality       0.00      0.00      0.00         9\n",
      "                                                         Summarization       0.85      0.35      0.50        31\n",
      "                                 Syntax: Tagging, Chunking and Parsing       0.50      0.41      0.45        17\n",
      "\n",
      "                                                              accuracy                           0.38       651\n",
      "                                                             macro avg       0.39      0.31      0.33       651\n",
      "                                                          weighted avg       0.49      0.38      0.41       651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxia/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/yanxia/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/yanxia/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_test['Label'], df_test['Predicted Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Label Outcome</th>\n",
       "      <th>Label</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Machine Translation and Multilinguality</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>60.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computational Social Science and Social Media</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dialogue and Interactive Systems</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>55.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generation</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information Extraction</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>44.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Syntax: Tagging, Chunking and Parsing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>41.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Semantics: Lexical Semantics</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentiment Analysis, Stylistic Analysis, and Argument Mining</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.483871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linguistic Theories, Cognitive Modeling and Psycholinguistics</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Question Answering</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Interpretability and Analysis of Models for NLP</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>28.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Semantics: Sentence-level Semantics, Textual Inference and Other areas</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>27.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Discourse and Pragmatics</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning for NLP</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Language Grounding to Vision, Robotics and Beyond</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Information Retrieval and Text Mining</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Phonology, Morphology and Word Segmentation</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Speech and Multimodality</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Label Outcome                                                                   Label  \\\n",
       "10                                            Machine Translation and Multilinguality   \n",
       "0                                       Computational Social Science and Social Media   \n",
       "1                                                    Dialogue and Interactive Systems   \n",
       "3                                                                          Generation   \n",
       "4                                                              Information Extraction   \n",
       "18                                              Syntax: Tagging, Chunking and Parsing   \n",
       "13                                                       Semantics: Lexical Semantics   \n",
       "15                        Sentiment Analysis, Stylistic Analysis, and Argument Mining   \n",
       "17                                                                      Summarization   \n",
       "8                       Linguistic Theories, Cognitive Modeling and Psycholinguistics   \n",
       "12                                                                 Question Answering   \n",
       "6                                     Interpretability and Analysis of Models for NLP   \n",
       "14             Semantics: Sentence-level Semantics, Textual Inference and Other areas   \n",
       "2                                                            Discourse and Pragmatics   \n",
       "9                                                            Machine Learning for NLP   \n",
       "7                                   Language Grounding to Vision, Robotics and Beyond   \n",
       "5                                               Information Retrieval and Text Mining   \n",
       "11                                        Phonology, Morphology and Word Segmentation   \n",
       "16                                                           Speech and Multimodality   \n",
       "\n",
       "Label Outcome  False  True   Accuracy  \n",
       "10              27.0  42.0  60.869565  \n",
       "0               11.0  17.0  60.714286  \n",
       "1               26.0  32.0  55.172414  \n",
       "3               20.0  22.0  52.380952  \n",
       "4               30.0  24.0  44.444444  \n",
       "18              10.0   7.0  41.176471  \n",
       "13              10.0   6.0  37.500000  \n",
       "15              18.0  10.0  35.714286  \n",
       "17              20.0  11.0  35.483871  \n",
       "8                6.0   3.0  33.333333  \n",
       "12              28.0  12.0  30.000000  \n",
       "6               37.0  15.0  28.846154  \n",
       "14              39.0  15.0  27.777778  \n",
       "2                8.0   3.0  27.272727  \n",
       "9               51.0  19.0  27.142857  \n",
       "7               23.0   6.0  20.689655  \n",
       "5               18.0   4.0  18.181818  \n",
       "11              10.0   2.0  16.666667  \n",
       "16               9.0   0.0   0.000000  "
      ]
     },
     "execution_count": 1562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_accuracy = df_test_outcome.pivot(index=\"Label\", columns=\"Label Outcome\", values=\"Counts\").reset_index().fillna(0)\n",
    "df_test_accuracy[\"Accuracy\"] = df_test_accuracy[True] / (df_test_accuracy[False] + df_test_accuracy[True]) * 100\n",
    "df_test_accuracy = df_test_accuracy.sort_values(by = 'Accuracy', axis=0, ascending=False)\n",
    "df_test_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b110531817a2bf0b8e1fa59ad47ae74cf2e8602bdaf1b8cf6b96ebd8cf78ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
