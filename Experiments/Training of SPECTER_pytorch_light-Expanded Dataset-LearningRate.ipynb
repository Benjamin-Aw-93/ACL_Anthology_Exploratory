{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import time\n",
    "\n",
    "# Reading in files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Torch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast as AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Lightning modules\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.functional import accuracy, auroc\n",
    "from torchmetrics import F1Score\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassPrecision, MulticlassRecall\n",
    "\n",
    "# Split dataset/validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Importing own functions \n",
    "from extract.importing_data import get_section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/Collated_dataset_for_scientific_papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Intro Concl\", \"Labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"string\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = list(df['label'].unique())\n",
    "possible_labels_num = list(range(0,len(possible_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'allenai/specter'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = zip(possible_labels, possible_labels_num)\n",
    "label_to_idx = {label: num  for label, num in mapping}\n",
    "mapping = zip(possible_labels, possible_labels_num)\n",
    "idx_to_label = {num: label for label, num in mapping}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_COUNT = 512\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 25 # Changes: Edit the batch size here\n",
    "KFOLD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecterDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: AutoTokenizer, max_token_len: int = MAX_TOKEN_COUNT, mapping = label_to_idx):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "        self.mapping = mapping\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "    \n",
    "        data_row = self.data.iloc[index]\n",
    "        text = data_row[\"string\"]\n",
    "        labels = self.mapping[data_row[\"label\"]]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_token_len,\n",
    "          return_token_type_ids=False,\n",
    "          padding=\"max_length\",\n",
    "          truncation=True,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "          text=text,\n",
    "          input_ids=encoding[\"input_ids\"].flatten(),\n",
    "          attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "          labels=labels\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecterDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, df,\n",
    "                 tokenizer,\n",
    "                 k = 0,  # fold number\n",
    "                 split_seed = 123,  # split needs to be always the same for correct cross validation\n",
    "                 num_splits = KFOLD,\n",
    "                 batch_size = BATCH_SIZE, \n",
    "                 max_token_len = MAX_TOKEN_COUNT,\n",
    "                 num_workers = 0,\n",
    "                 pin_memory = False):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters(logger=False)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # choose fold to train on\n",
    "        kf = StratifiedKFold(n_splits=self.hparams.num_splits, shuffle=True, random_state=self.hparams.split_seed)\n",
    "        all_splits = [k for k in kf.split(df, df.label)]\n",
    "        train_indexes, val_indexes = all_splits[self.hparams.k]\n",
    "        train_indexes, val_indexes = train_indexes.tolist(), val_indexes.tolist()\n",
    "\n",
    "        self.data_train, self.data_val = df.iloc[train_indexes], df.iloc[val_indexes]\n",
    "        \n",
    "        self.train_dataset = SpecterDataset(\n",
    "          self.data_train,\n",
    "          self.hparams.tokenizer,\n",
    "          self.hparams.max_token_len\n",
    "        )\n",
    "        self.val_dataset = SpecterDataset(\n",
    "          self.data_val,\n",
    "          self.hparams.tokenizer,\n",
    "          self.hparams.max_token_len\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "          self.train_dataset,\n",
    "          batch_size = self.hparams.batch_size,\n",
    "          shuffle=True\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "          self.val_dataset,\n",
    "          batch_size = self.hparams.batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecterClassModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "    \n",
    "        super().__init__()\n",
    "        self.specter = AutoModel.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "        # Changes: Edit model architecture forward pass here\n",
    "        self.classifier = nn.Linear(self.specter.config.hidden_size, n_classes)\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.acc = MulticlassAccuracy(num_classes = 21, average = 'weighted') #measure performance based on weighted average\n",
    "        self.f1 = MulticlassF1Score(num_classes = 21, average = 'weighted')\n",
    "        self.prec = MulticlassPrecision(num_classes = 21, average = 'weighted')\n",
    "        self.rec = MulticlassRecall(num_classes = 21, average = 'weighted')\n",
    "        \n",
    "        # Changes: Comment below code to remove freezing of the SPECTER embeddings\n",
    "        for name, param in self.specter.named_parameters():\n",
    "            if name.startswith('embeddings'):\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.specter(input_ids, attention_mask=attention_mask)\n",
    "        # Changes: Edit model architecture forward pass here\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "            #acc = self.acc(output, labels)\n",
    "            #f1 = self.f1(output, labels)\n",
    "            #prec = self.prec(output, labels)\n",
    "            #rec = self.rec(output, labels)\n",
    "        return loss, output#, acc, f1, prec, rec\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        #loss, output, acc, f1, prec, rec = self(input_ids, attention_mask, labels)\n",
    "        loss, output = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": output, \"labels\": labels}\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        #loss, output, acc, f1, prec, rec = self(input_ids, attention_mask, labels)\n",
    "        loss, output = self(input_ids, attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\"loss\": loss, \"predictions\": output, \"labels\": labels}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = sum(output['loss'].item() for output in outputs) / len(outputs)\n",
    "        \n",
    "        predictions = torch.cat([output['predictions'] for output in outputs])\n",
    "        labels = torch.cat([output['labels'] for output in outputs])\n",
    "        \n",
    "        acc = self.acc(predictions, labels)\n",
    "        f1 = self.f1(predictions, labels)\n",
    "        prec = self.prec(predictions, labels)\n",
    "        rec = self.rec(predictions, labels)\n",
    "        print(\"******Train epoch {} eval metrics: loss {:.8f}, f1 {:.4f} prec {:.4f} rec {:.4f}, acc {:.4f}\".format(self.current_epoch, avg_loss, f1, prec, rec, acc))\n",
    "        \n",
    "        self.logger.experiment.add_scalars('loss', {'train': avg_loss}, self.current_epoch)   \n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = sum(output['loss'].item() for output in outputs) / len(outputs)\n",
    "\n",
    "        predictions = torch.cat([output['predictions'] for output in outputs])\n",
    "        labels = torch.cat([output['labels'] for output in outputs])\n",
    "        \n",
    "        acc = self.acc(predictions, labels)\n",
    "        f1 = self.f1(predictions, labels)\n",
    "        prec = self.prec(predictions, labels)\n",
    "        rec = self.rec(predictions, labels)\n",
    "        print(\"******Val epoch {} eval metrics: loss {:.8f}, f1 {:.4f} prec {:.4f} rec {:.4f}, acc {:.4f}\".format(self.current_epoch, avg_loss, f1, prec, rec, acc))\n",
    "        \n",
    "            \n",
    "        #For final output/Tensorboard visualisation\n",
    "        self.log(\"Ignore/acc\", acc, logger=True)\n",
    "        self.log(\"Ignore/f1\", f1, logger=True)\n",
    "        self.log(\"Ignore/prec\", prec, logger=True)\n",
    "        self.log(\"Ignore/rec\", rec, logger=True)\n",
    "        \n",
    "        #For Tensorboard visualisaion with Epoch as x axis\n",
    "        self.logger.experiment.add_scalar('Collated/acc', acc, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar('Collated/f1', f1, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar('Collated/prec', prec, self.current_epoch)\n",
    "        self.logger.experiment.add_scalar('Collated/rec', rec, self.current_epoch)\n",
    "    \n",
    "        self.logger.experiment.add_scalars('loss', {'val': avg_loss}, self.current_epoch)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5) # Changes: Edit the learning rate\n",
    "        # Changes: Removed the scheduler\n",
    "        scheduler = get_linear_schedule_with_warmup( # Changes: Edit the scheduler\n",
    "          optimizer,\n",
    "          num_warmup_steps=self.n_warmup_steps,\n",
    "          num_training_steps=self.n_training_steps\n",
    "        )\n",
    "        \n",
    "        # Changes: Edit the optimizer\n",
    "        return dict(\n",
    "          optimizer = optimizer,\n",
    "          lr_scheduler = dict(\n",
    "            scheduler = scheduler,\n",
    "            interval = 'step'\n",
    "          )\n",
    "        )\n",
    "        # Changes: Edit the optimizer\n",
    "        #return dict(\n",
    "        #  optimizer = optimizer\n",
    "        #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"FixedLearningRate(2e-5)\"\n",
    "time_now = time.strftime(\"%d_%m_%Y_%H_%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = \"checkpoints\",\n",
    "    filename = f\"best-checkpoint-{experiment}\",\n",
    "    save_top_k = 1,\n",
    "    verbose = True,\n",
    "    monitor = \"val_loss\",\n",
    "    mode = \"min\"\n",
    ")\n",
    "\n",
    "\n",
    "# early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 405)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch= round(len(df) * 0.8 // BATCH_SIZE)\n",
    "total_training_steps = steps_per_epoch * N_EPOCHS\n",
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: lightning_logs/Specter_FixedLearningRate(2e-5)_01_02_2023_09_18_run0\n",
      "/home/yanxia/anaconda3/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /home/yanxia/projects/ACL_Anthology_Exploratory/Experiments/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/yanxia/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name       | Type                | Params\n",
      "---------------------------------------------------\n",
      "0 | specter    | BertModel           | 109 M \n",
      "1 | classifier | Linear              | 16.1 K\n",
      "2 | criterion  | CrossEntropyLoss    | 0     \n",
      "3 | acc        | MulticlassAccuracy  | 0     \n",
      "4 | f1         | MulticlassF1Score   | 0     \n",
      "5 | prec       | MulticlassPrecision | 0     \n",
      "6 | rec        | MulticlassRecall    | 0     \n",
      "---------------------------------------------------\n",
      "85.7 M    Trainable params\n",
      "24.3 M    Non-trainable params\n",
      "109 M     Total params\n",
      "439.818   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxia/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Val epoch 0 eval metrics: loss 3.16727924, f1 0.0000 prec 0.0000 rec 0.0000, acc 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanxia/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9e624e983847cca6c1634fa60b4a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 82: 'val_loss' reached 2.11448 (best 2.11448), saving model to '/home/yanxia/projects/ACL_Anthology_Exploratory/Experiments/checkpoints/best-checkpoint-FixedLearningRate(2e-5)-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Val epoch 0 eval metrics: loss 2.11563609, f1 0.4314 prec 0.4058 rec 0.5088, acc 0.5088\n",
      "******Train epoch 0 eval metrics: loss 2.76017244, f1 0.1880 prec 0.2707 rec 0.2078, acc 0.2078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 164: 'val_loss' reached 1.44826 (best 1.44826), saving model to '/home/yanxia/projects/ACL_Anthology_Exploratory/Experiments/checkpoints/best-checkpoint-FixedLearningRate(2e-5)-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Val epoch 1 eval metrics: loss 1.44533209, f1 0.5868 prec 0.6055 rec 0.6306, acc 0.6306\n",
      "******Train epoch 1 eval metrics: loss 1.72573994, f1 0.5186 prec 0.5353 rec 0.5747, acc 0.5747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 246: 'val_loss' reached 1.23638 (best 1.23638), saving model to '/home/yanxia/projects/ACL_Anthology_Exploratory/Experiments/checkpoints/best-checkpoint-FixedLearningRate(2e-5)-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Val epoch 2 eval metrics: loss 1.23993477, f1 0.6757 prec 0.6671 rec 0.6994, acc 0.6994\n",
      "******Train epoch 2 eval metrics: loss 1.22169697, f1 0.6797 prec 0.7221 rec 0.7058, acc 0.7058\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 328: 'val_loss' reached 1.17819 (best 1.17819), saving model to '/home/yanxia/projects/ACL_Anthology_Exploratory/Experiments/checkpoints/best-checkpoint-FixedLearningRate(2e-5)-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Val epoch 3 eval metrics: loss 1.18220257, f1 0.6767 prec 0.6661 rec 0.6994, acc 0.6994\n",
      "******Train epoch 3 eval metrics: loss 0.96518447, f1 0.7461 prec 0.7718 rec 0.7701, acc 0.7701\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 410: 'val_loss' reached 1.16230 (best 1.16230), saving model to '/home/yanxia/projects/ACL_Anthology_Exploratory/Experiments/checkpoints/best-checkpoint-FixedLearningRate(2e-5)-v5.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******Val epoch 4 eval metrics: loss 1.16677080, f1 0.6806 prec 0.6713 rec 0.7033, acc 0.7033\n",
      "******Train epoch 4 eval metrics: loss 0.84222512, f1 0.7820 prec 0.8045 rec 0.8021, acc 0.8021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_02_2023_09_18 01_02_2023_09_22\n"
     ]
    }
   ],
   "source": [
    "st_time = time.strftime(\"%d_%m_%Y_%H_%M\")\n",
    "result_acc_lst = []\n",
    "result_f1_lst = []\n",
    "result_prec_lst = []\n",
    "result_recall_lst = []\n",
    "nums_fold = 5\n",
    "split_seed = 123\n",
    "\n",
    "for k in range(nums_fold):\n",
    "    data_module = SpecterDataModule(df, tokenizer, k = k)\n",
    "\n",
    "    # here we train the model on given split...\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name = f\"Specter_{experiment}_{time_now}_run{k}\")\n",
    "    model = SpecterClassModel(n_classes = 21, n_warmup_steps = warmup_steps, n_training_steps = total_training_steps)\n",
    "    trainer = pl.Trainer(logger = logger, callbacks = [checkpoint_callback], max_epochs = N_EPOCHS, accelerator = \"auto\", devices=[1])\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    accuracy = trainer.callback_metrics['Ignore/acc'].item()\n",
    "    f1 = trainer.callback_metrics['Ignore/f1'].item()\n",
    "    precision = trainer.callback_metrics['Ignore/prec'].item()\n",
    "    recall = trainer.callback_metrics['Ignore/rec'].item()\n",
    "    \n",
    "    result_acc_lst.append(accuracy)\n",
    "    result_f1_lst.append(f1)\n",
    "    result_prec_lst.append(precision)\n",
    "    result_recall_lst.append(recall)\n",
    "    break\n",
    "\n",
    "average_val_acc_score = sum(result_acc_lst) / len(result_acc_lst)\n",
    "average_val_f1_score = sum(result_f1_lst) / len(result_f1_lst)\n",
    "average_val_prec_score = sum(result_prec_lst) / len(result_prec_lst)\n",
    "average_val_recall_score = sum(result_recall_lst) / len(result_recall_lst)\n",
    "\n",
    "ed_time = time.strftime(\"%d_%m_%Y_%H_%M\")\n",
    "print(st_time, ed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy of the validation set across 5 folds is: 0.7033398747444153\n",
      "The average F1 score of the validation set across 5 folds is: 0.6806449890136719\n",
      "The average precision of the validation set across 5 folds is: 0.6712760925292969\n",
      "The average recall of the validation set across 5 folds is: 0.7033398747444153\n"
     ]
    }
   ],
   "source": [
    "print(f\"The average accuracy of the validation set across 5 folds is: {average_val_acc_score}\")\n",
    "print(f\"The average F1 score of the validation set across 5 folds is: {average_val_f1_score}\")\n",
    "print(f\"The average precision of the validation set across 5 folds is: {average_val_prec_score}\")\n",
    "print(f\"The average recall of the validation set across 5 folds is: {average_val_recall_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop here for now We might want to take a look at creating a test set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2b110531817a2bf0b8e1fa59ad47ae74cf2e8602bdaf1b8cf6b96ebd8cf78ed6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
